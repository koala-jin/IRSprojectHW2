import streamlit as st
import time
from deep_translator import GoogleTranslator
from bert_engine.embedder import BertEmbedder
from bert_engine.searcher import SemanticSearcher
from bert_engine.database import MySQLDocumentDB
import base64

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI å‘é‡æ£€ç´¢ç³»ç»Ÿ",
    layout="centered",
)

# åŠ è½½èƒŒæ™¯å›¾åƒ
def set_background(image_path: str):
    with open(image_path, "rb") as f:
        encoded = base64.b64encode(f.read()).decode()
    css = f"""
    <style>
    .stApp {{
        background-image: url("data:image/png;base64,{encoded}");
        background-size: cover;
        background-repeat: no-repeat;
        background-attachment: fixed;
        color: white;
    }}
    h1 {{
        text-align: center;
        font-size: 42px;
        font-weight: bold;
        color: white;
        text-shadow: 2px 2px 4px #000;
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        background-color: rgba(0, 0, 0, 0);  /* é€æ˜èƒŒæ™¯ */
    }}
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

set_background("Background.png")

# ç¾åŒ–åçš„æ ‡é¢˜ï¼ˆæ— èƒŒæ™¯å—ï¼‰
st.markdown(
    "<h1 style='text-align: center;'>ğŸ¤– AI å‘é‡æ£€ç´¢ç³»ç»Ÿ</h1>", 
    unsafe_allow_html=True
)
# åˆå§‹åŒ– session_state
if "all_documents" not in st.session_state:
    st.session_state.all_documents = []
if "current_results" not in st.session_state:
    st.session_state.current_results = []
if "search_done" not in st.session_state:
    st.session_state.search_done = False
if "embedder" not in st.session_state:
    st.session_state.embedder = BertEmbedder()
if "elapsed_time" not in st.session_state:
    st.session_state.elapsed_time = 0.0

# æ£€ç´¢è®¾ç½®
query = st.text_input("è¯·è¾“å…¥æ£€ç´¢å†…å®¹ï¼ˆä¸­æ–‡å°†è‡ªåŠ¨ç¿»è¯‘ä¸ºè‹±æ–‡ï¼‰")
field = st.selectbox("é€‰æ‹©è®¡ç®—ç›¸ä¼¼åº¦æ ‡å‡†", ["title", "abstract", "authors", "category", "title+abstract"], index=4)
sort_by = st.selectbox("æ’åºæ–¹å¼", ["relevance", "date"])
page_size = st.selectbox("æ¯é¡µå±•ç¤ºç»“æœæ•°é‡", [5, 10, 20, 50])
similarity_threshold = st.slider("ç›¸å…³æ€§ä¸‹é™å€¼ï¼ˆç›¸ä¼¼åº¦ï¼‰", 0.2, 0.4, 0.25, step=0.01)
current_page = st.number_input("é¡µç ", min_value=1, value=1, step=1)

col1, col2 = st.columns([1, 1])
search_triggered = col1.button("å¼€å§‹æ£€ç´¢")
refine_triggered = col2.button("åœ¨ç»“æœä¸­æ£€ç´¢")

if (search_triggered or refine_triggered) and query.strip():
    #è®¡æ—¶å™¨
    start_time = time.time()
    #ç¿»è¯‘ï¼šä¸­æ–‡-->è‹±æ–‡
    translated_query = GoogleTranslator(source='auto', target='en').translate(query)
    #è¿›å…¥æ•°æ®åº“è¿›è¡ŒåŒ¹é…
    if search_triggered:
        db = MySQLDocumentDB(password='123456')
        st.session_state.all_documents = db.fetch_all_documents()
        source_docs = st.session_state.all_documents
    else:
        source_docs = st.session_state.current_results

    documents = [{
        "id": doc["id"] if refine_triggered else doc["paper_id"],
        "title": doc["title"],
        "abstract": doc["abstract"],
        "authors": doc["authors"],
        "category": doc["category"],
        "published": doc["published"]
    } for doc in source_docs]

    searcher = SemanticSearcher(st.session_state.embedder, documents, field=field)
    all_results = searcher.search(translated_query, top_k=1000, sort_by=sort_by)
    filtered_results = [(pid, score) for pid, score in all_results if score >= similarity_threshold]

    result_ids_sorted = [pid for pid, _ in filtered_results]
    st.session_state.current_results = [next(doc for doc in documents if doc["id"] == pid) for pid in result_ids_sorted]
    st.session_state.filtered_result_scores = {pid: score for pid, score in filtered_results}
    st.session_state.search_done = True
    st.session_state.elapsed_time = time.time() - start_time

# å±•ç¤ºç»“æœ
if st.session_state.search_done and st.session_state.current_results:
    total_results = len(st.session_state.current_results)
    total_pages = (total_results + page_size - 1) // page_size
    if current_page > total_pages:
        st.warning(f"é¡µç è¶…è¿‡æœ€å¤§é¡µæ•°ï¼ˆå…± {total_pages} é¡µï¼‰ï¼Œè¯·é‡æ–°é€‰æ‹©ã€‚")
    else:
        st.markdown(f"â± æœ¬æ¬¡æ£€ç´¢è€—æ—¶: **{st.session_state.elapsed_time:.2f} ç§’**")
        st.markdown(f"ğŸ” å…±æ‰¾åˆ° {total_results} æ¡ç›¸å…³ç»“æœï¼Œå½“å‰ä¸ºç¬¬ {current_page} é¡µï¼Œæ¯é¡µæ˜¾ç¤º {page_size} æ¡ï¼š")

        start_idx = (current_page - 1) * page_size
        end_idx = start_idx + page_size
        page_results = st.session_state.current_results[start_idx:end_idx]

        db = MySQLDocumentDB(password='123456')
        for doc in page_results:
            score = st.session_state.filtered_result_scores.get(doc["id"], 0)
            st.markdown("---")
            st.markdown(f"ğŸ“Œ **{doc['title']}**")
            st.markdown(f"ğŸ“… å‘å¸ƒæ—¶é—´: {doc['published']}")
            st.markdown(f"ğŸ§  ç›¸ä¼¼åº¦: {score:.2f}")
            with st.expander("ğŸ“– æŸ¥çœ‹æ‘˜è¦å…¨æ–‡"):
                st.markdown(f"{doc['abstract']}")
            with st.expander("ğŸ“˜ GPTæ‘˜è¦æŸ¥çœ‹"):
                try:
                    summary = db.fetch_summary_by_id(doc["id"])
                    st.markdown(summary if summary else "âš ï¸ å½“å‰è®ºæ–‡æš‚æ— æ‘˜è¦æ•°æ®ã€‚")
                except Exception as e:
                    st.markdown(f"âŒ è·å–æ‘˜è¦å¤±è´¥: {e}")
