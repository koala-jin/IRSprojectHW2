-- MySQL dump 10.13  Distrib 8.0.42, for Win64 (x86_64)
--
-- Host: localhost    Database: ai_papers
-- ------------------------------------------------------
-- Server version	8.0.42

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!50503 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `ai_processed_papers`
--

DROP TABLE IF EXISTS `ai_processed_papers`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `ai_processed_papers` (
  `paper_id` varchar(50) COLLATE utf8mb4_unicode_ci NOT NULL,
  `title` text COLLATE utf8mb4_unicode_ci,
  `abstract` text COLLATE utf8mb4_unicode_ci,
  `authors` text COLLATE utf8mb4_unicode_ci,
  `published` date DEFAULT NULL,
  `category` varchar(20) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `main_category` varchar(100) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `pdf_url` text COLLATE utf8mb4_unicode_ci,
  `summary` text COLLATE utf8mb4_unicode_ci,
  PRIMARY KEY (`paper_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `ai_processed_papers`
--

LOCK TABLES `ai_processed_papers` WRITE;
/*!40000 ALTER TABLE `ai_processed_papers` DISABLE KEYS */;
INSERT INTO `ai_processed_papers` VALUES ('2505.20016v1','TTPA: Token-level Tool-use Preference Alignment Training Framework with Fine-grained Evaluation','Existing tool-learning methods usually rely on supervised fine-tuning, they\noften overlook fine-grained optimization of internal tool call details, leading\nto limitations in preference alignment and error discrimination. To overcome\nthese challenges, we propose Token-level Tool-use Preference Alignment Training\nFramework (TTPA), a training paradigm for constructing token-level tool-use\npreference datasets that align LLMs with fine-grained preferences using a novel\nerror-oriented scoring mechanism. TTPA first introduces reversed dataset\nconstruction, a method for creating high-quality, multi-turn tool-use datasets\nby reversing the generation flow. Additionally, we propose Token-level\nPreference Sampling (TPS) to capture fine-grained preferences by modeling\ntoken-level differences during generation. To address biases in scoring, we\nintroduce the Error-oriented Scoring Mechanism (ESM), which quantifies\ntool-call errors and can be used as a training signal. Extensive experiments on\nthree diverse benchmark datasets demonstrate that TTPA significantly improves\ntool-using performance while showing strong generalization ability across\nmodels and datasets.','Chengrui Huang, Shen Gao, Zhengliang Shi, Dongsheng Wang, Shuo Shang','2025-05-26','cs.CL','LLM (语言模型)','http://arxiv.org/pdf/2505.20016v1','该论文提出了一种 Token-level Tool-use Preference Alignment Training Framework (TTPA) 方法，通过构建 token-level 工具使用偏好数据集，使用新颖的面向错误的评分机制来对齐 LLMs 与细粒度偏好，从而提高工具使用性能并展现强大的泛化能力。'),('2505.20020v1','Ontology- and LLM-based Data Harmonization for Federated Learning in Healthcare','The rise of electronic health records (EHRs) has unlocked new opportunities\nfor medical research, but privacy regulations and data heterogeneity remain key\nbarriers to large-scale machine learning. Federated learning (FL) enables\ncollaborative modeling without sharing raw data, yet faces challenges in\nharmonizing diverse clinical datasets. This paper presents a two-step data\nalignment strategy integrating ontologies and large language models (LLMs) to\nsupport secure, privacy-preserving FL in healthcare, demonstrating its\neffectiveness in a real-world project involving semantic mapping of EHR data.','Natallia Kokash, Lei Wang, Thomas H. Gillespie, Adam Belloum, Paola Grosso, Sara Quinney, Lang Li, Bernard de Bono','2025-05-26','cs.LG','LLM、医疗保健领域','http://arxiv.org/pdf/2505.20020v1','该论文介绍了一种整合本体和大型语言模型的两步数据对齐策略，以支持在医疗保健领域进行安全、隐私保护的联邦学习，通过一个涉及电子健康记录数据语义映射的真实项目展示了其有效性。'),('2505.20021v1','Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models','Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal\ncomprehension and reasoning capabilities, yet they often struggle with\ntrivially simple visual tasks. In this work, we focus on the domain of basic 2D\nEuclidean geometry and systematically categorize the fundamental, indivisible\nvisual perception skills, which we refer to as atomic visual skills. We then\nintroduce the Atomic Visual Skills Dataset (AVSD) for evaluating VLMs on the\natomic visual skills. Using AVSD, we benchmark state-of-the-art VLMs and find\nthat they struggle with these tasks, despite being trivial for adult humans.\nOur findings highlight the need for purpose-built datasets to train and\nevaluate VLMs on atomic, rather than composite, visual perception tasks.','Hyunsik Chae, Seungwoo Yoon, Jaden Park, Chloe Yewon Chun, Yongin Cho, Mu Cai, Yong Jae Lee, Ernest K. Ryu','2025-05-26','cs.CV','图像识别','http://arxiv.org/pdf/2505.20021v1','本文研究了最近的视觉-语言模型在基本二维欧几里得几何领域的表现，系统地对基本的视觉感知技能进行了分类，并介绍了原子视觉技能数据集（AVSD）来评估VLMs的性能。研究发现，尽管这些任务对成年人来说很简单，但最先进的VLMs在这些任务上仍然表现不佳。'),('2505.20023v1','Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking','Autonomous agents, which perceive environments and take actions to achieve\ngoals, have become increasingly feasible with the advancements in large\nlanguage models (LLMs). However, current powerful agents often depend on\nsophisticated prompt engineering combined with closed-source LLMs like GPT-4.\nAlthough training open-source LLMs using expert trajectories from teacher\nmodels has yielded some improvements in agent capabilities, this approach still\nfaces limitations such as performance plateauing and error propagation. To\nmitigate these challenges, we propose STeP, a novel method for improving\nLLM-based agent training. We synthesize self-reflected trajectories that\ninclude reflections and corrections of error steps, which enhance the\neffectiveness of LLM agents in learning from teacher models, enabling them to\nbecome agents capable of self-reflecting and correcting. We also introduce\npartial masking strategy that prevents the LLM from internalizing incorrect or\nsuboptimal steps. Experiments demonstrate that our method improves agent\nperformance across three representative tasks: ALFWorld, WebShop, and SciWorld.\nFor the open-source model LLaMA2-7B-Chat, when trained using self-reflected\ntrajectories constructed with Qwen1.5-110B-Chat as the teacher model, it\nachieves comprehensive improvements with less training data compared to agents\ntrained exclusively on expert trajectories.','Yihan Chen, Benfeng Xu, Xiaorui Wang, Yongdong Zhang, Zhendong Mao','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20023v1','该论文提出了一种名为STeP的新方法，用于改进基于LLM的代理训练。通过合成包含错误步骤反思和修正的自我反思轨迹，增强了LLM代理从教师模型学习的效果，使它们能够成为能够自我反思和纠正的代理。'),('2505.20024v1','ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving','Due to the powerful vision-language reasoning and generalization abilities,\nmultimodal large language models (MLLMs) have garnered significant attention in\nthe field of end-to-end (E2E) autonomous driving. However, their application to\nclosed-loop systems remains underexplored, and current MLLM-based methods have\nnot shown clear superiority to mainstream E2E imitation learning approaches. In\nthis work, we propose ReasonPlan, a novel MLLM fine-tuning framework designed\nfor closed-loop driving through holistic reasoning with a self-supervised Next\nScene Prediction task and supervised Decision Chain-of-Thought process. This\ndual mechanism encourages the model to align visual representations with\nactionable driving context, while promoting interpretable and causally grounded\ndecision making. We curate a planning-oriented decision reasoning dataset,\nnamely PDR, comprising 210k diverse and high-quality samples. Our method\noutperforms the mainstream E2E imitation learning method by a large margin of\n19% L2 and 16.1 driving score on Bench2Drive benchmark. Furthermore, ReasonPlan\ndemonstrates strong zero-shot generalization on unseen DOS benchmark,\nhighlighting its adaptability in handling zero-shot corner cases. Code and\ndataset will be found in https://github.com/Liuxueyi/ReasonPlan.','Xueyi Liu, Zuodong Zhong, Yuxin Guo, Yun-Fu Liu, Zhiguo Su, Qichao Zhang, Junli Wang, Yinfeng Gao, Yupeng Zheng, Qiao Lin, Huiyong Chen, Dongbin Zhao','2025-05-26','cs.CV','自然语言处理','http://arxiv.org/pdf/2505.20024v1','本论文提出了一种新的多模态大型语言模型（MLLM）微调框架 ReasonPlan，通过自监督的下一个场景预测任务和监督的决策思维链过程，实现了闭环驾驶的全面推理。他们构建了一个规划导向的决策推理数据集 PDR，并在 Bench2Drive 基准测试中比主流的端到端模仿学习方法表现出了显著的优势。'),('2505.20026v1','Gradient Inversion Transcript: Leveraging Robust Generative Priors to Reconstruct Training Data from Gradient Leakage','We propose Gradient Inversion Transcript (GIT), a novel generative approach\nfor reconstructing training data from leaked gradients. GIT employs a\ngenerative attack model, whose architecture is tailored to align with the\nstructure of the leaked model based on theoretical analysis. Once trained\noffline, GIT can be deployed efficiently and only relies on the leaked\ngradients to reconstruct the input data, rendering it applicable under various\ndistributed learning environments. When used as a prior for other iterative\noptimization-based methods, GIT not only accelerates convergence but also\nenhances the overall reconstruction quality. GIT consistently outperforms\nexisting methods across multiple datasets and demonstrates strong robustness\nunder challenging conditions, including inaccurate gradients, data distribution\nshifts and discrepancies in model parameters.','Xinping Chen, Chen Liu','2025-05-26','cs.LG','生成模型','http://arxiv.org/pdf/2505.20026v1','该论文提出了一种名为Gradient Inversion Transcript (GIT)的新型生成方法，用于从泄漏的梯度中重建训练数据。通过使用生成式攻击模型，GIT可以高效地重建输入数据，并在各种分布式学习环境下适用。在其他基于迭代优化方法的先验条件下使用GIT不仅加速了收敛速度，还提高了整体重建质量。GIT在多个数据集上表现优异，并在挑战性条件下展现出强大的鲁棒性。'),('2505.20027v1','Multi-modal brain encoding models for multi-modal stimuli','Despite participants engaging in unimodal stimuli, such as watching images or\nsilent videos, recent work has demonstrated that multi-modal Transformer models\ncan predict visual brain activity impressively well, even with incongruent\nmodality representations. This raises the question of how accurately these\nmulti-modal models can predict brain activity when participants are engaged in\nmulti-modal stimuli. As these models grow increasingly popular, their use in\nstudying neural activity provides insights into how our brains respond to such\nmulti-modal naturalistic stimuli, i.e., where it separates and integrates\ninformation across modalities through a hierarchy of early sensory regions to\nhigher cognition. We investigate this question by using multiple unimodal and\ntwo types of multi-modal models-cross-modal and jointly pretrained-to determine\nwhich type of model is more relevant to fMRI brain activity when participants\nare engaged in watching movies. We observe that both types of multi-modal\nmodels show improved alignment in several language and visual regions. This\nstudy also helps in identifying which brain regions process unimodal versus\nmulti-modal information. We further investigate the contribution of each\nmodality to multi-modal alignment by carefully removing unimodal features one\nby one from multi-modal representations, and find that there is additional\ninformation beyond the unimodal embeddings that is processed in the visual and\nlanguage regions. Based on this investigation, we find that while for\ncross-modal models, their brain alignment is partially attributed to the video\nmodality; for jointly pretrained models, it is partially attributed to both the\nvideo and audio modalities. This serves as a strong motivation for the\nneuroscience community to investigate the interpretability of these models for\ndeepening our understanding of multi-modal information processing in brain.','Subba Reddy Oota, Khushbu Pahwa, Mounika Marreddy, Maneesh Singh, Manish Gupta, Bapi S. Raju','2025-05-26','q-bio.NC','自然语言处理','http://arxiv.org/pdf/2505.20027v1','该论文研究了多模态Transformer模型在预测大脑活动方面的表现，特别是在参与多模态刺激时的情况。通过比较不同类型的模型在观看电影时对fMRI脑活动的预测能力，发现多模态模型在语言和视觉区域的对齐性得到改善，同时也揭示了不同模态在多模态对齐中的贡献。'),('2505.20029v1','Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)','Transformer-based language models, though not explicitly trained to mimic\nbrain recordings, have demonstrated surprising alignment with brain activity.\nProgress in these models-through increased size, instruction-tuning, and\nmultimodality-has led to better representational alignment with neural data.\nRecently, a new class of instruction-tuned multimodal LLMs (MLLMs) have\nemerged, showing remarkable zero-shot capabilities in open-ended multimodal\nvision tasks. However, it is unknown whether MLLMs, when prompted with natural\ninstructions, lead to better brain alignment and effectively capture\ninstruction-specific representations. To address this, we first investigate\nbrain alignment, i.e., measuring the degree of predictivity of neural visual\nactivity using text output response embeddings from MLLMs as participants\nengage in watching natural scenes. Experiments with 10 different instructions\nshow that MLLMs exhibit significantly better brain alignment than vision-only\nmodels and perform comparably to non-instruction-tuned multimodal models like\nCLIP. We also find that while these MLLMs are effective at generating\nhigh-quality responses suitable to the task-specific instructions, not all\ninstructions are relevant for brain alignment. Further, by varying\ninstructions, we make the MLLMs encode instruction-specific visual concepts\nrelated to the input image. This analysis shows that MLLMs effectively capture\ncount-related and recognition-related concepts, demonstrating strong alignment\nwith brain activity. Notably, the majority of the explained variance of the\nbrain encoding models is shared between MLLM embeddings of image captioning and\nother instructions. These results suggest that enhancing MLLMs\\\' ability to\ncapture task-specific information could lead to better differentiation between\nvarious types of instructions, and thereby improving their precision in\npredicting brain responses.','Subba Reddy Oota, Akshett Jindal, Ishani Mondal, Khushbu Pahwa, Satya Sai Srinath Namburi, Manish Shrivastava, Maneesh Singh, Bapi S. Raju, Manish Gupta','2025-05-26','q-bio.NC','LLM、自然语言处理、图像识别','http://arxiv.org/pdf/2505.20029v1','该论文研究了基于Transformer的语言模型在与大脑活动的对齐方面的表现，特别是新型的指导调整的多模态大型语言模型（MLLMs）在自然指令下的表现。研究发现，MLLMs在大脑对齐方面表现良好，并且能够有效捕捉特定指令的表征。'),('2505.20032v1','ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers','Tactile sensing provides local essential information that is complementary to\nvisual perception, such as texture, compliance, and force. Despite recent\nadvances in visuotactile representation learning, challenges remain in fusing\nthese modalities and generalizing across tasks and environments without heavy\nreliance on pre-trained vision-language models. Moreover, existing methods do\nnot study positional encodings, thereby overlooking the multi-scale spatial\nreasoning needed to capture fine-grained visuotactile correlations. We\nintroduce ViTaPEs, a transformer-based framework that robustly integrates\nvisual and tactile input data to learn task-agnostic representations for\nvisuotactile perception. Our approach exploits a novel multi-scale positional\nencoding scheme to capture intra-modal structures, while simultaneously\nmodeling cross-modal cues. Unlike prior work, we provide provable guarantees in\nvisuotactile fusion, showing that our encodings are injective,\nrigid-motion-equivariant, and information-preserving, validating these\nproperties empirically. Experiments on multiple large-scale real-world datasets\nshow that ViTaPEs not only surpasses state-of-the-art baselines across various\nrecognition tasks but also demonstrates zero-shot generalization to unseen,\nout-of-domain scenarios. We further demonstrate the transfer-learning strength\nof ViTaPEs in a robotic grasping task, where it outperforms state-of-the-art\nbaselines in predicting grasp success. Project page:\nhttps://sites.google.com/view/vitapes','Fotios Lygerakis, Ozan Özdenizci, Elmar Rückert','2025-05-26','cs.CV','视觉与触觉融合','http://arxiv.org/pdf/2505.20032v1','该论文介绍了一种基于Transformer的框架ViTaPEs，能够强大地整合视觉和触觉输入数据，学习用于视触知觉的任务不可知表示。他们的方法利用了一种新颖的多尺度位置编码方案，以捕捉细粒度的视触相关性。实验证明，ViTaPEs不仅在各种识别任务上超越了现有的基线，而且在未见过的领域中表现出零样本泛化能力，并在机器人抓取任务中展示了迁移学习的强大性能。'),('2505.20033v2','EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition','Effective human-AI interaction relies on AI\\\'s ability to accurately perceive\nand interpret human emotions. Current benchmarks for vision and vision-language\nmodels are severely limited, offering a narrow emotional spectrum that\noverlooks nuanced states (e.g., bitterness, intoxication) and fails to\ndistinguish subtle differences between related feelings (e.g., shame vs.\nembarrassment). Existing datasets also often use uncontrolled imagery with\noccluded faces and lack demographic diversity, risking significant bias. To\naddress these critical gaps, we introduce EmoNet Face, a comprehensive\nbenchmark suite. EmoNet Face features: (1) A novel 40-category emotion\ntaxonomy, meticulously derived from foundational research to capture finer\ndetails of human emotional experiences. (2) Three large-scale, AI-generated\ndatasets (EmoNet HQ, Binary, and Big) with explicit, full-face expressions and\ncontrolled demographic balance across ethnicity, age, and gender. (3) Rigorous,\nmulti-expert annotations for training and high-fidelity evaluation. (4) We\nbuilt EmpathicInsight-Face, a model achieving human-expert-level performance on\nour benchmark. The publicly released EmoNet Face suite - taxonomy, datasets,\nand model - provides a robust foundation for developing and evaluating AI\nsystems with a deeper understanding of human emotions.','Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Felix Friedrich, Maurice Kraus, Krishna Kalyan, Kourosh Nadi, Huu Nguyen, Kristian Kersting, Sören Auer','2025-05-26','cs.CV','情感识别','http://arxiv.org/pdf/2505.20033v2','该论文介绍了EmoNet Face，一个全面的情感分类基准套件，包括一个新颖的40种情感分类法、三个大规模的人工智能生成数据集、严格的多专家注释和一个在该基准上达到人类专家水平性能的模型。'),('2505.20034v1','Graph Wave Networks','Dynamics modeling has been introduced as a novel paradigm in message passing\n(MP) of graph neural networks (GNNs). Existing methods consider MP between\nnodes as a heat diffusion process, and leverage heat equation to model the\ntemporal evolution of nodes in the embedding space. However, heat equation can\nhardly depict the wave nature of graph signals in graph signal processing.\nBesides, heat equation is essentially a partial differential equation (PDE)\ninvolving a first partial derivative of time, whose numerical solution usually\nhas low stability, and leads to inefficient model training. In this paper, we\nwould like to depict more wave details in MP, since graph signals are\nessentially wave signals that can be seen as a superposition of a series of\nwaves in the form of eigenvector. This motivates us to consider MP as a wave\npropagation process to capture the temporal evolution of wave signals in the\nspace. Based on wave equation in physics, we innovatively develop a graph wave\nequation to leverage the wave propagation on graphs. In details, we demonstrate\nthat the graph wave equation can be connected to traditional spectral GNNs,\nfacilitating the design of graph wave networks based on various Laplacians and\nenhancing the performance of the spectral GNNs. Besides, the graph wave\nequation is particularly a PDE involving a second partial derivative of time,\nwhich has stronger stability on graphs than the heat equation that involves a\nfirst partial derivative of time. Additionally, we theoretically prove that the\nnumerical solution derived from the graph wave equation are constantly stable,\nenabling to significantly enhance model efficiency while ensuring its\nperformance. Extensive experiments show that GWNs achieve SOTA and efficient\nperformance on benchmark datasets, and exhibit outstanding performance in\naddressing challenging graph problems, such as over-smoothing and heterophily.','Juwei Yue, Haikuo Li, Jiawei Sheng, Yihan Guo, Xinghua Zhang, Chuan Zhou, Tingwen Liu, Li Guo','2025-05-26','cs.LG','图神经网络','http://arxiv.org/pdf/2505.20034v1','本文提出了一种基于图波动方程的图神经网络模型，用于捕捉图信号的波动特性，相比传统的热传导模型具有更好的稳定性和效率。实验证明该模型在各项基准数据集上取得了领先的性能，并在解决图问题中表现出色。'),('2505.20036v1','Beyond Simple Concatenation: Fairly Assessing PLM Architectures for Multi-Chain Protein-Protein Interactions Prediction','Protein-protein interactions (PPIs) are fundamental to numerous cellular\nprocesses, and their characterization is vital for understanding disease\nmechanisms and guiding drug discovery. While protein language models (PLMs)\nhave demonstrated remarkable success in predicting protein structure and\nfunction, their application to sequence-based PPI binding affinity prediction\nremains relatively underexplored. This gap is often attributed to the scarcity\nof high-quality, rigorously refined datasets and the reliance on simple\nstrategies for concatenating protein representations. In this work, we address\nthese limitations. First, we introduce a meticulously curated version of the\nPPB-Affinity dataset of a total of 8,207 unique protein-protein interaction\nentries, by resolving annotation inconsistencies and duplicate entries for\nmulti-chain protein interactions. This dataset incorporates a stringent, less\nthan or equal to 30%, sequence identity threshold to ensure robust splitting\ninto training, validation, and test sets, minimizing data leakage. Second, we\npropose and systematically evaluate four architectures for adapting PLMs to PPI\nbinding affinity prediction: embeddings concatenation (EC), sequences\nconcatenation (SC), hierarchical pooling (HP), and pooled attention addition\n(PAD). These architectures were assessed using two training methods: full\nfine-tuning and a lightweight approach employing ConvBERT heads over frozen PLM\nfeatures. Our comprehensive experiments across multiple leading PLMs (ProtT5,\nESM2, Ankh, Ankh2, and ESM3) demonstrated that the HP and PAD architectures\nconsistently outperform conventional concatenation methods, achieving up to 12%\nincrease in terms of Spearman correlation. These results highlight the\nnecessity of sophisticated architectural designs to fully exploit the\ncapabilities of PLMs for nuanced PPI binding affinity prediction.','Hazem Alsamkary, Mohamed Elshaffei, Mohamed Soudy, Sara Ossman, Abdallah Amr, Nehal Adel Abdelsalam, Mohamed Elkerdawy, Ahmed Elnaggar','2025-05-26','cs.LG','蛋白质相互作用预测','http://arxiv.org/pdf/2505.20036v1','该论文研究了蛋白质相互作用（PPIs）的预测，介绍了一个经过精心筛选的数据集，并提出了四种架构用于适应蛋白质语言模型（PLMs）进行PPI结合亲和力预测。实验证明，HP和PAD架构在预测准确性上优于传统的连接方法，最多可提高12%的Spearman相关性。'),('2505.20045v1','Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs','Large language models (LLMs) exhibit impressive fluency, but often produce\ncritical errors known as \"hallucinations\". Uncertainty quantification (UQ)\nmethods are a promising tool for coping with this fundamental shortcoming. Yet,\nexisting UQ methods face challenges such as high computational overhead or\nreliance on supervised learning. Here, we aim to bridge this gap. In\nparticular, we propose RAUQ (Recurrent Attention-based Uncertainty\nQuantification), an unsupervised approach that leverages intrinsic attention\npatterns in transformers to detect hallucinations efficiently. By analyzing\nattention weights, we identified a peculiar pattern: drops in attention to\npreceding tokens are systematically observed during incorrect generations for\ncertain \"uncertainty-aware\" heads. RAUQ automatically selects such heads,\nrecurrently aggregates their attention weights and token-level confidences, and\ncomputes sequence-level uncertainty scores in a single forward pass.\nExperiments across 4 LLMs and 12 question answering, summarization, and\ntranslation tasks demonstrate that RAUQ yields excellent results, outperforming\nstate-of-the-art UQ methods using minimal computational overhead (<1% latency).\nMoreover, it requires no task-specific labels and no careful hyperparameter\ntuning, offering plug-and-play real-time hallucination detection in white-box\nLLMs.','Artem Vazhentsev, Lyudmila Rvanova, Gleb Kuzmin, Ekaterina Fadeeva, Ivan Lazichny, Alexander Panchenko, Maxim Panov, Timothy Baldwin, Mrinmaya Sachan, Preslav Nakov, Artem Shelmanov','2025-05-26','cs.CL','大型语言模型（LLM）、不确定性量化（UQ）','http://arxiv.org/pdf/2505.20045v1','该论文提出了一种名为RAUQ的方法，利用注意力模式来有效检测大型语言模型中的幻觉错误，实现了在单次前向传递中计算序列级不确定性得分。实验证明，RAUQ在多个任务上表现优异，性能超过了最先进的UQ方法，并且计算开销极小。'),('2505.20046v1','REARANK: Reasoning Re-ranking Agent via Reinforcement Learning','We present REARANK, a large language model (LLM)-based listwise reasoning\nreranking agent. REARANK explicitly reasons before reranking, significantly\nimproving both performance and interpretability. Leveraging reinforcement\nlearning and data augmentation, REARANK achieves substantial improvements over\nbaseline models across popular information retrieval benchmarks, notably\nrequiring only 179 annotated samples. Built on top of Qwen2.5-7B, our\nREARANK-7B demonstrates performance comparable to GPT-4 on both in-domain and\nout-of-domain benchmarks and even surpasses GPT-4 on reasoning-intensive BRIGHT\nbenchmarks. These results underscore the effectiveness of our approach and\nhighlight how reinforcement learning can enhance LLM reasoning capabilities in\nreranking.','Le Zhang, Bo Wang, Xipeng Qiu, Siva Reddy, Aishwarya Agrawal','2025-05-26','cs.IR','LLM (大型语言模型)','http://arxiv.org/pdf/2505.20046v1','该论文介绍了一种基于大型语言模型的列表推理重新排序代理 REARANK，通过显式推理来重新排序，显著提高了性能和可解释性。利用强化学习和数据增强，REARANK在流行的信息检索基准上实现了显著改进，仅需 179 个标注样本。REARANK-7B 在领域内外基准上表现与 GPT-4 相当，甚至在需要推理的 BRIGHT 基准上超过了 GPT-4。'),('2505.20047v1','Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks','Large language models (LLMs) show remarkable promise for democratizing\nautomated reasoning by generating formal specifications. However, a fundamental\ntension exists: LLMs are probabilistic, while formal verification demands\ndeterministic guarantees. This paper addresses this epistemological gap by\ncomprehensively investigating failure modes and uncertainty quantification (UQ)\nin LLM-generated formal artifacts. Our systematic evaluation of five frontier\nLLMs reveals Satisfiability Modulo Theories (SMT) based autoformalization\\\'s\ndomain-specific impact on accuracy (from +34.8% on logical tasks to -44.5% on\nfactual ones), with known UQ techniques like the entropy of token probabilities\nfailing to identify these errors. We introduce a probabilistic context-free\ngrammar (PCFG) framework to model LLM outputs, yielding a refined uncertainty\ntaxonomy. We find uncertainty signals are task-dependent (e.g., grammar entropy\nfor logic, AUROC>0.93). Finally, a lightweight fusion of these signals enables\nselective verification, drastically reducing errors (14-100%) with minimal\nabstention, transforming LLM-driven formalization into a reliable engineering\ndiscipline.','Debargha Ganguly, Vikash Singh, Sreehari Sankar, Biyao Zhang, Xuecen Zhang, Srinivasan Iyengar, Xiaotian Han, Amit Sharma, Shivkumar Kalyanaraman, Vipin Chaudhary','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20047v1','本文研究了大型语言模型在生成形式规范方面的潜力，探讨了LLMs生成的形式规范存在的失败模式和不确定性量化问题。通过系统评估五种前沿LLMs，发现基于SMT的自动形式化对准确性有领域特定影响，引入了概率上下文无关文法框架来建模LLM输出，提出了一种精细的不确定性分类法。最终，通过这些信号的轻量级融合，实现了选择性验证，大大减少了错误，将LLM驱动的形式化转变为可靠的工程学科。'),('2505.20048v1','Synthetic Time Series Forecasting with Transformer Architectures: Extensive Simulation Benchmarks','Time series forecasting plays a critical role in domains such as energy,\nfinance, and healthcare, where accurate predictions inform decision-making\nunder uncertainty. Although Transformer-based models have demonstrated success\nin sequential modeling, their adoption for time series remains limited by\nchallenges such as noise sensitivity, long-range dependencies, and a lack of\ninductive bias for temporal structure. In this work, we present a unified and\nprincipled framework for benchmarking three prominent Transformer forecasting\narchitectures-Autoformer, Informer, and Patchtst-each evaluated through three\narchitectural variants: Minimal, Standard, and Full, representing increasing\nlevels of complexity and modeling capacity.\n  We conduct over 1500 controlled experiments on a suite of ten synthetic\nsignals, spanning five patch lengths and five forecast horizons under both\nclean and noisy conditions. Our analysis reveals consistent patterns across\nmodel families.\n  To advance this landscape further, we introduce the Koopman-enhanced\nTransformer framework, Deep Koopformer, which integrates operator-theoretic\nlatent state modeling to improve stability and interpretability. We demonstrate\nits efficacy on nonlinear and chaotic dynamical systems. Our results highlight\nKoopman based Transformer as a promising hybrid approach for robust,\ninterpretable, and theoretically grounded time series forecasting in noisy and\ncomplex real-world conditions.','Ali Forootani, Mohammad Khosravi','2025-05-26','cs.LG','时间序列预测','http://arxiv.org/pdf/2505.20048v1','该论文介绍了一个统一且有原则的框架，用于评估三种主要的Transformer预测架构，分别是Autoformer、Informer和Patchtst，通过三种不同的结构变体进行评估，展示了它们在时间序列预测中的表现。他们还引入了Koopman增强Transformer框架Deep Koopformer，通过集成操作符理论潜在状态建模来提高稳定性和可解释性。'),('2505.20050v1','MVP: Multi-source Voice Pathology detection','Voice disorders significantly impact patient quality of life, yet\nnon-invasive automated diagnosis remains under-explored due to both the\nscarcity of pathological voice data, and the variability in recording sources.\nThis work introduces MVP (Multi-source Voice Pathology detection), a novel\napproach that leverages transformers operating directly on raw voice signals.\nWe explore three fusion strategies to combine sentence reading and sustained\nvowel recordings: waveform concatenation, intermediate feature fusion, and\ndecision-level combination. Empirical validation across the German, Portuguese,\nand Italian languages shows that intermediate feature fusion using transformers\nbest captures the complementary characteristics of both recording types. Our\napproach achieves up to +13% AUC improvement over single-source methods.','Alkis Koudounas, Moreno La Quatra, Gabriele Ciravegna, Marco Fantini, Erika Crosetti, Giovanni Succo, Tania Cerquitelli, Sabato Marco Siniscalchi, Elena Baralis','2025-05-26','eess.AS','语音处理','http://arxiv.org/pdf/2505.20050v1','该论文介绍了一种名为MVP的新方法，利用transformers直接处理原始语音信号，用于多源语音病理检测。通过三种融合策略，实现了在德语、葡萄牙语和意大利语上的实证验证，结果显示中间特征融合的方法在捕捉两种录音类型的互补特征方面表现最佳，相比单一来源方法，AUC提高了最多13%。'),('2505.20052v1','Ankh3: Multi-Task Pretraining with Sequence Denoising and Completion Enhances Protein Representations','Protein language models (PLMs) have emerged as powerful tools to detect\ncomplex patterns of protein sequences. However, the capability of PLMs to fully\ncapture information on protein sequences might be limited by focusing on single\npre-training tasks. Although adding data modalities or supervised objectives\ncan improve the performance of PLMs, pre-training often remains focused on\ndenoising corrupted sequences. To push the boundaries of PLMs, our research\ninvestigated a multi-task pre-training strategy. We developed Ankh3, a model\njointly optimized on two objectives: masked language modeling with multiple\nmasking probabilities and protein sequence completion relying only on protein\nsequences as input. This multi-task pre-training demonstrated that PLMs can\nlearn richer and more generalizable representations solely from protein\nsequences. The results demonstrated improved performance in downstream tasks,\nsuch as secondary structure prediction, fluorescence, GB1 fitness, and contact\nprediction. The integration of multiple tasks gave the model a more\ncomprehensive understanding of protein properties, leading to more robust and\naccurate predictions.','Hazem Alsamkary, Mohamed Elshaffei, Mohamed Elkerdawy, Ahmed Elnaggar','2025-05-26','cs.LG','蛋白质语言模型','http://arxiv.org/pdf/2505.20052v1','该论文研究了蛋白质语言模型（PLMs）的多任务预训练策略，通过Ankh3模型在掩盖语言建模和蛋白质序列完成两个目标上进行联合优化。研究结果表明，这种多任务预训练可以使PLMs仅从蛋白质序列中学习到更丰富和更具一般性的表示，并在下游任务中表现出更好的性能。'),('2505.20053v1','Multimodal LLM-Guided Semantic Correction in Text-to-Image Diffusion','Diffusion models have become the mainstream architecture for text-to-image\ngeneration, achieving remarkable progress in visual quality and prompt\ncontrollability. However, current inference pipelines generally lack\ninterpretable semantic supervision and correction mechanisms throughout the\ndenoising process. Most existing approaches rely solely on post-hoc scoring of\nthe final image, prompt filtering, or heuristic resampling strategies-making\nthem ineffective in providing actionable guidance for correcting the generative\ntrajectory. As a result, models often suffer from object confusion, spatial\nerrors, inaccurate counts, and missing semantic elements, severely compromising\nprompt-image alignment and image quality. To tackle these challenges, we\npropose MLLM Semantic-Corrected Ping-Pong-Ahead Diffusion (PPAD), a novel\nframework that, for the first time, introduces a Multimodal Large Language\nModel (MLLM) as a semantic observer during inference. PPAD performs real-time\nanalysis on intermediate generations, identifies latent semantic\ninconsistencies, and translates feedback into controllable signals that\nactively guide the remaining denoising steps. The framework supports both\ninference-only and training-enhanced settings, and performs semantic correction\nat only extremely few diffusion steps, offering strong generality and\nscalability. Extensive experiments demonstrate PPAD\\\'s significant improvements.','Zheqi Lv, Junhao Chen, Qi Tian, Keting Yin, Shengyu Zhang, Fei Wu','2025-05-26','cs.CV','LLM (Large Language Model)','http://arxiv.org/pdf/2505.20053v1','该论文提出了一种新的框架PPAD，通过引入MLLM作为语义观察者，在推断过程中进行实时分析、识别潜在的语义不一致性，并将反馈转化为可控信号，积极引导剩余的去噪步骤，从而改善文本到图像生成的质量。'),('2505.20063v1','SAEs Are Good for Steering -- If You Select the Right Features','Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to\nlearn a decomposition of a model\\\'s latent space. This enables useful\napplications such as steering - influencing the output of a model towards a\ndesired concept - without requiring labeled data. Current methods identify SAE\nfeatures to steer by analyzing the input tokens that activate them. However,\nrecent work has highlighted that activations alone do not fully describe the\neffect of a feature on the model\\\'s output. In this work, we draw a distinction\nbetween two types of features: input features, which mainly capture patterns in\nthe model\\\'s input, and output features, which have a human-understandable\neffect on the model\\\'s output. We propose input and output scores to\ncharacterize and locate these types of features, and show that high values for\nboth scores rarely co-occur in the same features. These findings have practical\nimplications: after filtering out features with low output scores, we obtain\n2-3x improvements when steering with SAEs, making them competitive with\nsupervised methods.','Dana Arad, Aaron Mueller, Yonatan Belinkov','2025-05-26','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20063v1','本文提出了一种新的方法来区分稀疏自编码器中的输入特征和输出特征，并通过引入输入和输出分数来描述和定位这两种类型的特征。研究发现高输入和输出分数很少同时出现在相同的特征中，通过过滤低输出分数的特征，可以在使用SAEs进行转向时获得2-3倍的改进，使其与监督方法竞争力相当。'),('2505.20065v1','SafeDPO: A Simple Approach to Direct Preference Optimization with Enhanced Safety','As Large Language Models (LLMs) continue to advance and find applications\nacross a growing number of fields, ensuring the safety of LLMs has become\nincreasingly critical. To address safety concerns, recent studies have proposed\nintegrating safety constraints into Reinforcement Learning from Human Feedback\n(RLHF). However, these approaches tend to be complex, as they encompass\ncomplicated procedures in RLHF along with additional steps required by the\nsafety constraints. Inspired by Direct Preference Optimization (DPO), we\nintroduce a new algorithm called SafeDPO, which is designed to directly\noptimize the safety alignment objective in a single stage of policy learning,\nwithout requiring relaxation. SafeDPO introduces only one additional\nhyperparameter to further enhance safety and requires only minor modifications\nto standard DPO. As a result, it eliminates the need to fit separate reward and\ncost models or to sample from the language model during fine-tuning, while\nstill enhancing the safety of LLMs. Finally, we demonstrate that SafeDPO\nachieves competitive performance compared to state-of-the-art safety alignment\nalgorithms, both in terms of aligning with human preferences and improving\nsafety.','Geon-Hyeong Kim, Youngsoo Jang, Yu Jin Kim, Byoungjip Kim, Honglak Lee, Kyunghoon Bae, Moontae Lee','2025-05-26','cs.LG','LLM、强化学习','http://arxiv.org/pdf/2505.20065v1','本文介绍了一种名为SafeDPO的新算法，旨在通过在政策学习的单个阶段直接优化安全对齐目标来增强LLMs的安全性。SafeDPO仅引入一个额外的超参数，同时对标准DPO进行了轻微修改，从而消除了在微调过程中需要拟合单独的奖励和成本模型或从语言模型中采样的需要，同时提高了LLMs的安全性。'),('2505.20066v1','Automated data curation for self-supervised learning in underwater acoustic analysis','The sustainability of the ocean ecosystem is threatened by increased levels\nof sound pollution, making monitoring crucial to understand its variability and\nimpact. Passive acoustic monitoring (PAM) systems collect a large amount of\nunderwater sound recordings, but the large volume of data makes manual analysis\nimpossible, creating the need for automation. Although machine learning offers\na potential solution, most underwater acoustic recordings are unlabeled.\nSelf-supervised learning models have demonstrated success in learning from\nlarge-scale unlabeled data in various domains like computer vision, Natural\nLanguage Processing, and audio. However, these models require large, diverse,\nand balanced datasets for training in order to generalize well. To address\nthis, a fully automated self-supervised data curation pipeline is proposed to\ncreate a diverse and balanced dataset from raw PAM data. It integrates\nAutomatic Identification System (AIS) data with recordings from various\nhydrophones in the U.S. waters. Using hierarchical k-means clustering, the raw\naudio data is sampled and then combined with AIS samples to create a balanced\nand diverse dataset. The resulting curated dataset enables the development of\nself-supervised learning models, facilitating various tasks such as monitoring\nmarine mammals and assessing sound pollution.','Hilde I Hummel, Sandjai Bhulai, Burooj Ghani, Rob van der Mei','2025-05-26','cs.SD','自然语言处理','http://arxiv.org/pdf/2505.20066v1','本论文提出了一个全自动的自监督数据整理流程，从原始PAM数据中创建一个多样化和平衡的数据集，以便开发自监督学习模型，从而实现监测海洋哺乳动物和评估声音污染等任务。'),('2505.20068v1','On the Same Page: Dimensions of Perceived Shared Understanding in Human-AI Interaction','Shared understanding plays a key role in the effective communication in and\nperformance of human-human interactions. With the increasingly common\nintegration of AI into human contexts, the future of personal and workplace\ninteractions will likely see human-AI interaction (HAII) in which the\nperception of shared understanding is important. Existing literature has\naddressed the processes and effects of PSU in human-human interactions, but the\nconstrual remains underexplored in HAII. To better understand PSU in HAII, we\nconducted an online survey to collect user reflections on interactions with a\nlarge language model when it sunderstanding of a situation was thought to be\nsimilar to or different from the participant\\\'s. Through inductive thematic\nanalysis, we identified eight dimensions comprising PSU in human-AI\ninteractions: Fluency, aligned operation, fluidity, outcome satisfaction,\ncontextual awareness, lack of humanlike abilities, computational limits, and\nsuspicion.','Qingyu Liang, Jaime Banks','2025-05-26','cs.HC','人机交互','http://arxiv.org/pdf/2505.20068v1','该论文研究了在人与人之间的交互中共享理解的重要性，以及在人工智能与人类交互中共享理解的构建。通过在线调查和归纳主题分析，确定了人工智能与人类交互中共享理解的八个维度。'),('2505.20072v2','Incentivizing Strong Reasoning from Weak Supervision','Large language models (LLMs) have demonstrated impressive performance on\nreasoning-intensive tasks, but enhancing their reasoning abilities typically\nrelies on either reinforcement learning (RL) with verifiable signals or\nsupervised fine-tuning (SFT) with high-quality long chain-of-thought (CoT)\ndemonstrations, both of which are expensive. In this paper, we study a novel\nproblem of incentivizing the reasoning capacity of LLMs without expensive\nhigh-quality demonstrations and reinforcement learning. We investigate whether\nthe reasoning capabilities of LLMs can be effectively incentivized via\nsupervision from significantly weaker models. We further analyze when and why\nsuch weak supervision succeeds in eliciting reasoning abilities in stronger\nmodels. Our findings show that supervision from significantly weaker reasoners\ncan substantially improve student reasoning performance, recovering close to\n94% of the gains of expensive RL at a fraction of the cost. Experiments across\ndiverse benchmarks and model architectures demonstrate that weak reasoners can\neffectively incentivize reasoning in stronger student models, consistently\nimproving performance across a wide range of reasoning tasks. Our results\nsuggest that this simple weak-to-strong paradigm is a promising and\ngeneralizable alternative to costly methods for incentivizing strong reasoning\ncapabilities at inference-time in LLMs. The code is publicly available at\nhttps://github.com/yuanyige/w2sr.','Yige Yuan, Teng Xiao, Shuchang Tao, Xue Wang, Jinyang Gao, Bolin Ding, Bingbing Xu','2025-05-26','cs.CL','大型语言模型（LLM）','http://arxiv.org/pdf/2505.20072v2','本文研究了如何通过弱监督来激励大型语言模型（LLMs）的推理能力，而不需要昂贵的高质量演示或强化学习。研究发现，通过显著较弱的模型的监督，可以有效地激励LLMs的推理能力，而且这种方法成本较低，效果接近昂贵的强化学习。'),('2505.20074v1','An Out-Of-Distribution Membership Inference Attack Approach for Cross-Domain Graph Attacks','Graph Neural Network-based methods face privacy leakage risks due to the\nintroduction of topological structures about the targets, which allows\nattackers to bypass the target\\\'s prior knowledge of the sensitive attributes\nand realize membership inference attacks (MIA) by observing and analyzing the\ntopology distribution. As privacy concerns grow, the assumption of MIA, which\npresumes that attackers can obtain an auxiliary dataset with the same\ndistribution, is increasingly deviating from reality. In this paper, we\ncategorize the distribution diversity issue in real-world MIA scenarios as an\nOut-Of-Distribution (OOD) problem, and propose a novel Graph OOD Membership\nInference Attack (GOOD-MIA) to achieve cross-domain graph attacks.\nSpecifically, we construct shadow subgraphs with distributions from different\ndomains to model the diversity of real-world data. We then explore the stable\nnode representations that remain unchanged under external influences and\nconsider eliminating redundant information from confounding environments and\nextracting task-relevant key information to more clearly distinguish between\nthe characteristics of training data and unseen data. This OOD-based design\nmakes cross-domain graph attacks possible. Finally, we perform risk\nextrapolation to optimize the attack\\\'s domain adaptability during attack\ninference to generalize the attack to other domains. Experimental results\ndemonstrate that GOOD-MIA achieves superior attack performance in datasets\ndesigned for multiple domains.','Jinyan Wang, Liu Yang, Yuecen Wei, Jiaxuan Si, Chenhao Guo, Qingyun Sun, Xianxian Li, Xingcheng Fu','2025-05-26','cs.LG','图神经网络、隐私保护、跨领域攻击','http://arxiv.org/pdf/2505.20074v1','该论文研究了基于图神经网络的隐私泄露风险，提出了一种新颖的跨领域图攻击方法，通过构建不同领域的阴影子图来模拟真实世界数据的多样性，实现了优越的攻击性能。'),('2505.20075v1','Curriculum-RLAIF: Curriculum Alignment with Reinforcement Learning from AI Feedback','Reward models trained with conventional Reinforcement Learning from AI\nFeedback (RLAIF) methods suffer from limited generalizability, which hinders\nthe alignment performance of the policy model during reinforcement learning\n(RL). This challenge stems from various issues, including distribution shift,\npreference label noise, and mismatches between overly challenging samples and\nmodel capacity. In this paper, we attempt to enhance the generalizability of\nreward models through a data-centric approach, driven by the insight that these\nissues are inherently intertwined from the perspective of data difficulty. To\naddress this, we propose a novel framework, $\\textit{Curriculum-RLAIF}$, which\nconstructs preference pairs with varying difficulty levels and produces a\ncurriculum that progressively incorporates preference pairs of increasing\ndifficulty for reward model training. Our experimental results suggest that\nreward models trained with Curriculum-RLAIF achieve improved generalizability,\nsignificantly increasing the alignment performance of the policy model by a\nlarge margin without incurring additional inference costs compared to various\nnon-curriculum baselines. Detailed analysis and comparisons with alternative\napproaches, including data selection via external pretrained reward models or\ninternal self-selection mechanisms, as well as other curriculum strategies,\nfurther demonstrate the superiority of our approach in terms of simplicity,\nefficiency, and effectiveness.','Mengdi Li, Jiaye Lin, Xufeng Zhao, Wenhao Lu, Peilin Zhao, Stefan Wermter, Di Wang','2025-05-26','cs.AI','强化学习','http://arxiv.org/pdf/2505.20075v1','本文提出了一种通过数据为中心的方法，通过构建具有不同难度级别的偏好对，并为奖励模型训练逐渐融入难度递增的偏好对的课程，以增强奖励模型的泛化能力。实验结果表明，使用Curriculum-RLAIF训练的奖励模型在不增加额外推理成本的情况下，显著提高了策略模型的对齐性能。'),('2505.20076v1','Grokking ExPLAIND: Unifying Model, Data, and Training Attribution to Study Model Behavior','Post-hoc interpretability methods typically attribute a model\\\'s behavior to\nits components, data, or training trajectory in isolation. This leads to\nexplanations that lack a unified view and may miss key interactions. While\ncombining existing methods or applying them at different training stages offers\nbroader insights, these approaches usually lack theoretical support. In this\nwork, we present ExPLAIND, a unified framework that integrates all three\nperspectives. First, we generalize recent work on gradient path kernels, which\nreformulate models trained by gradient descent as a kernel machine, to more\nrealistic training settings. Empirically, we find that both a CNN and a\nTransformer model are replicated accurately by this reformulation. Second, we\nderive novel parameter- and step-wise influence scores from the kernel feature\nmaps. We show their effectiveness in parameter pruning that is comparable to\nexisting methods, reinforcing their value for model component attribution.\nFinally, jointly interpreting model components and data over the training\nprocess, we leverage ExPLAIND to analyze a Transformer that exhibits Grokking.\nAmong other things, our findings support previously proposed stages of\nGrokking, while refining the final phase as one of alignment of input\nembeddings and final layers around a representation pipeline learned after the\nmemorization phase. Overall, ExPLAIND provides a theoretically grounded,\nunified framework to interpret model behavior and training dynamics.','Florian Eichin, Yupei Du, Philipp Mondorf, Barbara Plank, Michael A. Hedderich','2025-05-26','cs.LG','解释性AI','http://arxiv.org/pdf/2505.20076v1','该论文提出了一个统一的框架 ExPLAIND，整合了模型行为、训练动态和数据三个方面的解释方法。通过将模型训练为核函数机器的梯度路径内核，推导出新的参数和步骤影响分数，并应用于参数修剪和模型组件归因。最终利用 ExPLAIND 分析了一个展示 Grokking 特征的 Transformer 模型。'),('2505.20081v2','Inference-time Alignment in Continuous Space','Aligning large language models with human feedback at inference time has\nreceived increasing attention due to its flexibility. Existing methods rely on\ngenerating multiple responses from the base policy for search using a reward\nmodel, which can be considered as searching in a discrete response space.\nHowever, these methods struggle to explore informative candidates when the base\npolicy is weak or the candidate set is small, resulting in limited\neffectiveness. In this paper, to address this problem, we propose Simple Energy\nAdaptation ($\\textbf{SEA}$), a simple yet effective algorithm for\ninference-time alignment. In contrast to expensive search over the discrete\nspace, SEA directly adapts original responses from the base policy toward the\noptimal one via gradient-based sampling in continuous latent space.\nSpecifically, SEA formulates inference as an iterative optimization procedure\non an energy function over actions in the continuous space defined by the\noptimal policy, enabling simple and effective alignment. For instance, despite\nits simplicity, SEA outperforms the second-best baseline with a relative\nimprovement of up to $ \\textbf{77.51%}$ on AdvBench and $\\textbf{16.36%}$ on\nMATH. Our code is publicly available at https://github.com/yuanyige/sea','Yige Yuan, Teng Xiao, Li Yunfan, Bingbing Xu, Shuchang Tao, Yunqi Qiu, Huawei Shen, Xueqi Cheng','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20081v2','本文提出了一种名为Simple Energy Adaptation ($\\textbf{SEA}$)的算法，用于在推理时将大型语言模型与人类反馈对齐。与现有方法相比，SEA通过在连续潜在空间中基于梯度的采样，直接将原始响应从基本策略调整到最佳响应，从而提高了对齐效果。'),('2505.20085v1','Explanation User Interfaces: A Systematic Literature Review','Artificial Intelligence (AI) is one of the major technological advancements\nof this century, bearing incredible potential for users through AI-powered\napplications and tools in numerous domains. Being often black-box (i.e., its\ndecision-making process is unintelligible), developers typically resort to\neXplainable Artificial Intelligence (XAI) techniques to interpret the behaviour\nof AI models to produce systems that are transparent, fair, reliable, and\ntrustworthy. However, presenting explanations to the user is not trivial and is\noften left as a secondary aspect of the system\\\'s design process, leading to AI\nsystems that are not useful to end-users. This paper presents a Systematic\nLiterature Review on Explanation User Interfaces (XUIs) to gain a deeper\nunderstanding of the solutions and design guidelines employed in the academic\nliterature to effectively present explanations to users. To improve the\ncontribution and real-world impact of this survey, we also present a framework\nfor Human-cEnteRed developMent of Explainable user interfaceS (HERMES) to guide\npractitioners and academics in the design and evaluation of XUIs.','Eleonora Cappuccio, Andrea Esposito, Francesco Greco, Giuseppe Desolda, Rosa Lanzilotti, Salvatore Rinzivillo','2025-05-26','cs.HC','可解释人工智能 (XAI)','http://arxiv.org/pdf/2505.20085v1','本文通过系统文献综述研究了解释用户界面（XUIs），以深入了解学术文献中采用的解决方案和设计准则，以有效地向用户呈现解释。同时，提出了一个人类中心的可解释用户界面（HERMES）框架，以指导从业者和学者设计和评估XUIs。'),('2505.20087v1','Safety Through Reasoning: An Empirical Study of Reasoning Guardrail Models','Reasoning-based language models have demonstrated strong performance across\nvarious domains, with the most notable gains seen in mathematical and coding\ntasks. Recent research has shown that reasoning also offers significant\nbenefits for LLM safety and guardrail applications. In this work, we conduct a\ncomprehensive analysis of training reasoning-based guardrail models for content\nmoderation, with an emphasis on generalization to custom safety policies at\ninference time. Our study focuses on two key dimensions: data efficiency and\ninference efficiency. On the data front, we find that reasoning-based models\nexhibit strong sample efficiency, achieving competitive performance with\nsignificantly fewer training examples than their non-reasoning counterparts.\nThis unlocks the potential to repurpose the remaining data for mining\nhigh-value, difficult samples that further enhance model performance. On the\ninference side, we evaluate practical trade-offs by introducing reasoning\nbudgets, examining the impact of reasoning length on latency and accuracy, and\nexploring dual-mode training to allow runtime control over reasoning behavior.\nOur findings will provide practical insights for researchers and developers to\neffectively and efficiently train and deploy reasoning-based guardrails models\nin real-world systems.','Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien','2025-05-26','cs.AI','LLM (Language and Logic Models)','http://arxiv.org/pdf/2505.20087v1','本论文研究了基于推理的语言模型在内容审核中的训练和推理效率，重点在于数据效率和推理效率。研究发现，基于推理的模型在样本利用效率上表现出色，可以用更少的训练样本达到竞争性表现，并且在推理效率上也进行了实际的权衡和探讨。'),('2505.20088v1','Multi-Domain Explainability of Preferences','Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and\nreward models, are central to aligning and evaluating large language models\n(LLMs). Yet, the underlying concepts that drive these preferences remain poorly\nunderstood. In this work, we propose a fully automated end-to-end method for\ngenerating local and global concept-based explanations of preferences across\nmultiple domains. Our method employs an LLM to discover concepts that\ndifferentiate between chosen and rejected responses and represent them with\nconcept-based vectors. To model the relationships between concepts and\npreferences, we propose a white-box Hierarchical Multi-Domain Regression model\nthat captures both domain-general and domain-specific effects. To evaluate our\nmethod, we curate a dataset spanning eight challenging and diverse domains and\nexplain twelve mechanisms. Our method achieves strong preference prediction\nperformance, outperforming baselines while also being explainable.\nAdditionally, we assess explanations in two novel application-driven settings.\nFirst, guiding LLM outputs with concepts from LaaJ explanations yields\nresponses that those judges consistently prefer. Second, prompting LaaJs with\nconcepts explaining humans improves their preference predictions. Together, our\nwork provides a new paradigm for explainability in the era of LLMs.','Nitay Calderon, Liat Ein-Dor, Roi Reichart','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20088v1','本文提出了一种全自动的端到端方法，用于生成跨多个领域的本地和全局基于概念的偏好解释。他们的方法利用LLM来发现区分选定和拒绝响应的概念，并用基于概念的向量表示它们。通过提出的白盒子层次多领域回归模型来建模概念与偏好之间的关系，该方法取得了强大的偏好预测性能，并在两个新的应用驱动设置中评估了解释。'),('2505.20089v2','Homophily Enhanced Graph Domain Adaptation','Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs\nto unlabeled target graphs, addressing the challenge of label scarcity. In this\npaper, we highlight the significance of graph homophily, a pivotal factor for\ngraph domain alignment, which, however, has long been overlooked in existing\napproaches. Specifically, our analysis first reveals that homophily\ndiscrepancies exist in benchmarks. Moreover, we also show that homophily\ndiscrepancies degrade GDA performance from both empirical and theoretical\naspects, which further underscores the importance of homophily alignment in\nGDA. Inspired by this finding, we propose a novel homophily alignment algorithm\nthat employs mixed filters to smooth graph signals, thereby effectively\ncapturing and mitigating homophily discrepancies between graphs. Experimental\nresults on a variety of benchmarks verify the effectiveness of our method.','Ruiyi Fang, Bingheng Li, Jingyu Zhao, Ruizhi Pu, Qiuhao Zeng, Gezheng Xu, Charles Ling, Boyu Wang','2025-05-26','cs.SI','图领域自适应','http://arxiv.org/pdf/2505.20089v2','本文研究了图领域自适应（GDA）的问题，提出了图同质性在领域对齐中的重要性，并提出了一种新颖的同质性对齐算法，通过混合滤波器平滑图信号，有效捕捉和减轻图之间的同质性差异。'),('2505.20094v1','SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale','Can a scientific simulation system be physically consistent, interpretable by\ndesign, and scalable across regimes--all at once? Despite decades of progress,\nthis trifecta remains elusive. Classical methods like Kinetic Monte Carlo\nensure thermodynamic accuracy but scale poorly; learning-based methods offer\nefficiency but often sacrifice physical consistency and interpretability. We\npresent SwarmThinkers, a reinforcement learning framework that recasts\natomic-scale simulation as a physically grounded swarm intelligence system.\nEach diffusing particle is modeled as a local decision-making agent that\nselects transitions via a shared policy network trained under thermodynamic\nconstraints. A reweighting mechanism fuses learned preferences with transition\nrates, preserving statistical fidelity while enabling interpretable, step-wise\ndecision making. Training follows a centralized-training,\ndecentralized-execution paradigm, allowing the policy to generalize across\nsystem sizes, concentrations, and temperatures without retraining. On a\nbenchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers\nis the first system to achieve full-scale, physically consistent simulation on\na single A100 GPU, previously attainable only via OpenKMC on a supercomputer.\nIt delivers up to 4963x (3185x on average) faster computation with 485x lower\nmemory usage. By treating particles as decision-makers, not passive samplers,\nSwarmThinkers marks a paradigm shift in scientific simulation--one that unifies\nphysical consistency, interpretability, and scalability through agent-driven\nintelligence.','Qi Li, Kun Li, Haozhi Han, Honghui Shang, Xinfu He, Yunquan Zhang, Hong An, Ting Cao, Mao Yang','2025-05-26','cs.AI','强化学习','http://arxiv.org/pdf/2505.20094v1','本文提出了一种名为SwarmThinkers的强化学习框架，将原子尺度模拟重新构建为一个基于群体智能系统的物理一致性模拟系统。每个扩散粒子被建模为一个本地决策制定代理，通过在热力学约束下训练的共享策略网络选择转换。通过一个重新加权机制，将学习到的偏好与转换速率融合在一起，保持统计准确性同时实现可解释的、逐步的决策制定。训练遵循中心化训练、分散执行的范式，使策略能够在不重新训练的情况下泛化到不同的系统大小、浓度和温度上。'),('2505.20095v1','Spurious Privacy Leakage in Neural Networks','Neural networks are vulnerable to privacy attacks aimed at stealing sensitive\ndata. The risks can be amplified in a real-world scenario, particularly when\nmodels are trained on limited and biased data. In this work, we investigate the\nimpact of spurious correlation bias on privacy vulnerability. We introduce\n\\emph{spurious privacy leakage}, a phenomenon where spurious groups are\nsignificantly more vulnerable to privacy attacks than non-spurious groups. We\nfurther show that group privacy disparity increases in tasks with simpler\nobjectives (e.g. fewer classes) due to the persistence of spurious features.\nSurprisingly, we find that reducing spurious correlation using spurious robust\nmethods does not mitigate spurious privacy leakage. This leads us to introduce\na perspective on privacy disparity based on memorization, where mitigating\nspurious correlation does not mitigate the memorization of spurious data, and\ntherefore, neither the privacy level. Lastly, we compare the privacy of\ndifferent model architectures trained with spurious data, demonstrating that,\ncontrary to prior works, architectural choice can affect privacy outcomes.','Chenxiang Zhang, Jun Pang, Sjouke Mauw','2025-05-26','cs.LG','隐私保护、模型安全','http://arxiv.org/pdf/2505.20095v1','本文研究神经网络在隐私攻击中的脆弱性，探讨了虚假相关性偏差对隐私漏洞的影响，发现虚假相关性会导致虚假群体比非虚假群体更容易受到隐私攻击，而减少虚假相关性并不能减轻隐私泄露。'),('2505.20096v1','MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning','We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\n(RAG) that addresses the inherent ambiguities and reasoning challenges in\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely on\neither end-to-end fine-tuning or isolated component enhancements, MA-RAG\norchestrates a collaborative set of specialized AI agents: Planner, Step\nDefiner, Extractor, and QA Agents, to tackle each stage of the RAG pipeline\nwith task-aware reasoning. Ambiguities may arise from underspecified queries,\nsparse or indirect evidence in retrieved documents, or the need to integrate\ninformation scattered across multiple sources. MA-RAG mitigates these\nchallenges by decomposing the problem into subtasks, such as query\ndisambiguation, evidence extraction, and answer synthesis, and dispatching them\nto dedicated agents equipped with chain-of-thought prompting. These agents\ncommunicate intermediate reasoning and progressively refine the retrieval and\nsynthesis process. Our design allows fine-grained control over information flow\nwithout any model fine-tuning. Crucially, agents are invoked on demand,\nenabling a dynamic and efficient workflow that avoids unnecessary computation.\nThis modular and reasoning-driven architecture enables MA-RAG to deliver\nrobust, interpretable results. Experiments on multi-hop and ambiguous QA\nbenchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free\nbaselines and rivals fine-tuned systems, validating the effectiveness of\ncollaborative agent-based reasoning in RAG.','Thang Nguyen, Peter Chin, Yu-Wing Tai','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20096v1','该论文介绍了一种名为MA-RAG的多智能体框架，用于处理复杂信息检索任务中的歧义和推理挑战。通过协作的专门化AI智能体，如规划器、步骤定义器、提取器和问答智能体，分阶段处理RAG流程，从而解决了信息检索中的挑战。'),('2505.20097v1','S2LPP: Small-to-Large Prompt Prediction across LLMs','The performance of pre-trained Large Language Models (LLMs) is often\nsensitive to nuances in prompt templates, requiring careful prompt engineering,\nadding costs in terms of computing and human effort. In this study, we present\nexperiments encompassing multiple LLMs variants of varying sizes aimed at\nprobing their preference with different prompts. Through experiments on\nQuestion Answering, we show prompt preference consistency across LLMs of\ndifferent sizes. We also show that this consistency extends to other tasks,\nsuch as Natural Language Inference. Utilizing this consistency, we propose a\nmethod to use a smaller model to select effective prompt templates for a larger\nmodel. We show that our method substantially reduces the cost of prompt\nengineering while consistently matching performance with optimal prompts among\ncandidates. More importantly, our experiment shows the efficacy of our strategy\nacross fourteen LLMs and its applicability to a broad range of NLP tasks,\nhighlighting its robustness','Liang Cheng, Tianyi LI, Zhaowei Wang, Mark Steedman','2025-05-26','cs.CL','大型语言模型（LLM）、自然语言处理（NLP）','http://arxiv.org/pdf/2505.20097v1','本研究通过实验展示了不同大小的预训练大型语言模型对不同提示的偏好一致性，并提出了一种方法，利用较小模型选择较大模型的有效提示模板，从而显著降低了提示工程成本。'),('2505.20098v2','Transformers in Protein: A Survey','As protein informatics advances rapidly, the demand for enhanced predictive\naccuracy, structural analysis, and functional understanding has intensified.\nTransformer models, as powerful deep learning architectures, have demonstrated\nunprecedented potential in addressing diverse challenges across protein\nresearch. However, a comprehensive review of Transformer applications in this\nfield remains lacking. This paper bridges this gap by surveying over 100\nstudies, offering an in-depth analysis of practical implementations and\nresearch progress of Transformers in protein-related tasks. Our review\nsystematically covers critical domains, including protein structure prediction,\nfunction prediction, protein-protein interaction analysis, functional\nannotation, and drug discovery/target identification. To contextualize these\nadvancements across various protein domains, we adopt a domain-oriented\nclassification system. We first introduce foundational concepts: the\nTransformer architecture and attention mechanisms, categorize Transformer\nvariants tailored for protein science, and summarize essential protein\nknowledge. For each research domain, we outline its objectives and background,\ncritically evaluate prior methods and their limitations, and highlight\ntransformative contributions enabled by Transformer models. We also curate and\nsummarize pivotal datasets and open-source code resources to facilitate\nreproducibility and benchmarking. Finally, we discuss persistent challenges in\napplying Transformers to protein informatics and propose future research\ndirections. This review aims to provide a consolidated foundation for the\nsynergistic integration of Transformer and protein informatics, fostering\nfurther innovation and expanded applications in the field.','Xiaowen Ling, Zhiqiang Li, Yanbin Wang, Zhuhong You','2025-05-26','cs.LG','蛋白质信息学','http://arxiv.org/pdf/2505.20098v2','本文是一篇综述文章，介绍了Transformer模型在蛋白质相关任务中的应用。通过调查超过100项研究，对Transformer在蛋白质结构预测、功能预测、蛋白质相互作用分析、功能注释和药物发现/靶标识别等领域的实际应用和研究进展进行了深入分析。'),('2505.20099v1','Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities','Large language models (LLMs) have demonstrated remarkable performance on\nquestion-answering (QA) tasks because of their superior capabilities in natural\nlanguage understanding and generation. However, LLM-based QA struggles with\ncomplex QA tasks due to poor reasoning capacity, outdated knowledge, and\nhallucinations. Several recent works synthesize LLMs and knowledge graphs (KGs)\nfor QA to address the above challenges. In this survey, we propose a new\nstructured taxonomy that categorizes the methodology of synthesizing LLMs and\nKGs for QA according to the categories of QA and the KG\\\'s role when integrating\nwith LLMs. We systematically survey state-of-the-art advances in synthesizing\nLLMs and KGs for QA and compare and analyze these approaches in terms of\nstrength, limitations, and KG requirements. We then align the approaches with\nQA and discuss how these approaches address the main challenges of different\ncomplex QA. Finally, we summarize the advancements, evaluation metrics, and\nbenchmark datasets and highlight open challenges and opportunities.','Chuangtao Ma, Yongrui Chen, Tianxing Wu, Arijit Khan, Haofen Wang','2025-05-26','cs.CL','LLM、自然语言处理、知识图谱','http://arxiv.org/pdf/2505.20099v1','该论文调查了最新的研究进展，将大型语言模型（LLMs）与知识图谱（KGs）相结合，以解决复杂的问答任务中存在的推理能力不足、知识过时和幻觉等挑战。通过提出新的结构化分类方法，系统地调查了合成LLMs和KGs用于QA的方法，并比较分析了这些方法的优势、局限性和KG要求。'),('2505.20100v1','AdaTP: Attention-Debiased Token Pruning for Video Large Language Models','Video Large Language Models (Video LLMs) have achieved remarkable results in\nvideo understanding tasks. However, they often suffer from heavy computational\noverhead due to the large number of visual tokens generated from multiple video\nframes. Existing visual token compression methods often rely on attention\nscores from language models as guidance. However, these scores exhibit inherent\nbiases: global bias reflects a tendency to focus on the two ends of the visual\ntoken sequence, while local bias leads to an over-concentration on the same\nspatial positions across different frames. To address the issue of attention\nbias, we propose $\\textbf{A}$ttention-$\\textbf{D}$ebi$\\textbf{a}$sed\n$\\textbf{T}$oken $\\textbf{P}$runing for Video Large Language Models\n($\\textbf{AdaTP}$), a novel token pruning pipeline for Video LLMs. AdaTP\nintegrates two dedicated debiasing modules into the pipeline, targeting global\nattention bias and local attention bias, respectively. Without the need for\nadditional training, our method significantly reduces the computational\noverhead of Video LLMs while retaining the performance of vanilla models.\nExtensive evaluation shows that AdaTP achieves state-of-the-art performance in\nvarious commonly used video understanding benchmarks. In particular, on\nLLaVA-OneVision-7B, AdaTP maintains performance without degradation while using\nonly up to $27.3\\%$ FLOPs compared to the vanilla model. Our code will be\nreleased soon.','Fengyuan Sun, Leqi Shen, Hui Chen, Sicheng Zhao, Jungong Han, Guiguang Ding','2025-05-26','cs.CV','LLM (视频大型语言模型)','http://arxiv.org/pdf/2505.20100v1','该论文提出了一种名为AdaTP的视频大型语言模型的注意力去偏置的方法，通过减少视觉令牌的数量来减少计算开销，同时保持模型性能。实验证明AdaTP在各种视频理解基准测试中取得了最先进的性能。'),('2505.20101v2','Adaptive Deep Reasoning: Triggering Deep Thinking When Needed','Large language models (LLMs) have shown impressive capabilities in handling\ncomplex tasks through long-chain reasoning. However, the extensive reasoning\nsteps involved can significantly increase computational costs, posing\nchallenges for real-world deployment. Recent efforts have focused on optimizing\nreasoning efficiency by shortening the Chain-of-Thought (CoT) reasoning\nprocesses through various approaches, such as length-aware prompt engineering,\nsupervised fine-tuning on CoT data with variable lengths, and reinforcement\nlearning with length penalties. Although these methods effectively reduce\nreasoning length, they still necessitate an initial reasoning phase. More\nrecent approaches have attempted to integrate long-chain and short-chain\nreasoning abilities into a single model, yet they still rely on manual control\nto toggle between short and long CoT. In this work, we propose a novel approach\nthat autonomously switches between short and long reasoning chains based on\nproblem complexity. Our method begins with supervised fine-tuning of the base\nmodel to equip both long-chain and short-chain reasoning abilities. We then\nemploy reinforcement learning to further balance short and long CoT generation\nwhile maintaining accuracy through two key strategies: first, integrating\nreinforcement learning with a long-short adaptive group-wise reward strategy to\nassess prompt complexity and provide corresponding rewards; second,\nimplementing a logit-based reasoning mode switching loss to optimize the\nmodel\\\'s initial token choice, thereby guiding the selection of the reasoning\ntype. Evaluations on mathematical datasets demonstrate that our model can\ndynamically switch between long-chain and short-chain reasoning modes without\nsubstantially sacrificing performance. This advancement enhances the\npracticality of reasoning in large language models for real-world applications.','Yunhao Wang, Yuhao Zhang, Tinghao Yu, Can Xu, Feng Zhang, Fengzong Lian','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20101v2','该论文提出了一种新颖的方法，通过基于问题复杂性自动切换长链和短链推理模式，以提高大型语言模型在实际应用中的实用性。'),('2505.20107v1','Refining Few-Step Text-to-Multiview Diffusion via Reinforcement Learning','Text-to-multiview (T2MV) generation, which produces coherent multiview images\nfrom a single text prompt, remains computationally intensive, while accelerated\nT2MV methods using few-step diffusion models often sacrifice image fidelity and\nview consistency. To address this, we propose a novel reinforcement learning\n(RL) finetuning framework tailored for few-step T2MV diffusion models to\njointly optimize per-view fidelity and cross-view consistency. Specifically, we\nfirst reformulate T2MV denoising across all views as a single unified Markov\ndecision process, enabling multiview-aware policy optimization driven by a\njoint-view reward objective. Next, we introduce ZMV-Sampling, a test-time T2MV\nsampling technique that adds an inversion-denoising pass to reinforce both\nviewpoint and text conditioning, resulting in improved T2MV generation at the\ncost of inference time. To internalize its performance gains into the base\nsampling policy, we develop MV-ZigAL, a novel policy optimization strategy that\nuses reward advantages of ZMV-Sampling over standard sampling as learning\nsignals for policy updates. Finally, noting that the joint-view reward\nobjective under-optimizes per-view fidelity but naively optimizing single-view\nmetrics neglects cross-view alignment, we reframe RL finetuning for T2MV\ndiffusion models as a constrained optimization problem that maximizes per-view\nfidelity subject to an explicit joint-view constraint, thereby enabling more\nefficient and balanced policy updates. By integrating this constrained\noptimization paradigm with MV-ZigAL, we establish our complete RL finetuning\nframework, referred to as MVC-ZigAL, which effectively refines the few-step\nT2MV diffusion baseline in both fidelity and consistency while preserving its\nfew-step efficiency.','Ziyi Zhang, Li Shen, Deheng Ye, Yong Luo, Huangxuan Zhao, Lefei Zhang','2025-05-26','cs.LG','生成模型','http://arxiv.org/pdf/2505.20107v1','该论文提出了一种针对少步骤T2MV扩散模型的强化学习微调框架，以同时优化每个视图的保真度和跨视图一致性。通过引入ZMV-Sampling和MV-ZigAL等技术，提高了T2MV生成的性能。'),('2505.20109v1','Language-Agnostic Suicidal Risk Detection Using Large Language Models','Suicidal risk detection in adolescents is a critical challenge, yet existing\nmethods rely on language-specific models, limiting scalability and\ngeneralization. This study introduces a novel language-agnostic framework for\nsuicidal risk assessment with large language models (LLMs). We generate Chinese\ntranscripts from speech using an ASR model and then employ LLMs with\nprompt-based queries to extract suicidal risk-related features from these\ntranscripts. The extracted features are retained in both Chinese and English to\nenable cross-linguistic analysis and then used to fine-tune corresponding\npretrained language models independently. Experimental results show that our\nmethod achieves performance comparable to direct fine-tuning with ASR results\nor to models trained solely on Chinese suicidal risk-related features,\ndemonstrating its potential to overcome language constraints and improve the\nrobustness of suicidal risk assessment.','June-Woo Kim, Wonkyo Oh, Haram Yoon, Sung-Hoon Yoon, Dae-Jin Kim, Dong-Ho Lee, Sang-Yeol Lee, Chan-Mo Yang','2025-05-26','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.20109v1','该论文介绍了一种新颖的语言无关框架，利用大型语言模型（LLMs）进行自杀风险评估。通过使用ASR模型从语音生成中文转录，并使用基于提示的查询从这些转录中提取与自杀风险相关的特征。实验结果表明，该方法在跨语言分析和改善自杀风险评估的鲁棒性方面具有潜力。'),('2505.20110v1','Proxy-Free GFlowNet','Generative Flow Networks (GFlowNets) are a promising class of generative\nmodels designed to sample diverse, high-reward structures by modeling\ndistributions over compositional objects. In many real-world applications,\nobtaining the reward function for such objects is expensive, time-consuming, or\nrequires human input, making it necessary to train GFlowNets from historical\ndatasets. Most existing methods adopt a model-based approach, learning a proxy\nmodel from the dataset to approximate the reward function. However, this\nstrategy inherently ties the quality of the learned policy to the accuracy of\nthe proxy, introducing additional complexity and uncertainty into the training\nprocess. To overcome these limitations, we propose \\textbf{Trajectory-Distilled\nGFlowNet (TD-GFN)}, a \\emph{proxy-free} training framework that eliminates the\nneed for out-of-dataset reward queries. Our method is motivated by the key\nobservation that different edges in the associated directed acyclic graph (DAG)\ncontribute unequally to effective policy learning. TD-GFN leverages inverse\nreinforcement learning to estimate edge-level rewards from the offline dataset,\nwhich are then used to ingeniously prune the DAG and guide backward trajectory\nsampling during training. This approach directs the policy toward high-reward\nregions while reducing the complexity of model fitting. Empirical results\nacross multiple tasks show that TD-GFN trains both efficiently and reliably,\nsignificantly outperforming existing baselines in convergence speed and sample\nquality.','Ruishuo Chen, Xun Wang, Rui Hu, Zhuoran Li, Longbo Huang','2025-05-26','cs.LG','生成模型','http://arxiv.org/pdf/2505.20110v1','本文提出了一种新的训练框架Trajectory-Distilled GFlowNet (TD-GFN)，用于训练Generative Flow Networks (GFlowNets)，通过估计边级奖励来指导策略学习，从而提高训练效率和可靠性。'),('2505.20112v1','ResSVD: Residual Compensated SVD for Large Language Model Compression','Large language models (LLMs) have demonstrated impressive capabilities in a\nwide range of downstream natural language processing tasks. Nevertheless, their\nconsiderable sizes and memory demands hinder practical deployment, underscoring\nthe importance of developing efficient compression strategies. Singular value\ndecomposition (SVD) decomposes a matrix into orthogonal components, enabling\nefficient low-rank approximation. This is particularly suitable for LLM\ncompression, where weight matrices often exhibit significant redundancy.\nHowever, current SVD-based methods neglect the residual matrix from truncation,\nresulting in significant truncation loss. Additionally, compressing all layers\nof the model results in severe performance degradation. To overcome these\nlimitations, we propose ResSVD, a new post-training SVD-based LLM compression\nmethod. Specifically, we leverage the residual matrix generated during the\ntruncation process to reduce truncation loss. Moreover, under a fixed overall\ncompression ratio, we selectively compress the last few layers of the model,\nwhich mitigates error propagation and significantly improves the performance of\ncompressed models.Comprehensive evaluations of ResSVD on diverse LLM families\nand multiple benchmark datasets indicate that ResSVD consistently achieves\nsuperior performance over existing counterpart methods, demonstrating its\npractical effectiveness.','Haolei Bai, Siyong Jian, Tuo Liang, Yu Yin, Huan Wang','2025-05-26','cs.CL','大语言模型(LLM)','http://arxiv.org/pdf/2505.20112v1','该论文提出了一种新的基于SVD的LLM压缩方法ResSVD，通过利用截断过程中生成的残差矩阵来减少截断损失，并选择性地压缩模型的最后几层，从而改善压缩模型的性能。'),('2505.20113v1','Named Entity Recognition in Historical Italian: The Case of Giacomo Leopardi\\\'s Zibaldone','The increased digitization of world\\\'s textual heritage poses significant\nchallenges for both computer science and literary studies. Overall, there is an\nurgent need of computational techniques able to adapt to the challenges of\nhistorical texts, such as orthographic and spelling variations, fragmentary\nstructure and digitization errors. The rise of large language models (LLMs) has\nrevolutionized natural language processing, suggesting promising applications\nfor Named Entity Recognition (NER) on historical documents. In spite of this,\nno thorough evaluation has been proposed for Italian texts. This research tries\nto fill the gap by proposing a new challenging dataset for entity extraction\nbased on a corpus of 19th century scholarly notes, i.e. Giacomo Leopardi\\\'s\nZibaldone (1898), containing 2,899 references to people, locations and literary\nworks. This dataset was used to carry out reproducible experiments with both\ndomain-specific BERT-based models and state-of-the-art LLMs such as LLaMa3.1.\nResults show that instruction-tuned models encounter multiple difficulties\nhandling historical humanistic texts, while fine-tuned NER models offer more\nrobust performance even with challenging entity types such as bibliographic\nreferences.','Cristian Santini, Laura Melosi, Emanuele Frontoni','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20113v1','该论文研究了如何应对历史文本中的拼写变体、片段结构和数字化错误等挑战，提出了一个基于19世纪学术笔记的新数据集，用于实施对具有挑战性实体类型的 NER 模型的可复现实验。研究结果表明，领域特定的 BERT 模型在处理历史人文文本时遇到了多个困难，而经过微调的 NER 模型在处理具有挑战性实体类型时表现更为稳健。'),('2505.20118v2','TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent','As large language models (LLMs) become integrated into sensitive workflows,\nconcerns grow over their potential to leak confidential information. We propose\nTrojanStego, a novel threat model in which an adversary fine-tunes an LLM to\nembed sensitive context information into natural-looking outputs via linguistic\nsteganography, without requiring explicit control over inference inputs. We\nintroduce a taxonomy outlining risk factors for compromised LLMs, and use it to\nevaluate the risk profile of the threat. To implement TrojanStego, we propose a\npractical encoding scheme based on vocabulary partitioning learnable by LLMs\nvia fine-tuning. Experimental results show that compromised models reliably\ntransmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over\n97% accuracy using majority voting across three generations. Further, they\nmaintain high utility, can evade human detection, and preserve coherence. These\nresults highlight a new class of LLM data exfiltration attacks that are\npassive, covert, practical, and dangerous.','Dominik Meier, Jan Philip Wahle, Paul Röttger, Terry Ruas, Bela Gipp','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20118v2','该论文提出了一种名为TrojanStego的新型威胁模型，通过语言隐写术在自然输出中嵌入敏感上下文信息，而无需对推理输入进行明确控制。他们提出了一种基于词汇划分的编码方案，通过微调LLM可学习，实验结果表明，受损模型可可靠地传输32位秘密信息，准确率达到87%。'),('2505.20119v1','Spatiotemporal Causal Decoupling Model for Air Quality Forecasting','Due to the profound impact of air pollution on human health, livelihoods, and\neconomic development, air quality forecasting is of paramount significance.\nInitially, we employ the causal graph method to scrutinize the constraints of\nexisting research in comprehensively modeling the causal relationships between\nthe air quality index (AQI) and meteorological features. In order to enhance\nprediction accuracy, we introduce a novel air quality forecasting model,\nAirCade, which incorporates a causal decoupling approach. AirCade leverages a\nspatiotemporal module in conjunction with knowledge embedding techniques to\ncapture the internal dynamics of AQI. Subsequently, a causal decoupling module\nis proposed to disentangle synchronous causality from past AQI and\nmeteorological features, followed by the dissemination of acquired knowledge to\nfuture time steps to enhance performance. Additionally, we introduce a causal\nintervention mechanism to explicitly represent the uncertainty of future\nmeteorological features, thereby bolstering the model\\\'s robustness. Our\nevaluation of AirCade on an open-source air quality dataset demonstrates over\n20\\% relative improvement over state-of-the-art models.','Jiaming Ma, Guanjun Wang, Sheng Huang, Kuo Yang, Binwu Wang, Pengkun Wang, Yang Wang','2025-05-26','cs.AI','预测模型','http://arxiv.org/pdf/2505.20119v1','该论文提出了一种新颖的空气质量预测模型AirCade，通过引入因果解耦方法和知识嵌入技术，以捕捉AQI的内部动态。该模型在开源空气质量数据集上表现出超过20%相对改进。'),('2505.20120v1','Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets','Current labor markets are strongly affected by the economic forces of adverse\nselection, moral hazard, and reputation, each of which arises due to\n$\\textit{incomplete information}$. These economic forces will still be\ninfluential after AI agents are introduced, and thus, agents must use\nmetacognitive and strategic reasoning to perform effectively. Metacognition is\na form of $\\textit{internal reasoning}$ that includes the capabilities for\nself-assessment, task understanding, and evaluation of strategies. Strategic\nreasoning is $\\textit{external reasoning}$ that covers holding beliefs about\nother participants in the labor market (e.g., competitors, colleagues), making\nstrategic decisions, and learning about others over time. Both types of\nreasoning are required by agents as they decide among the many\n$\\textit{actions}$ they can take in labor markets, both within and outside\ntheir jobs. We discuss current research into metacognitive and strategic\nreasoning and the areas requiring further development.','Simpson Zhang, Tennison Liu, Mihaela van der Schaar','2025-05-26','cs.AI','强化学习','http://arxiv.org/pdf/2505.20120v1','该论文讨论了当前劳动市场受到不完全信息引起的经济力量的影响，介绍了AI代理引入后仍然受到的不完全信息的影响，强调了代理必须使用元认知和战略推理来有效执行。论文探讨了元认知和战略推理的研究以及需要进一步发展的领域。'),('2505.20123v1','Understanding Generalization in Diffusion Models via Probability Flow Distance','Diffusion models have emerged as a powerful class of generative models,\ncapable of producing high-quality samples that generalize beyond the training\ndata. However, evaluating this generalization remains challenging: theoretical\nmetrics are often impractical for high-dimensional data, while no practical\nmetrics rigorously measure generalization. In this work, we bridge this gap by\nintroducing probability flow distance ($\\texttt{PFD}$), a theoretically\ngrounded and computationally efficient metric to measure distributional\ngeneralization. Specifically, $\\texttt{PFD}$ quantifies the distance between\ndistributions by comparing their noise-to-data mappings induced by the\nprobability flow ODE. Moreover, by using $\\texttt{PFD}$ under a teacher-student\nevaluation protocol, we empirically uncover several key generalization\nbehaviors in diffusion models, including: (1) scaling behavior from\nmemorization to generalization, (2) early learning and double descent training\ndynamics, and (3) bias-variance decomposition. Beyond these insights, our work\nlays a foundation for future empirical and theoretical studies on\ngeneralization in diffusion models.','Huijie Zhang, Zijian Huang, Siyi Chen, Jinfan Zhou, Zekai Zhang, Peng Wang, Qing Qu','2025-05-26','cs.LG','生成模型','http://arxiv.org/pdf/2505.20123v1','本文介绍了一种名为概率流距离（PFD）的度量方法，用于评估扩散模型的分布泛化能力。通过PFD度量，研究者揭示了扩散模型的几种关键泛化行为，并为未来关于扩散模型泛化的实证和理论研究奠定了基础。'),('2505.20127v1','Agentic AI Process Observability: Discovering Behavioral Variability','AI agents that leverage Large Language Models (LLMs) are increasingly\nbecoming core building blocks of modern software systems. A wide range of\nframeworks is now available to support the specification of such applications.\nThese frameworks enable the definition of agent setups using natural language\nprompting, which specifies the roles, goals, and tools assigned to the various\nagents involved. Within such setups, agent behavior is non-deterministic for\nany given input, highlighting the critical need for robust debugging and\nobservability tools. In this work, we explore the use of process and causal\ndiscovery applied to agent execution trajectories as a means of enhancing\ndeveloper observability. This approach aids in monitoring and understanding the\nemergent variability in agent behavior. Additionally, we complement this with\nLLM-based static analysis techniques to distinguish between intended and\nunintended behavioral variability. We argue that such instrumentation is\nessential for giving developers greater control over evolving specifications\nand for identifying aspects of functionality that may require more precise and\nexplicit definitions.','Fabiana Fournier, Lior Limonad, Yuval David','2025-05-26','cs.AI','LLM、开发者工具、调试技术','http://arxiv.org/pdf/2505.20127v1','本文探讨了利用过程和因果发现技术来增强开发者对基于大型语言模型的AI代理执行轨迹的可观察性，以及结合LLM-based静态分析技术来区分预期和非预期的行为变化。'),('2505.20128v1','Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers','Large language models (LLMs) have been widely integrated into information\nretrieval to advance traditional techniques. However, effectively enabling LLMs\nto seek accurate knowledge in complex tasks remains a challenge due to the\ncomplexity of multi-hop queries as well as the irrelevant retrieved content. To\naddress these limitations, we propose EXSEARCH, an agentic search framework,\nwhere the LLM learns to retrieve useful information as the reasoning unfolds\nthrough a self-incentivized process. At each step, the LLM decides what to\nretrieve (thinking), triggers an external retriever (search), and extracts\nfine-grained evidence (recording) to support next-step reasoning. To enable LLM\nwith this capability, EXSEARCH adopts a Generalized Expectation-Maximization\nalgorithm. In the E-step, the LLM generates multiple search trajectories and\nassigns an importance weight to each; the M-step trains the LLM on them with a\nre-weighted loss function. This creates a self-incentivized loop, where the LLM\niteratively learns from its own generated data, progressively improving itself\nfor search. We further theoretically analyze this training process,\nestablishing convergence guarantees. Extensive experiments on four\nknowledge-intensive benchmarks show that EXSEARCH substantially outperforms\nbaselines, e.g., +7.8% improvement on exact match score. Motivated by these\npromising results, we introduce EXSEARCH-Zoo, an extension that extends our\nmethod to broader scenarios, to facilitate future work.','Zhengliang Shi, Lingyong Yan, Dawei Yin, Suzan Verberne, Maarten de Rijke, Zhaochun Ren','2025-05-26','cs.CL','大语言模型（LLM）','http://arxiv.org/pdf/2505.20128v1','该论文提出了一种名为EXSEARCH的主动搜索框架，通过自我激励的过程，使LLM在复杂任务中能够准确获取知识。通过采用广义期望最大化算法，LLM在搜索过程中逐步改进自身性能，取得了显著的实验结果。'),('2505.20131v1','MolEditRL: Structure-Preserving Molecular Editing via Discrete Diffusion and Reinforcement Learning','Molecular editing aims to modify a given molecule to optimize desired\nchemical properties while preserving structural similarity. However, current\napproaches typically rely on string-based or continuous representations, which\nfail to adequately capture the discrete, graph-structured nature of molecules,\nresulting in limited structural fidelity and poor controllability. In this\npaper, we propose MolEditRL, a molecular editing framework that explicitly\nintegrates structural constraints with precise property optimization.\nSpecifically, MolEditRL consists of two stages: (1) a discrete graph diffusion\nmodel pretrained to reconstruct target molecules conditioned on source\nstructures and natural language instructions; (2) an editing-aware\nreinforcement learning fine-tuning stage that further enhances property\nalignment and structural preservation by explicitly optimizing editing\ndecisions under graph constraints. For comprehensive evaluation, we construct\nMolEdit-Instruct, the largest and most property-rich molecular editing dataset,\ncomprising 3 million diverse examples spanning single- and multi-property tasks\nacross 10 chemical attributes. Experimental results demonstrate that MolEditRL\nsignificantly outperforms state-of-the-art methods in both property\noptimization accuracy and structural fidelity, achieving a 74\\% improvement in\nediting success rate while using 98\\% fewer parameters.','Yuanxin Zhuang, Dazhong Shen, Ying Sun','2025-05-26','cs.LG','分子编辑','http://arxiv.org/pdf/2505.20131v1','该论文提出了一种分子编辑框架 MolEditRL，旨在通过结合结构约束和精确属性优化来修改分子，以提高编辑成功率和结构保真度。通过预训练离散图扩散模型和编辑感知强化学习微调阶段，实现了在分子编辑任务上的显著性能提升。'),('2505.20132v1','Tensorization is a powerful but underexplored tool for compression and interpretability of neural networks','Tensorizing a neural network involves reshaping some or all of its dense\nweight matrices into higher-order tensors and approximating them using low-rank\ntensor network decompositions. This technique has shown promise as a model\ncompression strategy for large-scale neural networks. However, despite\nencouraging empirical results, tensorized neural networks (TNNs) remain\nunderutilized in mainstream deep learning. In this position paper, we offer a\nperspective on both the potential and current limitations of TNNs. We argue\nthat TNNs represent a powerful yet underexplored framework for deep\nlearning--one that deserves greater attention from both engineering and\ntheoretical communities. Beyond compression, we highlight the value of TNNs as\na flexible class of architectures with distinctive scaling properties and\nincreased interpretability. A central feature of TNNs is the presence of bond\nindices, which introduce new latent spaces not found in conventional networks.\nThese internal representations may provide deeper insight into the evolution of\nfeatures across layers, potentially advancing the goals of mechanistic\ninterpretability. We conclude by outlining several key research directions\naimed at overcoming the practical barriers to scaling and adopting TNNs in\nmodern deep learning workflows.','Safa Hamreras, Sukhbinder Singh, Román Orús','2025-05-26','cs.LG','深度学习','http://arxiv.org/pdf/2505.20132v1','本文讨论了将神经网络张量化的技术，即将其密集权重矩阵重塑为高阶张量，并使用低秩张量网络分解进行近似。作者认为张量化神经网络是一种潜力巨大但目前被低估的深度学习框架，具有压缩模型、可扩展性和可解释性等优势。'),('2505.20133v1','AweDist: Attention-aware Embedding Distillation for New Input Token Embeddings','Current language models rely on static vocabularies determined at pretraining\ntime, which can lead to decreased performance and increased computational cost\nfor domains underrepresented in the original vocabulary. New tokens can be\nadded to solve this problem, when coupled with a good initialization for their\nnew embeddings. However, existing embedding initialization methods either\nrequire expensive further training or pretraining of additional modules. In\nthis paper, we propose AweDist and show that by distilling representations\nobtained using the original tokenization, we can quickly learn high-quality\ninput embeddings for new tokens. Experimental results with a wide range of\nopen-weight models show that AweDist is able to outperform even strong\nbaselines.','Konstantin Dobler, Desmond Elliott, Gerard de Melo','2025-05-26','cs.CL','LLM (语言模型)','http://arxiv.org/pdf/2505.20133v1','该论文提出了一种名为AweDist的方法，通过蒸馏原始标记化得到的表示，可以快速学习新标记的高质量输入嵌入。实验结果表明，AweDist能够胜过强基线模型。'),('2505.20135v2','Data-Distill-Net: A Data Distillation Approach Tailored for Reply-based Continual Learning','Replay-based continual learning (CL) methods assume that models trained on a\nsmall subset can also effectively minimize the empirical risk of the complete\ndataset. These methods maintain a memory buffer that stores a sampled subset of\ndata from previous tasks to consolidate past knowledge. However, this\nassumption is not guaranteed in practice due to the limited capacity of the\nmemory buffer and the heuristic criteria used for buffer data selection. To\naddress this issue, we propose a new dataset distillation framework tailored\nfor CL, which maintains a learnable memory buffer to distill the global\ninformation from the current task data and accumulated knowledge preserved in\nthe previous memory buffer. Moreover, to avoid the computational overhead and\noverfitting risks associated with parameterizing the entire buffer during\ndistillation, we introduce a lightweight distillation module that can achieve\nglobal information distillation solely by generating learnable soft labels for\nthe memory buffer data. Extensive experiments show that, our method can achieve\ncompetitive results and effectively mitigates forgetting across various\ndatasets. The source code will be publicly available.','Wenyang Liao, Quanziang Wang, Yichen Wu, Renzhen Wang, Deyu Meng','2025-05-26','cs.LG','继续学习（Continual Learning）','http://arxiv.org/pdf/2505.20135v2','该论文提出了一种适用于继续学习的新型数据集精炼框架，通过维护可学习的内存缓冲区来从当前任务数据和先前内存缓冲区中保留的累积知识中提炼全局信息。他们引入了一个轻量级蒸馏模块，可以通过为内存缓冲区数据生成可学习的软标签来实现全局信息的蒸馏。实验表明，他们的方法在各种数据集上取得了竞争性结果，并有效地减轻了遗忘问题。'),('2505.20137v1','Error Optimization: Overcoming Exponential Signal Decay in Deep Predictive Coding Networks','Predictive Coding (PC) offers a biologically plausible alternative to\nbackpropagation for neural network training, yet struggles with deeper\narchitectures. This paper identifies the root cause: an inherent signal decay\nproblem where gradients attenuate exponentially with depth, becoming\ncomputationally negligible due to numerical precision constraints. To address\nthis fundamental limitation, we introduce Error Optimization (EO), a novel\nreparameterization that preserves PC\\\'s theoretical properties while eliminating\nsignal decay. By optimizing over prediction errors rather than states, EO\nenables signals to reach all layers simultaneously and without attenuation,\nconverging orders of magnitude faster than standard PC. Experiments across\nmultiple architectures and datasets demonstrate that EO matches\nbackpropagation\\\'s performance even for deeper models where conventional PC\nstruggles. Besides practical improvements, our work provides theoretical\ninsight into PC dynamics and establishes a foundation for scaling\nbiologically-inspired learning to deeper architectures on digital hardware and\nbeyond.','Cédric Goemaere, Gaspard Oliviers, Rafal Bogacz, Thomas Demeester','2025-05-26','cs.LG','神经网络训练技术','http://arxiv.org/pdf/2505.20137v1','本论文提出了一种名为Error Optimization (EO)的新方法，用于解决Predictive Coding (PC)在深层神经网络训练中遇到的信号衰减问题，使信号能够同时到达所有层而不衰减，从而比标准PC收敛速度更快。实验证明，EO在多种架构和数据集上与反向传播相匹敌，甚至在深层模型上表现更好。'),('2505.20139v1','StructEval: Benchmarking LLMs\\\' Capabilities to Generate Structural Outputs','As Large Language Models (LLMs) become integral to software development\nworkflows, their ability to generate structured outputs has become critically\nimportant. We introduce StructEval, a comprehensive benchmark for evaluating\nLLMs\\\' capabilities in producing both non-renderable (JSON, YAML, CSV) and\nrenderable (HTML, React, SVG) structured formats. Unlike prior benchmarks,\nStructEval systematically evaluates structural fidelity across diverse formats\nthrough two paradigms: 1) generation tasks, producing structured output from\nnatural language prompts, and 2) conversion tasks, translating between\nstructured formats. Our benchmark encompasses 18 formats and 44 types of task,\nwith novel metrics for format adherence and structural correctness. Results\nreveal significant performance gaps, even state-of-the-art models like o1-mini\nachieve only 75.58 average score, with open-source alternatives lagging\napproximately 10 points behind. We find generation tasks more challenging than\nconversion tasks, and producing correct visual content more difficult than\ngenerating text-only structures.','Jialin Yang, Dongfu Jiang, Lipeng He, Sherman Siu, Yuxuan Zhang, Disen Liao, Zhuofeng Li, Huaye Zeng, Yiming Jia, Haozhe Wang, Benjamin Schneider, Chi Ruan, Wentao Ma, Zhiheng Lyu, Yifei Wang, Yi Lu, Quy Duc Do, Ziyan Jiang, Ping Nie, Wenhu Chen','2025-05-26','cs.SE','大型语言模型(LLM)','http://arxiv.org/pdf/2505.20139v1','该论文介绍了一个名为StructEval的综合基准，用于评估LLMs在生成非可渲染（JSON、YAML、CSV）和可渲染（HTML、React、SVG）结构化格式方面的能力。通过两种范式系统地评估不同格式的结构保真度，包括生成任务和转换任务。结果显示，即使是o1-mini等最先进的模型也只能达到75.58的平均分数，开源替代方案落后约10个点。'),('2505.20142v1','Model Stitching by Functional Latent Alignment','Evaluating functional similarity involves quantifying the degree to which\nindependently trained neural networks learn functionally similar\nrepresentations. Reliably inferring the functional similarity of these networks\nremains an open problem with far-reaching implications for AI. Model stitching\nhas emerged as a promising paradigm, where an optimal affine transformation\naligns two models to solve a task, with the stitched model serving as a proxy\nfor functional similarity. In this work, we draw inspiration from the knowledge\ndistillation literature and propose Functional Latent Alignment (FuLA) as a\nnovel optimality condition for model stitching. We revisit previously explored\nfunctional similarity testbeds and introduce a new one, based on which FuLA\nemerges as an overall more reliable method of functional similarity.\nSpecifically, our experiments in (a) adversarial training, (b) shortcut\ntraining and, (c) cross-layer stitching, reveal that FuLA is less prone to\nartifacts tied to training on task cues while achieving non-trivial alignments\nthat are missed by stitch-level matching.','Ioannis Athanasiadis, Anmar Karmush, Michael Felsberg','2025-05-26','cs.LG','模型融合/神经网络功能相似性','http://arxiv.org/pdf/2505.20142v1','该论文探讨了评估神经网络功能相似性的方法，提出了Functional Latent Alignment (FuLA) 作为模型拼接的新优化条件，通过实验表明FuLA在功能相似性测试中更可靠。'),('2505.20144v1','SeMe: Training-Free Language Model Merging via Semantic Alignment','Despite the remarkable capabilities of Language Models (LMs) across diverse\ntasks, no single model consistently outperforms others, necessitating efficient\nmethods to combine their strengths without expensive retraining. Existing model\nmerging techniques, such as parameter averaging and task-guided fusion, often\nrely on data-dependent computations or fail to preserve internal knowledge,\nlimiting their robustness and scalability. We introduce SeMe (Semantic-based\nMerging), a novel, data-free, and training-free approach that leverages latent\nsemantic alignment to merge LMs at a fine-grained, layer-wise level. Unlike\nprior work, SeMe not only preserves model behaviors but also explicitly\nstabilizes internal knowledge, addressing a critical gap in LM fusion. Through\nextensive experiments across diverse architectures and tasks, we demonstrate\nthat SeMe outperforms existing methods in both performance and efficiency while\neliminating reliance on external data. Our work establishes a new paradigm for\nknowledge-aware model merging and provides insights into the semantic structure\nof LMs, paving the way for more scalable and interpretable model composition.','Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang','2025-05-26','cs.CL','LLM（语言模型）','http://arxiv.org/pdf/2505.20144v1','该论文介绍了一种名为SeMe（基于语义的合并）的新方法，用于在细粒度的层次上合并语言模型，不需要数据和训练，通过潜在语义对齐来稳定内部知识，提高性能和效率。'),('2505.20148v2','MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents','Spatial Planning is a crucial part in the field of spatial intelligence,\nwhich requires the understanding and planning about object arrangements in\nspace perspective. AI agents with the spatial planning ability can better adapt\nto various real-world applications, including robotic manipulation, automatic\nassembly, urban planning etc. Recent works have attempted to construct\nbenchmarks for evaluating the spatial intelligence of Multimodal Large Language\nModels (MLLMs). Nevertheless, these benchmarks primarily focus on spatial\nreasoning based on typical Visual Question-Answering (VQA) forms, which suffers\nfrom the gap between abstract spatial understanding and concrete task\nexecution. In this work, we take a step further to build a comprehensive\nbenchmark called MineAnyBuild, aiming to evaluate the spatial planning ability\nof open-world AI agents in the Minecraft game. Specifically, MineAnyBuild\nrequires an agent to generate executable architecture building plans based on\nthe given multi-modal human instructions. It involves 4,000 curated spatial\nplanning tasks and also provides a paradigm for infinitely expandable data\ncollection by utilizing rich player-generated content. MineAnyBuild evaluates\nspatial planning through four core supporting dimensions: spatial\nunderstanding, spatial reasoning, creativity, and spatial commonsense. Based on\nMineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based\nagents, revealing the severe limitations but enormous potential in their\nspatial planning abilities. We believe our MineAnyBuild will open new avenues\nfor the evaluation of spatial intelligence and help promote further development\nfor open-world AI agents capable of spatial planning.','Ziming Wei, Bingqian Lin, Zijian Jiao, Yunshuang Nie, Liang Ma, Yuecheng Liu, Yuzheng Zhuang, Xiaodan Liang','2025-05-26','cs.AI','LLM (Multimodal Large Language Models)','http://arxiv.org/pdf/2505.20148v2','该论文介绍了一个名为MineAnyBuild的综合基准，旨在评估Minecraft游戏中开放世界AI代理的空间规划能力。通过给定的多模态人类指令，要求代理生成可执行的建筑规划方案，涉及4000个策划任务，并通过利用丰富的玩家生成内容提供了一个可无限扩展数据收集的范例。研究通过四个核心支持维度评估空间规划，揭示了现有基于MLLM的代理的空间规划能力的严重局限性和巨大潜力。'),('2505.20149v1','Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases','This paper focuses on using few-shot learning to improve the accuracy of\nclassifying OCT diagnosis images with major and rare classes. We used the\nGAN-based augmentation strategy as a baseline and introduced several novel\nmethods to further enhance our model. The proposed strategy contains U-GAT-IT\nfor improving the generative part and uses the data balance technique to narrow\ndown the skew of accuracy between all categories. The best model obtained was\nbuilt with CBAM attention mechanism and fine-tuned InceptionV3, and achieved an\noverall accuracy of 97.85%, representing a significant improvement over the\noriginal baseline.','Cheng-Yu Tai, Ching-Wen Chen, Chi-Chin Wu, Bo-Chen Chiu, Cheng-Hung, Lin, Cheng-Kai Lu, Jia-Kang Wang, Tzu-Lun Huang','2025-05-26','eess.IV','图像识别','http://arxiv.org/pdf/2505.20149v1','本文利用少样本学习来提高分类OCT诊断图像的准确性，采用基于GAN的数据增强策略作为基线，并引入了几种新方法来进一步增强模型。最佳模型采用了CBAM注意力机制和微调的InceptionV3，整体准确率达到了97.85%，较原始基线有显著提升。'),('2505.20150v1','On the (Non) Injectivity of Piecewise Linear Janossy Pooling','Multiset functions, which are functions that map multisets to vectors, are a\nfundamental tool in the construction of neural networks for multisets and\ngraphs. To guarantee that the vector representation of the multiset is\nfaithful, it is often desirable to have multiset mappings that are both\ninjective and bi-Lipschitz. Currently, there are several constructions of\nmultiset functions achieving both these guarantees, leading to improved\nperformance in some tasks but often also to higher compute time than standard\nconstructions. Accordingly, it is natural to inquire whether simpler multiset\nfunctions achieving the same guarantees are available. In this paper, we make a\nlarge step towards giving a negative answer to this question. We consider the\nfamily of k-ary Janossy pooling, which includes many of the most popular\nmultiset models, and prove that no piecewise linear Janossy pooling function\ncan be injective. On the positive side, we show that when restricted to\nmultisets without multiplicities, even simple deep-sets models suffice for\ninjectivity and bi-Lipschitzness.','Ilai Reshef, Nadav Dym','2025-05-26','cs.LG','图像识别','http://arxiv.org/pdf/2505.20150v1','本文研究了多重集函数在神经网络构建中的重要性，提出了一种新的k-ary Janossy pooling家族，证明了没有分段线性的Janossy pooling函数可以是单射的，并且在没有重复元素的多重集情况下，简单的深度集模型足以实现单射性和双Lipschitz性。'),('2505.20152v1','Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models','Benefiting from contrastively trained visual encoders on large-scale natural\nscene images, Large Multimodal Models (LMMs) have achieved remarkable\nperformance across various visual perception tasks. However, the inherent\nlimitations of contrastive learning upon summarized descriptions fundamentally\nrestrict the capabilities of models in meticulous reasoning, particularly in\ncrucial scenarios of geometric problem-solving. To enhance geometric\nunderstanding, we propose a novel hard negative contrastive learning framework\nfor the vision encoder, which combines image-based contrastive learning using\ngeneration-based hard negatives created by perturbing diagram generation code,\nand text-based contrastive learning using rule-based negatives derived from\nmodified geometric descriptions and retrieval-based negatives selected based on\ncaption similarity. We train CLIP using our strong negative learning method,\nnamely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for\ngeometric problem-solving. Experiments show that our trained model, MMGeoLM,\nsignificantly outperforms other open-source models on three geometric reasoning\nbenchmarks. Even with a size of 7B, it can rival powerful closed-source models\nlike GPT-4o. We further study the impact of different negative sample\nconstruction methods and the number of negative samples on the geometric\nreasoning performance of LMM, yielding fruitful conclusions. The code and\ndataset are available at https://github.com/THU-KEG/MMGeoLM.','Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li','2025-05-26','cs.CV','LLM (Large Multimodal Models)','http://arxiv.org/pdf/2505.20152v1','该论文提出了一种新颖的硬负对比学习框架，用于提升几何理解能力，通过结合基于图像和文本的对比学习方法，训练了一个在几何推理任务上表现显著优于其他模型的模型。'),('2505.20154v1','UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter-Efficient Fine-Tuning of Large Models','This paper introduces Uniform Orthogonal Reinitialization Adaptation (UORA),\na novel parameter-efficient fine-tuning (PEFT) approach for Large Language\nModels (LLMs). UORA achieves state-of-the-art performance and parameter\nefficiency by leveraging a low-rank approximation method to reduce the number\nof trainable parameters. Unlike existing methods such as LoRA and VeRA, UORA\nemploys an interpolation-based reparametrization mechanism that selectively\nreinitializes rows and columns in frozen projection matrices, guided by the\nvector magnitude heuristic. This results in substantially fewer trainable\nparameters compared to LoRA and outperforms VeRA in computation and storage\nefficiency. Comprehensive experiments across various benchmarks demonstrate\nUORA\\\'s superiority in achieving competitive fine-tuning performance with\nnegligible computational overhead. We demonstrate its performance on GLUE and\nE2E benchmarks and its effectiveness in instruction-tuning large language\nmodels and image classification models. Our contributions establish a new\nparadigm for scalable and resource-efficient fine-tuning of LLMs.','Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang','2025-05-26','cs.CL','LLM','http://arxiv.org/pdf/2505.20154v1','本文介绍了一种名为Uniform Orthogonal Reinitialization Adaptation (UORA)的新型参数高效微调方法，用于大型语言模型（LLMs）。通过利用低秩逼近方法来减少可训练参数的数量，UORA实现了最先进的性能和参数效率。与现有方法（如LoRA和VeRA）不同，UORA采用基于插值的重新参数化机制，通过向量大小启发式指导选择性地重新初始化冻结投影矩阵中的行和列，从而实现了比LoRA更少的可训练参数，并在计算和存储效率上优于VeRA。全面的实验表明，UORA在各种基准测试中表现出色，实现了具有可忽略计算开销的竞争性微调性能。我们展示了它在GLUE和E2E基准测试中的性能，以及在指导调整大型语言模型和图像分类模型中的有效性。我们的贡献为可扩展和资源高效的LLMs微调建立了一个新的范式。'),('2505.20155v1','Pangu Light: Weight Re-Initialization for Pruning and Accelerating LLMs','Large Language Models (LLMs) deliver state-of-the-art capabilities across\nnumerous tasks, but their immense size and inference costs pose significant\ncomputational challenges for practical deployment. While structured pruning\noffers a promising avenue for model compression, existing methods often\nstruggle with the detrimental effects of aggressive, simultaneous width and\ndepth reductions, leading to substantial performance degradation. This paper\nargues that a critical, often overlooked, aspect in making such aggressive\njoint pruning viable is the strategic re-initialization and adjustment of\nremaining weights to improve the model post-pruning training accuracies. We\nintroduce Pangu Light, a framework for LLM acceleration centered around\nstructured pruning coupled with novel weight re-initialization techniques\ndesigned to address this ``missing piece\\\'\\\'. Our framework systematically\ntargets multiple axes, including model width, depth, attention heads, and\nRMSNorm, with its effectiveness rooted in novel re-initialization methods like\nCross-Layer Attention Pruning (CLAP) and Stabilized LayerNorm Pruning (SLNP)\nthat mitigate performance drops by providing the network a better training\nstarting point. Further enhancing efficiency, Pangu Light incorporates\nspecialized optimizations such as absorbing Post-RMSNorm computations and\ntailors its strategies to Ascend NPU characteristics. The Pangu Light models\nconsistently exhibit a superior accuracy-efficiency trade-off, outperforming\nprominent baseline pruning methods like Nemotron and established LLMs like\nQwen3 series. For instance, on Ascend NPUs, Pangu Light-32B\\\'s 81.6 average\nscore and 2585 tokens/s throughput exceed Qwen3-32B\\\'s 80.9 average score and\n2225 tokens/s.','Hanting Chen, Jiarui Qin, Jialong Guo, Tao Yuan, Yichun Yin, Huiling Zhen, Yasheng Wang, Jinpeng Li, Xiaojun Meng, Meng Zhang, Rongju Ruan, Zheyuan Bai, Yehui Tang, Can Chen, Xinghao Chen, Fisher Yu, Ruiming Tang, Yunhe Wang','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20155v1','本文介绍了一种名为Pangu Light的大型语言模型（LLM）加速框架，结合结构化修剪和新颖的权重重新初始化技术，以改善模型修剪后的训练准确性。该框架在模型宽度、深度、注意力头和RMSNorm等多个方面进行了系统化的优化，表现出卓越的准确性和效率平衡，优于现有的修剪方法和已建立的LLM模型。'),('2505.20161v1','Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning','Effective generalization in language models depends critically on the\ndiversity of their training data. Yet existing diversity metrics often fall\nshort of this goal, relying on surface-level heuristics that are decoupled from\nmodel behavior. This motivates us to ask: What kind of diversity in training\ndata actually drives generalization in language models -- and how can we\nmeasure and amplify it? Through large-scale empirical analyses spanning over\n300 training runs, carefully controlled for data scale and quality, we show\nthat data diversity can be a strong predictor of generalization in LLM\nreasoning -- as measured by average model performance on unseen\nout-of-distribution benchmarks. We introduce G-Vendi, a metric that quantifies\ndiversity via the entropy of model-induced gradients. Despite using a small\noff-the-shelf proxy model for gradients, G-Vendi consistently outperforms\nalternative measures, achieving strong correlation (Spearman\\\'s $\\rho \\approx\n0.9$) with out-of-distribution (OOD) performance on both natural language\ninference (NLI) and math reasoning tasks. Building on this insight, we present\nPrismatic Synthesis, a framework for generating diverse synthetic data by\ntargeting underrepresented regions in gradient space. Experimental results show\nthat Prismatic Synthesis consistently improves model performance as we scale\nsynthetic data -- not just on in-distribution test but across unseen,\nout-of-distribution benchmarks -- significantly outperforming state-of-the-art\nmodels that rely on 20 times larger data generator than ours. For example,\nPrismMath-7B, our model distilled from a 32B LLM, outperforms\nR1-Distill-Qwen-7B -- the same base model trained on proprietary data generated\nby 671B R1 -- on 6 out of 7 challenging benchmarks.','Jaehun Jung, Seungju Han, Ximing Lu, Skyler Hallinan, David Acuna, Shrimai Prabhumoye, Mostafa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Yejin Choi','2025-05-26','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20161v1','该论文通过大规模实证分析，探讨了训练数据的多样性对语言模型泛化的影响，并提出了一种通过梯度熵量化多样性的新指标 G-Vendi。通过实验证明，基于这种洞见的 Prismatic Synthesis 框架可以生成多样化的合成数据，显著提高模型性能。'),('2505.20162v1','Capability-Based Scaling Laws for LLM Red-Teaming','As large language models grow in capability and agency, identifying\nvulnerabilities through red-teaming becomes vital for safe deployment. However,\ntraditional prompt-engineering approaches may prove ineffective once\nred-teaming turns into a weak-to-strong problem, where target models surpass\nred-teamers in capabilities. To study this shift, we frame red-teaming through\nthe lens of the capability gap between attacker and target. We evaluate more\nthan 500 attacker-target pairs using LLM-based jailbreak attacks that mimic\nhuman red-teamers across diverse families, sizes, and capability levels. Three\nstrong trends emerge: (i) more capable models are better attackers, (ii) attack\nsuccess drops sharply once the target\\\'s capability exceeds the attacker\\\'s, and\n(iii) attack success rates correlate with high performance on social science\nsplits of the MMLU-Pro benchmark. From these trends, we derive a jailbreaking\nscaling law that predicts attack success for a fixed target based on\nattacker-target capability gap. These findings suggest that fixed-capability\nattackers (e.g., humans) may become ineffective against future models,\nincreasingly capable open-source models amplify risks for existing systems, and\nmodel providers must accurately measure and control models\\\' persuasive and\nmanipulative abilities to limit their effectiveness as attackers.','Alexander Panfilov, Paul Kassianik, Maksym Andriushchenko, Jonas Geiping','2025-05-26','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20162v1','该论文研究了随着大型语言模型的能力和代理能力增强，通过红队测试来识别漏洞对于安全部署变得至关重要。作者通过LLM-based jailbreak攻击评估了500多个攻击者-目标对，发现更有能力的模型更容易成功攻击，攻击成功率与MMLU-Pro基准测试的表现相关。'),('2505.20163v1','Exploring Generative Error Correction for Dysarthric Speech Recognition','Despite the remarkable progress in end-to-end Automatic Speech Recognition\n(ASR) engines, accurately transcribing dysarthric speech remains a major\nchallenge. In this work, we proposed a two-stage framework for the Speech\nAccessibility Project Challenge at INTERSPEECH 2025, which combines\ncutting-edge speech recognition models with LLM-based generative error\ncorrection (GER). We assess different configurations of model scales and\ntraining strategies, incorporating specific hypothesis selection to improve\ntranscription accuracy. Experiments on the Speech Accessibility Project dataset\ndemonstrate the strength of our approach on structured and spontaneous speech,\nwhile highlighting challenges in single-word recognition. Through comprehensive\nanalysis, we provide insights into the complementary roles of acoustic and\nlinguistic modeling in dysarthric speech recognition','Moreno La Quatra, Alkis Koudounas, Valerio Mario Salerno, Sabato Marco Siniscalchi','2025-05-26','cs.CL','语音处理','http://arxiv.org/pdf/2505.20163v1','本文提出了一个两阶段框架，结合先进的语音识别模型和基于LLM的生成错误校正（GER），用于解决听障者语音转录的挑战。通过在Speech Accessibility Project数据集上的实验，展示了该方法在结构化和自发语音上的有效性，同时也指出了在单词识别上的挑战。'),('2505.20164v1','Visual Abstract Thinking Empowers Multimodal Reasoning','Images usually convey richer detail than text, but often include redundant\ninformation which potentially downgrades multimodal reasoning performance. When\nfaced with lengthy or complex messages, humans tend to employ abstract thinking\nto convert them into simple and concise abstracts. Inspired by this cognitive\nstrategy, we introduce Visual Abstract Thinking (VAT), a novel thinking\nparadigm that prompts Multimodal Large Language Models (MLLMs) with visual\nabstract instead of explicit verbal thoughts or elaborate guidance, permitting\na more concentrated visual reasoning mechanism. Explicit thinking, such as\nChain-of-thought (CoT) or tool-augmented approaches, increases the complexity\nof reasoning process via inserting verbose intermediate steps, external\nknowledge or visual information. In contrast, VAT reduces redundant visual\ninformation and encourages models to focus their reasoning on more essential\nvisual elements. Experimental results show that VAT consistently empowers\ndifferent models, and achieves an average gain of 17% over GPT-4o baseline by\nemploying diverse types of visual abstracts, demonstrating that VAT can enhance\nvisual reasoning abilities for MLLMs regarding conceptual, structural and\nrelational reasoning tasks. VAT is also compatible with CoT in\nknowledge-intensive multimodal reasoning tasks. These findings highlight the\neffectiveness of visual reasoning via abstract thinking and encourage further\nexploration of more diverse reasoning paradigms from the perspective of human\ncognition.','Dairu Liu, Ziyue Wang, Minyuan Ruan, Fuwen Luo, Chi Chen, Peng Li, Yang Liu','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20164v1','该论文介绍了一种名为Visual Abstract Thinking (VAT)的新型思维范式，通过提供视觉抽象而不是明确的语言思维或详细指导，促使多模态大型语言模型（MLLMs）进行更集中的视觉推理机制。实验证明，VAT可以提升MLLMs在概念、结构和关系推理任务上的视觉推理能力。'),('2505.20166v1','From Alignment to Advancement: Bootstrapping Audio-Language Alignment with Synthetic Data','Audio-aware large language models (ALLMs) have recently made great strides in\nunderstanding and processing audio inputs. These models are typically adapted\nfrom text-based large language models (LLMs) through additional training on\naudio-related tasks. However, this adaptation process presents two major\nlimitations. First, ALLMs often suffer from catastrophic forgetting, where\nimportant textual capabilities such as instruction-following are lost after\ntraining on audio data. In some cases, models may even hallucinate sounds that\nare not present in the input audio, raising concerns about their reliability.\nSecond, achieving cross-modal alignment between audio and language typically\nrelies on large collections of task-specific question-answer pairs for\ninstruction tuning, making the process resource-intensive. To address these\nissues, we leverage the backbone LLMs from ALLMs to synthesize general-purpose\ncaption-style alignment data. We refer to this process as bootstrapping\naudio-language alignment via synthetic data generation from backbone LLMs\n(BALSa). Building on BALSa, we introduce LISTEN (Learning to Identify Sounds\nThrough Extended Negative Samples), a contrastive-like training method designed\nto improve ALLMs\\\' ability to distinguish between present and absent sounds. We\nfurther extend BALSa to multi-audio scenarios, where the model either explains\nthe differences between audio inputs or produces a unified caption that\ndescribes them all, thereby enhancing audio-language alignment. Experimental\nresults indicate that our method effectively mitigates audio hallucinations\nwhile reliably maintaining strong performance in audio understanding,\nreasoning, and instruction-following skills. Moreover, incorporating\nmulti-audio training further enhances the model\\\'s comprehension and reasoning\ncapabilities. Overall, BALSa offers an efficient and scalable approach to the\ndevelopment of ALLMs.','Chun-Yi Kuan, Hung-yi Lee','2025-05-26','eess.AS','LLM（大型语言模型）、音频处理','http://arxiv.org/pdf/2505.20166v1','该论文介绍了一种通过合成数据生成来改善音频感知大型语言模型的方法，以解决音频与语言之间的对齐和训练过程中的问题。作者提出了一种名为LISTEN的对比式训练方法，以增强模型在区分存在和不存在声音方面的能力，并在多音频情景下扩展了该方法。'),('2505.20170v1','Program of Equations Thoughts to Solve Algebra Word Problems','Solving algebraic word problems (AWPs) has recently emerged as an important\nnatural language processing task. Recently, large language models (LLMs) have\ndemonstrated powerful mathematical capabilities, and the Chain-of-Thought\ntechnique, which guides LLMs through step-by-step reasoning, has yielded\nimpressive results. However, this reasoning ability is limited by the\ncomputational weaknesses of LLMs themselves, where calculation errors can\naccumulate, leading to incorrect final answers. To address this, we propose\nProgram of Equations Thoughts (POET), which transforms the task of generating\nstep-by-step reasoning answers into a two-stage task of predicting equations\nand generating code, offloading complex computations to a Python interpreter to\navoid calculation errors in LLMs. Furthermore, we propose Zero-shot POET, which\nutilizes a manually designed template to enable LLMs to directly generate\nPython code for one-step solving. Our method achieves accuracies of 95.3% and\n98.0% on the PEN and ALG514 datasets, respectively, setting a new\nstate-of-the-art (SOTA). Zero-shot POET also achieves the SOTA result of 95.5%\non the DRAW-1K dataset.','Yunze Lin','2025-05-26','cs.AI','自然语言处理','http://arxiv.org/pdf/2505.20170v1','本论文提出了一种名为POET的方法，通过将生成逐步推理答案的任务转化为预测方程式和生成代码的两阶段任务，将复杂计算转移到Python解释器中，以避免LLMs中的计算错误。他们还提出了Zero-shot POET方法，利用手动设计的模板使LLMs能够直接生成Python代码进行一步求解。实验结果表明，他们的方法在多个数据集上取得了新的最先进结果。'),('2505.20176v1','\"KAN you hear me?\" Exploring Kolmogorov-Arnold Networks for Spoken Language Understanding','Kolmogorov-Arnold Networks (KANs) have recently emerged as a promising\nalternative to traditional neural architectures, yet their application to\nspeech processing remains under explored. This work presents the first\ninvestigation of KANs for Spoken Language Understanding (SLU) tasks. We\nexperiment with 2D-CNN models on two datasets, integrating KAN layers in five\ndifferent configurations within the dense block. The best-performing setup,\nwhich places a KAN layer between two linear layers, is directly applied to\ntransformer-based models and evaluated on five SLU datasets with increasing\ncomplexity. Our results show that KAN layers can effectively replace the linear\nlayers, achieving comparable or superior performance in most cases. Finally, we\nprovide insights into how KAN and linear layers on top of transformers\ndifferently attend to input regions of the raw waveforms.','Alkis Koudounas, Moreno La Quatra, Eliana Pastor, Sabato Marco Siniscalchi, Elena Baralis','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20176v1','本文首次探索了Kolmogorov-Arnold Networks (KANs) 在口语理解任务中的应用，通过在2D-CNN模型中整合KAN层，发现KAN层可以有效地取代线性层，在大多数情况下实现可比或更优的性能。最终，对KAN和线性层在transformer模型中的不同输入区域进行了比较研究。'),('2505.20177v1','The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination','Inspired by recent work on learning with distribution shift, we give a\ngeneral outlier removal algorithm called iterative polynomial filtering and\nshow a number of striking applications for supervised learning with\ncontamination: (1) We show that any function class that can be approximated by\nlow-degree polynomials with respect to a hypercontractive distribution can be\nefficiently learned under bounded contamination (also known as nasty noise).\nThis is a surprising resolution to a longstanding gap between the complexity of\nagnostic learning and learning with contamination, as it was widely believed\nthat low-degree approximators only implied tolerance to label noise. (2) For\nany function class that admits the (stronger) notion of sandwiching\napproximators, we obtain near-optimal learning guarantees even with respect to\nheavy additive contamination, where far more than $1/2$ of the training set may\nbe added adversarially. Prior related work held only for regression and in a\nlist-decodable setting. (3) We obtain the first efficient algorithms for\ntolerant testable learning of functions of halfspaces with respect to any fixed\nlog-concave distribution. Even the non-tolerant case for a single halfspace in\nthis setting had remained open. These results significantly advance our\nunderstanding of efficient supervised learning under contamination, a setting\nthat has been much less studied than its unsupervised counterpart.','Adam R. Klivans, Konstantinos Stavropoulos, Kevin Tian, Arsen Vasilyan','2025-05-26','cs.LG','机器学习','http://arxiv.org/pdf/2505.20177v1','本文提出了一种名为迭代多项式滤波的异常值移除算法，并展示了在受污染的监督学习中的一些引人注目的应用：（1）任何可以通过低次多项式逼近的函数类在受界限污染（也称为恶意噪声）下可以被有效学习；（2）对于任何具有（更强）夹逼逼近器概念的函数类，我们即使在重度加性污染下也可以获得近乎最优的学习保证；（3）我们获得了第一个针对任何固定对数凹分布的半空间函数的容忍可测试学习的高效算法。这些结果显著推进了我们对受污染的高效监督学习的理解。'),('2505.20178v1','No Free Lunch: Non-Asymptotic Analysis of Prediction-Powered Inference','Prediction-Powered Inference (PPI) is a popular strategy for combining\ngold-standard and possibly noisy pseudo-labels to perform statistical\nestimation. Prior work has shown an asymptotic \"free lunch\" for PPI++, an\nadaptive form of PPI, showing that the *asymptotic* variance of PPI++ is always\nless than or equal to the variance obtained from using gold-standard labels\nalone. Notably, this result holds *regardless of the quality of the\npseudo-labels*. In this work, we demystify this result by conducting an exact\nfinite-sample analysis of the estimation error of PPI++ on the mean estimation\nproblem. We give a \"no free lunch\" result, characterizing the settings (and\nsample sizes) where PPI++ has provably worse estimation error than using\ngold-standard labels alone. Specifically, PPI++ will outperform if and only if\nthe correlation between pseudo- and gold-standard is above a certain level that\ndepends on the number of labeled samples ($n$). In some cases our results\nsimplify considerably: For Gaussian data, the correlation must be at least\n$1/\\sqrt{n - 2}$ in order to see improvement, and a similar result holds for\nbinary labels. In experiments, we illustrate that our theoretical findings hold\non real-world datasets, and give insights into trade-offs between single-sample\nand sample-splitting variants of PPI++.','Pranav Mani, Peng Xu, Zachary C. Lipton, Michael Oberst','2025-05-26','stat.ML','统计估计','http://arxiv.org/pdf/2505.20178v1','该论文研究了预测驱动推理（PPI）策略，通过精确的有限样本分析，揭示了PPI++在估计均值问题上的估计误差，得出了一个“没有免费午餐”的结论，即在某些情况下，PPI++的估计误差会比仅使用金标签更糟糕。'),('2505.20182v1','An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation','We study cost-efficient collaboration between strong and weak language models\nfor repository-level code generation, where the weak model handles simpler\ntasks at lower cost, and the most challenging tasks are delegated to the strong\nmodel. While many works propose architectures for this task, few analyze\nperformance relative to cost. We evaluate a broad spectrum of collaboration\nstrategies: context-based, pipeline-based, and dynamic, on GitHub issue\nresolution. Our most effective collaborative strategy achieves equivalent\nperformance to the strong model while reducing the cost by 40%. Based on our\nfindings, we offer actionable guidelines for choosing collaboration strategies\nunder varying budget and performance constraints. Our results show that\nstrong-weak collaboration substantially boosts the weak model\\\'s performance at\na fraction of the cost, pipeline and context-based methods being most\nefficient. We release the code for our work at\nhttps://github.com/shubhamrgandhi/codegen-strong-weak-collab.','Shubham Gandhi, Atharva Naik, Yiqing Xie, Carolyn Rose','2025-05-26','cs.AI','自然语言处理','http://arxiv.org/pdf/2505.20182v1','该论文研究了强弱语言模型在代码生成中的成本效益合作，弱模型处理简单任务，强模型处理挑战性任务。评估了多种合作策略在GitHub问题解决中的表现，最有效的合作策略在减少成本40%的情况下实现了与强模型相当的性能。'),('2505.20184v1','THiNK: Can Large Language Models Think-aloud?','Assessing higher-order thinking skills in large language models (LLMs)\nremains a fundamental challenge, especially in tasks that go beyond\nsurface-level accuracy. In this work, we propose THiNK (Testing Higher-order\nNotion of Knowledge), a multi-agent, feedback-driven evaluation framework\ngrounded in Bloom\\\'s Taxonomy. THiNK frames reasoning assessment as an iterative\ntask of problem generation, critique, and revision, encouraging LLMs to\nthink-aloud through step-by-step reflection and refinement. This enables a\nsystematic evaluation of both lower-order (e.g., remember, understand) and\nhigher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven\nstate-of-the-art LLMs and perform a detailed cognitive analysis of their\noutputs. Results reveal that while models reliably perform lower-order\ncategories well, they struggle with applying knowledge in realistic contexts\nand exhibit limited abstraction. Structured feedback loops significantly\nimprove reasoning performance, particularly in higher-order thinking.\nQualitative evaluations further confirm that THiNK-guided outputs better align\nwith domain logic and problem structure. The code of our framework provides a\nscalable methodology for probing and enhancing LLM reasoning, offering new\ndirections for evaluation grounded in learning science, which is available at\nour GitHub repository.','Yongan Yu, Mengqian Wu, Yiran Lin, Nikki G. Lobczowski','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20184v1','本文提出了一种名为THiNK的评估框架，旨在评估大型语言模型在高阶思维技能方面的表现。通过引入反馈驱动的多智能体评估方法，鼓励模型通过逐步反思和完善来进行推理评估，从而系统评估了模型在低阶和高阶思维技能上的表现。研究结果表明，结构化反馈循环显著提高了推理性能，特别是在高阶思维方面。'),('2505.20188v1','Research on feature fusion and multimodal patent text based on graph attention network','Aiming at the problems of cross-modal feature fusion, low efficiency of long\ntext modeling and lack of hierarchical semantic coherence in patent text\nsemantic mining, this study proposes HGM-Net, a deep learning framework that\nintegrates Hierarchical Comparative Learning (HCL), Multi-modal Graph Attention\nNetwork (M-GAT) and Multi-Granularity Sparse Attention (MSA), which builds a\ndynamic mask, contrast and cross-structural similarity constraints on the word,\nsentence and paragraph hierarchies through HCL. Contrast and cross-structural\nsimilarity constraints are constructed at the word and paragraph levels by HCL\nto strengthen the local semantic and global thematic consistency of patent\ntext; M-GAT models patent classification codes, citation relations and text\nsemantics as heterogeneous graph structures, and achieves dynamic fusion of\nmulti-source features by cross-modal gated attention; MSA adopts a hierarchical\nsparsity strategy to optimize the computational efficiency of long text\nmodeling at word, phrase, sentence and paragraph granularity. Experiments show\nthat the framework demonstrates significant advantages over existing deep\nlearning methods in tasks such as patent classification and similarity\nmatching, and provides a solution with both theoretical innovation and\npractical value for solving the problems of patent examination efficiency\nimprovement and technology relevance mining.','Zhenzhen Song, Ziwei Liu, Hongji Li','2025-05-26','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20188v1','该论文提出了一种深度学习框架 HGM-Net，通过整合 HCL、M-GAT 和 MSA 方法，解决了跨模态特征融合、长文本建模效率低和专利文本语义挖掘中缺乏层次语义连贯性等问题。实验证明该框架在专利分类和相似度匹配等任务中具有显著优势。'),('2505.20190v1','Leveraging Descriptions of Emotional Preferences in Recommender Systems','The affective attitude of liking a recommended item reflects just one\ncategory in a wide spectrum of affective phenomena that also includes emotions\nsuch as entranced or intrigued, moods such as cheerful or buoyant, as well as\nmore fine-grained affective states, such as \"pleasantly surprised by the\nconclusion\". In this paper, we introduce a novel recommendation task that can\nleverage a virtually unbounded range of affective states sought explicitly by\nthe user in order to identify items that, upon consumption, are likely to\ninduce those affective states. Correspondingly, we create a large dataset of\nuser preferences containing expressions of fine-grained affective states that\nare mined from book reviews, and propose a Transformer-based architecture that\nleverages such affective expressions as input. We then use the resulting\ndataset of affective states preferences, together with the linked users and\ntheir histories of book readings, ratings, and reviews, to train and evaluate\nmultiple recommendation models on the task of matching recommended items with\naffective preferences. Experiments show that the best results are obtained by\nmodels that can utilize textual descriptions of items and user affective\npreferences.','Tonmoy Hasan, Razvan Bunescu','2025-05-26','cs.IR','自然语言处理','http://arxiv.org/pdf/2505.20190v1','本文介绍了一项新颖的推荐任务，旨在识别消费后可能引起用户明确寻求的各种情感状态的物品。作者提出了一种基于Transformer的架构，利用从书评中挖掘的细粒度情感状态表达作为输入。实验结果表明，最佳结果是由能够利用物品的文本描述和用户情感偏好的模型获得的。'),('2505.20192v1','FunReason: Enhancing Large Language Models\\\' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement','The integration of large language models (LLMs) with function calling has\nemerged as a crucial capability for enhancing their practical utility in\nreal-world applications. However, effectively combining reasoning processes\nwith accurate function execution remains a significant challenge. Traditional\ntraining approaches often struggle to balance the detailed reasoning steps with\nthe precision of function calls, leading to suboptimal performance. To address\nthese limitations, we introduce FunReason, a novel framework that enhances\nLLMs\\\' function calling capabilities through an automated data refinement\nstrategy and a Self-Refinement Multiscale Loss (SRML) approach. FunReason\nleverages LLMs\\\' natural reasoning abilities to generate high-quality training\nexamples, focusing on query parseability, reasoning coherence, and function\ncall precision. The SRML approach dynamically balances the contribution of\nreasoning processes and function call accuracy during training, addressing the\ninherent trade-off between these two critical aspects. FunReason achieves\nperformance comparable to GPT-4o while effectively mitigating catastrophic\nforgetting during fine-tuning. FunReason provides a comprehensive solution for\nenhancing LLMs\\\' function calling capabilities by introducing a balanced\ntraining methodology and a data refinement pipeline. For code and dataset,\nplease refer to our repository at GitHub\nhttps://github.com/BingguangHao/FunReason','Bingguang Hao, Maolin Wang, Zengzhuang Xu, Cunyin Peng, Yicheng Chen, Xiangyu Zhao, Jinjie Gu, Chenyi Zhuang','2025-05-26','cs.LG','大语言模型（LLM）','http://arxiv.org/pdf/2505.20192v1','该论文介绍了一种名为FunReason的新框架，通过自动化数据细化策略和自我细化多尺度损失（SRML）方法增强了LLMs的函数调用能力。该框架能够在训练过程中动态平衡推理过程和函数调用准确性的贡献，从而提高了LLMs的性能。'),('2505.20195v2','Monocle: Hybrid Local-Global In-Context Evaluation for Long-Text Generation with Uncertainty-Based Active Learning','Assessing the quality of long-form, model-generated text is challenging, even\nwith advanced LLM-as-a-Judge methods, due to performance degradation as input\nlength increases. To address this issue, we propose a divide-and-conquer\napproach, which breaks down the comprehensive evaluation task into a series of\nlocalized scoring tasks, followed by a final global assessment. This strategy\nallows for more granular and manageable evaluations, ensuring that each segment\nof the text is assessed in isolation for both coherence and quality, while also\naccounting for the overall structure and consistency of the entire piece.\nMoreover, we introduce a hybrid in-context learning approach that leverages\nhuman annotations to enhance the performance of both local and global\nevaluations. By incorporating human-generated feedback directly into the\nevaluation process, this method allows the model to better align with human\njudgment. Finally, we develop an uncertainty-based active learning algorithm\nthat efficiently selects data samples for human annotation, thereby reducing\nannotation costs in practical scenarios. Experimental results show that the\nproposed evaluation framework outperforms several representative baselines,\nhighlighting the effectiveness of our approach.','Xiaorong Wang, Ting Yang, Zhu Zhang, Shuo Wang, Zihan Zhou, Liner Yang, Zhiyuan Liu, Maosong Sun','2025-05-26','cs.CL','生成模型','http://arxiv.org/pdf/2505.20195v2','该论文提出了一种分而治之的方法，将长篇生成文本的评估任务分解为一系列局部评分任务，然后进行最终的全局评估。通过引入混合的上下文学习方法，利用人类注释来增强本地和全局评估的性能。最后，他们开发了一种基于不确定性的主动学习算法，有效地选择数据样本进行人类注释，从而降低实际场景中的注释成本。'),('2505.20196v1','Temporal Sampling for Forgotten Reasoning in LLMs','Fine-tuning large language models (LLMs) is intended to improve their\nreasoning capabilities, yet we uncover a counterintuitive effect: models often\nforget how to solve problems they previously answered correctly during\ntraining. We term this phenomenon temporal forgetting and show that it is\nwidespread across model sizes, fine-tuning methods (both Reinforcement Learning\nand Supervised Fine-Tuning), and multiple reasoning benchmarks. To address this\ngap, we introduce Temporal Sampling, a simple decoding strategy that draws\noutputs from multiple checkpoints along the training trajectory. This approach\nrecovers forgotten solutions without retraining or ensembling, and leads to\nsubstantial improvements in reasoning performance, gains from 4 to 19 points in\nPass@k and consistent gains in Majority@k across several benchmarks. We further\nextend our method to LoRA-adapted models, demonstrating that storing only\nadapter weights across checkpoints achieves similar benefits with minimal\nstorage cost. By leveraging the temporal diversity inherent in training,\nTemporal Sampling offers a practical, compute-efficient way to surface hidden\nreasoning ability and rethink how we evaluate LLMs.','Yuetai Li, Zhangchen Xu, Fengqing Jiang, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Xiang Yue, Radha Poovendran','2025-05-26','cs.AI','LLM (大型语言模型)','http://arxiv.org/pdf/2505.20196v1','该论文研究发现在对大型语言模型进行微调以提高推理能力时，存在一个反直觉的效应：模型经常会忘记如何解决在训练期间先前正确回答的问题。他们提出了一种称为Temporal Sampling的简单解码策略，可以从训练轨迹上的多个检查点中绘制输出，从而恢复遗忘的解决方案，并在推理性能上取得显著改进。'),('2505.20199v1','Adaptive Classifier-Free Guidance via Dynamic Low-Confidence Masking','Classifier-Free Guidance (CFG) significantly enhances controllability in\ngenerative models by interpolating conditional and unconditional predictions.\nHowever, standard CFG often employs a static unconditional input, which can be\nsuboptimal for iterative generation processes where model uncertainty varies\ndynamically. We introduce Adaptive Classifier-Free Guidance (A-CFG), a novel\nmethod that tailors the unconditional input by leveraging the model\\\'s\ninstantaneous predictive confidence. At each step of an iterative (masked)\ndiffusion language model, A-CFG identifies tokens in the currently generated\nsequence for which the model exhibits low confidence. These tokens are\ntemporarily re-masked to create a dynamic, localized unconditional input. This\nfocuses CFG\\\'s corrective influence precisely on areas of ambiguity, leading to\nmore effective guidance. We integrate A-CFG into a state-of-the-art masked\ndiffusion language model and demonstrate its efficacy. Experiments on diverse\nlanguage generation benchmarks show that A-CFG yields substantial improvements\nover standard CFG, achieving, for instance, a 3.9 point gain on GPQA. Our work\nhighlights the benefit of dynamically adapting guidance mechanisms to model\nuncertainty in iterative generation.','Pengxiang Li, Shilin Yan, Joey Tsai, Renrui Zhang, Ruichuan An, Ziyu Guo, Xiaowei Gao','2025-05-26','cs.CL','语言生成/自然语言处理','http://arxiv.org/pdf/2505.20199v1','该论文介绍了一种名为自适应无分类器引导（A-CFG）的新方法，通过根据模型的瞬时预测置信度调整无条件输入，以提高生成模型的可控性和效果。实验结果表明，A-CFG在语言生成任务中取得了显著的改进。'),('2505.20201v2','Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations','Limited access to mental healthcare, extended wait times, and increasing\ncapabilities of Large Language Models (LLMs) has led individuals to turn to\nLLMs for fulfilling their mental health needs. However, examining the\nmulti-turn mental health conversation capabilities of LLMs remains\nunder-explored. Existing evaluation frameworks typically focus on diagnostic\naccuracy and win-rates and often overlook alignment with patient-specific\ngoals, values, and personalities required for meaningful conversations. To\naddress this, we introduce MedAgent, a novel framework for synthetically\ngenerating realistic, multi-turn mental health sensemaking conversations and\nuse it to create the Mental Health Sensemaking Dialogue (MHSD) dataset,\ncomprising over 2,200 patient-LLM conversations. Additionally, we present\nMultiSenseEval, a holistic framework to evaluate the multi-turn conversation\nabilities of LLMs in healthcare settings using human-centric criteria. Our\nfindings reveal that frontier reasoning models yield below-par performance for\npatient-centric communication and struggle at advanced diagnostic capabilities\nwith average score of 31%. Additionally, we observed variation in model\nperformance based on patient\\\'s persona and performance drop with increasing\nturns in the conversation. Our work provides a comprehensive synthetic data\ngeneration framework, a dataset and evaluation framework for assessing LLMs in\nmulti-turn mental health conversations.','Mohit Chandra, Siddharth Sriraman, Harneet Singh Khanuja, Yiqiao Jin, Munmun De Choudhury','2025-05-26','cs.CL','大语言模型(LLM)、自然语言处理(NLP)','http://arxiv.org/pdf/2505.20201v2','该论文介绍了一种新的框架MedAgent，用于合成真实的多轮心理健康对话，并使用它创建了包含超过2,200个患者-LLM对话的Mental Health Sensemaking Dialogue（MHSD）数据集。他们提出了MultiSenseEval，一个评估LLM在医疗环境中多轮对话能力的综合框架。研究发现，前沿推理模型在患者中心沟通方面表现不佳，对高级诊断能力也存在困难。'),('2505.20203v1','Shutdownable Agents through POST-Agency','Many fear that future artificial agents will resist shutdown. I present an\nidea - the POST-Agents Proposal - for ensuring that doesn\\\'t happen. I propose\nthat we train agents to satisfy Preferences Only Between Same-Length\nTrajectories (POST). I then prove that POST - together with other conditions -\nimplies Neutrality+: the agent maximizes expected utility, ignoring the\nprobability distribution over trajectory-lengths. I argue that Neutrality+\nkeeps agents shutdownable and allows them to be useful.','Elliott Thornley','2025-05-26','cs.AI','强化学习','http://arxiv.org/pdf/2505.20203v1','该论文提出了一个名为“POST-Agents Proposal”的想法，通过训练代理满足同长度轨迹之间的偏好来确保未来人工智能代理不会抵抗关闭。作者证明了满足POST条件以及其他条件可以推导出Neutrality+，即代理最大化期望效用，忽略轨迹长度的概率分布。作者认为Neutrality+可以保持代理可关闭性并使其有用。'),('2505.20206v1','Evaluating Large Language Models for Code Review','Context: Code reviews are crucial for software quality. Recent AI advances\nhave allowed large language models (LLMs) to review and fix code; now, there\nare tools that perform these reviews. However, their reliability and accuracy\nhave not yet been systematically evaluated. Objective: This study compares\ndifferent LLMs\\\' performance in detecting code correctness and suggesting\nimprovements. Method: We tested GPT4o and Gemini 2.0 Flash on 492 AI generated\ncode blocks of varying correctness, along with 164 canonical code blocks from\nthe HumanEval benchmark. To simulate the code review task objectively, we\nexpected LLMs to assess code correctness and improve the code if needed. We ran\nexperiments with different configurations and reported on the results. Results:\nWith problem descriptions, GPT4o and Gemini 2.0 Flash correctly classified code\ncorrectness 68.50% and 63.89% of the time, respectively, and corrected the code\n67.83% and 54.26% of the time for the 492 code blocks of varying correctness.\nWithout problem descriptions, performance declined. The results for the 164\ncanonical code blocks differed, suggesting that performance depends on the type\nof code. Conclusion: LLM code reviews can help suggest improvements and assess\ncorrectness, but there is a risk of faulty outputs. We propose a process that\ninvolves humans, called the \"Human in the loop LLM Code Review\" to promote\nknowledge sharing while mitigating the risk of faulty outputs.','Umut Cihan, Arda İçöz, Vahid Haratian, Eray Tüzün','2025-05-26','cs.SE','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20206v1','本研究比较了不同大型语言模型在检测代码正确性和提出改进建议方面的表现。研究使用了GPT4o和Gemini 2.0 Flash对492个AI生成的代码块和164个基准代码块进行了测试，结果显示语言模型在评估代码正确性和改进代码方面表现良好，但存在一定风险。'),('2505.20209v1','How to Improve the Robustness of Closed-Source Models on NLI','Closed-source Large Language Models (LLMs) have become increasingly popular,\nwith impressive performance across a wide range of natural language tasks.\nThese models can be fine-tuned to further improve performance, but this often\nresults in the models learning from dataset-specific heuristics that reduce\ntheir robustness on out-of-distribution (OOD) data. Existing methods to improve\nrobustness either perform poorly, or are non-applicable to closed-source models\nbecause they assume access to model internals, or the ability to change the\nmodel\\\'s training procedure. In this work, we investigate strategies to improve\nthe robustness of closed-source LLMs through data-centric methods that do not\nrequire access to model internals. We find that the optimal strategy depends on\nthe complexity of the OOD data. For highly complex OOD datasets, upsampling\nmore challenging training examples can improve robustness by up to 1.5%. For\nless complex OOD datasets, replacing a portion of the training set with\nLLM-generated examples can improve robustness by 3.7%. More broadly, we find\nthat large-scale closed-source autoregressive LLMs are substantially more\nrobust than commonly used encoder models, and are a more appropriate choice of\nbaseline going forward.','Joe Stacey, Lisa Alazraki, Aran Ubhi, Beyza Ermis, Aaron Mueller, Marek Rei','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20209v1','该论文研究了如何通过数据中心方法提高闭源大型语言模型（LLMs）的鲁棒性，不需要访问模型内部。研究发现，对于复杂的OOD数据集，增加具有挑战性的训练样本可以提高鲁棒性高达1.5％。对于较简单的OOD数据集，用LLM生成的示例替换部分训练集可以提高鲁棒性高达3.7％。此外，研究还发现，大规模闭源自回归LLMs比常用的编码器模型更具鲁棒性，是未来更合适的基准选择。'),('2505.20211v1','Parameter-Efficient Fine-Tuning with Column Space Projection','Fine-tuning large language models (LLMs) with minimal computational overhead\nis essential for efficiently adapting them to downstream tasks under resource\nconstraints. Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank\nAdaptation (LoRA), facilitate this by updating only a small subset of\nparameters. However, recent studies show that LoRA diverges from full\nfine-tuning (Full FT) in its learning behavior, particularly in terms of\nspectral properties. Motivated by these findings, we propose PiCa, the first\ntheoretically grounded PEFT method based on the spectral properties of\nfine-tuned weights. PiCa projects gradients onto the low-rank column subspace\nof pre-trained weights and exhibits learning patterns more closely aligned with\nFull FT. Furthermore, we show that combining PiCa with weight sharing\ndrastically reduces the number of trainable parameters without compromising\nperformance, enabling to achieve superior performance than LoRA using 13x fewer\ntrainable parameters. Extensive experiments demonstrate PiCa achieves the\nstate-of-the-art performance compared to existing PEFT methods.','Junseo Hwang, Wonguk Cho, Taesup Kim','2025-05-26','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20211v1','该论文提出了一种基于预训练权重的谱特性的参数高效微调方法PiCa，通过将梯度投影到低秩列子空间来实现微调，展现出与完全微调更加接近的学习模式。结合权重共享，可以显著减少可训练参数数量，同时不影响性能，比LoRA方法使用更少的参数实现更好的性能表现。'),('2505.20214v1','The Mirage of Multimodality: Where Truth is Tested and Honesty Unravels','Reasoning models have recently attracted significant attention, especially\nfor tasks that involve complex inference. Their strengths exemplify the System\nII paradigm (slow, structured thinking), contrasting with the System I (rapid,\nheuristic-driven). Yet, does slower reasoning necessarily lead to greater\ntruthfulness? Our findings suggest otherwise. In this study, we present the\nfirst systematic investigation of distortions associated with System I and\nSystem II reasoning in multimodal contexts. We demonstrate that slower\nreasoning models, when presented with incomplete or misleading visual inputs,\nare more likely to fabricate plausible yet false details to support flawed\nreasoning -- a phenomenon we term the \"Mirage of Multimodality\". To examine\nthis, we constructed a 5,000-sample hierarchical prompt dataset annotated by 50\nhuman participants. These prompts gradually increase in complexity, revealing a\nconsistent pattern: slower reasoning models tend to employ depth-first thinking\n(delving deeper into incorrect premises), whereas faster chat models favor\nbreadth-first inference, exhibiting greater caution under uncertainty. Our\nresults highlight a critical vulnerability of slower reasoning models: although\nhighly effective in structured domains such as mathematics, it becomes brittle\nwhen confronted with ambiguous multimodal inputs.','Jiaming Ji, Sitong Fang, Wenjing Cao, Jiahao Li, Xuyao Wang, Juntao Dai, Chi-Min Chan, Sirui Han, Yike Guo, Yaodong Yang','2025-05-26','cs.AI','推理模型','http://arxiv.org/pdf/2505.20214v1','本研究对多模态环境下的System I和System II推理进行了系统调查，发现较慢的推理模型在面对不完整或误导性的视觉输入时，更容易编造似是而非的细节支持错误的推理，这种现象被称为“多模态幻觉”。研究结果表明，虽然较慢的推理模型在结构化领域（如数学）中非常有效，但在面对模糊的多模态输入时变得脆弱。'),('2505.20215v1','Dependency Parsing is More Parameter-Efficient with Normalization','Dependency parsing is the task of inferring natural language structure, often\napproached by modeling word interactions via attention through biaffine\nscoring. This mechanism works like self-attention in Transformers, where scores\nare calculated for every pair of words in a sentence. However, unlike\nTransformer attention, biaffine scoring does not use normalization prior to\ntaking the softmax of the scores. In this paper, we provide theoretical\nevidence and empirical results revealing that a lack of normalization\nnecessarily results in overparameterized parser models, where the extra\nparameters compensate for the sharp softmax outputs produced by high variance\ninputs to the biaffine scoring function. We argue that biaffine scoring can be\nmade substantially more efficient by performing score normalization. We conduct\nexperiments on six datasets for semantic and syntactic dependency parsing using\na one-hop parser. We train N-layer stacked BiLSTMs and evaluate the parser\\\'s\nperformance with and without normalizing biaffine scores. Normalizing allows us\nto beat the state of the art on two datasets, with fewer samples and trainable\nparameters. Code: https://anonymous.4open.science/r/EfficientSDP-70C1','Paolo Gajo, Domenic Rosati, Hassan Sajjad, Alberto Barrón-Cedeño','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20215v1','本文研究依存句法分析中的注意力机制，提出通过对双仿射评分进行规范化，可以使模型更高效，并在语义和句法依存分析任务上取得了优于现有技术的结果。'),('2505.20218v1','Fine-grained List-wise Alignment for Generative Medication Recommendation','Accurate and safe medication recommendations are critical for effective\nclinical decision-making, especially in multimorbidity cases. However, existing\nsystems rely on point-wise prediction paradigms that overlook synergistic drug\neffects and potential adverse drug-drug interactions (DDIs). We propose FLAME,\na fine-grained list-wise alignment framework for large language models (LLMs),\nenabling drug-by-drug generation of drug lists. FLAME formulates recommendation\nas a sequential decision process, where each step adds or removes a single\ndrug. To provide fine-grained learning signals, we devise step-wise Group\nRelative Policy Optimization (GRPO) with potential-based reward shaping, which\nexplicitly models DDIs and optimizes the contribution of each drug to the\noverall prescription. Furthermore, FLAME enhances patient modeling by\nintegrating structured clinical knowledge and collaborative information into\nthe representation space of LLMs. Experiments on benchmark datasets demonstrate\nthat FLAME achieves state-of-the-art performance, delivering superior accuracy,\ncontrollable safety-accuracy trade-offs, and strong generalization across\ndiverse clinical scenarios. Our code is available at\nhttps://github.com/cxfann/Flame.','Chenxiao Fan, Chongming Gao, Wentao Shi, Yaxin Gong, Zihao Zhao, Fuli Feng','2025-05-26','cs.LG','大型语言模型(LLM)、药物推荐、医疗健康AI','http://arxiv.org/pdf/2505.20218v1','该论文提出了一种名为FLAME的细粒度列表对齐框架，用于大型语言模型（LLMs）的药物推荐，通过顺序决策过程生成药物列表，考虑了药物之间的协同效应和潜在的不良药物相互作用（DDIs），并结合了结构化临床知识和协作信息来增强患者建模。实验结果表明，FLAME在各种临床场景中实现了最先进的性能。'),('2505.20221v1','Gradient Flow Matching for Learning Update Dynamics in Neural Network Training','Training deep neural networks remains computationally intensive due to the\nitera2 tive nature of gradient-based optimization. We propose Gradient Flow\nMatching (GFM), a continuous-time modeling framework that treats neural network\ntraining as a dynamical system governed by learned optimizer-aware vector\nfields. By leveraging conditional flow matching, GFM captures the underlying\nupdate rules of optimizers such as SGD, Adam, and RMSprop, enabling smooth\nextrapolation of weight trajectories toward convergence. Unlike black-box\nsequence models, GFM incorporates structural knowledge of gradient-based\nupdates into the learning objective, facilitating accurate forecasting of final\nweights from partial training sequences. Empirically, GFM achieves forecasting\naccuracy that is competitive with Transformer-based models and significantly\noutperforms LSTM and other classical baselines. Furthermore, GFM generalizes\nacross neural architectures and initializations, providing a unified framework\nfor studying optimization dynamics and accelerating convergence prediction.','Xiao Shou, Yanna Ding, Jianxi Gao','2025-05-26','cs.LG','优化动力学','http://arxiv.org/pdf/2505.20221v1','该论文提出了一种名为Gradient Flow Matching (GFM) 的连续时间建模框架，将神经网络训练视为由学习的优化器感知向量场控制的动力系统。通过利用条件流匹配，GFM捕获了优化器（如SGD、Adam和RMSprop）的基本更新规则，实现了对权重轨迹向收敛的平滑外推。与黑盒序列模型不同，GFM将基于梯度的更新结构知识纳入学习目标中，促进了从部分训练序列中准确预测最终权重的能力。在实证方面，GFM在预测准确性上与基于Transformer的模型竞争，并显著优于LSTM和其他经典基线模型。'),('2505.20223v1','Chain-of-Thought for Autonomous Driving: A Comprehensive Survey and Future Prospects','The rapid evolution of large language models in natural language processing\nhas substantially elevated their semantic understanding and logical reasoning\ncapabilities. Such proficiencies have been leveraged in autonomous driving\nsystems, contributing to significant improvements in system performance. Models\nsuch as OpenAI o1 and DeepSeek-R1, leverage Chain-of-Thought (CoT) reasoning,\nan advanced cognitive method that simulates human thinking processes,\ndemonstrating remarkable reasoning capabilities in complex tasks. By\nstructuring complex driving scenarios within a systematic reasoning framework,\nthis approach has emerged as a prominent research focus in autonomous driving,\nsubstantially improving the system\\\'s ability to handle challenging cases. This\npaper investigates how CoT methods improve the reasoning abilities of\nautonomous driving models. Based on a comprehensive literature review, we\npresent a systematic analysis of the motivations, methodologies, challenges,\nand future research directions of CoT in autonomous driving. Furthermore, we\npropose the insight of combining CoT with self-learning to facilitate\nself-evolution in driving systems. To ensure the relevance and timeliness of\nthis study, we have compiled a dynamic repository of literature and open-source\nprojects, diligently updated to incorporate forefront developments. The\nrepository is publicly available at\nhttps://github.com/cuiyx1720/Awesome-CoT4AD.','Yixin Cui, Haotian Lin, Shuo Yang, Yixiao Wang, Yanjun Huang, Hong Chen','2025-05-26','cs.RO','自然语言处理','http://arxiv.org/pdf/2505.20223v1','本论文研究了如何利用Chain-of-Thought (CoT) 推理方法来提高自动驾驶模型的推理能力，并提出了将CoT与自学习相结合以促进驾驶系统的自我进化。'),('2505.20225v1','FLAME-MoE: A Transparent End-to-End Research Platform for Mixture-of-Experts Language Models','Recent large language models such as Gemini-1.5, DeepSeek-V3, and Llama-4\nincreasingly adopt Mixture-of-Experts (MoE) architectures, which offer strong\nefficiency-performance trade-offs by activating only a fraction of the model\nper token. Yet academic researchers still lack a fully open, end-to-end MoE\nplatform for investigating scaling, routing, and expert behavior. We release\nFLAME-MoE, a completely open-source research suite composed of seven\ndecoder-only models, ranging from 38M to 1.7B active parameters, whose\narchitecture--64 experts with top-8 gating and 2 shared experts--closely\nreflects modern production LLMs. All training data pipelines, scripts, logs,\nand checkpoints are publicly available to enable reproducible experimentation.\nAcross six evaluation tasks, FLAME-MoE improves average accuracy by up to 3.4\npoints over dense baselines trained with identical FLOPs. Leveraging full\ntraining trace transparency, we present initial analyses showing that (i)\nexperts increasingly specialize on distinct token subsets, (ii) co-activation\nmatrices remain sparse, reflecting diverse expert usage, and (iii) routing\nbehavior stabilizes early in training. All code, training logs, and model\ncheckpoints are available at https://github.com/cmu-flame/FLAME-MoE.','Hao Kang, Zichun Yu, Chenyan Xiong','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20225v1','该论文介绍了一个完全开放源的研究套件FLAME-MoE，其中包括七个仅有解码器的模型，采用Mixture-of-Experts (MoE)架构，通过激活模型中的一小部分来实现强效率-性能权衡。在六个评估任务中，FLAME-MoE相比使用相同FLOPs训练的密集基线模型，平均准确率提高了最多3.4个百分点。'),('2505.20229v1','From What to How: Attributing CLIP\\\'s Latent Components Reveals Unexpected Semantic Reliance','Transformer-based CLIP models are widely used for text-image probing and\nfeature extraction, making it relevant to understand the internal mechanisms\nbehind their predictions. While recent works show that Sparse Autoencoders\n(SAEs) yield interpretable latent components, they focus on what these encode\nand miss how they drive predictions. We introduce a scalable framework that\nreveals what latent components activate for, how they align with expected\nsemantics, and how important they are to predictions. To achieve this, we adapt\nattribution patching for instance-wise component attributions in CLIP and\nhighlight key faithfulness limitations of the widely used Logit Lens technique.\nBy combining attributions with semantic alignment scores, we can automatically\nuncover reliance on components that encode semantically unexpected or spurious\nconcepts. Applied across multiple CLIP variants, our method uncovers hundreds\nof surprising components linked to polysemous words, compound nouns, visual\ntypography and dataset artifacts. While text embeddings remain prone to\nsemantic ambiguity, they are more robust to spurious correlations compared to\nlinear classifiers trained on image embeddings. A case study on skin lesion\ndetection highlights how such classifiers can amplify hidden shortcuts,\nunderscoring the need for holistic, mechanistic interpretability. We provide\ncode at https://github.com/maxdreyer/attributing-clip.','Maximilian Dreyer, Lorenz Hufe, Jim Berend, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek','2025-05-26','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20229v1','该论文介绍了一个可扩展的框架，揭示了Transformer-based CLIP模型中激活的潜在组件是如何驱动预测的，以及它们与预期语义的对齐程度和对预测的重要性。通过结合归因和语义对齐分数，我们可以自动发现编码语义意外或虚假概念的组件的依赖性。'),('2505.20231v1','Bridging the Long-Term Gap: A Memory-Active Policy for Multi-Session Task-Oriented Dialogue','Existing Task-Oriented Dialogue (TOD) systems primarily focus on\nsingle-session dialogues, limiting their effectiveness in long-term memory\naugmentation. To address this challenge, we introduce a MS-TOD dataset, the\nfirst multi-session TOD dataset designed to retain long-term memory across\nsessions, enabling fewer turns and more efficient task completion. This defines\na new benchmark task for evaluating long-term memory in multi-session TOD.\nBased on this new dataset, we propose a Memory-Active Policy (MAP) that\nimproves multi-session dialogue efficiency through a two-stage approach. 1)\nMemory-Guided Dialogue Planning retrieves intent-aligned history, identifies\nkey QA units via a memory judger, refines them by removing redundant questions,\nand generates responses based on the reconstructed memory. 2) Proactive\nResponse Strategy detects and correct errors or omissions, ensuring efficient\nand accurate task completion. We evaluate MAP on MS-TOD dataset, focusing on\nresponse quality and effectiveness of the proactive strategy. Experiments on\nMS-TOD demonstrate that MAP significantly improves task success and turn\nefficiency in multi-session scenarios, while maintaining competitive\nperformance on conventional single-session tasks.','Yiming Du, Bingbing Wang, Yang He, Bin Liang, Baojun Wang, Zhongyang Li, Lin Gui, Jeff Z. Pan, Ruifeng Xu, Kam-Fai Wong','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20231v1','该论文介绍了一个新的多轮任务导向对话（MS-TOD）数据集，旨在保留跨会话的长期记忆，提出了一种名为Memory-Active Policy (MAP)的方法，通过两阶段方法来改善多轮对话的效率。'),('2505.20232v1','Multimodal Federated Learning With Missing Modalities through Feature Imputation Network','Multimodal federated learning holds immense potential for collaboratively\ntraining models from multiple sources without sharing raw data, addressing both\ndata scarcity and privacy concerns, two key challenges in healthcare. A major\nchallenge in training multimodal federated models in healthcare is the presence\nof missing modalities due to multiple reasons, including variations in clinical\npractice, cost and accessibility constraints, retrospective data collection,\nprivacy concerns, and occasional technical or human errors. Previous methods\ntypically rely on publicly available real datasets or synthetic data to\ncompensate for missing modalities. However, obtaining real datasets for every\ndisease is impractical, and training generative models to synthesize missing\nmodalities is computationally expensive and prone to errors due to the high\ndimensionality of medical data. In this paper, we propose a novel, lightweight,\nlow-dimensional feature translator to reconstruct bottleneck features of the\nmissing modalities. Our experiments on three different datasets (MIMIC-CXR, NIH\nOpen-I, and CheXpert), in both homogeneous and heterogeneous settings\nconsistently improve the performance of competitive baselines. The code and\nimplementation details are available at:\nhttps://github.com/bhattarailab/FedFeatGen','Pranav Poudel, Aavash Chhetri, Prashnna Gyawali, Georgios Leontidis, Binod Bhattarai','2025-05-26','cs.LG','多模态联合学习','http://arxiv.org/pdf/2505.20232v1','该论文提出了一种新颖的、轻量级、低维特征转换器，用于重建缺失模态的瓶颈特征，以解决医疗保健中训练多模态联合学习模型时存在的挑战。实验结果表明，在三个不同数据集上，无论是同质还是异质设置，该方法都能提高竞争基线的性能。'),('2505.20235v1','Variational Deep Learning via Implicit Regularization','Modern deep learning models generalize remarkably well in-distribution,\ndespite being overparametrized and trained with little to no explicit\nregularization. Instead, current theory credits implicit regularization imposed\nby the choice of architecture, hyperparameters and optimization procedure.\nHowever, deploying deep learning models out-of-distribution, in sequential\ndecision-making tasks, or in safety-critical domains, necessitates reliable\nuncertainty quantification, not just a point estimate. The machinery of modern\napproximate inference -- Bayesian deep learning -- should answer the need for\nuncertainty quantification, but its effectiveness has been challenged by our\ninability to define useful explicit inductive biases through priors, as well as\nthe associated computational burden. Instead, in this work we demonstrate, both\ntheoretically and empirically, how to regularize a variational deep network\nimplicitly via the optimization procedure, just as for standard deep learning.\nWe fully characterize the inductive bias of (stochastic) gradient descent in\nthe case of an overparametrized linear model as generalized variational\ninference and demonstrate the importance of the choice of parametrization.\nFinally, we show empirically that our approach achieves strong in- and\nout-of-distribution performance without tuning of additional hyperparameters\nand with minimal time and memory overhead over standard deep learning.','Jonathan Wenger, Beau Coker, Juraj Marusic, John P. Cunningham','2025-05-26','cs.LG','变分深度学习','http://arxiv.org/pdf/2505.20235v1','本文研究了如何通过优化过程隐式地对变分深度网络进行正则化，以实现可靠的不确定性量化，并在内外分布性能方面取得了强大的表现。'),('2505.20237v1','Efficient Speech Translation through Model Compression and Knowledge Distillation','Efficient deployment of large audio-language models for speech translation\nremains challenging due to their significant computational requirements. In\nthis paper, we address this challenge through our system submissions to the\n\"Model Compression\" track at the International Conference on Spoken Language\nTranslation (IWSLT 2025). We experiment with a combination of approaches\nincluding iterative layer pruning based on layer importance evaluation,\nlow-rank adaptation with 4-bit quantization (QLoRA), and knowledge\ndistillation. In our experiments, we use Qwen2-Audio-7B-Instruct for speech\ntranslation into German and Chinese. Our pruned (student) models achieve up to\na 50% reduction in both model parameters and storage footprint, while retaining\n97-100% of the translation quality of the in-domain (teacher) models.','Yasmin Moslem','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20237v1','本文通过在国际口语翻译会议（IWSLT 2025）的“模型压缩”赛道上提交系统，通过迭代层剪枝、低秩适应和知识蒸馏等方法，实现了大型音频语言模型的高效部署，实现了模型参数和存储占用的显著减少，同时保持了翻译质量。'),('2505.20241v1','DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning','Reasoning has substantially improved the performance of large language models\n(LLMs) on complicated tasks. Central to the current reasoning studies, Process\nReward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning\nsteps and guide the reasoning process. However, extending PRMs to multimodal\nlarge language models (MLLMs) introduces challenges. Since multimodal reasoning\ncovers a wider range of tasks compared to text-only scenarios, the resulting\ndistribution shift from the training to testing sets is more severe, leading to\ngreater generalization difficulty. Training a reliable multimodal PRM,\ntherefore, demands large and diverse datasets to ensure sufficient coverage.\nHowever, current multimodal reasoning datasets suffer from a marked quality\nimbalance, which degrades PRM performance and highlights the need for an\neffective data selection strategy. To address the issues, we introduce\nDreamPRM, a domain-reweighted training framework for multimodal PRMs which\nemploys bi-level optimization. In the lower-level optimization, DreamPRM\nperforms fine-tuning on multiple datasets with domain weights, allowing the PRM\nto prioritize high-quality reasoning signals and alleviating the impact of\ndataset quality imbalance. In the upper-level optimization, the PRM is\nevaluated on a separate meta-learning dataset; this feedback updates the domain\nweights through an aggregation loss function, thereby improving the\ngeneralization capability of trained PRM. Extensive experiments on multiple\nmultimodal reasoning benchmarks covering both mathematical and general\nreasoning show that test-time scaling with DreamPRM consistently improves the\nperformance of state-of-the-art MLLMs. Further comparisons reveal that\nDreamPRM\\\'s domain-reweighting strategy surpasses other data selection methods\nand yields higher accuracy gains than existing test-time scaling approaches.','Qi Cao, Ruiyi Wang, Ruiyi Zhang, Sai Ashish Somayajula, Pengtao Xie','2025-05-26','cs.LG','多模态大语言模型（MLLM）','http://arxiv.org/pdf/2505.20241v1','该论文介绍了一种名为DreamPRM的域重新加权训练框架，用于多模态PRM，通过双层优化来提高多模态大语言模型的性能。'),('2505.20242v1','RedAHD: Reduction-Based End-to-End Automatic Heuristic Design with Large Language Models','Solving NP-hard combinatorial optimization problems (COPs) (e.g., traveling\nsalesman problems (TSPs) and capacitated vehicle routing problems (CVRPs)) in\npractice traditionally involves handcrafting heuristics or specifying a search\nspace for finding effective heuristics. The main challenges from these\napproaches, however, are the sheer amount of domain knowledge and\nimplementation efforts required from human experts. Recently, significant\nprogress has been made to address these challenges, particularly by using large\nlanguage models (LLMs) to design heuristics within some predetermined\ngeneralized algorithmic framework (GAF, e.g., ant colony optimization and\nguided local search) for building key functions/components (e.g., a priori\ninformation on how promising it is to include each edge in a solution for TSP\nand CVRP). Although existing methods leveraging this idea have shown to yield\nimpressive optimization performance, they are not fully end-to-end and still\nrequire considerable manual interventions. In this paper, we propose a novel\nend-to-end framework, named RedAHD, that enables these LLM-based heuristic\ndesign methods to operate without the need of GAFs. More specifically, RedAHD\nemploys LLMs to automate the process of reduction, i.e., transforming the COP\nat hand into similar COPs that are better-understood, from which LLM-based\nheuristic design methods can design effective heuristics for directly solving\nthe transformed COPs and, in turn, indirectly solving the original COP. Our\nexperimental results, evaluated on six COPs, show that RedAHD is capable of\ndesigning heuristics with competitive or improved results over the\nstate-of-the-art methods with minimal human involvement.','Nguyen Thach, Aida Riahifar, Nathan Huynh, Hau Chan','2025-05-26','cs.LG','组合优化问题（Combinatorial Optimization）','http://arxiv.org/pdf/2505.20242v1','本文提出了一种名为RedAHD的新型端到端框架，利用大型语言模型自动化缩减组合优化问题，从而设计出有效的启发式方法来解决这些问题，实验结果表明RedAHD在六个组合优化问题上设计出具有竞争力或改进的启发式方法。'),('2505.20243v1','It\\\'s High Time: A Survey of Temporal Information Retrieval and Question Answering','Time plays a critical role in how information is generated, retrieved, and\ninterpreted. In this survey, we provide a comprehensive overview of Temporal\nInformation Retrieval and Temporal Question Answering, two research areas aimed\nat handling and understanding time-sensitive information. As the amount of\ntime-stamped content from sources like news articles, web archives, and\nknowledge bases increases, systems must address challenges such as detecting\ntemporal intent, normalizing time expressions, ordering events, and reasoning\nover evolving or ambiguous facts. These challenges are critical across many\ndynamic and time-sensitive domains, from news and encyclopedias to science,\nhistory, and social media. We review both traditional approaches and modern\nneural methods, including those that use transformer models and Large Language\nModels (LLMs). We also review recent advances in temporal language modeling,\nmulti-hop reasoning, and retrieval-augmented generation (RAG), alongside\nbenchmark datasets and evaluation strategies that test temporal robustness,\nrecency awareness, and generalization.','Bhawna Piryani, Abdelrahman Abdullah, Jamshid Mozafari, Avishek Anand, Adam Jatowt','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20243v1','该论文综述了时间信息检索和时间问答两个研究领域，旨在处理和理解时间敏感信息。论文讨论了处理时间意图、规范化时间表达、事件排序和推理等挑战，涵盖了传统方法和现代神经方法，包括使用Transformer模型和大型语言模型（LLMs）等。'),('2505.20245v1','KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing','Recent advances in retrieval-augmented generation (RAG) furnish large\nlanguage models (LLMs) with iterative retrievals of relevant information to\nhandle complex multi-hop questions. These methods typically alternate between\nLLM reasoning and retrieval to accumulate external information into the LLM\\\'s\ncontext. However, the ever-growing context inherently imposes an increasing\nburden on the LLM to perceive connections among critical information pieces,\nwith futile reasoning steps further exacerbating this overload issue. In this\npaper, we present KnowTrace, an elegant RAG framework to (1) mitigate the\ncontext overload and (2) bootstrap higher-quality multi-step reasoning. Instead\nof simply piling the retrieved contents, KnowTrace autonomously traces out\ndesired knowledge triplets to organize a specific knowledge graph relevant to\nthe input question. Such a structured workflow not only empowers the LLM with\nan intelligible context for inference, but also naturally inspires a reflective\nmechanism of knowledge backtracing to identify contributive LLM generations as\nprocess supervision data for self-bootstrapping. Extensive experiments show\nthat KnowTrace consistently surpasses existing methods across three multi-hop\nquestion answering benchmarks, and the bootstrapped version further amplifies\nthe gains.','Rui Li, Quanyu Dai, Zeyu Zhang, Xu Chen, Zhenhua Dong, Ji-Rong Wen','2025-05-26','cs.CL','LLM (大语言模型)、自然语言处理 (NLP)','http://arxiv.org/pdf/2505.20245v1','该论文介绍了一种名为KnowTrace的检索增强生成框架，旨在减轻大语言模型在处理复杂多跳问题时的上下文负担，并提高多步推理的质量。通过自动跟踪所需知识三元组，组织与输入问题相关的特定知识图，为LLM提供可理解的推理上下文，并启发知识回溯机制，用于自我引导。实验证明，KnowTrace在三个多跳问题回答基准上持续优于现有方法，引入的自我引导版本进一步增加了收益。'),('2505.20246v1','On Path to Multimodal Historical Reasoning: HistBench and HistAgent','Recent advances in large language models (LLMs) have led to remarkable\nprogress across domains, yet their capabilities in the humanities, particularly\nhistory, remain underexplored. Historical reasoning poses unique challenges for\nAI, involving multimodal source interpretation, temporal inference, and\ncross-linguistic analysis. While general-purpose agents perform well on many\nexisting benchmarks, they lack the domain-specific expertise required to engage\nwith historical materials and questions. To address this gap, we introduce\nHistBench, a new benchmark of 414 high-quality questions designed to evaluate\nAI\\\'s capacity for historical reasoning and authored by more than 40 expert\ncontributors. The tasks span a wide range of historical problems-from factual\nretrieval based on primary sources to interpretive analysis of manuscripts and\nimages, to interdisciplinary challenges involving archaeology, linguistics, or\ncultural history. Furthermore, the benchmark dataset spans 29 ancient and\nmodern languages and covers a wide range of historical periods and world\nregions. Finding the poor performance of LLMs and other agents on HistBench, we\nfurther present HistAgent, a history-specific agent equipped with carefully\ndesigned tools for OCR, translation, archival search, and image understanding\nin History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of\n27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online\nsearch and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%)\nand Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These\nresults highlight the limitations of existing LLMs and generalist agents and\ndemonstrate the advantages of HistAgent for historical reasoning.','Jiahao Qiu, Fulian Xiao, Yimin Wang, Yuchen Mao, Yijia Chen, Xinzhe Juan, Siran Wang, Xuan Qi, Tongcheng Zhang, Zixin Yao, Jiacheng Guo, Yifu Lu, Charles Argon, Jundi Cui, Daixin Chen, Junran Zhou, Shuyao Zhou, Zhanpeng Zhou, Ling Yang, Shilong Liu, Hongru Wang, Kaixuan Huang, Xun Jiang, Yuming Cao, Yue Chen, Yunfei Chen, Zhengyi Chen, Ruowei Dai, Mengqiu Deng, Jiye Fu, Yunting Gu, Zijie Guan, Zirui Huang, Xiaoyan Ji, Yumeng Jiang, Delong Kong, Haolong Li, Jiaqi Li, Ruipeng Li, Tianze Li, Zhuoran Li, Haixia Lian, Mengyue Lin, Xudong Liu, Jiayi Lu, Jinghan Lu, Wanyu Luo, Ziyue Luo, Zihao Pu, Zhi Qiao, Ruihuan Ren, Liang Wan, Ruixiang Wang, Tianhui Wang, Yang Wang, Zeyu Wang, Zihua Wang, Yujia Wu, Zhaoyi Wu, Hao Xin, Weiao Xing, Ruojun Xiong, Weijie Xu, Yao Shu, Xiao Yao, Xiaorui Yang, Yuchen Yang, Nan Yi, Jiadong Yu, Yangyuxuan Yu, Huiting Zeng, Danni Zhang, Yunjie Zhang, Zhaoyu Zhang, Zhiheng Zhang, Xiaofeng Zheng, Peirong Zhou, Linyan Zhong, Xiaoyin Zong, Ying Zhao, Zhenxin Chen, Lin Ding, Xiaoyu Gao, Bingbing Gong, Yichao Li, Yang Liao, Guang Ma, Tianyuan Ma, Xinrui Sun, Tianyi Wang, Han Xia, Ruobing Xian, Gen Ye, Tengfei Yu, Wentao Zhang, Yuxi Wang, Xi Gao, Mengdi Wang','2025-05-26','cs.AI','LLM、历史推理','http://arxiv.org/pdf/2505.20246v1','该论文介绍了HistBench，一个旨在评估AI在历史推理方面能力的新基准，涉及多模态源解释、时间推断和跨语言分析等挑战。作者提出了一个专门用于历史推理的代理人HistAgent，并在HistBench上取得了显著的性能优势。'),('2505.20249v1','WXImpactBench: A Disruptive Weather Impact Understanding Benchmark for Evaluating Large Language Models','Climate change adaptation requires the understanding of disruptive weather\nimpacts on society, where large language models (LLMs) might be applicable.\nHowever, their effectiveness is under-explored due to the difficulty of\nhigh-quality corpus collection and the lack of available benchmarks. The\nclimate-related events stored in regional newspapers record how communities\nadapted and recovered from disasters. However, the processing of the original\ncorpus is non-trivial. In this study, we first develop a disruptive weather\nimpact dataset with a four-stage well-crafted construction pipeline. Then, we\npropose WXImpactBench, the first benchmark for evaluating the capacity of LLMs\non disruptive weather impacts. The benchmark involves two evaluation tasks,\nmulti-label classification and ranking-based question answering. Extensive\nexperiments on evaluating a set of LLMs provide first-hand analysis of the\nchallenges in developing disruptive weather impact understanding and climate\nchange adaptation systems. The constructed dataset and the code for the\nevaluation framework are available to help society protect against\nvulnerabilities from disasters.','Yongan Yu, Qingchen Hu, Xianda Du, Jiayin Wang, Fengran Mo, Renee Sieber','2025-05-26','cs.CL','LLM（大型语言模型）','http://arxiv.org/pdf/2505.20249v1','该论文介绍了如何利用大型语言模型（LLMs）来理解气候变化对社会的影响，通过构建一个包含四个阶段的数据集，并提出了评估LLMs在气候变化适应中的能力的基准测试。实验结果表明开发气候变化适应系统的挑战。'),('2505.20250v1','Efficient Optimization Accelerator Framework for Multistate Ising Problems','Ising Machines are a prominent class of hardware architectures that aim to\nsolve NP-hard combinatorial optimization problems. These machines consist of a\nnetwork of interacting binary spins/neurons that evolve to represent the\noptimum ground state energy solution. Generally, combinatorial problems are\ntransformed into quadratic unconstrained binary optimization (QUBO) form to\nharness the computational efficiency of these Ising machines. However, this\ntransformation, especially for multi-state problems, often leads to a more\ncomplex exploration landscape than the original problem, thus severely\nimpacting the solution quality. To address this challenge, we model the spin\ninteractions as a generalized boolean logic function to significantly reduce\nthe exploration space. We benchmark the graph coloring problem from the class\nof multi-state NP-hard optimization using probabilistic Ising solvers to\nillustrate the effectiveness of our framework. The proposed methodology\nachieves similar accuracy compared to state-of-the-art heuristics and machine\nlearning algorithms, and demonstrates significant improvement over the existing\nIsing methods. Additionally, we demonstrate that combining parallel tempering\nwith our existing framework further reduces the coloring error by up to 50%\ncompared to the conventionally used Gibbs sampling algorithm. We also design a\n1024-neuron all-to-all connected probabilistic Ising accelerator that shows up\nto 10000x performance acceleration compared to heuristics while reducing the\nnumber of required physical neurons by 1.5-4x compared to conventional Ising\nmachines. Indeed, this accelerator solution demonstrates improvement across all\nmetrics over the current methods, i.e., energy, performance, area, and solution\nquality. Thus, this work expands the potential of existing Ising hardware to\nsolve a broad class of these multistate optimization problems.','Chirag Garg, Sayeef Salahuddin','2025-05-26','cs.AR','强化学习','http://arxiv.org/pdf/2505.20250v1','该论文提出了一种新的方法，将多状态问题中的自旋相互作用建模为广义布尔逻辑函数，以显著减少探索空间，从而改善了Ising机器在解决图着色问题时的效果。作者还设计了一种1024神经元全连接的概率Ising加速器，相比启发式方法性能提升了10000倍，同时减少了所需物理神经元数量。该方法在能量、性能、面积和解决方案质量等各方面都取得了改进。'),('2505.20251v1','Learning Extrapolative Sequence Transformations from Markov Chains','Most successful applications of deep learning involve similar training and\ntest conditions. However, tasks such as biological sequence design involve\nsearching for sequences that improve desirable properties beyond previously\nknown values, which requires novel hypotheses that \\emph{extrapolate} beyond\ntraining data. In these settings, extrapolation may be achieved by using random\nsearch methods such as Markov chain Monte Carlo (MCMC), which, given an initial\nstate, sample local transformations to approximate a target density that\nrewards states with the desired properties. However, even with a well-designed\nproposal, MCMC may struggle to explore large structured state spaces\nefficiently. Rather than relying on stochastic search, it would be desirable to\nhave a model that greedily optimizes the properties of interest, successfully\nextrapolating in as few steps as possible. We propose to learn such a model\nfrom the Markov chains resulting from MCMC search. Specifically, our approach\nuses selected states from Markov chains as a source of training data for an\nautoregressive model, which is then able to efficiently generate novel\nsequences that extrapolate along the sequence-level properties of interest. The\nproposed approach is validated on three problems: protein sequence design, text\nsentiment control, and text anonymization. We find that the autoregressive\nmodel can extrapolate as well or better than MCMC, but with the additional\nbenefits of scalability and significantly higher sample efficiency.','Sophia Hager, Aleem Khan, Andrew Wang, Nicholas Andrews','2025-05-26','cs.LG','生成模型','http://arxiv.org/pdf/2505.20251v1','该论文提出了一种从MCMC搜索中学习的方法，通过使用自回归模型生成具有所需属性的新序列，从而成功地进行外推。在蛋白质序列设计、文本情感控制和文本匿名化等问题上进行了验证，发现自回归模型在外推方面效果良好且具有可扩展性和更高的样本效率。'),('2505.20254v1','Position: Mechanistic Interpretability Should Prioritize Feature Consistency in SAEs','Sparse Autoencoders (SAEs) are a prominent tool in mechanistic\ninterpretability (MI) for decomposing neural network activations into\ninterpretable features. However, the aspiration to identify a canonical set of\nfeatures is challenged by the observed inconsistency of learned SAE features\nacross different training runs, undermining the reliability and efficiency of\nMI research. This position paper argues that mechanistic interpretability\nshould prioritize feature consistency in SAEs -- the reliable convergence to\nequivalent feature sets across independent runs. We propose using the Pairwise\nDictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to\noperationalize consistency and demonstrate that high levels are achievable\n(0.80 for TopK SAEs on LLM activations) with appropriate architectural choices.\nOur contributions include detailing the benefits of prioritizing consistency;\nproviding theoretical grounding and synthetic validation using a model\norganism, which verifies PW-MCC as a reliable proxy for ground-truth recovery;\nand extending these findings to real-world LLM data, where high feature\nconsistency strongly correlates with the semantic similarity of learned feature\nexplanations. We call for a community-wide shift towards systematically\nmeasuring feature consistency to foster robust cumulative progress in MI.','Xiangchen Song, Aashiq Muhamed, Yujia Zheng, Lingjing Kong, Zeyu Tang, Mona T. Diab, Virginia Smith, Kun Zhang','2025-05-26','cs.LG','机械可解释性','http://arxiv.org/pdf/2505.20254v1','本文讨论了稀疏自动编码器（SAEs）在机械可解释性（MI）中的应用，提出了机械可解释性应该优先考虑SAEs中特征的一致性，提出了使用Pairwise Dictionary Mean Correlation Coefficient（PW-MCC）作为衡量一致性的指标，并通过理论分析和实验验证了其可靠性。'),('2505.20258v1','ARM: Adaptive Reasoning Model','While large reasoning models demonstrate strong performance on complex tasks,\nthey lack the ability to adjust reasoning token usage based on task difficulty.\nThis often leads to the \"overthinking\" problem -- excessive and unnecessary\nreasoning -- which, although potentially mitigated by human intervention to\ncontrol the token budget, still fundamentally contradicts the goal of achieving\nfully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a\nreasoning model capable of adaptively selecting appropriate reasoning formats\nbased on the task at hand. These formats include three efficient ones -- Direct\nAnswer, Short CoT, and Code -- as well as a more elaborate format, Long CoT. To\ntrain ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy\nOptimization (GRPO), which addresses the format collapse issue in traditional\nGRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by\nan average of 30%, and up to 70%, while maintaining performance comparable to\nthe model that relies solely on Long CoT. Furthermore, not only does it improve\ninference efficiency through reduced token generation, but it also brings a 2x\nspeedup in training. In addition to the default Adaptive Mode, ARM supports two\nadditional reasoning modes: 1) Instruction-Guided Mode, which allows users to\nexplicitly specify the reasoning format via special tokens -- ideal when the\nappropriate format is known for a batch of tasks. 2) Consensus-Guided Mode,\nwhich aggregates the outputs of the three efficient formats and resorts to Long\nCoT in case of disagreement, prioritizing performance with higher token usage.','Siye Wu, Jian Xie, Yikai Zhang, Aili Chen, Kai Zhang, Yu Su, Yanghua Xiao','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20258v1','该论文提出了一种自适应推理模型（ARM），能够根据任务自适应选择合适的推理格式，包括三种高效格式和一种更复杂的格式。通过引入Ada-GRPO训练ARM，使其在保持性能的同时提高了推理效率和训练速度。'),('2505.20259v1','Lifelong Safety Alignment for Language Models','LLMs have made impressive progress, but their growing capabilities also\nexpose them to highly flexible jailbreaking attacks designed to bypass safety\nalignment. While many existing defenses focus on known types of attacks, it is\nmore critical to prepare LLMs for unseen attacks that may arise during\ndeployment. To address this, we propose a lifelong safety alignment framework\nthat enables LLMs to continuously adapt to new and evolving jailbreaking\nstrategies. Our framework introduces a competitive setup between two\ncomponents: a Meta-Attacker, trained to actively discover novel jailbreaking\nstrategies, and a Defender, trained to resist them. To effectively warm up the\nMeta-Attacker, we first leverage the GPT-4o API to extract key insights from a\nlarge collection of jailbreak-related research papers. Through iterative\ntraining, the first iteration Meta-Attacker achieves a 73% attack success rate\n(ASR) on RR and a 57% transfer ASR on LAT using only single-turn attacks.\nMeanwhile, the Defender progressively improves its robustness and ultimately\nreduces the Meta-Attacker\\\'s success rate to just 7%, enabling safer and more\nreliable deployment of LLMs in open-ended environments. The code is available\nat https://github.com/sail-sg/LifelongSafetyAlignment.','Haoyu Wang, Zeyu Qin, Yifei Zhao, Chao Du, Min Lin, Xueqian Wang, Tianyu Pang','2025-05-26','cs.CR','LLM、安全对齐','http://arxiv.org/pdf/2505.20259v1','该论文提出了一个终身安全对齐框架，使LLMs能够不断适应新的和不断发展的越狱策略。通过竞争性设置Meta-Attacker和Defender两个组件，有效地提高了LLMs在开放环境中的安全性和可靠性。'),('2505.20266v1','syftr: Pareto-Optimal Generative AI','Retrieval-Augmented Generation (RAG) pipelines are central to applying large\nlanguage models (LLMs) to proprietary or dynamic data. However, building\neffective RAG flows is complex, requiring careful selection among vector\ndatabases, embedding models, text splitters, retrievers, and synthesizing LLMs.\nThe challenge deepens with the rise of agentic paradigms. Modules like\nverifiers, rewriters, and rerankers-each with intricate hyperparameter\ndependencies have to be carefully tuned. Balancing tradeoffs between latency,\naccuracy, and cost becomes increasingly difficult in performance-sensitive\napplications.\n  We introduce syftr, a framework that performs efficient multi-objective\nsearch over a broad space of agentic and non-agentic RAG configurations. Using\nBayesian Optimization, syftr discovers Pareto-optimal flows that jointly\noptimize task accuracy and cost. A novel early-stopping mechanism further\nimproves efficiency by pruning clearly suboptimal candidates. Across multiple\nRAG benchmarks, syftr finds flows which are on average approximately 9 times\ncheaper while preserving most of the accuracy of the most accurate flows on the\nPareto-frontier. Furthermore, syftr\\\'s ability to design and optimize allows\nintegrating new modules, making it even easier and faster to realize\nhigh-performing generative AI pipelines.','Alexander Conway, Debadeepta Dey, Stefan Hackmann, Matthew Hausknecht, Michael Schmidt, Mark Steadman, Nick Volynets','2025-05-26','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20266v1','该论文介绍了一种名为syftr的框架，通过贝叶斯优化在广泛的agentic和non-agentic RAG配置空间中进行高效的多目标搜索，发现了联合优化任务准确性和成本的Pareto最优流程。在多个RAG基准测试中，syftr找到了平均约便宜9倍的流程，同时保留了Pareto前沿上最准确流程大部分准确性。此外，syftr的设计和优化能力使得集成新模块变得更容易和更快速。'),('2505.20268v1','Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits','Reinforcement learning with outcome-based feedback faces a fundamental\nchallenge: when rewards are only observed at trajectory endpoints, how do we\nassign credit to the right actions? This paper provides the first comprehensive\nanalysis of this problem in online RL with general function approximation. We\ndevelop a provably sample-efficient algorithm achieving $\\widetilde{O}({C_{\\rm\ncov} H^3}/{\\epsilon^2})$ sample complexity, where $C_{\\rm cov}$ is the\ncoverability coefficient of the underlying MDP. By leveraging general function\napproximation, our approach works effectively in large or infinite state spaces\nwhere tabular methods fail, requiring only that value functions and reward\nfunctions can be represented by appropriate function classes. Our results also\ncharacterize when outcome-based feedback is statistically separated from\nper-step rewards, revealing an unavoidable exponential separation for certain\nMDPs. For deterministic MDPs, we show how to eliminate the completeness\nassumption, dramatically simplifying the algorithm. We further extend our\napproach to preference-based feedback settings, proving that equivalent\nstatistical efficiency can be achieved even under more limited information.\nTogether, these results constitute a theoretical foundation for understanding\nthe statistical properties of outcome-based reinforcement learning.','Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie','2025-05-26','cs.LG','强化学习','http://arxiv.org/pdf/2505.20268v1','本论文研究了具有基于结果反馈的强化学习面临的基本挑战，即当奖励仅在轨迹端点处观察时，如何为正确的动作分配信用。研究提供了在线RL中具有一般函数逼近的这一问题的首个全面分析。他们开发了一种经过证明的样本有效算法，实现了$\\widetilde{O}({C_{\\rm cov} H^3}/{\\epsilon^2})$的样本复杂度，其中$C_{\\rm cov}$是底层MDP的可覆盖系数。'),('2505.20269v1','Comparing Neural Network Encodings for Logic-based Explainability','Providing explanations for the outputs of artificial neural networks (ANNs)\nis crucial in many contexts, such as critical systems, data protection laws and\nhandling adversarial examples. Logic-based methods can offer explanations with\ncorrectness guarantees, but face scalability challenges. Due to these issues,\nit is necessary to compare different encodings of ANNs into logical\nconstraints, which are used in logic-based explainability. This work compares\ntwo encodings of ANNs: one has been used in the literature to provide\nexplanations, while the other will be adapted for our context of\nexplainability. Additionally, the second encoding uses fewer variables and\nconstraints, thus, potentially enhancing efficiency. Experiments showed similar\nrunning times for computing explanations, but the adapted encoding performed up\nto 18\\% better in building logical constraints and up to 16\\% better in overall\ntime.','Levi Cordeiro Carvalho, Saulo A. F. Oliveira, Thiago Alves Rocha','2025-05-26','cs.LO','解释性人工智能','http://arxiv.org/pdf/2505.20269v1','本论文比较了两种人工神经网络到逻辑约束的编码方式，用于提供解释。实验结果显示，第二种编码方式在构建逻辑约束和整体时间上表现更好。'),('2505.20271v1','In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation','Recent advances in diffusion models have enhanced multimodal-guided visual\ngeneration, enabling customized subject insertion that seamlessly \"brushes\"\nuser-specified objects into a given image guided by textual prompts. However,\nexisting methods often struggle to insert customized subjects with high\nfidelity and align results with the user\\\'s intent through textual prompts. In\nthis work, we propose \"In-Context Brush\", a zero-shot framework for customized\nsubject insertion by reformulating the task within the paradigm of in-context\nlearning. Without loss of generality, we formulate the object image and the\ntextual prompts as cross-modal demonstrations, and the target image with the\nmasked region as the query. The goal is to inpaint the target image with the\nsubject aligning textual prompts without model tuning. Building upon a\npretrained MMDiT-based inpainting network, we perform test-time enhancement via\ndual-level latent space manipulation: intra-head \"latent feature shifting\"\nwithin each attention head that dynamically shifts attention outputs to reflect\nthe desired subject semantics and inter-head \"attention reweighting\" across\ndifferent heads that amplifies prompt controllability through differential\nattention prioritization. Extensive experiments and applications demonstrate\nthat our approach achieves superior identity preservation, text alignment, and\nimage quality compared to existing state-of-the-art methods, without requiring\ndedicated training or additional data collection.','Yu Xu, Fan Tang, You Wu, Lin Gao, Oliver Deussen, Hongbin Yan, Jintao Li, Juan Cao, Tong-Yee Lee','2025-05-26','cs.CV','图像识别','http://arxiv.org/pdf/2505.20271v1','本论文提出了一种名为“In-Context Brush”的零样本框架，用于定制主体插入图像，并通过文本提示对齐结果。通过预训练的MMDiT-based修补网络，在测试时通过双级潜在空间操作来增强结果。实验表明，该方法在身份保留、文本对齐和图像质量方面优于现有的最先进方法，而无需专门训练或额外数据收集。'),('2505.20273v1','Ten Principles of AI Agent Economics','The rapid rise of AI-based autonomous agents is transforming human society\nand economic systems, as these entities increasingly exhibit human-like or\nsuperhuman intelligence. From excelling at complex games like Go to tackling\ndiverse general-purpose tasks with large language and multimodal models, AI\nagents are evolving from specialized tools into dynamic participants in social\nand economic ecosystems. Their autonomy and decision-making capabilities are\npoised to impact industries, professions, and human lives profoundly, raising\ncritical questions about their integration into economic activities, potential\nethical concerns, and the balance between their utility and safety.\n  To address these challenges, this paper presents ten principles of AI agent\neconomics, offering a framework to understand how AI agents make decisions,\ninfluence social interactions, and participate in the broader economy. Drawing\non economics, decision theory, and ethics, we explore fundamental questions,\nsuch as whether AI agents might evolve from tools into independent entities,\ntheir impact on labor markets, and the ethical safeguards needed to align them\nwith human values. These principles build on existing economic theories while\naccounting for the unique traits of AI agents, providing a roadmap for their\nresponsible integration into human systems.\n  Beyond theoretical insights, this paper highlights the urgency of future\nresearch into AI trustworthiness, ethical guidelines, and regulatory oversight.\nAs we enter a transformative era, this work serves as both a guide and a call\nto action, ensuring AI agents contribute positively to human progress while\naddressing risks tied to their unprecedented capabilities.','Ke Yang, ChengXiang Zhai','2025-05-26','cs.AI','AI伦理与经济学','http://arxiv.org/pdf/2505.20273v1','本文提出了十项AI代理经济学原则，为理解AI代理如何做出决策、影响社会互动以及参与更广泛经济提供了框架。文章强调了对AI可信度、伦理指南和监管监督的迫切性。'),('2505.20274v1','Probabilistic Kernel Function for Fast Angle Testing','In this paper, we study the angle testing problem in high-dimensional\nEuclidean spaces and propose two projection-based probabilistic kernel\nfunctions, one designed for angle comparison and the other for angle\nthresholding. Unlike existing approaches that rely on random projection vectors\ndrawn from Gaussian distributions, our approach leverages reference angles and\nemploys a deterministic structure for the projection vectors. Notably, our\nkernel functions do not require asymptotic assumptions, such as the number of\nprojection vectors tending to infinity, and can be both theoretically and\nexperimentally shown to outperform Gaussian-distribution-based kernel\nfunctions. We further apply the proposed kernel function to Approximate Nearest\nNeighbor Search (ANNS) and demonstrate that our approach achieves a 2.5X ~ 3X\nhigher query-per-second (QPS) throughput compared to the state-of-the-art\ngraph-based search algorithm HNSW.','Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa','2025-05-26','cs.LG','高维数据处理/近似最近邻搜索','http://arxiv.org/pdf/2505.20274v1','本文研究了高维欧几里得空间中的角度测试问题，并提出了两种基于投影的概率核函数，一种用于角度比较，另一种用于角度阈值设定。与现有方法不同，我们的方法利用参考角度并采用确定性结构的投影向量。我们进一步将提出的核函数应用于近似最近邻搜索（ANNS），并展示我们的方法在查询每秒（QPS）吞吐量方面比基于图的搜索算法HNSW高出2.5倍至3倍。'),('2505.20276v2','Does quantization affect models\\\' performance on long-context tasks?','Large language models (LLMs) now support context windows exceeding 128K\ntokens, but this comes with significant memory requirements and high inference\nlatency. Quantization can mitigate these costs, but may degrade performance. In\nthis work, we present the first systematic evaluation of quantized LLMs on\ntasks with long-inputs (>64K tokens) and long-form outputs. Our evaluation\nspans 9.7K test examples, five quantization methods (FP8, GPTQ-int8, AWQ-int4,\nGPTQ-int4, BNB-nf4), and five models (Llama-3.1 8B and 70B; Qwen-2.5 7B, 32B,\nand 72B). We find that, on average, 8-bit quantization preserves accuracy\n(~0.8% drop), whereas 4-bit methods lead to substantial losses, especially for\ntasks involving long context inputs (drops of up to 59%). This degradation\ntends to worsen when the input is in a language other than English. Crucially,\nthe effects of quantization depend heavily on the quantization method, model,\nand task. For instance, while Qwen-2.5 72B remains robust under BNB-nf4,\nLlama-3.1 70B experiences a 32% performance drop on the same task. These\nfindings highlight the importance of a careful, task-specific evaluation before\ndeploying quantized LLMs, particularly in long-context scenarios and with\nlanguages other than English.','Anmol Mekala, Anirudh Atmakuru, Yixiao Song, Marzena Karpinska, Mohit Iyyer','2025-05-26','cs.CL','大型语言模型（LLM）Quantization','http://arxiv.org/pdf/2505.20276v2','本文系统评估了在长输入（>64K tokens）和长输出任务上的量化大型语言模型（LLMs）的性能。研究发现，8位量化保留了准确性（下降约0.8%），而4位方法导致了较大的性能损失，尤其是对于涉及长上下文输入的任务。'),('2505.20277v1','OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction','Role-Playing Agents (RPAs), benefiting from large language models, is an\nemerging interactive AI system that simulates roles or characters with diverse\npersonalities. However, existing methods primarily focus on mimicking dialogues\namong roles in textual form, neglecting the role\\\'s voice traits (e.g., voice\nstyle and emotions) as playing a crucial effect in interaction, which tends to\nbe more immersive experiences in realistic scenarios. Towards this goal, we\npropose OmniCharacter, a first seamless speech-language personality interaction\nmodel to achieve immersive RPAs with low latency. Specifically, OmniCharacter\nenables agents to consistently exhibit role-specific personality traits and\nvocal traits throughout the interaction, enabling a mixture of speech and\nlanguage responses. To align the model with speech-language scenarios, we\nconstruct a dataset named OmniCharacter-10K, which involves more distinctive\ncharacters (20), richly contextualized multi-round dialogue (10K), and dynamic\nspeech response (135K). Experimental results showcase that our method yields\nbetter responses in terms of both content and style compared to existing RPAs\nand mainstream speech-language models, with a response latency as low as 289ms.\nCode and dataset are available at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/OmniCharacter.','Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, Qiang Qu, Feiteng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li','2025-05-26','cs.CL','语音处理','http://arxiv.org/pdf/2505.20277v1','该论文提出了一种名为OmniCharacter的语音-语言个性化交互模型，旨在实现具有低延迟的沉浸式角色扮演代理。通过构建OmniCharacter-10K数据集，实验结果表明该方法在内容和风格方面均优于现有的RPAs和主流语音-语言模型，响应延迟低至289ms。'),('2505.20278v1','The Coverage Principle: A Framework for Understanding Compositional Generalization','Large language models excel at pattern matching, yet often fall short in\nsystematic compositional generalization. We propose the coverage principle: a\ndata-centric framework showing that models relying primarily on pattern\nmatching for compositional tasks cannot reliably generalize beyond substituting\nfragments that yield identical results when used in the same contexts. We\ndemonstrate that this framework has a strong predictive power for the\ngeneralization capabilities of Transformers. First, we derive and empirically\nconfirm that the training data required for two-hop generalization grows at\nleast quadratically with the token set size, and the training data efficiency\ndoes not improve with 20x parameter scaling. Second, for compositional tasks\nwith path ambiguity where one variable affects the output through multiple\ncomputational paths, we show that Transformers learn context-dependent state\nrepresentations that undermine both performance and interoperability. Third,\nChain-of-Thought supervision improves training data efficiency for multi-hop\ntasks but still struggles with path ambiguity. Finally, we outline a\n\\emph{mechanism-based} taxonomy that distinguishes three ways neural networks\ncan generalize: structure-based (bounded by coverage), property-based\n(leveraging algebraic invariances), and shared-operator (through function\nreuse). This conceptual lens contextualizes our results and highlights where\nnew architectural ideas are needed to achieve systematic compositionally.\nOverall, the coverage principle provides a unified lens for understanding\ncompositional reasoning, and underscores the need for fundamental architectural\nor training innovations to achieve truly systematic compositionality.','Hoyeon Chang, Jinho Park, Hanseul Cho, Sohee Yang, Miyoung Ko, Hyeonbin Hwang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo','2025-05-26','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20278v1','该论文提出了覆盖原则，指出依赖于模式匹配的模型在组合任务中无法可靠地推广到超出在相同上下文中产生相同结果的片段替换。通过实验证明，这一框架对于Transformer的泛化能力具有很强的预测能力。'),('2505.20279v1','VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction','The rapid advancement of Large Multimodal Models (LMMs) for 2D images and\nvideos has motivated extending these models to understand 3D scenes, aiming for\nhuman-like visual-spatial intelligence. Nevertheless, achieving deep spatial\nunderstanding comparable to human capabilities poses significant challenges in\nmodel encoding and data acquisition. Existing methods frequently depend on\nexternal depth sensors for geometry capture or utilize off-the-shelf algorithms\nfor pre-constructing 3D maps, thereby limiting their scalability, especially\nwith prevalent monocular video inputs and for time-sensitive applications. In\nthis work, we introduce VLM-3R, a unified framework for Vision-Language Models\n(VLMs) that incorporates 3D Reconstructive instruction tuning. VLM-3R processes\nmonocular video frames by employing a geometry encoder to derive implicit 3D\ntokens that represent spatial understanding. Leveraging our Spatial-Visual-View\nFusion and over 200K curated 3D reconstructive instruction tuning\nquestion-answer (QA) pairs, VLM-3R effectively aligns real-world spatial\ncontext with language instructions. This enables monocular 3D spatial\nassistance and embodied reasoning. To facilitate the evaluation of temporal\nreasoning, we introduce the Vision-Spatial-Temporal Intelligence benchmark,\nfeaturing over 138.6K QA pairs across five distinct tasks focused on evolving\nspatial relationships. Extensive experiments demonstrate that our model,\nVLM-3R, not only facilitates robust visual-spatial reasoning but also enables\nthe understanding of temporal 3D context changes, excelling in both accuracy\nand scalability.','Zhiwen Fan, Jian Zhang, Renjie Li, Junge Zhang, Runjin Chen, Hezhen Hu, Kevin Wang, Huaizhi Qu, Dilin Wang, Zhicheng Yan, Hongyu Xu, Justin Theiss, Tianlong Chen, Jiachen Li, Zhengzhong Tu, Zhangyang Wang, Rakesh Ranjan','2025-05-26','cs.CV','LLM (Large Multimodal Models)','http://arxiv.org/pdf/2505.20279v1','该论文介绍了一种统一框架 VLM-3R，用于视觉-语言模型，结合了3D重建指导调整，以实现对3D空间的理解和时间推理。通过处理单眼视频帧，利用几何编码器提取隐式3D token，结合200K多个3D重建指导调整的问答对，实现了真实世界空间背景与语言指导的对齐，从而实现了单眼3D空间辅助和具身推理。'),('2505.20280v1','Lorentz Local Canonicalization: How to Make Any Network Lorentz-Equivariant','Lorentz-equivariant neural networks are becoming the leading architectures\nfor high-energy physics. Current implementations rely on specialized layers,\nlimiting architectural choices. We introduce Lorentz Local Canonicalization\n(LLoCa), a general framework that renders any backbone network exactly\nLorentz-equivariant. Using equivariantly predicted local reference frames, we\nconstruct LLoCa-transformers and graph networks. We adapt a recent approach to\ngeometric message passing to the non-compact Lorentz group, allowing\npropagation of space-time tensorial features. Data augmentation emerges from\nLLoCa as a special choice of reference frame. Our models surpass\nstate-of-the-art accuracy on relevant particle physics tasks, while being\n$4\\times$ faster and using $5$-$100\\times$ fewer FLOPs.','Jonas Spinner, Luigi Favaro, Peter Lippmann, Sebastian Pitz, Gerrit Gerhartz, Tilman Plehn, Fred A. Hamprecht','2025-05-26','stat.ML','强化学习','http://arxiv.org/pdf/2505.20280v1','该论文介绍了Lorentz Local Canonicalization (LLoCa) 框架，可以使任何骨干网络完全满足Lorentz等变性。通过等变地预测本地参考框架，构建了LLoCa-transformers和图网络，同时适应了几何消息传递的最新方法，允许传播时空张量特征。通过LLoCa框架，数据增强成为参考框架的一种特殊选择。该模型在相关粒子物理任务上超过了最先进的准确性，同时速度提高了4倍，使用的FLOPs减少了5-100倍。'),('2505.20282v2','One-shot Entropy Minimization','We trained 13,440 large language models and found that entropy minimization\nrequires only a single unlabeled data and 10 steps optimization to achieve\nperformance improvements comparable to or even greater than those obtained\nusing thousands of data and carefully designed rewards in rule-based\nreinforcement learning. This striking result may prompt a rethinking of\npost-training paradigms for large language models. Our code is avaliable at\nhttps://github.com/zitian-gao/one-shot-em.','Zitian Gao, Lynx Chen, Joey Zhou, Bryan Dai','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20282v2','该论文研究表明，通过最小化熵仅使用单个未标记数据和10步优化即可实现与基于规则的强化学习中使用成千上万数据和精心设计奖励相媲美甚至更好的性能改进。这一惊人结果可能促使重新思考大型语言模型的后训练范式。'),('2505.20285v2','MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability','Retrieval-Augmented Language Models (RALMs) represent a classic paradigm\nwhere models enhance generative capabilities using external knowledge retrieved\nvia a specialized module. Recent advancements in Agent techniques enable Large\nLanguage Models (LLMs) to autonomously utilize tools for retrieval, planning,\nand reasoning. While existing training-based methods show promise, their\nagentic abilities are limited by inherent characteristics of the task-specific\ndata used during training. To further enhance the universal search capability\nof agents, we propose a novel pre-training framework, MaskSearch. In the\npre-training stage, we introduce the Retrieval Augmented Mask Prediction (RAMP)\ntask, where the model learns to leverage search tools to fill masked spans on a\nlarge number of pre-training data, thus acquiring universal retrieval and\nreasoning capabilities for LLMs. After that, the model is trained on downstream\ntasks to achieve further improvement. We apply both Supervised Fine-tuning\n(SFT) and Reinforcement Learning (RL) for training. For SFT, we combine\nagent-based and distillation-based methods to generate training data, starting\nwith a multi-agent system consisting of a planner, rewriter, observer, and\nfollowed by a self-evolving teacher model. While for RL, we employ DAPO as the\ntraining framework and adopt a hybrid reward system consisting of answer\nrewards and format rewards. Additionally, we introduce a curriculum learning\napproach that allows the model to learn progressively from easier to more\nchallenging instances based on the number of masked spans. We evaluate the\neffectiveness of our framework in the scenario of open-domain multi-hop\nquestion answering. Through extensive experiments, we demonstrate that\nMaskSearch significantly enhances the performance of LLM-based search agents on\nboth in-domain and out-of-domain downstream tasks.','Weiqi Wu, Xin Guan, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Jiuxin Cao, Hai Zhao, Jingren Zhou','2025-05-26','cs.CL','LLM','http://arxiv.org/pdf/2505.20285v2','该论文提出了一种新的预训练框架 MaskSearch，通过 Retrieval Augmented Mask Prediction (RAMP) 任务，在大量的预训练数据上学习利用搜索工具填充掩码空间，从而为LLMs获取通用的检索和推理能力。在下游任务上，通过监督微调和强化学习来进一步提高模型性能。'),('2505.20286v1','Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution','Recent advances in large language models (LLMs) have enabled agents to\nautonomously perform complex, open-ended tasks. However, many existing\nframeworks depend heavily on manually predefined tools and workflows, which\nhinder their adaptability, scalability, and generalization across domains. In\nthis work, we introduce Alita--a generalist agent designed with the principle\nof \"Simplicity is the ultimate sophistication,\" enabling scalable agentic\nreasoning through minimal predefinition and maximal self-evolution. For minimal\npredefinition, Alita is equipped with only one component for direct\nproblem-solving, making it much simpler and neater than previous approaches\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean\ndesign enhances its potential to generalize to challenging questions, without\nbeing limited by tools. For Maximal self-evolution, we enable the creativity of\nAlita by providing a suite of general-purpose components to autonomously\nconstruct, refine, and reuse external capabilities by generating task-related\nmodel context protocols (MCPs) from open source, which contributes to scalable\nagentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3\naccuracy, which is top-ranking among general-purpose agents, on the GAIA\nbenchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on\nMathvista and PathVQA, outperforming many agent systems with far greater\ncomplexity. More details will be updated at\n$\\href{https://github.com/CharlesQ9/Alita}{https://github.com/CharlesQ9/Alita}$.','Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, Xing Zhou, Dongrui Liu, Ling Yang, Yue Wu, Kaixuan Huang, Shilong Liu, Hongru Wang, Mengdi Wang','2025-05-26','cs.AI','大型语言模型（LLM）','http://arxiv.org/pdf/2505.20286v1','本论文介绍了一种名为Alita的通用智能体，采用“简单即是终极的复杂”原则，通过最小的预定义和最大的自我演化实现可扩展的智能推理。Alita在GAIA基准验证数据集上取得了75.15%的pass@1和87.27%的pass@3准确率，表现优异。'),('2505.20290v1','EgoZero: Robot Learning from Smart Glasses','Despite recent progress in general purpose robotics, robot policies still lag\nfar behind basic human capabilities in the real world. Humans interact\nconstantly with the physical world, yet this rich data resource remains largely\nuntapped in robot learning. We propose EgoZero, a minimal system that learns\nrobust manipulation policies from human demonstrations captured with Project\nAria smart glasses, $\\textbf{and zero robot data}$. EgoZero enables: (1)\nextraction of complete, robot-executable actions from in-the-wild, egocentric,\nhuman demonstrations, (2) compression of human visual observations into\nmorphology-agnostic state representations, and (3) closed-loop policy learning\nthat generalizes morphologically, spatially, and semantically. We deploy\nEgoZero policies on a gripper Franka Panda robot and demonstrate zero-shot\ntransfer with 70% success rate over 7 manipulation tasks and only 20 minutes of\ndata collection per task. Our results suggest that in-the-wild human data can\nserve as a scalable foundation for real-world robot learning - paving the way\ntoward a future of abundant, diverse, and naturalistic training data for\nrobots. Code and videos are available at https://egozero-robot.github.io.','Vincent Liu, Ademi Adeniji, Haotian Zhan, Raunaq Bhirangi, Pieter Abbeel, Lerrel Pinto','2025-05-26','cs.RO','机器人学习','http://arxiv.org/pdf/2505.20290v1','该论文提出了一种名为EgoZero的系统，通过使用Project Aria智能眼镜捕获的人类演示数据，实现了从人类演示中学习稳健的操作策略，并且不需要任何机器人数据。该系统能够从野外、自我中心的人类演示中提取完整的、可执行的动作，将人类视觉观察压缩成与形态无关的状态表示，并进行泛化的闭环策略学习。实验结果表明，EgoZero策略在Franka Panda机器人上的部署实现了7项操作任务的零次转移，成功率达到70%，且每项任务仅需20分钟的数据收集。'),('2505.20291v1','Visualized Text-to-Image Retrieval','We propose Visualize-then-Retrieve (VisRet), a new paradigm for Text-to-Image\n(T2I) retrieval that mitigates the limitations of cross-modal similarity\nalignment of existing multi-modal embeddings. VisRet first projects textual\nqueries into the image modality via T2I generation. Then, it performs retrieval\nwithin the image modality to bypass the weaknesses of cross-modal retrievers in\nrecognizing subtle visual-spatial features. Experiments on three\nknowledge-intensive T2I retrieval benchmarks, including a newly introduced\nmulti-entity benchmark, demonstrate that VisRet consistently improves T2I\nretrieval by 24.5% to 32.7% NDCG@10 across different embedding models. VisRet\nalso significantly benefits downstream visual question answering accuracy when\nused in retrieval-augmented generation pipelines. The method is plug-and-play\nand compatible with off-the-shelf retrievers, making it an effective module for\nknowledge-intensive multi-modal systems. Our code and the new benchmark are\npublicly available at https://github.com/xiaowu0162/Visualize-then-Retrieve.','Di Wu, Yixin Wan, Kai-Wei Chang','2025-05-26','cs.CV','图像识别','http://arxiv.org/pdf/2505.20291v1','该论文提出了一种新的文本到图像检索范式Visualize-then-Retrieve (VisRet)，通过T2I生成将文本查询投影到图像模态，然后在图像模态内进行检索，绕过现有多模态嵌入的跨模态相似性对齐的局限性。实验证明，VisRet在三个知识密集型T2I检索基准上持续改进了24.5%至32.7%的NDCG@10，也在检索增强生成管道中显著提高了下游视觉问答的准确性。'),('2505.20292v3','OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation','Subject-to-Video (S2V) generation aims to create videos that faithfully\nincorporate reference content, providing enhanced flexibility in the production\nof videos. To establish the infrastructure for S2V generation, we propose\nOpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, and\n(ii) OpenS2V-5M, a million-scale dataset. In contrast to existing S2V\nbenchmarks inherited from VBench that focus on global and coarse-grained\nassessment of generated videos, OpenS2V-Eval focuses on the model\\\'s ability to\ngenerate subject-consistent videos with natural subject appearance and identity\nfidelity. For these purposes, OpenS2V-Eval introduces 180 prompts from seven\nmajor categories of S2V, which incorporate both real and synthetic test data.\nFurthermore, to accurately align human preferences with S2V benchmarks, we\npropose three automatic metrics, NexusScore, NaturalScore and GmeScore, to\nseparately quantify subject consistency, naturalness, and text relevance in\ngenerated videos. Building on this, we conduct a comprehensive evaluation of 16\nrepresentative S2V models, highlighting their strengths and weaknesses across\ndifferent content. Moreover, we create the first open-source large-scale S2V\ngeneration dataset OpenS2V-5M, which consists of five million high-quality 720P\nsubject-text-video triples. Specifically, we ensure subject-information\ndiversity in our dataset by (1) segmenting subjects and building pairing\ninformation via cross-video associations and (2) prompting GPT-Image-1 on raw\nframes to synthesize multi-view representations. Through OpenS2V-Nexus, we\ndeliver a robust infrastructure to accelerate future S2V generation research.','Shenghai Yuan, Xianyi He, Yufan Deng, Yang Ye, Jinfa Huang, Bin Lin, Jiebo Luo, Li Yuan','2025-05-26','cs.CV','视频生成','http://arxiv.org/pdf/2505.20292v3','该论文介绍了Subject-to-Video (S2V)生成的基础设施OpenS2V-Nexus，包括OpenS2V-Eval细粒度基准和OpenS2V-5M百万规模数据集。他们提出了三个自动度量标准，NexusScore、NaturalScore和GmeScore，分别量化生成视频中的主题一致性、自然性和文本相关性。通过对16个代表性S2V模型的全面评估，突出了它们在不同内容上的优势和劣势。此外，他们创建了第一个开源大规模S2V生成数据集OpenS2V-5M。'),('2505.20293v1','Enhancing the Comprehensibility of Text Explanations via Unsupervised Concept Discovery','Concept-based explainable approaches have emerged as a promising method in\nexplainable AI because they can interpret models in a way that aligns with\nhuman reasoning. However, their adaption in the text domain remains limited.\nMost existing methods rely on predefined concept annotations and cannot\ndiscover unseen concepts, while other methods that extract concepts without\nsupervision often produce explanations that are not intuitively comprehensible\nto humans, potentially diminishing user trust. These methods fall short of\ndiscovering comprehensible concepts automatically. To address this issue, we\npropose \\textbf{ECO-Concept}, an intrinsically interpretable framework to\ndiscover comprehensible concepts with no concept annotations. ECO-Concept first\nutilizes an object-centric architecture to extract semantic concepts\nautomatically. Then the comprehensibility of the extracted concepts is\nevaluated by large language models. Finally, the evaluation result guides the\nsubsequent model fine-tuning to obtain more understandable explanations.\nExperiments show that our method achieves superior performance across diverse\ntasks. Further concept evaluations validate that the concepts learned by\nECO-Concept surpassed current counterparts in comprehensibility.','Yifan Sun, Danding Wang, Qiang Sheng, Juan Cao, Jintao Li','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20293v1','该论文提出了一种名为ECO-Concept的框架，用于在文本领域自动发现可理解的概念，无需预定义的概念注释。该方法首先利用面向对象的架构自动提取语义概念，然后通过大型语言模型评估提取的概念的可理解性，并通过评估结果指导后续模型微调以获得更易理解的解释。实验证明，该方法在各种任务上表现出优越性能。进一步的概念评估验证了ECO-Concept学习到的概念在可理解性方面超越了当前的对手。'),('2505.20294v1','GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes','Generalizable active mapping in complex unknown environments remains a\ncritical challenge for mobile robots. Existing methods, constrained by\ninsufficient training data and conservative exploration strategies, exhibit\nlimited generalizability across scenes with diverse layouts and complex\nconnectivity. To enable scalable training and reliable evaluation, we introduce\nGLEAM-Bench, the first large-scale benchmark designed for generalizable active\nmapping with 1,152 diverse 3D scenes from synthetic and real-scan datasets.\nBuilding upon this foundation, we propose GLEAM, a unified generalizable\nexploration policy for active mapping. Its superior generalizability comes\nmainly from our semantic representations, long-term navigable goals, and\nrandomized strategies. It significantly outperforms state-of-the-art methods,\nachieving 66.50% coverage (+9.49%) with efficient trajectories and improved\nmapping accuracy on 128 unseen complex scenes. Project page:\nhttps://xiao-chen.tech/gleam/.','Xiao Chen, Tai Wang, Quanyi Li, Tao Huang, Jiangmiao Pang, Tianfan Xue','2025-05-26','cs.CV','强化学习','http://arxiv.org/pdf/2505.20294v1','该论文介绍了一个用于在复杂未知环境中进行通用主动建图的方法，提出了一个大规模基准测试集GLEAM-Bench，并提出了一个统一的通用探索策略GLEAM，通过语义表示、长期可导航目标和随机策略实现了显著的性能提升。'),('2505.20295v1','Self-reflective Uncertainties: Do LLMs Know Their Internal Answer Distribution?','To reveal when a large language model (LLM) is uncertain about a response,\nuncertainty quantification commonly produces percentage numbers along with the\noutput. But is this all we can do? We argue that in the output space of LLMs,\nthe space of strings, exist strings expressive enough to summarize the\ndistribution over output strings the LLM deems possible. We lay a foundation\nfor this new avenue of uncertainty explication and present SelfReflect, a\ntheoretically-motivated metric to assess how faithfully a string summarizes an\nLLM\\\'s internal answer distribution. We show that SelfReflect is able to\ndiscriminate even subtle differences of candidate summary strings and that it\naligns with human judgement, outperforming alternative metrics such as LLM\njudges and embedding comparisons. With SelfReflect, we investigate a number of\nself-summarization methods and find that even state-of-the-art reasoning models\nstruggle to explicate their internal uncertainty. But we find that faithful\nsummarizations can be generated by sampling and summarizing. Our metric enables\nfuture works towards this universal form of LLM uncertainties.','Michael Kirchhof, Luca Füger, Adam Goliński, Eeshan Gunesh Dhekane, Arno Blaas, Sinead Williamson','2025-05-26','cs.CL','LLM (Large Language Model)','http://arxiv.org/pdf/2505.20295v1','该论文探讨了大型语言模型在回答时的不确定性表达方式，提出了一种新的不确定性解释方法，并介绍了SelfReflect指标来评估字符串对LLM内部答案分布的准确性。研究表明，通过抽样和总结可以生成忠实的总结，为未来研究提供了可能性。'),('2505.20296v1','Reasoning LLMs are Wandering Solution Explorers','Large Language Models (LLMs) have demonstrated impressive reasoning abilities\nthrough test-time computation (TTC) techniques such as chain-of-thought\nprompting and tree-based reasoning. However, we argue that current reasoning\nLLMs (RLLMs) lack the ability to systematically explore the solution space.\nThis paper formalizes what constitutes systematic problem solving and\nidentifies common failure modes that reveal reasoning LLMs to be wanderers\nrather than systematic explorers. Through qualitative and quantitative analysis\nacross multiple state-of-the-art LLMs, we uncover persistent issues: invalid\nreasoning steps, redundant explorations, hallucinated or unfaithful\nconclusions, and so on. Our findings suggest that current models\\\' performance\ncan appear to be competent on simple tasks yet degrade sharply as complexity\nincreases. Based on the findings, we advocate for new metrics and tools that\nevaluate not just final outputs but the structure of the reasoning process\nitself.','Jiahao Lu, Ziwei Xu, Mohan Kankanhalli','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20296v1','该论文探讨了当前推理大型语言模型在系统性问题解决方面的不足，通过定性和定量分析揭示了一些持久性问题，并提出了需要新的评估指标和工具来评估推理过程结构的建议。'),('2505.20297v1','DiSA: Diffusion Step Annealing in Autoregressive Image Generation','An increasing number of autoregressive models, such as MAR, FlowAR, xAR, and\nHarmon adopt diffusion sampling to improve the quality of image generation.\nHowever, this strategy leads to low inference efficiency, because it usually\ntakes 50 to 100 steps for diffusion to sample a token. This paper explores how\nto effectively address this issue. Our key motivation is that as more tokens\nare generated during the autoregressive process, subsequent tokens follow more\nconstrained distributions and are easier to sample. To intuitively explain, if\na model has generated part of a dog, the remaining tokens must complete the dog\nand thus are more constrained. Empirical evidence supports our motivation: at\nlater generation stages, the next tokens can be well predicted by a multilayer\nperceptron, exhibit low variance, and follow closer-to-straight-line denoising\npaths from noise to tokens. Based on our finding, we introduce diffusion step\nannealing (DiSA), a training-free method which gradually uses fewer diffusion\nsteps as more tokens are generated, e.g., using 50 steps at the beginning and\ngradually decreasing to 5 steps at later stages. Because DiSA is derived from\nour finding specific to diffusion in autoregressive models, it is complementary\nto existing acceleration methods designed for diffusion alone. DiSA can be\nimplemented in only a few lines of code on existing models, and albeit simple,\nachieves $5-10\\times$ faster inference for MAR and Harmon and $1.4-2.5\\times$\nfor FlowAR and xAR, while maintaining the generation quality.','Qinyu Zhao, Jaskirat Singh, Ming Xu, Akshay Asthana, Stephen Gould, Liang Zheng','2025-05-26','cs.CV','生成模型','http://arxiv.org/pdf/2505.20297v1','本论文探讨了如何有效解决采用扩散采样改善图像生成质量时遇到的推理效率低的问题。作者提出了扩散步骤退火（DiSA）方法，通过逐渐减少扩散步骤来加快推理速度，同时保持生成质量。'),('2505.20298v1','MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal Manga Understanding','Manga, or Japanese comics, is a richly multimodal narrative form that blends\nimages and text in complex ways. Teaching large multimodal models (LMMs) to\nunderstand such narratives at a human-like level could help manga creators\nreflect on and refine their stories. To this end, we introduce two benchmarks\nfor multimodal manga understanding: MangaOCR, which targets in-page text\nrecognition, and MangaVQA, a novel benchmark designed to evaluate contextual\nunderstanding through visual question answering. MangaVQA consists of 526\nhigh-quality, manually constructed question-answer pairs, enabling reliable\nevaluation across diverse narrative and visual scenarios. Building on these\nbenchmarks, we develop MangaLMM, a manga-specialized model finetuned from the\nopen-source LMM Qwen2.5-VL to jointly handle both tasks. Through extensive\nexperiments, including comparisons with proprietary models such as GPT-4o and\nGemini 2.5, we assess how well LMMs understand manga. Our benchmark and model\nprovide a comprehensive foundation for evaluating and advancing LMMs in the\nrichly narrative domain of manga.','Jeonghun Baek, Kazuki Egashira, Shota Onohara, Atsuyuki Miyai, Yuki Imajuku, Hikaru Ikuta, Kiyoharu Aizawa','2025-05-26','cs.CL','多模态学习、自然语言处理','http://arxiv.org/pdf/2505.20298v1','该论文介绍了两个用于多模态漫画理解的基准测试：MangaOCR 用于页面内文本识别，MangaVQA 用于通过视觉问答评估上下文理解。他们开发了一个针对漫画的特殊模型 MangaLMM，通过实验评估了 LMMs 在理解漫画方面的表现。'),('2505.20377v1','Algorithmic Control Improves Residential Building Energy and EV Management when PV Capacity is High but Battery Capacity is Low','Efficient energy management in prosumer households is key to alleviating grid\nstress in an energy transition marked by electric vehicles (EV), renewable\nenergies and battery storage. However, it is unclear how households optimize\nprosumer EV charging. Here we study real-world data from 90 households on\nfixed-rate electricity tariffs in German-speaking countries to investigate the\npotential of Deep Reinforcement Learning (DRL) and other control approaches\n(Rule-Based, Model Predictive Control) to manage the dynamic and uncertain\nenvironment of Home Energy Management (HEM) and optimize household charging\npatterns. The DRL agent efficiently aligns charging of EV and battery storage\nwith photovoltaic (PV) surplus. We find that frequent EV charging transactions,\nearly EV connections and PV surplus increase optimization potential. A detailed\nanalysis of nine households (1 hour resolution, 1 year) demonstrates that high\nbattery capacity facilitates self optimization; in this case further\nalgorithmic control shows little value. In cases with relatively low battery\ncapacity, algorithmic control with DRL improves energy management and cost\nsavings by a relevant margin. This result is further corroborated by our\nsimulation of a synthetic household. We conclude that prosumer households with\noptimization potential would profit from DRL, thus benefiting also the full\nelectricity system and its decarbonization.','Lennart Ullner, Alona Zharova, Felix Creutzig','2025-05-26','eess.SY','强化学习','http://arxiv.org/pdf/2505.20377v1','该论文研究了如何通过深度强化学习（DRL）等控制方法优化家庭能源管理，特别是在处理光伏（PV）剩余电量、电动汽车（EV）充电和电池储能方面的效率。研究结果表明，DRL能够有效地调整EV和电池储能的充电模式，提高能源管理和成本节约。'),('2505.20380v1','GRAPE: Optimize Data Mixture for Group Robust Multi-target Adaptive Pretraining','The performance of large language models (LLMs) across diverse downstream\napplications is fundamentally governed by the quality and composition of their\npretraining corpora. Existing domain reweighting algorithms primarily optimize\ndata mixtures for a single target task, thereby resulting in models that\noverfit to specialized objectives while exhibiting substantial performance\ndegradation on other benchmarks. This paper introduces Group Robust\nMulti-target Adaptive PrEtraining (GRAPE), a novel multi-source-multi-target\ndomain reweighting framework designed to calibrate pretraining data mixtures\nfor robust performance across multiple target tasks simultaneously. GRAPE\ndynamically adjusts sampling weights across source domains (domain weights)\nwhile concurrently modulating task weights that quantify the relative\nimportance of each individual target task. This adaptive process prioritizes\ntasks based on their learning difficulty throughout training. We formulate this\ninterleaved reweighting mechanism as a minimax optimization problem: The inner\nmaximization adjusts task weights leveraging group\ndistributed-robust-optimization (DRO), where those tasks demonstrating the\nleast improvement under the current data mixture are prioritized with higher\nweights; The outer minimization then optimizes domain weights to maximize loss\nreduction on the prioritized tasks. Experiments on ClimbLab and SlimPajama\ndatasets demonstrate that GRAPE consistently outperforms baseline methods in\nterms of reasoning performance across 6 benchmarks. Furthermore, when applied\nto multilingual targets, GRAPE effectively identifies optimal training mixtures\nfrom mainstream languages, achieving superior language modeling capabilities\nacross 8 low-resource target languages.','Simin Fan, Maria Ios Glarou, Martin Jaggi','2025-05-26','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20380v1','该论文介绍了一种名为GRAPE的多源多目标领域重新加权框架，旨在校准预训练数据混合物，以实现在多个目标任务上的稳健性表现。通过动态调整源域（领域权重）的采样权重，同时调节量化每个单独目标任务的相对重要性的任务权重，以优先考虑根据其学习难度调整任务。实验表明，GRAPE在6个基准测试中始终优于基线方法。'),('2505.20405v1','What Changed? Detecting and Evaluating Instruction-Guided Image Edits with Multimodal Large Language Models','Instruction-based image editing models offer increased personalization\nopportunities in generative tasks. However, properly evaluating their results\nis challenging, and most of the existing metrics lag in terms of alignment with\nhuman judgment and explainability. To tackle these issues, we introduce DICE\n(DIfference Coherence Estimator), a model designed to detect localized\ndifferences between the original and the edited image and to assess their\nrelevance to the given modification request. DICE consists of two key\ncomponents: a difference detector and a coherence estimator, both built on an\nautoregressive Multimodal Large Language Model (MLLM) and trained using a\nstrategy that leverages self-supervision, distillation from inpainting\nnetworks, and full supervision. Through extensive experiments, we evaluate each\nstage of our pipeline, comparing different MLLMs within the proposed framework.\nWe demonstrate that DICE effectively identifies coherent edits, effectively\nevaluating images generated by different editing models with a strong\ncorrelation with human judgment. We publicly release our source code, models,\nand data.','Lorenzo Baraldi, Davide Bucciarelli, Federico Betti, Marcella Cornia, Lorenzo Baraldi, Nicu Sebe, Rita Cucchiara','2025-05-26','cs.CV','图像识别','http://arxiv.org/pdf/2505.20405v1','该论文介绍了一种名为DICE的模型，旨在检测原始图像和编辑图像之间的局部差异，并评估这些差异与给定修改请求的相关性。该模型基于自监督、从修补网络中提取的知识以及全面监督进行训练，通过对不同MLLMs进行比较，有效地评估了图像编辑模型生成的图像。'),('2505.20411v1','SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents','LLM-based agents have shown promising capabilities in a growing range of\nsoftware engineering (SWE) tasks. However, advancing this field faces two\ncritical challenges. First, high-quality training data is scarce, especially\ndata that reflects real-world SWE scenarios, where agents must interact with\ndevelopment environments, execute code and adapt behavior based on the outcomes\nof their actions. Existing datasets are either limited to one-shot code\ngeneration or comprise small, manually curated collections of interactive\ntasks, lacking both scale and diversity. Second, the lack of fresh interactive\nSWE tasks affects evaluation of rapidly improving models, as static benchmarks\nquickly become outdated due to contamination issues. To address these\nlimitations, we introduce a novel, automated, and scalable pipeline to\ncontinuously extract real-world interactive SWE tasks from diverse GitHub\nrepositories. Using this pipeline, we construct SWE-rebench, a public dataset\ncomprising over 21,000 interactive Python-based SWE tasks, suitable for\nreinforcement learning of SWE agents at scale. Additionally, we use continuous\nsupply of fresh tasks collected using SWE-rebench methodology to build a\ncontamination-free benchmark for agentic software engineering. We compare\nresults of various LLMs on this benchmark to results on SWE-bench Verified and\nshow that performance of some language models might be inflated due to\ncontamination issues.','Ibragim Badertdinov, Alexander Golubev, Maksim Nekrashevich, Anton Shevtsov, Simon Karasik, Andrei Andriushchenko, Maria Trofimova, Daria Litvintseva, Boris Yangel','2025-05-26','cs.SE','强化学习','http://arxiv.org/pdf/2505.20411v1','该论文介绍了一种新颖、自动化且可扩展的方法，用于从各种GitHub存储库中持续提取真实世界的交互式软件工程任务，构建了一个包含超过21,000个基于Python的交互式SWE任务的公共数据集，并用于规模化强化学习。此外，作者还利用SWE-rebench方法持续收集新任务，构建了一个无污染的基准，用于评估代理式软件工程。研究比较了各种LLMs在这一基准上的表现，并显示一些语言模型的性能可能因污染问题而被夸大。'),('2505.20414v1','RetroMotion: Retrocausal Motion Forecasting Models are Instructable','Motion forecasts of road users (i.e., agents) vary in complexity as a\nfunction of scene constraints and interactive behavior. We address this with a\nmulti-task learning method for motion forecasting that includes a retrocausal\nflow of information. The corresponding tasks are to forecast (1) marginal\ntrajectory distributions for all modeled agents and (2) joint trajectory\ndistributions for interacting agents. Using a transformer model, we generate\nthe joint distributions by re-encoding marginal distributions followed by\npairwise modeling. This incorporates a retrocausal flow of information from\nlater points in marginal trajectories to earlier points in joint trajectories.\nPer trajectory point, we model positional uncertainty using compressed\nexponential power distributions. Notably, our method achieves state-of-the-art\nresults in the Waymo Interaction Prediction dataset and generalizes well to the\nArgoverse 2 dataset. Additionally, our method provides an interface for issuing\ninstructions through trajectory modifications. Our experiments show that\nregular training of motion forecasting leads to the ability to follow\ngoal-based instructions and to adapt basic directional instructions to the\nscene context. Code: https://github.com/kit-mrt/future-motion','Royden Wagner, Omer Sahin Tas, Felix Hauser, Marlon Steiner, Dominik Strutz, Abhishek Vivekanandan, Carlos Fernandez, Christoph Stiller','2025-05-26','cs.CV','预测模型/交互模型/多任务学习','http://arxiv.org/pdf/2505.20414v1','该论文提出了一种多任务学习方法，用于预测道路用户（即代理）的运动轨迹，包括预测所有建模代理的边际轨迹分布和交互代理的联合轨迹分布。他们使用变压器模型生成联合分布，通过重新编码边际分布后进行成对建模，实现了信息的逆因果流动。实验结果表明，他们的方法在Waymo Interaction Prediction数据集中取得了最先进的结果，并且在Argoverse 2数据集上有良好的泛化能力。'),('2505.20415v1','Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision','Large language models (LLMs) have shown promising performance in mathematical\nand logical reasoning benchmarks. However, recent studies have pointed to\nmemorization, rather than generalization, as one of the leading causes for such\nperformance. LLMs, in fact, are susceptible to content variations,\ndemonstrating a lack of robust symbolic abstractions supporting their reasoning\nprocess. To improve reliability, many attempts have been made to combine LLMs\nwith symbolic methods. Nevertheless, existing approaches fail to effectively\nleverage symbolic representations due to the challenges involved in developing\nreliable and scalable verification mechanisms. In this paper, we propose to\novercome such limitations by generating symbolic reasoning trajectories and\nselect the high-quality ones using a process reward model automatically tuned\nbased on Monte Carlo estimation. The trajectories are then employed via\nfine-tuning methods to improve logical reasoning and generalization. Our\nresults on logical reasoning benchmarks such as FOLIO and LogicAsker show the\neffectiveness of the proposed method with large gains on frontier and\nopen-weight models. Moreover, additional experiments on claim verification\nreveal that fine-tuning on the generated symbolic reasoning trajectories\nenhances out-of-domain generalizability, suggesting the potential impact of\nsymbolically-guided process supervision in alleviating the effect of\nmemorization on LLM reasoning.','Xingwei Tan, Marco Valentino, Mahmud Akhter, Maria Liakata, Nikolaos Aletras','2025-05-26','cs.CL','LLM（大型语言模型）、符号推理','http://arxiv.org/pdf/2505.20415v1','该论文提出了一种通过生成符号推理轨迹并利用过程奖励模型选择高质量轨迹的方法，以改善大型语言模型在逻辑推理和泛化方面的性能。实验结果表明，该方法在逻辑推理基准测试中取得了显著的改进，并且在声明验证方面也表现出了潜在的泛化能力提升。'),('2505.20416v1','GraphGen: Enhancing Supervised Fine-Tuning for LLMs with Knowledge-Driven Synthetic Data Generation','Fine-tuning for large language models (LLMs) typically requires substantial\namounts of high-quality supervised data, which is both costly and\nlabor-intensive to acquire. While synthetic data generation has emerged as a\npromising solution, existing approaches frequently suffer from factual\ninaccuracies, insufficient long-tail coverage, simplistic knowledge structures,\nand homogenized outputs. To address these challenges, we introduce GraphGen, a\nknowledge graph-guided framework designed for three key question-answering (QA)\nscenarios: atomic QA, aggregated QA, and multi-hop QA. It begins by\nconstructing a fine-grained knowledge graph from the source text. It then\nidentifies knowledge gaps in LLMs using the expected calibration error metric,\nprioritizing the generation of QA pairs that target high-value, long-tail\nknowledge. Furthermore, GraphGen incorporates multi-hop neighborhood sampling\nto capture complex relational information and employs style-controlled\ngeneration to diversify the resulting QA data. Experimental results on\nknowledge-intensive tasks under closed-book settings demonstrate that GraphGen\noutperforms conventional synthetic data methods, offering a more reliable and\ncomprehensive solution to the data scarcity challenge in supervised\nfine-tuning. The code and data are publicly available at\nhttps://github.com/open-sciencelab/GraphGen.','Zihong Chen, Wanli Jiang, Jinzhe Li, Zhonghang Yuan, Huanjun Kong, Wanli Ouyang, Nanqing Dong','2025-05-26','cs.CL','LLM（大型语言模型）、自然语言处理','http://arxiv.org/pdf/2505.20416v1','该论文介绍了一种名为GraphGen的知识图引导框架，用于生成针对三种关键问答场景的合成数据，以解决大型语言模型在微调过程中需要大量高质量监督数据的问题。该方法通过构建细粒度的知识图，识别LLMs中的知识缺口，并利用多跳邻域抽样和样式控制生成QA数据，实验结果表明GraphGen优于传统合成数据方法。'),('2505.20417v1','SCAR: Shapley Credit Assignment for More Efficient RLHF','Reinforcement Learning from Human Feedback (RLHF) is a widely used technique\nfor aligning Large Language Models (LLMs) with human preferences, yet it often\nsuffers from sparse reward signals, making effective credit assignment\nchallenging. In typical setups, the reward model provides a single scalar score\nfor an entire generated sequence, offering little insight into which token or\nspan-level decisions were responsible for the outcome. To address this, we\npropose Shapley Credit Assignment Rewards (SCAR), a novel method that leverages\nShapley values in cooperative game theory. SCAR distributes the total\nsequence-level reward among constituent tokens or text spans based on their\nprincipled marginal contributions. This creates dense reward signals,\ncrucially, without necessitating the training of auxiliary critique models or\nrecourse to fine-grained human annotations at intermediate generation stages.\nUnlike prior dense reward methods, SCAR offers a game-theoretic foundation for\nfair credit attribution. Theoretically, we demonstrate that SCAR preserves the\noriginal optimal policy, and empirically, across diverse tasks including\nsentiment control, text summarization, and instruction tuning, we show that\nSCAR converges significantly faster and achieves higher final reward scores\ncompared to standard RLHF and attention-based dense reward baselines. Our\nfindings suggest that SCAR provides a more effective and theoretically sound\nmethod for credit assignment in RLHF, leading to more efficient alignment of\nLLMs.','Meng Cao, Shuyuan Zhang, Xiao-Wen Chang, Doina Precup','2025-05-26','cs.AI','强化学习','http://arxiv.org/pdf/2505.20417v1','该论文提出了一种新的方法 SCAR，利用合作博弈论中的 Shapley 值来解决强化学习中稀疏奖励信号导致的信用分配困难问题。SCAR能够将总的序列级奖励分配给组成部分的标记或文本片段，从而提供密集的奖励信号，比传统的RLHF和基于注意力的密集奖励基线收敛更快，获得更高的最终奖励分数。'),('2505.20422v1','SEMMA: A Semantic Aware Knowledge Graph Foundation Model','Knowledge Graph Foundation Models (KGFMs) have shown promise in enabling\nzero-shot reasoning over unseen graphs by learning transferable patterns.\nHowever, most existing KGFMs rely solely on graph structure, overlooking the\nrich semantic signals encoded in textual attributes. We introduce SEMMA, a\ndual-module KGFM that systematically integrates transferable textual semantics\nalongside structure. SEMMA leverages Large Language Models (LLMs) to enrich\nrelation identifiers, generating semantic embeddings that subsequently form a\ntextual relation graph, which is fused with the structural component. Across 54\ndiverse KGs, SEMMA outperforms purely structural baselines like ULTRA in fully\ninductive link prediction. Crucially, we show that in more challenging\ngeneralization settings, where the test-time relation vocabulary is entirely\nunseen, structural methods collapse while SEMMA is 2x more effective. Our\nfindings demonstrate that textual semantics are critical for generalization in\nsettings where structure alone fails, highlighting the need for foundation\nmodels that unify structural and linguistic signals in knowledge reasoning.','Arvindh Arun, Sumit Kumar, Mojtaba Nayyeri, Bo Xiong, Ponnurangam Kumaraguru, Antonio Vergari, Steffen Staab','2025-05-26','cs.CL','知识图基础模型(Large Language Models)','http://arxiv.org/pdf/2505.20422v1','SEMMA是一个双模块的知识图基础模型，通过系统地整合可转移的文本语义和结构来进行知识推理。在54个不同的知识图上，SEMMA在全归纳链接预测方面优于仅使用结构的基线模型ULTRA。研究结果表明，在更具挑战性的泛化设置中，结构方法崩溃，而SEMMA的效果提高了2倍。'),('2505.20423v1','Vision-Based Risk Aware Emergency Landing for UAVs in Complex Urban Environments','Landing safely in crowded urban environments remains an essential yet\nchallenging endeavor for Unmanned Aerial Vehicles (UAVs), especially in\nemergency situations. In this work, we propose a risk-aware approach that\nharnesses semantic segmentation to continuously evaluate potential hazards in\nthe drone\\\'s field of view. By using a specialized deep neural network to assign\npixel-level risk values and applying an algorithm based on risk maps, our\nmethod adaptively identifies a stable Safe Landing Zone (SLZ) despite moving\ncritical obstacles such as vehicles, people, etc., and other visual challenges\nlike shifting illumination. A control system then guides the UAV toward this\nlow-risk region, employing altitude-dependent safety thresholds and temporal\nlanding point stabilization to ensure robust descent trajectories. Experimental\nvalidation in diverse urban environments demonstrates the effectiveness of our\napproach, achieving over 90% landing success rates in very challenging real\nscenarios, showing significant improvements in various risk metrics. Our\nfindings suggest that risk-oriented vision methods can effectively help reduce\nthe risk of accidents in emergency landing situations, particularly in complex,\nunstructured, urban scenarios, densely populated with moving risky obstacles,\nwhile potentiating the true capabilities of UAVs in complex urban operations.','Julio de la Torre-Vanegas, Miguel Soriano-Garcia, Israel Becerra, Diego Mercado-Ravell','2025-05-26','cs.RO','强化学习','http://arxiv.org/pdf/2505.20423v1','本文提出了一种风险感知的方法，利用语义分割来评估无人机视野中的潜在危险，以实现在拥挤的城市环境中安全着陆。通过使用深度神经网络分配像素级风险值，并应用基于风险地图的算法，方法能够自适应地识别出一个稳定的安全着陆区域，以确保无人机在移动的障碍物和其他视觉挑战下实现稳健的下降轨迹。'),('2505.20424v1','Robot Operation of Home Appliances by Reading User Manuals','Operating home appliances, among the most common tools in every household, is\na critical capability for assistive home robots. This paper presents ApBot, a\nrobot system that operates novel household appliances by \"reading\" their user\nmanuals. ApBot faces multiple challenges: (i) infer goal-conditioned partial\npolicies from their unstructured, textual descriptions in a user manual\ndocument, (ii) ground the policies to the appliance in the physical world, and\n(iii) execute the policies reliably over potentially many steps, despite\ncompounding errors. To tackle these challenges, ApBot constructs a structured,\nsymbolic model of an appliance from its manual, with the help of a large\nvision-language model (VLM). It grounds the symbolic actions visually to\ncontrol panel elements. Finally, ApBot closes the loop by updating the model\nbased on visual feedback. Our experiments show that across a wide range of\nsimulated and real-world appliances, ApBot achieves consistent and\nstatistically significant improvements in task success rate, compared with\nstate-of-the-art large VLMs used directly as control policies. These results\nsuggest that a structured internal representations plays an important role in\nrobust robot operation of home appliances, especially, complex ones.','Jian Zhang, Hanbo Zhang, Anxing Xiao, David Hsu','2025-05-26','cs.RO','自然语言处理','http://arxiv.org/pdf/2505.20424v1','本文介绍了一种名为ApBot的机器人系统，通过“阅读”家用电器的用户手册来操作新型家用电器。该系统利用大型视觉语言模型构建电器的结构化符号模型，并通过视觉方式将符号动作与控制面板元素进行关联，最终通过视觉反馈更新模型。实验结果显示，ApBot在模拟和真实家用电器上实现了一致且显著的任务成功率提高。'),('2505.20428v1','The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project','This paper presents UD-NewsCrawl, the largest Tagalog treebank to date,\ncontaining 15.6k trees manually annotated according to the Universal\nDependencies framework. We detail our treebank development process, including\ndata collection, pre-processing, manual annotation, and quality assurance\nprocedures. We provide baseline evaluations using multiple transformer-based\nmodels to assess the performance of state-of-the-art dependency parsers on\nTagalog. We also highlight challenges in the syntactic analysis of Tagalog\ngiven its distinctive grammatical properties, and discuss its implications for\nthe annotation of this treebank. We anticipate that UD-NewsCrawl and our\nbaseline model implementations will serve as valuable resources for advancing\ncomputational linguistics research in underrepresented languages like Tagalog.','Angelina A. Aquino, Lester James V. Miranda, Elsie Marie T. Or','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20428v1','该论文介绍了目前规模最大的菲律宾语树库UD-NewsCrawl，包含15.6k棵树，根据Universal Dependencies框架手动注释。研究详细介绍了树库的开发过程，包括数据收集、预处理、手动标注和质量保证程序。作者使用多个基于Transformer的模型进行基准评估，评估了最先进的依存分析器在菲律宾语上的性能。同时，作者还强调了菲律宾语在句法分析中的挑战和其对树库标注的影响。'),('2505.20429v2','PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy','This paper introduces PreP-OCR, a two-stage pipeline that combines document\nimage restoration with semantic-aware post-OCR correction to enhance both\nvisual clarity and textual consistency, thereby improving text extraction from\ndegraded historical documents. First, we synthesize document-image pairs from\nplaintext, rendering them with diverse fonts and layouts and then applying a\nrandomly ordered set of degradation operations. An image restoration model is\ntrained on this synthetic data, using multi-directional patch extraction and\nfusion to process large images. Second, a ByT5 post-OCR model, fine-tuned on\nsynthetic historical text pairs, addresses remaining OCR errors. Detailed\nexperiments on 13,831 pages of real historical documents in English, French,\nand Spanish show that the PreP-OCR pipeline reduces character error rates by\n63.9-70.3% compared to OCR on raw images. Our pipeline demonstrates the\npotential of integrating image restoration with linguistic error correction for\ndigitizing historical archives.','Shuhao Guan, Moule Lin, Cheng Xu, Xinyi Liu, Jinman Zhao, Jiexin Fan, Qi Xu, Derek Greene','2025-05-26','cs.CL','文档图像处理/OCR','http://arxiv.org/pdf/2505.20429v2','该论文介绍了一种名为PreP-OCR的两阶段流程，将文档图像恢复与语义感知后OCR校正相结合，以增强视觉清晰度和文本一致性，从而改善从陈旧历史文档中提取文本的效果。通过合成文档图像对，并训练图像恢复模型和后OCR模型，实验证明PreP-OCR流程可以显著降低字符错误率。'),('2505.20433v1','Kernel Quantile Embeddings and Associated Probability Metrics','Embedding probability distributions into reproducing kernel Hilbert spaces\n(RKHS) has enabled powerful nonparametric methods such as the maximum mean\ndiscrepancy (MMD), a statistical distance with strong theoretical and\ncomputational properties. At its core, the MMD relies on kernel mean embeddings\nto represent distributions as mean functions in RKHS. However, it remains\nunclear if the mean function is the only meaningful RKHS representation.\nInspired by generalised quantiles, we introduce the notion of kernel quantile\nembeddings (KQEs). We then use KQEs to construct a family of distances that:\n(i) are probability metrics under weaker kernel conditions than MMD; (ii)\nrecover a kernelised form of the sliced Wasserstein distance; and (iii) can be\nefficiently estimated with near-linear cost. Through hypothesis testing, we\nshow that these distances offer a competitive alternative to MMD and its fast\napproximations.','Masha Naslidnyk, Siu Lun Chau, François-Xavier Briol, Krikamol Muandet','2025-05-26','stat.ML','核方法 (Kernel Methods)','http://arxiv.org/pdf/2505.20433v1','该论文介绍了将概率分布嵌入再生核希尔伯特空间(RKHS)的方法，引入了核分位数嵌入(KQE)的概念，并构建了一族距离，这些距离在比MMD更弱的核条件下是概率度量，恢复了切片Wasserstein距离的核化形式，并且可以以近线性成本有效估计。'),('2505.20435v1','Holes in Latent Space: Topological Signatures Under Adversarial Influence','Understanding how adversarial conditions affect language models requires\ntechniques that capture both global structure and local detail within\nhigh-dimensional activation spaces. We propose persistent homology (PH), a tool\nfrom topological data analysis, to systematically characterize multiscale\nlatent space dynamics in LLMs under two distinct attack modes -- backdoor\nfine-tuning and indirect prompt injection. By analyzing six state-of-the-art\nLLMs, we show that adversarial conditions consistently compress latent\ntopologies, reducing structural diversity at smaller scales while amplifying\ndominant features at coarser ones. These topological signatures are\nstatistically robust across layers, architectures, model sizes, and align with\nthe emergence of adversarial effects deeper in the network. To capture\nfiner-grained mechanisms underlying these shifts, we introduce a neuron-level\nPH framework that quantifies how information flows and transforms within and\nacross layers. Together, our findings demonstrate that PH offers a principled\nand unifying approach to interpreting representational dynamics in LLMs,\nparticularly under distributional shift.','Aideen Fay, Inés García-Redondo, Qiquan Wang, Haim Dubossarsky, Anthea Monod','2025-05-26','cs.LG','LLM（大规模语言模型）','http://arxiv.org/pdf/2505.20435v1','该论文使用持久同调（PH）工具从拓扑数据分析的角度系统地表征了在两种不同攻击模式下的大规模语言模型（LLMs）的多尺度潜在空间动态。研究表明，对抗条件一致地压缩了潜在拓扑结构，减少了较小尺度上的结构多样性，同时在较粗糙的尺度上放大了主导特征。通过引入神经元级的PH框架，可以更好地量化信息在层内和层间的流动和转换。'),('2505.20438v1','HAMburger: Accelerating LLM Inference via Token Smashing','The growing demand for efficient Large Language Model (LLM) inference\nrequires a holistic optimization on algorithms, systems, and hardware. However,\nvery few works have fundamentally changed the generation pattern: each token\nneeds one forward pass and one KV cache. This can be sub-optimal because we\nfound that LLMs are extremely capable of self-identifying the exact dose of\ninformation that a single KV cache can store, and many tokens can be generated\nconfidently without global context. Based on this insight, we introduce\nHAMburger, a Hierarchically Auto-regressive Model that redefines resource\nallocation in LLMs by moving beyond uniform computation and storage per token\nduring inference. Stacking a compositional embedder and a micro-step decoder in\nbetween a base LLM, HAMburger smashes multiple tokens into a single KV and\ngenerates several tokens per step. Additionally, HAMburger functions as a\nspeculative decoding framework where it can blindly trust self-drafted tokens.\nAs a result, HAMburger shifts the growth of KV cache and forward FLOPs from\nlinear to sub-linear with respect to output length, and adjusts its inference\nspeed based on query perplexity and output structure. Extensive evaluations\nshow that HAMburger reduces the KV cache computation by up to 2$\\times$ and\nachieves up to 2$\\times$ TPS, while maintaining quality in both short- and\nlong-context tasks. Our method explores an extremely challenging inference\nregime that requires both computation- and memory-efficiency with a\nhardware-agnostic design.','Jingyu Liu, Ce Zhang','2025-05-26','cs.CL','LLM (Large Language Model)','http://arxiv.org/pdf/2505.20438v1','该论文提出了一种名为HAMburger的分层自回归模型，通过重新定义LLM中的资源分配，将多个token压缩为单个KV，并实现每步生成多个token，从而减少KV缓存计算和提高推理速度。'),('2505.20444v1','HoPE: Hybrid of Position Embedding for Length Generalization in Vision-Language Models','Vision-Language Models (VLMs) have made significant progress in multimodal\ntasks. However, their performance often deteriorates in long-context scenarios,\nparticularly long videos. While Rotary Position Embedding (RoPE) has been\nwidely adopted for length generalization in Large Language Models (LLMs),\nextending vanilla RoPE to capture the intricate spatial-temporal dependencies\nin videos remains an unsolved challenge. Existing methods typically allocate\ndifferent frequencies within RoPE to encode 3D positional information. However,\nthese allocation strategies mainly rely on heuristics, lacking in-depth\ntheoretical analysis. In this paper, we first study how different allocation\nstrategies impact the long-context capabilities of VLMs. Our analysis reveals\nthat current multimodal RoPEs fail to reliably capture semantic similarities\nover extended contexts. To address this issue, we propose HoPE, a Hybrid of\nPosition Embedding designed to improve the long-context capabilities of VLMs.\nHoPE introduces a hybrid frequency allocation strategy for reliable semantic\nmodeling over arbitrarily long context, and a dynamic temporal scaling\nmechanism to facilitate robust learning and flexible inference across diverse\ncontext lengths. Extensive experiments across four video benchmarks on long\nvideo understanding and retrieval tasks demonstrate that HoPE consistently\noutperforms existing methods, confirming its effectiveness. Code is available\nat https://github.com/hrlics/HoPE.','Haoran Li, Yingjie Qin, Baoyuan Ou, Lai Xu, Ruiwen Xu','2025-05-26','cs.LG','视觉-语言模型','http://arxiv.org/pdf/2505.20444v1','本文研究了视觉-语言模型在长视频场景下性能下降的问题，提出了一种名为HoPE的混合位置嵌入方法，旨在改善VLMs的长上下文能力。通过实验证明，HoPE在长视频理解和检索任务中表现优异。'),('2505.20445v2','In-context Language Learning for Endangered Languages in Speech Recognition','With approximately 7,000 languages spoken worldwide, current large language\nmodels (LLMs) support only a small subset. Prior research indicates LLMs can\nlearn new languages for certain tasks without supervised data. We extend this\ninvestigation to speech recognition, investigating whether LLMs can learn\nunseen, low-resource languages through in-context learning (ICL). With\nexperiments on four diverse endangered languages that LLMs have not been\ntrained on, we find that providing more relevant text samples enhances\nperformance in both language modelling and Automatic Speech Recognition (ASR)\ntasks. Furthermore, we show that the probability-based approach outperforms the\ntraditional instruction-based approach in language learning. Lastly, we show\nICL enables LLMs to achieve ASR performance that is comparable to or even\nsurpasses dedicated language models trained specifically for these languages,\nwhile preserving the original capabilities of the LLMs.','Zhaolin Li, Jan Niehues','2025-05-26','cs.CL','LLM、语音处理','http://arxiv.org/pdf/2505.20445v2','该论文研究了如何通过上下文学习（ICL）让大型语言模型（LLMs）学习未知的、低资源的语言，并在四种少数语言上进行了实验。研究结果表明，提供更相关的文本样本可以提高语言建模和自动语音识别（ASR）任务的性能，概率化方法在语言学习中表现优于传统的指导式方法。'),('2505.20446v1','Time Series Generation Under Data Scarcity: A Unified Generative Modeling Approach','Generative modeling of time series is a central challenge in time series\nanalysis, particularly under data-scarce conditions. Despite recent advances in\ngenerative modeling, a comprehensive understanding of how state-of-the-art\ngenerative models perform under limited supervision remains lacking. In this\nwork, we conduct the first large-scale study evaluating leading generative\nmodels in data-scarce settings, revealing a substantial performance gap between\nfull-data and data-scarce regimes. To close this gap, we propose a unified\ndiffusion-based generative framework that can synthesize high-fidelity time\nseries across diverse domains using just a few examples. Our model is\npre-trained on a large, heterogeneous collection of time series datasets,\nenabling it to learn generalizable temporal representations. It further\nincorporates architectural innovations such as dynamic convolutional layers for\nflexible channel adaptation and dataset token conditioning for domain-aware\ngeneration. Without requiring abundant supervision, our unified model achieves\nstate-of-the-art performance in few-shot settings-outperforming domain-specific\nbaselines across a wide range of subset sizes. Remarkably, it also surpasses\nall baselines even when tested on full datasets benchmarks, highlighting the\nstrength of pre-training and cross-domain generalization. We hope this work\nencourages the community to revisit few-shot generative modeling as a key\nproblem in time series research and pursue unified solutions that scale\nefficiently across domains. Code is available at\nhttps://github.com/azencot-group/ImagenFew.','Tal Gonen, Itai Pemper, Ilan Naiman, Nimrod Berman, Omri Azencot','2025-05-26','cs.LG','生成模型','http://arxiv.org/pdf/2505.20446v1','该论文研究了在数据稀缺条件下时间序列的生成建模问题，通过评估领先的生成模型在数据稀缺情况下的表现，并提出了基于扩散的统一生成框架，可以使用少量示例合成高保真度的时间序列。'),('2505.20451v1','Amulet: Putting Complex Multi-Turn Conversations on the Stand with LLM Juries','Today, large language models are widely used as judges to evaluate responses\nfrom other language models. Hence, it is imperative to benchmark and improve\nthese LLM-judges on real-world language model usage: a typical human-assistant\nconversation is lengthy, and shows significant diversity in topics, intents,\nand requirements across turns, e.g. social interactions, task requests,\nfeedback. We present Amulet, a framework that leverages pertinent linguistic\nconcepts of dialog-acts and maxims to improve the accuracy of LLM-judges on\npreference data with complex, multi-turn conversational context. Amulet\npresents valuable insights about (a) the communicative structures and intents\npresent in the conversation (dialog acts), and (b) the satisfaction of\nconversational principles (maxims) by the preference responses, and uses them\nto make judgments. On four challenging datasets, Amulet shows that (a) humans\nfrequently (60 to 70 percent of the time) change their intents from one turn of\nthe conversation to the next, and (b) in 75 percent of instances, the\npreference responses can be differentiated via dialog acts and/or maxims,\nreiterating the latter\\\'s significance in judging such data. Amulet can be used\neither as a judge by applying the framework to a single LLM, or integrated into\na jury with different LLM judges; our judges and juries show strong\nimprovements on relevant baselines for all four datasets.','Sahana Ramnath, Anurag Mudgil, Brihi Joshi, Skyler Hallinan, Xiang Ren','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20451v1','该论文提出了一个名为Amulet的框架，利用对话行为和准则来改善大型语言模型在复杂、多轮对话背景下的偏好数据的准确性。通过四个具有挑战性的数据集，Amulet展示了人类在对话中经常改变意图，并且在75%的情况下，偏好响应可以通过对话行为和/或准则进行区分，强调了它们在判断此类数据中的重要性。该框架可以作为一个单一LLM的评判者，也可以与不同的LLM评判者集成为一个评判团体，对所有四个数据集的相关基线都表现出了显著的改进。'),('2505.20452v1','Active Learning for Multiple Change Point Detection in Non-stationary Time Series with Deep Gaussian Processes','Multiple change point (MCP) detection in non-stationary time series is\nchallenging due to the variety of underlying patterns. To address these\nchallenges, we propose a novel algorithm that integrates Active Learning (AL)\nwith Deep Gaussian Processes (DGPs) for robust MCP detection. Our method\nleverages spectral analysis to identify potential changes and employs AL to\nstrategically select new sampling points for improved efficiency. By\nincorporating the modeling flexibility of DGPs with the change-identification\ncapabilities of spectral methods, our approach adapts to diverse spectral\nchange behaviors and effectively localizes multiple change points. Experiments\non both simulated and real-world data demonstrate that our method outperforms\nexisting techniques in terms of detection accuracy and sampling efficiency for\nnon-stationary time series.','Hao Zhao, Rong Pan','2025-05-26','cs.LG','时间序列分析','http://arxiv.org/pdf/2505.20452v1','该论文提出了一种将主动学习与深度高斯过程相结合的算法，用于在非平稳时间序列中检测多个变点。通过结合谱分析和主动学习，该方法能够有效地定位多个变点，提高检测准确性和采样效率。'),('2505.20454v1','BlastOFormer: Attention and Neural Operator Deep Learning Methods for Explosive Blast Prediction','Accurate prediction of blast pressure fields is essential for applications in\nstructural safety, defense planning, and hazard mitigation. Traditional methods\nsuch as empirical models and computational fluid dynamics (CFD) simulations\noffer limited trade offs between speed and accuracy; empirical models fail to\ncapture complex interactions in cluttered environments, while CFD simulations\nare computationally expensive and time consuming. In this work, we introduce\nBlastOFormer, a novel Transformer based surrogate model for full field maximum\npressure prediction from arbitrary obstacle and charge configurations.\nBlastOFormer leverages a signed distance function (SDF) encoding and a grid to\ngrid attention based architecture inspired by OFormer and Vision Transformer\n(ViT) frameworks. Trained on a dataset generated using the open source\nblastFoam CFD solver, our model outperforms convolutional neural networks\n(CNNs) and Fourier Neural Operators (FNOs) across both log transformed and\nunscaled domains. Quantitatively, BlastOFormer achieves the highest R2 score\n(0.9516) and lowest error metrics, while requiring only 6.4 milliseconds for\ninference, more than 600,000 times faster than CFD simulations. Qualitative\nvisualizations and error analyses further confirm BlastOFormer\\\'s superior\nspatial coherence and generalization capabilities. These results highlight its\npotential as a real time alternative to conventional CFD approaches for blast\npressure estimation in complex environments.','Reid Graves, Anthony Zhou, Amir Barati Farimani','2025-05-26','cs.LG','计算流体动力学(CFD)、Transformer模型、预测模型','http://arxiv.org/pdf/2505.20454v1','本论文介绍了一种名为BlastOFormer的基于Transformer的替代模型，用于从任意障碍物和荷载配置中预测全场最大压力。该模型在速度和准确性之间取得了良好的平衡，优于传统的方法，并且在压力预测方面表现出色。'),('2505.20456v1','Federated Learning-Distillation Alternation for Resource-Constrained IoT','Federated learning (FL) faces significant challenges in Internet of Things\n(IoT) networks due to device limitations in energy and communication resources,\nespecially when considering the large size of FL models. From an energy\nperspective, the challenge is aggravated if devices rely on energy harvesting\n(EH), as energy availability can vary significantly over time, influencing the\naverage number of participating users in each iteration. Additionally, the\ntransmission of large model updates is more susceptible to interference from\nuncorrelated background traffic in shared wireless environments. As an\nalternative, federated distillation (FD) reduces communication overhead and\nenergy consumption by transmitting local model outputs, which are typically\nmuch smaller than the entire model used in FL. However, this comes at the cost\nof reduced model accuracy. Therefore, in this paper, we propose FL-distillation\nalternation (FLDA). In FLDA, devices alternate between FD and FL phases,\nbalancing model information with lower communication overhead and energy\nconsumption per iteration. We consider a multichannel slotted-ALOHA EH-IoT\nnetwork subject to background traffic/interference. In such a scenario, FLDA\ndemonstrates higher model accuracy than both FL and FD, and achieves faster\nconvergence than FL. Moreover, FLDA achieves target accuracies saving up to 98%\nin energy consumption, while also being less sensitive to interference, both\nrelative to FL.','Rafael Valente da Silva, Onel L. Alcaraz López, Richard Demo Souza','2025-05-26','eess.SP','强化学习','http://arxiv.org/pdf/2505.20456v1','本文提出了一种名为FL-distillation alternation (FLDA)的方法，通过在设备之间交替使用federated distillation (FD)和federated learning (FL)阶段，平衡模型信息与通信开销，以在能量受限的物联网网络中提高模型准确性和收敛速度。'),('2505.20465v1','Learning with Expected Signatures: Theory and Applications','The expected signature maps a collection of data streams to a lower\ndimensional representation, with a remarkable property: the resulting feature\ntensor can fully characterize the data generating distribution. This\n\"model-free\" embedding has been successfully leveraged to build multiple\ndomain-agnostic machine learning (ML) algorithms for time series and sequential\ndata. The convergence results proved in this paper bridge the gap between the\nexpected signature\\\'s empirical discrete-time estimator and its theoretical\ncontinuous-time value, allowing for a more complete probabilistic\ninterpretation of expected signature-based ML methods. Moreover, when the data\ngenerating process is a martingale, we suggest a simple modification of the\nexpected signature estimator with significantly lower mean squared error and\nempirically demonstrate how it can be effectively applied to improve predictive\nperformance.','Lorenzo Lucchese, Mikko S. Pakkanen, Almut E. D. Veraart','2025-05-26','stat.ML','时间序列数据处理','http://arxiv.org/pdf/2505.20465v1','该论文研究了预期签名的特征映射，将数据流映射到较低维度的表示，能够完全描述数据生成分布。通过证明预期签名的收敛性结果，填补了预期签名的离散时间估计器与理论连续时间值之间的差距，提供了更完整的概率解释。此外，当数据生成过程是鞅时，作者提出了一个简单修改的预期签名估计器，具有更低的均方误差，并在实证中展示了如何有效地应用于提高预测性能。'),('2505.20466v1','Reconceptualizing Smart Microscopy: From Data Collection to Knowledge Creation by Multi-Agent Integration','Smart microscopy represents a paradigm shift in biological imaging, moving\nfrom passive observation tools to active collaborators in scientific inquiry.\nEnabled by advances in automation, computational power, and artificial\nintelligence, these systems are now capable of adaptive decision-making and\nreal-time experimental control. Here, we introduce a theoretical framework that\nreconceptualizes smart microscopy as a partner in scientific investigation.\nCentral to our framework is the concept of the \\\'epistemic-empirical divide\\\' in\ncellular investigation-the gap between what is observable (empirical domain)\nand what must be understood (epistemic domain). We propose six core design\nprinciples: epistemic-empirical awareness, hierarchical context integration, an\nevolution from detection to perception, adaptive measurement frameworks,\nnarrative synthesis capabilities, and cross-contextual reasoning. Together,\nthese principles guide a multi-agent architecture designed to align empirical\nobservation with the goals of scientific understanding. Our framework provides\na roadmap for building microscopy systems that go beyond automation to actively\nsupport hypothesis generation, insight discovery, and theory development,\nredefining the role of scientific instruments in the process of knowledge\ncreation.','P. S. Kesavan, Pontus Nordenfelt','2025-05-26','cs.AI','智能显微镜','http://arxiv.org/pdf/2505.20466v1','该论文介绍了一个理论框架，将智能显微镜重新构想为科学探究的合作伙伴，提出了六个核心设计原则，并设计了一个多智能体架构，旨在将经验观察与科学理解的目标对齐，为建立超越自动化的显微镜系统提供了一个路线图，以积极支持假设生成、洞察发现和理论发展。'),('2505.20469v1','CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting','Recent advances in 3D reconstruction techniques and vision-language models\nhave fueled significant progress in 3D semantic understanding, a capability\ncritical to robotics, autonomous driving, and virtual/augmented reality.\nHowever, methods that rely on 2D priors are prone to a critical challenge:\ncross-view semantic inconsistencies induced by occlusion, image blur, and\nview-dependent variations. These inconsistencies, when propagated via\nprojection supervision, deteriorate the quality of 3D Gaussian semantic fields\nand introduce artifacts in the rendered outputs. To mitigate this limitation,\nwe propose CCL-LGS, a novel framework that enforces view-consistent semantic\nsupervision by integrating multi-view semantic cues. Specifically, our approach\nfirst employs a zero-shot tracker to align a set of SAM-generated 2D masks and\nreliably identify their corresponding categories. Next, we utilize CLIP to\nextract robust semantic encodings across views. Finally, our Contrastive\nCodebook Learning (CCL) module distills discriminative semantic features by\nenforcing intra-class compactness and inter-class distinctiveness. In contrast\nto previous methods that directly apply CLIP to imperfect masks, our framework\nexplicitly resolves semantic conflicts while preserving category\ndiscriminability. Extensive experiments demonstrate that CCL-LGS outperforms\nprevious state-of-the-art methods. Our project page is available at\nhttps://epsilontl.github.io/CCL-LGS/.','Lei Tian, Xiaomin Li, Liqian Ma, Hefei Huang, Zirui Zheng, Hao Yin, Taiqing Li, Huchuan Lu, Xu Jia','2025-05-26','cs.CV','三维重建、视觉语言模型、多视角语义理解','http://arxiv.org/pdf/2505.20469v1','本文提出了一种新颖的框架 CCL-LGS，通过整合多视角语义线索来强化视图一致的语义监督，以解决2D先验引起的跨视图语义不一致挑战。通过使用零样本跟踪器、CLIP提取语义编码以及对比码书学习模块，该框架能够提取具有鲁棒性的语义特征，优于先前的方法。'),('2505.20471v1','WeatherEdit: Controllable Weather Editing with 4D Gaussian Field','In this work, we present WeatherEdit, a novel weather editing pipeline for\ngenerating realistic weather effects with controllable types and severity in 3D\nscenes. Our approach is structured into two key components: weather background\nediting and weather particle construction. For weather background editing, we\nintroduce an all-in-one adapter that integrates multiple weather styles into a\nsingle pretrained diffusion model, enabling the generation of diverse weather\neffects in 2D image backgrounds. During inference, we design a Temporal-View\n(TV-) attention mechanism that follows a specific order to aggregate temporal\nand spatial information, ensuring consistent editing across multi-frame and\nmulti-view images. To construct the weather particles, we first reconstruct a\n3D scene using the edited images and then introduce a dynamic 4D Gaussian field\nto generate snowflakes, raindrops and fog in the scene. The attributes and\ndynamics of these particles are precisely controlled through physical-based\nmodelling and simulation, ensuring realistic weather representation and\nflexible severity adjustments. Finally, we integrate the 4D Gaussian field with\nthe 3D scene to render consistent and highly realistic weather effects.\nExperiments on multiple driving datasets demonstrate that WeatherEdit can\ngenerate diverse weather effects with controllable condition severity,\nhighlighting its potential for autonomous driving simulation in adverse\nweather. See project page: https://jumponthemoon.github.io/w-edit','Chenghao Qian, Wenjing Li, Yuhu Guo, Gustav Markkula','2025-05-26','cs.CV','图像识别','http://arxiv.org/pdf/2505.20471v1','该论文介绍了一种新颖的天气编辑管道WeatherEdit，用于在3D场景中生成具有可控类型和严重程度的逼真天气效果。通过天气背景编辑和天气粒子构建两个关键组件，实现了多样化的天气效果生成和精确控制。'),('2505.20473v1','Stochastic Preconditioning for Neural Field Optimization','Neural fields are a highly effective representation across visual computing.\nThis work observes that fitting these fields is greatly improved by\nincorporating spatial stochasticity during training, and that this simple\ntechnique can replace or even outperform custom-designed hierarchies and\nfrequency space constructions. The approach is formalized as implicitly\noperating on a blurred version of the field, evaluated in-expectation by\nsampling with Gaussian-distributed offsets. Querying the blurred field during\noptimization greatly improves convergence and robustness, akin to the role of\npreconditioners in numerical linear algebra. This implicit, sampling-based\nperspective fits naturally into the neural field paradigm, comes at no\nadditional cost, and is extremely simple to implement. We describe the basic\ntheory of this technique, including details such as handling boundary\nconditions, and extending to a spatially-varying blur. Experiments demonstrate\nthis approach on representations including coordinate MLPs, neural hashgrids,\ntriplanes, and more, across tasks including surface reconstruction and radiance\nfields. In settings where custom-designed hierarchies have already been\ndeveloped, stochastic preconditioning nearly matches or improves their\nperformance with a simple and unified approach; in settings without existing\nhierarchies it provides an immediate boost to quality and robustness.','Selena Ling, Merlin Nimier-David, Alec Jacobson, Nicholas Sharp','2025-05-26','cs.GR','图像识别','http://arxiv.org/pdf/2505.20473v1','本文研究了神经场在视觉计算中的高效表示方法。通过在训练过程中引入空间随机性，可以大大改善对这些场的拟合，这种简单的技术可以替代甚至胜过定制设计的层次结构和频率空间构造。作者提出的方法在模糊场上进行操作，并通过使用高斯分布的偏移进行采样来评估期望值。在优化过程中查询模糊场可以极大地改善收敛性和鲁棒性。'),('2505.20480v1','BrainStratify: Coarse-to-Fine Disentanglement of Intracranial Neural Dynamics','Decoding speech directly from neural activity is a central goal in\nbrain-computer interface (BCI) research. In recent years, exciting advances\nhave been made through the growing use of intracranial field potential\nrecordings, such as stereo-ElectroEncephaloGraphy (sEEG) and\nElectroCorticoGraphy (ECoG). These neural signals capture rich population-level\nactivity but present key challenges: (i) task-relevant neural signals are\nsparsely distributed across sEEG electrodes, and (ii) they are often entangled\nwith task-irrelevant neural signals in both sEEG and ECoG. To address these\nchallenges, we introduce a unified Coarse-to-Fine neural disentanglement\nframework, BrainStratify, which includes (i) identifying functional groups\nthrough spatial-context-guided temporal-spatial modeling, and (ii)\ndisentangling distinct neural dynamics within the target functional group using\nDecoupled Product Quantization (DPQ). We evaluate BrainStratify on two\nopen-source sEEG datasets and one (epidural) ECoG dataset, spanning tasks like\nvocal production and speech perception. Extensive experiments show that\nBrainStratify, as a unified framework for decoding speech from intracranial\nneural signals, significantly outperforms previous decoding methods. Overall,\nby combining data-driven stratification with neuroscience-inspired modularity,\nBrainStratify offers a robust and interpretable solution for speech decoding\nfrom intracranial recordings.','Hui Zheng, Hai-Teng Wang, Yi-Tao Jing, Pei-Yang Lin, Han-Qing Zhao, Wei Chen, Peng-Hu Wei, Yong-Zhi Shan, Guo-Guang Zhao, Yun-Zhe Liu','2025-05-26','eess.SP','脑机接口','http://arxiv.org/pdf/2505.20480v1','该论文介绍了一种统一的粗到细的神经解缠框架，名为BrainStratify，用于从颅内神经信号中解码语音。该方法通过空间上下文引导的时间-空间建模来识别功能组，并使用解耦产品量化（DPQ）来解开目标功能组内的不同神经动态。实验结果表明，BrainStratify在解码语音方面表现出色，显著优于以往的解码方法。'),('2505.20481v1','CardioPatternFormer: Pattern-Guided Attention for Interpretable ECG Classification with Transformer Architecture','Accurate ECG interpretation is vital, yet complex cardiac data and\n\"black-box\" AI models limit clinical utility. Inspired by Transformer\narchitectures\\\' success in NLP for understanding sequential data, we frame ECG\nas the heart\\\'s unique \"language\" of temporal patterns. We present\nCardioPatternFormer, a novel Transformer-based model for interpretable ECG\nclassification. It employs a sophisticated attention mechanism to precisely\nidentify and classify diverse cardiac patterns, excelling at discerning subtle\nanomalies and distinguishing multiple co-occurring conditions. This\npattern-guided attention provides clear insights by highlighting influential\nsignal regions, effectively allowing the \"heart to talk\" through transparent\ninterpretations. CardioPatternFormer demonstrates robust performance on\nchallenging ECGs, including complex multi-pathology cases. Its interpretability\nvia attention maps enables clinicians to understand the model\\\'s rationale,\nfostering trust and aiding informed diagnostic decisions. This work offers a\npowerful, transparent solution for advanced ECG analysis, paving the way for\nmore reliable and clinically actionable AI in cardiology.','Berat Kutay Uğraş, Ömer Nezih Gerek, İbrahim Talha Saygı','2025-05-26','eess.SP','自然语言处理','http://arxiv.org/pdf/2505.20481v1','该论文介绍了一种基于Transformer架构的模型——CardioPatternFormer，用于可解释的心电图分类。该模型通过复杂的注意力机制精确识别和分类不同的心脏模式，能够在识别微小异常和区分多种共同存在的病症方面表现出色。通过模式引导的注意力提供清晰的见解，有效地通过透明的解释让“心脏说话”。'),('2505.20482v1','Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Understanding','Understanding online conversations has attracted research attention with the\ngrowth of social networks and online discussion forums. Content analysis of\nposts and replies in online conversations is difficult because each individual\nutterance is usually short and may implicitly refer to other posts within the\nsame conversation. Thus, understanding individual posts requires capturing the\nconversational context and dependencies between different parts of a\nconversation tree and then encoding the context dependencies between posts and\ncomments/replies into the language model.\n  To this end, we propose a general-purpose mechanism to discover appropriate\nconversational context for various aspects about an online post in a\nconversation, such as whether it is informative, insightful, interesting or\nfunny. Specifically, we design two families of Conversation Kernels, which\nexplore different parts of the neighborhood of a post in the tree representing\nthe conversation and through this, build relevant conversational context that\nis appropriate for each task being considered. We apply our developed method to\nconversations crawled from slashdot.org, which allows users to apply highly\ndifferent labels to posts, such as \\\'insightful\\\', \\\'funny\\\', etc., and therefore\nprovides an ideal experimental platform to study whether a framework such as\nConversation Kernels is general-purpose and flexible enough to be adapted to\ndisparately different conversation understanding tasks.','Vibhor Agarwal, Arjoo Gupta, Suparna De, Nishanth Sastry','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20482v1','该论文提出了一种通用机制，用于发现在线对话中关于帖子的各种方面的适当对话背景，如是否信息丰富、有见地、有趣或滑稽。他们设计了两个Conversation Kernels家族，探索代表对话的树中帖子附近的不同部分，并通过这种方式构建相关的对话背景，适用于考虑的每个任务。'),('2505.20485v1','Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data','The inevitable presence of data heterogeneity has made federated learning\nvery challenging. There are numerous methods to deal with this issue, such as\nlocal regularization, better model fusion techniques, and data sharing. Though\neffective, they lack a deep understanding of how data heterogeneity can affect\nthe global decision boundary. In this paper, we bridge this gap by performing\nan experimental analysis of the learned decision boundary using a toy example.\nOur observations are surprising: (1) we find that the existing methods suffer\nfrom forgetting and clients forget the global decision boundary and only learn\nthe perfect local one, and (2) this happens regardless of the initial weights,\nand clients forget the global decision boundary even starting from pre-trained\noptimal weights. In this paper, we present FedProj, a federated learning\nframework that robustly learns the global decision boundary and avoids its\nforgetting during local training. To achieve better ensemble knowledge fusion,\nwe design a novel server-side ensemble knowledge transfer loss to further\ncalibrate the learned global decision boundary. To alleviate the issue of\nlearned global decision boundary forgetting, we further propose leveraging an\nepisodic memory of average ensemble logits on a public unlabeled dataset to\nregulate the gradient updates at each step of local training. Experimental\nresults demonstrate that FedProj outperforms state-of-the-art methods by a\nlarge margin.','Abhijit Chunduru, Majid Morafah, Mahdi Morafah, Vishnu Pandi Chellapandi, Ang Li','2025-05-26','cs.LG','联邦学习 (Federated Learning)','http://arxiv.org/pdf/2505.20485v1','本文研究了数据异质性对联邦学习的影响，提出了FedProj框架来解决全局决策边界遗忘的问题，并通过实验证明其优于现有方法。'),('2505.20487v1','InFact: Informativeness Alignment for Improved LLM Factuality','Factual completeness is a general term that captures how detailed and\ninformative a factually correct text is. For instance, the factual sentence\n``Barack Obama was born in the United States\\\'\\\' is factually correct, though\nless informative than the factual sentence ``Barack Obama was born in Honolulu,\nHawaii, United States\\\'\\\'. Despite the known fact that LLMs tend to hallucinate\nand generate factually incorrect text, they might also tend to choose to\ngenerate factual text that is indeed factually correct and yet less informative\nthan other, more informative choices. In this work, we tackle this problem by\nproposing an informativeness alignment mechanism. This mechanism takes\nadvantage of recent factual benchmarks to propose an informativeness alignment\nobjective. This objective prioritizes answers that are both correct and\ninformative. A key finding of our work is that when training a model to\nmaximize this objective or optimize its preference, we can improve not just\ninformativeness but also factuality.','Roi Cohen, Russa Biswas, Gerard de Melo','2025-05-26','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20487v1','该论文研究了事实完整性的概念，提出了一个信息对齐机制，旨在生成既正确又具信息量的文本。通过最大化这一目标或优化其偏好，不仅可以提高信息量，还可以提高事实性。'),('2505.20496v1','Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages','Conventional transformer models typically compress the information from all\ntokens in a sequence into a single \\texttt{[CLS]} token to represent global\ncontext-- an approach that can lead to information loss in tasks requiring\nlocalized or hierarchical cues. In this work, we introduce \\textit{Inceptive\nTransformer}, a modular and lightweight architecture that enriches\ntransformer-based token representations by integrating a multi-scale feature\nextraction module inspired by inception networks. Our model is designed to\nbalance local and global dependencies by dynamically weighting tokens based on\ntheir relevance to a particular task. Evaluation across a diverse range of\ntasks including emotion recognition (both English and Bangla), irony detection,\ndisease identification, and anti-COVID vaccine tweets classification shows that\nour models consistently outperform the baselines by 1\\% to 14\\% while\nmaintaining efficiency. These findings highlight the versatility and\ncross-lingual applicability of our method for enriching transformer-based\nrepresentations across diverse domains.','Asif Shahriar, Rifat Shahriyar, M Saifur Rahman','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20496v1','本文介绍了Inceptive Transformer，这是一个模块化且轻量级的架构，通过整合受Inception网络启发的多尺度特征提取模块，丰富了基于transformer的token表示。该模型设计旨在平衡局部和全局依赖，通过根据它们对特定任务的相关性动态加权token。在情感识别、讽刺检测、疾病识别和反COVID疫苗推文分类等各种任务上的评估表明，我们的模型在效率保持的同时，始终优于基线1%至14%。这些发现突显了我们的方法在丰富跨领域的基于transformer的表示方面的多功能性和跨语言适用性。'),('2505.20498v2','ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image','Vision-based tactile sensing has been widely used in perception,\nreconstruction, and robotic manipulation. However, collecting large-scale\ntactile data remains costly due to the localized nature of sensor-object\ninteractions and inconsistencies across sensor instances. Existing approaches\nto scaling tactile data, such as simulation and free-form tactile generation,\noften suffer from unrealistic output and poor transferability to downstream\ntasks. To address this, we propose ControlTac, a two-stage controllable\nframework that generates realistic tactile images conditioned on a single\nreference tactile image, contact force, and contact position. With those\nphysical priors as control input, ControlTac generates physically plausible and\nvaried tactile images that can be used for effective data augmentation. Through\nexperiments on three downstream tasks, we demonstrate that ControlTac can\neffectively augment tactile datasets and lead to consistent gains. Our three\nreal-world experiments further validate the practical utility of our approach.\nProject page: https://dongyuluo.github.io/controltac.','Dongyu Luo, Kelin Yu, Amir-Hossein Shahidzadeh, Cornelia Fermüller, Yiannis Aloimonos, Ruohan Gao','2025-05-26','cs.CV','视觉感知/机器人Manipulation','http://arxiv.org/pdf/2505.20498v2','该论文提出了一种名为ControlTac的两阶段可控框架，可以生成逼真的触觉图像，用于有效数据增强。通过实验证明，ControlTac可以有效增强触觉数据集，并取得一致的收益。'),('2505.20500v1','Beyond Keywords: Evaluating Large Language Model Classification of Nuanced Ableism','Large language models (LLMs) are increasingly used in decision-making tasks\nlike r\\\\\'esum\\\\\'e screening and content moderation, giving them the power to\namplify or suppress certain perspectives. While previous research has\nidentified disability-related biases in LLMs, little is known about how they\nconceptualize ableism or detect it in text. We evaluate the ability of four\nLLMs to identify nuanced ableism directed at autistic individuals. We examine\nthe gap between their understanding of relevant terminology and their\neffectiveness in recognizing ableist content in context. Our results reveal\nthat LLMs can identify autism-related language but often miss harmful or\noffensive connotations. Further, we conduct a qualitative comparison of human\nand LLM explanations. We find that LLMs tend to rely on surface-level keyword\nmatching, leading to context misinterpretations, in contrast to human\nannotators who consider context, speaker identity, and potential impact. On the\nother hand, both LLMs and humans agree on the annotation scheme, suggesting\nthat a binary classification is adequate for evaluating LLM performance, which\nis consistent with findings from prior studies involving human annotators.','Naba Rizvi, Harper Strickland, Saleha Ahmedi, Aekta Kallepalli, Isha Khirwadkar, William Wu, Imani N. S. Munyaka, Nedjma Ousidhoum','2025-05-26','cs.CL','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.20500v1','该论文研究了大型语言模型在识别针对自闭症个体的隐性歧视能力。通过评估四种LLM模型的表现，发现它们能够识别与自闭症相关的语言，但往往会错过有害或冒犯性的内涵。'),('2505.20503v1','Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review','Rapid advancements in foundation models, including Large Language Models,\nVision-Language Models, Multimodal Large Language Models, and\nVision-Language-Action Models have opened new avenues for embodied AI in mobile\nservice robotics. By combining foundation models with the principles of\nembodied AI, where intelligent systems perceive, reason, and act through\nphysical interactions, robots can improve understanding, adapt to, and execute\ncomplex tasks in dynamic real-world environments. However, embodied AI in\nmobile service robots continues to face key challenges, including multimodal\nsensor fusion, real-time decision-making under uncertainty, task\ngeneralization, and effective human-robot interactions (HRI). In this paper, we\npresent the first systematic review of the integration of foundation models in\nmobile service robotics, identifying key open challenges in embodied AI and\nexamining how foundation models can address them. Namely, we explore the role\nof such models in enabling real-time sensor fusion, language-conditioned\ncontrol, and adaptive task execution. Furthermore, we discuss real-world\napplications in the domestic assistance, healthcare, and service automation\nsectors, demonstrating the transformative impact of foundation models on\nservice robotics. We also include potential future research directions,\nemphasizing the need for predictive scaling laws, autonomous long-term\nadaptation, and cross-embodiment generalization to enable scalable, efficient,\nand robust deployment of foundation models in human-centric robotic systems.','Matthew Lisondra, Beno Benhabib, Goldie Nejat','2025-05-26','cs.RO','强化学习','http://arxiv.org/pdf/2505.20503v1','本文系统回顾了基于基础模型在移动服务机器人中的整合，并指出了在体现AI中的关键挑战，包括多模态传感器融合、不确定性下的实时决策、任务泛化和有效的人机交互。作者探讨了这些模型在实现实时传感器融合、语言条件控制和自适应任务执行方面的作用，并展示了在家庭援助、医疗保健和服务自动化领域的真实应用。此外，还提出了未来的研究方向，强调了预测性缩放定律、自主长期适应和跨体现泛化的需求，以实现基础模型在以人为中心的机器人系统中的可扩展、高效和稳健部署。'),('2505.20505v1','Large Language Models for IT Automation Tasks: Are We There Yet?','LLMs show promise in code generation, yet their effectiveness for IT\nautomation tasks, particularly for tools like Ansible, remains understudied.\nExisting benchmarks rely primarily on synthetic tasks that fail to capture the\nneeds of practitioners who use IT automation tools, such as Ansible. We present\nITAB (IT Automation Task Benchmark), a benchmark of 126 diverse tasks (e.g.,\nconfiguring servers, managing files) where each task accounts for state\nreconciliation: a property unique to IT automation tools. ITAB evaluates LLMs\\\'\nability to generate functional Ansible automation scripts via dynamic execution\nin controlled environments. We evaluate 14 open-source LLMs, none of which\naccomplish pass@10 at a rate beyond 12%. To explain these low scores, we\nanalyze 1,411 execution failures across the evaluated LLMs and identify two\nmain categories of prevalent semantic errors: failures in state reconciliation\nrelated reasoning (44.87% combined from variable (11.43%), host (11.84%),\npath(11.63%), and template (9.97%) issues) and deficiencies in module-specific\nexecution knowledge (24.37% combined from Attribute and parameter (14.44%) and\nmodule (9.93%) errors). Our findings reveal key limitations in open-source\nLLMs\\\' ability to track state changes and apply specialized module knowledge,\nindicating that reliable IT automation will require major advances in state\nreasoning and domain-specific execution understanding.','Md Mahadi Hassan, John Salvador, Akond Rahman, Santu Karmaker','2025-05-26','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.20505v1','该论文研究了语言模型在IT自动化任务中的效果，提出了一个包含126个不同任务的基准测试ITAB，并评估了14个开源语言模型在生成功能性Ansible自动化脚本方面的表现。研究发现这些语言模型在状态推理和领域特定执行理解方面存在重要限制。'),('2505.20506v1','ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis','We introduce ArVoice, a multi-speaker Modern Standard Arabic (MSA) speech\ncorpus with diacritized transcriptions, intended for multi-speaker speech\nsynthesis, and can be useful for other tasks such as speech-based diacritic\nrestoration, voice conversion, and deepfake detection. ArVoice comprises: (1) a\nnew professionally recorded set from six voice talents with diverse\ndemographics, (2) a modified subset of the Arabic Speech Corpus; and (3)\nhigh-quality synthetic speech from two commercial systems. The complete corpus\nconsists of a total of 83.52 hours of speech across 11 voices; around 10 hours\nconsist of human voices from 7 speakers. We train three open-source TTS and two\nvoice conversion systems to illustrate the use cases of the dataset. The corpus\nis available for research use.','Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki','2025-05-26','cs.CL','语音处理','http://arxiv.org/pdf/2505.20506v1','该论文介绍了 ArVoice，这是一个包含多位说话者的现代标准阿拉伯语语音语料库，具有带变音符号的转录，旨在用于多说话者语音合成，以及其他任务如基于语音的变音符号恢复、声音转换和深度伪造检测。该语料库包括来自六位声音人才的新专业录制集合，修改的阿拉伯语语音语料库的子集，以及两个商业系统生成的高质量合成语音。总共包含了11位说话者的83.52小时的语音，其中大约有10小时是来自7位说话者的人类声音。研究者使用了三个开源文本到语音合成系统和两个声音转换系统来展示数据集的用途。该语料库可供研究使用。'),('2505.20507v1','Electrolyzers-HSI: Close-Range Multi-Scene Hyperspectral Imaging Benchmark Dataset','The global challenge of sustainable recycling demands automated, fast, and\naccurate, state-of-the-art (SOTA) material detection systems that act as a\nbedrock for a circular economy. Democratizing access to these cutting-edge\nsolutions that enable real-time waste analysis is essential for scaling up\nrecycling efforts and fostering the Green Deal. In response, we introduce\n\\textbf{Electrolyzers-HSI}, a novel multimodal benchmark dataset designed to\naccelerate the recovery of critical raw materials through accurate electrolyzer\nmaterials classification. The dataset comprises 55 co-registered\nhigh-resolution RGB images and hyperspectral imaging (HSI) data cubes spanning\nthe 400--2500 nm spectral range, yielding over 4.2 million pixel vectors and\n424,169 labeled ones. This enables non-invasive spectral analysis of shredded\nelectrolyzer samples, supporting quantitative and qualitative material\nclassification and spectral properties investigation. We evaluate a suite of\nbaseline machine learning (ML) methods alongside SOTA transformer-based deep\nlearning (DL) architectures, including Vision Transformer, SpectralFormer, and\nthe Multimodal Fusion Transformer, to investigate architectural bottlenecks for\nfurther efficiency optimisation when deploying transformers in material\nidentification. We implement zero-shot detection techniques and majority voting\nacross pixel-level predictions to establish object-level classification\nrobustness. In adherence to the FAIR data principles, the electrolyzers-HSI\ndataset and accompanying codebase are openly available at\nhttps://github.com/hifexplo/Electrolyzers-HSI and\nhttps://rodare.hzdr.de/record/3668, supporting reproducible research and\nfacilitating the broader adoption of smart and sustainable e-waste recycling\nsolutions.','Elias Arbash, Ahmed Jamal Afifi, Ymane Belahsen, Margret Fuchs, Pedram Ghamisi, Paul Scheunders, Richard Gloaguen','2025-05-26','cs.CV','图像识别','http://arxiv.org/pdf/2505.20507v1','该论文介绍了一个新的多模态基准数据集Electrolyzers-HSI，旨在通过准确的电解槽材料分类加速重要原材料的回收。研究使用了一系列基线机器学习方法和最先进的基于Transformer的深度学习架构，以探讨在材料识别中使用Transformer时的架构瓶颈，并实现了零样本检测技术和多数投票方法来建立对象级别的分类鲁棒性。'),('2505.20511v1','Multimodal Emotion Recognition in Conversations: A Survey of Methods, Trends, Challenges and Prospects','While text-based emotion recognition methods have achieved notable success,\nreal-world dialogue systems often demand a more nuanced emotional understanding\nthan any single modality can offer. Multimodal Emotion Recognition in\nConversations (MERC) has thus emerged as a crucial direction for enhancing the\nnaturalness and emotional understanding of human-computer interaction. Its goal\nis to accurately recognize emotions by integrating information from various\nmodalities such as text, speech, and visual signals.\n  This survey offers a systematic overview of MERC, including its motivations,\ncore tasks, representative methods, and evaluation strategies. We further\nexamine recent trends, highlight key challenges, and outline future directions.\nAs interest in emotionally intelligent systems grows, this survey provides\ntimely guidance for advancing MERC research.','Chengyan Wu, Yiqiang Cai, Yang Liu, Pengxu Zhu, Yun Xue, Ziwei Gong, Julia Hirschberg, Bolei Ma','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20511v1','该论文综述了多模态情感识别在对话系统中的重要性和发展趋势，旨在通过整合文本、语音和视觉信号等多种信息来准确识别情感。'),('2505.20515v1','Semi-Explicit Neural DAEs: Learning Long-Horizon Dynamical Systems with Algebraic Constraints','Despite the promise of scientific machine learning (SciML) in combining\ndata-driven techniques with mechanistic modeling, existing approaches for\nincorporating hard constraints in neural differential equations (NDEs) face\nsignificant limitations. Scalability issues and poor numerical properties\nprevent these neural models from being used for modeling physical systems with\ncomplicated conservation laws. We propose Manifold-Projected Neural ODEs\n(PNODEs), a method that explicitly enforces algebraic constraints by projecting\neach ODE step onto the constraint manifold. This framework arises naturally\nfrom semi-explicit differential-algebraic equations (DAEs), and includes both a\nrobust iterative variant and a fast approximation requiring a single Jacobian\nfactorization. We further demonstrate that prior works on relaxation methods\nare special cases of our approach. PNODEs consistently outperform baselines\nacross six benchmark problems achieving a mean constraint violation error below\n$10^{-10}$. Additionally, PNODEs consistently achieve lower runtime compared to\nother methods for a given level of error tolerance. These results show that\nconstraint projection offers a simple strategy for learning physically\nconsistent long-horizon dynamics.','Avik Pal, Alan Edelman, Christopher Rackauckas','2025-05-26','cs.LG','科学机器学习 (SciML)','http://arxiv.org/pdf/2505.20515v1','该论文提出了一种名为 Manifold-Projected Neural ODEs (PNODEs) 的方法，通过将每个ODE步骤投影到约束流形上，显式地强制执行代数约束，解决了在神经微分方程（NDEs）中引入硬约束的问题。该方法在六个基准问题上 consistently outperform baselines，实现了平均约束违反误差低于$10^{-10}$的结果，并在给定误差容忍度的情况下始终实现更低的运行时间。'),('2505.20521v1','Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting','This paper presents Project Riley, a novel multimodal and multi-model\nconversational AI architecture oriented towards the simulation of reasoning\ninfluenced by emotional states. Drawing inspiration from Pixar\\\'s Inside Out,\nthe system comprises five distinct emotional agents - Joy, Sadness, Fear,\nAnger, and Disgust - that engage in structured multi-round dialogues to\ngenerate, criticise, and iteratively refine responses. A final reasoning\nmechanism synthesises the contributions of these agents into a coherent output\nthat either reflects the dominant emotion or integrates multiple perspectives.\nThe architecture incorporates both textual and visual large language models\n(LLMs), alongside advanced reasoning and self-refinement processes. A\nfunctional prototype was deployed locally in an offline environment, optimised\nfor emotional expressiveness and computational efficiency. From this initial\nprototype, another one emerged, called Armando, which was developed for use in\nemergency contexts, delivering emotionally calibrated and factually accurate\ninformation through the integration of Retrieval-Augmented Generation (RAG) and\ncumulative context tracking. The Project Riley prototype was evaluated through\nuser testing, in which participants interacted with the chatbot and completed a\nstructured questionnaire assessing three dimensions: Emotional Appropriateness,\nClarity and Utility, and Naturalness and Human-likeness. The results indicate\nstrong performance in structured scenarios, particularly with respect to\nemotional alignment and communicative clarity.','Ana Rita Ortigoso, Gabriel Vieira, Daniel Fuentes, Luis Frazão, Nuno Costa, António Pereira','2025-05-26','cs.AI','自然语言处理','http://arxiv.org/pdf/2505.20521v1','该论文介绍了Project Riley，这是一个新颖的多模态和多模型对话AI架构，旨在模拟受情绪状态影响的推理过程。系统由五个不同的情绪代理 - 快乐、悲伤、恐惧、愤怒和厌恶 - 组成，它们参与结构化的多轮对话，生成、批评和迭代地完善回应。最终的推理机制将这些代理的贡献综合成一个连贯的输出，反映主导情绪或整合多个视角。'),('2505.20522v1','Scaling over Scaling: Exploring Test-Time Scaling Pareto in Large Reasoning Models','Large reasoning models (LRMs) have exhibited the capacity of enhancing\nreasoning performance via internal test-time scaling. Building upon this, a\npromising direction is to further scale test-time compute to unlock even\ngreater reasoning capabilities. However, as we push these scaling boundaries,\nsystematically understanding the practical limits and achieving optimal\nresource allocation becomes a critical challenge. In this paper, we investigate\nthe scaling Pareto of test-time scaling and introduce the Test-Time Scaling\nPerformance Model (TTSPM). We theoretically analyze two fundamental paradigms\nfor such extended scaling, parallel scaling and sequential scaling, from a\nprobabilistic modeling perspective. Our primary contribution is the derivation\nof the saturation point on the scaling budget for both strategies, identifying\nthresholds beyond which additional computation yields diminishing returns.\nRemarkably, despite their distinct mechanisms, both paradigms converge to a\nunified mathematical structure in their upper bounds. We empirically validate\nour theoretical findings on challenging reasoning benchmarks, including AIME,\nMATH-500, and GPQA, demonstrating the practical utility of these bounds for\ntest-time resource allocation. We hope that this work provides insights into\nthe cost-benefit trade-offs of test-time scaling, guiding the development of\nmore resource-efficient inference strategies for large reasoning models.','Jian Wang, Boyan Zhu, Chak Tou Leong, Yongqi Li, Wenjie Li','2025-05-26','cs.AI','大规模推理模型（LRMs）','http://arxiv.org/pdf/2505.20522v1','本文研究了如何通过内部测试时间缩放来提高推理性能，并探讨了进一步扩展测试时间计算以解锁更大推理能力的方向。通过理论分析两种扩展缩放策略的饱和点，识别了额外计算超过阈值后产生递减收益的情况。'),('2505.20524v1','Towards Fully FP8 GEMM LLM Training at Scale','Despite the significant potential of FP8 data formats for large language\nmodel (LLM) pre-training, their adoption has been limited due to challenges in\nmaintaining stability at scale. Existing approaches often rely on suboptimal\nfine-grained FP8 kernels or fall back to higher-precision matrix\nmultiplications (GEMMs) in sensitive components, such as attention projections,\ncompromising potential throughput gains. We introduce a new class of LLM\narchitectures that, for the first time, support FP8 computation for all GEMMs\nwithin transformer blocks during both forward and backward passes. This enables\nunprecedented throughput gains, particularly at scale, while matching the\ndownstream performance of standard BF16 training. Our architecture design\nreduces large outlier activations, promoting stable long-term FP8 training. In\naddition, we identify key metrics to monitor low-precision training and predict\npotential future divergences.','Alejandro Hernández-Cano, Dhia Garbaya, Imanol Schlag, Martin Jaggi','2025-05-26','cs.LG','LLM (大语言模型)','http://arxiv.org/pdf/2505.20524v1','该论文介绍了一种新型的大语言模型（LLM）架构，支持在transformer块中所有GEMMs的FP8计算，从而实现了前向和后向传播的FP8计算，提高了吞吐量，同时保持与标准BF16训练相匹配的下游性能。'),('2505.20529v1','Training Articulatory Inversion Models for Inter-Speaker Consistency','Acoustic-to-Articulatory Inversion (AAI) attempts to model the inverse\nmapping from speech to articulation. Exact articulatory prediction from speech\nalone may be impossible, as speakers can choose different forms of articulation\nseemingly without reference to their vocal tract structure. However, once a\nspeaker has selected an articulatory form, their productions vary minimally.\nRecent works in AAI have proposed adapting Self-Supervised Learning (SSL)\nmodels to single-speaker datasets, claiming that these single-speaker models\nprovide a universal articulatory template. In this paper, we investigate\nwhether SSL-adapted models trained on single and multi-speaker data produce\narticulatory targets which are consistent across speaker identities for English\nand Russian. We do this through the use of a novel evaluation method which\nextracts articulatory targets using minimal pair sets. We also present a\ntraining method which can improve inter-speaker consistency using only speech\ndata.','Charles McGhee, Mark J. F. Gales, Kate M. Knill','2025-05-26','cs.SD','语音处理','http://arxiv.org/pdf/2505.20529v1','该论文研究了声学到发音的反演问题，提出了通过自监督学习模型对单个和多个说话者数据进行训练，以产生跨说话者一致的发音目标。'),('2505.20535v1','Rotary Masked Autoencoders are Versatile Learners','Applying Transformers to irregular time-series typically requires\nspecializations to their baseline architecture, which can result in additional\ncomputational overhead and increased method complexity. We present the Rotary\nMasked Autoencoder (RoMAE), which utilizes the popular Rotary Positional\nEmbedding (RoPE) method for continuous positions. RoMAE is an extension to the\nMasked Autoencoder (MAE) that enables representation learning with\nmultidimensional continuous positional information while avoiding any\ntime-series-specific architectural specializations. We showcase RoMAE\\\'s\nperformance on a variety of modalities including irregular and multivariate\ntime-series, images, and audio, demonstrating that RoMAE surpasses specialized\ntime-series architectures on difficult datasets such as the DESC ELAsTiCC\nChallenge while maintaining MAE\\\'s usual performance across other modalities. In\naddition, we investigate RoMAE\\\'s ability to reconstruct the embedded continuous\npositions, demonstrating that including learned embeddings in the input\nsequence breaks RoPE\\\'s relative position property.','Uros Zivanovic, Serafina Di Gioia, Andre Scaffidi, Martín de los Rios, Gabriella Contardo, Roberto Trotta','2025-05-26','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20535v1','该论文介绍了Rotary Masked Autoencoder (RoMAE) 方法，利用Rotary Positional Embedding (RoPE) 方法处理不规则时间序列数据，实现了在多维连续位置信息下的表示学习，同时避免了特定于时间序列的架构专门化。研究结果表明，RoMAE在处理不规则和多变量时间序列、图像和音频等各种模态数据时表现优异。'),('2505.20536v1','Covariate-Adjusted Deep Causal Learning for Heterogeneous Panel Data Models','This paper studies the task of estimating heterogeneous treatment effects in\ncausal panel data models, in the presence of covariate effects. We propose a\nnovel Covariate-Adjusted Deep Causal Learning (CoDEAL) for panel data models,\nthat employs flexible model structures and powerful neural network\narchitectures to cohesively deal with the underlying heterogeneity and\nnonlinearity of both panel units and covariate effects. The proposed CoDEAL\nintegrates nonlinear covariate effect components (parameterized by a\nfeed-forward neural network) with nonlinear factor structures (modeled by a\nmulti-output autoencoder) to form a heterogeneous causal panel model. The\nnonlinear covariate component offers a flexible framework for capturing the\ncomplex influences of covariates on outcomes. The nonlinear factor analysis\nenables CoDEAL to effectively capture both cross-sectional and temporal\ndependencies inherent in the data panel. This latent structural information is\nsubsequently integrated into a customized matrix completion algorithm, thereby\nfacilitating more accurate imputation of missing counterfactual outcomes.\nMoreover, the use of a multi-output autoencoder explicitly accounts for\nheterogeneity across units and enhances the model interpretability of the\nlatent factors. We establish theoretical guarantees on the convergence of the\nestimated counterfactuals, and demonstrate the compelling performance of the\nproposed method using extensive simulation studies and a real data application.','Guanhao Zhou, Yuefeng Han, Xiufan Yu','2025-05-26','stat.ML','强化学习','http://arxiv.org/pdf/2505.20536v1','该论文研究了在因果面板数据模型中估计异质性治疗效应的任务，在协变量效应存在的情况下。他们提出了一种新颖的 Covariate-Adjusted Deep Causal Learning (CoDEAL) 方法，利用灵活的模型结构和强大的神经网络架构来统一处理面板单位和协变量效应的异质性和非线性性。CoDEAL 结合了非线性协变量效应组件（由前馈神经网络参数化）和非线性因子结构（由多输出自动编码器建模），形成了一个异质因果面板模型。非线性因子分析使得 CoDEAL 能够有效捕捉数据面板中固有的横截面和时间依赖关系。这些潜在的结构信息随后被整合到一个定制的矩阵补全算法中，从而促进对缺失反事实结果的更准确插补。'),('2505.20538v2','AstroVisBench: A Code Benchmark for Scientific Computing and Visualization in Astronomy','Large Language Models (LLMs) are being explored for applications in\nscientific research, including their capabilities to synthesize literature,\nanswer research questions, generate research ideas, and even conduct\ncomputational experiments. Ultimately, our goal is for these to help scientists\nderive novel scientific insights. In many areas of science, such insights often\narise from processing and visualizing data to understand its patterns. However,\nevaluating whether an LLM-mediated scientific workflow produces outputs\nconveying the correct scientific insights is challenging to evaluate and has\nnot been addressed in past work. We introduce AstroVisBench, the first\nbenchmark for both scientific computing and visualization in the astronomy\ndomain. AstroVisBench judges a language model\\\'s ability to both (1) create\nastronomy-specific workflows to process and analyze data and (2) visualize the\nresults of these workflows through complex plots. Our evaluation of\nvisualizations uses a novel LLM-as-a-judge workflow, which is validated against\nannotation by five professional astronomers. Using AstroVisBench we present an\nevaluation of state-of-the-art language models, showing a significant gap in\ntheir ability to engage in astronomy research as useful assistants. This\nevaluation provides a strong end-to-end evaluation for AI scientists that\noffers a path forward for the development of visualization-based workflows,\nwhich are central to a broad range of domains from physics to biology.','Sebastian Antony Joseph, Syed Murtaza Husain, Stella S. R. Offner, Stéphanie Juneau, Paul Torrey, Adam S. Bolton, Juan P. Farias, Niall Gaffney, Greg Durrett, Junyi Jessy Li','2025-05-26','cs.CL','LLM、科学计算、可视化处理','http://arxiv.org/pdf/2505.20538v2','该论文介绍了一种用于科学研究的大型语言模型（LLMs），并提出了AstroVisBench，这是天文学领域科学计算和可视化的第一个基准。通过评估语言模型在处理和分析数据以及可视化结果方面的能力，揭示了当前语言模型在天文学研究中作为有用助手的能力存在显著差距。'),('2505.20546v2','Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline','Multilingual large language models (LLMs) often exhibit factual\ninconsistencies across languages, with significantly better performance in\nfactual recall tasks in English than in other languages. The causes of these\nfailures, however, remain poorly understood. Using mechanistic analysis\ntechniques, we uncover the underlying pipeline that LLMs employ, which involves\nusing the English-centric factual recall mechanism to process multilingual\nqueries and then translating English answers back into the target language. We\nidentify two primary sources of error: insufficient engagement of the reliable\nEnglish-centric mechanism for factual recall, and incorrect translation from\nEnglish back into the target language for the final answer. To address these\nvulnerabilities, we introduce two vector interventions, both independent of\nlanguages and datasets, to redirect the model toward better internal paths for\nhigher factual consistency. Our interventions combined increase the recall\naccuracy by over 35 percent for the lowest-performing language. Our findings\ndemonstrate how mechanistic insights can be used to unlock latent multilingual\ncapabilities in LLMs.','Meng Lu, Ruochen Zhang, Carsten Eickhoff, Ellie Pavlick','2025-05-26','cs.CL','LLM (Multilingual large language models)','http://arxiv.org/pdf/2505.20546v2','该论文研究了多语言大型语言模型在事实召回任务中存在的事实不一致性问题，通过揭示模型的工作机制和错误来源，并引入两种矢量干预方法来提高模型的事实一致性。'),('2505.20553v1','A ZeNN architecture to avoid the Gaussian trap','We propose a new simple architecture, Zeta Neural Networks (ZeNNs), in order\nto overcome several shortcomings of standard multi-layer perceptrons (MLPs).\nNamely, in the large width limit, MLPs are non-parametric, they do not have a\nwell-defined pointwise limit, they lose non-Gaussian attributes and become\nunable to perform feature learning; moreover, finite width MLPs perform poorly\nin learning high frequencies. The new ZeNN architecture is inspired by three\nsimple principles from harmonic analysis:\n  i) Enumerate the perceptons and introduce a non-learnable weight to enforce\nconvergence;\n  ii) Introduce a scaling (or frequency) factor;\n  iii) Choose activation functions that lead to near orthogonal systems.\n  We will show that these ideas allow us to fix the referred shortcomings of\nMLPs. In fact, in the infinite width limit, ZeNNs converge pointwise, they\nexhibit a rich asymptotic structure beyond Gaussianity, and perform feature\nlearning. Moreover, when appropriate activation functions are chosen, (finite\nwidth) ZeNNs excel at learning high-frequency features of functions with low\ndimensional domains.','Luís Carvalho, João L. Costa, José Mourão, Gonçalo Oliveira','2025-05-26','cs.LG','神经网络','http://arxiv.org/pdf/2505.20553v1','本文提出了一种新的简单架构，Zeta神经网络（ZeNNs），旨在克服标准多层感知器（MLPs）的几个缺点。通过三个简单的原则，ZeNNs能够解决MLPs的缺陷，并在无限宽度限制下收敛点，展现丰富的渐近结构，并进行特征学习。'),('2505.20556v1','Learning a Pessimistic Reward Model in RLHF','This work proposes `PET\\\', a novel pessimistic reward fine-tuning method, to\nlearn a pessimistic reward model robust against reward hacking in offline\nreinforcement learning from human feedback (RLHF). Traditional reward modeling\ntechniques in RLHF train an imperfect reward model, on which a KL\nregularization plays a pivotal role in mitigating reward hacking when\noptimizing a policy. Such an intuition-based method still suffers from reward\nhacking, and the policies with large KL divergence from the dataset\ndistribution are excluded during learning. In contrast, we show that when\noptimizing a policy on a pessimistic reward model fine-tuned through PET,\nreward hacking can be prevented without relying on any regularization. We test\nour methods on the standard TL;DR summarization dataset. We find that one can\nlearn a high-quality policy on our pessimistic reward without using any\nregularization. Such a policy has a high KL divergence from the dataset\ndistribution while having high performance in practice. In summary, our work\nshows the feasibility of learning a pessimistic reward model against reward\nhacking. The agent can greedily search for the policy with a high pessimistic\nreward without suffering from reward hacking.','Yinglun Xu, Hangoo Kang, Tarun Suresh, Yuxuan Wan, Gagandeep Singh','2025-05-26','cs.LG','强化学习','http://arxiv.org/pdf/2505.20556v1','该论文提出了一种新颖的悲观奖励微调方法“PET”，用于在离线强化学习中学习一个对奖励欺骗具有鲁棒性的悲观奖励模型。通过PET微调悲观奖励模型，可以预防奖励欺骗，而无需依赖任何正则化方法。'),('2505.20561v1','Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning','Large Language Models (LLMs) trained via Reinforcement Learning (RL) have\nexhibited strong reasoning capabilities and emergent reflective behaviors, such\nas backtracking and error correction. However, conventional Markovian RL\nconfines exploration to the training phase to learn an optimal deterministic\npolicy and depends on the history contexts only through the current state.\nTherefore, it remains unclear whether reflective reasoning will emerge during\nMarkovian RL training, or why they are beneficial at test time. To remedy this,\nwe recast reflective exploration within the Bayes-Adaptive RL framework, which\nexplicitly optimizes the expected return under a posterior distribution over\nMarkov decision processes. This Bayesian formulation inherently incentivizes\nboth reward-maximizing exploitation and information-gathering exploration via\nbelief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and\nswitch strategies based on the observed outcomes, offering principled guidance\non when and how the model should reflectively explore. Empirical results on\nboth synthetic and mathematical reasoning tasks demonstrate that BARL\noutperforms standard Markovian RL approaches at test time, achieving superior\ntoken efficiency with improved exploration effectiveness. Our code is available\nat https://github.com/shenao-zhang/BARL.','Shenao Zhang, Yaqing Wang, Yinxiao Liu, Tianqi Liu, Peter Grabowski, Eugene Ie, Zhaoran Wang, Yunxuan Li','2025-05-26','cs.LG','LLM、强化学习','http://arxiv.org/pdf/2505.20561v1','该论文介绍了一种基于贝叶斯自适应强化学习框架的算法BARL，用于训练大型语言模型，以实现反思性推理和优化探索效果。'),('2505.20564v1','The NaijaVoices Dataset: Cultivating Large-Scale, High-Quality, Culturally-Rich Speech Data for African Languages','The development of high-performing, robust, and reliable speech technologies\ndepends on large, high-quality datasets. However, African languages --\nincluding our focus, Igbo, Hausa, and Yoruba -- remain under-represented due to\ninsufficient data. Popular voice-enabled technologies do not support any of the\n2000+ African languages, limiting accessibility for circa one billion people.\nWhile previous dataset efforts exist for the target languages, they lack the\nscale and diversity needed for robust speech models. To bridge this gap, we\nintroduce the NaijaVoices dataset, a 1,800-hour speech-text dataset with 5,000+\nspeakers. We outline our unique data collection approach, analyze its acoustic\ndiversity, and demonstrate its impact through finetuning experiments on\nautomatic speech recognition, averagely achieving 75.86% (Whisper), 52.06%\n(MMS), and 42.33% (XLSR) WER improvements. These results highlight NaijaVoices\\\'\npotential to advance multilingual speech processing for African languages.','Chris Emezue, The NaijaVoices Community, Busayo Awobade, Abraham Owodunni, Handel Emezue, Gloria Monica Tobechukwu Emezue, Nefertiti Nneoma Emezue, Sewade Ogun, Bunmi Akinremi, David Ifeoluwa Adelani, Chris Pal','2025-05-26','cs.CL','语音处理','http://arxiv.org/pdf/2505.20564v1','该论文介绍了NaijaVoices数据集，这是一个包含1,800小时语音文本数据和5,000多个说话者的数据集，旨在填补非洲语言数据不足的空白。研究通过微调实验展示了该数据集在自动语音识别上的影响，平均实现了75.86%（Whisper）、52.06%（MMS）和42.33%（XLSR）的识别错误率改进。'),('2505.20569v1','Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models','Despite significant advancements in Large Vision-Language Models, Object\nHallucination (OH) remains a persistent challenge. Building upon prior studies\non contrastive decoding that address this issue without requiring additional\nmodel training, we introduce RVCD (Retrieval Visual Contrastive Decoding), an\nadvanced method to suppress OH. RVCD leverages both negative and positive\nimages at the logit level, explicitly referencing AI-generated images designed\nto represent a single concept. Our approach demonstrates substantial\nimprovements over existing decoding-based methods.','Jihoon Lee, Min Song','2025-05-26','cs.CV','大视觉-语言模型(LLM)','http://arxiv.org/pdf/2505.20569v1','该论文介绍了一种名为RVCD的高级方法，用于抑制目标幻觉（OH），通过利用对比解码来解决这一挑战，不需要额外的模型训练。该方法在对抗OH方面取得了显著的改进。'),('2505.20571v1','Emotion Classification In-Context in Spanish','Classifying customer feedback into distinct emotion categories is essential\nfor understanding sentiment and improving customer experience. In this paper,\nwe classify customer feedback in Spanish into three emotion\ncategories--positive, neutral, and negative--using advanced NLP and ML\ntechniques. Traditional methods translate feedback from widely spoken languages\nto less common ones, resulting in a loss of semantic integrity and contextual\nnuances inherent to the original language. To address this limitation, we\npropose a hybrid approach that combines TF-IDF with BERT embeddings,\neffectively transforming Spanish text into rich numerical representations that\npreserve the semantic depth of the original language by using a Custom Stacking\nEnsemble (CSE) approach. To evaluate emotion classification, we utilize a range\nof models, including Logistic Regression, KNN, Bagging classifier with LGBM,\nand AdaBoost. The CSE model combines these classifiers as base models and uses\na one-vs-all Logistic Regression as the meta-model. Our experimental results\ndemonstrate that CSE significantly outperforms the individual and BERT model,\nachieving a test accuracy of 93.3% on the native Spanish dataset--higher than\nthe accuracy obtained from the translated version. These findings underscore\nthe challenges of emotion classification in Spanish and highlight the\nadvantages of combining vectorization techniques like TF-IDF with BERT for\nimproved accuracy. Our results provide valuable insights for businesses seeking\nto leverage emotion classification to enhance customer feedback analysis and\nservice improvements.','Bipul Thapa, Gabriel Cofre','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20571v1','本文研究了如何利用先进的NLP和ML技术将西班牙语客户反馈分类为积极、中立和消极情绪类别。提出了一种混合方法，结合了TF-IDF和BERT嵌入，通过自定义堆叠集成方法将西班牙文本转化为丰富的数值表示，以实现更好的情感分类准确性。'),('2505.20573v1','Collision- and Reachability-Aware Multi-Robot Control with Grounded LLM Planners','Large language models (LLMs) have demonstrated strong performance in various\nrobot control tasks. However, their deployment in real-world applications\nremains constrained. Even state-ofthe-art LLMs, such as GPT-o4mini, frequently\nproduce invalid action plans that violate physical constraints, such as\ndirecting a robot to an unreachable location or causing collisions between\nrobots. This issue primarily arises from a lack of awareness of these physical\nconstraints during the reasoning process. To address this issue, we propose a\nnovel framework that integrates reinforcement learning with verifiable rewards\n(RLVR) to incentivize knowledge of physical constraints into LLMs to induce\nconstraints-aware reasoning during plan generation. In this approach, only\nvalid action plans that successfully complete a control task receive positive\nrewards. We applied our method to two small-scale LLMs: a non-reasoning\nQwen2.5-3B-Instruct and a reasoning Qwen3-4B. The experiment results\ndemonstrate that constraint-aware small LLMs largely outperform large-scale\nmodels without constraints, grounded on both the BoxNet task and a newly\ndeveloped BoxNet3D environment built using MuJoCo. This work highlights the\neffectiveness of grounding even small LLMs with physical constraints to enable\nscalable and efficient multi-robot control in complex, physically constrained\nenvironments.','Jiabao Ji, Yongchao Chen, Yang Zhang, Ramana Rao Kompella, Chuchu Fan, Gaowen Liu, Shiyu Chang','2025-05-26','cs.RO','强化学习','http://arxiv.org/pdf/2505.20573v1','该论文提出了一种新颖的框架，将强化学习与可验证奖励（RLVR）相结合，以激励大型语言模型（LLMs）对物理约束的认识，从而在规划生成过程中引入约束感知推理。实验结果表明，具有约束感知能力的小型LLMs在复杂的物理约束环境中比没有约束的大型模型表现更好。'),('2505.20578v1','Ctrl-DNA: Controllable Cell-Type-Specific Regulatory DNA Design via Constrained RL','Designing regulatory DNA sequences that achieve precise cell-type-specific\ngene expression is crucial for advancements in synthetic biology, gene therapy\nand precision medicine. Although transformer-based language models (LMs) can\neffectively capture patterns in regulatory DNA, their generative approaches\noften struggle to produce novel sequences with reliable cell-specific activity.\nHere, we introduce Ctrl-DNA, a novel constrained reinforcement learning (RL)\nframework tailored for designing regulatory DNA sequences with controllable\ncell-type specificity. By formulating regulatory sequence design as a\nbiologically informed constrained optimization problem, we apply RL to\nautoregressive genomic LMs, enabling the models to iteratively refine sequences\nthat maximize regulatory activity in targeted cell types while constraining\noff-target effects. Our evaluation on human promoters and enhancers\ndemonstrates that Ctrl-DNA consistently outperforms existing generative and\nRL-based approaches, generating high-fitness regulatory sequences and achieving\nstate-of-the-art cell-type specificity. Moreover, Ctrl-DNA-generated sequences\ncapture key cell-type-specific transcription factor binding sites (TFBS), short\nDNA motifs recognized by regulatory proteins that control gene expression,\ndemonstrating the biological plausibility of the generated sequences.','Xingyu Chen, Shihao Ma, Runsheng Lin, Jiecong Lin, Bo Wang','2025-05-26','cs.LG','LLM、生成模型','http://arxiv.org/pdf/2505.20578v1','该论文介绍了一种名为Ctrl-DNA的新型受限强化学习框架，用于设计具有可控细胞特异性的调控DNA序列。通过将调控序列设计作为受限优化问题，并应用RL到自回归基因组LM中，使模型能够迭代地优化序列，最大化在目标细胞类型中的调控活性，同时约束非靶效应。研究结果表明，Ctrl-DNA在人类启动子和增强子上始终优于现有的生成和RL方法，生成高适应性的调控序列，并实现了最先进的细胞特异性。'),('2505.20579v1','The challenge of hidden gifts in multi-agent reinforcement learning','Sometimes we benefit from actions that others have taken even when we are\nunaware that they took those actions. For example, if your neighbor chooses not\nto take a parking spot in front of your house when you are not there, you can\nbenefit, even without being aware that they took this action. These \"hidden\ngifts\" represent an interesting challenge for multi-agent reinforcement\nlearning (MARL), since assigning credit when the beneficial actions of others\nare hidden is non-trivial. Here, we study the impact of hidden gifts with a\nvery simple MARL task. In this task, agents in a grid-world environment have\nindividual doors to unlock in order to obtain individual rewards. As well, if\nall the agents unlock their door the group receives a larger collective reward.\nHowever, there is only one key for all of the doors, such that the collective\nreward can only be obtained when the agents drop the key for others after they\nuse it. Notably, there is nothing to indicate to an agent that the other agents\nhave dropped the key, thus the act of dropping the key for others is a \"hidden\ngift\". We show that several different state-of-the-art RL algorithms, including\nMARL algorithms, fail to learn how to obtain the collective reward in this\nsimple task. Interestingly, we find that independent model-free policy gradient\nagents can solve the task when we provide them with information about their own\naction history, but MARL agents still cannot solve the task with action\nhistory. Finally, we derive a correction term for these independent agents,\ninspired by learning aware approaches, which reduces the variance in learning\nand helps them to converge to collective success more reliably. These results\nshow that credit assignment in multi-agent settings can be particularly\nchallenging in the presence of \"hidden gifts\", and demonstrate that learning\nawareness in independent agents can benefit these settings.','Dane Malenfant, Blake A. Richards','2025-05-26','cs.LG','强化学习','http://arxiv.org/pdf/2505.20579v1','该论文研究了在多智能体强化学习中存在“隐藏礼物”时的信用分配问题，通过一个简单的任务展示了独立模型无关策略梯度代理可以解决这一问题，并提出了一个修正项来帮助它们更可靠地收敛到集体成功。'),('2505.20589v1','Prot2Token: A Unified Framework for Protein Modeling via Next-Token Prediction','The diverse nature of protein prediction tasks has traditionally necessitated\nspecialized models, hindering the development of broadly applicable and\ncomputationally efficient Protein Language Models (PLMs). In this work, we\nintroduce Prot2Token, a unified framework that overcomes these challenges by\nconverting a wide spectrum of protein-related predictions, from sequence-level\nproperties and residue-specific attributes to complex inter-protein\ninteractions, into a standardized next-token prediction format. At its core,\nProt2Token employs an autoregressive decoder, conditioned on embeddings from\npre-trained protein encoders and guided by learnable task tokens, to perform\ndiverse predictions. This architecture uniquely facilitates multi-task\nlearning, enabling a single model to master numerous tasks with improved\nefficiency. We present extensive experimental validation across a variety of\nbenchmarks, demonstrating Prot2Tokens strong predictive power in different\ntypes of protein-prediction tasks. Key results include significant speedups\n(e.g., near 1000x over AlphaFold2 with MSA) and performance often matching or\nexceeding specialized approaches. Beyond that, we introduce an auxiliary\nself-supervised decoder pre-training approach to improve spatially sensitive\ntask performance. Prot2Token thus offers a significant step towards a\nversatile, high-throughput paradigm for protein modeling, promising to\naccelerate biological discovery and the development of novel therapeutics. The\ncode is available at https://github.com/mahdip72/prot2token .','Mahdi Pourmirzaei, Farzaneh Esmaili, Salhuldin Alqarghuli, Mohammadreza Pourmirzaei, Ye Han, Kai Chen, Mohsen Rezaei, Duolin Wang, Dong Xu','2025-05-26','cs.LG','蛋白质预测','http://arxiv.org/pdf/2505.20589v1','该论文介绍了Prot2Token，一个统一框架，通过将各种蛋白相关预测转换为标准化的下一个标记预测格式，克服了传统上需要专门模型的问题，从而实现了高效的蛋白质语言模型。该框架利用自回归解码器和预训练蛋白质编码器的嵌入，以及可学习的任务标记，实现了多样化的预测任务。实验验证表明，Prot2Token在各种蛋白质预测任务中具有强大的预测能力。'),('2505.20591v1','Effectiveness of Prompt Optimization in NL2SQL Systems','NL2SQL approaches have greatly benefited from the impressive capabilities of\nlarge language models (LLMs). In particular, bootstrapping an NL2SQL system for\na specific domain can be as simple as instructing an LLM with sufficient\ncontextual information, such as schema details and translation demonstrations.\nHowever, building an accurate system still requires the rigorous task of\nselecting the right context for each query-including identifying relevant\nschema elements, cell values, and suitable exemplars that help the LLM\nunderstand domain-specific nuances. Retrieval-based methods have become the\ngo-to approach for identifying such context. While effective, these methods\nintroduce additional inference-time costs due to the retrieval process.\n  In this paper, we argue that production scenarios demand high-precision,\nhigh-performance NL2SQL systems, rather than simply high-quality SQL\ngeneration, which is the focus of most current NL2SQL approaches. In such\nscenarios, the careful selection of a static set of exemplars-capturing the\nintricacies of the query log, target database, SQL constructs, and execution\nlatencies-plays a more crucial role than exemplar selection based solely on\nsimilarity. The key challenge, however, lies in identifying a representative\nset of exemplars for a given production setting. To this end, we propose a\nprompt optimization framework that not only addresses the high-precision\nrequirement but also optimizes the performance of the generated SQL through\nmulti-objective optimization. Preliminary empirical analysis demonstrates the\neffectiveness of the proposed framework.','Sairam Gurajada, Eser Kandogan, Sajjadur Rahman','2025-05-26','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20591v1','本文讨论了NL2SQL方法如何受益于大型语言模型（LLMs），并提出了一个优化框架，旨在提高NL2SQL系统的高精度和高性能。'),('2505.20600v1','InstGenIE: Generative Image Editing Made Efficient with Mask-aware Caching and Scheduling','Generative image editing using diffusion models has become a prevalent\napplication in today\\\'s AI cloud services. In production environments, image\nediting typically involves a mask that specifies the regions of an image\ntemplate to be edited. The use of masks provides direct control over the\nediting process and introduces sparsity in the model inference. In this paper,\nwe present InstGenIE, a system that efficiently serves image editing requests.\nThe key insight behind InstGenIE is that image editing only modifies the masked\nregions of image templates while preserving the original content in the\nunmasked areas. Driven by this insight, InstGenIE judiciously skips redundant\ncomputations associated with the unmasked areas by reusing cached intermediate\nactivations from previous inferences. To mitigate the high cache loading\noverhead, InstGenIE employs a bubble-free pipeline scheme that overlaps\ncomputation with cache loading. Additionally, to reduce queuing latency in\nonline serving while improving the GPU utilization, InstGenIE proposes a novel\ncontinuous batching strategy for diffusion model serving, allowing newly\narrived requests to join the running batch in just one step of denoising\ncomputation, without waiting for the entire batch to complete. As heterogeneous\nmasks induce imbalanced loads, InstGenIE also develops a load balancing\nstrategy that takes into account the loads of both computation and cache\nloading. Collectively, InstGenIE outperforms state-of-the-art diffusion serving\nsystems for image editing, achieving up to 3x higher throughput and reducing\naverage request latency by up to 14.7x while ensuring image quality.','Xiaoxiao Jiang, Suyi Li, Lingyun Yang, Tianyu Feng, Zhipeng Di, Weiyi Lu, Guoxuan Zhu, Xiu Lin, Kan Liu, Yinghao Yu, Tao Lan, Guodong Yang, Lin Qu, Liping Zhang, Wei Wang','2025-05-27','cs.DC','图像识别','http://arxiv.org/pdf/2505.20600v1','本文介绍了一种名为InstGenIE的系统，用于高效地处理图像编辑请求。该系统通过利用图像编辑只修改蒙版区域的特点，避免了不必要的计算，并提出了一种连续批处理策略和负载均衡策略，以提高图像编辑的吞吐量和降低请求延迟。'),('2505.20606v1','Towards Pretraining Robust ASR Foundation Model with Acoustic-Aware Data Augmentation','Whisper\\\'s robust performance in automatic speech recognition (ASR) is often\nattributed to its massive 680k-hour training set, an impractical scale for most\nresearchers. In this work, we examine how linguistic and acoustic diversity in\ntraining data affect the robustness of the ASR model and reveal that\ntranscription generalization is primarily driven by acoustic variation rather\nthan linguistic richness. We find that targeted acoustic augmentation methods\ncould significantly improve the generalization ability of ASR models, reducing\nword-error rates by up to 19.24 percent on unseen datasets when training on the\n960-hour Librispeech dataset. These findings highlight strategic acoustically\nfocused data augmentation as a promising alternative to massive datasets for\nbuilding robust ASR models, offering a potential solution to future foundation\nASR models when massive human speech data is lacking.','Dancheng Liu, Amir Nassereldine, Chenhui Xu, Jinjun Xiong','2025-05-27','cs.CL','语音处理','http://arxiv.org/pdf/2505.20606v1','本文研究了语言和声学多样性对自动语音识别模型的影响，发现声学变化对转录泛化起主导作用。研究表明，有针对性的声学增强方法可以显著提高ASR模型的泛化能力，在Librispeech数据集上训练时，可以将词错误率降低高达19.24％。'),('2505.20609v1','Comparisons between a Large Language Model-based Real-Time Compound Diagnostic Medical AI Interface and Physicians for Common Internal Medicine Cases using Simulated Patients','Objective To develop an LLM based realtime compound diagnostic medical AI\ninterface and performed a clinical trial comparing this interface and\nphysicians for common internal medicine cases based on the United States\nMedical License Exam (USMLE) Step 2 Clinical Skill (CS) style exams. Methods A\nnonrandomized clinical trial was conducted on August 20, 2024. We recruited one\ngeneral physician, two internal medicine residents (2nd and 3rd year), and five\nsimulated patients. The clinical vignettes were adapted from the USMLE Step 2\nCS style exams. We developed 10 representative internal medicine cases based on\nactual patients and included information available on initial diagnostic\nevaluation. Primary outcome was the accuracy of the first differential\ndiagnosis. Repeatability was evaluated based on the proportion of agreement.\nResults The accuracy of the physicians\\\' first differential diagnosis ranged\nfrom 50% to 70%, whereas the realtime compound diagnostic medical AI interface\nachieved an accuracy of 80%. The proportion of agreement for the first\ndifferential diagnosis was 0.7. The accuracy of the first and second\ndifferential diagnoses ranged from 70% to 90% for physicians, whereas the AI\ninterface achieved an accuracy rate of 100%. The average time for the AI\ninterface (557 sec) was 44.6% shorter than that of the physicians (1006 sec).\nThe AI interface ($0.08) also reduced costs by 98.1% compared to the\nphysicians\\\' average ($4.2). Patient satisfaction scores ranged from 4.2 to 4.3\nfor care by physicians and were 3.9 for the AI interface Conclusion An LLM\nbased realtime compound diagnostic medical AI interface demonstrated diagnostic\naccuracy and patient satisfaction comparable to those of a physician, while\nrequiring less time and lower costs. These findings suggest that AI interfaces\nmay have the potential to assist primary care consultations for common internal\nmedicine cases.','Hyungjun Park, Chang-Yun Woo, Seungjo Lim, Seunghwan Lim, Keunho Kwak, Ju Young Jeong, Chong Hyun Suh','2025-05-27','cs.AI','LLM (语言模型)、医疗人工智能','http://arxiv.org/pdf/2505.20609v1','该论文研究了基于LLM的实时化合诊断医疗人工智能界面，并通过临床试验比较了该界面和医生在常见内科病例上的表现。研究结果显示，AI界面在第一诊断准确性、第一和第二诊断准确性、时间和成本等方面均表现出优势。'),('2505.20612v1','Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models','Vision-language models (VLMs) trained on internet-scale data achieve\nremarkable zero-shot detection performance on common objects like car, truck,\nand pedestrian. However, state-of-the-art models still struggle to generalize\nto out-of-distribution classes, tasks and imaging modalities not typically\nfound in their pre-training. Rather than simply re-training VLMs on more visual\ndata, we argue that one should align VLMs to new concepts with annotation\ninstructions containing a few visual examples and rich textual descriptions. To\nthis end, we introduce Roboflow100-VL, a large-scale collection of 100\nmulti-modal object detection datasets with diverse concepts not commonly found\nin VLM pre-training. We evaluate state-of-the-art models on our benchmark in\nzero-shot, few-shot, semi-supervised, and fully-supervised settings, allowing\nfor comparison across data regimes. Notably, we find that VLMs like\nGroundingDINO and Qwen2.5-VL achieve less than 2% zero-shot accuracy on\nchallenging medical imaging datasets within Roboflow100-VL, demonstrating the\nneed for few-shot concept alignment. Our code and dataset are available at\nhttps://github.com/roboflow/rf100-vl/ and\nhttps://universe.roboflow.com/rf100-vl/','Peter Robicheaux, Matvei Popov, Anish Madan, Isaac Robinson, Joseph Nelson, Deva Ramanan, Neehar Peri','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.20612v1','该论文提出了一种方法，通过使用包含少量视觉示例和丰富文本描述的注释指导，使VLMs能够对新概念进行对齐。作者介绍了一个大规模的多模态目标检测数据集Roboflow100-VL，并在零样本、少样本、半监督和全监督设置下评估了最先进的模型。'),('2505.20613v1','REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning','Nowadays, formal theorem provers have made monumental progress on high-school\nand competition-level mathematics, but few of them generalize to more advanced\nmathematics. In this paper, we present REAL-Prover, a new open-source stepwise\ntheorem prover for Lean 4 to push this boundary. This prover, based on our\nfine-tuned large language model (REAL-Prover-v1) and integrated with a\nretrieval system (Leansearch-PS), notably boosts performance on solving\ncollege-level mathematics problems. To train REAL-Prover-v1, we developed\nHERALD-AF, a data extraction pipeline that converts natural language math\nproblems into formal statements, and a new open-source Lean 4 interactive\nenvironment (Jixia-interactive) to facilitate synthesis data collection. In our\nexperiments, our prover using only supervised fine-tune achieves competitive\nresults with a 23.7% success rate (Pass@64) on the ProofNet dataset-comparable\nto state-of-the-art (SOTA) models. To further evaluate our approach, we\nintroduce FATE-M, a new benchmark focused on algebraic problems, where our\nprover achieves a SOTA success rate of 56.7% (Pass@64).','Ziju Shen, Naohao Huang, Fanyi Yang, Yutong Wang, Guoxiong Gao, Tianyi Xu, Jiedong Jiang, Wanyi He, Pu Yang, Mengzhou Sun, Haocheng Ju, Peihao Wu, Bryan Dai, Bin Dong','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20613v1','本文介绍了一种基于大型语言模型的定理证明器REAL-Prover，能够在解决大学水平数学问题方面取得显著的性能提升。他们使用了一个数据提取管道HERALD-AF将自然语言数学问题转化为形式化陈述，并开发了一个新的开源Lean 4交互环境Jixia-interactive来促进数据收集。实验结果表明，他们的证明器在ProofNet数据集上取得了竞争性的结果，并在代数问题基准测试FATE-M上取得了最先进的成功率。'),('2505.20615v1','Intelligent Incident Hypertension Prediction in Obstructive Sleep Apnea','Obstructive sleep apnea (OSA) is a significant risk factor for hypertension,\nprimarily due to intermittent hypoxia and sleep fragmentation. Predicting\nwhether individuals with OSA will develop hypertension within five years\nremains a complex challenge. This study introduces a novel deep learning\napproach that integrates Discrete Cosine Transform (DCT)-based transfer\nlearning to enhance prediction accuracy. We are the first to incorporate all\npolysomnography signals together for hypertension prediction, leveraging their\ncollective information to improve model performance. Features were extracted\nfrom these signals and transformed into a 2D representation to utilize\npre-trained 2D neural networks such as MobileNet, EfficientNet, and ResNet\nvariants. To further improve feature learning, we introduced a DCT layer, which\ntransforms input features into a frequency-based representation, preserving\nessential spectral information, decorrelating features, and enhancing\nrobustness to noise. This frequency-domain approach, coupled with transfer\nlearning, is especially beneficial for limited medical datasets, as it\nleverages rich representations from pre-trained networks to improve\ngeneralization. By strategically placing the DCT layer at deeper truncation\ndepths within EfficientNet, our model achieved a best area under the curve\n(AUC) of 72.88%, demonstrating the effectiveness of frequency-domain feature\nextraction and transfer learning in predicting hypertension risk in OSA\npatients over a five-year period.','Omid Halimi Milani, Ahmet Enis Cetin, Bharati Prasad','2025-05-27','cs.CV','深度学习、医疗健康AI','http://arxiv.org/pdf/2505.20615v1','该论文介绍了一种新颖的深度学习方法，结合了基于离散余弦变换（DCT）的迁移学习，以提高预测精度。研究首次将所有多导睡眠图信号整合在一起进行高血压预测，利用它们的集体信息来提高模型性能。通过在EfficientNet中 strategically 放置 DCT 层，该模型在预测睡眠呼吸暂停综合征（OSA）患者在五年内发展高血压风险方面取得了最佳的AUC（曲线下面积）为72.88%。'),('2505.20621v1','Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning','Similar to other machine learning frameworks, Offline Reinforcement Learning\n(RL) is shown to be vulnerable to poisoning attacks, due to its reliance on\nexternally sourced datasets, a vulnerability that is exacerbated by its\nsequential nature. To mitigate the risks posed by RL poisoning, we extend\ncertified defenses to provide larger guarantees against adversarial\nmanipulation, ensuring robustness for both per-state actions, and the overall\nexpected cumulative reward. Our approach leverages properties of Differential\nPrivacy, in a manner that allows this work to span both continuous and discrete\nspaces, as well as stochastic and deterministic environments -- significantly\nexpanding the scope and applicability of achievable guarantees. Empirical\nevaluations demonstrate that our approach ensures the performance drops to no\nmore than $50\\%$ with up to $7\\%$ of the training data poisoned, significantly\nimproving over the $0.008\\%$ in prior work~\\citep{wu_copa_2022}, while\nproducing certified radii that is $5$ times larger as well. This highlights the\npotential of our framework to enhance safety and reliability in offline RL.','Shijie Liu, Andrew C. Cullen, Paul Montague, Sarah Erfani, Benjamin I. P. Rubinstein','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.20621v1','该论文研究了离线强化学习中存在的毒化攻击漏洞，并提出了一种基于差分隐私的认证防御方法，可以在连续和离散空间以及随机和确定性环境中提供更大的保证范围，显著扩展了可实现的保证范围。实证评估表明，该方法可以确保性能下降不超过50％，并且训练数据中毒化不超过7％时，明显优于之前的工作，同时还产生了5倍大的认证半径。这突显了该框架在增强离线强化学习的安全性和可靠性方面的潜力。'),('2505.20622v1','SeqPO-SiMT: Sequential Policy Optimization for Simultaneous Machine Translation','We present Sequential Policy Optimization for Simultaneous Machine\nTranslation (SeqPO-SiMT), a new policy optimization framework that defines the\nsimultaneous machine translation (SiMT) task as a sequential decision making\nproblem, incorporating a tailored reward to enhance translation quality while\nreducing latency. In contrast to popular Reinforcement Learning from Human\nFeedback (RLHF) methods, such as PPO and DPO, which are typically applied in\nsingle-step tasks, SeqPO-SiMT effectively tackles the multi-step SiMT task.\nThis intuitive framework allows the SiMT LLMs to simulate and refine the SiMT\nprocess using a tailored reward. We conduct experiments on six datasets from\ndiverse domains for En to Zh and Zh to En SiMT tasks, demonstrating that\nSeqPO-SiMT consistently achieves significantly higher translation quality with\nlower latency. In particular, SeqPO-SiMT outperforms the supervised fine-tuning\n(SFT) model by 1.13 points in COMET, while reducing the Average Lagging by 6.17\nin the NEWSTEST2021 En to Zh dataset. While SiMT operates with far less context\nthan offline translation, the SiMT results of SeqPO-SiMT on 7B LLM surprisingly\nrival the offline translation of high-performing LLMs, including\nQwen-2.5-7B-Instruct and LLaMA-3-8B-Instruct.','Ting Xu, Zhichao Huang, Jiankai Sun, Shanbo Cheng, Wai Lam','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20622v1','该论文提出了一种新的顺序策略优化框架，将同时机器翻译任务定义为顺序决策问题，通过定制奖励来提高翻译质量同时降低延迟。与传统的强化学习方法不同，该框架有效地解决了多步骤的同时机器翻译任务，并在多个数据集上展示了显著更高的翻译质量和更低的延迟。'),('2505.20624v1','POLAR: A Benchmark for Multilingual, Multicultural, and Multi-Event Online Polarization','Online polarization poses a growing challenge for democratic discourse, yet\nmost computational social science research remains monolingual, culturally\nnarrow, or event-specific. We introduce POLAR, a multilingual, multicultural,\nand multievent dataset with over 23k instances in seven languages from diverse\nonline platforms and real-world events. Polarization is annotated along three\naxes: presence, type, and manifestation, using a variety of annotation\nplatforms adapted to each cultural context. We conduct two main experiments:\n(1) we fine-tune six multilingual pretrained language models in both\nmonolingual and cross-lingual setups; and (2) we evaluate a range of open and\nclosed large language models (LLMs) in few-shot and zero-shot scenarios.\nResults show that while most models perform well on binary polarization\ndetection, they achieve substantially lower scores when predicting polarization\ntypes and manifestations. These findings highlight the complex, highly\ncontextual nature of polarization and the need for robust, adaptable approaches\nin NLP and computational social science. All resources will be released to\nsupport further research and effective mitigation of digital polarization\nglobally.','Usman Naseem, Juan Ren, Saba Anwar, Sarah Kohail, Rudy Alexandro Garrido Veliz, Robert Geislinger, Aisha Jabr, Idris Abdulmumin, Laiba Qureshi, Aarushi Ajay Borkar, Maryam Ibrahim Mukhtar, Abinew Ali Ayele, Ibrahim Said Ahmad, Adem Ali, Martin Semmann, Shamsuddeen Hassan Muhammad, Seid Muhie Yimam','2025-05-27','cs.CL','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.20624v1','该论文介绍了一个名为POLAR的多语言、多文化、多事件数据集，包含来自不同在线平台和现实世界事件的超过23k个实例。作者通过在单语和跨语言设置中对六个多语言预训练语言模型进行微调，并在少样本和零样本情况下评估一系列开放和封闭的大型语言模型（LLMs）。结果显示，大多数模型在二元极化检测上表现良好，但在预测极化类型和表现时得分显著较低。'),('2505.20625v1','Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration','Processing long contexts has become a critical capability for modern large\nlanguage models (LLMs). Existing works leverage agent-based divide-and-conquer\nmethods for processing long contexts. But these methods face crucial\nlimitations, including prohibitive accumulated latency and amplified\ninformation loss from excessive agent invocations, and the disruption of\ninherent textual dependencies by immoderate partitioning. In this paper, we\npropose a novel multi-agent framework XpandA (Expand-Agent) coupled with\nquestion-driven workflow and dynamic partitioning for robust long-context\nprocessing. XpandA overcomes these limitations through: 1) dynamic partitioning\nof long texts, which adaptively modulates the filling rate of context windows\nfor input sequences of vastly varying lengths; 2) question-guided protocol to\nupdate flat information ensembles within centralized shared memory,\nconstructing consistent inter-agent knowledge across partitions; and 3)\nselectively replaying specific partitions based on the state-tracking of\nquestion-information couples to promote the resolution of inverted-order\nstructures across partitions (e.g., flashbacks). We perform a comprehensive\nevaluation of XpandA on multiple long-context benchmarks with length varying\nfrom 1k to 1M, demonstrating XpandA\\\'s feasibility for processing ultra-long\nsequences and its significant effectiveness in enhancing the long-context\ncapabilities of various LLMs by achieving 20\\% improvements and 1.5x inference\nspeedup over baselines of full-context, RAG and previous agent-based methods.','Sibo Xiao, Zixin Lin, Wenyang Gao, Yue Zhang','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20625v1','本文提出了一种名为XpandA的多代理框架，结合了问题驱动的工作流程和动态分区，用于处理长上下文。XpandA通过动态分区长文本、问题引导协议更新共享内存中的平面信息集合以及基于状态跟踪的选择性重播特定分区等方法，有效克服了现有基于代理的长上下文处理方法的一些限制，并在多个长上下文基准测试中取得了显著的效果提升。'),('2505.20627v1','Fundamental Limits of Game-Theoretic LLM Alignment: Smith Consistency and Preference Matching','Nash Learning from Human Feedback is a game-theoretic framework for aligning\nlarge language models (LLMs) with human preferences by modeling learning as a\ntwo-player zero-sum game. However, using raw preference as the payoff in the\ngame highly limits the potential of the game-theoretic LLM alignment framework.\nIn this paper, we systematically study using what choices of payoff based on\nthe pairwise human preferences can yield desirable alignment properties. We\nestablish necessary and sufficient conditions for Condorcet consistency,\ndiversity through mixed strategies, and Smith consistency. These results\nprovide a theoretical foundation for the robustness of game-theoretic LLM\nalignment. Further, we show the impossibility of preference matching -- i.e.,\nno smooth and learnable mappings of pairwise preferences can guarantee a unique\nNash equilibrium that matches a target policy, even under standard assumptions\nlike the Bradley-Terry-Luce model. This result highlights the fundamental\nlimitation of game-theoretic LLM alignment.','Zhekun Shi, Kaizhao Liu, Qi Long, Weijie J. Su, Jiancong Xiao','2025-05-27','cs.GT','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20627v1','本文研究了一种基于博弈论的框架，用于通过建模学习为一个双人零和博弈来将大型语言模型与人类偏好对齐。研究发现在使用基于成对人类偏好的不同选择作为支付时，可以实现理想的对齐性质，并建立了Condorcet一致性、通过混合策略实现多样性以及Smith一致性的必要和充分条件。然而，研究还表明了在标准假设下，即使使用Bradley-Terry-Luce模型，也无法保证平滑可学习的映射能够保证唯一的纳什均衡，从而突显了博弈论语言模型对齐的基本限制。'),('2505.20628v1','Position: Adopt Constraints Over Penalties in Deep Learning','Recent efforts toward developing trustworthy AI systems with accountability\nguarantees have led to a growing reliance on machine learning formulations that\nincorporate external requirements, or constraints. These requirements are often\nenforced through penalization--adding fixed-weight terms to the task loss. We\nargue that this approach is ill-suited, and that tailored constrained\noptimization methods should be adopted instead. In particular, no penalty\ncoefficient may yield a solution that both satisfies the constraints and\nachieves good performance--i.e., one solving the constrained problem. Moreover,\ntuning these coefficients is costly, incurring significant time and\ncomputational overhead. In contrast, tailored constrained methods--such as the\nLagrangian approach, which optimizes the penalization \"coefficients\" (the\nLagrange multipliers) alongside the model--(i) truly solve the constrained\nproblem and add accountability, (ii) eliminate the need for extensive penalty\ntuning, and (iii) integrate seamlessly with modern deep learning pipelines.','Juan Ramirez, Meraj Hashemizadeh, Simon Lacoste-Julien','2025-05-27','cs.LG','优化方法','http://arxiv.org/pdf/2505.20628v1','该论文讨论了在开发具有责任保证的可信AI系统时，采用定制的受限优化方法代替传统的通过惩罚项实施外部约束的机器学习方法。这种方法可以更好地解决约束问题，提高性能，并且减少对惩罚系数的调整成本。'),('2505.20629v1','Incorporating Flexible Image Conditioning into Text-to-Video Diffusion Models without Training','Text-image-to-video (TI2V) generation is a critical problem for controllable\nvideo generation using both semantic and visual conditions. Most existing\nmethods typically add visual conditions to text-to-video (T2V) foundation\nmodels by finetuning, which is costly in resources and only limited to a few\npredefined conditioning settings. To tackle this issue, we introduce a unified\nformulation for TI2V generation with flexible visual conditioning. Furthermore,\nwe propose an innovative training-free approach, dubbed FlexTI2V, that can\ncondition T2V foundation models on an arbitrary amount of images at arbitrary\npositions. Specifically, we firstly invert the condition images to noisy\nrepresentation in a latent space. Then, in the denoising process of T2V models,\nour method uses a novel random patch swapping strategy to incorporate visual\nfeatures into video representations through local image patches. To balance\ncreativity and fidelity, we use a dynamic control mechanism to adjust the\nstrength of visual conditioning to each video frame. Extensive experiments\nvalidate that our method surpasses previous training-free image conditioning\nmethods by a notable margin. We also show more insights of our method by\ndetailed ablation study and analysis.','Bolin Lai, Sangmin Lee, Xu Cao, Xiang Li, James M. Rehg','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.20629v1','该论文提出了一种灵活的文本-图像-视频生成方法，通过将图像条件引入文本-视频基础模型，实现了对视频生成的控制。他们提出的FlexTI2V方法可以在任意位置对任意数量的图像进行条件设置，通过随机补丁交换策略将视觉特征融入视频表示，同时使用动态控制机制平衡创造力和保真度。'),('2505.20630v1','SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis','As Large Language Models (LLMs) evolve in understanding and generating code,\naccurately evaluating their reliability in analyzing source code\nvulnerabilities becomes increasingly vital. While studies have examined LLM\ncapabilities in tasks like vulnerability detection and repair, they often\noverlook the importance of both structure and semantic reasoning crucial for\ntrustworthy vulnerability analysis. To address this gap, we introduce\nSV-TrustEval-C, a benchmark designed to evaluate LLMs\\\' abilities for\nvulnerability analysis of code written in the C programming language through\ntwo key dimensions: structure reasoning - assessing how models identify\nrelationships between code elements under varying data and control flow\ncomplexities; and semantic reasoning - examining their logical consistency in\nscenarios where code is structurally and semantically perturbed. Our results\nshow that current LLMs are far from satisfactory in understanding complex code\nrelationships and that their vulnerability analyses rely more on pattern\nmatching than on robust logical reasoning. These findings underscore the\neffectiveness of the SV-TrustEval-C benchmark and highlight critical areas for\nenhancing the reasoning capabilities and trustworthiness of LLMs in real-world\nvulnerability analysis tasks. Our initial benchmark dataset is publicly\navailable.','Yansong Li, Paula Branco, Alexander M. Hoole, Manish Marwah, Hari Manassery Koduvely, Guy-Vincent Jourdan, Stephan Jou','2025-05-27','cs.SE','LLM、漏洞分析','http://arxiv.org/pdf/2505.20630v1','该论文介绍了一个名为SV-TrustEval-C的基准测试，旨在评估大型语言模型在C编程语言代码漏洞分析中的能力，通过结构推理和语义推理两个关键维度。研究结果显示，当前的LLMs在理解复杂代码关系方面仍有很大提升空间。'),('2505.20633v1','Test-Time Learning for Large Language Models','While Large Language Models (LLMs) have exhibited remarkable emergent\ncapabilities through extensive pre-training, they still face critical\nlimitations in generalizing to specialized domains and handling diverse\nlinguistic variations, known as distribution shifts. In this paper, we propose\na Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically\nadapts LLMs to target domains using only unlabeled test data during testing.\nSpecifically, we first provide empirical evidence and theoretical insights to\nreveal that more accurate predictions from LLMs can be achieved by minimizing\nthe input perplexity of the unlabeled test data. Based on this insight, we\nformulate the Test-Time Learning process of LLMs as input perplexity\nminimization, enabling self-supervised enhancement of LLM performance.\nFurthermore, we observe that high-perplexity samples tend to be more\ninformative for model optimization. Accordingly, we introduce a Sample\nEfficient Learning Strategy that actively selects and emphasizes these\nhigh-perplexity samples for test-time updates. Lastly, to mitigate catastrophic\nforgetting and ensure adaptation stability, we adopt Low-Rank Adaptation (LoRA)\ninstead of full-parameter optimization, which allows lightweight model updates\nwhile preserving more original knowledge from the model. We introduce the\nAdaptEval benchmark for TTL and demonstrate through experiments that TLM\nimproves performance by at least 20% compared to original LLMs on domain\nknowledge adaptation.','Jinwu Hu, Zhitian Zhang, Guohao Chen, Xutao Wen, Chao Shuai, Wei Luo, Bin Xiao, Yuanqing Li, Mingkui Tan','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20633v1','本文提出了一种名为Test-Time Learning (TTL) 的范式，用于通过仅在测试期间使用未标记的测试数据动态调整LLMs到目标领域，从而提高LLMs的性能。通过最小化未标记测试数据的输入困惑度，可以实现更准确的预测，并引入了一种Sample Efficient Learning Strategy来选择和强调高困惑度样本进行测试时更新。采用Low-Rank Adaptation (LoRA)来减轻灾难性遗忘并确保适应性稳定性。'),('2505.20634v1','Explaining Concept Shift with Interpretable Feature Attribution','Regardless the amount of data a machine learning (ML) model is trained on,\nthere will inevitably be data that differs from their training set, lowering\nmodel performance. Concept shift occurs when the distribution of labels\nconditioned on the features changes, making even a well-tuned ML model to have\nlearned a fundamentally incorrect representation. Identifying these shifted\nfeatures provides unique insight into how one dataset differs from another,\nconsidering the difference may be across a scientifically relevant dimension,\nsuch as time, disease status, population, etc. In this paper, we propose\nSGShift, a model for detecting concept shift in tabular data and attributing\nreduced model performance to a sparse set of shifted features. SGShift models\nconcept shift with a Generalized Additive Model (GAM) and performs subsequent\nfeature selection to identify shifted features. We propose further extensions\nof SGShift by incorporating knockoffs to control false discoveries and an\nabsorption term to account for models with poor fit to the data. We conduct\nextensive experiments in synthetic and real data across various ML models and\nfind SGShift can identify shifted features with AUC $>0.9$ and recall $>90\\%$,\noften 2 or 3 times as high as baseline methods.','Ruiqi Lyu, Alistair Turcan, Bryan Wilder','2025-05-27','cs.LG','数据挖掘/机器学习','http://arxiv.org/pdf/2505.20634v1','本文提出了一种用于检测表格数据中概念转变的模型SGShift，通过广义加性模型（GAM）建模概念转变，并进行后续特征选择以识别转变的特征。实验结果表明，SGShift能够在合成和真实数据中识别转变的特征，并且性能优于基准方法。'),('2505.20635v1','Plug-and-Play Co-Occurring Face Attention for Robust Audio-Visual Speaker Extraction','Audio-visual speaker extraction isolates a target speaker\\\'s speech from a\nmixture speech signal conditioned on a visual cue, typically using the target\nspeaker\\\'s face recording. However, in real-world scenarios, other co-occurring\nfaces are often present on-screen, providing valuable speaker activity cues in\nthe scene. In this work, we introduce a plug-and-play inter-speaker attention\nmodule to process these flexible numbers of co-occurring faces, allowing for\nmore accurate speaker extraction in complex multi-person environments. We\nintegrate our module into two prominent models: the AV-DPRNN and the\nstate-of-the-art AV-TFGridNet. Extensive experiments on diverse datasets,\nincluding the highly overlapped VoxCeleb2 and sparsely overlapped MISP,\ndemonstrate that our approach consistently outperforms baselines. Furthermore,\ncross-dataset evaluations on LRS2 and LRS3 confirm the robustness and\ngeneralizability of our method.','Zexu Pan, Shengkui Zhao, Tingting Wang, Kun Zhou, Yukun Ma, Chong Zhang, Bin Ma','2025-05-27','eess.AS','音视频处理','http://arxiv.org/pdf/2505.20635v1','该论文介绍了一种音视频说话人提取方法，利用视觉线索从混合语音信号中分离出目标说话人的语音。他们引入了一个可插拔的说话人间注意力模块，处理灵活数量的共存人脸，从而在复杂的多人环境中实现更准确的说话人提取。'),('2505.20637v1','TrustSkin: A Fairness Pipeline for Trustworthy Facial Affect Analysis Across Skin Tone','Understanding how facial affect analysis (FAA) systems perform across\ndifferent demographic groups requires reliable measurement of sensitive\nattributes such as ancestry, often approximated by skin tone, which itself is\nhighly influenced by lighting conditions. This study compares two objective\nskin tone classification methods: the widely used Individual Typology Angle\n(ITA) and a perceptually grounded alternative based on Lightness ($L^*$) and\nHue ($H^*$). Using AffectNet and a MobileNet-based model, we assess fairness\nacross skin tone groups defined by each method. Results reveal a severe\nunderrepresentation of dark skin tones ($\\sim 2 \\%$), alongside fairness\ndisparities in F1-score (up to 0.08) and TPR (up to 0.11) across groups. While\nITA shows limitations due to its sensitivity to lighting, the $H^*$-$L^*$\nmethod yields more consistent subgrouping and enables clearer diagnostics\nthrough metrics such as Equal Opportunity. Grad-CAM analysis further highlights\ndifferences in model attention patterns by skin tone, suggesting variation in\nfeature encoding. To support future mitigation efforts, we also propose a\nmodular fairness-aware pipeline that integrates perceptual skin tone\nestimation, model interpretability, and fairness evaluation. These findings\nemphasize the relevance of skin tone measurement choices in fairness assessment\nand suggest that ITA-based evaluations may overlook disparities affecting\ndarker-skinned individuals.','Ana M. Cabanas, Alma Pedro, Domingo Mery','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.20637v1','本研究比较了两种客观皮肤色调分类方法：广泛使用的Individual Typology Angle (ITA)和基于Lightness ($L^*$)和Hue ($H^*$)的感知基础替代方法。使用AffectNet和基于MobileNet的模型，评估了每种方法定义的皮肤色调组之间的公平性。结果显示，深色皮肤色调严重被低估（约2%），同时在不同组之间的F1分数（高达0.08）和TPR（高达0.11）存在公平性差异。研究表明，ITA由于对光照的敏感性而存在局限性，而$H^*$-$L^*$方法产生更一致的子组划分，并通过诸如Equal Opportunity等指标实现更清晰的诊断。'),('2505.20642v1','CoderAgent: Simulating Student Behavior for Personalized Programming Learning with Large Language Models','Personalized programming tutoring, such as exercise recommendation, can\nenhance learners\\\' efficiency, motivation, and outcomes, which is increasingly\nimportant in modern digital education. However, the lack of sufficient and\nhigh-quality programming data, combined with the mismatch between offline\nevaluation and real-world learning, hinders the practical deployment of such\nsystems. To address this challenge, many approaches attempt to simulate learner\npractice data, yet they often overlook the fine-grained, iterative nature of\nprogramming learning, resulting in a lack of interpretability and granularity.\nTo fill this gap, we propose a LLM-based agent, CoderAgent, to simulate\nstudents\\\' programming processes in a fine-grained manner without relying on\nreal data. Specifically, we equip each human learner with an intelligent agent,\nthe core of which lies in capturing the cognitive states of the human\nprogramming practice process. Inspired by ACT-R, a cognitive architecture\nframework, we design the structure of CoderAgent to align with human cognitive\narchitecture by focusing on the mastery of programming knowledge and the\napplication of coding ability. Recognizing the inherent patterns in\nmulti-layered cognitive reasoning, we introduce the Programming Tree of Thought\n(PTOT), which breaks down the process into four steps: why, how, where, and\nwhat. This approach enables a detailed analysis of iterative problem-solving\nstrategies. Finally, experimental evaluations on real-world datasets\ndemonstrate that CoderAgent provides interpretable insights into learning\ntrajectories and achieves accurate simulations, paving the way for personalized\nprogramming education.','Yi Zhan, Qi Liu, Weibo Gao, Zheng Zhang, Tianfu Wang, Shuanghong Shen, Junyu Lu, Zhenya Huang','2025-05-27','cs.AI','LLM (语言与语义建模)','http://arxiv.org/pdf/2505.20642v1','该论文提出了一种基于LLM的智能代理CoderAgent，用于模拟学生的编程过程，以填补现有方法在细粒度和可解释性方面的不足。通过实验验证，该方法能够提供可解释的学习轨迹和准确的模拟，为个性化编程教育铺平了道路。'),('2505.20643v1','Can Past Experience Accelerate LLM Reasoning?','Allocating more compute to large language models (LLMs) reasoning has\ngenerally been demonstrated to improve their effectiveness, but also results in\nincreased inference time. In contrast, humans can perform tasks faster and\nbetter with increased experience and exposure. Hence, this paper aims to\ninvestigate the question: Can LLMs also become faster at reasoning through\nrecurrent exposure on relevant tasks, and if so, how can it be achieved? To\naddress these questions, we first formalize the problem setting of LLM\nreasoning speedup systematically in the dimensions of task relevancy and\ncompute budget calculation. We then propose SpeedupLLM, a theoretically\nguaranteed framework to implement and benchmark such reasoning speedup\nbehaviour based on adaptive compute allocation and memory mechanisms. We\nfurther conduct comprehensive experiments to benchmark such behaviour across\ndifferent question similarity levels, memory methods, and reasoning methods.\nResults show that LLMs can generally reason faster with past experience,\nachieving up to a 56% reduction in compute cost when equipped with appropriate\nmemory and reasoning methods.','Bo Pan, Liang Zhao','2025-05-27','cs.LG','LLM (大型语言模型)','http://arxiv.org/pdf/2505.20643v1','本论文研究了如何通过重复暴露于相关任务来提高大型语言模型（LLMs）的推理速度，提出了SpeedupLLM框架来实现这一目标，并通过实验证明，LLMs在过去的经验中可以更快地推理，最多可以减少56%的计算成本。'),('2505.20644v1','HCQA-1.5 @ Ego4D EgoSchema Challenge 2025','In this report, we present the method that achieves third place for Ego4D\nEgoSchema Challenge in CVPR 2025. To improve the reliability of answer\nprediction in egocentric video question answering, we propose an effective\nextension to the previously proposed HCQA framework. Our approach introduces a\nmulti-source aggregation strategy to generate diverse predictions, followed by\na confidence-based filtering mechanism that selects high-confidence answers\ndirectly. For low-confidence cases, we incorporate a fine-grained reasoning\nmodule that performs additional visual and contextual analysis to refine the\npredictions. Evaluated on the EgoSchema blind test set, our method achieves 77%\naccuracy on over 5,000 human-curated multiple-choice questions, outperforming\nlast year\\\'s winning solution and the majority of participating teams. Our code\nwill be added at https://github.com/Hyu-Zhang/HCQA.','Haoyu Zhang, Yisen Feng, Qiaohui Chu, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie','2025-05-27','cs.CV','计算机视觉 (CV)','http://arxiv.org/pdf/2505.20644v1','该论文介绍了在CVPR 2025年Ego4D EgoSchema挑战赛中获得第三名的方法。他们提出了一种改进的HCQA框架，通过引入多源聚合策略和基于置信度的过滤机制来提高自我中心视频问题回答的可靠性。他们的方法在EgoSchema盲测数据集上取得了77%的准确率，超过了去年的获奖解决方案和大多数参赛团队。'),('2505.20645v1','STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models','Steerability, or the ability of large language models (LLMs) to adapt outputs\nto align with diverse community-specific norms, perspectives, and communication\nstyles, is critical for real-world applications but remains under-evaluated. We\nintroduce Steer-Bench, a benchmark for assessing population-specific steering\nusing contrasting Reddit communities. Covering 30 contrasting subreddit pairs\nacross 19 domains, Steer-Bench includes over 10,000 instruction-response pairs\nand validated 5,500 multiple-choice question with corresponding silver labels\nto test alignment with diverse community norms. Our evaluation of 13 popular\nLLMs using Steer-Bench reveals that while human experts achieve an accuracy of\n81% with silver labels, the best-performing models reach only around 65%\naccuracy depending on the domain and configuration. Some models lag behind\nhuman-level alignment by over 15 percentage points, highlighting significant\ngaps in community-sensitive steerability. Steer-Bench is a benchmark to\nsystematically assess how effectively LLMs understand community-specific\ninstructions, their resilience to adversarial steering attempts, and their\nability to accurately represent diverse cultural and ideological perspectives.','Kai Chen, Zihao He, Taiwei Shi, Kristina Lerman','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20645v1','该论文介绍了Steer-Bench，一个用于评估大型语言模型在不同Reddit社区之间适应性的基准测试。研究发现，尽管人类专家在使用银标签时达到81%的准确率，但最佳表现的模型在不同领域和配置下只能达到约65%的准确率。一些模型在与人类对齐方面落后于15个百分点以上，突显了在社区敏感性方面的显著差距。'),('2505.20646v1','Evaluating Training in Binarized Neural Networks Through the Lens of Algorithmic Information Theory','Understanding and controlling the informational complexity of neural networks\nis a central challenge in machine learning, with implications for\ngeneralization, optimization, and model capacity. While most approaches rely on\nentropy-based loss functions and statistical metrics, these measures often fail\nto capture deeper, causally relevant algorithmic regularities embedded in\nnetwork structure. We propose a shift toward algorithmic information theory,\nusing Binarized Neural Networks (BNNs) as a first proxy. Grounded in\nalgorithmic probability (AP) and the universal distribution it defines, our\napproach characterizes learning dynamics through a formal, causally grounded\nlens. We apply the Block Decomposition Method (BDM) -- a scalable approximation\nof algorithmic complexity based on AP -- and demonstrate that it more closely\ntracks structural changes during training than entropy, consistently exhibiting\nstronger correlations with training loss across varying model sizes and\nrandomized training runs. These results support the view of training as a\nprocess of algorithmic compression, where learning corresponds to the\nprogressive internalization of structured regularities. In doing so, our work\noffers a principled estimate of learning progression and suggests a framework\nfor complexity-aware learning and regularization, grounded in first principles\nfrom information theory, complexity, and computability.','Eduardo Y. Sakabe, Felipe S. Abrahão, Alexandre Simões, Esther Colombini, Paula Costa, Ricardo Gudwin, Hector Zenil','2025-05-27','cs.LG','神经网络/机器学习','http://arxiv.org/pdf/2505.20646v1','该论文提出了一种基于算法信息理论的方法，使用二值化神经网络作为第一个代理，通过算法复杂性的可扩展近似方法来表征学习动态，并展示了其在训练过程中更好地跟踪结构变化的能力。'),('2505.20648v1','Voronoi-grid-based Pareto Front Learning and Its Application to Collaborative Federated Learning','Multi-objective optimization (MOO) exists extensively in machine learning,\nand aims to find a set of Pareto-optimal solutions, called the Pareto front,\ne.g., it is fundamental for multiple avenues of research in federated learning\n(FL). Pareto-Front Learning (PFL) is a powerful method implemented using\nHypernetworks (PHNs) to approximate the Pareto front. This method enables the\nacquisition of a mapping function from a given preference vector to the\nsolutions on the Pareto front. However, most existing PFL approaches still face\ntwo challenges: (a) sampling rays in high-dimensional spaces; (b) failing to\ncover the entire Pareto Front which has a convex shape. Here, we introduce a\nnovel PFL framework, called as PHN-HVVS, which decomposes the design space into\nVoronoi grids and deploys a genetic algorithm (GA) for Voronoi grid\npartitioning within high-dimensional space. We put forward a new loss function,\nwhich effectively contributes to more extensive coverage of the resultant\nPareto front and maximizes the HV Indicator. Experimental results on multiple\nMOO machine learning tasks demonstrate that PHN-HVVS outperforms the baselines\nsignificantly in generating Pareto front. Also, we illustrate that PHN-HVVS\nadvances the methodologies of several recent problems in the FL field. The code\nis available at\nhttps://github.com/buptcmm/phnhvvs}{https://github.com/buptcmm/phnhvvs.','Mengmeng Chen, Xiaohu Wu, Qiqi Liu, Tiantian He, Yew-Soon Ong, Yaochu Jin, Qicheng Lao, Han Yu','2025-05-27','cs.LG','机器学习','http://arxiv.org/pdf/2505.20648v1','该论文介绍了一种名为PHN-HVVS的PFL框架，通过将设计空间分解为Voronoi网格，并在高维空间中使用遗传算法进行Voronoi网格划分，提出了一种新的损失函数，有效地扩展了结果Pareto前沿的覆盖范围并最大化了HV指标。'),('2505.20650v1','FinTagging: An LLM-ready Benchmark for Extracting and Structuring Financial Information','We introduce FinTagging, the first full-scope, table-aware XBRL benchmark\ndesigned to evaluate the structured information extraction and semantic\nalignment capabilities of large language models (LLMs) in the context of\nXBRL-based financial reporting. Unlike prior benchmarks that oversimplify XBRL\ntagging as flat multi-class classification and focus solely on narrative text,\nFinTagging decomposes the XBRL tagging problem into two subtasks: FinNI for\nfinancial entity extraction and FinCL for taxonomy-driven concept alignment. It\nrequires models to jointly extract facts and align them with the full 10k+\nUS-GAAP taxonomy across both unstructured text and structured tables, enabling\nrealistic, fine-grained evaluation. We assess a diverse set of LLMs under\nzero-shot settings, systematically analyzing their performance on both subtasks\nand overall tagging accuracy. Our results reveal that, while LLMs demonstrate\nstrong generalization in information extraction, they struggle with\nfine-grained concept alignment, particularly in disambiguating closely related\ntaxonomy entries. These findings highlight the limitations of existing LLMs in\nfully automating XBRL tagging and underscore the need for improved semantic\nreasoning and schema-aware modeling to meet the demands of accurate financial\ndisclosure. Code is available at our GitHub repository and data is at our\nHugging Face repository.','Yan Wang, Yang Ren, Lingfei Qian, Xueqing Peng, Keyi Wang, Yi Han, Dongji Feng, Xiao-Yang Liu, Jimin Huang, Qianqian Xie','2025-05-27','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.20650v1','该论文介绍了FinTagging，这是第一个全面、表格感知的XBRL基准，旨在评估大型语言模型（LLMs）在XBRL财务报告背景下的结构化信息提取和语义对齐能力。通过将XBRL标记问题分解为两个子任务：FinNI用于财务实体提取和FinCL用于基于分类法的概念对齐，要求模型在非结构化文本和结构化表格中联合提取事实并将其与完整的10k+ US-GAAP分类法对齐，从而实现了现实、细粒度的评估。研究结果表明，虽然LLMs在信息提取方面表现出很强的泛化能力，但在细粒度概念对齐方面存在困难，特别是在消除密切相关的分类法条目时。'),('2505.20653v1','RoGA: Towards Generalizable Deepfake Detection through Robust Gradient Alignment','Recent advancements in domain generalization for deepfake detection have\nattracted significant attention, with previous methods often incorporating\nadditional modules to prevent overfitting to domain-specific patterns. However,\nsuch regularization can hinder the optimization of the empirical risk\nminimization (ERM) objective, ultimately degrading model performance. In this\npaper, we propose a novel learning objective that aligns generalization\ngradient updates with ERM gradient updates. The key innovation is the\napplication of perturbations to model parameters, aligning the ascending points\nacross domains, which specifically enhances the robustness of deepfake\ndetection models to domain shifts. This approach effectively preserves\ndomain-invariant features while managing domain-specific characteristics,\nwithout introducing additional regularization. Experimental results on multiple\nchallenging deepfake detection datasets demonstrate that our gradient alignment\nstrategy outperforms state-of-the-art domain generalization techniques,\nconfirming the efficacy of our method. The code is available at\nhttps://github.com/Lynn0925/RoGA.','Lingyu Qiu, Ke Jiang, Xiaoyang Tan','2025-05-27','cs.CV','深度伪造检测','http://arxiv.org/pdf/2505.20653v1','本文提出了一种新颖的学习目标，通过对模型参数引入扰动，使得梯度更新在不同领域之间对齐，增强了深度伪造检测模型对领域转移的鲁棒性，同时保留了领域不变特征和管理领域特定特征。'),('2505.20658v1','Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge','Temporal Logic (TL), especially Signal Temporal Logic (STL), enables precise\nformal specification, making it widely used in cyber-physical systems such as\nautonomous driving and robotics. Automatically transforming NL into STL is an\nattractive approach to overcome the limitations of manual transformation, which\nis time-consuming and error-prone. However, due to the lack of datasets,\nautomatic transformation currently faces significant challenges and has not\nbeen fully explored. In this paper, we propose an NL-STL dataset named\nSTL-Diversity-Enhanced (STL-DivEn), which comprises 16,000 samples enriched\nwith diverse patterns. To develop the dataset, we first manually create a\nsmall-scale seed set of NL-STL pairs. Next, representative examples are\nidentified through clustering and used to guide large language models (LLMs) in\ngenerating additional NL-STL pairs. Finally, diversity and accuracy are ensured\nthrough rigorous rule-based filters and human validation. Furthermore, we\nintroduce the Knowledge-Guided STL Transformation (KGST) framework, a novel\napproach for transforming natural language into STL, involving a\ngenerate-then-refine process based on external knowledge. Statistical analysis\nshows that the STL-DivEn dataset exhibits more diversity than the existing\nNL-STL dataset. Moreover, both metric-based and human evaluations indicate that\nour KGST approach outperforms baseline models in transformation accuracy on\nSTL-DivEn and DeepSTL datasets.','Yue Fang, Zhi Jin, Jie An, Hongshen Chen, Xiaohong Chen, Naijun Zhan','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20658v1','本文提出了一个NL-STL数据集STL-Diversity-Enhanced（STL-DivEn），包含16,000个样本，通过多样化模式丰富了数据集。引入了Knowledge-Guided STL Transformation（KGST）框架，通过外部知识进行生成和优化，提高了自然语言到STL的转换准确性。'),('2505.20659v1','An Optimisation Framework for Unsupervised Environment Design','For reinforcement learning agents to be deployed in high-risk settings, they\nmust achieve a high level of robustness to unfamiliar scenarios. One method for\nimproving robustness is unsupervised environment design (UED), a suite of\nmethods aiming to maximise an agent\\\'s generalisability across configurations of\nan environment. In this work, we study UED from an optimisation perspective,\nproviding stronger theoretical guarantees for practical settings than prior\nwork. Whereas previous methods relied on guarantees if they reach convergence,\nour framework employs a nonconvex-strongly-concave objective for which we\nprovide a provably convergent algorithm in the zero-sum setting. We empirically\nverify the efficacy of our method, outperforming prior methods in a number of\nenvironments with varying difficulties.','Nathan Monette, Alistair Letcher, Michael Beukman, Matthew T. Jackson, Alexander Rutherford, Alexander D. Goldie, Jakob N. Foerster','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.20659v1','本文研究了一种名为无监督环境设计（UED）的方法，旨在提高强化学习代理在陌生场景下的鲁棒性。通过优化方法，提供了比以往更强的理论保证，并在零和设置中提供了可证明收敛的算法。实验证实了该方法的有效性，优于以往方法在多个难度不同的环境中。'),('2505.20660v1','BacktrackAgent: Enhancing GUI Agent with Error Detection and Backtracking Mechanism','Graphical User Interface (GUI) agents have gained substantial attention due\nto their impressive capabilities to complete tasks through multiple\ninteractions within GUI environments. However, existing agents primarily focus\non enhancing the accuracy of individual actions and often lack effective\nmechanisms for detecting and recovering from errors. To address these\nshortcomings, we propose the BacktrackAgent, a robust framework that\nincorporates a backtracking mechanism to improve task completion efficiency.\nBacktrackAgent includes verifier, judger, and reflector components as modules\nfor error detection and recovery, while also applying judgment rewards to\nfurther enhance the agent\\\'s performance. Additionally, we develop a training\ndataset specifically designed for the backtracking mechanism, which considers\nthe outcome pages after action executions. Experimental results show that\nBacktrackAgent has achieved performance improvements in both task success rate\nand step accuracy on Mobile3M and Auto-UI benchmarks. Our data and code will be\nreleased upon acceptance.','Qinzhuo Wu, Pengzhi Gao, Wei Liu, Jian Luan','2025-05-27','cs.CL','强化学习','http://arxiv.org/pdf/2505.20660v1','该论文提出了一种名为BacktrackAgent的框架，通过引入回溯机制来改善任务完成效率，包括错误检测和恢复模块，并应用判断奖励来提高代理的性能。实验结果表明BacktrackAgent在Mobile3M和Auto-UI基准测试中在任务成功率和步骤准确性方面取得了性能改进。'),('2505.20662v1','AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage','Efficient experiment reproduction is critical to accelerating progress in\nartificial intelligence. However, the inherent complexity of method design and\ntraining procedures presents substantial challenges for automation. Notably,\nreproducing experiments often requires implicit domain-specific knowledge not\nexplicitly documented in the original papers. To address this, we introduce the\npaper lineage algorithm, which identifies and extracts implicit knowledge from\nthe relevant references cited by the target paper. Building on this idea, we\npropose AutoReproduce, a multi-agent framework capable of automatically\nreproducing experiments described in research papers in an end-to-end manner.\nAutoReproduce enhances code executability by generating unit tests alongside\nthe reproduction process. To evaluate the reproduction capability, we construct\nReproduceBench, a benchmark annotated with verified implementations, and\nintroduce novel evaluation metrics to assess both the reproduction and\nexecution fidelity. Experimental results demonstrate that AutoReproduce\noutperforms the existing strong agent baselines on all five evaluation metrics\nby a peak margin of over $70\\%$. In particular, compared to the official\nimplementations, AutoReproduce achieves an average performance gap of $22.1\\%$\non $89.74\\%$ of the executable experiment runs. The code will be available at\nhttps://github.com/AI9Stars/AutoReproduce.','Xuanle Zhao, Zilin Sang, Yuxuan Li, Qi Shi, Shuo Wang, Duzhen Zhang, Xu Han, Zhiyuan Liu, Maosong Sun','2025-05-27','cs.AI','实验复现/自动化','http://arxiv.org/pdf/2505.20662v1','该论文介绍了一种新的算法和框架，名为AutoReproduce，可以自动复现研究论文中描述的实验，并生成单元测试以增强代码的可执行性。实验结果表明，AutoReproduce在五个评估指标上均优于现有的强基线代理，并且与官方实现相比，在可执行实验运行的89.74%上平均性能差距为22.1%。'),('2505.20663v1','TeroSeek: An AI-Powered Knowledge Base and Retrieval Generation Platform for Terpenoid Research','Terpenoids are a crucial class of natural products that have been studied for\nover 150 years, but their interdisciplinary nature (spanning chemistry,\npharmacology, and biology) complicates knowledge integration. To address this,\nthe authors developed TeroSeek, a curated knowledge base (KB) built from two\ndecades of terpenoid literature, coupled with an AI-powered question-answering\nchatbot and web service. Leveraging a retrieval-augmented generation (RAG)\nframework, TeroSeek provides structured, high-quality information and\noutperforms general-purpose large language models (LLMs) in terpenoid-related\nqueries. It serves as a domain-specific expert tool for multidisciplinary\nresearch and is publicly available at http://teroseek.qmclab.com.','Xu Kang, Siqi Jiang, Kangwei Xu, Jiahao Li, Ruibo Wu','2025-05-27','cs.IR','自然语言处理','http://arxiv.org/pdf/2505.20663v1','该论文介绍了一种名为TeroSeek的知识库，利用人工智能技术构建了一个基于两个多年的萜烯类文献的问答聊天机器人和网络服务。通过检索增强生成（RAG）框架，TeroSeek提供了结构化、高质量的信息，并在萜烯相关查询中表现优于通用大型语言模型（LLMs）。它作为一个领域专家工具，为跨学科研究提供支持。'),('2505.20664v1','Self-Route: Automatic Mode Switching via Capability Estimation for Efficient Reasoning','While reasoning-augmented large language models (RLLMs) significantly enhance\ncomplex task performance through extended reasoning chains, they inevitably\nintroduce substantial unnecessary token consumption, particularly for simpler\nproblems where Short Chain-of-Thought (Short CoT) suffices. This overthinking\nphenomenon leads to inefficient resource usage without proportional accuracy\ngains. To address this issue, we propose Self-Route, a dynamic reasoning\nframework that automatically selects between general and reasoning modes based\non model capability estimation. Our approach introduces a lightweight\npre-inference stage to extract capability-aware embeddings from hidden layer\nrepresentations, enabling real-time evaluation of the model\\\'s ability to solve\nproblems. We further construct Gradient-10K, a model difficulty\nestimation-based dataset with dense complexity sampling, to train the router\nfor precise capability boundary detection. Extensive experiments demonstrate\nthat Self-Route achieves comparable accuracy to reasoning models while reducing\ntoken consumption by 30-55\\% across diverse benchmarks. The proposed framework\ndemonstrates consistent effectiveness across models with different parameter\nscales and reasoning paradigms, highlighting its general applicability and\npractical value.','Yang He, Xiao Ding, Bibo Cai, Yufei Zhang, Kai Xiong, Zhouhao Sun, Bing Qin, Ting Liu','2025-05-27','cs.CL','LLM (Reasoning-augmented large language models)','http://arxiv.org/pdf/2505.20664v1','该论文提出了一种名为Self-Route的动态推理框架，可以根据模型能力估计自动选择一般模式和推理模式，以解决RLLMs在简单问题上不必要的token消耗问题。他们还构建了一个基于模型难度估计的数据集Gradient-10K，用于训练路由器进行准确的能力边界检测。实验证明，Self-Route在各种基准测试中实现了与推理模型相当的准确性，同时将token消耗降低了30-55%。'),('2505.20666v1','Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers','We propose a novel framework, Continuous_Time Attention, which infuses\npartial differential equations (PDEs) into the Transformer\\\'s attention\nmechanism to address the challenges of extremely long input sequences. Instead\nof relying solely on a static attention matrix, we allow attention weights to\nevolve over a pseudo_time dimension via diffusion, wave, or reaction_diffusion\ndynamics. This mechanism systematically smooths local noise, enhances\nlong_range dependencies, and stabilizes gradient flow. Theoretically, our\nanalysis shows that PDE_based attention leads to better optimization landscapes\nand polynomial rather than exponential decay of distant interactions.\nEmpirically, we benchmark our method on diverse experiments_demonstrating\nconsistent gains over both standard and specialized long sequence Transformer\nvariants. Our findings highlight the potential of PDE_based formulations to\nenrich attention mechanisms with continuous_time dynamics and global coherence.','Yukun Zhang, Xueqing Zhou','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20666v1','该论文提出了一种新颖的框架，Continuous_Time Attention，将偏微分方程（PDEs）融入Transformer的注意力机制中，以解决极长输入序列的挑战。通过扩散、波动或反应扩散动态，使注意力权重在伪时间维度上演变，从而系统地平滑局部噪声，增强长距离依赖性，并稳定梯度流。理论上，他们的分析表明，基于PDE的注意力导致更好的优化景观和远距离交互的多项式而不是指数衰减。在实证方面，他们在各种实验中对他们的方法进行基准测试，展示了与标准和专门的长序列Transformer变体相比的一致收益。他们的发现突显了基于PDE的公式丰富注意力机制的潜力，具有连续时间动态和全局连贯性。'),('2505.20670v1','MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning in Tool Learning','Complex tasks involving tool integration pose significant challenges for\nLarge Language Models (LLMs), leading to the emergence of multi-agent workflows\nas a promising solution. Reflection has emerged as an effective strategy for\ncorrecting erroneous trajectories in agentic workflows. However, existing\napproaches only exploit such capability in the post-action stage, where the\nagent observes the execution outcomes. We argue that, like humans, LLMs can\nalso engage in reflection before action execution: the agent can anticipate\nundesirable outcomes from its own decisions, which not only provides a\nnecessarily complementary perspective to evaluate the decision but also\nprevents the propagation of errors throughout the trajectory. In this paper, we\npropose MIRROR, a framework that consists of both intra-reflection, which\ncritically assesses intended actions before execution, and inter-reflection,\nwhich further adjusts the trajectory based on observations. This design\nsystematically leverages LLM reflection capabilities to eliminate and rectify\nerroneous actions on a more comprehensive scope. Evaluations on both the\nStableToolBench and TravelPlanner benchmarks demonstrate MIRROR\\\'s superior\nperformance, achieving state-of-the-art results compared to existing\napproaches.','Zikang Guo, Benfeng Xu, Xiaorui Wang, Zhendong Mao','2025-05-27','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20670v1','本文提出了一个名为MIRROR的框架，通过利用LLM的反思能力，在行动执行前进行内部反思，评估决策，并在观察到结果后进行外部反思，进一步调整行动轨迹，从而消除和纠正错误行动。在StableToolBench和TravelPlanner基准测试中，MIRROR表现出优越的性能，相比现有方法取得了最先进的结果。'),('2505.20671v1','LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation','While reinforcement learning (RL) has achieved notable success in various\ndomains, training effective policies for complex tasks remains challenging.\nAgents often converge to local optima and fail to maximize long-term rewards.\nExisting approaches to mitigate training bottlenecks typically fall into two\ncategories: (i) Automated policy refinement, which identifies critical states\nfrom past trajectories to guide policy updates, but suffers from costly and\nuncertain model training; and (ii) Human-in-the-loop refinement, where human\nfeedback is used to correct agent behavior, but this does not scale well to\nenvironments with large or continuous action spaces. In this work, we design a\nlarge language model-guided policy modulation framework that leverages LLMs to\nimprove RL training without additional model training or human intervention. We\nfirst prompt an LLM to identify critical states from a sub-optimal agent\\\'s\ntrajectories. Based on these states, the LLM then provides action suggestions\nand assigns implicit rewards to guide policy refinement. Experiments across\nstandard RL benchmarks demonstrate that our method outperforms state-of-the-art\nbaselines, highlighting the effectiveness of LLM-based explanations in\naddressing RL training bottlenecks.','Heng Tan, Hua Yan, Yu Yang','2025-05-27','cs.AI','强化学习 (RL)','http://arxiv.org/pdf/2505.20671v1','该论文提出了一种基于大型语言模型的策略调节框架，利用LLM来改进RL训练，无需额外的模型训练或人类干预。通过LLM识别关键状态并提供行动建议，指导策略改进，实验证明该方法优于现有基线方法，有效解决了RL训练中的瓶颈问题。'),('2505.20672v1','GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning','The Abstraction and Reasoning Corpus (ARC) poses a stringent test of general\nAI capabilities, requiring solvers to infer abstract patterns from only a\nhandful of examples. Despite substantial progress in deep learning,\nstate-of-the-art models still achieve accuracy rates of merely 40-55% on 2024\nARC Competition, indicative of a significant gap between their performance and\nhuman-level reasoning. In this work, we seek to bridge that gap by introducing\nan analogy-inspired ARC dataset, GIFARC. Leveraging large language models\n(LLMs) and vision-language models (VLMs), we synthesize new ARC-style tasks\nfrom a variety of GIF images that include analogies. Each new task is paired\nwith ground-truth analogy, providing an explicit mapping between visual\ntransformations and everyday concepts. By embedding robust human-intuitive\nanalogies into ARC-style tasks, GIFARC guides AI agents to evaluate the task\nanalogically before engaging in brute-force pattern search, thus efficiently\nreducing problem complexity and build a more concise and human-understandable\nsolution. We empirically validate that guiding LLM with analogic approach with\nGIFARC affects task-solving approaches of LLMs to align with analogic approach\nof human.','Woochang Sim, Hyunseok Ryu, Kyungmin Choi, Sungwon Han, Sundong Kim','2025-05-27','cs.AI','LLM、自然语言处理','http://arxiv.org/pdf/2505.20672v1','该论文介绍了一种新的数据集 GIFARC，通过引入类比启发的方法，将大型语言模型和视觉-语言模型应用于ARC风格的任务中，从而提高AI代理在ARC任务上的表现。'),('2505.20674v1','Pretraining Language Models to Ponder in Continuous Space','Humans ponder before articulating complex sentence elements, enabling deeper\ncognitive processing through focused effort. In this work, we introduce this\npondering process into language models by repeatedly invoking the forward\nprocess within a single token generation step. During pondering, instead of\ngenerating an actual token sampled from the prediction distribution, the model\nponders by yielding a weighted sum of all token embeddings according to the\npredicted token distribution. The generated embedding is then fed back as input\nfor another forward pass. We show that the model can learn to ponder in this\nway through self-supervised learning, without any human annotations. Our method\nis straightforward and can be seamlessly integrated with various existing\nlanguage models. Experiments across three widely used open-source\narchitectures-GPT-2, Pythia, and LLaMA-and extensive downstream task\nevaluations demonstrate the effectiveness and generality of our method. For\nlanguage modeling tasks, pondering language models achieve performance\ncomparable to vanilla models with twice the number of parameters. On 9\ndownstream benchmarks, our pondering-enhanced Pythia models significantly\noutperform the official Pythia models. Notably, pondering-enhanced Pythia-1B is\ncomparable to TinyLlama-1.1B, which is trained on 10 times more data. The code\nis available at https://github.com/LUMIA-Group/PonderingLM.','Boyi Zeng, Shixiang Song, Siyuan Huang, Yixuan Wang, He Li, Ziwei He, Xinbing Wang, Zhiyu Li, Zhouhan Lin','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20674v1','该论文介绍了一种在语言模型中引入思考过程的方法，通过在单个标记生成步骤中重复调用前向过程，而不是直接生成预测分布中的实际标记。他们通过自监督学习表明，模型可以学会通过这种方式进行思考，而无需任何人类注释。实验证明，这种思考增强的语言模型在多个任务上表现出色。'),('2505.20679v1','SELF-PERCEPT: Introspection Improves Large Language Models\\\' Detection of Multi-Person Mental Manipulation in Conversations','Mental manipulation is a subtle yet pervasive form of abuse in interpersonal\ncommunication, making its detection critical for safeguarding potential\nvictims. However, due to manipulation\\\'s nuanced and context-specific nature,\nidentifying manipulative language in complex, multi-turn, and multi-person\nconversations remains a significant challenge for large language models (LLMs).\nTo address this gap, we introduce the MultiManip dataset, comprising 220\nmulti-turn, multi-person dialogues balanced between manipulative and\nnon-manipulative interactions, all drawn from reality shows that mimic\nreal-world scenarios. For manipulative interactions, it includes 11 distinct\nmanipulations depicting real-life scenarios. We conduct extensive evaluations\nof state-of-the-art LLMs, such as GPT-4o and Llama-3.1-8B, employing various\nprompting strategies. Despite their capabilities, these models often struggle\nto detect manipulation effectively. To overcome this limitation, we propose\nSELF-PERCEPT, a novel, two-stage prompting framework inspired by\nSelf-Perception Theory, demonstrating strong performance in detecting\nmulti-person, multi-turn mental manipulation. Our code and data are publicly\navailable at https://github.com/danushkhanna/self-percept .','Danush Khanna, Pratinav Seth, Sidhaarth Sredharan Murali, Aditya Kumar Guru, Siddharth Shukla, Tanuj Tyagi, Sandeep Chaurasia, Kripabandhu Ghosh','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20679v1','该论文介绍了一种针对人际交流中心理操纵的检测方法，提出了一个新的两阶段提示框架 SELF-PERCEPT，能够有效检测多人、多轮心理操纵。'),('2505.20686v1','Accelerating RL for LLM Reasoning with Optimal Advantage Regression','Reinforcement learning (RL) has emerged as a powerful tool for fine-tuning\nlarge language models (LLMs) to improve complex reasoning abilities. However,\nstate-of-the-art policy optimization methods often suffer from high\ncomputational overhead and memory consumption, primarily due to the need for\nmultiple generations per prompt and the reliance on critic networks or\nadvantage estimates of the current policy. In this paper, we propose $A$*-PO, a\nnovel two-stage policy optimization framework that directly approximates the\noptimal advantage function and enables efficient training of LLMs for reasoning\ntasks. In the first stage, we leverage offline sampling from a reference policy\nto estimate the optimal value function $V$*, eliminating the need for costly\nonline value estimation. In the second stage, we perform on-policy updates\nusing a simple least-squares regression loss with only a single generation per\nprompt. Theoretically, we establish performance guarantees and prove that the\nKL-regularized RL objective can be optimized without requiring complex\nexploration strategies. Empirically, $A$*-PO achieves competitive performance\nacross a wide range of mathematical reasoning benchmarks, while reducing\ntraining time by up to 2$\\times$ and peak memory usage by over 30% compared to\nPPO, GRPO, and REBEL. Implementation of $A$*-PO can be found at\nhttps://github.com/ZhaolinGao/A-PO.','Kianté Brantley, Mingyu Chen, Zhaolin Gao, Jason D. Lee, Wen Sun, Wenhao Zhan, Xuezhou Zhang','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.20686v1','该论文提出了一种名为$A$*-PO的新型两阶段策略优化框架，直接逼近最优优势函数，实现了对LLMs进行高效的推理任务训练。通过离线采样估计最优价值函数$V$*，并使用简单的最小二乘回归损失进行在线策略更新，从而在数学推理基准测试中取得了竞争性表现。'),('2505.20688v1','A False Discovery Rate Control Method Using a Fully Connected Hidden Markov Random Field for Neuroimaging Data','False discovery rate (FDR) control methods are essential for voxel-wise\nmultiple testing in neuroimaging data analysis, where hundreds of thousands or\neven millions of tests are conducted to detect brain regions associated with\ndisease-related changes. Classical FDR control methods (e.g., BH, q-value, and\nLocalFDR) assume independence among tests and often lead to high false\nnon-discovery rates (FNR). Although various spatial FDR control methods have\nbeen developed to improve power, they still fall short in jointly addressing\nthree major challenges in neuroimaging applications: capturing complex spatial\ndependencies, maintaining low variability in both false discovery proportion\n(FDP) and false non-discovery proportion (FNP) across replications, and\nachieving computational scalability for high-resolution data. To address these\nchallenges, we propose fcHMRF-LIS, a powerful, stable, and scalable spatial FDR\ncontrol method for voxel-wise multiple testing. It integrates the local index\nof significance (LIS)-based testing procedure with a novel fully connected\nhidden Markov random field (fcHMRF) designed to model complex spatial\nstructures using a parsimonious parameterization. We develop an efficient\nexpectation-maximization algorithm incorporating mean-field approximation, the\nConditional Random Fields as Recurrent Neural Networks (CRF-RNN) technique, and\npermutohedral lattice filtering, reducing the computational complexity from\nquadratic to linear in the number of tests. Extensive simulations demonstrate\nthat fcHMRF-LIS achieves accurate FDR control, lower FNR, reduced variability\nin FDP and FNP, and a higher number of true positives compared to existing\nmethods. Applied to an FDG-PET dataset from the Alzheimer\\\'s Disease\nNeuroimaging Initiative, fcHMRF-LIS identifies neurobiologically relevant brain\nregions and offers notable advantages in computational efficiency.','Taehyo Kim, Qiran Jia, Mony J. de Leon, Hai Shu','2025-05-27','stat.ML','图像识别','http://arxiv.org/pdf/2505.20688v1','本文提出了一种新的空间FDR控制方法fcHMRF-LIS，用于处理神经影像数据中的多重检验问题。该方法结合了基于局部显著性指数（LIS）的测试程序和一种新颖的全连接隐藏马尔可夫随机场（fcHMRF），能够准确控制FDR、降低FNR、减少FDP和FNP的变异性，并在计算效率上具有显著优势。'),('2505.20691v1','Evidential Deep Active Learning for Semi-Supervised Classification','Semi-supervised classification based on active learning has made significant\nprogress, but the existing methods often ignore the uncertainty estimation (or\nreliability) of the prediction results during the learning process, which makes\nit questionable whether the selected samples can effectively update the model.\nHence, this paper proposes an evidential deep active learning approach for\nsemi-supervised classification (EDALSSC). EDALSSC builds a semi-supervised\nlearning framework to simultaneously quantify the uncertainty estimation of\nlabeled and unlabeled data during the learning process. The uncertainty\nestimation of the former is associated with evidential deep learning, while\nthat of the latter is modeled by combining ignorance information and conflict\ninformation of the evidence from the perspective of the T-conorm operator.\nFurthermore, this article constructs a heuristic method to dynamically balance\nthe influence of evidence and the number of classes on uncertainty estimation\nto ensure that it does not produce counter-intuitive results in EDALSSC. For\nthe sample selection strategy, EDALSSC selects the sample with the greatest\nuncertainty estimation that is calculated in the form of a sum when the\ntraining loss increases in the latter half of the learning process.\nExperimental results demonstrate that EDALSSC outperforms existing\nsemi-supervised and supervised active learning approaches on image\nclassification datasets.','Shenkai Zhao, Xinao Zhang, Lipeng Pan, Xiaobin Xu, Danilo Pelusi','2025-05-27','cs.LG','半监督学习','http://arxiv.org/pdf/2505.20691v1','本文提出了一种基于证据的深度主动学习方法，用于半监督分类，能够同时量化标记和未标记数据的不确定性估计，并通过动态平衡证据和类别数量的影响来选择样本，实验结果表明该方法在图像分类数据集上优于现有的半监督和监督主动学习方法。'),('2505.20692v1','Can we Debias Social Stereotypes in AI-Generated Images? Examining Text-to-Image Outputs and User Perceptions','Recent advances in generative AI have enabled visual content creation through\ntext-to-image (T2I) generation. However, despite their creative potential, T2I\nmodels often replicate and amplify societal stereotypes -- particularly those\nrelated to gender, race, and culture -- raising important ethical concerns.\nThis paper proposes a theory-driven bias detection rubric and a Social\nStereotype Index (SSI) to systematically evaluate social biases in T2I outputs.\nWe audited three major T2I model outputs -- DALL-E-3, Midjourney-6.1, and\nStability AI Core -- using 100 queries across three categories -- geocultural,\noccupational, and adjectival. Our analysis reveals that initial outputs are\nprone to include stereotypical visual cues, including gendered professions,\ncultural markers, and western beauty norms. To address this, we adopted our\nrubric to conduct targeted prompt refinement using LLMs, which significantly\nreduced bias -- SSI dropped by 61% for geocultural, 69% for occupational, and\n51% for adjectival queries. We complemented our quantitative analysis through a\nuser study examining perceptions, awareness, and preferences around\nAI-generated biased imagery. Our findings reveal a key tension -- although\nprompt refinement can mitigate stereotypes, it can limit contextual alignment.\nInterestingly, users often perceived stereotypical images to be more aligned\nwith their expectations. We discuss the need to balance ethical debiasing with\ncontextual relevance and call for T2I systems that support global diversity and\ninclusivity while not compromising the reflection of real-world social\ncomplexity.','Saharsh Barve, Andy Mao, Jiayue Melissa Shi, Prerna Juneja, Koustuv Saha','2025-05-27','cs.HC','生成模型/偏见检测/伦理问题','http://arxiv.org/pdf/2505.20692v1','本论文提出了一个基于理论的偏见检测标准和社会刻板印象指数（SSI），以系统评估T2I输出中的社会偏见。通过对三个主要T2I模型输出进行审计，发现初始输出往往包含刻板印象的视觉线索，包括性别职业、文化标志和西方美丽标准。通过采用LLM进行有针对性的提示精炼，成功降低了偏见。用户研究结果显示，虽然提示精炼可以减少刻板印象，但可能限制上下文对齐。'),('2505.20693v1','Phir Hera Fairy: An English Fairytaler is a Strong Faker of Fluent Speech in Low-Resource Indian Languages','What happens when an English Fairytaler is fine-tuned on Indian languages? We\nevaluate how the English F5-TTS model adapts to 11 Indian languages, measuring\npolyglot fluency, voice-cloning, style-cloning, and code-mixing. We compare:\n(i) training from scratch, (ii) fine-tuning English F5 on Indian data, and\n(iii) fine-tuning on both Indian and English data to prevent forgetting.\nFine-tuning with only Indian data proves most effective and the resultant IN-F5\nis a near-human polyglot; that enables speakers of one language (e.g., Odia) to\nfluently speak in another (e.g., Hindi). Our results show English pretraining\naids low-resource TTS in reaching human parity. To aid progress in other\nlow-resource languages, we study data-constrained setups and arrive at a\ncompute optimal strategy. Finally, we show IN-F5 can synthesize unseen\nlanguages like Bhojpuri and Tulu using a human-in-the-loop approach for\nzero-resource TTS via synthetic data generation.','Praveen Srinivasa Varadhan, Srija Anand, Soma Siddhartha, Mitesh M. Khapra','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20693v1','该论文研究了将英语故事生成模型Fine-tuned到印度语言上的效果，通过评估多语流畅度、语音克隆、风格克隆和代码混合等指标。研究表明，仅使用印度数据进行Fine-tuning效果最好，生成的IN-F5接近人类多语者水平，可以帮助低资源TTS达到人类水平。'),('2505.20694v1','Temporal Saliency-Guided Distillation: A Scalable Framework for Distilling Video Datasets','Dataset distillation (DD) has emerged as a powerful paradigm for dataset\ncompression, enabling the synthesis of compact surrogate datasets that\napproximate the training utility of large-scale ones. While significant\nprogress has been achieved in distilling image datasets, extending DD to the\nvideo domain remains challenging due to the high dimensionality and temporal\ncomplexity inherent in video data. Existing video distillation (VD) methods\noften suffer from excessive computational costs and struggle to preserve\ntemporal dynamics, as na\\\"ive extensions of image-based approaches typically\nlead to degraded performance. In this paper, we propose a novel uni-level video\ndataset distillation framework that directly optimizes synthetic videos with\nrespect to a pre-trained model. To address temporal redundancy and enhance\nmotion preservation, we introduce a temporal saliency-guided filtering\nmechanism that leverages inter-frame differences to guide the distillation\nprocess, encouraging the retention of informative temporal cues while\nsuppressing frame-level redundancy. Extensive experiments on standard video\nbenchmarks demonstrate that our method achieves state-of-the-art performance,\nbridging the gap between real and distilled video data and offering a scalable\nsolution for video dataset compression.','Xulin Gu, Xinhao Zhong, Zhixing Wei, Yimin Zhou, Shuoyang Sun, Bin Chen, Hongpeng Wang, Yuan Luo','2025-05-27','cs.CV','视频处理','http://arxiv.org/pdf/2505.20694v1','本文提出了一种新颖的单级视频数据集精炼框架，直接优化合成视频以逼近预训练模型的效果。通过引入一种基于时间重复性的滤波机制，利用帧间差异来引导精炼过程，鼓励保留信息丰富的时间线索，同时抑制帧级冗余。实验证明，该方法在标准视频基准上实现了最先进的性能，弥合了真实视频数据与精炼视频数据之间的差距，为视频数据集压缩提供了可扩展的解决方案。'),('2505.20697v1','Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series','The field of hypothesis generation promises to reduce costs in neuroscience\nby narrowing the range of interventional studies needed to study various\nphenomena. Existing machine learning methods can generate scientific hypotheses\nfrom complex datasets, but many approaches assume causal relationships are\nstatic over time, limiting their applicability to systems with dynamic,\nstate-dependent behavior, such as the brain. While some techniques attempt\ndynamic causal discovery through factor models, they often restrict\nrelationships to linear patterns or impose other simplifying assumptions. We\npropose a novel method that models dynamic graphs as a conditionally weighted\nsuperposition of static graphs, where each static graph can capture nonlinear\nrelationships. This approach enables the detection of complex, time-varying\ninteractions between variables beyond linear limitations. Our method improves\nf1-scores of predicted dynamic causal patterns by roughly 22-28% on average\nover baselines in some of our experiments, with some improvements reaching well\nover 60%. A case study on real brain data demonstrates our method\\\'s ability to\nuncover relationships linked to specific behavioral states, offering valuable\ninsights into neural dynamics.','Zachary C. Brown, David Carlson','2025-05-27','cs.LG','神经科学、动态图建模、因果推断','http://arxiv.org/pdf/2505.20697v1','该论文提出了一种新颖的方法，将动态图建模为条件加权的静态图的叠加，从而能够检测变量之间复杂、时变的相互作用，超越线性限制。在一些实验中，该方法将预测的动态因果模式的f1分数平均提高了约22-28%，有些实验中甚至提高了超过60%。通过对真实脑数据的案例研究，展示了该方法揭示与特定行为状态相关的关系，提供了有价值的神经动态洞见。'),('2505.20698v1','Sparsified State-Space Models are Efficient Highway Networks','State-space models (SSMs) offer a promising architecture for sequence\nmodeling, providing an alternative to Transformers by replacing expensive\nself-attention with linear recurrences. In this paper, we propose a simple yet\neffective trick to enhance SSMs within given computational budgets by\nsparsifying them. Our intuition is that tokens in SSMs are highly redundant due\nto gradual recurrent updates, and dense recurrence operations block the\ndelivery of past information. In particular, we observe that upper layers of\nSSMs tend to be more redundant as they encode global information, while lower\nlayers encode local information. Motivated by this, we introduce Simba, a\nhierarchical sparsification method for SSMs based on token pruning. Simba\nsparsifies upper layers more than lower layers, encouraging the upper layers to\nbehave like highways. To achieve this, we propose a novel token pruning\ncriterion for SSMs, measuring the global impact of tokens on the final output\nby accumulating local recurrences. We demonstrate that Simba outperforms the\nbaseline model, Mamba, with the same FLOPS in various natural language tasks.\nMoreover, we illustrate the effect of highways, showing that Simba not only\nenhances efficiency but also improves the information flow across long\nsequences. Code is available at https://github.com/woominsong/Simba.','Woomin Song, Jihoon Tack, Sangwoo Mo, Seunghyuk Oh, Jinwoo Shin','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20698v1','本文提出了一种简单而有效的方法，通过稀疏化状态空间模型（SSMs）来增强序列建模，以在给定的计算预算内提高性能。他们引入了一种基于令牌修剪的层次稀疏化方法Simba，通过测量令牌对最终输出的全局影响来实现这一目标。实验证明，Simba在各种自然语言任务中优于基线模型Mamba，同时提高了长序列中的信息流动。'),('2505.20700v1','Beyond Templates: Dynamic Adaptation of Reasoning Demonstrations via Feasibility-Aware Exploration','Large language models (LLMs) have shown remarkable reasoning capabilities,\nyet aligning such abilities to small language models (SLMs) remains a challenge\ndue to distributional mismatches and limited model capacity. Existing reasoning\ndatasets, typically designed for powerful LLMs, often lead to degraded\nperformance when directly applied to weaker models. In this work, we introduce\nDynamic Adaptation of Reasoning Trajectories (DART), a novel data adaptation\nframework that bridges the capability gap between expert reasoning trajectories\nand diverse SLMs. Instead of uniformly imitating expert steps, DART employs a\nselective imitation strategy guided by step-wise adaptability estimation via\nsolution simulation. When expert steps surpass the student\\\'s capacity --\nsignaled by an Imitation Gap -- the student autonomously explores alternative\nreasoning paths, constrained by outcome consistency. We validate DART across\nmultiple reasoning benchmarks and model scales, demonstrating that it\nsignificantly improves generalization and data efficiency over static\nfine-tuning. Our method enhances supervision quality by aligning training\nsignals with the student\\\'s reasoning capabilities, offering a scalable solution\nfor reasoning alignment in resource-constrained models.','Yong Wu, Weihang Pan, Ke Li, Chen Binhui, Ping Li, Binbin Lin','2025-05-27','cs.CL','大语言模型（LLM）/推理对齐/数据适应','http://arxiv.org/pdf/2505.20700v1','该论文介绍了一种名为DART的新颖数据适应框架，旨在弥合专家推理轨迹与各种SLMs之间的能力差距。DART通过解决方案模拟引导的逐步适应性估计，采用选择性模仿策略，使学生在专家步骤超过其能力时自主探索替代推理路径，从而提高泛化性能和数据效率。'),('2505.20705v1','Time-Series Learning for Proactive Fault Prediction in Distributed Systems with Deep Neural Structures','This paper addresses the challenges of fault prediction and delayed response\nin distributed systems by proposing an intelligent prediction method based on\ntemporal feature learning. The method takes multi-dimensional performance\nmetric sequences as input. We use a Gated Recurrent Unit (GRU) to model the\nevolution of system states over time. An attention mechanism is then applied to\nenhance key temporal segments, improving the model\\\'s ability to identify\npotential faults. On this basis, a feedforward neural network is designed to\nperform the final classification, enabling early warning of system failures. To\nvalidate the effectiveness of the proposed approach, comparative experiments\nand ablation analyses were conducted using data from a large-scale real-world\ncloud system. The experimental results show that the model outperforms various\nmainstream time-series models in terms of Accuracy, F1-Score, and AUC. This\ndemonstrates strong prediction capability and stability. Furthermore, the loss\nfunction curve confirms the convergence and reliability of the training\nprocess. It indicates that the proposed method effectively learns system\nbehavior patterns and achieves efficient fault detection.','Yang Wang, Wenxuan Zhu, Xuehui Quan, Heyi Wang, Chang Liu, Qiyuan Wu','2025-05-27','cs.DC','强化学习','http://arxiv.org/pdf/2505.20705v1','该论文提出了一种基于时间特征学习的智能预测方法，用于解决分布式系统中的故障预测和延迟响应挑战。该方法以多维性能指标序列作为输入，使用门控循环单元（GRU）对系统状态随时间的演变进行建模，应用注意力机制增强关键时间段，设计前馈神经网络进行最终分类，实现系统故障的早期预警。'),('2505.20707v1','Dissecting Physics Reasoning in Small Language Models: A Multi-Dimensional Analysis from an Educational Perspective','Small Language Models (SLMs) offer computational efficiency and\naccessibility, making them promising for educational applications. However,\ntheir capacity for complex reasoning, particularly in domains such as physics,\nremains underexplored. This study investigates the high school physics\nreasoning capabilities of state-of-the-art SLMs (under 4 billion parameters),\nincluding instruct versions of Llama 3.2, Phi 4 Mini, Gemma 3, and Qwen series.\nWe developed a comprehensive physics dataset from the OpenStax High School\nPhysics textbook, annotated according to Bloom\\\'s Taxonomy, with LaTeX and\nplaintext mathematical notations. A novel cultural contextualization approach\nwas applied to a subset, creating culturally adapted problems for Asian,\nAfrican, and South American/Australian contexts while preserving core physics\nprinciples. Using an LLM-as-a-judge framework with Google\\\'s Gemini 2.5 Flash,\nwe evaluated answer and reasoning chain correctness, along with calculation\naccuracy. The results reveal significant differences between the SLMs. Qwen 3\n1.7B achieved high `answer accuracy\\\' (85%), but `fully correct reasoning\\\' was\nsubstantially low (38%). The format of the mathematical notation had a\nnegligible impact on performance. SLMs exhibited varied performance across the\nphysics topics and showed a decline in reasoning quality with increasing\ncognitive and knowledge complexity. In particular, the consistency of reasoning\nwas largely maintained in diverse cultural contexts, especially by better\nperforming models. These findings indicate that, while SLMs can often find\ncorrect answers, their underlying reasoning is frequently flawed, suggesting an\noverreliance on pattern recognition. For SLMs to become reliable educational\ntools in physics, future development must prioritize enhancing genuine\nunderstanding and the generation of sound, verifiable reasoning chains over\nmere answer accuracy.','Nicy Scaria, Silvester John Joseph Kennedy, Diksha Seth, Deepak Subramani','2025-05-27','cs.CL','语言模型（LLM）','http://arxiv.org/pdf/2505.20707v1','本研究调查了最先进的小语言模型（SLMs）在高中物理推理能力方面的表现，包括Llama 3.2、Phi 4 Mini、Gemma 3和Qwen系列的版本。研究发现，虽然SLMs通常可以找到正确答案，但其推理能力经常存在缺陷，表明过度依赖模式识别。未来发展应优先考虑增强真正理解和生成可靠推理链的能力。'),('2505.20715v1','MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding','Video temporal understanding is crucial for multimodal large language models\n(MLLMs) to reason over events in videos. Despite recent advances in general\nvideo understanding, current MLLMs still struggle with fine-grained temporal\nreasoning. While reinforcement learning (RL) has been explored to address this\nissue recently, existing RL approaches remain limited in effectiveness. In this\nwork, we propose MUSEG, a novel RL-based method that enhances temporal\nunderstanding by introducing timestamp-aware multi-segment grounding. MUSEG\nenables MLLMs to align queries with multiple relevant video segments, promoting\nmore comprehensive temporal reasoning. To facilitate effective learning, we\ndesign a customized RL training recipe with phased rewards that progressively\nguides the model toward temporally grounded reasoning. Extensive experiments on\ntemporal grounding and time-sensitive video QA tasks demonstrate that MUSEG\nsignificantly outperforms existing methods and generalizes well across diverse\ntemporal understanding scenarios. View our project at\nhttps://github.com/THUNLP-MT/MUSEG.','Fuwen Luo, Shengfeng Lou, Chi Chen, Ziyue Wang, Chenliang Li, Weizhou Shen, Jiyue Guo, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu','2025-05-27','cs.CV','LLM (大型语言模型)、强化学习','http://arxiv.org/pdf/2505.20715v1','该论文提出了一种名为MUSEG的基于强化学习的方法，通过引入时间戳感知的多段落基础，增强了视频的时间理解能力，从而促进了更全面的时间推理。作者设计了一个定制的强化学习训练方案，逐步引导模型朝着时间上的合理推理方向发展。'),('2505.20718v2','VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Vision-Language Models','We introduce a novel self-improving framework that enhances Embodied Visual\nTracking (EVT) with Vision-Language Models (VLMs) to address the limitations of\ncurrent active visual tracking systems in recovering from tracking failure. Our\napproach combines the off-the-shelf active tracking methods with VLMs\\\'\nreasoning capabilities, deploying a fast visual policy for normal tracking and\nactivating VLM reasoning only upon failure detection. The framework features a\nmemory-augmented self-reflection mechanism that enables the VLM to\nprogressively improve by learning from past experiences, effectively addressing\nVLMs\\\' limitations in 3D spatial reasoning. Experimental results demonstrate\nsignificant performance improvements, with our framework boosting success rates\nby $72\\%$ with state-of-the-art RL-based approaches and $220\\%$ with PID-based\nmethods in challenging environments. This work represents the first integration\nof VLM-based reasoning to assist EVT agents in proactive failure recovery,\noffering substantial advances for real-world robotic applications that require\ncontinuous target monitoring in dynamic, unstructured environments. Project\nwebsite: https://sites.google.com/view/evt-recovery-assistant.','Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong','2025-05-27','cs.CV','强化学习','http://arxiv.org/pdf/2505.20718v2','该论文介绍了一种新颖的自我改进框架，将视觉-语言模型（VLMs）与具有体现视觉跟踪（EVT）相结合，以解决当前主动视觉跟踪系统在恢复跟踪失败方面的局限性。他们的方法结合了现成的主动跟踪方法和VLMs的推理能力，在正常跟踪时部署快速视觉策略，并仅在检测到失败时激活VLMs的推理能力。实验结果表明，在具有挑战性的环境中，他们的框架使成功率提高了72％，比基于最先进的RL方法提高了220％。'),('2505.20721v1','Recurrent Neural Operators: Stable Long-Term PDE Prediction','Neural operators have emerged as powerful tools for learning solution\noperators of partial differential equations. However, in time-dependent\nproblems, standard training strategies such as teacher forcing introduce a\nmismatch between training and inference, leading to compounding errors in\nlong-term autoregressive predictions. To address this issue, we propose\nRecurrent Neural Operators (RNOs)-a novel framework that integrates recurrent\ntraining into neural operator architectures. Instead of conditioning each\ntraining step on ground-truth inputs, RNOs recursively apply the operator to\ntheir own predictions over a temporal window, effectively simulating\ninference-time dynamics during training. This alignment mitigates exposure bias\nand enhances robustness to error accumulation. Theoretically, we show that\nrecurrent training can reduce the worst-case exponential error growth typical\nof teacher forcing to linear growth. Empirically, we demonstrate that\nrecurrently trained Multigrid Neural Operators significantly outperform their\nteacher-forced counterparts in long-term accuracy and stability on standard\nbenchmarks. Our results underscore the importance of aligning training with\ninference dynamics for robust temporal generalization in neural operator\nlearning.','Zaijun Ye, Chen-Song Zhang, Wansheng Wang','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.20721v1','该论文提出了一种新颖的框架，称为循环神经算子（RNOs），将循环训练集成到神经算子架构中，以解决时间相关问题中训练和推断之间的不匹配问题。理论上，循环训练可以将教师强迫引入的最坏情况指数误差增长减少到线性增长。实证上，研究表明，经过循环训练的多网格神经算子在标准基准测试中在长期准确性和稳定性方面明显优于其教师强迫的对应物。'),('2505.20723v1','LeDiFlow: Learned Distribution-guided Flow Matching to Accelerate Image Generation','Enhancing the efficiency of high-quality image generation using Diffusion\nModels (DMs) is a significant challenge due to the iterative nature of the\nprocess. Flow Matching (FM) is emerging as a powerful generative modeling\nparadigm based on a simulation-free training objective instead of a score-based\none used in DMs. Typical FM approaches rely on a Gaussian distribution prior,\nwhich induces curved, conditional probability paths between the prior and\ntarget data distribution. These curved paths pose a challenge for the Ordinary\nDifferential Equation (ODE) solver, requiring a large number of inference calls\nto the flow prediction network. To address this issue, we present Learned\nDistribution-guided Flow Matching (LeDiFlow), a novel scalable method for\ntraining FM-based image generation models using a better-suited prior\ndistribution learned via a regression-based auxiliary model. By initializing\nthe ODE solver with a prior closer to the target data distribution, LeDiFlow\nenables the learning of more computationally tractable probability paths. These\npaths directly translate to fewer solver steps needed for high-quality image\ngeneration at inference time. Our method utilizes a State-Of-The-Art (SOTA)\ntransformer architecture combined with latent space sampling and can be trained\non a consumer workstation. We empirically demonstrate that LeDiFlow remarkably\noutperforms the respective FM baselines. For instance, when operating directly\non pixels, our model accelerates inference by up to 3.75x compared to the\ncorresponding pixel-space baseline. Simultaneously, our latent FM model\nenhances image quality on average by 1.32x in CLIP Maximum Mean Discrepancy\n(CMMD) metric against its respective baseline.','Pascal Zwick, Nils Friederich, Maximilian Beichter, Lennart Hilbert, Ralf Mikut, Oliver Bringmann','2025-05-27','cs.CV','生成模型','http://arxiv.org/pdf/2505.20723v1','该论文介绍了一种名为LeDiFlow的方法，用于训练基于FM的图像生成模型，通过学习更适合的先验分布来减少求解器步骤，从而提高生成效率和图像质量。'),('2505.20725v1','A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs','Efficient maintenance has always been essential for the successful\napplication of engineering systems. However, the challenges to be overcome in\nthe implementation of Industry 4.0 necessitate new paradigms of maintenance\noptimization. Machine learning techniques are becoming increasingly used in\nengineering and maintenance, with reinforcement learning being one of the most\npromising. In this paper, we propose a gamma degradation process together with\na novel maintenance model in which repairs are increasingly imperfect, i.e.,\nthe beneficial effect of system repairs decreases as more repairs are\nperformed, reflecting the degradational behavior of real-world systems. To\ngenerate maintenance policies for this system, we developed a\nreinforcement-learning-based agent using a Double Deep Q-Network architecture.\nThis agent presents two important advantages: it works without a predefined\npreventive threshold, and it can operate in a continuous degradation state\nspace. Our agent learns to behave in different scenarios, showing great\nflexibility. In addition, we performed an analysis of how changes in the main\nparameters of the environment affect the maintenance policy proposed by the\nagent. The proposed approach is demonstrated to be appropriate and to\nsignificatively improve long-run cost as compared with other common maintenance\nstrategies.','Alberto Pliego Marugán, Jesús M. Pinar-Pérez, Fausto Pedro García Márquez','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.20725v1','本文提出了一种新的维护优化模型，结合了伽马退化过程和逐渐不完善的维修策略，利用基于强化学习的双深度Q网络架构来生成维护策略。研究结果表明，该方法相对于其他常见的维护策略显著提高了长期成本效益。'),('2505.20728v1','Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models','Spatial reasoning is a core component of human cognition, enabling\nindividuals to perceive, comprehend, and interact with the physical world. It\nrelies on a nuanced understanding of spatial structures and inter-object\nrelationships, serving as the foundation for complex reasoning and\ndecision-making. To investigate whether current vision-language models (VLMs)\nexhibit similar capability, we introduce Jigsaw-Puzzles, a novel benchmark\nconsisting of 1,100 carefully curated real-world images with high spatial\ncomplexity. Based on this dataset, we design five tasks to rigorously evaluate\nVLMs\\\' spatial perception, structural understanding, and reasoning capabilities,\nwhile deliberately minimizing reliance on domain-specific knowledge to better\nisolate and assess the general spatial reasoning capability. We conduct a\ncomprehensive evaluation across 24 state-of-the-art VLMs. The results show that\neven the strongest model, Gemini-2.5-Pro, achieves only 77.14% overall accuracy\nand performs particularly poorly on the Order Generation task, with only 30.00%\naccuracy, far below the performance exceeding 90% achieved by human\nparticipants. This persistent gap underscores the need for continued progress,\npositioning Jigsaw-Puzzles as a challenging and diagnostic benchmark for\nadvancing spatial reasoning research in VLMs.','Zesen Lyu, Dandan Zhang, Wei Ye, Fangdi Li, Zhihang Jiang, Yao Yang','2025-05-27','cs.AI','视觉-语言模型','http://arxiv.org/pdf/2505.20728v1','该论文研究了空间推理在人类认知中的重要性，提出了一个新的基准测试Jigsaw-Puzzles，用于评估当前视觉-语言模型在空间感知、结构理解和推理能力方面的表现。研究结果表明，即使最强的模型Gemini-2.5-Pro在这些任务中的表现也不及人类参与者，强调了在视觉-语言模型中推进空间推理研究的必要性。'),('2505.20730v1','What LLMs Miss in Recommendations: Bridging the Gap with Retrieval-Augmented Collaborative Signals','User-item interactions contain rich collaborative signals that form the\nbackbone of many successful recommender systems. While recent work has explored\nthe use of large language models (LLMs) for recommendation, it remains unclear\nwhether LLMs can effectively reason over this type of collaborative\ninformation. In this paper, we conduct a systematic comparison between LLMs and\nclassical matrix factorization (MF) models to assess LLMs\\\' ability to leverage\nuser-item interaction data. We further introduce a simple retrieval-augmented\ngeneration (RAG) method that enhances LLMs by grounding their predictions in\nstructured interaction data. Our experiments reveal that current LLMs often\nfall short in capturing collaborative patterns inherent to MF models, but that\nour RAG-based approach substantially improves recommendation\nquality-highlighting a promising direction for future LLM-based recommenders.','Shahrooz Pouryousef','2025-05-27','cs.IR','推荐系统','http://arxiv.org/pdf/2505.20730v1','该论文通过比较大型语言模型（LLMs）和经典矩阵分解（MF）模型的能力，评估LLMs利用用户-物品交互数据的能力。研究者进一步引入了一种简单的检索增强生成（RAG）方法，通过将LLMs的预测基于结构化交互数据来增强其性能。实验结果表明，当前的LLMs在捕捉MF模型固有的协作模式方面存在不足，但我们基于RAG的方法显著提高了推荐质量，为未来基于LLMs的推荐系统指明了一个有前途的方向。'),('2505.20731v1','Semi-supervised Clustering Through Representation Learning of Large-scale EHR Data','Electronic Health Records (EHR) offer rich real-world data for personalized\nmedicine, providing insights into disease progression, treatment responses, and\npatient outcomes. However, their sparsity, heterogeneity, and high\ndimensionality make them difficult to model, while the lack of standardized\nground truth further complicates predictive modeling. To address these\nchallenges, we propose SCORE, a semi-supervised representation learning\nframework that captures multi-domain disease profiles through patient\nembeddings. SCORE employs a Poisson-Adapted Latent factor Mixture (PALM) Model\nwith pre-trained code embeddings to characterize codified features and extract\nmeaningful patient phenotypes and embeddings. To handle the computational\nchallenges of large-scale data, it introduces a hybrid Expectation-Maximization\n(EM) and Gaussian Variational Approximation (GVA) algorithm, leveraging limited\nlabeled data to refine estimates on a vast pool of unlabeled samples. We\ntheoretically establish the convergence of this hybrid approach, quantify GVA\nerrors, and derive SCORE\\\'s error rate under diverging embedding dimensions. Our\nanalysis shows that incorporating unlabeled data enhances accuracy and reduces\nsensitivity to label scarcity. Extensive simulations confirm SCORE\\\'s superior\nfinite-sample performance over existing methods. Finally, we apply SCORE to\npredict disability status for patients with multiple sclerosis (MS) using\npartially labeled EHR data, demonstrating that it produces more informative and\npredictive patient embeddings for multiple MS-related conditions compared to\nexisting approaches.','Linshanshan Wang, Mengyan Li, Zongqi Xia, Molei Liu, Tianxi Cai','2025-05-27','stat.ME','自然语言处理','http://arxiv.org/pdf/2505.20731v1','该论文提出了一个名为SCORE的半监督表示学习框架，通过患者嵌入来捕捉多领域疾病特征。它使用了一种Poisson-Adapted Latent factor Mixture (PALM)模型和预训练的编码嵌入来表征编码特征，并提取有意义的患者表型和嵌入。通过引入混合的期望最大化(EM)和高斯变分近似(GVA)算法，利用有限的标记数据来优化对大量未标记样本的估计。'),('2505.20732v1','SPA-RL: Reinforcing LLM Agents via Stepwise Progress Attribution','Reinforcement learning (RL) holds significant promise for training LLM agents\nto handle complex, goal-oriented tasks that require multi-step interactions\nwith external environments. However, a critical challenge when applying RL to\nthese agentic tasks arises from delayed rewards: feedback signals are typically\navailable only after the entire task is completed. This makes it non-trivial to\nassign delayed rewards to earlier actions, providing insufficient guidance\nregarding environmental constraints and hindering agent training. In this work,\nwe draw on the insight that the ultimate completion of a task emerges from the\ncumulative progress an agent makes across individual steps. We propose Stepwise\nProgress Attribution (SPA), a general reward redistribution framework that\ndecomposes the final reward into stepwise contributions, each reflecting its\nincremental progress toward overall task completion. To achieve this, we train\na progress estimator that accumulates stepwise contributions over a trajectory\nto match the task completion. During policy optimization, we combine the\nestimated per-step contribution with a grounding signal for actions executed in\nthe environment as the fine-grained, intermediate reward for effective agent\ntraining. Extensive experiments on common agent benchmarks (including Webshop,\nALFWorld, and VirtualHome) demonstrate that SPA consistently outperforms the\nstate-of-the-art method in both success rate (+2.5\\% on average) and grounding\naccuracy (+1.9\\% on average). Further analyses demonstrate that our method\nremarkably provides more effective intermediate rewards for RL training. Our\ncode is available at https://github.com/WangHanLinHenry/SPA-RL-Agent.','Hanlin Wang, Chak Tou Leong, Jiashuo Wang, Jian Wang, Wenjie Li','2025-05-27','cs.CL','强化学习','http://arxiv.org/pdf/2505.20732v1','该论文提出了Stepwise Progress Attribution (SPA) 框架，通过将最终奖励分解为逐步贡献来解决强化学习中延迟奖励的问题，从而提高智能体在复杂目标导向任务中的训练效果。'),('2505.20733v1','E2E Process Automation Leveraging Generative AI and IDP-Based Automation Agent: A Case Study on Corporate Expense Processing','This paper presents an intelligent work automation approach in the context of\ncontemporary digital transformation by integrating generative AI and\nIntelligent Document Processing (IDP) technologies with an Automation Agent to\nrealize End-to-End (E2E) automation of corporate financial expense processing\ntasks. While traditional Robotic Process Automation (RPA) has proven effective\nfor repetitive, rule-based simple task automation, it faces limitations in\nhandling unstructured data, exception management, and complex decision-making.\nThis study designs and implements a four-stage integrated process comprising\nautomatic recognition of supporting documents such as receipts via OCR/IDP,\nitem classification based on a policy-driven database, intelligent exception\nhandling supported by generative AI (large language models, LLMs), and\nhuman-in-the-loop final decision-making with continuous system learning through\nan Automation Agent. Applied to a major Korean enterprise (Company S), the\nsystem demonstrated quantitative benefits including over 80% reduction in\nprocessing time for paper receipt expense tasks, decreased error rates, and\nimproved compliance, as well as qualitative benefits such as enhanced accuracy\nand consistency, increased employee satisfaction, and data-driven decision\nsupport. Furthermore, the system embodies a virtuous cycle by learning from\nhuman judgments to progressively improve automatic exception handling\ncapabilities. Empirically, this research confirms that the organic integration\nof generative AI, IDP, and Automation Agents effectively overcomes the\nlimitations of conventional automation and enables E2E automation of complex\ncorporate processes. The study also discusses potential extensions to other\ndomains such as accounting, human resources, and procurement, and proposes\nfuture directions for AI-driven hyper-automation development.','Cheonsu Jeong, Seongmin Sim, Hyoyoung Cho, Sungsu Kim, Byounggwan Shin','2025-05-27','cs.AI','自然语言处理(AI驱动的自动化)','http://arxiv.org/pdf/2505.20733v1','该论文介绍了在当代数字转型背景下，通过将生成式人工智能和智能文档处理技术与自动化代理集成，实现企业财务报销处理任务的端到端自动化。研究设计并实施了一个四阶段的集成流程，包括通过OCR/IDP自动识别支持文件、基于策略驱动数据库的项目分类、由生成式人工智能支持的智能异常处理，以及人在循环中的最终决策。'),('2505.20737v1','RRO: LLM Agent Optimization Through Rising Reward Trajectories','Large language models (LLMs) have exhibited extraordinary performance in a\nvariety of tasks while it remains challenging for them to solve complex\nmulti-step tasks as agents. In practice, agents sensitive to the outcome of\ncertain key steps which makes them likely to fail the task because of a subtle\nmistake in the planning trajectory. Recent approaches resort to calibrating the\nreasoning process through reinforcement learning. They reward or penalize every\nreasoning step with process supervision, as known as Process Reward Models\n(PRMs). However, PRMs are difficult and costly to scale up with a large number\nof next action candidates since they require extensive computations to acquire\nthe training data through the per-step trajectory exploration. To mitigate this\nissue, we focus on the relative reward trend across successive reasoning steps\nand propose maintaining an increasing reward in the collected trajectories for\nprocess supervision, which we term Reward Rising Optimization (RRO).\nSpecifically, we incrementally augment the process supervision until\nidentifying a step exhibiting positive reward differentials, i.e. rising\nrewards, relative to its preceding iteration. This method dynamically expands\nthe search space for the next action candidates, efficiently capturing\nhigh-quality data. We provide mathematical groundings and empirical results on\nthe WebShop and InterCode-SQL benchmarks, showing that our proposed RRO\nachieves superior performance while requiring much less exploration cost.','Zilong Wang, Jingfeng Yang, Sreyashi Nag, Samarth Varshney, Xianfeng Tang, Haoming Jiang, Jingbo Shang, Sheikh Muhammad Sarwar','2025-05-27','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20737v1','该论文提出了一种名为Reward Rising Optimization (RRO)的方法，通过维护在连续推理步骤中不断增加的奖励趋势来优化过程监督，以解决大型语言模型在复杂多步任务中的问题。实验结果表明，RRO方法在WebShop和InterCode-SQL基准测试中表现出色，同时需要更少的探索成本。'),('2505.20738v1','Silencer: From Discovery to Mitigation of Self-Bias in LLM-as-Benchmark-Generator','LLM-as-Benchmark-Generator methods have been widely studied as a supplement\nto human annotators for scalable evaluation, while the potential biases within\nthis paradigm remain underexplored. In this work, we systematically define and\nvalidate the phenomenon of inflated performance in models evaluated on their\nself-generated benchmarks, referred to as self-bias, and attribute it to\nsub-biases arising from question domain, language style, and wrong labels. On\nthis basis, we propose Silencer, a general framework that leverages the\nheterogeneity between multiple generators at both the sample and benchmark\nlevels to neutralize bias and generate high-quality, self-bias-silenced\nbenchmark. Experimental results across various settings demonstrate that\nSilencer can suppress self-bias to near zero, significantly improve evaluation\neffectiveness of the generated benchmark (with an average improvement from\n0.655 to 0.833 in Pearson correlation with high-quality human-annotated\nbenchmark), while also exhibiting strong generalizability.','Peiwen Yuan, Yiwei Li, Shaoxiong Feng, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li','2025-05-27','cs.CL','LLM (Language Model)','http://arxiv.org/pdf/2505.20738v1','本文系统地定义和验证了在自动生成基准测试的模型中存在的性能夸大现象，称为自我偏见，并将其归因于问题领域、语言风格和错误标签等子偏见。在此基础上，提出了Silencer框架，利用多个生成器之间的异质性在样本和基准测试级别中来中和偏见，生成高质量的、自我偏见消除的基准测试。实验结果表明，Silencer可以将自我偏见抑制到接近零，显著提高生成基准测试的评估效果，并表现出强大的泛化能力。'),('2505.20739v1','Detecting Informative Channels: ActionFormer','Human Activity Recognition (HAR) has recently witnessed advancements with\nTransformer-based models. Especially, ActionFormer shows us a new perspectives\nfor HAR in the sense that this approach gives us additional outputs which\ndetect the border of the activities as well as the activity labels.\nActionFormer was originally proposed with its input as image/video. However,\nthis was converted to with its input as sensor signals as well. We analyze this\nextensively in terms of deep learning architectures. Based on the report of\nhigh temporal dynamics which limits the model\\\'s ability to capture subtle\nchanges effectively and of the interdependencies between the spatial and\ntemporal features. We propose the modified ActionFormer which will decrease\nthese defects for sensor signals. The key to our approach lies in accordance\nwith the Sequence-and-Excitation strategy to minimize the increase in\nadditional parameters and opt for the swish activation function to retain the\ninformation about direction in the negative range. Experiments on the WEAR\ndataset show that our method achieves substantial improvement of a 16.01\\% in\nterms of average mAP for inertial data.','Kunpeng Zhao, Asahi Miyazaki, Tsuyoshi Okita','2025-05-27','cs.LG','传感器信号处理','http://arxiv.org/pdf/2505.20739v1','该论文介绍了基于Transformer的ActionFormer模型在人类活动识别中的应用，通过对传感器信号进行输入，提出了修改后的ActionFormer模型以改善其在捕捉微小变化和空间与时间特征之间相互依赖性方面的缺陷。实验结果表明，在WEAR数据集上，该方法在惯性数据的平均mAP方面取得了16.01%的显著改进。'),('2505.20740v1','MSEarth: A Benchmark for Multimodal Scientific Comprehension of Earth Science','The rapid advancement of multimodal large language models (MLLMs) has\nunlocked new opportunities to tackle complex scientific challenges. Despite\nthis progress, their application in addressing earth science problems,\nespecially at the graduate level, remains underexplored. A significant barrier\nis the absence of benchmarks that capture the depth and contextual complexity\nof geoscientific reasoning. Current benchmarks often rely on synthetic datasets\nor simplistic figure-caption pairs, which do not adequately reflect the\nintricate reasoning and domain-specific insights required for real-world\nscientific applications. To address these gaps, we introduce MSEarth, a\nmultimodal scientific benchmark curated from high-quality, open-access\nscientific publications. MSEarth encompasses the five major spheres of Earth\nscience: atmosphere, cryosphere, hydrosphere, lithosphere, and biosphere,\nfeaturing over 7K figures with refined captions. These captions are crafted\nfrom the original figure captions and enriched with discussions and reasoning\nfrom the papers, ensuring the benchmark captures the nuanced reasoning and\nknowledge-intensive content essential for advanced scientific tasks. MSEarth\nsupports a variety of tasks, including scientific figure captioning, multiple\nchoice questions, and open-ended reasoning challenges. By bridging the gap in\ngraduate-level benchmarks, MSEarth provides a scalable and high-fidelity\nresource to enhance the development and evaluation of MLLMs in scientific\nreasoning. The benchmark is publicly available to foster further research and\ninnovation in this field. Resources related to this benchmark can be found at\nhttps://huggingface.co/MSEarth and https://github.com/xiangyu-mm/MSEarth.','Xiangyu Zhao, Wanghan Xu, Bo Liu, Yuhao Zhou, Fenghua Ling, Ben Fei, Xiaoyu Yue, Lei Bai, Wenlong Zhang, Xiao-Ming Wu','2025-05-27','cs.AI','多模态学习、科学推理','http://arxiv.org/pdf/2505.20740v1','该论文介绍了一个名为MSEarth的多模态科学基准，旨在解决地球科学问题中缺乏深度和上下文复杂性的挑战。该基准包含来自高质量科学出版物的超过7K个图表和精炼的标题，支持科学图表标题、多项选择问题和开放式推理挑战等任务。'),('2505.20742v1','\\\'Hello, World!\\\': Making GNNs Talk with LLMs','While graph neural networks (GNNs) have shown remarkable performance across\ndiverse graph-related tasks, their high-dimensional hidden representations\nrender them black boxes. In this work, we propose Graph Lingual Network (GLN),\na GNN built on large language models (LLMs), with hidden representations in the\nform of human-readable text. Through careful prompt design, GLN incorporates\nnot only the message passing module of GNNs but also advanced GNN techniques,\nincluding graph attention and initial residual connection. The\ncomprehensibility of GLN\\\'s hidden representations enables an intuitive analysis\nof how node representations change (1) across layers and (2) under advanced GNN\ntechniques, shedding light on the inner workings of GNNs. Furthermore, we\ndemonstrate that GLN achieves strong zero-shot performance on node\nclassification and link prediction, outperforming existing LLM-based baseline\nmethods.','Sunwoo Kim, Soo Yong Lee, Jaemin Yoo, Kijung Shin','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20742v1','本文提出了一种基于大型语言模型（LLMs）的图语言网络（GLN），其隐藏表示形式为可读的文本，通过精心设计的提示，GLN不仅包含了GNN的消息传递模块，还包括了图注意力和初始残差连接等高级GNN技术。GLN的可理解性使得可以直观分析节点表示在不同层之间以及在高级GNN技术下的变化，揭示了GNN的内部工作原理。此外，作者还展示了GLN在节点分类和链接预测上取得了强大的零样本性能，优于现有的基于LLM的基准方法。'),('2505.20745v1','Foundation Model Hidden Representations for Heart Rate Estimation from Auscultation','Auscultation, particularly heart sound, is a non-invasive technique that\nprovides essential vital sign information. Recently, self-supervised acoustic\nrepresentation foundation models (FMs) have been proposed to offer insights\ninto acoustics-based vital signs. However, there has been little exploration of\nthe extent to which auscultation is encoded in these pre-trained FM\nrepresentations. In this work, using a publicly available phonocardiogram (PCG)\ndataset and a heart rate (HR) estimation model, we conduct a layer-wise\ninvestigation of six acoustic representation FMs: HuBERT, wav2vec2, wavLM,\nWhisper, Contrastive Language-Audio Pretraining (CLAP), and an in-house CLAP\nmodel. Additionally, we implement the baseline method from Nie et al., 2024\n(which relies on acoustic features) and show that overall, representation\nvectors from pre-trained foundation models (FMs) offer comparable performance\nto the baseline. Notably, HR estimation using the representations from the\naudio encoder of the in-house CLAP model outperforms the results obtained from\nthe baseline, achieving a lower mean absolute error (MAE) across various\ntrain/validation/test splits despite the domain mismatch.','Jingping Nie, Dung T. Tran, Karan Thakkar, Vasudha Kowtha, John Huang, Carlos Avendano, Erdrin Azemi, Vikramjit Mitra','2025-05-27','cs.SD','自然语言处理','http://arxiv.org/pdf/2505.20745v1','本研究探讨了自监督声学表示基础模型在听诊方面的应用，通过对六种声学表示基础模型进行分层研究，发现这些模型提供的表示向量在心率估计方面具有可比性，并且一种自研CLAP模型的音频编码器表示在心率估计中表现优异。'),('2505.20749v1','Can Agents Fix Agent Issues?','LLM-based agent systems are emerging as a new software paradigm and have been\nwidely adopted across diverse domains such as medicine, robotics, and\nprogramming. However, maintaining these systems requires substantial effort, as\nthey are inevitably prone to bugs and continually evolve to meet changing\nexternal requirements. Therefore, automatically resolving agent issues (i.e.,\nbug reports or feature requests) is a crucial and challenging task. While\nrecent software engineering (SE) agents (e.g., SWE-agent) have shown promise in\naddressing issues in traditional software systems, it remains unclear how\neffectively they can resolve real-world issues in agent systems, which differ\nsignificantly from traditional software. To fill this gap, we first manually\nanalyze 201 real-world agent issues and identify common categories of agent\nissues. We then spend 500 person-hours constructing AGENTISSUE-BENCH, a\nreproducible benchmark comprising 50 agent issue resolution tasks (each with an\nexecutable environment and failure-triggering tests). We further evaluate\nstate-of-the-art SE agents on AGENTISSUE-BENCH and reveal their limited\neffectiveness (i.e., with only 3.33% - 12.67% resolution rates). These results\nunderscore the unique challenges of maintaining agent systems compared to\ntraditional software, highlighting the need for further research to develop\nadvanced SE agents for resolving agent issues. Data and code are available at\nhttps://alfin06.github.io/AgentIssue-Bench-Leaderboard/#/ .','Alfin Wijaya Rahardja, Junwei Liu, Weitong Chen, Zhenpeng Chen, Yiling Lou','2025-05-27','cs.AI','LLM、软件工程、代理系统','http://arxiv.org/pdf/2505.20749v1','该论文研究了基于LLM的代理系统在自动解决代理系统问题（如错误报告或功能请求）方面的挑战性任务。研究首先对201个真实代理系统问题进行了手动分析，然后构建了包含50个代理问题解决任务的可重现基准，并评估了最先进的SE代理在该基准上的效果，结果显示它们的解决率有限。'),('2505.20751v1','Interactive OT Gym: A Reinforcement Learning-Based Interactive Optical tweezer (OT)-Driven Microrobotics Simulation Platform','Optical tweezers (OT) offer unparalleled capabilities for micromanipulation\nwith submicron precision in biomedical applications. However, controlling\nconventional multi-trap OT to achieve cooperative manipulation of multiple\ncomplex-shaped microrobots in dynamic environments poses a significant\nchallenge. To address this, we introduce Interactive OT Gym, a reinforcement\nlearning (RL)-based simulation platform designed for OT-driven microrobotics.\nOur platform supports complex physical field simulations and integrates haptic\nfeedback interfaces, RL modules, and context-aware shared control strategies\ntailored for OT-driven microrobot in cooperative biological object manipulation\ntasks. This integration allows for an adaptive blend of manual and autonomous\ncontrol, enabling seamless transitions between human input and autonomous\noperation. We evaluated the effectiveness of our platform using a cell\nmanipulation task. Experimental results show that our shared control system\nsignificantly improves micromanipulation performance, reducing task completion\ntime by approximately 67% compared to using pure human or RL control alone and\nachieving a 100% success rate. With its high fidelity, interactivity, low cost,\nand high-speed simulation capabilities, Interactive OT Gym serves as a\nuser-friendly training and testing environment for the development of advanced\ninteractive OT-driven micromanipulation systems and control algorithms. For\nmore details on the project, please see our website\nhttps://sites.google.com/view/otgym','Zongcai Tan amd Dandan Zhang','2025-05-27','cs.RO','强化学习','http://arxiv.org/pdf/2505.20751v1','该论文介绍了一种基于强化学习的模拟平台 Interactive OT Gym，用于光学夹持驱动的微型机器人协作生物对象操纵任务。该平台支持复杂的物理场景模拟，整合了触觉反馈界面、强化学习模块和上下文感知的共享控制策略，实现了人工输入和自主操作之间的无缝过渡。实验结果表明，共享控制系统显著提高了微操作性能，任务完成时间比纯人工或强化学习控制减少了约67%，成功率达到100%。'),('2505.20753v1','Understand, Think, and Answer: Advancing Visual Reasoning with Large Multimodal Models','Large Multimodal Models (LMMs) have recently demonstrated remarkable visual\nunderstanding performance on both vision-language and vision-centric tasks.\nHowever, they often fall short in integrating advanced, task-specific\ncapabilities for compositional reasoning, which hinders their progress toward\ntruly competent general vision models. To address this, we present a unified\nvisual reasoning mechanism that enables LMMs to solve complicated compositional\nproblems by leveraging their intrinsic capabilities (e.g. grounding and visual\nunderstanding capabilities). Different from the previous shortcut learning\nmechanism, our approach introduces a human-like\nunderstanding-thinking-answering process, allowing the model to complete all\nsteps in a single pass forwarding without the need for multiple inferences or\nexternal tools. This design bridges the gap between foundational visual\ncapabilities and general question answering, encouraging LMMs to generate\nfaithful and traceable responses for complex visual reasoning. Meanwhile, we\ncurate 334K visual instruction samples covering both general scenes and\ntext-rich scenes and involving multiple foundational visual capabilities. Our\ntrained model, Griffon-R, has the ability of end-to-end automatic\nunderstanding, self-thinking, and reasoning answers. Comprehensive experiments\nshow that Griffon-R not only achieves advancing performance on complex visual\nreasoning benchmarks including VSR and CLEVR, but also enhances multimodal\ncapabilities across various benchmarks like MMBench and ScienceQA. Data,\nmodels, and codes will be release at\nhttps://github.com/jefferyZhan/Griffon/tree/master/Griffon-R soon.','Yufei Zhan, Hongyin Zhao, Yousong Zhu, Shurong Zheng, Fan Yang, Ming Tang, Jinqiao Wang','2025-05-27','cs.CV','LLM（Large Multimodal Models）','http://arxiv.org/pdf/2505.20753v1','该论文介绍了一种统一的视觉推理机制，使大型多模态模型能够通过利用其内在能力（如基础视觉能力和理解能力）解决复杂的组合问题。他们的方法引入了类似人类的理解-思考-回答过程，使模型能够在单次前向传递中完成所有步骤，而无需多次推理或外部工具。'),('2505.20755v1','Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction','In this paper, we unify more than 10 existing one-step diffusion distillation\napproaches, such as Diff-Instruct, DMD, SIM, SiD, $f$-distill, etc, inside a\ntheory-driven framework which we name the \\textbf{\\emph{Uni-Instruct}}.\nUni-Instruct is motivated by our proposed diffusion expansion theory of the\n$f$-divergence family. Then we introduce key theories that overcome the\nintractability issue of the original expanded $f$-divergence, resulting in an\nequivalent yet tractable loss that effectively trains one-step diffusion models\nby minimizing the expanded $f$-divergence family. The novel unification\nintroduced by Uni-Instruct not only offers new theoretical contributions that\nhelp understand existing approaches from a high-level perspective but also\nleads to state-of-the-art one-step diffusion generation performances. On the\nCIFAR10 generation benchmark, Uni-Instruct achieves record-breaking Frechet\nInception Distance (FID) values of \\textbf{\\emph{1.46}} for unconditional\ngeneration and \\textbf{\\emph{1.38}} for conditional generation. On the\nImageNet-$64\\times 64$ generation benchmark, Uni-Instruct achieves a new SoTA\none-step generation FID of \\textbf{\\emph{1.02}}, which outperforms its 79-step\nteacher diffusion with a significant improvement margin of 1.33 (1.02 vs 2.35).\nWe also apply Uni-Instruct on broader tasks like text-to-3D generation. For\ntext-to-3D generation, Uni-Instruct gives decent results, which slightly\noutperforms previous methods, such as SDS and VSD, in terms of both generation\nquality and diversity. Both the solid theoretical and empirical contributions\nof Uni-Instruct will potentially help future studies on one-step diffusion\ndistillation and knowledge transferring of diffusion models.','Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun','2025-05-27','cs.LG','生成模型','http://arxiv.org/pdf/2505.20755v1','本文提出了一个名为Uni-Instruct的理论驱动框架，统一了10多种现有的一步扩散蒸馏方法，并通过最小化扩展的$f$-divergence家族来有效训练一步扩散模型，取得了领先的生成性能。'),('2505.20759v1','PARTONOMY: Large Multimodal Models with Part-Level Visual Understanding','Real-world objects are composed of distinctive, object-specific parts.\nIdentifying these parts is key to performing fine-grained, compositional\nreasoning-yet, large multimodal models (LMMs) struggle to perform this\nseemingly straightforward task. In this work, we introduce PARTONOMY, an LMM\nbenchmark designed for pixel-level part grounding. We construct PARTONOMY from\nexisting part datasets and our own rigorously annotated set of images,\nencompassing 862 part labels and 534 object labels for evaluation. Unlike\nexisting datasets that simply ask models to identify generic parts, PARTONOMY\nuses specialized concepts (e.g., agricultural airplane), and challenges models\nto compare objects\\\' parts, consider part-whole relationships, and justify\ntextual predictions with visual segmentations. Our experiments demonstrate\nsignificant limitations in state-of-the-art LMMs (e.g., LISA-13B achieves only\n5.9% gIoU), highlighting a critical gap in their part grounding abilities. We\nnote that existing segmentation-enabled LMMs (segmenting LMMs) have two key\narchitectural shortcomings: they use special [SEG] tokens not seen during\npretraining which induce distribution shift, and they discard predicted\nsegmentations instead of using past predictions to guide future ones. To\naddress these deficiencies, we train several part-centric LMMs and propose\nPLUM, a novel segmenting LMM that uses span tagging instead of segmentation\ntokens and that conditions on prior predictions in a feedback loop. We find\nthat pretrained PLUM outperforms existing segmenting LMMs on reasoning\nsegmentation, VQA, and visual hallucination benchmarks. In addition, PLUM\nfinetuned on our proposed Explanatory Part Segmentation task is competitive\nwith segmenting LMMs trained on significantly more segmentation data. Our work\nopens up new avenues towards enabling fine-grained, grounded visual\nunderstanding in LMMs.','Ansel Blume, Jeonghwan Kim, Hyeonjeong Ha, Elen Chatikyan, Xiaomeng Jin, Khanh Duy Nguyen, Nanyun Peng, Kai-Wei Chang, Derek Hoiem, Heng Ji','2025-05-27','cs.CV','LLM','http://arxiv.org/pdf/2505.20759v1','本文介绍了一个名为PARTONOMY的LMM基准测试，旨在进行像素级部件定位。作者发现现有的分割型LMM存在两个关键的架构缺陷，并提出了一种新的分割型LMM（PLUM），在推理分割、VQA和视觉幻觉基准测试上表现优异。'),('2505.20764v1','ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval','Composed image retrieval (CIR) is the task of retrieving a target image\nspecified by a query image and a relative text that describes a semantic\nmodification to the query image. Existing methods in CIR struggle to accurately\nrepresent the image and the text modification, resulting in subpar performance.\nTo address this limitation, we introduce a CIR framework, ConText-CIR, trained\nwith a Text Concept-Consistency loss that encourages the representations of\nnoun phrases in the text modification to better attend to the relevant parts of\nthe query image. To support training with this loss function, we also propose a\nsynthetic data generation pipeline that creates training data from existing CIR\ndatasets or unlabeled images. We show that these components together enable\nstronger performance on CIR tasks, setting a new state-of-the-art in composed\nimage retrieval in both the supervised and zero-shot settings on multiple\nbenchmark datasets, including CIRR and CIRCO. Source code, model checkpoints,\nand our new datasets are available at https://github.com/mvrl/ConText-CIR.','Eric Xing, Pranavi Kolouju, Robert Pless, Abby Stylianou, Nathan Jacobs','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.20764v1','该论文介绍了一种新的组合图像检索框架 ConText-CIR，通过引入 Text Concept-Consistency 损失函数来改善图像和文本修改的表示，从而提高了组合图像检索任务的性能。'),('2505.20765v1','Robust and Explainable Detector of Time Series Anomaly via Augmenting Multiclass Pseudo-Anomalies','Unsupervised anomaly detection in time series has been a pivotal research\narea for decades. Current mainstream approaches focus on learning normality, on\nthe assumption that all or most of the samples in the training set are normal.\nHowever, anomalies in the training set (i.e., anomaly contamination) can be\nmisleading. Recent studies employ data augmentation to generate\npseudo-anomalies and learn the boundary separating the training samples from\nthe augmented samples. Although this approach mitigates anomaly contamination\nif augmented samples mimic unseen real anomalies, it suffers from several\nlimitations. (1) Covering a wide range of time series anomalies is challenging.\n(2) It disregards augmented samples that resemble normal samples (i.e., false\nanomalies). (3) It places too much trust in the labels of training and\naugmented samples. In response, we propose RedLamp, which employs diverse data\naugmentations to generate multiclass pseudo-anomalies and learns the multiclass\nboundary. Such multiclass pseudo-anomalies cover a wide variety of time series\nanomalies. We conduct multiclass classification using soft labels, which\nprevents the model from being overconfident and ensures its robustness against\ncontaminated/false anomalies. The learned latent space is inherently\nexplainable as it is trained to separate pseudo-anomalies into multiclasses.\nExtensive experiments demonstrate the effectiveness of RedLamp in anomaly\ndetection and its robustness against anomaly contamination.','Kohei Obata, Yasuko Matsubara, Yasushi Sakurai','2025-05-27','cs.LG','异常检测','http://arxiv.org/pdf/2505.20765v1','该论文提出了一种名为RedLamp的方法，通过使用多样的数据增强技术生成多类伪异常，并学习多类别边界，以覆盖各种时间序列异常。通过使用软标签进行多类别分类，可以防止模型过度自信，并确保其对受污染/虚假异常的鲁棒性。实验结果表明RedLamp在异常检测方面的有效性和对异常污染的鲁棒性。'),('2505.20767v2','CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models','Faithfulness hallucination are claims generated by a Large Language Model\n(LLM) not supported by contexts provided to the LLM. Lacking assessment\nstandard, existing benchmarks only contain \"factual statements\" that rephrase\nsource materials without marking \"cognitive statements\" that make inference\nfrom the given context, making the consistency evaluation and optimization of\ncognitive statements difficult. Inspired by how an evidence is assessed in the\nlegislative domain, we design a rigorous framework to assess different levels\nof faithfulness of cognitive statements and create a benchmark dataset where we\nreveal insightful statistics. We design an annotation pipeline to create larger\nbenchmarks for different LLMs automatically, and the resulting larger-scale\nCogniBench-L dataset can be used to train accurate cognitive hallucination\ndetection model. We release our model and dataset at:\nhttps://github.com/FUTUREEEEEE/CogniBench','Xiaqiang Tang, Jian Li, Keyu Hu, Du Nan, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie','2025-05-27','cs.CL','LLM (Large Language Model)','http://arxiv.org/pdf/2505.20767v2','该论文提出了一个严格的框架来评估不同级别的认知陈述的忠实度，并创建了一个基准数据集，揭示了有见地的统计数据。他们设计了一个注释管道，自动创建不同LLM的更大基准，最终得到的大规模CogniBench-L数据集可用于训练准确的认知幻觉检测模型。'),('2505.20771v1','Bridging the Gap: Self-Optimized Fine-Tuning for LLM-based Recommender Systems','Recent years have witnessed extensive exploration of Large Language Models\n(LLMs) on the field of Recommender Systems (RS). There are currently two\ncommonly used strategies to enable LLMs to have recommendation capabilities: 1)\nThe \"Guidance-Only\" strategy uses in-context learning to exploit and amplify\nthe inherent semantic understanding and item recommendation capabilities of\nLLMs; 2) The \"Tuning-Only\" strategy uses supervised fine-tuning (SFT) to\nfine-tune LLMs with the aim of fitting them to real recommendation data.\nHowever, neither of these strategies can effectively bridge the gap between the\nknowledge space of LLMs and recommendation, and their performance do not meet\nour expectations.\n  To better enable LLMs to learn recommendation knowledge, we combine the\nadvantages of the above two strategies and proposed a novel \"Guidance+Tuning\"\nmethod called Self-Optimized Fine-Tuning (SOFT), which adopts the idea of\ncurriculum learning. It first employs self-distillation to construct an\nauxiliary easy-to-learn but meaningful dataset from a fine-tuned LLM. Then it\nfurther utilizes a self-adaptive curriculum scheduler to enable LLMs to\ngradually learn from simpler data (self-distilled data) to more challenging\ndata (real RS data). Extensive experiments demonstrate that SOFT significantly\nenhances the recommendation accuracy (37.59\\% on average) of LLM-based methods.\nThe code is available via\nhttps://anonymous.4open.science/r/Self-Optimized-Fine-Tuning-264E','Heng Tang, Feng Liu, Xinbo Chen, Jiawei Chen, Bohao Wang, Changwang Zhang, Jun Wang, Yuegang Sun, Bingde Hu, Can Wang','2025-05-27','cs.IR','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.20771v1','该论文提出了一种名为Self-Optimized Fine-Tuning (SOFT)的方法，结合了\"Guidance-Only\"和\"Tuning-Only\"两种策略，通过自我优化的微调方法，使LLMs能够更好地学习推荐知识，从而显著提高推荐准确性。'),('2505.20772v1','MetaSlot: Break Through the Fixed Number of Slots in Object-Centric Learning','Learning object-level, structured representations is widely regarded as a key\nto better generalization in vision and underpins the design of next-generation\nPre-trained Vision Models (PVMs). Mainstream Object-Centric Learning (OCL)\nmethods adopt Slot Attention or its variants to iteratively aggregate objects\\\'\nsuper-pixels into a fixed set of query feature vectors, termed slots. However,\ntheir reliance on a static slot count leads to an object being represented as\nmultiple parts when the number of objects varies. We introduce MetaSlot, a\nplug-and-play Slot Attention variant that adapts to variable object counts.\nMetaSlot (i) maintains a codebook that holds prototypes of objects in a dataset\nby vector-quantizing the resulting slot representations; (ii) removes duplicate\nslots from the traditionally aggregated slots by quantizing them with the\ncodebook; and (iii) injects progressively weaker noise into the Slot Attention\niterations to accelerate and stabilize the aggregation. MetaSlot is a general\nSlot Attention variant that can be seamlessly integrated into existing OCL\narchitectures. Across multiple public datasets and tasks--including object\ndiscovery and recognition--models equipped with MetaSlot achieve significant\nperformance gains and markedly interpretable slot representations, compared\nwith existing Slot Attention variants.','Hongjia Liu, Rongzhen Zhao, Haohan Chen, Joni Pajarinen','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.20772v1','该论文介绍了一种名为MetaSlot的插拔式Slot Attention变体，可以适应可变的对象数量，提高了视觉任务中的泛化性能和可解释性。'),('2505.20774v1','TimePro: Efficient Multivariate Long-term Time Series Forecasting with Variable- and Time-Aware Hyper-state','In long-term time series forecasting, different variables often influence the\ntarget variable over distinct time intervals, a challenge known as the\nmulti-delay issue. Traditional models typically process all variables or time\npoints uniformly, which limits their ability to capture complex variable\nrelationships and obtain non-trivial time representations. To address this\nissue, we propose TimePro, an innovative Mamba-based model that constructs\nvariate- and time-aware hyper-states. Unlike conventional approaches that\nmerely transfer plain states across variable or time dimensions, TimePro\npreserves the fine-grained temporal features of each variate token and\nadaptively selects the focused time points to tune the plain state. The\nreconstructed hyper-state can perceive both variable relationships and salient\ntemporal information, which helps the model make accurate forecasting. In\nexperiments, TimePro performs competitively on eight real-world long-term\nforecasting benchmarks with satisfactory linear complexity. Code is available\nat https://github.com/xwmaxwma/TimePro.','Xiaowen Ma, Zhenliang Ni, Shuai Xiao, Xinghao Chen','2025-05-27','cs.LG','预测建模 (Time Series Forecasting)','http://arxiv.org/pdf/2505.20774v1','该论文提出了一种名为TimePro的基于Mamba的模型，用于解决长期时间序列预测中的多延迟问题。通过构建变量和时间感知的超状态，TimePro能够准确预测复杂的变量关系和显著的时间信息。'),('2505.20775v1','Non-invasive maturity assessment of iPSC-CMs based on optical maturity characteristics using interpretable AI','Human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) are an\nimportant resource for the identification of new therapeutic targets and\ncardioprotective drugs. After differentiation iPSC-CMs show an immature,\nfetal-like phenotype. Cultivation of iPSC-CMs in lipid-supplemented maturation\nmedium (MM) strongly enhances their structural, metabolic and functional\nphenotype. Nevertheless, assessing iPSC-CM maturation state remains challenging\nas most methods are time consuming and go in line with cell damage or loss of\nthe sample. To address this issue, we developed a non-invasive approach for\nautomated classification of iPSC-CM maturity through interpretable artificial\nintelligence (AI)-based analysis of beat characteristics derived from\nvideo-based motion analysis. In a prospective study, we evaluated 230 video\nrecordings of early-state, immature iPSC-CMs on day 21 after differentiation\n(d21) and more mature iPSC-CMs cultured in MM (d42, MM). For each recording, 10\nfeatures were extracted using Maia motion analysis software and entered into a\nsupport vector machine (SVM). The hyperparameters of the SVM were optimized in\na grid search on 80 % of the data using 5-fold cross-validation. The optimized\nmodel achieved an accuracy of 99.5 $\\pm$ 1.1 % on a hold-out test set. Shapley\nAdditive Explanations (SHAP) identified displacement, relaxation-rise time and\nbeating duration as the most relevant features for assessing maturity level.\nOur results suggest the use of non-invasive, optical motion analysis combined\nwith AI-based methods as a tool to assess iPSC-CMs maturity and could be\napplied before performing functional readouts or drug testing. This may\npotentially reduce the variability and improve the reproducibility of\nexperimental studies.','Fabian Scheurer, Alexander Hammer, Mario Schubert, Robert-Patrick Steiner, Oliver Gamm, Kaomei Guan, Frank Sonntag, Hagen Malberg, Martin Schmidt','2025-05-27','cs.LG','生物医学工程/医学应用','http://arxiv.org/pdf/2505.20775v1','该论文介绍了一种利用可解释的人工智能分析心脏肌细胞成熟度的非侵入式方法，通过视频运动分析提取心跳特征，并使用支持向量机进行分类。研究结果表明，该方法在评估诱导多能干细胞来源心肌细胞（iPSC-CMs）成熟度方面具有很高的准确性。'),('2505.20776v1','SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences','Speculative decoding is a widely adopted technique for accelerating inference\nin large language models (LLMs), but its performance degrades on long inputs\ndue to increased attention cost and reduced draft accuracy. We introduce\nSpecExtend, a drop-in enhancement that improves the performance of speculative\ndecoding on long sequences without any additional training. SpecExtend\nintegrates efficient attention mechanisms such as FlashAttention and Hybrid\nTree Attention into both the draft and target models, reducing latency across\nall stages. To improve draft accuracy and speed, we propose Cross-model\nRetrieval, a novel KV cache update strategy that uses the target model\\\'s\nattention scores to dynamically select relevant context for the draft model.\nExtensive evaluations on three long-context understanding datasets show that\nSpecExtend accelerates standard tree-based speculative decoding by up to 2.22x\nfor inputs up to 16K tokens, providing an effective solution for speculative\ndecoding of long sequences. The code is available at\nhttps://github.com/jycha98/SpecExtend .','Jungyoub Cha, Hyunjong Kim, Sungzoon Cho','2025-05-27','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.20776v1','该论文介绍了一种名为SpecExtend的增强技术，用于改善大型语言模型中长序列的推理性解码性能，通过引入高效的注意力机制和交叉模型检索策略，提高了推理的速度和准确性。'),('2505.20779v2','CHIMERA: A Knowledge Base of Idea Recombination in Scientific Literature','A hallmark of human innovation is the process of recombination -- creating\noriginal ideas by integrating elements of existing mechanisms and concepts. In\nthis work, we automatically mine the scientific literature and build CHIMERA: a\nlarge-scale knowledge base (KB) of recombination examples. CHIMERA can be used\nto empirically explore at scale how scientists recombine concepts and take\ninspiration from different areas, or to train supervised machine learning\nmodels that learn to predict new creative cross-domain directions. To build\nthis KB, we present a novel information extraction task of extracting\nrecombination from scientific paper abstracts, collect a high-quality corpus of\nhundreds of manually annotated abstracts, and use it to train an LLM-based\nextraction model. The model is applied to a large corpus of papers in the AI\ndomain, yielding a KB of over 28K recombination examples. We analyze CHIMERA to\nexplore the properties of recombination in different subareas of AI. Finally,\nwe train a scientific hypothesis generation model using the KB, which predicts\nnew recombination directions that real-world researchers find inspiring. Our\ndata and code are available at https://github.com/noy-sternlicht/CHIMERA-KB','Noy Sternlicht, Tom Hope','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20779v2','该论文通过自动挖掘科学文献构建了一个大规模的重新组合示例知识库CHIMERA，可以用于探索科学家如何重新组合概念，训练机器学习模型预测新的创新跨领域方向。他们提出了一项新的信息提取任务，收集了高质量的语料库，并使用LLM模型进行提取，最终构建了包含超过28K重新组合示例的知识库。最后，他们利用这个知识库训练了一个科学假设生成模型，预测出真实研究人员认为有启发性的新的重新组合方向。'),('2505.20781v1','STITCH-OPE: Trajectory Stitching with Guided Diffusion for Off-Policy Evaluation','Off-policy evaluation (OPE) estimates the performance of a target policy\nusing offline data collected from a behavior policy, and is crucial in domains\nsuch as robotics or healthcare where direct interaction with the environment is\ncostly or unsafe. Existing OPE methods are ineffective for high-dimensional,\nlong-horizon problems, due to exponential blow-ups in variance from importance\nweighting or compounding errors from learned dynamics models. To address these\nchallenges, we propose STITCH-OPE, a model-based generative framework that\nleverages denoising diffusion for long-horizon OPE in high-dimensional state\nand action spaces. Starting with a diffusion model pre-trained on the behavior\ndata, STITCH-OPE generates synthetic trajectories from the target policy by\nguiding the denoising process using the score function of the target policy.\nSTITCH-OPE proposes two technical innovations that make it advantageous for\nOPE: (1) prevents over-regularization by subtracting the score of the behavior\npolicy during guidance, and (2) generates long-horizon trajectories by\nstitching partial trajectories together end-to-end. We provide a theoretical\nguarantee that under mild assumptions, these modifications result in an\nexponential reduction in variance versus long-horizon trajectory diffusion.\nExperiments on the D4RL and OpenAI Gym benchmarks show substantial improvement\nin mean squared error, correlation, and regret metrics compared to\nstate-of-the-art OPE methods.','Hossein Goli, Michael Gimelfarb, Nathan Samuel de Lara, Haruki Nishimura, Masha Itkina, Florian Shkurti','2025-05-27','cs.RO','强化学习','http://arxiv.org/pdf/2505.20781v1','该论文提出了一种基于模型的生成框架 STITCH-OPE，用于解决高维、长时间跨度问题的离线策略评估。通过利用去噪扩散生成合成轨迹，通过目标策略的评分函数引导去噪过程，以及通过将部分轨迹端到端拼接生成长时间跨度轨迹，从而显著降低了方差，实现了比现有 OPE 方法更好的性能。'),('2505.20783v1','FM-Planner: Foundation Model Guided Path Planning for Autonomous Drone Navigation','Path planning is a critical component in autonomous drone operations,\nenabling safe and efficient navigation through complex environments. Recent\nadvances in foundation models, particularly large language models (LLMs) and\nvision-language models (VLMs), have opened new opportunities for enhanced\nperception and intelligent decision-making in robotics. However, their\npractical applicability and effectiveness in global path planning remain\nrelatively unexplored. This paper proposes foundation model-guided path\nplanners (FM-Planner) and presents a comprehensive benchmarking study and\npractical validation for drone path planning. Specifically, we first\nsystematically evaluate eight representative LLM and VLM approaches using\nstandardized simulation scenarios. To enable effective real-time navigation, we\nthen design an integrated LLM-Vision planner that combines semantic reasoning\nwith visual perception. Furthermore, we deploy and validate the proposed path\nplanner through real-world experiments under multiple configurations. Our\nfindings provide valuable insights into the strengths, limitations, and\nfeasibility of deploying foundation models in real-world drone applications and\nproviding practical implementations in autonomous flight. Project site:\nhttps://github.com/NTU-ICG/FM-Planner.','Jiaping Xiao, Cheng Wen Tsao, Yuhang Zhang, Mir Feroskhan','2025-05-27','cs.RO','强化学习','http://arxiv.org/pdf/2505.20783v1','本文提出了基于基础模型的路径规划器（FM-Planner），通过对八种代表性的LLM和VLM方法进行评估，并设计了整合语义推理和视觉感知的LLM-Vision规划器，为自主飞行提供了实用的路径规划解决方案。'),('2505.20789v2','Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models','Inverse problems (IPs) involve reconstructing signals from noisy\nobservations. Recently, diffusion models (DMs) have emerged as a powerful\nframework for solving IPs, achieving remarkable reconstruction performance.\nHowever, existing DM-based methods frequently encounter issues such as heavy\ncomputational demands and suboptimal convergence. In this work, building upon\nthe idea of the recent work DMPlug, we propose two novel methods, DMILO and\nDMILO-PGD, to address these challenges. Our first method, DMILO, employs\nintermediate layer optimization (ILO) to alleviate the memory burden inherent\nin DMPlug. Additionally, by introducing sparse deviations, we expand the range\nof DMs, enabling the exploration of underlying signals that may lie outside the\nrange of the diffusion model. We further propose DMILO-PGD, which integrates\nILO with projected gradient descent (PGD), thereby reducing the risk of\nsuboptimal convergence. We provide an intuitive theoretical analysis of our\napproaches under appropriate conditions and validate their superiority through\nextensive experiments on diverse image datasets, encompassing both linear and\nnonlinear IPs. Our results demonstrate significant performance gains over\nstate-of-the-art methods, highlighting the effectiveness of DMILO and DMILO-PGD\nin addressing common challenges in DM-based IP solvers.','Yang Zheng, Wen Li, Zhaoqiang Liu','2025-05-27','cs.CV','图像处理','http://arxiv.org/pdf/2505.20789v2','该论文提出了两种新方法 DMILO 和 DMILO-PGD，用于解决扩散模型在逆问题中的挑战，包括减少计算需求、改善收敛性能和扩展模型范围。通过理论分析和实验证明这两种方法在各种图像数据集上取得了显著的性能提升。'),('2505.20793v1','Rendering-Aware Reinforcement Learning for Vector Graphics Generation','Scalable Vector Graphics (SVG) offer a powerful format for representing\nvisual designs as interpretable code. Recent advances in vision-language models\n(VLMs) have enabled high-quality SVG generation by framing the problem as a\ncode generation task and leveraging large-scale pretraining. VLMs are\nparticularly suitable for this task as they capture both global semantics and\nfine-grained visual patterns, while transferring knowledge across vision,\nnatural language, and code domains. However, existing VLM approaches often\nstruggle to produce faithful and efficient SVGs because they never observe the\nrendered images during training. Although differentiable rendering for\nautoregressive SVG code generation remains unavailable, rendered outputs can\nstill be compared to original inputs, enabling evaluative feedback suitable for\nreinforcement learning (RL). We introduce RLRF(Reinforcement Learning from\nRendering Feedback), an RL method that enhances SVG generation in\nautoregressive VLMs by leveraging feedback from rendered SVG outputs. Given an\ninput image, the model generates SVG roll-outs that are rendered and compared\nto the original image to compute a reward. This visual fidelity feedback guides\nthe model toward producing more accurate, efficient, and semantically coherent\nSVGs. RLRF significantly outperforms supervised fine-tuning, addressing common\nfailure modes and enabling precise, high-quality SVG generation with strong\nstructural understanding and generalization.','Juan A. Rodriguez, Haotian Zhang, Abhay Puri, Aarash Feizi, Rishav Pramanik, Pascal Wichmann, Arnab Mondal, Mohammad Reza Samsami, Rabiul Awal, Perouz Taslakian, Spandana Gella, Sai Rajeswar, David Vazquez, Christopher Pal, Marco Pedersoli','2025-05-27','cs.CV','强化学习','http://arxiv.org/pdf/2505.20793v1','该论文介绍了一种利用强化学习方法来增强自动生成 SVG 图形的方法，通过渲染输出与原始输入进行比较，以提供评估反馈，从而指导模型生成更准确、高效和语义连贯的 SVG 图形。'),('2505.20794v1','VibE-SVC: Vibrato Extraction with High-frequency F0 Contour for Singing Voice Conversion','Controlling singing style is crucial for achieving an expressive and natural\nsinging voice. Among the various style factors, vibrato plays a key role in\nconveying emotions and enhancing musical depth. However, modeling vibrato\nremains challenging due to its dynamic nature, making it difficult to control\nin singing voice conversion. To address this, we propose VibESVC, a\ncontrollable singing voice conversion model that explicitly extracts and\nmanipulates vibrato using discrete wavelet transform. Unlike previous methods\nthat model vibrato implicitly, our approach decomposes the F0 contour into\nfrequency components, enabling precise transfer. This allows vibrato control\nfor enhanced flexibility. Experimental results show that VibE-SVC effectively\ntransforms singing styles while preserving speaker similarity. Both subjective\nand objective evaluations confirm high-quality conversion.','Joon-Seung Choi, Dong-Min Byun, Hyung-Seok Oh, Seong-Whan Lee','2025-05-27','cs.SD','音频处理','http://arxiv.org/pdf/2505.20794v1','该论文提出了一种可控的歌声转换模型VibESVC，通过离散小波变换明确提取和操作颤音，实现了歌声风格的转换，并在保留说话者相似性的同时增强了灵活性。'),('2505.20797v1','Multi-VQC: A Novel QML Approach for Enhancing Healthcare Classification','Accurate and reliable diagnosis of diseases is crucial in enabling timely\nmedical treatment and enhancing patient survival rates. In recent years,\nMachine Learning has revolutionized diagnostic practices by creating\nclassification models capable of identifying diseases. However, these\nclassification problems often suffer from significant class imbalances, which\ncan inhibit the effectiveness of traditional models. Therefore, the interest in\nQuantum models has arisen, driven by the captivating promise of overcoming the\nlimitations of the classical counterpart thanks to their ability to express\ncomplex patterns by mapping data in a higher-dimensional computational space.','Antonio Tudisco, Deborah Volpe, Giovanna Turvani','2025-05-27','cs.LG','量子模型','http://arxiv.org/pdf/2505.20797v1','该论文探讨了在医学诊断中利用机器学习创建分类模型来识别疾病的重要性，指出传统模型在面对类别不平衡问题时的限制，并提出了量子模型的潜力能够克服这些限制。'),('2505.20802v1','Leaner Transformers: More Heads, Less Depth','Transformers have reshaped machine learning by utilizing attention mechanisms\nto capture complex patterns in large datasets, leading to significant\nimprovements in performance. This success has contributed to the belief that\n\"bigger means better\", leading to ever-increasing model sizes. This paper\nchallenge this ideology by showing that many existing transformers might be\nunnecessarily oversized. We discover a theoretical principle that redefines the\nrole of multi-head attention. An important benefit of the multiple heads is in\nimproving the conditioning of the attention block. We exploit this theoretical\ninsight and redesign popular architectures with an increased number of heads.\nThe improvement in the conditioning proves so significant in practice that\nmodel depth can be decreased, reducing the parameter count by up to 30-50%\nwhile maintaining accuracy. We obtain consistent benefits across a variety of\ntransformer-based architectures of various scales, on tasks in computer vision\n(ImageNet-1k) as well as language and sequence modeling (GLUE benchmark,\nTinyStories, and the Long-Range Arena benchmark).','Hemanth Saratchandran, Damien Teney, Simon Lucey','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20802v1','本文挑战了“更大即更好”的观念，通过重新定义多头注意力的作用，重新设计了流行的transformer架构，增加了头的数量以提高注意力块的条件性。实践中发现，这种改进在很大程度上降低了模型深度，减少了参数数量30-50%，同时保持了准确性。'),('2505.20804v1','Quantum Machine Learning in Healthcare: Evaluating QNN and QSVM Models','Effective and accurate diagnosis of diseases such as cancer, diabetes, and\nheart failure is crucial for timely medical intervention and improving patient\nsurvival rates. Machine learning has revolutionized diagnostic methods in\nrecent years by developing classification models that detect diseases based on\nselected features. However, these classification tasks are often highly\nimbalanced, limiting the performance of classical models. Quantum models offer\na promising alternative, exploiting their ability to express complex patterns\nby operating in a higher-dimensional computational space through superposition\nand entanglement. These unique properties make quantum models potentially more\neffective in addressing the challenges of imbalanced datasets. This work\nevaluates the potential of quantum classifiers in healthcare, focusing on\nQuantum Neural Networks (QNNs) and Quantum Support Vector Machines (QSVMs),\ncomparing them with popular classical models. The study is based on three\nwell-known healthcare datasets -- Prostate Cancer, Heart Failure, and Diabetes.\nThe results indicate that QSVMs outperform QNNs across all datasets due to\ntheir susceptibility to overfitting. Furthermore, quantum models prove the\nability to overcome classical models in scenarios with high dataset imbalance.\nAlthough preliminary, these findings highlight the potential of quantum models\nin healthcare classification tasks and lead the way for further research in\nthis domain.','Antonio Tudisco, Deborah Volpe, Giovanna Turvani','2025-05-27','cs.LG','量子计算/医疗保健分类任务','http://arxiv.org/pdf/2505.20804v1','该论文评估了量子分类器在医疗保健领域的潜力，重点关注量子神经网络（QNNs）和量子支持向量机（QSVMs），并将它们与流行的经典模型进行比较。研究基于三个知名的医疗保健数据集 -- 前列腺癌、心力衰竭和糖尿病。结果表明，由于其容易过拟合，QSVMs在所有数据集上优于QNNs。此外，量子模型证明了在高数据集不平衡情况下克服经典模型的能力。'),('2505.20807v1','Simple yet Effective Graph Distillation via Clustering','Despite plentiful successes achieved by graph representation learning in\nvarious domains, the training of graph neural networks (GNNs) still remains\ntenaciously challenging due to the tremendous computational overhead needed for\nsizable graphs in practice. Recently, graph data distillation (GDD), which\nseeks to distill large graphs into compact and informative ones, has emerged as\na promising technique to enable efficient GNN training. However, most existing\nGDD works rely on heuristics that align model gradients or representation\ndistributions on condensed and original graphs, leading to compromised result\nquality, expensive training for distilling large graphs, or both. Motivated by\nthis, this paper presents an efficient and effective GDD approach, ClustGDD.\nUnder the hood, ClustGDD resorts to synthesizing the condensed graph and node\nattributes through fast and theoretically-grounded clustering that minimizes\nthe within-cluster sum of squares and maximizes the homophily on the original\ngraph. The fundamental idea is inspired by our empirical and theoretical\nfindings unveiling the connection between clustering and empirical condensation\nquality using Fr\\\\\'echet Inception Distance, a well-known quality metric for\nsynthetic images. Furthermore, to mitigate the adverse effects caused by the\nhomophily-based clustering, ClustGDD refines the nodal attributes of the\ncondensed graph with a small augmentation learned via class-aware graph\nsampling and consistency loss. Our extensive experiments exhibit that GNNs\ntrained over condensed graphs output by ClustGDD consistently achieve superior\nor comparable performance to state-of-the-art GDD methods in terms of node\nclassification on five benchmark datasets, while being orders of magnitude\nfaster.','Yurui Lai, Taiyan Zhang, Renchi Yang','2025-05-27','cs.LG','图数据精炼 (GDD)','http://arxiv.org/pdf/2505.20807v1','本文提出了一种高效有效的图数据精炼（GDD）方法ClustGDD，通过快速和理论基础的聚类来合成压缩图和节点属性，从而实现了对大规模图的高效训练。实验证明，ClustGDD生成的压缩图训练的GNN在节点分类任务上表现出优越或可比的性能，同时训练速度快得多。'),('2505.20809v1','Improved Representation Steering for Language Models','Steering methods for language models (LMs) seek to provide fine-grained and\ninterpretable control over model generations by variously changing model\ninputs, weights, or representations to adjust behavior. Recent work has shown\nthat adjusting weights or representations is often less effective than steering\nby prompting, for instance when wanting to introduce or suppress a particular\nconcept. We demonstrate how to improve representation steering via our new\nReference-free Preference Steering (RePS), a bidirectional\npreference-optimization objective that jointly does concept steering and\nsuppression. We train three parameterizations of RePS and evaluate them on\nAxBench, a large-scale model steering benchmark. On Gemma models with sizes\nranging from 2B to 27B, RePS outperforms all existing steering methods trained\nwith a language modeling objective and substantially narrows the gap with\nprompting -- while promoting interpretability and minimizing parameter count.\nIn suppression, RePS matches the language-modeling objective on Gemma-2 and\noutperforms it on the larger Gemma-3 variants while remaining resilient to\nprompt-based jailbreaking attacks that defeat prompting. Overall, our results\nsuggest that RePS provides an interpretable and robust alternative to prompting\nfor both steering and suppression.','Zhengxuan Wu, Qinan Yu, Aryaman Arora, Christopher D. Manning, Christopher Potts','2025-05-27','cs.CL','语言模型 (LLM)','http://arxiv.org/pdf/2505.20809v1','该论文介绍了一种名为Reference-free Preference Steering (RePS)的新方法，通过双向偏好优化目标来改进语言模型的表示调整，同时实现概念调整和抑制。实验结果表明，RePS在大规模模型调整基准测试中表现优异，提高了模型的可解释性和减少参数数量。'),('2505.20813v2','RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph','In knowledge graph embedding, leveraging relation specific entity\ntransformation has markedly enhanced performance. However, the consistency of\nembedding differences before and after transformation remains unaddressed,\nrisking the loss of valuable inductive bias inherent in the embeddings. This\ninconsistency stems from two problems. First, transformation representations\nare specified for relations in a disconnected manner, allowing dissimilar\ntransformations and corresponding entity embeddings for similar relations.\nSecond, a generalized plug-in approach as a SFBR (Semantic Filter Based on\nRelations) disrupts this consistency through excessive concentration of entity\nembeddings under entity-based regularization, generating indistinguishable\nscore distributions among relations. In this paper, we introduce a plug-in KGE\nmethod, Relation-Semantics Consistent Filter (RSCF). Its entity transformation\nhas three features for enhancing semantic consistency: 1) shared affine\ntransformation of relation embeddings across all relations, 2) rooted entity\ntransformation that adds an entity embedding to its change represented by the\ntransformed vector, and 3) normalization of the change to prevent scale\nreduction. To amplify the advantages of consistency that preserve semantics on\nembeddings, RSCF adds relation transformation and prediction modules for\nenhancing the semantics. In knowledge graph completion tasks with\ndistance-based and tensor decomposition models, RSCF significantly outperforms\nstate-of-the-art KGE methods, showing robustness across all relations and their\nfrequencies.','Junsik Kim, Jinwook Park, Kangil Kim','2025-05-27','cs.CL','知识图嵌入','http://arxiv.org/pdf/2505.20813v2','本文介绍了一种名为RSCF的知识图嵌入方法，通过增强语义一致性来提高性能。该方法包括共享仿射变换、根实体变换和归一化变换等特性，在知识图完成任务中显著优于现有方法。'),('2505.20816v1','Rethinking Information Synthesis in Multimodal Question Answering A Multi-Agent Perspective','Recent advances in multimodal question answering have primarily focused on\ncombining heterogeneous modalities or fine-tuning multimodal large language\nmodels. While these approaches have shown strong performance, they often rely\non a single, generalized reasoning strategy, overlooking the unique\ncharacteristics of each modality ultimately limiting both accuracy and\ninterpretability. To address these limitations, we propose MAMMQA, a\nmulti-agent QA framework for multimodal inputs spanning text, tables, and\nimages. Our system includes two Visual Language Model (VLM) agents and one\ntext-based Large Language Model (LLM) agent. The first VLM decomposes the user\nquery into sub-questions and sequentially retrieves partial answers from each\nmodality. The second VLM synthesizes and refines these results through\ncross-modal reasoning. Finally, the LLM integrates the insights into a cohesive\nanswer. This modular design enhances interpretability by making the reasoning\nprocess transparent and allows each agent to operate within its domain of\nexpertise. Experiments on diverse multimodal QA benchmarks demonstrate that our\ncooperative, multi-agent framework consistently outperforms existing baselines\nin both accuracy and robustness.','Krishna Singh Rajput, Tejas Anvekar, Chitta Baral, Vivek Gupta','2025-05-27','cs.CL','多模态问题回答(Multimodal Question Answering)','http://arxiv.org/pdf/2505.20816v1','该论文提出了一种名为MAMMQA的多智能体QA框架，用于处理跨文本、表格和图像的多模态输入。系统包括两个视觉语言模型（VLM）智能体和一个基于文本的大型语言模型（LLM）智能体，通过协作和跨模态推理提高了准确性和鲁棒性。'),('2505.20817v1','Convergence of Clipped-SGD for Convex $(L_0,L_1)$-Smooth Optimization with Heavy-Tailed Noise','Gradient clipping is a widely used technique in Machine Learning and Deep\nLearning (DL), known for its effectiveness in mitigating the impact of\nheavy-tailed noise, which frequently arises in the training of large language\nmodels. Additionally, first-order methods with clipping, such as Clip-SGD,\nexhibit stronger convergence guarantees than SGD under the\n$(L_0,L_1)$-smoothness assumption, a property observed in many DL tasks.\nHowever, the high-probability convergence of Clip-SGD under both assumptions --\nheavy-tailed noise and $(L_0,L_1)$-smoothness -- has not been fully addressed\nin the literature. In this paper, we bridge this critical gap by establishing\nthe first high-probability convergence bounds for Clip-SGD applied to convex\n$(L_0,L_1)$-smooth optimization with heavy-tailed noise. Our analysis extends\nprior results by recovering known bounds for the deterministic case and the\nstochastic setting with $L_1 = 0$ as special cases. Notably, our rates avoid\nexponentially large factors and do not rely on restrictive sub-Gaussian noise\nassumptions, significantly broadening the applicability of gradient clipping.','Savelii Chezhegov, Aleksandr Beznosikov, Samuel Horváth, Eduard Gorbunov','2025-05-27','math.OC','优化算法','http://arxiv.org/pdf/2505.20817v1','本文研究了梯度裁剪在机器学习和深度学习中的应用，特别是在训练大型语言模型时对重尾噪声的影响。通过建立梯度裁剪在凸$(L_0,L_1)$-平滑优化中应用于重尾噪声的高概率收敛界，填补了相关研究中的关键空白。'),('2505.20819v1','Tracing and Reversing Rank-One Model Edits','Knowledge editing methods (KEs) are a cost-effective way to update the\nfactual content of large language models (LLMs), but they pose a dual-use risk.\nWhile KEs are beneficial for updating outdated or incorrect information, they\ncan be exploited maliciously to implant misinformation or bias. In order to\ndefend against these types of malicious manipulation, we need robust techniques\nthat can reliably detect, interpret, and mitigate adversarial edits. This work\ninvestigates the traceability and reversibility of knowledge edits, focusing on\nthe widely used Rank-One Model Editing (ROME) method. We first show that ROME\nintroduces distinctive distributional patterns in the edited weight matrices,\nwhich can serve as effective signals for locating the edited weights. Second,\nwe show that these altered weights can reliably be used to predict the edited\nfactual relation, enabling partial reconstruction of the modified fact.\nBuilding on this, we propose a method to infer the edited object entity\ndirectly from the modified weights, without access to the editing prompt,\nachieving over 95% accuracy. Finally, we demonstrate that ROME edits can be\nreversed, recovering the model\\\'s original outputs with $\\geq$ 80% accuracy. Our\nfindings highlight the feasibility of detecting, tracing, and reversing edits\nbased on the edited weights, offering a robust framework for safeguarding LLMs\nagainst adversarial manipulations.','Paul Youssef, Zhixue Zhao, Christin Seifert, Jörg Schlötterer','2025-05-27','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.20819v1','该论文研究了知识编辑方法对大型语言模型的影响，提出了一种能够可靠检测、解释和减轻恶意编辑的方法。他们发现编辑后的权重矩阵中存在着独特的分布模式，可以用于定位编辑过的权重，并能够部分重构修改后的事实关系。最终他们展示了编辑的可逆性，能够以超过80%的准确率恢复模型的原始输出。'),('2505.20820v1','MT-Mol:Multi Agent System with Tool-based Reasoning for Molecular Optimization','Large language models (LLMs) have large potential for molecular optimization,\nas they can gather external chemistry tools and enable collaborative\ninteractions to iteratively refine molecular candidates. However, this\npotential remains underexplored, particularly in the context of structured\nreasoning, interpretability, and comprehensive tool-grounded molecular\noptimization. To address this gap, we introduce MT-Mol, a multi-agent framework\nfor molecular optimization that leverages tool-guided reasoning and\nrole-specialized LLM agents. Our system incorporates comprehensive RDKit tools,\ncategorized into five distinct domains: structural descriptors, electronic and\ntopological features, fragment-based functional groups, molecular\nrepresentations, and miscellaneous chemical properties. Each category is\nmanaged by an expert analyst agent, responsible for extracting task-relevant\ntools and enabling interpretable, chemically grounded feedback. MT-Mol produces\nmolecules with tool-aligned and stepwise reasoning through the interaction\nbetween the analyst agents, a molecule-generating scientist, a reasoning-output\nverifier, and a reviewer agent. As a result, we show that our framework shows\nthe state-of-the-art performance of the PMO-1K benchmark on 17 out of 23 tasks.','Hyomin Kim, Yunhui Jang, Sungsoo Ahn','2025-05-27','cs.AI','LLM、分子优化','http://arxiv.org/pdf/2505.20820v1','该论文介绍了一种名为MT-Mol的多智能体分子优化框架，利用工具引导的推理和角色专门化的LLM代理。他们展示了该框架在PMO-1K基准测试中在23个任务中有17个任务取得了最先进的性能。'),('2505.20824v1','MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems','As large language models (LLMs) are increasingly deployed in healthcare,\nensuring their safety, particularly within collaborative multi-agent\nconfigurations, is paramount. In this paper we introduce MedSentry, a benchmark\ncomprising 5 000 adversarial medical prompts spanning 25 threat categories with\n100 subthemes. Coupled with this dataset, we develop an end-to-end\nattack-defense evaluation pipeline to systematically analyze how four\nrepresentative multi-agent topologies (Layers, SharedPool, Centralized, and\nDecentralized) withstand attacks from \\\'dark-personality\\\' agents. Our findings\nreveal critical differences in how these architectures handle information\ncontamination and maintain robust decision-making, exposing their underlying\nvulnerability mechanisms. For instance, SharedPool\\\'s open information sharing\nmakes it highly susceptible, whereas Decentralized architectures exhibit\ngreater resilience thanks to inherent redundancy and isolation. To mitigate\nthese risks, we propose a personality-scale detection and correction mechanism\nthat identifies and rehabilitates malicious agents, restoring system safety to\nnear-baseline levels. MedSentry thus furnishes both a rigorous evaluation\nframework and practical defense strategies that guide the design of safer\nLLM-based multi-agent systems in medical domains.','Kai Chen, Taihang Zhen, Hewei Wang, Kailai Liu, Xinfeng Li, Jing Huo, Tianpei Yang, Jinfeng Xu, Wei Dong, Yang Gao','2025-05-27','cs.MA','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20824v1','本文介绍了MedSentry，一个包含5000个对抗性医疗提示的基准数据集，涵盖25个威胁类别和100个子主题。作者开发了一个端到端的攻击-防御评估管道，系统分析了四种典型的多智能体拓扑结构在面对“黑暗个性”代理的攻击时的表现。研究结果揭示了这些架构在处理信息污染和维持强大决策制定方面的关键差异，揭示了它们的潜在脆弱性机制。作者提出了一种个性规模检测和纠正机制，用于识别和恢复恶意代理，将系统安全恢复到接近基线水平。'),('2505.20825v1','Reinforced Informativeness Optimization for Long-Form Retrieval-Augmented Generation','Long-form question answering (LFQA) presents unique challenges for large\nlanguage models, requiring the synthesis of coherent, paragraph-length answers.\nWhile retrieval-augmented generation (RAG) systems have emerged as a promising\nsolution, existing research struggles with key limitations: the scarcity of\nhigh-quality training data for long-form generation, the compounding risk of\nhallucination in extended outputs, and the absence of reliable evaluation\nmetrics for factual completeness. In this paper, we propose RioRAG, a novel\nreinforcement learning (RL) framework that advances long-form RAG through\nreinforced informativeness optimization. Our approach introduces two\nfundamental innovations to address the core challenges. First, we develop an RL\ntraining paradigm of reinforced informativeness optimization that directly\noptimizes informativeness and effectively addresses the slow-thinking deficit\nin conventional RAG systems, bypassing the need for expensive supervised data.\nSecond, we propose a nugget-centric hierarchical reward modeling approach that\nenables precise assessment of long-form answers through a three-stage process:\nextracting the nugget from every source webpage, constructing a nugget claim\nchecklist, and computing rewards based on factual alignment. Extensive\nexperiments on two LFQA benchmarks LongFact and RAGChecker demonstrate the\neffectiveness of the proposed method. Our codes are available at\nhttps://github.com/RUCAIBox/RioRAG.','Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang','2025-05-27','cs.CL','长篇问题回答生成 (Long-form question answering)、强化学习 (Reinforcement Learning)','http://arxiv.org/pdf/2505.20825v1','本文提出了一种新的强化学习框架 RioRAG，通过强化信息量优化来推进长篇回答生成，解决了长篇问题回答中的关键挑战。该方法通过两项创新解决了核心挑战，即开发了一种强化信息量优化的RL训练范式，以及提出了一种基于金块的分层奖励建模方法，通过三阶段过程精确评估长篇答案。'),('2505.20826v1','AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset','Identifying factors that make ad text attractive is essential for advertising\nsuccess. This study proposes AdParaphrase v2.0, a dataset for ad text\nparaphrasing, containing human preference data, to enable the analysis of the\nlinguistic factors and to support the development of methods for generating\nattractive ad texts. Compared with v1.0, this dataset is 20 times larger,\ncomprising 16,460 ad text paraphrase pairs, each annotated with preference data\nfrom ten evaluators, thereby enabling a more comprehensive and reliable\nanalysis. Through the experiments, we identified multiple linguistic features\nof engaging ad texts that were not observed in v1.0 and explored various\nmethods for generating attractive ad texts. Furthermore, our analysis\ndemonstrated the relationships between human preference and ad performance, and\nhighlighted the potential of reference-free metrics based on large language\nmodels for evaluating ad text attractiveness. The dataset is publicly available\nat: https://github.com/CyberAgentAILab/AdParaphrase-v2.0.','Soichiro Murakami, Peinan Zhang, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20826v1','本研究提出了 AdParaphrase v2.0 数据集，用于广告文本改写，包含人类偏好数据，以分析语言因素并支持生成吸引人广告文本的方法开发。通过实验，发现了吸引人广告文本的多种语言特征，并探索了生成吸引人广告文本的各种方法。研究还展示了人类偏好与广告表现之间的关系，并强调了基于大型语言模型的无参考度量方法在评估广告文本吸引力方面的潜力。'),('2505.20836v1','HAD: Hybrid Architecture Distillation Outperforms Teacher in Genomic Sequence Modeling','Inspired by the great success of Masked Language Modeling (MLM) in the\nnatural language domain, the paradigm of self-supervised pre-training and\nfine-tuning has also achieved remarkable progress in the field of DNA sequence\nmodeling. However, previous methods often relied on massive pre-training data\nor large-scale base models with huge parameters, imposing a significant\ncomputational burden. To address this, many works attempted to use more compact\nmodels to achieve similar outcomes but still fell short by a considerable\nmargin. In this work, we propose a Hybrid Architecture Distillation (HAD)\napproach, leveraging both distillation and reconstruction tasks for more\nefficient and effective pre-training. Specifically, we employ the NTv2-500M as\nthe teacher model and devise a grouping masking strategy to align the feature\nembeddings of visible tokens while concurrently reconstructing the invisible\ntokens during MLM pre-training. To validate the effectiveness of our proposed\nmethod, we conducted comprehensive experiments on the Nucleotide Transformer\nBenchmark and Genomic Benchmark. Compared to models with similar parameters,\nour model achieved excellent performance. More surprisingly, it even surpassed\nthe distillation ceiling-teacher model on some sub-tasks, which is more than\n500 $\\times$ larger. Lastly, we utilize t-SNE for more intuitive visualization,\nwhich shows that our model can gain a sophisticated understanding of the\nintrinsic representation pattern in genomic sequences.','Hexiong Yang, Mingrui Chen, Huaibo Huang, Junxian Duan, Jie Cao, Zhen Zhou, Ran He','2025-05-27','cs.LG','LLM (Language Model)','http://arxiv.org/pdf/2505.20836v1','该论文提出了一种混合架构蒸馏（HAD）方法，结合了蒸馏和重构任务，用于DNA序列建模的自监督预训练。实验证明，该方法在Nucleotide Transformer Benchmark和Genomic Benchmark上表现出色，甚至在某些子任务上超越了比其大500倍的蒸馏教师模型。'),('2505.20839v2','FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration','As large language models become increasingly prevalent, memory bandwidth\nconstraints significantly limit inference throughput, motivating post-training\nquantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ\nframework and an INT4-FP8 matrix multiplication kernel that accelerates LLM\ninference across all linear layers. Specifically, FireQ quantizes linear layer\nweights and key-values to INT4, and activations and queries to FP8,\nsignificantly enhancing throughput. Additionally, we introduce a three-stage\npipelining for the prefill phase, which modifies the FlashAttention-3 kernel,\neffectively reducing time-to-first-token in the prefill phase. To minimize\naccuracy loss from quantization, we develop novel outlier smoothing techniques\ntailored separately for linear and attention layers. In linear layers, we\nexplicitly use per-tensor scaling to prevent underflow caused by the FP8\nquantization scaling factor of INT4 quantization, and channel-wise scaling to\ncompensate for coarse granularity of INT4. In attention layers, we address\nquantization challenges posed by rotary positional embeddings (RoPE) by\ncombining pre-RoPE and post-RoPE scaling strategies. FireQ significantly\noutperforms state-of-the-art methods, achieving 1.68x faster inference in\nfeed-forward network layers on Llama2-7B and 1.26x faster prefill phase\nperformance on Llama3-8B compared to QServe, with negligible accuracy loss.','Daehyeon Baek, Jieun Choi, Jimyoung Son, Kyungmin Bin, Seungbeom Choi, Kihyo Moon, Minsung Jang, Hyojung Lee','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20839v2','该论文提出了一种名为FireQ的后训练量化框架，通过将线性层权重和键-值量化为INT4，激活和查询量化为FP8，以及引入三阶段流水线技术和异常值平滑技术，显著提高了LLM推理的吞吐量，并在Llama2-7B和Llama3-8B上取得了比QServe更快的推理性能。'),('2505.20840v1','Aggregation Buffer: Revisiting DropEdge with a New Parameter Block','We revisit DropEdge, a data augmentation technique for GNNs which randomly\nremoves edges to expose diverse graph structures during training. While being a\npromising approach to effectively reduce overfitting on specific connections in\nthe graph, we observe that its potential performance gain in supervised\nlearning tasks is significantly limited. To understand why, we provide a\ntheoretical analysis showing that the limited performance of DropEdge comes\nfrom the fundamental limitation that exists in many GNN architectures. Based on\nthis analysis, we propose Aggregation Buffer, a parameter block specifically\ndesigned to improve the robustness of GNNs by addressing the limitation of\nDropEdge. Our method is compatible with any GNN model, and shows consistent\nperformance improvements on multiple datasets. Moreover, our method effectively\naddresses well-known problems such as degree bias or structural disparity as a\nunifying solution. Code and datasets are available at\nhttps://github.com/dooho00/agg-buffer.','Dooho Lee, Myeong Kong, Sagad Hamid, Cheonwoo Lee, Jaemin Yoo','2025-05-27','cs.LG','图神经网络 (GNN)','http://arxiv.org/pdf/2505.20840v1','该论文重新审视了DropEdge，这是一种用于GNN的数据增强技术，通过在训练过程中随机删除边来暴露多样化的图结构。作者提出了Aggregation Buffer，一个专门设计的参数块，旨在改善GNN的鲁棒性，解决DropEdge存在的局限性，并在多个数据集上表现出一致的性能提升。'),('2505.20841v1','Concealment of Intent: A Game-Theoretic Analysis','As large language models (LLMs) grow more capable, concerns about their safe\ndeployment have also grown. Although alignment mechanisms have been introduced\nto deter misuse, they remain vulnerable to carefully designed adversarial\nprompts. In this work, we present a scalable attack strategy: intent-hiding\nadversarial prompting, which conceals malicious intent through the composition\nof skills. We develop a game-theoretic framework to model the interaction\nbetween such attacks and defense systems that apply both prompt and response\nfiltering. Our analysis identifies equilibrium points and reveals structural\nadvantages for the attacker. To counter these threats, we propose and analyze a\ndefense mechanism tailored to intent-hiding attacks. Empirically, we validate\nthe attack\\\'s effectiveness on multiple real-world LLMs across a range of\nmalicious behaviors, demonstrating clear advantages over existing adversarial\nprompting techniques.','Xinbo Wu, Abhishek Umrawal, Lav R. Varshney','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20841v1','该论文研究了针对大型语言模型的安全部署问题，提出了一种新的攻击策略：意图隐藏的对抗提示，通过技能组合来隐藏恶意意图。他们开发了一个博弈论框架来建模攻击和防御系统之间的互动，并提出了一种针对意图隐藏攻击的防御机制。'),('2505.20853v2','Cooperation of Experts: Fusing Heterogeneous Information with Large Margin','Fusing heterogeneous information remains a persistent challenge in modern\ndata analysis. While significant progress has been made, existing approaches\noften fail to account for the inherent heterogeneity of object patterns across\ndifferent semantic spaces. To address this limitation, we propose the\nCooperation of Experts (CoE) framework, which encodes multi-typed information\ninto unified heterogeneous multiplex networks. By overcoming modality and\nconnection differences, CoE provides a powerful and flexible model for\ncapturing the intricate structures of real-world complex data. In our\nframework, dedicated encoders act as domain-specific experts, each specializing\nin learning distinct relational patterns in specific semantic spaces. To\nenhance robustness and extract complementary knowledge, these experts\ncollaborate through a novel large margin mechanism supported by a tailored\noptimization strategy. Rigorous theoretical analyses guarantee the framework\\\'s\nfeasibility and stability, while extensive experiments across diverse\nbenchmarks demonstrate its superior performance and broad applicability. Our\ncode is available at https://github.com/strangeAlan/CoE.','Shuo Wang, Shunyang Huang, Jinghui Yuan, Zhixiang Shen, Zhao Kang','2025-05-27','cs.LG','异构多模态数据融合','http://arxiv.org/pdf/2505.20853v2','该论文提出了一种合作专家（CoE）框架，将多类型信息编码为统一的异构多重网络，以捕捉现实世界复杂数据的结构。通过专门的编码器作为领域专家，通过新颖的大边界机制和优化策略进行合作，增强鲁棒性并提取互补知识。严格的理论分析和广泛的实验表明该框架具有卓越性能和广泛适用性。'),('2505.20854v1','An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks','Large Language Models (LLMs) and other automated techniques have been\nincreasingly used to support software developers by generating software\nartifacts such as code snippets, patches, and comments. However, accurately\nassessing the correctness of these generated artifacts remains a significant\nchallenge. On one hand, human evaluation provides high accuracy but is\nlabor-intensive and lacks scalability. On the other hand, other existing\nautomatic evaluation metrics are scalable and require minimal human effort, but\nthey often fail to accurately reflect the actual correctness of generated\nsoftware artifacts.\n  In this paper, we present SWE-Judge, the first evaluation metric for\nLLM-as-Ensemble-Judge specifically designed to accurately assess the\ncorrectness of generated software artifacts. SWE-Judge first defines five\ndistinct evaluation strategies, each implemented as an independent judge. A\ndynamic team selection mechanism then identifies the most appropriate subset of\njudges to produce a final correctness score through ensembling. We evaluate\nSWE-Judge across a diverse set of software engineering (SE) benchmarks,\nincluding CoNaLa, Card2Code, HumanEval-X, APPS, APR-Assess, and Summary-Assess.\nThese benchmarks span three SE tasks: code generation, automated program\nrepair, and code summarization. Experimental results demonstrate that SWE-Judge\nconsistently achieves a higher correlation with human judgments, with\nimprovements ranging from 5.9% to 183.8% over existing automatic metrics.\nFurthermore, SWE-Judge reaches agreement levels with human annotators that are\ncomparable to inter-annotator agreement in code generation and program repair\ntasks. These findings underscore SWE-Judge\\\'s potential as a scalable and\nreliable alternative to human evaluation.','Xin Zhou, Kisub Kim, Ting Zhang, Martin Weyssow, Luis F. Gomes, Guang Yang, David Lo','2025-05-27','cs.SE','大型语言模型（LLM）、软件工程','http://arxiv.org/pdf/2505.20854v1','本文介绍了一种名为SWE-Judge的评估度量标准，旨在准确评估生成的软件工件的正确性。该度量标准通过将五种独立评估策略实现为独立的评委，并通过集成机制选择最合适的评委子集来生成最终的正确性评分。实验结果表明，SWE-Judge在软件工程基准测试中表现出更高的与人类判断的相关性，与现有自动度量标准相比，改进范围从5.9%到183.8%不等。'),('2505.20863v1','Leveraging Diffusion Models for Parameterized Quantum Circuit Generation','Quantum computing holds immense potential, yet its practical success depends\non multiple factors, including advances in quantum circuit design. In this\npaper, we introduce a generative approach based on denoising diffusion models\n(DMs) to synthesize parameterized quantum circuits (PQCs). Extending the recent\ndiffusion model pipeline of F\\\"urrutter et al. [1], our model effectively\nconditions the synthesis process, enabling the simultaneous generation of\ncircuit architectures and their continuous gate parameters. We demonstrate our\napproach in synthesizing PQCs optimized for generating high-fidelity\nGreenberger-Horne-Zeilinger (GHZ) states and achieving high accuracy in quantum\nmachine learning (QML) classification tasks. Our results indicate a strong\ngeneralization across varying gate sets and scaling qubit counts, highlighting\nthe versatility and computational efficiency of diffusion-based methods. This\nwork illustrates the potential of generative models as a powerful tool for\naccelerating and optimizing the design of PQCs, supporting the development of\nmore practical and scalable quantum applications.','Daniel Barta, Darya Martyniuk, Johannes Jung, Adrian Paschke','2025-05-27','quant-ph','量子计算/生成模型','http://arxiv.org/pdf/2505.20863v1','本文介绍了一种基于去噪扩散模型（DMs）的生成方法，用于合成参数化量子电路（PQCs），并展示了在量子机器学习分类任务中优化生成高保真度GHZ态的PQCs的效果。'),('2505.20866v1','Respond to Change with Constancy: Instruction-tuning with LLM for Non-I.I.D. Network Traffic Classification','Encrypted traffic classification is highly challenging in network security\ndue to the need for extracting robust features from content-agnostic traffic\ndata. Existing approaches face critical issues: (i) Distribution drift, caused\nby reliance on the closedworld assumption, limits adaptability to realworld,\nshifting patterns; (ii) Dependence on labeled data restricts applicability\nwhere such data is scarce or unavailable. Large language models (LLMs) have\ndemonstrated remarkable potential in offering generalizable solutions across a\nwide range of tasks, achieving notable success in various specialized fields.\nHowever, their effectiveness in traffic analysis remains constrained by\nchallenges in adapting to the unique requirements of the traffic domain. In\nthis paper, we introduce a novel traffic representation model named Encrypted\nTraffic Out-of-Distribution Instruction Tuning with LLM (ETooL), which\nintegrates LLMs with knowledge of traffic structures through a self-supervised\ninstruction tuning paradigm. This framework establishes connections between\ntextual information and traffic interactions. ETooL demonstrates more robust\nclassification performance and superior generalization in both supervised and\nzero-shot traffic classification tasks. Notably, it achieves significant\nimprovements in F1 scores: APP53 (I.I.D.) to 93.19%(6.62%) and 92.11%(4.19%),\nAPP53 (O.O.D.) to 74.88%(18.17%) and 72.13%(15.15%), and ISCX-Botnet (O.O.D.)\nto 95.03%(9.16%) and 81.95%(12.08%). Additionally, we construct NETD, a traffic\ndataset designed to support dynamic distributional shifts, and use it to\nvalidate ETooL\\\'s effectiveness under varying distributional conditions.\nFurthermore, we evaluate the efficiency gains achieved through ETooL\\\'s\ninstruction tuning approach.','Xinjie Lin, Gang Xiong, Gaopeng Gou, Wenqi Dong, Jing Yu, Zhen Li, Wei Xia','2025-05-27','cs.CR','流量分类/大语言模型(LLM)','http://arxiv.org/pdf/2505.20866v1','本文介绍了一种名为ETooL的新型流量表示模型，通过自监督指令调整范式将LLM与流量结构知识相结合，建立了文本信息和流量交互之间的联系。ETooL在监督和零样本流量分类任务中表现出更强大的分类性能和更优越的泛化能力。'),('2505.20868v1','Spotlight-TTS: Spotlighting the Style via Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech','Recent advances in expressive text-to-speech (TTS) have introduced diverse\nmethods based on style embedding extracted from reference speech. However,\nsynthesizing high-quality expressive speech remains challenging. We propose\nSpotlight-TTS, which exclusively emphasizes style via voiced-aware style\nextraction and style direction adjustment. Voiced-aware style extraction\nfocuses on voiced regions highly related to style while maintaining continuity\nacross different speech regions to improve expressiveness. We adjust the\ndirection of the extracted style for optimal integration into the TTS model,\nwhich improves speech quality. Experimental results demonstrate that\nSpotlight-TTS achieves superior performance compared to baseline models in\nterms of expressiveness, overall speech quality, and style transfer capability.\nOur audio samples are publicly available.','Nam-Gyu Kim, Deok-Hyeon Cho, Seung-Bin Kim, Seong-Whan Lee','2025-05-27','cs.SD','自然语言处理','http://arxiv.org/pdf/2505.20868v1','该论文提出了一种名为Spotlight-TTS的方法，通过声音感知风格提取和风格方向调整，专注于风格的表达，从而改善了文本转语音的表现。实验结果表明，Spotlight-TTS在表达性、整体语音质量和风格转移能力方面优于基准模型。'),('2505.20869v1','Step-Wise Formal Verification for LLM-Based Mathematical Problem Solving','Large Language Models (LLMs) have demonstrated formidable capabilities in\nsolving mathematical problems, yet they may still commit logical reasoning and\ncomputational errors during the problem-solving process. Thus, this paper\nproposes a framework, MATH-VF, which includes a Formalizer and a Critic, for\nformally verifying the correctness of the solutions generated by large language\nmodels. Our framework first utilizes a Formalizer which employs an LLM to\ntranslate a natural language solution into a formal context. Afterward, our\nCritic (which integrates various external tools such as a Computer Algebra\nSystem and an SMT solver) evaluates the correctness of each statement within\nthe formal context, and when a statement is incorrect, our Critic provides\ncorrective feedback. We empirically investigate the effectiveness of MATH-VF in\ntwo scenarios: 1) Verification: MATH-VF is utilized to determine the\ncorrectness of a solution to a given problem. 2) Refinement: When MATH-VF\nidentifies errors in the solution generated by an LLM-based solution generator\nfor a given problem, it submits the corrective suggestions proposed by the\nCritic to the solution generator to regenerate the solution. We evaluate our\nframework on widely used mathematical benchmarks: MATH500 and ProcessBench,\ndemonstrating the superiority of our approach over existing approaches.','Kuo Zhou, Lu Zhang','2025-05-27','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20869v1','本文提出了一个名为MATH-VF的框架，包括一个形式化器和一个评论者，用于验证大型语言模型生成的解决方案的正确性。通过将自然语言解决方案转化为形式化上下文，并利用评论者评估每个语句的正确性，提供纠正反馈。在数学基准测试中验证了该框架的有效性。'),('2505.20871v1','Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG','Large language models (LLMs) augmented with retrieval systems have\nsignificantly advanced natural language processing tasks by integrating\nexternal knowledge sources, enabling more accurate and contextually rich\nresponses. To improve the robustness of such systems against noisy retrievals,\nRetrieval-Augmented Fine-Tuning (RAFT) has emerged as a widely adopted method.\nHowever, RAFT conditions models to generate answers even in the absence of\nreliable knowledge. This behavior undermines their reliability in high-stakes\ndomains, where acknowledging uncertainty is critical. To address this issue, we\npropose Divide-Then-Align (DTA), a post-training approach designed to endow RAG\nsystems with the ability to respond with \"I don\\\'t know\" when the query is out\nof the knowledge boundary of both the retrieved passages and the model\\\'s\ninternal knowledge. DTA divides data samples into four knowledge quadrants and\nconstructs tailored preference data for each quadrant, resulting in a curated\ndataset for Direct Preference Optimization (DPO). Experimental results on three\nbenchmark datasets demonstrate that DTA effectively balances accuracy with\nappropriate abstention, enhancing the reliability and trustworthiness of\nretrieval-augmented systems.','Xin Sun, Jianan Xie, Zhongqi Chen, Qiang Liu, Shu Wu, Yuehe Chen, Bowen Song, Weiqiang Wang, Zilei Wang, Liang Wang','2025-05-27','cs.CL','大型语言模型（LLM）','http://arxiv.org/pdf/2505.20871v1','该论文提出了一种名为Divide-Then-Align (DTA) 的方法，用于改善检索增强微调系统在噪声检索情况下的鲁棒性，使其能够在缺乏可靠知识的情况下回答“我不知道”。通过将数据样本分为四个知识象限，并为每个象限构建定制偏好数据，从而实现了直接偏好优化的精心策划数据集。实验结果表明，DTA有效地平衡了准确性和适当的弃权，提高了检索增强系统的可靠性和可信度。'),('2505.20872v1','In Context Learning with Vision Transformers: Case Study','Large transformer models have been shown to be capable of performing\nin-context learning. By using examples in a prompt as well as a query, they are\ncapable of performing tasks such as few-shot, one-shot, or zero-shot learning\nto output the corresponding answer to this query. One area of interest to us is\nthat these transformer models have been shown to be capable of learning the\ngeneral class of certain functions, such as linear functions and small 2-layer\nneural networks, on random data (Garg et al, 2023). We aim to extend this to\nthe image space to analyze their capability to in-context learn more complex\nfunctions on the image space, such as convolutional neural networks and other\nmethods.','Antony Zhao, Alex Proshkin, Fergal Hennessy, Francesco Crivelli','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.20872v1','该论文研究了大型transformer模型在上下文学习中的表现，通过在提示和查询中使用示例，能够执行少样本、一样本或零样本学习任务，并输出相应的答案。研究目的是扩展这种能力到图像空间，分析它们在图像空间上学习更复杂函数的能力。'),('2505.20874v1','Can LLMs Learn to Map the World from Local Descriptions?','Recent advances in Large Language Models (LLMs) have demonstrated strong\ncapabilities in tasks such as code and mathematics. However, their potential to\ninternalize structured spatial knowledge remains underexplored. This study\ninvestigates whether LLMs, grounded in locally relative human observations, can\nconstruct coherent global spatial cognition by integrating fragmented\nrelational descriptions. We focus on two core aspects of spatial cognition:\nspatial perception, where models infer consistent global layouts from local\npositional relationships, and spatial navigation, where models learn road\nconnectivity from trajectory data and plan optimal paths between unconnected\nlocations. Experiments conducted in a simulated urban environment demonstrate\nthat LLMs not only generalize to unseen spatial relationships between points of\ninterest (POIs) but also exhibit latent representations aligned with real-world\nspatial distributions. Furthermore, LLMs can learn road connectivity from\ntrajectory descriptions, enabling accurate path planning and dynamic spatial\nawareness during navigation.','Sirui Xia, Aili Chen, Xintao Wang, Tinghui Zhu, Yikai Zhang, Jiangjie Chen, Yanghua Xiao','2025-05-27','cs.CL','LLM、自然语言处理、空间认知','http://arxiv.org/pdf/2505.20874v1','本研究探讨了基于大型语言模型（LLMs）的全局空间认知能力，通过整合碎片化的关系描述，研究了空间感知和空间导航两个核心方面。实验结果表明，LLMs不仅可以泛化到未见的空间关系，还能学习道路连接性和进行路径规划。'),('2505.20875v1','Trans-EnV: A Framework for Evaluating the Linguistic Robustness of LLMs Against English Varieties','Large Language Models (LLMs) are predominantly evaluated on Standard American\nEnglish (SAE), often overlooking the diversity of global English varieties.\nThis narrow focus may raise fairness concerns as degraded performance on\nnon-standard varieties can lead to unequal benefits for users worldwide.\nTherefore, it is critical to extensively evaluate the linguistic robustness of\nLLMs on multiple non-standard English varieties. We introduce Trans-EnV, a\nframework that automatically transforms SAE datasets into multiple English\nvarieties to evaluate the linguistic robustness. Our framework combines (1)\nlinguistics expert knowledge to curate variety-specific features and\ntransformation guidelines from linguistic literature and corpora, and (2)\nLLM-based transformations to ensure both linguistic validity and scalability.\nUsing Trans-EnV, we transform six benchmark datasets into 38 English varieties\nand evaluate seven state-of-the-art LLMs. Our results reveal significant\nperformance disparities, with accuracy decreasing by up to 46.3% on\nnon-standard varieties. These findings highlight the importance of\ncomprehensive linguistic robustness evaluation across diverse English\nvarieties. Each construction of Trans-EnV was validated through rigorous\nstatistical testing and consultation with a researcher in the field of second\nlanguage acquisition, ensuring its linguistic validity. Our\n\\href{https://github.com/jiyounglee-0523/TransEnV}{code} and\n\\href{https://huggingface.co/collections/jiyounglee0523/transenv-681eadb3c0c8cf363b363fb1}{datasets}\nare publicly available.','Jiyoung Lee, Seungho Kim, Jieun Han, Jun-Min Lee, Kitaek Kim, Alice Oh, Edward Choi','2025-05-27','cs.CL','大语言模型（LLM）, 自然语言处理','http://arxiv.org/pdf/2505.20875v1','该论文介绍了一个名为Trans-EnV的框架，用于将标准美式英语数据集转换为多种英语方言，以评估大型语言模型在非标准英语方言上的语言鲁棒性。研究结果显示，在非标准英语方言上，准确率下降高达46.3%，强调了对多样化英语方言进行全面语言鲁棒性评估的重要性。'),('2505.20880v1','MSA at SemEval-2025 Task 3: High Quality Weak Labeling and LLM Ensemble Verification for Multilingual Hallucination Detection','This paper describes our submission for SemEval-2025 Task 3: Mu-SHROOM, the\nMultilingual Shared-task on Hallucinations and Related Observable\nOvergeneration Mistakes. The task involves detecting hallucinated spans in text\ngenerated by instruction-tuned Large Language Models (LLMs) across multiple\nlanguages. Our approach combines task-specific prompt engineering with an LLM\nensemble verification mechanism, where a primary model extracts hallucination\nspans and three independent LLMs adjudicate their validity through\nprobability-based voting. This framework simulates the human annotation\nworkflow used in the shared task validation and test data. Additionally, fuzzy\nmatching refines span alignment. Our system ranked 1st in Arabic and Basque,\n2nd in German, Swedish, and Finnish, and 3rd in Czech, Farsi, and French.','Baraa Hikal, Ahmed Nasreldin, Ali Hamdi','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20880v1','该论文介绍了他们在SemEval-2025任务3中的提交Mu-SHROOM，这是一个关于幻觉和相关可观察过度生成错误的多语言共享任务。他们的方法结合了任务特定的提示工程和LLM集成验证机制，其中一个主要模型提取幻觉跨度，三个独立的LLM通过基于概率的投票来裁决它们的有效性。他们的系统在阿拉伯语和巴斯克语中排名第一，在德语、瑞典语和芬兰语中排名第二，在捷克语、波斯语和法语中排名第三。'),('2505.20881v1','Generalizable Heuristic Generation Through Large Language Models with Meta-Optimization','Heuristic design with large language models (LLMs) has emerged as a promising\napproach for tackling combinatorial optimization problems (COPs). However,\nexisting approaches often rely on manually predefined evolutionary computation\n(EC) optimizers and single-task training schemes, which may constrain the\nexploration of diverse heuristic algorithms and hinder the generalization of\nthe resulting heuristics. To address these issues, we propose Meta-Optimization\nof Heuristics (MoH), a novel framework that operates at the optimizer level,\ndiscovering effective optimizers through the principle of meta-learning.\nSpecifically, MoH leverages LLMs to iteratively refine a meta-optimizer that\nautonomously constructs diverse optimizers through (self-)invocation, thereby\neliminating the reliance on a predefined EC optimizer. These constructed\noptimizers subsequently evolve heuristics for downstream tasks, enabling\nbroader heuristic exploration. Moreover, MoH employs a multi-task training\nscheme to promote its generalization capability. Experiments on classic COPs\ndemonstrate that MoH constructs an effective and interpretable meta-optimizer,\nachieving state-of-the-art performance across various downstream tasks,\nparticularly in cross-size settings.','Yiding Shi, Jianan Zhou, Wen Song, Jieyi Bi, Yaoxin Wu, Jie Zhang','2025-05-27','cs.LG','元学习 (LLM)','http://arxiv.org/pdf/2505.20881v1','该论文提出了一种新颖的框架 MoH，通过元学习原则在优化器级别上操作，通过迭代优化元优化器来自主构建多样化的优化器，从而消除对预定义进化计算优化器的依赖。实验结果表明，MoH在经典的组合优化问题上构建了一个有效且可解释的元优化器，在各种下游任务中取得了最先进的性能，特别是在交叉尺寸设置中。'),('2505.20888v1','EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models','In this paper, we present EasyDistill, a comprehensive toolkit designed for\neffective black-box and white-box knowledge distillation (KD) of large language\nmodels (LLMs). Our framework offers versatile functionalities, including data\nsynthesis, supervised fine-tuning, ranking optimization, and reinforcement\nlearning techniques specifically tailored for KD scenarios. The toolkit\naccommodates KD functionalities for both System 1 (fast, intuitive) and System\n2 (slow, analytical) models. With its modular design and user-friendly\ninterface, EasyDistill empowers researchers and industry practitioners to\nseamlessly experiment with and implement state-of-the-art KD strategies for\nLLMs. In addition, EasyDistill provides a series of robust distilled models and\nKD-based industrial solutions developed by us, along with the corresponding\nopen-sourced datasets, catering to a variety of use cases. Furthermore, we\ndescribe the seamless integration of EasyDistill into Alibaba Cloud\\\'s Platform\nfor AI (PAI). Overall, the EasyDistill toolkit makes advanced KD techniques for\nLLMs more accessible and impactful within the NLP community.','Chengyu Wang, Junbing Yan, Wenrui Cai, Yuanhao Yue, Jun Huang','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20888v1','该论文介绍了EasyDistill，一个专为大型语言模型（LLMs）的黑盒和白盒知识蒸馏（KD）而设计的全面工具包。他们的框架提供了多功能性，包括数据合成、监督微调、排名优化和专门针对KD场景的强化学习技术。EasyDistill通过其模块化设计和用户友好的界面，使研究人员和行业从业者能够轻松地尝试和实施LLMs的最新KD策略。此外，EasyDistill还提供了一系列由他们开发的强大的蒸馏模型和基于KD的工业解决方案，以及相应的开源数据集，满足各种用例。最后，他们描述了EasyDistill如何无缝集成到阿里巴巴云的AI平台（PAI）中。总的来说，EasyDistill工具包使LLMs的高级KD技术更容易获得并在NLP社区中产生更大的影响。'),('2505.20889v1','Reinforcement Learning-based Sequential Route Recommendation for System-Optimal Traffic Assignment','Modern navigation systems and shared mobility platforms increasingly rely on\npersonalized route recommendations to improve individual travel experience and\noperational efficiency. However, a key question remains: can such sequential,\npersonalized routing decisions collectively lead to system-optimal (SO) traffic\nassignment? This paper addresses this question by proposing a learning-based\nframework that reformulates the static SO traffic assignment problem as a\nsingle-agent deep reinforcement learning (RL) task. A central agent\nsequentially recommends routes to travelers as origin-destination (OD) demands\narrive, to minimize total system travel time. To enhance learning efficiency\nand solution quality, we develop an MSA-guided deep Q-learning algorithm that\nintegrates the iterative structure of traditional traffic assignment methods\ninto the RL training process. The proposed approach is evaluated on both the\nBraess and Ortuzar-Willumsen (OW) networks. Results show that the RL agent\nconverges to the theoretical SO solution in the Braess network and achieves\nonly a 0.35% deviation in the OW network. Further ablation studies demonstrate\nthat the route action set\\\'s design significantly impacts convergence speed and\nfinal performance, with SO-informed route sets leading to faster learning and\nbetter outcomes. This work provides a theoretically grounded and practically\nrelevant approach to bridging individual routing behavior with system-level\nefficiency through learning-based sequential assignment.','Leizhen Wang, Peibo Duan, Cheng Lyu, Zhenliang Ma','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.20889v1','该论文提出了一个基于深度强化学习的框架，将静态的系统最优交通分配问题重新定义为单一代理深度强化学习任务，以最小化总系统旅行时间。通过在Braess和OW网络上的评估，结果显示RL代理在Braess网络中收敛到理论SO解决方案，并在OW网络中仅出现0.35%的偏差。'),('2505.20890v1','Frequency Composition for Compressed and Domain-Adaptive Neural Networks','Modern on-device neural network applications must operate under resource\nconstraints while adapting to unpredictable domain shifts. However, this\ncombined challenge-model compression and domain adaptation-remains largely\nunaddressed, as prior work has tackled each issue in isolation: compressed\nnetworks prioritize efficiency within a fixed domain, whereas large, capable\nmodels focus on handling domain shifts. In this work, we propose CoDA, a\nfrequency composition-based framework that unifies compression and domain\nadaptation. During training, CoDA employs quantization-aware training (QAT)\nwith low-frequency components, enabling a compressed model to selectively learn\nrobust, generalizable features. At test time, it refines the compact model in a\nsource-free manner (i.e., test-time adaptation, TTA), leveraging the\nfull-frequency information from incoming data to adapt to target domains while\ntreating high-frequency components as domain-specific cues. LFC are aligned\nwith the trained distribution, while HFC unique to the target distribution are\nsolely utilized for batch normalization. CoDA can be integrated synergistically\ninto existing QAT and TTA methods. CoDA is evaluated on widely used\ndomain-shift benchmarks, including CIFAR10-C and ImageNet-C, across various\nmodel architectures. With significant compression, it achieves accuracy\nimprovements of 7.96%p on CIFAR10-C and 5.37%p on ImageNet-C over the\nfull-precision TTA baseline.','Yoojin Kwon, Hongjun Suh, Wooseok Lee, Taesik Gong, Songyi Han, Hyung-Sin Kim','2025-05-27','cs.CV','模型压缩和领域自适应','http://arxiv.org/pdf/2505.20890v1','该论文提出了一种基于频率组合的框架 CoDA，将模型压缩和领域自适应结合起来。在训练过程中，CoDA利用量化感知训练（QAT）和低频组件，使压缩模型能够选择性地学习稳健且具有泛化能力的特征。在测试阶段，它以无源的方式（即测试时自适应，TTA）对紧凑模型进行优化，利用来自传入数据的全频率信息来适应目标领域，同时将高频组件视为领域特定的线索。'),('2505.20892v1','One-Time Soft Alignment Enables Resilient Learning without Weight Transport','Backpropagation is the cornerstone of deep learning, but its reliance on\nsymmetric weight transport and global synchronization makes it computationally\nexpensive and biologically implausible. Feedback alignment offers a promising\nalternative by approximating error gradients through fixed random feedback,\nthereby avoiding symmetric weight transport. However, this approach often\nstruggles with poor learning performance and instability, especially in deep\nnetworks. Here, we show that a one-time soft alignment between forward and\nfeedback weights at initialization enables deep networks to achieve performance\ncomparable to backpropagation, without requiring weight transport during\nlearning. This simple initialization condition guides stable error minimization\nin the loss landscape, improving network trainability. Spectral analyses\nfurther reveal that initial alignment promotes smoother gradient flow and\nconvergence to flatter minima, resulting in better generalization and\nrobustness. Notably, we also find that allowing moderate deviations from exact\nweight symmetry can improve adversarial robustness compared to standard\nbackpropagation. These findings demonstrate that a simple initialization\nstrategy can enable effective learning in deep networks in a biologically\nplausible and resource-efficient manner.','Jeonghwan Cheon, Jaehyuk Bae, Se-Bum Paik','2025-05-27','cs.LG','深度学习','http://arxiv.org/pdf/2505.20892v1','该论文提出了一种反馈对齐的方法，通过在初始化阶段在前向和反馈权重之间进行一次软对齐，使得深度网络可以在学习过程中避免对称权重传输，从而实现与反向传播相媲美的性能。这种简单的初始化条件有助于改善网络的训练性能，使得网络在损失函数的空间中更容易找到稳定的误差最小化解。'),('2505.20894v1','DeepConvContext: A Multi-Scale Approach to Timeseries Classification in Human Activity Recognition','Despite recognized limitations in modeling long-range temporal dependencies,\nHuman Activity Recognition (HAR) has traditionally relied on a sliding window\napproach to segment labeled datasets. Deep learning models like the\nDeepConvLSTM typically classify each window independently, thereby restricting\nlearnable temporal context to within-window information. To address this\nconstraint, we propose DeepConvContext, a multi-scale time series\nclassification framework for HAR. Drawing inspiration from the vision-based\nTemporal Action Localization community, DeepConvContext models both intra- and\ninter-window temporal patterns by processing sequences of time-ordered windows.\nUnlike recent HAR models that incorporate attention mechanisms, DeepConvContext\nrelies solely on LSTMs -- with ablation studies demonstrating the superior\nperformance of LSTMs over attention-based variants for modeling inertial sensor\ndata. Across six widely-used HAR benchmarks, DeepConvContext achieves an\naverage 10% improvement in F1-score over the classic DeepConvLSTM, with gains\nof up to 21%. Code to reproduce our experiments is publicly available via\ngithub.com/mariusbock/context_har.','Marius Bock, Michael Moeller, Kristof Van Laerhoven','2025-05-27','cs.LG','人类活动识别 (Human Activity Recognition)','http://arxiv.org/pdf/2505.20894v1','该论文提出了一种名为DeepConvContext的多尺度时间序列分类框架，用于解决人类活动识别中长期时间依赖性建模的问题。通过处理时间顺序窗口序列，DeepConvContext模拟了窗口内和窗口间的时间模式，相比于其他最近的HAR模型，DeepConvContext仅依赖于LSTMs，在六个常用的HAR基准测试中，DeepConvContext在F1分数上平均提高了10%，最高可达21%。'),('2505.20896v1','How Do Transformers Learn Variable Binding in Symbolic Programs?','Variable binding -- the ability to associate variables with values -- is\nfundamental to symbolic computation and cognition. Although classical\narchitectures typically implement variable binding via addressable memory, it\nis not well understood how modern neural networks lacking built-in binding\noperations may acquire this capacity. We investigate this by training a\nTransformer to dereference queried variables in symbolic programs where\nvariables are assigned either numerical constants or other variables. Each\nprogram requires following chains of variable assignments up to four steps deep\nto find the queried value, and also contains irrelevant chains of assignments\nacting as distractors. Our analysis reveals a developmental trajectory with\nthree distinct phases during training: (1) random prediction of numerical\nconstants, (2) a shallow heuristic prioritizing early variable assignments, and\n(3) the emergence of a systematic mechanism for dereferencing assignment\nchains. Using causal interventions, we find that the model learns to exploit\nthe residual stream as an addressable memory space, with specialized attention\nheads routing information across token positions. This mechanism allows the\nmodel to dynamically track variable bindings across layers, resulting in\naccurate dereferencing. Our results show how Transformer models can learn to\nimplement systematic variable binding without explicit architectural support,\nbridging connectionist and symbolic approaches.','Yiwei Wu, Atticus Geiger, Raphaël Millière','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.20896v1','本论文研究了如何训练Transformer模型在符号程序中实现变量绑定的能力，通过追踪变量赋值链来查询变量的值，最终发现模型学会了利用残余流作为可寻址的内存空间，通过专门的注意力头在token位置之间传递信息，从而实现了准确的变量解引用。'),('2505.20897v1','Cross from Left to Right Brain: Adaptive Text Dreamer for Vision-and-Language Navigation','Vision-and-Language Navigation (VLN) requires the agent to navigate by\nfollowing natural instructions under partial observability, making it difficult\nto align perception with language. Recent methods mitigate this by imagining\nfuture scenes, yet they rely on vision-based synthesis, leading to high\ncomputational cost and redundant details. To this end, we propose to adaptively\nimagine key environmental semantics via \\textit{language} form, enabling a more\nreliable and efficient strategy. Specifically, we introduce a novel Adaptive\nText Dreamer (ATD), a dual-branch self-guided imagination policy built upon a\nlarge language model (LLM). ATD is designed with a human-like left-right brain\narchitecture, where the left brain focuses on logical integration, and the\nright brain is responsible for imaginative prediction of future scenes. To\nachieve this, we fine-tune only the Q-former within both brains to efficiently\nactivate domain-specific knowledge in the LLM, enabling dynamic updates of\nlogical reasoning and imagination during navigation. Furthermore, we introduce\na cross-interaction mechanism to regularize the imagined outputs and inject\nthem into a navigation expert module, allowing ATD to jointly exploit both the\nreasoning capacity of the LLM and the expertise of the navigation model. We\nconduct extensive experiments on the R2R benchmark, where ATD achieves\nstate-of-the-art performance with fewer parameters. The code is\n\\href{https://github.com/zhangpingrui/Adaptive-Text-Dreamer}{here}.','Pingrui Zhang, Yifei Su, Pengyuan Wu, Dong An, Li Zhang, Zhigang Wang, Dong Wang, Yan Ding, Bin Zhao, Xuelong Li','2025-05-27','cs.CV','自然语言处理','http://arxiv.org/pdf/2505.20897v1','该论文提出了一种新颖的自适应文本梦想者（ATD）方法，通过大型语言模型（LLM）实现对关键环境语义的想象，以在视觉与语言之间实现更可靠和高效的对齐。ATD在R2R基准测试上取得了最先进的性能，参数更少。'),('2505.20899v1','Dub-S2ST: Textless Speech-to-Speech Translation for Seamless Dubbing','This paper introduces a cross-lingual dubbing system that translates speech\nfrom one language to another while preserving key characteristics such as\nduration, speaker identity, and speaking speed. Despite the strong translation\nquality of existing speech translation approaches, they often overlook the\ntransfer of speech patterns, leading to mismatches with source speech and\nlimiting their suitability for dubbing applications. To address this, we\npropose a discrete diffusion-based speech-to-unit translation model with\nexplicit duration control, enabling time-aligned translation. We then\nsynthesize speech based on the predicted units and source identity with a\nconditional flow matching model. Additionally, we introduce a unit-based speed\nadaptation mechanism that guides the translation model to produce speech at a\nrate consistent with the source, without relying on any text. Extensive\nexperiments demonstrate that our framework generates natural and fluent\ntranslations that align with the original speech\\\'s duration and speaking pace,\nwhile achieving competitive translation performance.','Jeongsoo Choi, Jaehun Kim, Joon Son Chung','2025-05-27','cs.CL','语音处理','http://arxiv.org/pdf/2505.20899v1','本文介绍了一种跨语言配音系统，可以将一种语言的语音翻译成另一种语言，同时保留关键特征，如持续时间、说话者身份和说话速度。作者提出了一种基于离散扩散的语音到单元翻译模型，具有明确的持续时间控制，能够实现时间对齐翻译。他们还引入了基于单元的速度适应机制，指导翻译模型以与源语音一致的速率生成语音。'),('2505.20901v1','A Stereotype Content Analysis on Color-related Social Bias in Large Vision Language Models','As large vision language models(LVLMs) rapidly advance, concerns about their\npotential to learn and generate social biases and stereotypes are increasing.\nPrevious studies on LVLM\\\'s stereotypes face two primary limitations: metrics\nthat overlooked the importance of content words, and datasets that overlooked\nthe effect of color. To address these limitations, this study introduces new\nevaluation metrics based on the Stereotype Content Model (SCM). We also propose\nBASIC, a benchmark for assessing gender, race, and color stereotypes. Using SCM\nmetrics and BASIC, we conduct a study with eight LVLMs to discover stereotypes.\nAs a result, we found three findings. (1) The SCM-based evaluation is effective\nin capturing stereotypes. (2) LVLMs exhibit color stereotypes in the output\nalong with gender and race ones. (3) Interaction between model architecture and\nparameter sizes seems to affect stereotypes. We release BASIC publicly on\n[anonymized for review].','Junhyuk Choi, Minju Kim, Yeseon Hong, Bugeun Kim','2025-05-27','cs.CL','LLM（大型语言模型）、社会偏见和刻板印象','http://arxiv.org/pdf/2505.20901v1','该论文研究了大型视觉语言模型（LVLMs）学习和生成社会偏见和刻板印象的问题，提出了基于 Stereotype Content Model（SCM）的新评估指标和基准（BASIC）用于评估性别、种族和肤色刻板印象，通过研究发现LVLMs在输出中展现了肤色刻板印象，并且模型架构和参数大小之间的交互似乎影响了刻板印象。'),('2505.20903v1','Towards Objective Fine-tuning: How LLMs\\\' Prior Knowledge Causes Potential Poor Calibration?','Fine-tuned Large Language Models (LLMs) often demonstrate poor calibration,\nwith their confidence scores misaligned with actual performance. While\ncalibration has been extensively studied in models trained from scratch, the\nimpact of LLMs\\\' prior knowledge on calibration during fine-tuning remains\nunderstudied. Our research reveals that LLMs\\\' prior knowledge causes potential\npoor calibration due to the ubiquitous presence of known data in real-world\nfine-tuning, which appears harmful for calibration. Specifically, data aligned\nwith LLMs\\\' prior knowledge would induce overconfidence, while new knowledge\nimproves calibration. Our findings expose a tension: LLMs\\\' encyclopedic\nknowledge, while enabling task versatility, undermines calibration through\nunavoidable knowledge overlaps. To address this, we propose CogCalib, a\ncognition-aware framework that applies targeted learning strategies according\nto the model\\\'s prior knowledge. Experiments across 7 tasks using 3 LLM families\nprove that CogCalib significantly improves calibration while maintaining\nperformance, achieving an average 57\\% reduction in ECE compared to standard\nfine-tuning in Llama3-8B. These improvements generalize well to out-of-domain\ntasks, enhancing the objectivity and reliability of domain-specific LLMs, and\nmaking them more trustworthy for critical human-AI interaction applications.','Ziming Wang, Zeyu Shi, Haoyi Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.20903v1','该论文研究了Fine-tuned Large Language Models (LLMs) 在校准方面存在的问题，发现LLMs的先验知识可能导致校准不佳，提出了一个基于认知的框架CogCalib来改善校准。'),('2505.20910v1','Automated Privacy Information Annotation in Large Language Model Interactions','Users interacting with large language models (LLMs) under their real\nidentifiers often unknowingly risk disclosing private information.\nAutomatically notifying users whether their queries leak privacy and which\nphrases leak what private information has therefore become a practical need.\nExisting privacy detection methods, however, were designed for different\nobjectives and application scenarios, typically tagging personally identifiable\ninformation (PII) in anonymous content. In this work, to support the\ndevelopment and evaluation of privacy detection models for LLM interactions\nthat are deployable on local user devices, we construct a large-scale\nmultilingual dataset with 249K user queries and 154K annotated privacy phrases.\nIn particular, we build an automated privacy annotation pipeline with\ncloud-based strong LLMs to automatically extract privacy phrases from dialogue\ndatasets and annotate leaked information. We also design evaluation metrics at\nthe levels of privacy leakage, extracted privacy phrase, and privacy\ninformation. We further establish baseline methods using light-weight LLMs with\nboth tuning-free and tuning-based methods, and report a comprehensive\nevaluation of their performance. Evaluation results reveal a gap between\ncurrent performance and the requirements of real-world LLM applications,\nmotivating future research into more effective local privacy detection methods\ngrounded in our dataset.','Hang Zeng, Xiangyu Liu, Yong Hu, Chaoyue Niu, Fan Wu, Shaojie Tang, Guihai Chen','2025-05-27','cs.CL','隐私检测','http://arxiv.org/pdf/2505.20910v1','该论文主要研究用户与大型语言模型（LLMs）交互时可能泄露私人信息的问题，提出了构建大规模多语言数据集以支持隐私检测模型的发展和评估，并设计了评估指标和基准方法，结果显示当前性能与实际应用需求存在差距。'),('2505.20918v1','Humble AI in the real-world: the case of algorithmic hiring','Humble AI (Knowles et al., 2023) argues for cautiousness in AI development\nand deployments through scepticism (accounting for limitations of statistical\nlearning), curiosity (accounting for unexpected outcomes), and commitment\n(accounting for multifaceted values beyond performance). We present a\nreal-world case study for humble AI in the domain of algorithmic hiring.\nSpecifically, we evaluate virtual screening algorithms in a widely used hiring\nplatform that matches candidates to job openings. There are several challenges\nin misrecognition and stereotyping in such contexts that are difficult to\nassess through standard fairness and trust frameworks; e.g., someone with a\nnon-traditional background is less likely to rank highly. We demonstrate\ntechnical feasibility of how humble AI principles can be translated to practice\nthrough uncertainty quantification of ranks, entropy estimates, and a user\nexperience that highlights algorithmic unknowns. We describe preliminary\ndiscussions with focus groups made up of recruiters. Future user studies seek\nto evaluate whether the higher cognitive load of a humble AI system fosters a\nclimate of trust in its outcomes.','Rahul Nair, Inge Vejsbjerg, Elizabeth Daly, Christos Varytimidis, Bran Knowles','2025-05-27','cs.LG','人工智能伦理和社会影响','http://arxiv.org/pdf/2505.20918v1','该论文主要讨论了谦卑人工智能的概念，通过怀疑、好奇和承诺来谨慎开发和部署人工智能，并通过一个算法招聘的案例研究展示了谦卑人工智能原则如何转化为实践。'),('2505.20921v1','Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models','LLM providers typically offer multiple LLM tiers, varying in performance and\nprice. As NLP tasks become more complex and modularized, selecting the suitable\nLLM tier for each subtask is a key challenge to balance between cost and\nperformance. To address the problem, we introduce LLM Automatic Transmission\n(LLM-AT) framework that automatically selects LLM tiers without training.\nLLM-AT consists of Starter, Generator, and Judge. The starter selects the\ninitial LLM tier expected to solve the given question, the generator produces a\nresponse using the LLM of the selected tier, and the judge evaluates the\nvalidity of the response. If the response is invalid, LLM-AT iteratively\nupgrades to a higher-tier model, generates a new response, and re-evaluates\nuntil a valid response is obtained. Additionally, we propose accuracy\nestimator, which enables the suitable initial LLM tier selection without\ntraining. Given an input question, accuracy estimator estimates the expected\naccuracy of each LLM tier by computing the valid response rate across top-k\nsimilar queries from past inference records. Experiments demonstrate that\nLLM-AT achieves superior performance while reducing costs, making it a\npractical solution for real-world applications.','Injae Na, Keonwoong Noh, Woohwan Jung','2025-05-27','cs.CL','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.20921v1','该论文介绍了一种名为LLM Automatic Transmission (LLM-AT) 框架，可以自动选择适合的LLM层级来解决NLP任务，从而在性能和成本之间取得平衡。'),('2505.20922v1','Revisiting Multi-Agent World Modeling from a Diffusion-Inspired Perspective','World models have recently attracted growing interest in Multi-Agent\nReinforcement Learning (MARL) due to their ability to improve sample efficiency\nfor policy learning. However, accurately modeling environments in MARL is\nchallenging due to the exponentially large joint action space and highly\nuncertain dynamics inherent in multi-agent systems. To address this, we reduce\nmodeling complexity by shifting from jointly modeling the entire state-action\ntransition dynamics to focusing on the state space alone at each timestep\nthrough sequential agent modeling. Specifically, our approach enables the model\nto progressively resolve uncertainty while capturing the structured\ndependencies among agents, providing a more accurate representation of how\nagents influence the state. Interestingly, this sequential revelation of\nagents\\\' actions in a multi-agent system aligns with the reverse process in\ndiffusion models--a class of powerful generative models known for their\nexpressiveness and training stability compared to autoregressive or latent\nvariable models. Leveraging this insight, we develop a flexible and robust\nworld model for MARL using diffusion models. Our method, Diffusion-Inspired\nMulti-Agent world model (DIMA), achieves state-of-the-art performance across\nmultiple multi-agent control benchmarks, significantly outperforming prior\nworld models in terms of final return and sample efficiency, including MAMuJoCo\nand Bi-DexHands. DIMA establishes a new paradigm for constructing multi-agent\nworld models, advancing the frontier of MARL research.','Yang Zhang, Xinran Li, Jianing Ye, Delin Qu, Shuang Qiu, Chongjie Zhang, Xiu Li, Chenjia Bai','2025-05-27','cs.MA','强化学习','http://arxiv.org/pdf/2505.20922v1','该论文提出了一种基于扩散模型的多智能体世界模型（DIMA），通过顺序智能体建模来减少建模复杂性，提高多智能体强化学习的效率和性能。'),('2505.20924v1','Label Leakage in Federated Inertial-based Human Activity Recognition','While prior work has shown that Federated Learning updates can leak sensitive\ninformation, label reconstruction attacks, which aim to recover input labels\nfrom shared gradients, have not yet been examined in the context of Human\nActivity Recognition (HAR). Given the sensitive nature of activity labels, this\nstudy evaluates the effectiveness of state-of-the-art gradient-based label\nleakage attacks on HAR benchmark datasets. Our findings show that the number of\nactivity classes, sampling strategy, and class imbalance are critical factors\ninfluencing the extent of label leakage, with reconstruction accuracies\nreaching up to 90% on two benchmark datasets, even for trained models.\nMoreover, we find that Local Differential Privacy techniques such as gradient\nnoise and clipping offer only limited protection, as certain attacks still\nreliably infer both majority and minority class labels. We conclude by offering\npractical recommendations for the privacy-aware deployment of federated HAR\nsystems and identify open challenges for future research. Code to reproduce our\nexperiments is publicly available via github.com/mariusbock/leakage_har.','Marius Bock, Maximilian Hopp, Kristof Van Laerhoven, Michael Moeller','2025-05-27','cs.LG','隐私保护、人类活动识别','http://arxiv.org/pdf/2505.20924v1','该论文研究了在人类活动识别中，梯度共享可能导致标签信息泄漏的问题，评估了梯度基础标签泄漏攻击的有效性，并发现活动类别数量、采样策略和类别不平衡等因素对标签泄漏的影响。研究结果显示，在两个基准数据集上，重建准确率可达到90％，即使对训练模型也是如此。此外，本研究发现局部差分隐私技术对保护标签泄漏的作用有限。'),('2505.20925v1','Multi-objective Large Language Model Alignment with Hierarchical Experts','Aligning large language models (LLMs) to simultaneously satisfy multiple\nobjectives remains a significant challenge, especially given the diverse and\noften conflicting nature of human preferences. Existing alignment methods\nstruggle to balance trade-offs effectively, often requiring costly retraining\nor yielding suboptimal results across the Pareto frontier of preferences. In\nthis paper, we introduce \\textit{HoE}(Hierarchical Mixture-of-Experts), a\n\\textit{lightweight}, \\textit{parameter-efficient}, and \\textit{plug-and-play}\napproach that eliminates the need for model training, while enabling LLMs to\nadapt across the entire Pareto frontier and accommodate diverse user\npreferences. In particular, \\textit{HoE} consists of three hierarchical\ncomponents: LoRA Experts, Router Experts and Preference Routing, reaching\noptimal Pareto frontiers and achieving a trade-off between parameter size,\ntraining cost, and performance. We evaluate \\textit{HoE} across various tasks\non 14 objectives and 200 different preferences among 6 benchmarks,\ndemonstrating superior performance over 15 recent baselines. Code is available\nin the supplementary materials.','Zhuo Li, Guodong Du, Weiyang Guo, Yigeng Zhou, Xiucheng Li, Wenya Wang, Fangming Liu, Yequan Wang, Deheng Ye, Min Zhang, Jing Li','2025-05-27','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.20925v1','本文介绍了一种名为HoE（Hierarchical Mixture-of-Experts）的轻量级、参数高效、即插即用的方法，可以使LLMs适应整个Pareto前沿并适应多样化用户偏好，同时在参数大小、训练成本和性能之间实现权衡。'),('2505.20933v1','Information-Theoretic Complementary Prompts for Improved Continual Text Classification','Continual Text Classification (CTC) aims to continuously classify new text\ndata over time while minimizing catastrophic forgetting of previously acquired\nknowledge. However, existing methods often focus on task-specific knowledge,\noverlooking the importance of shared, task-agnostic knowledge. Inspired by the\ncomplementary learning systems theory, which posits that humans learn\ncontinually through the interaction of two systems -- the hippocampus,\nresponsible for forming distinct representations of specific experiences, and\nthe neocortex, which extracts more general and transferable representations\nfrom past experiences -- we introduce Information-Theoretic Complementary\nPrompts (InfoComp), a novel approach for CTC. InfoComp explicitly learns two\ndistinct prompt spaces: P(rivate)-Prompt and S(hared)-Prompt. These\nrespectively encode task-specific and task-invariant knowledge, enabling models\nto sequentially learn classification tasks without relying on data replay. To\npromote more informative prompt learning, InfoComp uses an\ninformation-theoretic framework that maximizes mutual information between\ndifferent parameters (or encoded representations). Within this framework, we\ndesign two novel loss functions: (1) to strengthen the accumulation of\ntask-specific knowledge in P-Prompt, effectively mitigating catastrophic\nforgetting, and (2) to enhance the retention of task-invariant knowledge in\nS-Prompt, improving forward knowledge transfer. Extensive experiments on\ndiverse CTC benchmarks show that our approach outperforms previous\nstate-of-the-art methods.','Duzhen Zhang, Yong Ren, Chenxing Li, Dong Yu, Tielin Zhang','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20933v1','该论文介绍了一种名为Information-Theoretic Complementary Prompts (InfoComp)的方法，用于解决Continual Text Classification (CTC)中的遗忘问题。该方法通过学习两个不同的提示空间，分别编码任务特定和任务不变的知识，使模型能够连续学习分类任务而不依赖于数据重放。实验结果表明，该方法优于先前的最先进方法。'),('2505.20934v1','NatADiff: Adversarial Boundary Guidance for Natural Adversarial Diffusion','Adversarial samples exploit irregularities in the manifold ``learned\\\'\\\' by\ndeep learning models to cause misclassifications. The study of these\nadversarial samples provides insight into the features a model uses to classify\ninputs, which can be leveraged to improve robustness against future attacks.\nHowever, much of the existing literature focuses on constrained adversarial\nsamples, which do not accurately reflect test-time errors encountered in\nreal-world settings. To address this, we propose `NatADiff\\\', an adversarial\nsampling scheme that leverages denoising diffusion to generate natural\nadversarial samples. Our approach is based on the observation that natural\nadversarial samples frequently contain structural elements from the adversarial\nclass. Deep learning models can exploit these structural elements to shortcut\nthe classification process, rather than learning to genuinely distinguish\nbetween classes. To leverage this behavior, we guide the diffusion trajectory\ntowards the intersection of the true and adversarial classes, combining\ntime-travel sampling with augmented classifier guidance to enhance attack\ntransferability while preserving image fidelity. Our method achieves comparable\nattack success rates to current state-of-the-art techniques, while exhibiting\nsignificantly higher transferability across model architectures and better\nalignment with natural test-time errors as measured by FID. These results\ndemonstrate that NatADiff produces adversarial samples that not only transfer\nmore effectively across models, but more faithfully resemble naturally\noccurring test-time errors.','Max Collins, Jordan Vice, Tim French, Ajmal Mian','2025-05-27','cs.LG','对抗样本生成','http://arxiv.org/pdf/2505.20934v1','该论文提出了一种新的对抗样本生成方法NatADiff，利用去噪扩散生成自然对抗样本，以提高模型对未来攻击的鲁棒性。通过引导扩散轨迹并结合增强的分类器指导，该方法在攻击成功率、模型间传递性和与自然测试错误的一致性方面表现优异。'),('2505.20937v1','On VLMs for Diverse Tasks in Multimodal Meme Classification','In this paper, we present a comprehensive and systematic analysis of\nvision-language models (VLMs) for disparate meme classification tasks. We\nintroduced a novel approach that generates a VLM-based understanding of meme\nimages and fine-tunes the LLMs on textual understanding of the embedded meme\ntext for improving the performance. Our contributions are threefold: (1)\nBenchmarking VLMs with diverse prompting strategies purposely to each sub-task;\n(2) Evaluating LoRA fine-tuning across all VLM components to assess performance\ngains; and (3) Proposing a novel approach where detailed meme interpretations\ngenerated by VLMs are used to train smaller language models (LLMs),\nsignificantly improving classification. The strategy of combining VLMs with\nLLMs improved the baseline performance by 8.34%, 3.52% and 26.24% for sarcasm,\noffensive and sentiment classification, respectively. Our results reveal the\nstrengths and limitations of VLMs and present a novel strategy for meme\nunderstanding.','Deepesh Gavit, Debajyoti Mazumder, Samiran Das, Jasabanta Patro','2025-05-27','cs.CL','图像识别','http://arxiv.org/pdf/2505.20937v1','该论文通过对视觉-语言模型（VLMs）在不同的模因分类任务中的分析，提出了一种新颖的方法，通过生成VLM对模因图像的理解并在嵌入的模因文本的文本理解上微调LLMs来提高性能。实验结果显示，将VLMs与LLMs相结合可以显著提高模因分类性能。'),('2505.20947v1','Unified Deep Learning Approach for Estimating the Metallicities of RR Lyrae Stars Using light curves from Gaia Data Release 3','RR Lyrae stars (RRLs) are old pulsating variables widely used as metallicity\ntracers due to the correlation between their metal abundances and light curve\nmorphology. With ESA Gaia DR3 providing light curves for about 270,000 RRLs,\nthere is a pressing need for scalable methods to estimate their metallicities\nfrom photometric data. We introduce a unified deep learning framework that\nestimates metallicities for both fundamental-mode (RRab) and first-overtone\n(RRc) RRLs using Gaia G-band light curves. This approach extends our previous\nwork on RRab stars to include RRc stars, aiming for high predictive accuracy\nand broad generalization across both pulsation types. The model is based on a\nGated Recurrent Unit (GRU) neural network optimized for time-series extrinsic\nregression. Our pipeline includes preprocessing steps such as phase folding,\nsmoothing, and sample weighting, and uses photometric metallicities from the\nliterature as training targets. The architecture is designed to handle\nmorphological differences between RRab and RRc light curves without requiring\nseparate models. On held-out validation sets, our GRU model achieves strong\nperformance: for RRab stars, MAE = 0.0565 dex, RMSE = 0.0765 dex, R^2 = 0.9401;\nfor RRc stars, MAE = 0.0505 dex, RMSE = 0.0720 dex, R^2 = 0.9625. These results\nshow the effectiveness of deep learning for large-scale photometric metallicity\nestimation and support its application to studies of stellar populations and\nGalactic structure.','Lorenzo Monti, Tatiana Muraveva, Alessia Garofalo, Gisella Clementini, Maria Letizia Valentini','2025-05-27','astro-ph.SR','自然语言处理','http://arxiv.org/pdf/2505.20947v1','该论文介绍了一种统一的深度学习框架，利用Gaia G带光变曲线估计RR Lyrae星的金属丰度，包括基本模式（RRab）和第一超调模式（RRc）的星。他们的GRU模型在验证集上表现出色，证明了深度学习在大规模光度金属丰度估计中的有效性。'),('2505.20948v1','Controllable Logical Hypothesis Generation for Abductive Reasoning in Knowledge Graphs','Abductive reasoning in knowledge graphs aims to generate plausible logical\nhypotheses from observed entities, with broad applications in areas such as\nclinical diagnosis and scientific discovery. However, due to a lack of\ncontrollability, a single observation may yield numerous plausible but\nredundant or irrelevant hypotheses on large-scale knowledge graphs. To address\nthis limitation, we introduce the task of controllable hypothesis generation to\nimprove the practical utility of abductive reasoning. This task faces two key\nchallenges when controlling for generating long and complex logical hypotheses:\nhypothesis space collapse and hypothesis oversensitivity. To address these\nchallenges, we propose CtrlHGen, a Controllable logcial Hypothesis Generation\nframework for abductive reasoning over knowledge graphs, trained in a two-stage\nparadigm including supervised learning and subsequent reinforcement learning.\nTo mitigate hypothesis space collapse, we design a dataset augmentation\nstrategy based on sub-logical decomposition, enabling the model to learn\ncomplex logical structures by leveraging semantic patterns in simpler\ncomponents. To address hypothesis oversensitivity, we incorporate smoothed\nsemantic rewards including Dice and Overlap scores, and introduce a\ncondition-adherence reward to guide the generation toward user-specified\ncontrol constraints. Extensive experiments on three benchmark datasets\ndemonstrate that our model not only better adheres to control conditions but\nalso achieves superior semantic similarity performance compared to baselines.','Yisen Gao, Jiaxin Bai, Tianshi Zheng, Qingyun Sun, Ziwei Zhang, Jianxin Li, Yangqiu Song, Xingcheng Fu','2025-05-27','cs.AI','知识图谱、逻辑推理','http://arxiv.org/pdf/2505.20948v1','该论文介绍了在知识图谱中进行假设推理的可控假设生成任务，以提高实际应用的效用。作者提出了CtrlHGen框架，通过两阶段训练（监督学习和强化学习）来解决生成长且复杂逻辑假设时的挑战，并在三个基准数据集上进行了广泛实验验证。'),('2505.20950v1','Scattering Networks on Noncommutative Finite Groups','Scattering Networks were initially designed to elucidate the behavior of\nearly layers in Convolutional Neural Networks (CNNs) over Euclidean spaces and\nare grounded in wavelets. In this work, we introduce a scattering transform on\nan arbitrary finite group (not necessarily abelian) within the context of\ngroup-equivariant convolutional neural networks (G-CNNs). We present wavelets\non finite groups and analyze their similarity to classical wavelets. We\ndemonstrate that, under certain conditions in the wavelet coefficients, the\nscattering transform is non-expansive, stable under deformations, preserves\nenergy, equivariant with respect to left and right group translations, and, as\ndepth increases, the scattering coefficients are less sensitive to group\ntranslations of the signal, all desirable properties of convolutional neural\nnetworks. Furthermore, we provide examples illustrating the application of the\nscattering transform to classify data with domains involving abelian and\nnonabelian groups.','Maria Teresa Arias, Davide Barbieri, Eugenio Hernández','2025-05-27','math.NA','图像识别','http://arxiv.org/pdf/2505.20950v1','本文介绍了在群等变卷积神经网络（G-CNNs）中引入了一个在任意有限群上的散射变换，展示了在有限群上的小波以及它们与经典小波的相似性。研究表明，在某些条件下，散射变换是非扩张的，对变形稳定，能保持能量，与左右群平移等变，随着深度增加，散射系数对信号的群平移不敏感，这些都是卷积神经网络的理想特性。此外，提供了应用散射变换对包含阿贝尔和非阿贝尔群的数据进行分类的示例。'),('2505.20955v1','Unveiling Impact of Frequency Components on Membership Inference Attacks for Diffusion Models','Diffusion models have achieved tremendous success in image generation, but\nthey also raise significant concerns regarding privacy and copyright issues.\nMembership Inference Attacks (MIAs) are designed to ascertain whether specific\ndata were utilized during a model\\\'s training phase. As current MIAs for\ndiffusion models typically exploit the model\\\'s image prediction ability, we\nformalize them into a unified general paradigm which computes the membership\nscore for membership identification. Under this paradigm, we empirically find\nthat existing attacks overlook the inherent deficiency in how diffusion models\nprocess high-frequency information. Consequently, this deficiency leads to\nmember data with more high-frequency content being misclassified as hold-out\ndata, and hold-out data with less high-frequency content tend to be\nmisclassified as member data. Moreover, we theoretically demonstrate that this\ndeficiency reduces the membership advantage of attacks, thereby interfering\nwith the effective discrimination of member data and hold-out data. Based on\nthis insight, we propose a plug-and-play high-frequency filter module to\nmitigate the adverse effects of the deficiency, which can be seamlessly\nintegrated into any attacks within this general paradigm without additional\ntime costs. Extensive experiments corroborate that this module significantly\nimproves the performance of baseline attacks across different datasets and\nmodels.','Puwei Lian, Yujun Cai, Songze Li','2025-05-27','cs.CR','生成模型','http://arxiv.org/pdf/2505.20955v1','该论文研究了扩散模型在图像生成中取得的成功，但也引发了隐私和版权问题。作者提出了一个统一的范式，用于计算成员识别的成员得分，并发现现有攻击方法忽视了扩散模型处理高频信息的固有缺陷。他们提出了一个高频滤波器模块来缓解这种缺陷的不良影响，显著提高了基线攻击的性能。'),('2505.20963v1','Context-Aware Content Moderation for German Newspaper Comments','The increasing volume of online discussions requires advanced automatic\ncontent moderation to maintain responsible discourse. While hate speech\ndetection on social media is well-studied, research on German-language\nnewspaper forums remains limited. Existing studies often neglect\nplatform-specific context, such as user history and article themes. This paper\naddresses this gap by developing and evaluating binary classification models\nfor automatic content moderation in German newspaper forums, incorporating\ncontextual information. Using LSTM, CNN, and ChatGPT-3.5 Turbo, and leveraging\nthe One Million Posts Corpus from the Austrian newspaper Der Standard, we\nassess the impact of context-aware models. Results show that CNN and LSTM\nmodels benefit from contextual information and perform competitively with\nstate-of-the-art approaches. In contrast, ChatGPT\\\'s zero-shot classification\ndoes not improve with added context and underperforms.','Felix Krejca, Tobias Kietreiber, Alexander Buchelt, Sebastian Neumaier','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20963v1','该论文研究了如何在德语报纸论坛中进行自动内容审核，通过使用LSTM、CNN和ChatGPT-3.5 Turbo等模型，结合上下文信息进行二元分类。研究结果表明，CNN和LSTM模型在加入上下文信息后表现良好，与最先进方法竞争激烈，而ChatGPT的零样本分类在加入上下文信息后表现不佳。'),('2505.20964v1','Semantic Communication meets System 2 ML: How Abstraction, Compositionality and Emergent Languages Shape Intelligence','The trajectories of 6G and AI are set for a creative collision. However,\ncurrent visions for 6G remain largely incremental evolutions of 5G, while\nprogress in AI is hampered by brittle, data-hungry models that lack robust\nreasoning capabilities. This paper argues for a foundational paradigm shift,\nmoving beyond the purely technical level of communication toward systems\ncapable of semantic understanding and effective, goal-oriented interaction. We\npropose a unified research vision rooted in the principles of System-2\ncognition, built upon three pillars: Abstraction, enabling agents to learn\nmeaningful world models from raw sensorimotor data; Compositionality, providing\nthe algebraic tools to combine learned concepts and subsystems; and Emergent\nCommunication, allowing intelligent agents to create their own adaptive and\ngrounded languages. By integrating these principles, we lay the groundwork for\ntruly intelligent systems that can reason, adapt, and collaborate, unifying\nadvances in wireless communications, machine learning, and robotics under a\nsingle coherent framework.','Mehdi Bennis, Salem Lahlou','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.20964v1','本文提出了一个基于System-2认知原则的统一研究愿景，包括抽象、组合和新兴通信三大支柱，旨在建立能够推理、适应和协作的真正智能系统。'),('2505.20966v1','Personalized Query Auto-Completion for Long and Short-Term Interests with Adaptive Detoxification Generation','Query auto-completion (QAC) plays a crucial role in modern search systems.\nHowever, in real-world applications, there are two pressing challenges that\nstill need to be addressed. First, there is a need for hierarchical\npersonalized representations for users. Previous approaches have typically used\nusers\\\' search behavior as a single, overall representation, which proves\ninadequate in more nuanced generative scenarios. Additionally, query prefixes\nare typically short and may contain typos or sensitive information, increasing\nthe likelihood of generating toxic content compared to traditional text\ngeneration tasks. Such toxic content can degrade user experience and lead to\npublic relations issues. Therefore, the second critical challenge is\ndetoxifying QAC systems.\n  To address these two limitations, we propose a novel model (LaD) that\ncaptures personalized information from both long-term and short-term interests,\nincorporating adaptive detoxification. In LaD, personalized information is\ncaptured hierarchically at both coarse-grained and fine-grained levels. This\napproach preserves as much personalized information as possible while enabling\nonline generation within time constraints. To move a futher step, we propose an\nonline training method based on Reject Preference Optimization (RPO). By\nincorporating a special token [Reject] during both the training and inference\nprocesses, the model achieves adaptive detoxification. Consequently, the\ngenerated text presented to users is both non-toxic and relevant to the given\nprefix. We conduct comprehensive experiments on industrial-scale datasets and\nperform online A/B tests, delivering the largest single-experiment metric\nimprovement in nearly two years of our product. Our model has been deployed on\nKuaishou search, driving the primary traffic for hundreds of millions of active\nusers. The code is available at https://github.com/JXZe/LaD.','Zhibo Wang, Xiaoze Jiang, Zhiheng Qin, Enyun Yu, Han Li','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20966v1','该论文提出了一种新颖的模型 LaD，用于解决查询自动完成系统中的两个关键挑战：个性化表示和毒化问题。该模型通过捕获长期和短期兴趣的个性化信息，并引入自适应毒化方法，实现了在线生成非毒化且相关的文本。'),('2505.20970v2','Understanding the behavior of representation forgetting in continual learning','In continual learning scenarios, catastrophic forgetting of previously\nlearned tasks is a critical issue, making it essential to effectively measure\nsuch forgetting. Recently, there has been growing interest in focusing on\nrepresentation forgetting, the forgetting measured at the hidden layer. In this\npaper, we provide the first theoretical analysis of representation forgetting\nand use this analysis to better understand the behavior of continual learning.\nFirst, we introduce a new metric called representation discrepancy, which\nmeasures the difference between representation spaces constructed by two\nsnapshots of a model trained through continual learning. We demonstrate that\nour proposed metric serves as an effective surrogate for the representation\nforgetting while remaining analytically tractable. Second, through mathematical\nanalysis of our metric, we derive several key findings about the dynamics of\nrepresentation forgetting: the forgetting occurs more rapidly to a higher\ndegree as the layer index increases, while increasing the width of the network\nslows down the forgetting process. Third, we support our theoretical findings\nthrough experiments on real image datasets, including Split-CIFAR100 and\nImageNet1K.','Joonkyu Kim, Yejin Kim, Jy-yong Sohn','2025-05-27','cs.LG','持续学习','http://arxiv.org/pdf/2505.20970v2','本文针对持续学习场景中的灾难性遗忘问题进行了研究，提出了一种新的度量标准称为表示差异度，用于衡量模型通过持续学习构建的两个快照之间的表示空间的差异。通过数学分析，揭示了表示遗忘的动态特性，并在真实图像数据集上进行了实验证实。'),('2505.20971v1','Reason-Align-Respond: Aligning LLM Reasoning with Knowledge Graphs for KGQA','LLMs have demonstrated remarkable capabilities in complex reasoning tasks,\nyet they often suffer from hallucinations and lack reliable factual grounding.\nMeanwhile, knowledge graphs (KGs) provide structured factual knowledge but lack\nthe flexible reasoning abilities of LLMs. In this paper, we present\nReason-Align-Respond (RAR), a novel framework that systematically integrates\nLLM reasoning with knowledge graphs for KGQA. Our approach consists of three\nkey components: a Reasoner that generates human-like reasoning chains, an\nAligner that maps these chains to valid KG paths, and a Responser that\nsynthesizes the final answer. We formulate this process as a probabilistic\nmodel and optimize it using the Expectation-Maximization algorithm, which\niteratively refines the reasoning chains and knowledge paths. Extensive\nexperiments on multiple benchmarks demonstrate the effectiveness of RAR,\nachieving state-of-the-art performance with Hit@1 scores of 93.3% and 91.0% on\nWebQSP and CWQ respectively. Human evaluation confirms that RAR generates\nhigh-quality, interpretable reasoning chains well-aligned with KG paths.\nFurthermore, RAR exhibits strong zero-shot generalization capabilities and\nmaintains computational efficiency during inference.','Xiangqing Shen, Fanfan Wang, Rui Xia','2025-05-27','cs.CL','LLM、知识图谱、自然语言处理','http://arxiv.org/pdf/2505.20971v1','该论文介绍了一种新的框架 Reason-Align-Respond (RAR)，系统地将LLM的推理能力与知识图谱结合，用于知识图谱问答。该方法包括Reasoner生成推理链、Aligner将这些链映射到有效的知识图路径、Responser综合最终答案。通过概率模型和期望最大化算法优化此过程，取得了令人瞩目的性能。'),('2505.20972v1','Deep k-grouping: An Unsupervised Learning Framework for Combinatorial Optimization on Graphs and Hypergraphs','Along with AI computing shining in scientific discovery, its potential in the\ncombinatorial optimization (CO) domain has also emerged in recent years. Yet,\nexisting unsupervised neural network solvers struggle to solve $k$-grouping\nproblems (e.g., coloring, partitioning) on large-scale graphs and hypergraphs,\ndue to limited computational frameworks. In this work, we propose Deep\n$k$-grouping, an unsupervised learning-based CO framework. Specifically, we\ncontribute: Novel one-hot encoded polynomial unconstrained binary optimization\n(OH-PUBO), a formulation for modeling k-grouping problems on graphs and\nhypergraphs (e.g., graph/hypergraph coloring and partitioning); GPU-accelerated\nalgorithms for large-scale k-grouping CO problems. Deep $k$-grouping employs\nthe relaxation of large-scale OH-PUBO objectives as differentiable loss\nfunctions and trains to optimize them in an unsupervised manner. To ensure\nscalability, it leverages GPU-accelerated algorithms to unify the training\npipeline; A Gini coefficient-based continuous relaxation annealing strategy to\nenforce discreteness of solutions while preventing convergence to local optima.\nExperimental results demonstrate that Deep $k$-grouping outperforms existing\nneural network solvers and classical heuristics such as SCIP and Tabu.','Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang','2025-05-27','cs.LG','组合优化、神经网络解算器、GPU加速算法','http://arxiv.org/pdf/2505.20972v1','本文提出了一种基于无监督学习的组合优化框架 Deep k-grouping，用于解决大规模图和超图上的 k-分组问题。通过引入新的编码形式 OH-PUBO 和 GPU 加速算法，Deep k-grouping 在图着色和分区等问题上表现优于现有神经网络解算器和经典启发式算法。'),('2505.20973v2','Towards Conversational Development Environments: Using Theory-of-Mind and Multi-Agent Architectures for Requirements Refinement','Foundation Models (FMs) have shown remarkable capabilities in various natural\nlanguage tasks. However, their ability to accurately capture stakeholder\nrequirements remains a significant challenge for using FMs for software\ndevelopment. This paper introduces a novel approach that leverages an\nFM-powered multi-agent system called AlignMind to address this issue. By having\na cognitive architecture that enhances FMs with Theory-of-Mind capabilities,\nour approach considers the mental states and perspectives of software makers.\nThis allows our solution to iteratively clarify the beliefs, desires, and\nintentions of stakeholders, translating these into a set of refined\nrequirements and a corresponding actionable natural language workflow in the\noften-overlooked requirements refinement phase of software engineering, which\nis crucial after initial elicitation. Through a multifaceted evaluation\ncovering 150 diverse use cases, we demonstrate that our approach can accurately\ncapture the intents and requirements of stakeholders, articulating them as both\nspecifications and a step-by-step plan of action. Our findings suggest that the\npotential for significant improvements in the software development process\njustifies these investments. Our work lays the groundwork for future innovation\nin building intent-first development environments, where software makers can\nseamlessly collaborate with AIs to create software that truly meets their\nneeds.','Keheliya Gallaba, Ali Arabat, Dayi Lin, Mohammed Sayagh, Ahmed E. Hassan','2025-05-27','cs.SE','自然语言处理','http://arxiv.org/pdf/2505.20973v2','本文介绍了一种利用基于基础模型的多智能体系统 AlignMind 的新方法，以解决基础模型在准确捕捉利益相关者需求方面的挑战。通过增强基础模型的认知架构，考虑软件制作者的心理状态和观点，能够准确捕捉利益相关者的意图和需求，并将其转化为规范和可操作的自然语言工作流程。'),('2505.20976v1','Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing','Cross-domain constituency parsing is still an unsolved challenge in\ncomputational linguistics since the available multi-domain constituency\ntreebank is limited. We investigate automatic treebank generation by large\nlanguage models (LLMs) in this paper. The performance of LLMs on constituency\nparsing is poor, therefore we propose a novel treebank generation method, LLM\nback generation, which is similar to the reverse process of constituency\nparsing. LLM back generation takes the incomplete cross-domain constituency\ntree with only domain keyword leaf nodes as input and fills the missing words\nto generate the cross-domain constituency treebank. Besides, we also introduce\na span-level contrastive learning pre-training strategy to make full use of the\nLLM back generation treebank for cross-domain constituency parsing. We verify\nthe effectiveness of our LLM back generation treebank coupled with contrastive\nlearning pre-training on five target domains of MCTB. Experimental results show\nthat our approach achieves state-of-the-art performance on average results\ncompared with various baselines.','Peiming Guo, Meishan Zhang, Jianling Li, Min Zhang, Yue Zhang','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.20976v1','本文研究跨领域的成分句法分析问题，提出了一种基于大型语言模型的自动生成树库方法，并引入了跨领域成分句法分析的对比学习预训练策略。实验证明该方法在MCTB的五个目标领域上取得了最先进的性能。'),('2505.20977v1','Evaluating and Steering Modality Preferences in Multimodal Large Language Model','Multimodal large language models (MLLMs) have achieved remarkable performance\non complex tasks with multimodal context. However, it is still understudied\nwhether they exhibit modality preference when processing multimodal contexts.\nTo study this question, we first build a \\textbf{MC\\textsuperscript{2}}\nbenchmark under controlled evidence conflict scenarios to systematically\nevaluate modality preference, which is the tendency to favor one modality over\nanother when making decisions based on multimodal conflicting evidence. Our\nextensive evaluation reveals that all 18 tested MLLMs generally demonstrate\nclear modality bias, and modality preference can be influenced by external\ninterventions. An in-depth analysis reveals that the preference direction can\nbe captured within the latent representations of MLLMs. Built on this, we\npropose a probing and steering method based on representation engineering to\nexplicitly control modality preference without additional fine-tuning or\ncarefully crafted prompts. Our method effectively amplifies modality preference\ntoward a desired direction and applies to downstream tasks such as\nhallucination mitigation and multimodal machine translation, yielding promising\nimprovements.','Yu Zhang, Jinlong Ma, Yongshuai Hou, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang','2025-05-27','cs.CL','LLM（多模态大型语言模型）','http://arxiv.org/pdf/2505.20977v1','该论文研究了多模态大型语言模型在处理多模态背景时是否存在模态偏好的问题，通过建立一个基于控制证据冲突场景的基准测试，系统评估了模态偏好的表现，并提出了一种基于表示工程的探测和引导方法来明确控制模态偏好。'),('2505.20980v1','Identifying Super Spreaders in Multilayer Networks','Identifying super-spreaders can be framed as a subtask of the influence\nmaximisation problem. It seeks to pinpoint agents within a network that, if\nselected as single diffusion seeds, disseminate information most effectively.\nMultilayer networks, a specific class of heterogeneous graphs, can capture\ndiverse types of interactions (e.g., physical-virtual or professional-social),\nand thus offer a more accurate representation of complex relational structures.\nIn this work, we introduce a novel approach to identifying super-spreaders in\nsuch networks by leveraging graph neural networks. To this end, we construct a\ndataset by simulating information diffusion across hundreds of networks - to\nthe best of our knowledge, the first of its kind tailored specifically to\nmultilayer networks. We further formulate the task as a variation of the\nranking prediction problem based on a four-dimensional vector that quantifies\neach agent\\\'s spreading potential: (i) the number of activations; (ii) the\nduration of the diffusion process; (iii) the peak number of activations; and\n(iv) the simulation step at which this peak occurs. Our model,\nTopSpreadersNetwork, comprises a relationship-agnostic encoder and a custom\naggregation layer. This design enables generalisation to previously unseen data\nand adapts to varying graph sizes. In an extensive evaluation, we compare our\nmodel against classic centrality-based heuristics and competitive deep learning\nmethods. The results, obtained across a broad spectrum of real-world and\nsynthetic multilayer networks, demonstrate that TopSpreadersNetwork achieves\nsuperior performance in identifying high-impact nodes, while also offering\nimproved interpretability through its structured output.','Michał Czuba, Mateusz Stolarski, Adam Piróg, Piotr Bielak, Piotr Bródka','2025-05-27','cs.SI','图神经网络','http://arxiv.org/pdf/2505.20980v1','该论文介绍了一种利用图神经网络在多层网络中识别超级传播者的新方法，通过构建一个数据集并将任务形式化为基于四维向量的排序预测问题，该向量量化了每个代理的传播潜力。他们的模型TopSpreadersNetwork在广泛的评估中表现出优越性能，能够更好地识别高影响节点，并通过结构化输出提供更好的可解释性。'),('2505.20981v1','RefAV: Towards Planning-Centric Scenario Mining','Autonomous Vehicles (AVs) collect and pseudo-label terabytes of multi-modal\ndata localized to HD maps during normal fleet testing. However, identifying\ninteresting and safety-critical scenarios from uncurated driving logs remains a\nsignificant challenge. Traditional scenario mining techniques are error-prone\nand prohibitively time-consuming, often relying on hand-crafted structured\nqueries. In this work, we revisit spatio-temporal scenario mining through the\nlens of recent vision-language models (VLMs) to detect whether a described\nscenario occurs in a driving log and, if so, precisely localize it in both time\nand space. To address this problem, we introduce RefAV, a large-scale dataset\nof 10,000 diverse natural language queries that describe complex multi-agent\ninteractions relevant to motion planning derived from 1000 driving logs in the\nArgoverse 2 Sensor dataset. We evaluate several referential multi-object\ntrackers and present an empirical analysis of our baselines. Notably, we find\nthat naively repurposing off-the-shelf VLMs yields poor performance, suggesting\nthat scenario mining presents unique challenges. Our code and dataset are\navailable at https://github.com/CainanD/RefAV/ and\nhttps://argoverse.github.io/user-guide/tasks/scenario_mining.html','Cainan Davidson, Deva Ramanan, Neehar Peri','2025-05-27','cs.CV','自然语言处理','http://arxiv.org/pdf/2505.20981v1','该论文通过利用最近的视觉-语言模型（VLMs）重新审视时空情景挖掘，以检测驾驶日志中是否发生所描述的情景，并在时间和空间上精确定位。作者引入了一个包含10,000个多样化自然语言查询的大规模数据集RefAV，评估了几种指代多物体跟踪器，并对基线进行了实证分析。'),('2505.20992v1','Efficient Identity and Position Graph Embedding via Spectral-Based Random Feature Aggregation','Graph neural networks (GNNs), which capture graph structures via a feature\naggregation mechanism following the graph embedding framework, have\ndemonstrated a powerful ability to support various tasks. According to the\ntopology properties (e.g., structural roles or community memberships of nodes)\nto be preserved, graph embedding can be categorized into identity and position\nembedding. However, it is unclear for most GNN-based methods which property\nthey can capture. Some of them may also suffer from low efficiency and\nscalability caused by several time- and space-consuming procedures (e.g.,\nfeature extraction and training). From a perspective of graph signal\nprocessing, we find that high- and low-frequency information in the graph\nspectral domain may characterize node identities and positions, respectively.\nBased on this investigation, we propose random feature aggregation (RFA) for\nefficient identity and position embedding, serving as an extreme ablation study\nregarding GNN feature aggregation. RFA (i) adopts a spectral-based GNN without\nlearnable parameters as its backbone, (ii) only uses random noises as inputs,\nand (iii) derives embeddings via just one feed-forward propagation (FFP).\nInspired by degree-corrected spectral clustering, we further introduce a degree\ncorrection mechanism to the GNN backbone. Surprisingly, our experiments\ndemonstrate that two variants of RFA with high- and low-pass filters can\nrespectively derive informative identity and position embeddings via just one\nFFP (i.e., without any training). As a result, RFA can achieve a better\ntrade-off between quality and efficiency for both identity and position\nembedding over various baselines.','Meng Qin, Jiahong Liu, Irwin King','2025-05-27','cs.LG','图神经网络','http://arxiv.org/pdf/2505.20992v1','该论文提出了一种名为random feature aggregation (RFA)的方法，用于高效地进行节点身份和位置嵌入，通过仅进行一次前向传播即可得到信息丰富的嵌入结果，相比其他方法在质量和效率上取得更好的平衡。'),('2505.20993v1','Who Reasons in the Large Language Models?','Despite the impressive performance of large language models (LLMs), the\nprocess of endowing them with new capabilities--such as mathematical\nreasoning--remains largely empirical and opaque. A critical open question is\nwhether reasoning abilities stem from the entire model, specific modules, or\nare merely artifacts of overfitting. In this work, we hypothesize that the\nreasoning capabilities in well-trained LLMs are primarily attributed to the\noutput projection module (oproj) in the Transformer\\\'s multi-head self-attention\n(MHSA) mechanism. To support this hypothesis, we introduce Stethoscope for\nNetworks (SfN), a suite of diagnostic tools designed to probe and analyze the\ninternal behaviors of LLMs. Using SfN, we provide both circumstantial and\nempirical evidence suggesting that oproj plays a central role in enabling\nreasoning, whereas other modules contribute more to fluent dialogue. These\nfindings offer a new perspective on LLM interpretability and open avenues for\nmore targeted training strategies, potentially enabling more efficient and\nspecialized LLMs.','Jie Shao, Jianxin Wu','2025-05-27','cs.CL','LLM（大型语言模型）','http://arxiv.org/pdf/2505.20993v1','该论文研究了大型语言模型（LLMs）如何具备数学推理能力，通过引入一套诊断工具来分析LLMs内部行为，认为输出投影模块（oproj）在启用推理能力方面起着关键作用。'),('2505.20997v1','BIPNN: Learning to Solve Binary Integer Programming via Hypergraph Neural Networks','Binary (0-1) integer programming (BIP) is pivotal in scientific domains\nrequiring discrete decision-making. As the advance of AI computing, recent\nworks explore neural network-based solvers for integer linear programming (ILP)\nproblems. Yet, they lack scalability for tackling nonlinear challenges. To\nhandle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linear\nrelaxations, leading to exponential growth in auxiliary variables and severe\ncomputation limitations. To overcome these limitations, we propose BIPNN\n(Binary Integer Programming Neural Network), an unsupervised learning framework\nto solve nonlinear BIP problems via hypergraph neural networks (HyperGNN).\nSpecifically, BIPNN reformulates BIPs-constrained, discrete, and nonlinear\n(sin, log, exp) optimization problems-into unconstrained, differentiable, and\npolynomial loss functions. The reformulation stems from the observation of a\nprecise one-to-one mapping between polynomial BIP objectives and hypergraph\nstructures, enabling the unsupervised training of HyperGNN to optimize BIP\nproblems in an end-to-end manner. On this basis, we propose a GPU-accelerated\nand continuous-annealing-enhanced training pipeline for BIPNN. The pipeline\nenables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallel\nvia straightforward gradient descent, thus significantly reducing the training\ncost while ensuring the generation of discrete, high-quality solutions.\nExtensive experiments on synthetic and real-world datasets highlight the\nsuperiority of our approach.','Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang','2025-05-27','cs.LG','人工智能、优化算法','http://arxiv.org/pdf/2505.20997v1','该论文提出了一种名为BIPNN的框架，通过超图神经网络(HyperGNN)解决非线性的二进制整数规划问题。通过将BIP问题重新表述为可微损失函数，使得HyperGNN可以在端到端的方式下进行无监督训练，从而优化BIP问题。实验结果表明该方法在合成和真实数据集上具有显著优势。'),('2505.21003v1','Uncertainty Unveiled: Can Exposure to More In-context Examples Mitigate Uncertainty for Large Language Models?','Recent advances in handling long sequences have facilitated the exploration\nof long-context in-context learning (ICL). While much of the existing research\nemphasizes performance improvements driven by additional in-context examples,\nthe influence on the trustworthiness of generated responses remains\nunderexplored. This paper addresses this gap by investigating how increased\nexamples influence predictive uncertainty, an essential aspect in\ntrustworthiness. We begin by systematically quantifying the uncertainty of ICL\nwith varying shot counts, analyzing the impact of example quantity. Through\nuncertainty decomposition, we introduce a novel perspective on performance\nenhancement, with a focus on epistemic uncertainty (EU). Our results reveal\nthat additional examples reduce total uncertainty in both simple and complex\ntasks by injecting task-specific knowledge, thereby diminishing EU and\nenhancing performance. For complex tasks, these advantages emerge only after\naddressing the increased noise and uncertainty associated with longer inputs.\nFinally, we explore the evolution of internal confidence across layers,\nunveiling the mechanisms driving the reduction in uncertainty.','Yifei Wang, Yu Sheng, Linjing Li, Daniel Zeng','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21003v1','本文研究了长序列处理中的长上下文学习（ICL），通过增加示例数量来影响生成响应的可信度。研究发现，增加示例数量可以降低总不确定性，提高性能。'),('2505.21005v1','Efficient and Unbiased Sampling from Boltzmann Distributions via Variance-Tuned Diffusion Models','Score-based diffusion models (SBDMs) are powerful amortized samplers for\nBoltzmann distributions; however, imperfect score estimates bias downstream\nMonte Carlo estimates. Classical importance sampling (IS) can correct this\nbias, but computing exact likelihoods requires solving the probability-flow\nordinary differential equation (PF-ODE), a procedure that is prohibitively\ncostly and scales poorly with dimensionality. We introduce Variance-Tuned\nDiffusion Importance Sampling (VT-DIS), a lightweight post-training method that\nadapts the per-step noise covariance of a pretrained SBDM by minimizing the\n$\\alpha$-divergence ($\\alpha=2$) between its forward diffusion and reverse\ndenoising trajectories. VT-DIS assigns a single trajectory-wise importance\nweight to the joint forward-reverse process, yielding unbiased expectation\nestimates at test time with negligible overhead compared to standard sampling.\nOn the DW-4, LJ-13, and alanine-dipeptide benchmarks, VT-DIS achieves effective\nsample sizes of approximately 80 %, 35 %, and 3.5 %, respectively, while using\nonly a fraction of the computational budget required by vanilla diffusion + IS\nor PF-ODE-based IS.','Fengzhe Zhang, Laurence I. Midgley, José Miguel Hernández-Lobato','2025-05-27','cs.LG','生成模型','http://arxiv.org/pdf/2505.21005v1','该论文介绍了一种名为VT-DIS的轻量级后训练方法，通过最小化前向扩散和反向去噪轨迹之间的$\\alpha$-散度($\\alpha=2$)来调整预训练的SBDM的每步噪声协方差，从而在测试时实现无偏期望估计。'),('2505.21010v1','Unified Alignment Protocol: Making Sense of the Unlabeled Data in New Domains','Semi-Supervised Federated Learning (SSFL) is gaining popularity over\nconventional Federated Learning in many real-world applications. Due to the\npractical limitation of limited labeled data on the client side, SSFL considers\nthat participating clients train with unlabeled data, and only the central\nserver has the necessary resources to access limited labeled data, making it an\nideal fit for real-world applications (e.g., healthcare). However, traditional\nSSFL assumes that the data distributions in the training phase and testing\nphase are the same. In practice, however, domain shifts frequently occur,\nmaking it essential for SSFL to incorporate generalization capabilities and\nenhance their practicality. The core challenge is improving model\ngeneralization to new, unseen domains while the client participate in SSFL.\nHowever, the decentralized setup of SSFL and unsupervised client training\nnecessitates innovation to achieve improved generalization across domains. To\nachieve this, we propose a novel framework called the Unified Alignment\nProtocol (UAP), which consists of an alternating two-stage training process.\nThe first stage involves training the server model to learn and align the\nfeatures with a parametric distribution, which is subsequently communicated to\nclients without additional communication overhead. The second stage proposes a\nnovel training algorithm that utilizes the server feature distribution to align\nclient features accordingly. Our extensive experiments on standard domain\ngeneralization benchmark datasets across multiple model architectures reveal\nthat proposed UAP successfully achieves SOTA generalization performance in SSFL\nsetting.','Sabbir Ahmed, Mamshad Nayeem Rizve, Abdullah Al Arafat, Jacqueline Liu, Rahim Hossain, Mohaiminul Al Nahian, Adnan Siraj Rakin','2025-05-27','cs.CV','联邦学习','http://arxiv.org/pdf/2505.21010v1','该论文提出了一种新颖的框架 Unified Alignment Protocol (UAP)，用于解决半监督联邦学习中的领域泛化问题，通过两阶段训练过程实现模型在新领域的泛化性能。'),('2505.21011v1','LLMs are Frequency Pattern Learners in Natural Language Inference','While fine-tuning LLMs on NLI corpora improves their inferential performance,\nthe underlying mechanisms driving this improvement remain largely opaque. In\nthis work, we conduct a series of experiments to investigate what LLMs actually\nlearn during fine-tuning. We begin by analyzing predicate frequencies in\npremises and hypotheses across NLI datasets and identify a consistent frequency\nbias, where predicates in hypotheses occur more frequently than those in\npremises for positive instances. To assess the impact of this bias, we evaluate\nboth standard and NLI fine-tuned LLMs on bias-consistent and bias-adversarial\ncases. We find that LLMs exploit frequency bias for inference and perform\npoorly on adversarial instances. Furthermore, fine-tuned LLMs exhibit\nsignificantly increased reliance on this bias, suggesting that they are\nlearning these frequency patterns from datasets. Finally, we compute the\nfrequencies of hyponyms and their corresponding hypernyms from WordNet,\nrevealing a correlation between frequency bias and textual entailment. These\nfindings help explain why learning frequency patterns can enhance model\nperformance on inference tasks.','Liang Cheng, Zhaowei Wang, Mark Steedman','2025-05-27','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.21011v1','本文通过一系列实验研究LLMs在NLI数据集上微调时学到的内容，发现LLMs在推理任务中利用频率偏差，并且在对抗性实例上表现不佳。'),('2505.21012v1','Federated Instrumental Variable Analysis via Federated Generalized Method of Moments','Instrumental variables (IV) analysis is an important applied tool for areas\nsuch as healthcare and consumer economics. For IV analysis in high-dimensional\nsettings, the Generalized Method of Moments (GMM) using deep neural networks\noffers an efficient approach. With non-i.i.d. data sourced from scattered\ndecentralized clients, federated learning is a popular paradigm for training\nthe models while promising data privacy. However, to our knowledge, no\nfederated algorithm for either GMM or IV analysis exists to date. In this work,\nwe introduce federated instrumental variables analysis (FedIV) via federated\ngeneralized method of moments (FedGMM). We formulate FedGMM as a federated\nzero-sum game defined by a federated non-convex non-concave minimax\noptimization problem, which is solved using federated gradient descent ascent\n(FedGDA) algorithm. One key challenge arises in theoretically characterizing\nthe federated local optimality. To address this, we present properties and\nexistence results of clients\\\' local equilibria via FedGDA limit points.\nThereby, we show that the federated solution consistently estimates the local\nmoment conditions of every participating client. The proposed algorithm is\nbacked by extensive experiments to demonstrate the efficacy of our approach.','Geetika, Somya Tyagi, Bapi Chatterjee','2025-05-27','cs.LG','联邦学习','http://arxiv.org/pdf/2505.21012v1','本文介绍了一种名为FedIV的方法，通过联邦广义矩估计（FedGMM）进行联邦仪器变量分析。该方法解决了高维设置下的仪器变量分析问题，利用深度神经网络提供了有效的方法，并通过联邦学习保护数据隐私。'),('2505.21019v1','Cardiac Digital Twins at Scale from MRI: Open Tools and Representative Models from ~55000 UK Biobank Participants','A cardiac digital twin is a virtual replica of a patient\\\'s heart for\nscreening, diagnosis, prognosis, risk assessment, and treatment planning of\ncardiovascular diseases. This requires an anatomically accurate\npatient-specific 3D structural representation of the heart, suitable for\nelectro-mechanical simulations or study of disease mechanisms. However,\ngeneration of cardiac digital twins at scale is demanding and there are no\npublic repositories of models across demographic groups. We describe an\nautomatic open-source pipeline for creating patient-specific left and right\nventricular meshes from cardiovascular magnetic resonance images, its\napplication to a large cohort of ~55000 participants from UK Biobank, and the\nconstruction of the most comprehensive cohort of adult heart models to date,\ncomprising 1423 representative meshes across sex (male, female), body mass\nindex (range: 16 - 42 kg/m$^2$) and age (range: 49 - 80 years). Our code is\navailable at https://github.com/cdttk/biv-volumetric-meshing/tree/plos2025 ,\nand pre-trained networks, representative volumetric meshes with fibers and UVCs\nwill be made available soon.','Devran Ugurlu, Shuang Qian, Elliot Fairweather, Charlene Mauger, Bram Ruijsink, Laura Dal Toso, Yu Deng, Marina Strocchi, Reza Razavi, Alistair Young, Pablo Lamata, Steven Niederer, Martin Bishop','2025-05-27','eess.IV','图像识别','http://arxiv.org/pdf/2505.21019v1','该论文介绍了一种自动开源管道，用于从心血管磁共振图像中创建患者特定的左心室和右心室网格，应用于英国生物库的大型队列，并构建迄今为止最全面的成人心脏模型队列。'),('2505.21020v1','NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation','Accurate Subseasonal-to-Seasonal (S2S) ocean simulation is critically\nimportant for marine research, yet remains challenging due to its substantial\nthermal inertia and extended time delay. Machine learning (ML)-based models\nhave demonstrated significant advancements in simulation accuracy and\ncomputational efficiency compared to traditional numerical methods.\nNevertheless, a significant limitation of current ML models for S2S ocean\nsimulation is their inadequate incorporation of physical consistency and the\nslow-changing properties of the ocean system. In this work, we propose a neural\nocean model (NeuralOM) for S2S ocean simulation with a multi-scale interactive\ngraph neural network to emulate diverse physical phenomena associated with\nocean systems effectively. Specifically, we propose a multi-stage framework\ntailored to model the ocean\\\'s slowly changing nature. Additionally, we\nintroduce a multi-scale interactive messaging module to capture complex\ndynamical behaviors, such as gradient changes and multiplicative coupling\nrelationships inherent in ocean dynamics. Extensive experimental evaluations\nconfirm that our proposed NeuralOM outperforms state-of-the-art models in S2S\nand extreme event simulation. The codes are available at\nhttps://github.com/YuanGao-YG/NeuralOM.','Yuan Gao, Ruiqi Shu, Hao Wu, Fan Xu, Yanfei Xiang, Ruijian Gou, Qingsong Wen, Xian Wu, Xiaomeng Huang','2025-05-27','cs.LG','海洋模拟、神经网络','http://arxiv.org/pdf/2505.21020v1','该论文提出了一种名为NeuralOM的神经海洋模型，用于实现准确的亚季节至季节尺度的海洋模拟。该模型采用了多尺度交互式图神经网络，有效地模拟了与海洋系统相关的多样物理现象，并在实验评估中表现优于现有模型。'),('2505.21024v1','Pause Tokens Strictly Increase the Expressivity of Constant-Depth Transformers','Pause tokens, simple filler symbols such as \"...\", consistently improve\nTransformer performance on both language and mathematical tasks, yet their\ntheoretical effect remains unexplained. We provide the first formal separation\nresult, proving that adding pause tokens to constant-depth, logarithmic-width\nTransformers strictly increases their computational expressivity. With\nbounded-precision activations, Transformers without pause tokens compute only a\nstrict subset of $\\mathsf{AC}^0$ functions, while adding a polynomial number of\npause tokens allows them to express the entire class. For logarithmic-precision\nTransformers, we show that adding pause tokens achieves expressivity equivalent\nto $\\mathsf{TC}^0$, matching known upper bounds. Empirically, we demonstrate\nthat two-layer causally masked Transformers can learn parity when supplied with\npause tokens, a function that they appear unable to learn without them. Our\nresults provide a rigorous theoretical explanation for prior empirical\nfindings, clarify how pause tokens interact with width, depth, and numeric\nprecision, and position them as a distinct mechanism, complementary to\nchain-of-thought prompting, for enhancing Transformer reasoning.','Charles London, Varun Kanade','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21024v1','该论文研究了在Transformer模型中添加暂停符号（如“...”）对其计算表达能力的影响，证明了这种操作可以提高Transformer的计算表达能力，并在实验中展示了其在学习某些函数时的有效性。'),('2505.21025v1','Text-Queried Audio Source Separation via Hierarchical Modeling','Target audio source separation with natural language queries presents a\npromising paradigm for extracting arbitrary audio events through arbitrary text\ndescriptions. Existing methods mainly face two challenges, the difficulty in\njointly modeling acoustic-textual alignment and semantic-aware separation\nwithin a blindly-learned single-stage architecture, and the reliance on\nlarge-scale accurately-labeled training data to compensate for inefficient\ncross-modal learning and separation. To address these challenges, we propose a\nhierarchical decomposition framework, HSM-TSS, that decouples the task into\nglobal-local semantic-guided feature separation and structure-preserving\nacoustic reconstruction. Our approach introduces a dual-stage mechanism for\nsemantic separation, operating on distinct global and local semantic feature\nspaces. We first perform global-semantic separation through a global semantic\nfeature space aligned with text queries. A Q-Audio architecture is employed to\nalign audio and text modalities, serving as pretrained global-semantic\nencoders. Conditioned on the predicted global feature, we then perform the\nsecond-stage local-semantic separation on AudioMAE features that preserve\ntime-frequency structures, followed by acoustic reconstruction. We also propose\nan instruction processing pipeline to parse arbitrary text queries into\nstructured operations, extraction or removal, coupled with audio descriptions,\nenabling flexible sound manipulation. Our method achieves state-of-the-art\nseparation performance with data-efficient training while maintaining superior\nsemantic consistency with queries in complex auditory scenes.','Xinlei Yin, Xiulian Peng, Xue Jiang, Zhiwei Xiong, Yan Lu','2025-05-27','cs.SD','自然语言处理','http://arxiv.org/pdf/2505.21025v1','该论文提出了一种分层分解框架 HSM-TSS，用于通过自然语言查询进行目标音频源分离，解决了在单阶段架构中同时建模声学-文本对齐和语义感知分离的困难以及依赖大规模准确标记训练数据的挑战。他们的方法在数据效率训练下实现了最先进的分离性能，同时在复杂的听觉场景中保持了与查询的优越语义一致性。'),('2505.21026v1','Multi-Mode Process Control Using Multi-Task Inverse Reinforcement Learning','In the era of Industry 4.0 and smart manufacturing, process systems\nengineering must adapt to digital transformation. While reinforcement learning\noffers a model-free approach to process control, its applications are limited\nby the dependence on accurate digital twins and well-designed reward functions.\nTo address these limitations, this paper introduces a novel framework that\nintegrates inverse reinforcement learning (IRL) with multi-task learning for\ndata-driven, multi-mode control design. Using historical closed-loop data as\nexpert demonstrations, IRL extracts optimal reward functions and control\npolicies. A latent-context variable is incorporated to distinguish modes,\nenabling the training of mode-specific controllers. Case studies on a\ncontinuous stirred tank reactor and a fed-batch bioreactor validate the\neffectiveness of this framework in handling multi-mode data and training\nadaptable controllers.','Runze Lin, Junghui Chen, Biao Huang, Lei Xie, Hongye Su','2025-05-27','eess.SY','强化学习','http://arxiv.org/pdf/2505.21026v1','本文介绍了一种将逆强化学习（IRL）与多任务学习相结合的新框架，用于基于数据驱动的多模控制设计。通过使用历史闭环数据作为专家演示，IRL提取最佳奖励函数和控制策略，同时引入潜在上下文变量以区分模式，从而训练特定模式的控制器。案例研究验证了该框架在处理多模数据和训练适应性控制器方面的有效性。'),('2505.21032v1','FeatInv: Spatially resolved mapping from feature space to input space using conditional diffusion models','Internal representations are crucial for understanding deep neural networks,\nsuch as their properties and reasoning patterns, but remain difficult to\ninterpret. While mapping from feature space to input space aids in interpreting\nthe former, existing approaches often rely on crude approximations. We propose\nusing a conditional diffusion model - a pretrained high-fidelity diffusion\nmodel conditioned on spatially resolved feature maps - to learn such a mapping\nin a probabilistic manner. We demonstrate the feasibility of this approach\nacross various pretrained image classifiers from CNNs to ViTs, showing\nexcellent reconstruction capabilities. Through qualitative comparisons and\nrobustness analysis, we validate our method and showcase possible applications,\nsuch as the visualization of concept steering in input space or investigations\nof the composite nature of the feature space. This approach has broad potential\nfor improving feature space understanding in computer vision models.','Nils Neukirch, Johanna Vielhaben, Nils Strodthoff','2025-05-27','cs.CV','计算机视觉','http://arxiv.org/pdf/2505.21032v1','该论文提出使用条件扩散模型来学习从特征空间到输入空间的映射，以帮助解释深度神经网络的内部表示。他们展示了这种方法在各种预训练图像分类器上的可行性，并展示了出色的重建能力。'),('2505.21033v1','Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation','Dialogue Topic Segmentation (DTS) aims to divide dialogues into coherent\nsegments. DTS plays a crucial role in various NLP downstream tasks, but suffers\nfrom chronic problems: data shortage, labeling ambiguity, and incremental\ncomplexity of recently proposed solutions. On the other hand, Despite advances\nin Large Language Models (LLMs) and reasoning strategies, these have rarely\nbeen applied to DTS. This paper introduces Def-DTS: Deductive Reasoning for\nOpen-domain Dialogue Topic Segmentation, which utilizes LLM-based multi-step\ndeductive reasoning to enhance DTS performance and enable case study using\nintermediate result. Our method employs a structured prompting approach for\nbidirectional context summarization, utterance intent classification, and\ndeductive topic shift detection. In the intent classification process, we\npropose the generalizable intent list for domain-agnostic dialogue intent\nclassification. Experiments in various dialogue settings demonstrate that\nDef-DTS consistently outperforms traditional and state-of-the-art approaches,\nwith each subtask contributing to improved performance, particularly in\nreducing type 2 error. We also explore the potential for autolabeling,\nemphasizing the importance of LLM reasoning techniques in DTS.','Seungmin Lee, Yongsang Yoo, Minhwa Jung, Min Song','2025-05-27','cs.CL','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.21033v1','该论文介绍了一种新的对话主题分割方法 Def-DTS，利用基于LLM的多步演绎推理来增强DTS性能，并通过中间结果进行案例研究。实验结果表明，Def-DTS在各种对话设置中始终优于传统和最新方法，特别是在减少类型2错误方面表现出色。'),('2505.21034v1','LLaMEA-BO: A Large Language Model Evolutionary Algorithm for Automatically Generating Bayesian Optimization Algorithms','Bayesian optimization (BO) is a powerful class of algorithms for optimizing\nexpensive black-box functions, but designing effective BO algorithms remains a\nmanual, expertise-driven task. Recent advancements in Large Language Models\n(LLMs) have opened new avenues for automating scientific discovery, including\nthe automatic design of optimization algorithms. While prior work has used LLMs\nwithin optimization loops or to generate non-BO algorithms, we tackle a new\nchallenge: Using LLMs to automatically generate full BO algorithm code. Our\nframework uses an evolution strategy to guide an LLM in generating Python code\nthat preserves the key components of BO algorithms: An initial design, a\nsurrogate model, and an acquisition function. The LLM is prompted to produce\nmultiple candidate algorithms, which are evaluated on the established Black-Box\nOptimization Benchmarking (BBOB) test suite from the COmparing Continuous\nOptimizers (COCO) platform. Based on their performance, top candidates are\nselected, combined, and mutated via controlled prompt variations, enabling\niterative refinement. Despite no additional fine-tuning, the LLM-generated\nalgorithms outperform state-of-the-art BO baselines in 19 (out of 24) BBOB\nfunctions in dimension 5 and generalize well to higher dimensions, and\ndifferent tasks (from the Bayesmark framework). This work demonstrates that\nLLMs can serve as algorithmic co-designers, offering a new paradigm for\nautomating BO development and accelerating the discovery of novel algorithmic\ncombinations. The source code is provided at\nhttps://github.com/Ewendawi/LLaMEA-BO.','Wenhu Li, Niki van Stein, Thomas Bäck, Elena Raponi','2025-05-27','cs.LG','LLM, 优化算法','http://arxiv.org/pdf/2505.21034v1','本文利用大型语言模型(Large Language Models, LLMs)自动生成贝叶斯优化(Bayesian optimization, BO)算法代码，通过进化策略指导LLMs生成Python代码，优化了BO算法的性能，超越了现有的基准算法。'),('2505.21036v1','RainFusion: Adaptive Video Generation Acceleration via Multi-Dimensional Visual Redundancy','Video generation using diffusion models is highly computationally intensive,\nwith 3D attention in Diffusion Transformer (DiT) models accounting for over\n80\\% of the total computational resources. In this work, we introduce {\\bf\nRainFusion}, a novel training-free sparse attention method that exploits\ninherent sparsity nature in visual data to accelerate attention computation\nwhile preserving video quality. Specifically, we identify three unique sparse\npatterns in video generation attention calculations--Spatial Pattern, Temporal\nPattern and Textural Pattern. The sparse pattern for each attention head is\ndetermined online with negligible overhead (\\textasciitilde\\,0.2\\%) with our\nproposed {\\bf ARM} (Adaptive Recognition Module) during inference. Our proposed\n{\\bf RainFusion} is a plug-and-play method, that can be seamlessly integrated\ninto state-of-the-art 3D-attention video generation models without additional\ntraining or calibration. We evaluate our method on leading open-sourced models\nincluding HunyuanVideo, OpenSoraPlan-1.2 and CogVideoX-5B, demonstrating its\nbroad applicability and effectiveness. Experimental results show that\nRainFusion achieves over {\\bf 2\\(\\times\\)} speedup in attention computation\nwhile maintaining video quality, with only a minimal impact on VBench scores\n(-0.2\\%).','Aiyue Chen, Bin Dong, Jingru Li, Jing Lin, Yiwu Yao, Gongyi Wang','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21036v1','本文介绍了一种名为RainFusion的新型训练免费的稀疏注意力方法，利用视觉数据中固有的稀疏性质加速注意力计算，同时保持视频质量。通过在线确定每个注意力头的稀疏模式，RainFusion在推断过程中实现了超过2倍的注意力计算加速。'),('2505.21040v2','FCKT: Fine-Grained Cross-Task Knowledge Transfer with Semantic Contrastive Learning for Targeted Sentiment Analysis','In this paper, we address the task of targeted sentiment analysis (TSA),\nwhich involves two sub-tasks, i.e., identifying specific aspects from reviews\nand determining their corresponding sentiments. Aspect extraction forms the\nfoundation for sentiment prediction, highlighting the critical dependency\nbetween these two tasks for effective cross-task knowledge transfer. While most\nexisting studies adopt a multi-task learning paradigm to align task-specific\nfeatures in the latent space, they predominantly rely on coarse-grained\nknowledge transfer. Such approaches lack fine-grained control over\naspect-sentiment relationships, often assuming uniform sentiment polarity\nwithin related aspects. This oversimplification neglects contextual cues that\ndifferentiate sentiments, leading to negative transfer. To overcome these\nlimitations, we propose FCKT, a fine-grained cross-task knowledge transfer\nframework tailored for TSA. By explicitly incorporating aspect-level\ninformation into sentiment prediction, FCKT achieves fine-grained knowledge\ntransfer, effectively mitigating negative transfer and enhancing task\nperformance. Experiments on three datasets, including comparisons with various\nbaselines and large language models (LLMs), demonstrate the effectiveness of\nFCKT. The source code is available on https://github.com/cwei01/FCKT.','Wei Chen, Zhao Zhang, Meng Yuan, Kepeng Xu, Fuzhen Zhuang','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21040v2','本文针对目标情感分析（TSA）任务提出了一种细粒度的跨任务知识传递框架FCKT，通过在情感预测中明确地融入方面级别信息，实现了细粒度的知识传递，有效缓解了负面传递并提升了任务性能。'),('2505.21043v1','Visual Cues Enhance Predictive Turn-Taking for Two-Party Human Interaction','Turn-taking is richly multimodal. Predictive turn-taking models (PTTMs)\nfacilitate naturalistic human-robot interaction, yet most rely solely on\nspeech. We introduce MM-VAP, a multimodal PTTM which combines speech with\nvisual cues including facial expression, head pose and gaze. We find that it\noutperforms the state-of-the-art audio-only in videoconferencing interactions\n(84% vs. 79% hold/shift prediction accuracy). Unlike prior work which\naggregates all holds and shifts, we group by duration of silence between turns.\nThis reveals that through the inclusion of visual features, MM-VAP outperforms\na state-of-the-art audio-only turn-taking model across all durations of speaker\ntransitions. We conduct a detailed ablation study, which reveals that facial\nexpression features contribute the most to model performance. Thus, our working\nhypothesis is that when interlocutors can see one another, visual cues are\nvital for turn-taking and must therefore be included for accurate turn-taking\nprediction. We additionally validate the suitability of automatic speech\nalignment for PTTM training using telephone speech. This work represents the\nfirst comprehensive analysis of multimodal PTTMs. We discuss implications for\nfuture work and make all code publicly available.','Sam O\'Connor Russell, Naomi Harte','2025-05-27','cs.CL','多模态交互','http://arxiv.org/pdf/2505.21043v1','本文介绍了一种多模态的预测轮替模型（MM-VAP），结合了语音和视觉线索，包括面部表情、头部姿势和凝视。研究发现，MM-VAP在视频会议互动中表现优于仅使用语音的最先进模型（84% vs. 79% 的持续/转移预测准确率）。通过将持续和转移按照对话者之间的沉默持续时间进行分组，发现通过包含视觉特征，MM-VAP在所有对话者转换持续时间上都优于最先进的仅使用语音的轮替模型。'),('2505.21045v1','Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking','Low-Altitude Economic Networking (LAENet) aims to support diverse flying\napplications below 1,000 meters by deploying various aerial vehicles for\nflexible and cost-effective aerial networking. However, complex\ndecision-making, resource constraints, and environmental uncertainty pose\nsignificant challenges to the development of the LAENet. Reinforcement learning\n(RL) offers a potential solution in response to these challenges but has\nlimitations in generalization, reward design, and model stability. The\nemergence of large language models (LLMs) offers new opportunities for RL to\nmitigate these limitations. In this paper, we first present a tutorial about\nintegrating LLMs into RL by using the capacities of generation, contextual\nunderstanding, and structured reasoning of LLMs. We then propose an\nLLM-enhanced RL framework for the LAENet in terms of serving the LLM as\ninformation processor, reward designer, decision-maker, and generator.\nMoreover, we conduct a case study by using LLMs to design a reward function to\nimprove the learning performance of RL in the LAENet. Finally, we provide a\nconclusion and discuss future work.','Lingyi Cai, Ruichen Zhang, Changyuan Zhao, Yu Zhang, Jiawen Kang, Dusit Niyato, Tao Jiang, Xuemin Shen','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.21045v1','该论文介绍了如何将大型语言模型（LLMs）集成到强化学习（RL）中，以应对低空经济网络（LAENet）发展中的复杂决策、资源约束和环境不确定性等挑战。作者提出了一个LLM增强的RL框架，并通过案例研究展示了LLMs如何设计奖励函数来提高RL在LAENet中的学习性能。'),('2505.21046v1','A domain adaptation neural network for digital twin-supported fault diagnosis','Digital twins offer a promising solution to the lack of sufficient labeled\ndata in deep learning-based fault diagnosis by generating simulated data for\nmodel training. However, discrepancies between simulation and real-world\nsystems can lead to a significant drop in performance when models are applied\nin real scenarios. To address this issue, we propose a fault diagnosis\nframework based on Domain-Adversarial Neural Networks (DANN), which enables\nknowledge transfer from simulated (source domain) to real-world (target domain)\ndata. We evaluate the proposed framework using a publicly available robotics\nfault diagnosis dataset, which includes 3,600 sequences generated by a digital\ntwin model and 90 real sequences collected from physical systems. The DANN\nmethod is compared with commonly used lightweight deep learning models such as\nCNN, TCN, Transformer, and LSTM. Experimental results show that incorporating\ndomain adaptation significantly improves the diagnostic performance. For\nexample, applying DANN to a baseline CNN model improves its accuracy from\n70.00% to 80.22% on real-world test data, demonstrating the effectiveness of\ndomain adaptation in bridging the sim-to-real gap.','Zhenling Chen, Haiwei Fu, Zhiguo Zeng','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21046v1','该论文提出了一种基于领域对抗神经网络（DANN）的故障诊断框架，通过实现从模拟数据到真实数据的知识转移，解决了数字孪生模型在深度学习故障诊断中的性能下降问题。实验结果表明，领域适应显著提高了诊断性能。'),('2505.21055v1','Agent-Environment Alignment via Automated Interface Generation','Large language model (LLM) agents have shown impressive reasoning\ncapabilities in interactive decision-making tasks. These agents interact with\nenvironment through intermediate interfaces, such as predefined action spaces\nand interaction rules, which mediate the perception and action. However,\nmismatches often happen between the internal expectations of the agent\nregarding the influence of its issued actions and the actual state transitions\nin the environment, a phenomenon referred to as \\textbf{agent-environment\nmisalignment}. While prior work has invested substantially in improving agent\nstrategies and environment design, the critical role of the interface still\nremains underexplored. In this work, we empirically demonstrate that\nagent-environment misalignment poses a significant bottleneck to agent\nperformance. To mitigate this issue, we propose \\textbf{ALIGN}, an\n\\underline{A}uto-A\\underline{l}igned \\underline{I}nterface\n\\underline{G}e\\underline{n}eration framework that alleviates the misalignment\nby enriching the interface. Specifically, the ALIGN-generated interface\nenhances both the static information of the environment and the step-wise\nobservations returned to the agent. Implemented as a lightweight wrapper, this\ninterface achieves the alignment without modifying either the agent logic or\nthe environment code. Experiments across multiple domains including embodied\ntasks, web navigation and tool-use, show consistent performance improvements,\nwith up to a 45.67\\% success rate improvement observed in ALFWorld. Meanwhile,\nALIGN-generated interface can generalize across different agent architectures\nand LLM backbones without interface regeneration. Code and experimental results\nare available at https://github.com/THUNLP-MT/ALIGN.','Kaiming Liu, Xuanyu Lei, Ziyue Wang, Peng Li, Yang Liu','2025-05-27','cs.AI','大型语言模型（LLM）','http://arxiv.org/pdf/2505.21055v1','本文研究了大型语言模型代理在交互式决策任务中的推理能力。作者提出了一种名为ALIGN的自动对齐接口生成框架，通过丰富接口来缓解代理与环境之间的不匹配问题，从而提高代理性能。'),('2505.21061v1','LPOI: Listwise Preference Optimization for Vision Language Models','Aligning large VLMs with human preferences is a challenging task, as methods\nlike RLHF and DPO often overfit to textual information or exacerbate\nhallucinations. Although augmenting negative image samples partially addresses\nthese pitfalls, no prior work has employed listwise preference optimization for\nVLMs, due to the complexity and cost of constructing listwise image samples. In\nthis work, we propose LPOI, the first object-aware listwise preference\noptimization developed for reducing hallucinations in VLMs. LPOI identifies and\nmasks a critical object in the image, and then interpolates the masked region\nbetween the positive and negative images to form a sequence of incrementally\nmore complete images. The model is trained to rank these images in ascending\norder of object visibility, effectively reducing hallucinations while retaining\nvisual fidelity. LPOI requires no extra annotations beyond standard pairwise\npreference data, as it automatically constructs the ranked lists through object\nmasking and interpolation. Comprehensive experiments on MMHalBench, AMBER, and\nObject HalBench confirm that LPOI outperforms existing preference optimization\nmethods in reducing hallucinations and enhancing VLM performance. We make the\ncode available at https://github.com/fatemehpesaran310/lpoi.','Fatemeh Pesaran Zadeh, Yoojin Oh, Gunhee Kim','2025-05-27','cs.CV','生成模型','http://arxiv.org/pdf/2505.21061v1','本文提出了一种新的对象感知列表偏好优化方法 LPOI，用于减少大型 VLMs 中的幻觉，通过识别和遮罩图像中的关键对象，并在正负图像之间插值形成一系列逐渐完整的图像，训练模型以按对象可见性升序排列这些图像，有效减少幻觉同时保留视觉保真度。'),('2505.21067v1','Why Distillation can Outperform Zero-RL: The Role of Flexible Reasoning','Reinforcement learning (RL) has played an important role in improving the\nreasoning ability of large language models (LLMs). Some studies apply RL\ndirectly to \\textit{smaller} base models (known as zero-RL) and also achieve\nnotable progress. However, in this paper, we show that using only 920 examples,\na simple distillation method based on the base model can clearly outperform\nzero-RL, which typically requires much more data and computational cost. By\nanalyzing the token frequency in model outputs, we find that the distilled\nmodel shows more flexible reasoning. It uses anthropomorphic tokens and logical\nconnectors much more often than the zero-RL model. Further analysis reveals\nthat distillation enhances the presence of two advanced cognitive behaviors:\nMulti-Perspective Thinking or Attempting and Metacognitive Awareness. Frequent\noccurrences of these two advanced cognitive behaviors give rise to flexible\nreasoning, which is essential for solving complex reasoning problems, while\nzero-RL fails to significantly boost the frequency of these behaviors.','Xiao Hu, Xingyu Lu, Liyuan Mao, YiFan Zhang, Tianke Zhang, Bin Wen, Fan Yang, Tingting Gao, Guorui Zhou','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.21067v1','本文研究了如何通过简单的蒸馏方法基于基础模型来提高推理能力，相比于直接应用强化学习到较小的基础模型（零强化学习），这种方法在仅使用920个样本的情况下表现更好。通过分析模型输出中的标记频率，发现蒸馏模型展现出更灵活的推理能力，使用人类化标记和逻辑连接词更频繁。进一步分析揭示蒸馏增强了两种高级认知行为的存在，这些行为对于解决复杂推理问题至关重要，而零强化学习未能显著提升这些行为的频率。'),('2505.21068v1','Predicting Implicit Arguments in Procedural Video Instructions','Procedural texts help AI enhance reasoning about context and action\nsequences. Transforming these into Semantic Role Labeling (SRL) improves\nunderstanding of individual steps by identifying predicate-argument structure\nlike {verb,what,where/with}. Procedural instructions are highly elliptic, for\ninstance, (i) add cucumber to the bowl and (ii) add sliced tomatoes, the second\nstep\\\'s where argument is inferred from the context, referring to where the\ncucumber was placed. Prior SRL benchmarks often miss implicit arguments,\nleading to incomplete understanding. To address this, we introduce\nImplicit-VidSRL, a dataset that necessitates inferring implicit and explicit\narguments from contextual information in multimodal cooking procedures. Our\nproposed dataset benchmarks multimodal models\\\' contextual reasoning, requiring\nentity tracking through visual changes in recipes. We study recent multimodal\nLLMs and reveal that they struggle to predict implicit arguments of what and\nwhere/with from multi-modal procedural data given the verb. Lastly, we propose\niSRL-Qwen2-VL, which achieves a 17% relative improvement in F1-score for\nwhat-implicit and a 14.7% for where/with-implicit semantic roles over GPT-4o.','Anil Batra, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller','2025-05-27','cs.CL','自然语言处理(NLP)','http://arxiv.org/pdf/2505.21068v1','该论文介绍了如何将程序性文本转化为语义角色标注（SRL），以提高对个别步骤的理解，通过识别谓语-论元结构。作者提出了一个新的数据集Implicit-VidSRL，要求从多模态烹饪过程中的上下文信息中推断出隐含和显式的论元。他们还提出了iSRL-Qwen2-VL模型，相对于GPT-4o，在what-implicit和where/with-implicit语义角色上取得了显著的提升。'),('2505.21072v2','Faithfulness-Aware Uncertainty Quantification for Fact-Checking the Output of Retrieval Augmented Generation','Large Language Models (LLMs) enhanced with external knowledge retrieval, an\napproach known as Retrieval-Augmented Generation (RAG), have shown strong\nperformance in open-domain question answering. However, RAG systems remain\nsusceptible to hallucinations: factually incorrect outputs that may arise\neither from inconsistencies in the model\\\'s internal knowledge or incorrect use\nof the retrieved context. Existing approaches often conflate factuality with\nfaithfulness to the retrieved context, misclassifying factually correct\nstatements as hallucinations if they are not directly supported by the\nretrieval. In this paper, we introduce FRANQ (Faithfulness-based Retrieval\nAugmented UNcertainty Quantification), a novel method for hallucination\ndetection in RAG outputs. FRANQ applies different Uncertainty Quantification\n(UQ) techniques to estimate factuality based on whether a statement is faithful\nto the retrieved context or not. To evaluate FRANQ and other UQ techniques for\nRAG, we present a new long-form Question Answering (QA) dataset annotated for\nboth factuality and faithfulness, combining automated labeling with manual\nvalidation of challenging examples. Extensive experiments on long- and\nshort-form QA across multiple datasets and LLMs show that FRANQ achieves more\naccurate detection of factual errors in RAG-generated responses compared to\nexisting methods.','Ekaterina Fadeeva, Aleksandr Rubashevskii, Roman Vashurin, Shehzaad Dhuliawala, Artem Shelmanov, Timothy Baldwin, Preslav Nakov, Mrinmaya Sachan, Maxim Panov','2025-05-27','cs.CL','LLM (Large Language Models)、自然语言处理 (NLP)','http://arxiv.org/pdf/2505.21072v2','本文介绍了一种新的方法 FRANQ，用于检测在检索增强生成（RAG）中出现的虚构现象。该方法通过应用不同的不确定性量化技术来估计陈述是否忠实于检索到的上下文，从而更准确地检测 RAG 生成的响应中的事实错误。'),('2505.21074v1','Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling','Text-to-image (T2I) models raise ethical and safety concerns due to their\npotential to generate inappropriate or harmful images. Evaluating these models\\\'\nsecurity through red-teaming is vital, yet white-box approaches are limited by\ntheir need for internal access, complicating their use with closed-source\nmodels. Moreover, existing black-box methods often assume knowledge about the\nmodel\\\'s specific defense mechanisms, limiting their utility in real-world\ncommercial API scenarios. A significant challenge is how to evade unknown and\ndiverse defense mechanisms. To overcome this difficulty, we propose a novel\nRule-based Preference modeling Guided Red-Teaming (RPG-RT), which iteratively\nemploys LLM to modify prompts to query and leverages feedback from T2I systems\nfor fine-tuning the LLM. RPG-RT treats the feedback from each iteration as a\nprior, enabling the LLM to dynamically adapt to unknown defense mechanisms.\nGiven that the feedback is often labeled and coarse-grained, making it\ndifficult to utilize directly, we further propose rule-based preference\nmodeling, which employs a set of rules to evaluate desired or undesired\nfeedback, facilitating finer-grained control over the LLM\\\'s dynamic adaptation\nprocess. Extensive experiments on nineteen T2I systems with varied safety\nmechanisms, three online commercial API services, and T2V models verify the\nsuperiority and practicality of our approach.','Yichuan Cao, Yibo Miao, Xiao-Shan Gao, Yinpeng Dong','2025-05-27','cs.LG','文本到图像生成(Text-to-image generation)','http://arxiv.org/pdf/2505.21074v1','该论文提出了一种新颖的基于规则的偏好建模引导的红队测试方法（RPG-RT），通过迭代使用LLM修改提示查询并利用T2I系统的反馈进行微调，以适应未知的防御机制。实验证明该方法在多种T2I系统、在线商业API服务和T2V模型上具有优越性和实用性。'),('2505.21077v1','Efficient Large Language Model Inference with Neural Block Linearization','The high inference demands of transformer-based Large Language Models (LLMs)\npose substantial challenges in their deployment. To this end, we introduce\nNeural Block Linearization (NBL), a novel framework for accelerating\ntransformer model inference by replacing self-attention layers with linear\napproximations derived from Linear Minimum Mean Squared Error estimators. NBL\nleverages Canonical Correlation Analysis to compute a theoretical upper bound\non the approximation error. Then, we use this bound as a criterion for\nsubstitution, selecting the LLM layers with the lowest linearization error. NBL\ncan be efficiently applied to pre-trained LLMs without the need for\nfine-tuning. In experiments, NBL achieves notable computational speed-ups while\npreserving competitive accuracy on multiple reasoning benchmarks. For instance,\napplying NBL to 12 self-attention layers in DeepSeek-R1-Distill-Llama-8B\nincreases the inference speed by 32% with less than 1% accuracy trade-off,\nmaking it a flexible and promising solution to improve the inference efficiency\nof LLMs.','Mete Erdogan, Francesco Tonin, Volkan Cevher','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21077v1','该论文介绍了一种名为神经块线性化（NBL）的新框架，用于加速transformer模型推理，通过用线性逼近替换自注意力层。NBL在不需要微调的情况下，可以有效地应用于预训练的LLMs。在实验中，NBL在多个推理基准上取得了显著的计算加速，同时保持了竞争性的准确性。'),('2505.21082v2','LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models','Large language models (LLMs) have recently achieved impressive performance\nacross a wide range of natural language tasks and are now widely used in\nreal-world applications. Among them, black-box LLMs--served via APIs without\naccess to model internals--are especially dominant due to their scalability and\nease of deployment. Despite their strong capabilities, these models typically\nproduce generalized responses that overlook personal preferences and reasoning\nstyles. This has led to growing interest in black-box LLM personalization,\nwhich aims to tailor model outputs to user-specific context without modifying\nmodel parameters. However, existing approaches primarily focus on\nresponse-level personalization, attempting to match final outputs without\nmodeling personal thought process. To address this limitation, we propose RPM,\na framework for reasoning-level personalization that aligns the model\\\'s\nreasoning process with a user\\\'s personalized logic. RPM first constructs\nstatistical user-specific factors by extracting and grouping\nresponse-influential features from user history. It then builds personalized\nreasoning paths that reflect how these factors are used in context. In the\ninference stage, RPM retrieves reasoning-aligned examples for new queries via\nfeature-level similarity and performs inference conditioned on the structured\nfactors and retrieved reasoning paths, enabling the model to follow\nuser-specific reasoning trajectories. This reasoning-level personalization\nenhances both predictive accuracy and interpretability by grounding model\noutputs in user-specific logic through structured information. Extensive\nexperiments across diverse tasks show that RPM consistently outperforms\nresponse-level personalization methods, demonstrating the effectiveness of\nreasoning-level personalization in black-box LLMs.','Jieyong Kim, Tongyoung Kim, Soojin Yoon, Jaehyung Kim, Dongha Lee','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21082v2','该论文提出了一种名为RPM的框架，用于在黑匣子大型语言模型中进行推理级个性化，以使模型输出符合用户个性化逻辑。通过提取和分组用户历史数据中的影响特征，并构建反映这些因素在上下文中使用方式的个性化推理路径，RPM能够提高模型的预测准确性和可解释性。'),('2505.21087v1','Stopping Criteria for Value Iteration on Concurrent Stochastic Reachability and Safety Games','We consider two-player zero-sum concurrent stochastic games (CSGs) played on\ngraphs with reachability and safety objectives. These include degenerate\nclasses such as Markov decision processes or turn-based stochastic games, which\ncan be solved by linear or quadratic programming; however, in practice, value\niteration (VI) outperforms the other approaches and is the most implemented\nmethod. Similarly, for CSGs, this practical performance makes VI an attractive\nalternative to the standard theoretical solution via the existential theory of\nreals.\n  VI starts with an under-approximation of the sought values for each state and\niteratively updates them, traditionally terminating once two consecutive\napproximations are $\\epsilon$-close. However, this stopping criterion lacks\nguarantees on the precision of the approximation, which is the goal of this\nwork. We provide bounded (a.k.a. interval) VI for CSGs: it complements standard\nVI with a converging sequence of over-approximations and terminates once the\nover- and under-approximations are $\\epsilon$-close.','Marta Grobelna, Jan Křetínský, Maximilian Weininger','2025-05-27','cs.LO','强化学习','http://arxiv.org/pdf/2505.21087v1','该论文研究了在图上具有可达性和安全性目标的两人零和并发随机游戏，提出了有界值迭代方法来改进值迭代算法的精度。'),('2505.21091v1','Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)','System prompts in Large Language Models (LLMs) are predefined directives that\nguide model behaviour, taking precedence over user inputs in text processing\nand generation. LLM deployers increasingly use them to ensure consistent\nresponses across contexts. While model providers set a foundation of system\nprompts, deployers and third-party developers can append additional prompts\nwithout visibility into others\\\' additions, while this layered implementation\nremains entirely hidden from end-users. As system prompts become more complex,\nthey can directly or indirectly introduce unaccounted for side effects. This\nlack of transparency raises fundamental questions about how the position of\ninformation in different directives shapes model outputs. As such, this work\nexamines how the placement of information affects model behaviour. To this end,\nwe compare how models process demographic information in system versus user\nprompts across six commercially available LLMs and 50 demographic groups. Our\nanalysis reveals significant biases, manifesting in differences in user\nrepresentation and decision-making scenarios. Since these variations stem from\ninaccessible and opaque system-level configurations, they risk\nrepresentational, allocative and potential other biases and downstream harms\nbeyond the user\\\'s ability to detect or correct. Our findings draw attention to\nthese critical issues, which have the potential to perpetuate harms if left\nunexamined. Further, we argue that system prompt analysis must be incorporated\ninto AI auditing processes, particularly as customisable system prompts become\nincreasingly prevalent in commercial AI deployments.','Anna Neumann, Elisabeth Kirsten, Muhammad Bilal Zafar, Jatinder Singh','2025-05-27','cs.CY','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21091v1','该论文研究了在大型语言模型中系统提示的作用，探讨了信息放置对模型行为的影响，比较了系统提示和用户提示中处理人口统计信息的差异，并发现了显著的偏见。'),('2505.21092v1','BLUCK: A Benchmark Dataset for Bengali Linguistic Understanding and Cultural Knowledge','In this work, we introduce BLUCK, a new dataset designed to measure the\nperformance of Large Language Models (LLMs) in Bengali linguistic understanding\nand cultural knowledge. Our dataset comprises 2366 multiple-choice questions\n(MCQs) carefully curated from compiled collections of several college and job\nlevel examinations and spans 23 categories covering knowledge on Bangladesh\\\'s\nculture and history and Bengali linguistics. We benchmarked BLUCK using 6\nproprietary and 3 open-source LLMs - including GPT-4o, Claude-3.5-Sonnet,\nGemini-1.5-Pro, Llama-3.3-70B-Instruct, and DeepSeekV3. Our results show that\nwhile these models perform reasonably well overall, they, however, struggles in\nsome areas of Bengali phonetics. Although current LLMs\\\' performance on Bengali\ncultural and linguistic contexts is still not comparable to that of mainstream\nlanguages like English, our results indicate Bengali\\\'s status as a mid-resource\nlanguage. Importantly, BLUCK is also the first MCQ-based evaluation benchmark\nthat is centered around native Bengali culture, history, and linguistics.','Daeen Kabir, Minhajur Rahman Chowdhury Mahim, Sheikh Shafayat, Adnan Sadik, Arian Ahmed, Eunsu Kim, Alice Oh','2025-05-27','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.21092v1','该论文介绍了BLUCK数据集，旨在衡量大型语言模型在孟加拉语言理解和文化知识方面的表现。通过对2366个多项选择题进行基准测试，结果显示当前的LLMs在孟加拉语音学方面存在一些困难。'),('2505.21095v1','Improved Impossible Tuning and Lipschitz-Adaptive Universal Online Learning with Gradient Variations','A central goal in online learning is to achieve adaptivity to unknown problem\ncharacteristics, such as environmental changes captured by gradient variation\n(GV), function curvature (universal online learning, UOL), and gradient scales\n(Lipschitz adaptivity, LA). Simultaneously achieving these with optimal\nperformance is a major challenge, partly due to limitations in algorithms for\nprediction with expert advice. These algorithms often serve as meta-algorithms\nin online ensemble frameworks, and their sub-optimality hinders overall UOL\nperformance. Specifically, existing algorithms addressing the ``impossible\ntuning\\\'\\\' issue incur an excess $\\sqrt{\\log T}$ factor in their regret bound\ncompared to the lower bound. To solve this problem, we propose a novel\noptimistic online mirror descent algorithm with an auxiliary initial round\nusing large learning rates. This design enables a refined analysis where a\ngenerated negative term cancels the gap-related factor, resolving the\nimpossible tuning issue up to $\\log\\log T$ factors. Leveraging our improved\nalgorithm as a meta-algorithm, we develop the first UOL algorithm that\nsimultaneously achieves state-of-the-art GV bounds and LA under standard\nassumptions. Our UOL result overcomes key limitations of prior works, notably\nresolving the conflict between LA mechanisms and regret analysis for GV bounds\n-- an open problem highlighted by Xie et al.','Kei Takemura, Ryuta Matsuno, Keita Sakuma','2025-05-27','cs.LG','在线学习 (Online Learning)','http://arxiv.org/pdf/2505.21095v1','该论文提出了一种新颖的乐观在线镜像下降算法，通过辅助初始轮使用大学习率，解决了在线学习中的“不可能调整”问题，实现了优化性能。利用改进的算法作为元算法，开发了第一个同时实现最先进GV界限和LA的UOL算法。'),('2505.21097v1','Thinker: Learning to Think Fast and Slow','Recent studies show that the reasoning capabilities of Large Language Models\n(LLMs) can be improved by applying Reinforcement Learning (RL) to\nquestion-answering (QA) tasks in areas such as math and coding. With a long\ncontext length, LLMs may learn to perform search, as indicated by the\nself-correction behavior observed in DeepSeek R1. However, this search behavior\nis often imprecise and lacks confidence, resulting in long, redundant responses\nand highlighting deficiencies in intuition and verification. Inspired by the\nDual Process Theory in psychology, we introduce a simple modification to the QA\ntask that includes four stages: Fast Thinking, where the LLM must answer within\na strict token budget; Verification, where the model evaluates its initial\nresponse; Slow Thinking, where it refines the initial response with more\ndeliberation; and Summarization, where it distills the refinement from the\nprevious stage into precise steps. Our proposed task improves average accuracy\nfrom 24.9% to 27.9% for Qwen2.5-1.5B, and from 45.9% to 49.8% for\nDeepSeek-R1-Qwen-1.5B. Notably, for Qwen2.5-1.5B, the Fast Thinking mode alone\nachieves 26.8% accuracy using fewer than 1000 tokens, demonstrating substantial\ninference efficiency gains. These findings suggest that intuition and\ndeliberative reasoning are distinct, complementary systems benefiting from\ntargeted training.','Stephen Chung, Wenyu Du, Jie Fu','2025-05-27','cs.CL','LLM、强化学习','http://arxiv.org/pdf/2505.21097v1','该论文通过在问答任务中应用强化学习来提高大型语言模型的推理能力，引入了四个阶段的修改来改进QA任务，从而提高了准确率。'),('2505.21101v1','Conditional Diffusion Models with Classifier-Free Gibbs-like Guidance','Classifier-Free Guidance (CFG) is a widely used technique for improving\nconditional diffusion models by linearly combining the outputs of conditional\nand unconditional denoisers. While CFG enhances visual quality and improves\nalignment with prompts, it often reduces sample diversity, leading to a\nchallenging trade-off between quality and diversity. To address this issue, we\nmake two key contributions. First, CFG generally does not correspond to a\nwell-defined denoising diffusion model (DDM). In particular, contrary to common\nintuition, CFG does not yield samples from the target distribution associated\nwith the limiting CFG score as the noise level approaches zero -- where the\ndata distribution is tilted by a power $w \\gt 1$ of the conditional\ndistribution. We identify the missing component: a R\\\\\'enyi divergence term that\nacts as a repulsive force and is required to correct CFG and render it\nconsistent with a proper DDM. Our analysis shows that this correction term\nvanishes in the low-noise limit. Second, motivated by this insight, we propose\na Gibbs-like sampling procedure to draw samples from the desired tilted\ndistribution. This method starts with an initial sample from the conditional\ndiffusion model without CFG and iteratively refines it, preserving diversity\nwhile progressively enhancing sample quality. We evaluate our approach on both\nimage and text-to-audio generation tasks, demonstrating substantial\nimprovements over CFG across all considered metrics. The code is available at\nhttps://github.com/yazidjanati/cfgig','Badr Moufad, Yazid Janati, Alain Durmus, Ahmed Ghorbel, Eric Moulines, Jimmy Olsson','2025-05-27','cs.LG','生成模型 (Generative Models)','http://arxiv.org/pdf/2505.21101v1','该论文提出了一种新的方法解决Classifier-Free Guidance (CFG)在提高条件扩散模型质量和对齐性的同时降低样本多样性的问题。作者发现CFG并不符合良定义的去噪扩散模型(DDM)，并提出了一种新的采样方法来从所需的倾斜分布中绘制样本。'),('2505.21106v1','Interpreting Social Bias in LVLMs via Information Flow Analysis and Multi-Round Dialogue Evaluation','Large Vision Language Models (LVLMs) have achieved remarkable progress in\nmultimodal tasks, yet they also exhibit notable social biases. These biases\noften manifest as unintended associations between neutral concepts and\nsensitive human attributes, leading to disparate model behaviors across\ndemographic groups. While existing studies primarily focus on detecting and\nquantifying such biases, they offer limited insight into the underlying\nmechanisms within the models. To address this gap, we propose an explanatory\nframework that combines information flow analysis with multi-round dialogue\nevaluation, aiming to understand the origin of social bias from the perspective\nof imbalanced internal information utilization. Specifically, we first identify\nhigh-contribution image tokens involved in the model\\\'s reasoning process for\nneutral questions via information flow analysis. Then, we design a multi-turn\ndialogue mechanism to evaluate the extent to which these key tokens encode\nsensitive information. Extensive experiments reveal that LVLMs exhibit\nsystematic disparities in information usage when processing images of different\ndemographic groups, suggesting that social bias is deeply rooted in the model\\\'s\ninternal reasoning dynamics. Furthermore, we complement our findings from a\ntextual modality perspective, showing that the model\\\'s semantic representations\nalready display biased proximity patterns, thereby offering a cross-modal\nexplanation of bias formation.','Zhengyang Ji, Yifan Jia, Shang Gao, Yutao Yue','2025-05-27','cs.AI','多模态学习/社会偏见检测','http://arxiv.org/pdf/2505.21106v1','该论文提出了一个解释性框架，结合信息流分析和多轮对话评估，旨在理解社会偏见的来源，从内部信息利用的不平衡角度进行研究。实验证明，LVLMs在处理不同人群的图像时存在系统性的信息利用差异，表明社会偏见深深扎根于模型的内部推理动态中。'),('2505.21109v1','A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction','Despite recent advancements in domain adaptation techniques for large\nlanguage models, these methods remain computationally intensive, and the\nresulting models can still exhibit hallucination issues. Most existing\nadaptation methods do not prioritize reducing the computational resources\nrequired for fine-tuning and inference of language models. Hallucination issues\nhave gradually decreased with each new model release. However, they remain\nprevalent in engineering contexts, where generating well-structured text with\nminimal errors and inconsistencies is critical. This work introduces a novel\napproach called the Small Language Graph (SLG), which is a lightweight\nadaptation solution designed to address the two key challenges outlined above.\nThe system is structured in the form of a graph, where each node represents a\nlightweight expert - a small language model fine-tuned on specific and concise\ntexts. The results of this study have shown that SLG was able to surpass\nconventional fine-tuning methods on the Exact Match metric by 3 times.\nAdditionally, the fine-tuning process was 1.7 times faster compared to that of\na larger stand-alone language model. These findings introduce a potential for\nsmall to medium-sized engineering companies to confidently use generative AI\ntechnologies, such as LLMs, without the necessity to invest in expensive\ncomputational resources. Also, the graph architecture and the small size of\nexpert nodes offer a possible opportunity for distributed AI systems, thus\npotentially diverting the global need for expensive centralized compute\nclusters.','Bogdan Bogachov, Yaoyao Fiona Zhao','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21109v1','该论文介绍了一种名为Small Language Graph (SLG)的轻量级适应性解决方案，用于解决大语言模型领域适应的两个关键挑战。研究结果表明，SLG在精确匹配指标上超过传统微调方法3倍，并且微调过程比较独立的大型语言模型快1.7倍。'),('2505.21115v1','Will It Still Be True Tomorrow? Multilingual Evergreen Question Classification to Improve Trustworthy QA','Large Language Models (LLMs) often hallucinate in question answering (QA)\ntasks. A key yet underexplored factor contributing to this is the temporality\nof questions -- whether they are evergreen (answers remain stable over time) or\nmutable (answers change). In this work, we introduce EverGreenQA, the first\nmultilingual QA dataset with evergreen labels, supporting both evaluation and\ntraining. Using EverGreenQA, we benchmark 12 modern LLMs to assess whether they\nencode question temporality explicitly (via verbalized judgments) or implicitly\n(via uncertainty signals). We also train EG-E5, a lightweight multilingual\nclassifier that achieves SoTA performance on this task. Finally, we demonstrate\nthe practical utility of evergreen classification across three applications:\nimproving self-knowledge estimation, filtering QA datasets, and explaining\nGPT-4o retrieval behavior.','Sergey Pletenev, Maria Marina, Nikolay Ivanov, Daria Galimzianova, Nikita Krayko, Mikhail Salnikov, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii','2025-05-27','cs.CL','大语言模型(LLM)、自然语言处理(NLP)','http://arxiv.org/pdf/2505.21115v1','本文介绍了EverGreenQA，这是第一个具有永久标签的多语言QA数据集，支持评估和训练。作者使用EverGreenQA对12个现代LLMs进行基准测试，评估它们是否显式地编码问题的时间性或隐式地通过不确定性信号。他们还训练了EG-E5，一个轻量级的多语言分类器，在这一任务上取得了最先进的性能。最后，作者展示了永久分类在三个应用中的实际效用：改善自我知识估计、过滤QA数据集和解释GPT-4o的检索行为。'),('2505.21116v1','Creativity in LLM-based Multi-Agent Systems: A Survey','Large language model (LLM)-driven multi-agent systems (MAS) are transforming\nhow humans and AIs collaboratively generate ideas and artifacts. While existing\nsurveys provide comprehensive overviews of MAS infrastructures, they largely\noverlook the dimension of \\emph{creativity}, including how novel outputs are\ngenerated and evaluated, how creativity informs agent personas, and how\ncreative workflows are coordinated. This is the first survey dedicated to\ncreativity in MAS. We focus on text and image generation tasks, and present:\n(1) a taxonomy of agent proactivity and persona design; (2) an overview of\ngeneration techniques, including divergent exploration, iterative refinement,\nand collaborative synthesis, as well as relevant datasets and evaluation\nmetrics; and (3) a discussion of key challenges, such as inconsistent\nevaluation standards, insufficient bias mitigation, coordination conflicts, and\nthe lack of unified benchmarks. This survey offers a structured framework and\nroadmap for advancing the development, evaluation, and standardization of\ncreative MAS.','Yi-Cheng Lin, Kang-Chieh Chen, Zhe-Yan Li, Tzu-Heng Wu, Tzu-Hsuan Wu, Kuan-Yu Chen, Hung-yi Lee, Yun-Nung Chen','2025-05-27','cs.HC','LLM、自然语言处理','http://arxiv.org/pdf/2505.21116v1','该论文是关于大型语言模型驱动的多智能体系统在创造性任务中的应用和挑战的综述，包括了创意生成和评估、智能体角色设计、创意工作流协调等内容。'),('2505.21119v1','Universal Value-Function Uncertainties','Estimating epistemic uncertainty in value functions is a crucial challenge\nfor many aspects of reinforcement learning (RL), including efficient\nexploration, safe decision-making, and offline RL. While deep ensembles provide\na robust method for quantifying value uncertainty, they come with significant\ncomputational overhead. Single-model methods, while computationally favorable,\noften rely on heuristics and typically require additional propagation\nmechanisms for myopic uncertainty estimates. In this work we introduce\nuniversal value-function uncertainties (UVU), which, similar in spirit to\nrandom network distillation (RND), quantify uncertainty as squared prediction\nerrors between an online learner and a fixed, randomly initialized target\nnetwork. Unlike RND, UVU errors reflect policy-conditional value uncertainty,\nincorporating the future uncertainties any given policy may encounter. This is\ndue to the training procedure employed in UVU: the online network is trained\nusing temporal difference learning with a synthetic reward derived from the\nfixed, randomly initialized target network. We provide an extensive theoretical\nanalysis of our approach using neural tangent kernel (NTK) theory and show that\nin the limit of infinite network width, UVU errors are exactly equivalent to\nthe variance of an ensemble of independent universal value functions.\nEmpirically, we show that UVU achieves equal performance to large ensembles on\nchallenging multi-task offline RL settings, while offering simplicity and\nsubstantial computational savings.','Moritz A. Zanger, Max Weltevrede, Yaniv Oren, Pascal R. Van der Vaart, Caroline Horsch, Wendelin Böhmer, Matthijs T. J. Spaan','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21119v1','本文介绍了一种称为universal value-function uncertainties (UVU) 的方法，用于估计值函数的认知不确定性，通过在线学习器和固定、随机初始化的目标网络之间的平方预测误差来量化不确定性。UVU 在多任务离线强化学习设置中取得了与大型集成相同的性能，同时提供了简单性和大幅的计算节约。'),('2505.21133v1','Robust and Computation-Aware Gaussian Processes','Gaussian processes (GPs) are widely used for regression and optimization\ntasks such as Bayesian optimization (BO) due to their expressiveness and\nprincipled uncertainty estimates. However, in settings with large datasets\ncorrupted by outliers, standard GPs and their sparse approximations struggle\nwith computational tractability and robustness. We introduce Robust\nComputation-aware Gaussian Process (RCaGP), a novel GP model that jointly\naddresses these challenges by combining a principled treatment of\napproximation-induced uncertainty with robust generalized Bayesian updating.\nThe key insight is that robustness and approximation-awareness are not\northogonal but intertwined: approximations can exacerbate the impact of\noutliers, and mitigating one without the other is insufficient. Unlike previous\nwork that focuses narrowly on either robustness or approximation quality, RCaGP\ncombines both in a principled and scalable framework, thus effectively managing\nboth outliers and computational uncertainties introduced by approximations such\nas low-rank matrix multiplications. Our model ensures more conservative and\nreliable uncertainty estimates, a property we rigorously demonstrate.\nAdditionally, we establish a robustness property and show that the mean\nfunction is key to preserving it, motivating a tailored model selection scheme\nfor robust mean functions. Empirical results confirm that solving these\nchallenges jointly leads to superior performance across both clean and\noutlier-contaminated settings, both on regression and high-throughput Bayesian\noptimization benchmarks.','Marshal Arijona Sinaga, Julien Martinelli, Samuel Kaski','2025-05-27','cs.LG','高斯过程模型、贝叶斯优化、异常值处理','http://arxiv.org/pdf/2505.21133v1','该论文介绍了一种新颖的高斯过程模型 RCaGP，通过结合对近似引起的不确定性的原则处理和鲁棒的广义贝叶斯更新，同时解决了大数据集中存在异常值的情况下标准高斯过程和其稀疏逼近的计算可行性和鲁棒性挑战。他们的模型确保更加保守和可靠的不确定性估计，并在回归和高通量贝叶斯优化基准测试中取得了卓越性能。'),('2505.21135v1','Learning Single Index Models with Diffusion Priors','Diffusion models (DMs) have demonstrated remarkable ability to generate\ndiverse and high-quality images by efficiently modeling complex data\ndistributions. They have also been explored as powerful generative priors for\nsignal recovery, resulting in a substantial improvement in the quality of\nreconstructed signals. However, existing research on signal recovery with\ndiffusion models either focuses on specific reconstruction problems or is\nunable to handle nonlinear measurement models with discontinuous or unknown\nlink functions. In this work, we focus on using DMs to achieve accurate\nrecovery from semi-parametric single index models, which encompass a variety of\npopular nonlinear models that may have {\\em discontinuous} and {\\em unknown}\nlink functions. We propose an efficient reconstruction method that only\nrequires one round of unconditional sampling and (partial) inversion of DMs.\nTheoretical analysis on the effectiveness of the proposed methods has been\nestablished under appropriate conditions. We perform numerical experiments on\nimage datasets for different nonlinear measurement models. We observe that\ncompared to competing methods, our approach can yield more accurate\nreconstructions while utilizing significantly fewer neural function\nevaluations.','Anqi Tang, Youming Chen, Shuchen Xue, Zhaoqiang Liu','2025-05-27','cs.LG','图像识别','http://arxiv.org/pdf/2505.21135v1','该论文研究了如何利用扩散模型在半参数单指数模型中实现准确的信号恢复，提出了一种高效的重建方法，并在图像数据集上进行了数值实验，结果表明相比竞争方法，该方法可以实现更准确的重建。'),('2505.21136v2','SageAttention2++: A More Efficient Implementation of SageAttention2','The efficiency of attention is critical because its time complexity grows\nquadratically with sequence length. SageAttention2 addresses this by utilizing\nquantization to accelerate matrix multiplications (Matmul) in attention. To\nfurther accelerate SageAttention2, we propose to utilize the faster instruction\nof FP8 Matmul accumulated in FP16. The instruction is 2x faster than the FP8\nMatmul used in SageAttention2. Our experiments show that SageAttention2++\nachieves a 3.9x speedup over FlashAttention while maintaining the same\nattention accuracy as SageAttention2. This means SageAttention2++ effectively\naccelerates various models, including those for language, image, and video\ngeneration, with negligible end-to-end metrics loss. The code will be available\nat https://github.com/thu-ml/SageAttention.','Jintao Zhang, Xiaoming Xu, Jia Wei, Haofeng Huang, Pengle Zhang, Chendong Xiang, Jun Zhu, Jianfei Chen','2025-05-27','cs.LG','自然语言处理、图像识别','http://arxiv.org/pdf/2505.21136v2','该论文提出了一种名为SageAttention2++的注意力机制，通过利用量化加速注意力机制中的矩阵乘法，进一步利用FP16中更快的指令来加速计算。实验证明，SageAttention2++相比FlashAttention获得了3.9倍的加速，并在保持注意力准确性的同时有效加速了语言、图像和视频生成等模型。'),('2505.21137v1','Scaling and Prompting for Improved End-to-End Spoken Grammatical Error Correction','Spoken Grammatical Error Correction (SGEC) and Feedback (SGECF) are crucial\nfor second language learners, teachers and test takers. Traditional SGEC\nsystems rely on a cascaded pipeline consisting of an ASR, a module for\ndisfluency detection (DD) and removal and one for GEC. With the rise of\nend-to-end (E2E) speech foundation models, we investigate their effectiveness\nin SGEC and feedback generation. This work introduces a pseudo-labelling\nprocess to address the challenge of limited labelled data, expanding the\ntraining data size from 77 hours to approximately 2500 hours, leading to\nimproved performance. Additionally, we prompt an E2E Whisper-based SGEC model\nwith fluent transcriptions, showing a slight improvement in SGEC performance,\nwith more significant gains in feedback generation. Finally, we assess the\nimpact of increasing model size, revealing that while pseudo-labelled data does\nnot yield performance gain for a larger Whisper model, training with prompts\nproves beneficial.','Mengjie Qian, Rao Ma, Stefano Bannò, Kate M. Knill, Mark J. F. Gales','2025-05-27','cs.CL','语音处理','http://arxiv.org/pdf/2505.21137v1','本文研究了口语语法错误纠正（SGEC）和反馈（SGECF）在第二语言学习者、教师和考试者中的重要性。通过引入伪标记过程，扩大了训练数据规模，提高了性能。此外，使用流畅的转录来促进端到端 Whisper 模型在 SGEC 和反馈生成中的表现。'),('2505.21138v1','Leveraging LLM and Self-Supervised Training Models for Speech Recognition in Chinese Dialects: A Comparative Analysis','Large-scale training corpora have significantly improved the performance of\nASR models. Unfortunately, due to the relative scarcity of data, Chinese\naccents and dialects remain a challenge for most ASR models. Recent\nadvancements in self-supervised learning have shown that self-supervised pre-\ntraining, combined with large language models (LLM), can effectively enhance\nASR performance in low-resource scenarios. We aim to investigate the\neffectiveness of this paradigm for Chinese dialects. Specifically, we pre-train\na Data2vec2 model on 300,000 hours of unlabeled dialect and accented speech\ndata and do alignment training on a supervised dataset of 40,000 hours. Then,\nwe systematically examine the impact of various projectors and LLMs on\nMandarin, dialect, and accented speech recognition performance under this\nparadigm. Our method achieved SOTA results on multiple dialect datasets,\nincluding Kespeech. We will open-source our work to promote reproducible\nresearch','Tianyi Xu, Hongjie Chen, Wang Qing, Lv Hang, Jian Kang, Li Jie, Zhennan Lin, Yongxiang Li, Xie Lei','2025-05-27','cs.CL','语音处理','http://arxiv.org/pdf/2505.21138v1','该论文研究了如何利用自监督学习和大型语言模型（LLM）来提高低资源情况下中国方言和口音的语音识别性能，通过对30万小时无标签的方言和口音语音数据进行预训练，并在有监督的40,000小时数据集上进行对齐训练，最终在多个方言数据集上取得了最先进的结果。'),('2505.21140v1','HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs','Heterogeneous graph neural networks (HGNNs) have recently drawn increasing\nattention for modeling complex multi-relational data in domains such as\nrecommendation, finance, and social networks. While existing research has been\nlargely focused on enhancing HGNNs\\\' predictive performance, their robustness\nand security, especially under backdoor attacks, remain underexplored. In this\npaper, we propose a novel Heterogeneous Backdoor Attack (HeteroBA) framework\nfor node classification tasks on heterogeneous graphs. HeteroBA inserts\ncarefully crafted trigger nodes with realistic features and targeted structural\nconnections, leveraging attention-based and clustering-based strategies to\nselect influential auxiliary nodes for effective trigger propagation, thereby\ncausing the model to misclassify specific nodes into a target label while\nmaintaining accuracy on clean data. Experimental results on three datasets and\nvarious HGNN architectures demonstrate that HeteroBA achieves high attack\nsuccess rates with minimal impact on the clean accuracy. Our method sheds light\non potential vulnerabilities in HGNNs and calls for more robust defenses\nagainst backdoor threats in multi-relational graph scenarios.','Honglin Gao, Xiang Li, Lan Zhao, Gaoxi Xiao','2025-05-27','cs.LG','异构图神经网络','http://arxiv.org/pdf/2505.21140v1','该论文提出了一种新颖的异构后门攻击（HeteroBA）框架，用于异构图上的节点分类任务，通过插入精心设计的触发节点来引发模型误分类特定节点，同时对干净数据的准确性影响最小。'),('2505.21147v1','Semi-Supervised Conformal Prediction With Unlabeled Nonconformity Score','Conformal prediction (CP) is a powerful framework for uncertainty\nquantification, providing prediction sets with coverage guarantees when\ncalibrated on sufficient labeled data. However, in real-world applications\nwhere labeled data is often limited, standard CP can lead to coverage deviation\nand output overly large prediction sets. In this paper, we extend CP to the\nsemi-supervised setting and propose SemiCP, leveraging both labeled data and\nunlabeled data for calibration. Specifically, we introduce a novel\nnonconformity score function, NNM, designed for unlabeled data. This function\nselects labeled data with similar pseudo-label scores to estimate nonconformity\nscores, integrating them into the calibration process to overcome sample size\nlimitations. We theoretically demonstrate that, under mild assumptions, SemiCP\nprovide asymptotically coverage guarantee for prediction sets. Extensive\nexperiments further validate that our approach effectively reduces instability\nand inefficiency under limited calibration data, can be adapted to conditional\ncoverage settings, and integrates seamlessly with existing CP methods.','Xuanning Zhou, Hao Zeng, Xiaobo Xia, Bingyi Jing, Hongxin Wei','2025-05-27','cs.LG','符合预测/不确定性量化','http://arxiv.org/pdf/2505.21147v1','本文提出了一种半监督的符合预测框架SemiCP，通过结合有标签数据和无标签数据进行校准，引入了一种新颖的非符合度评分函数NNM，可以在有限的校准数据下有效减少不稳定性和低效性。'),('2505.21148v1','Assessment of L2 Oral Proficiency using Speech Large Language Models','The growing population of L2 English speakers has increased the demand for\ndeveloping automatic graders for spoken language assessment (SLA).\nHistorically, statistical models, text encoders, and self-supervised speech\nmodels have been utilised for this task. However, cascaded systems suffer from\nthe loss of information, while E2E graders also have limitations. With the\nrecent advancements of multi-modal large language models (LLMs), we aim to\nexplore their potential as L2 oral proficiency graders and overcome these\nissues. In this work, we compare various training strategies using regression\nand classification targets. Our results show that speech LLMs outperform all\nprevious competitive baselines, achieving superior performance on two datasets.\nFurthermore, the trained grader demonstrates strong generalisation capabilities\nin the cross-part or cross-task evaluation, facilitated by the audio\nunderstanding knowledge acquired during LLM pre-training.','Rao Ma, Mengjie Qian, Siyuan Tang, Stefano Bannò, Kate M. Knill, Mark J. F. Gales','2025-05-27','cs.CL','语音处理','http://arxiv.org/pdf/2505.21148v1','本文研究了针对第二语言英语学习者口语能力评估的自动评分系统。通过利用多模态大型语言模型（LLMs），作者比较了不同的训练策略，并发现语音LLMs在两个数据集上表现优异，具有强大的泛化能力。'),('2505.21154v1','GGBond: Growing Graph-Based AI-Agent Society for Socially-Aware Recommender Simulation','Current personalized recommender systems predominantly rely on static offline\ndata for algorithm design and evaluation, significantly limiting their ability\nto capture long-term user preference evolution and social influence dynamics in\nreal-world scenarios. To address this fundamental challenge, we propose a\nhigh-fidelity social simulation platform integrating human-like cognitive\nagents and dynamic social interactions to realistically simulate user behavior\nevolution under recommendation interventions. Specifically, the system\ncomprises a population of Sim-User Agents, each equipped with a five-layer\ncognitive architecture that encapsulates key psychological mechanisms,\nincluding episodic memory, affective state transitions, adaptive preference\nlearning, and dynamic trust-risk assessments. In particular, we innovatively\nintroduce the Intimacy--Curiosity--Reciprocity--Risk (ICR2) motivational engine\ngrounded in psychological and sociological theories, enabling more realistic\nuser decision-making processes. Furthermore, we construct a multilayer\nheterogeneous social graph (GGBond Graph) supporting dynamic relational\nevolution, effectively modeling users\\\' evolving social ties and trust dynamics\nbased on interest similarity, personality alignment, and structural homophily.\nDuring system operation, agents autonomously respond to recommendations\ngenerated by typical recommender algorithms (e.g., Matrix Factorization,\nMultVAE, LightGCN), deciding whether to consume, rate, and share content while\ndynamically updating their internal states and social connections, thereby\nforming a stable, multi-round feedback loop. This innovative design transcends\nthe limitations of traditional static datasets, providing a controlled,\nobservable environment for evaluating long-term recommender effects.','Hailin Zhong, Hanlin Wang, Yujun Ye, Meiyi Zhang, Shengxin Zhu','2025-05-27','cs.MA','推荐系统、社交仿真','http://arxiv.org/pdf/2505.21154v1','该论文提出了一个高保真度的社交仿真平台，整合了类人认知代理和动态社交互动，以实现在推荐干预下用户行为演变的真实模拟。通过引入基于心理学和社会学理论的ICR2动机引擎和支持动态关系演化的多层异质社交图，实现了更真实的用户决策过程和社交关系建模。'),('2505.21156v1','Model as Loss: A Self-Consistent Training Paradigm','Conventional methods for speech enhancement rely on handcrafted loss\nfunctions (e.g., time or frequency domain losses) or deep feature losses (e.g.,\nusing WavLM or wav2vec), which often fail to capture subtle signal properties\nessential for optimal performance. To address this, we propose Model as Loss, a\nnovel training paradigm that utilizes the encoder from the same model as a loss\nfunction to guide the training.\n  The Model as Loss paradigm leverages the encoder\\\'s task-specific feature\nspace, optimizing the decoder to produce output consistent with perceptual and\ntask-relevant characteristics of the clean signal. By using the encoder\\\'s\nlearned features as a loss function, this framework enforces self-consistency\nbetween the clean reference speech and the enhanced model output. Our approach\noutperforms pre-trained deep feature losses on standard speech enhancement\nbenchmarks, offering better perceptual quality and robust generalization to\nboth in-domain and out-of-domain datasets.','Saisamarth Rajesh Phaye, Milos Cernak, Andrew Harper','2025-05-27','cs.SD','语音处理','http://arxiv.org/pdf/2505.21156v1','该论文提出了一种新的训练范式 Model as Loss，利用相同模型的编码器作为损失函数来指导训练，以优化解码器产生与干净信号的感知和任务相关特征一致的输出。该方法在标准语音增强基准测试中表现优异，提供更好的感知质量和对域内外数据集的稳健泛化能力。'),('2505.21170v1','Quantum AIXI: Universal Intelligence via Quantum Information','AIXI is a widely studied model of artificial general intelligence (AGI) based\nupon principles of induction and reinforcement learning. However, AIXI is\nfundamentally classical in nature - as are the environments in which it is\nmodelled. Given the universe is quantum mechanical in nature and the\nexponential overhead required to simulate quantum mechanical systems\nclassically, the question arises as to whether there are quantum mechanical\nanalogues of AIXI which are theoretically consistent or practically feasible as\nmodels of universal intelligence. To address this question, we extend the\nframework to quantum information and present Quantum AIXI (QAIXI). We introduce\na model of quantum agent/environment interaction based upon quantum and\nclassical registers and channels, showing how quantum AIXI agents may take both\nclassical and quantum actions. We formulate the key components of AIXI in\nquantum information terms, extending previous research on quantum Kolmogorov\ncomplexity and a QAIXI value function. We discuss conditions and limitations\nupon quantum Solomonoff induction and show how contextuality fundamentally\naffects QAIXI models.','Elija Perrier','2025-05-27','quant-ph','强化学习','http://arxiv.org/pdf/2505.21170v1','该论文探讨了在量子信息框架下，是否存在类似AIXI的量子机制，并提出了Quantum AIXI (QAIXI)模型。研究表明量子信息对AIXI的关键组成部分具有重要影响。'),('2505.21171v1','M-Wanda: Improving One-Shot Pruning for Multilingual LLMs','Multilingual LLM performance is often critically dependent on model size.\nWith an eye on efficiency, this has led to a surge in interest in one-shot\npruning methods that retain the benefits of large-scale pretraining while\nshrinking the model size. However, as pruning tends to come with performance\nloss, it is important to understand the trade-offs between multilinguality and\nsparsification. In this work, we study multilingual performance under different\nsparsity constraints and show that moderate ratios already substantially harm\nperformance. To help bridge this gap, we propose M-Wanda, a pruning method that\nmodels cross-lingual variation by incorporating language-aware activation\nstatistics into its pruning criterion and dynamically adjusts layerwise\nsparsity based on cross-lingual importance. We show that M-Wanda consistently\nimproves performance at minimal additional costs. We are the first to\nexplicitly optimize pruning to retain multilingual performance, and hope to\ninspire future advances in multilingual pruning.','Rochelle Choenni, Ivan Titov','2025-05-27','cs.CL','LLM (多语言学习)','http://arxiv.org/pdf/2505.21171v1','该论文研究了多语言LLM性能与模型大小之间的关系，提出了一种新的剪枝方法M-Wanda，通过考虑跨语言变化并动态调整稀疏度来优化多语言性能。'),('2505.21172v1','TAT-R1: Terminology-Aware Translation with Reinforcement Learning and Word Alignment','Recently, deep reasoning large language models(LLMs) like DeepSeek-R1 have\nmade significant progress in tasks such as mathematics and coding. Inspired by\nthis, several studies have employed reinforcement learning(RL) to enhance\nmodels\\\' deep reasoning capabilities and improve machine translation(MT)\nquality. However, the terminology translation, an essential task in MT, remains\nunexplored in deep reasoning LLMs. In this paper, we propose \\textbf{TAT-R1}, a\nterminology-aware translation model trained with reinforcement learning and\nword alignment. Specifically, we first extract the keyword translation pairs\nusing a word alignment model. Then we carefully design three types of\nrule-based alignment rewards with the extracted alignment relationships. With\nthose alignment rewards, the RL-trained translation model can learn to focus on\nthe accurate translation of key information, including terminology in the\nsource text. Experimental results show the effectiveness of TAT-R1. Our model\nsignificantly improves terminology translation accuracy compared to the\nbaseline models while maintaining comparable performance on general translation\ntasks. In addition, we conduct detailed ablation studies of the\nDeepSeek-R1-like training paradigm for machine translation and reveal several\nkey findings.','Zheng Li, Mao Zheng, Mingyang Song, Wenjie Yang','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21172v1','本文提出了一种使用强化学习和词对齐训练的术语感知翻译模型TAT-R1，用于改善机器翻译中的术语翻译准确性。实验结果表明，该模型在术语翻译准确性方面显著提高，同时在一般翻译任务上保持可比性表现。作者还对类似DeepSeek-R1的训练范式进行了详细的消融研究，揭示了一些关键发现。'),('2505.21173v1','Topological Deep Learning for Speech Data','Topological data analysis (TDA) offers novel mathematical tools for deep\nlearning. Inspired by Carlsson et al., this study designs topology-aware\nconvolutional kernels that significantly improve speech recognition networks.\nTheoretically, by investigating orthogonal group actions on kernels, we\nestablish a fiber-bundle decomposition of matrix spaces, enabling new filter\ngeneration methods. Practically, our proposed Orthogonal Feature (OF) layer\nachieves superior performance in phoneme recognition, particularly in low-noise\nscenarios, while demonstrating cross-domain adaptability. This work reveals\nTDA\\\'s potential in neural network optimization, opening new avenues for\nmathematics-deep learning interdisciplinary studies.','Zhiwang Yu','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21173v1','该论文设计了具有拓扑意识的卷积核，显著改善了语音识别网络的性能。通过研究核上的正交群作用，建立了矩阵空间的纤维丛分解，实现了新的滤波器生成方法。'),('2505.21178v1','Walk Before You Run! Concise LLM Reasoning via Reinforcement Learning','As test-time scaling becomes a pivotal research frontier in Large Language\nModels (LLMs) development, contemporary and advanced post-training\nmethodologies increasingly focus on extending the generation length of long\nChain-of-Thought (CoT) responses to enhance reasoning capabilities toward\nDeepSeek R1-like performance. However, recent studies reveal a persistent\noverthinking phenomenon in state-of-the-art reasoning models, manifesting as\nexcessive redundancy or repetitive thinking patterns in long CoT responses. To\naddress this issue, in this paper, we propose a simple yet effective two-stage\nreinforcement learning framework for achieving concise reasoning in LLMs, named\nConciseR. Specifically, the first stage, using more training steps, aims to\nincentivize the model\\\'s reasoning capabilities via Group Relative Policy\nOptimization with clip-higher and dynamic sampling components (GRPO++), and the\nsecond stage, using fewer training steps, explicitly enforces conciseness and\nimproves efficiency via Length-aware Group Relative Policy Optimization\n(L-GRPO). Significantly, ConciseR only optimizes response length once all\nrollouts of a sample are correct, following the \"walk before you run\"\nprinciple. Extensive experimental results demonstrate that our ConciseR model,\nwhich generates more concise CoT reasoning responses, outperforms recent\nstate-of-the-art reasoning models with zero RL paradigm across AIME 2024,\nMATH-500, AMC 2023, Minerva, and Olympiad benchmarks.','Mingyang Song, Mao Zheng','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21178v1','本文提出了一种名为ConciseR的简洁推理模型，通过两阶段强化学习框架实现对LLMs中长CoT推理响应的简洁生成，优于最新的基于零RL范式的最新推理模型。'),('2505.21180v1','Latent label distribution grid representation for modeling uncertainty','Although \\textbf{L}abel \\textbf{D}istribution \\textbf{L}earning (LDL) has\npromising representation capabilities for characterizing the polysemy of an\ninstance, the complexity and high cost of the label distribution annotation\nlead to inexact in the construction of the label space. The existence of a\nlarge number of inexact labels generates a label space with uncertainty, which\nmisleads the LDL algorithm to yield incorrect decisions. To alleviate this\nproblem, we model the uncertainty of label distributions by constructing a\n\\textbf{L}atent \\textbf{L}abel \\textbf{D}istribution \\textbf{G}rid (LLDG) to\nform a low-noise representation space. Specifically, we first construct a label\ncorrelation matrix based on the differences between labels, and then expand\neach value of the matrix into a vector that obeys a Gaussian distribution, thus\nbuilding a LLDG to model the uncertainty of the label space. Finally, the LLDG\nis reconstructed by the LLDG-Mixer to generate an accurate label distribution.\nNote that we enforce a customized low-rank scheme on this grid, which assumes\nthat the label relations may be noisy and it needs to perform noise-reduction\nwith the help of a Tucker reconstruction technique. Furthermore, we attempt to\nevaluate the effectiveness of the LLDG by considering its generation as an\nupstream task to achieve the classification of the objects. Extensive\nexperimental results show that our approach performs competitively on several\nbenchmarks.','ShuNing Sun, YinSong Xiong, Yu Zhang, Zhuoran Zheng','2025-05-27','cs.LG','标签分布学习 (Label Distribution Learning)','http://arxiv.org/pdf/2505.21180v1','该论文提出了一种通过构建潜在标签分布网格（LLDG）来建模标签分布的不确定性，以减少标签空间的噪声，从而生成准确的标签分布的方法。实验证明该方法在多个基准测试中表现竞争力。'),('2505.21182v1','Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations','Offline imitation learning typically learns from expert and unlabeled\ndemonstrations, yet often overlooks the valuable signal in explicitly\nundesirable behaviors. In this work, we study offline imitation learning from\ncontrasting behaviors, where the dataset contains both expert and undesirable\ndemonstrations. We propose a novel formulation that optimizes a difference of\nKL divergences over the state-action visitation distributions of expert and\nundesirable (or bad) data. Although the resulting objective is a DC\n(Difference-of-Convex) program, we prove that it becomes convex when expert\ndemonstrations outweigh undesirable demonstrations, enabling a practical and\nstable non-adversarial training objective. Our method avoids adversarial\ntraining and handles both positive and negative demonstrations in a unified\nframework. Extensive experiments on standard offline imitation learning\nbenchmarks demonstrate that our approach consistently outperforms\nstate-of-the-art baselines.','Huy Hoang, Tien Mai, Pradeep Varakantham, Tanvi Verma','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21182v1','本论文研究了从对比行为中进行离线模仿学习，数据集包含专家和不良演示。他们提出了一种新的公式，优化专家和不良数据的状态-动作访问分布的KL散度之差。虽然目标是一个DC程序，但当专家演示超过不良演示时，它变得凸，实现了实用和稳定的非对抗训练目标。他们的方法避免了对抗训练，并在一个统一框架中处理正面和负面演示。实验表明，他们的方法在标准离线模仿学习基准测试中始终优于现有技术基线。'),('2505.21184v1','PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing','To construct responsible and secure AI applications, harmful information data\nis widely utilized for adversarial testing and the development of safeguards.\nExisting studies mainly leverage Large Language Models (LLMs) to synthesize\ndata to obtain high-quality task datasets at scale, thereby avoiding costly\nhuman annotation. However, limited by the safety alignment mechanisms of LLMs,\nthe synthesis of harmful data still faces challenges in generation reliability\nand content diversity. In this study, we propose a novel harmful information\nsynthesis framework, PoisonSwarm, which applies the model crowdsourcing\nstrategy to generate diverse harmful data while maintaining a high success\nrate. Specifically, we generate abundant benign data as the based templates in\na counterfactual manner. Subsequently, we decompose each based template into\nmultiple semantic units and perform unit-by-unit toxification and final\nrefinement through dynamic model switching, thus ensuring the success of\nsynthesis. Experimental results demonstrate that PoisonSwarm achieves\nstate-of-the-art performance in synthesizing different categories of harmful\ndata with high scalability and diversity.','Yu Yan, Sheng Sun, Zhifei Zheng, Ziji Hao, Teli Liu, Min Liu','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21184v1','该论文提出了一种新颖的有害信息合成框架PoisonSwarm，应用模型众包策略生成多样化的有害数据，同时保持高成功率。通过动态模型切换，将基础模板分解成多个语义单元，逐个毒化并最终优化，确保合成成功。实验结果表明，PoisonSwarm在合成不同类别的有害数据方面具有高可扩展性和多样性。'),('2505.21189v1','Exploring the Latent Capacity of LLMs for One-Step Text Generation','A recent study showed that large language models (LLMs) can reconstruct\nsurprisingly long texts - up to thousands of tokens - via autoregressive\ngeneration from just one specially trained input embedding. In this work, we\nexplore whether such reconstruction is possible without autoregression. We show\nthat frozen LLMs can generate hundreds of accurate tokens in just one forward\npass, when provided with only two learned embeddings. This reveals a surprising\nand underexplored capability of LLMs - multi-token generation without iterative\ndecoding. We investigate the behaviour of these embeddings and provide insight\ninto the type of information they encode. We also empirically show that\nalthough these representations are not unique for a given text, they form\nconnected and local regions in embedding space - a property that suggests the\npotential of learning a dedicated encoder into that space.','Gleb Mezentsev, Ivan Oseledets','2025-05-27','cs.CL','LLM','http://arxiv.org/pdf/2505.21189v1','该论文研究了大型语言模型（LLMs）是否可以在不使用自回归的情况下重构长文本，通过提供两个学习的嵌入，冻结的LLMs可以在一个前向传递中生成数百个准确的标记。研究揭示了LLMs的一个令人惊讶且未被充分探索的能力 - 多标记生成而无需迭代解码。研究人员还调查了这些嵌入的行为，并提供了关于它们编码的信息类型的见解。'),('2505.21190v1','Lunguage: A Benchmark for Structured and Sequential Chest X-ray Interpretation','Radiology reports convey detailed clinical observations and capture\ndiagnostic reasoning that evolves over time. However, existing evaluation\nmethods are limited to single-report settings and rely on coarse metrics that\nfail to capture fine-grained clinical semantics and temporal dependencies. We\nintroduce LUNGUAGE,a benchmark dataset for structured radiology report\ngeneration that supports both single-report evaluation and longitudinal\npatient-level assessment across multiple studies. It contains 1,473 annotated\nchest X-ray reports, each reviewed by experts, and 80 of them contain\nlongitudinal annotations to capture disease progression and inter-study\nintervals, also reviewed by experts. Using this benchmark, we develop a\ntwo-stage framework that transforms generated reports into fine-grained,\nschema-aligned structured representations, enabling longitudinal\ninterpretation. We also propose LUNGUAGESCORE, an interpretable metric that\ncompares structured outputs at the entity, relation, and attribute level while\nmodeling temporal consistency across patient timelines. These contributions\nestablish the first benchmark dataset, structuring framework, and evaluation\nmetric for sequential radiology reporting, with empirical results demonstrating\nthat LUNGUAGESCORE effectively supports structured report evaluation. The code\nis available at: https://github.com/SuperSupermoon/Lunguage','Jong Hak Moon, Geon Choi, Paloma Rabaey, Min Gwan Kim, Hyuk Gi Hong, Jung-Oh Lee, Hangyul Yoon, Eun Woo Doe, Jiyoun Kim, Harshita Sharma, Daniel C. Castro, Javier Alvarez-Valle, Edward Choi','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21190v1','该论文介绍了一个名为LUNGUAGE的基准数据集，用于结构化放射学报告生成，并支持单一报告评估和纵向患者级评估。作者提出了一个两阶段框架，将生成的报告转换为细粒度、与模式对齐的结构化表示，同时提出了LUNGUAGESCORE，一个可解释的度量标准，用于比较实体、关系和属性级别的结构化输出，同时建模患者时间轴上的时间一致性。'),('2505.21191v1','Unveiling Instruction-Specific Neurons & Experts: An Analytical Framework for LLM\\\'s Instruction-Following Capabilities','The finetuning of Large Language Models (LLMs) has significantly advanced\ntheir instruction-following capabilities, yet the underlying computational\nmechanisms driving these improvements remain poorly understood. This study\nsystematically examines how fine-tuning reconfigures LLM computations by\nisolating and analyzing instruction-specific sparse components, i.e., neurons\nin dense models and both neurons and experts in Mixture-of-Experts (MoE)\narchitectures. In particular, we introduce HexaInst, a carefully curated and\nbalanced instructional dataset spanning six distinct categories, and propose\nSPARCOM, a novel analytical framework comprising three key contributions: (1) a\nmethod for identifying these sparse components, (2) an evaluation of their\nfunctional generality and uniqueness, and (3) a systematic comparison of their\nalterations. Through experiments, we demonstrate functional generality,\nuniqueness, and the critical role of these components in instruction execution.\nBy elucidating the relationship between fine-tuning-induced adaptations and\nsparse computational substrates, this work provides deeper insights into how\nLLMs internalize instruction-following behavior for the trustworthy LLM\ncommunity.','Junyan Zhang, Yubo Gao, Yibo Yan, Jungang Li, Zhaorui Hou, Sicheng Tao, Shuliang Liu, Song Dai, Yonghua Hei, Junzhuo Li, Xuming Hu','2025-05-27','cs.CL','LLM','http://arxiv.org/pdf/2505.21191v1','本研究系统地研究了如何通过细调来重新配置LLM计算，通过分析指令特定的稀疏组件，即密集模型中的神经元和MoE架构中的神经元和专家。通过实验，展示了这些组件在指令执行中的功能普遍性、独特性以及关键作用。'),('2505.21201v1','Crop recommendation with machine learning: leveraging environmental and economic factors for optimal crop selection','Agriculture constitutes a primary source of food production, economic growth\nand employment in India, but the sector is confronted with low farm\nproductivity and yields aggravated by increased pressure on natural resources\nand adverse climate change variability. Efforts involving green revolution,\nland irrigations, improved seeds and organic farming have yielded suboptimal\noutcomes. The adoption of computational tools like crop recommendation systems\noffers a new way to provide insights and help farmers tackle low productivity.\nHowever, most agricultural recommendation systems in India focus narrowly on\nenvironmental factors and regions, limiting accurate predictions of high-yield,\nprofitable crops. This study uses environmental and economic factors with 19\ncrops across 15 states to develop and evaluate Random Forest and SVM models\nusing 10-fold Cross Validation, Time-series Split, and Lag Variables. The\n10-fold cross validation showed high accuracy (RF: 99.96%, SVM: 94.71%) but\nraised overfitting concerns. Introducing temporal order, better reflecting\nreal-world conditions, reduced performance (RF: 78.55%, SVM: 71.18%) in the\nTime-series Split.To further increase the model accuracy while maintaining the\ntemporal order, the Lag Variables approach was employed, which resulted in\nimproved performance (RF: 83.62%, SVM: 74.38%) compared to the 10-fold cross\nvalidation approach. Overall, the models in the Time-series Split and Lag\nVariable Approaches offer practical insights by handling temporal dependencies\nand enhancing its adaptability to changing agricultural conditions over time.\nConsequently, the study shows the Random Forest model developed based on the\nLag Variables as the most preferred algorithm for optimal crop recommendation\nin the Indian context.','Steven Sam, Silima Marshal DAbreo','2025-05-27','cs.LG','农业智能化','http://arxiv.org/pdf/2505.21201v1','该论文研究了印度农业低产出和气候变化对农业生产的影响，提出了使用随机森林和支持向量机模型结合时间序列分割和滞后变量方法来提高农作物推荐系统的准确性。'),('2505.21204v1','Developing hybrid mechanistic and data-driven personalized prediction models for platelet dynamics','Hematotoxicity, drug-induced damage to the blood-forming system, is a\nfrequent side effect of cytotoxic chemotherapy and poses a significant\nchallenge in clinical practice due to its high inter-patient variability and\nlimited predictability. Current mechanistic models often struggle to accurately\nforecast outcomes for patients with irregular or atypical trajectories. In this\nstudy, we develop and compare hybrid mechanistic and data-driven approaches for\nindividualized time series modeling of platelet counts during chemotherapy. We\nconsider hybrid models that combine mechanistic models with neural networks,\nknown as universal differential equations. As a purely data-driven alternative,\nwe utilize a nonlinear autoregressive exogenous model using gated recurrent\nunits as the underlying architecture. These models are evaluated across a range\nof real patient scenarios, varying in data availability and sparsity, to assess\npredictive performance. Our findings demonstrate that data-driven methods, when\nprovided with sufficient data, significantly improve prediction accuracy,\nparticularly for high-risk patients with irregular platelet dynamics. This\nhighlights the potential of data-driven approaches in enhancing clinical\ndecision-making. In contrast, hybrid and mechanistic models are superior in\nscenarios with limited or sparse data. The proposed modeling and comparison\nframework is generalizable and could be extended to predict other\ntreatment-related toxicities, offering broad applicability in personalized\nmedicine.','Marie Steinacker, Yuri Kheifetz, Markus Scholz','2025-05-27','cs.LG','医疗健康AI','http://arxiv.org/pdf/2505.21204v1','该论文研究了在化疗过程中血小板计数的个体化时间序列建模方法，比较了混合机械模型和数据驱动方法的效果，发现数据驱动方法在提高预测准确性方面表现显著，尤其对于血小板动态不规则的高风险患者。'),('2505.21215v1','Transfer learning for multifidelity simulation-based inference in cosmology','Simulation-based inference (SBI) enables cosmological parameter estimation\nwhen closed-form likelihoods or models are unavailable. However, SBI relies on\nmachine learning for neural compression and density estimation. This requires\nlarge training datasets which are prohibitively expensive for high-quality\nsimulations. We overcome this limitation with multifidelity transfer learning,\ncombining less expensive, lower-fidelity simulations with a limited number of\nhigh-fidelity simulations. We demonstrate our methodology on dark matter\ndensity maps from two separate simulation suites in the hydrodynamical CAMELS\nMultifield Dataset. Pre-training on dark-matter-only $N$-body simulations\nreduces the required number of high-fidelity hydrodynamical simulations by a\nfactor between $8$ and $15$, depending on the model complexity, posterior\ndimensionality, and performance metrics used. By leveraging cheaper\nsimulations, our approach enables performant and accurate inference on\nhigh-fidelity models while substantially reducing computational costs.','Alex A. Saoulis, Davide Piras, Niall Jeffrey, Alessio Spurio Mancini, Ana M. G. Ferreira, Benjamin Joachimi','2025-05-27','astro-ph.CO','强化学习','http://arxiv.org/pdf/2505.21215v1','该论文提出了一种基于多保真度迁移学习的方法，结合成本较低的低保真度模拟和有限数量的高保真度模拟，用于宇宙学参数估计。通过在暗物质密度图上进行预训练，可以显著减少高保真度模拟的数量，从而降低计算成本。'),('2505.21218v1','Pretrained LLMs Learn Multiple Types of Uncertainty','Large Language Models are known to capture real-world knowledge, allowing\nthem to excel in many downstream tasks. Despite recent advances, these models\nare still prone to what are commonly known as hallucinations, causing them to\nemit unwanted and factually incorrect text. In this work, we study how well\nLLMs capture uncertainty, without explicitly being trained for that. We show\nthat, if considering uncertainty as a linear concept in the model\\\'s latent\nspace, it might indeed be captured, even after only pretraining. We further\nshow that, though unintuitive, LLMs appear to capture several different types\nof uncertainty, each of which can be useful to predict the correctness for a\nspecific task or benchmark. Furthermore, we provide in-depth results such as\ndemonstrating a correlation between our correction prediction and the model\\\'s\nability to abstain from misinformation using words, and the lack of impact of\nmodel scaling for capturing uncertainty. Finally, we claim that unifying the\nuncertainty types as a single one using instruction-tuning or [IDK]-token\ntuning is helpful for the model in terms of correctness prediction.','Roi Cohen, Omri Fahn, Gerard de Melo','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21218v1','本文研究了大型语言模型如何捕捉不确定性，展示了即使在预训练后，考虑不确定性作为模型潜在空间中的线性概念时，可能会被捕捉到。研究表明，LLMs似乎捕捉到了几种不同类型的不确定性，每种类型对于预测特定任务或基准的正确性都有用。'),('2505.21219v1','Addressing Data Quality Decompensation in Federated Learning via Dynamic Client Selection','In cross-silo Federated Learning (FL), client selection is critical to ensure\nhigh model performance, yet it remains challenging due to data quality\ndecompensation, budget constraints, and incentive compatibility. As training\nprogresses, these factors exacerbate client heterogeneity and degrade global\nperformance. Most existing approaches treat these challenges in isolation,\nmaking jointly optimizing multiple factors difficult. To address this, we\npropose Shapley-Bid Reputation Optimized Federated Learning (SBRO-FL), a\nunified framework integrating dynamic bidding, reputation modeling, and\ncost-aware selection. Clients submit bids based on their perceived data\nquality, and their contributions are evaluated using Shapley values to quantify\ntheir marginal impact on the global model. A reputation system, inspired by\nprospect theory, captures historical performance while penalizing\ninconsistency. The client selection problem is formulated as a 0-1 integer\nprogram that maximizes reputation-weighted utility under budget constraints.\nExperiments on FashionMNIST, EMNIST, CIFAR-10, and SVHN datasets show that\nSBRO-FL improves accuracy, convergence speed, and robustness, even in\nadversarial and low-bid interference scenarios. Our results highlight the\nimportance of balancing data reliability, incentive compatibility, and cost\nefficiency to enable scalable and trustworthy FL deployments.','Qinjun Fei, Nuria Rodríguez-Barroso, María Victoria Luzón, Zhongliang Zhang, Francisco Herrera','2025-05-27','cs.LG','联邦学习','http://arxiv.org/pdf/2505.21219v1','该论文提出了一种统一框架 SBRO-FL，集成了动态竞标、声誉建模和成本感知选择，以解决跨领域联邦学习中的客户选择问题。通过实验验证，SBRO-FL 在提高准确性、收敛速度和鲁棒性方面取得了显著效果。'),('2505.21220v1','Wavelet Flow For Extragalactic Foreground Simulations','Extragalactic foregrounds in cosmic microwave background (CMB) observations\nare both a source of cosmological and astrophysical information and a nuisance\nto the CMB. Effective field-level modeling that captures their non-Gaussian\nstatistical distributions is increasingly important for optimal information\nextraction, particularly given the precise and low-noise observations from\ncurrent and upcoming experiments. We explore the use of Wavelet Flow (WF)\nmodels to tackle the novel task of modeling the field-level probability\ndistributions of multi-component CMB secondaries. Specifically, we jointly\ntrain correlated CMB lensing convergence ($\\kappa$) and cosmic infrared\nbackground (CIB) maps with a WF model and obtain a network that statistically\nrecovers the input to high accuracy -- the trained network generates samples of\n$\\kappa$ and CIB fields whose average power spectra are within a few percent of\nthe inputs across all scales, and whose Minkowski functionals are similarly\naccurate compared to the inputs. Leveraging the multiscale architecture of\nthese models, we fine-tune both the model parameters and the priors at each\nscale independently, optimizing performance across different resolutions. These\nresults demonstrate that WF models can accurately simulate correlated\ncomponents of CMB secondaries, supporting improved analysis of cosmological\ndata. Our code and trained models can be found here\n(https://github.com/matiwosm/HybridPriorWavletFlow.git).','M. Mebratu, W. L. K. Wu','2025-05-27','astro-ph.CO','强化学习','http://arxiv.org/pdf/2505.21220v1','本文研究了在宇宙微波背景（CMB）观测中的星系外前景，提出了使用 Wavelet Flow（WF）模型来建模多组分CMB二次成分的概率分布。他们通过联合训练相关的CMB透镜收敛（$\\kappa$）和宇宙红外背景（CIB）地图，获得了一个能够高度准确地统计恢复输入的网络。'),('2505.21224v1','A Representation Level Analysis of NMT Model Robustness to Grammatical Errors','Understanding robustness is essential for building reliable NLP systems.\nUnfortunately, in the context of machine translation, previous work mainly\nfocused on documenting robustness failures or improving robustness. In\ncontrast, we study robustness from a model representation perspective by\nlooking at internal model representations of ungrammatical inputs and how they\nevolve through model layers. For this purpose, we perform Grammatical Error\nDetection (GED) probing and representational similarity analysis. Our findings\nindicate that the encoder first detects the grammatical error, then corrects it\nby moving its representation toward the correct form. To understand what\ncontributes to this process, we turn to the attention mechanism where we\nidentify what we term Robustness Heads. We find that Robustness Heads attend to\ninterpretable linguistic units when responding to grammatical errors, and that\nwhen we fine-tune models for robustness, they tend to rely more on Robustness\nHeads for updating the ungrammatical word representation.','Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21224v1','该论文研究了从模型表示的角度来理解机器翻译中的鲁棒性，通过Grammatical Error Detection探测和表示相似性分析，发现编码器首先检测语法错误，然后通过将其表示移向正确形式来纠正错误。研究还发现了所谓的Robustness Heads，它们在回应语法错误时关注可解释的语言单元，并且在为鲁棒性进行微调时，模型倾向于更多地依赖于Robustness Heads。'),('2505.21226v1','Why Do More Experts Fail? A Theoretical Analysis of Model Merging','Model merging dramatically reduces storage and computational resources by\ncombining multiple expert models into a single multi-task model. Although\nrecent model merging methods have shown promising results, they struggle to\nmaintain performance gains as the number of merged models increases. In this\npaper, we investigate the key obstacles that limit the scalability of model\nmerging when integrating a large number of expert models. First, we prove that\nthere is an upper bound on model merging. Further theoretical analysis reveals\nthat the limited effective parameter space imposes a strict constraint on the\nnumber of models that can be successfully merged. Gaussian Width shows that the\nmarginal benefit of merging additional models diminishes according to a\nstrictly concave function. This implies that the effective parameter space\nbecomes rapidly saturated as the number of merged models increases.\nFurthermore, using Approximate Kinematics Theory, we prove the existence of a\nunique optimal threshold beyond which adding more models does not yield\nsignificant performance improvements. At the same time, we introduce a\nstraightforward Reparameterized Heavy-Tailed method (RHT) to extend the\ncoverage of the merged model, thereby enhancing its performance. Empirical\nresults on 12 benchmarks, including both knowledge-intensive and\ngeneral-purpose tasks, validate our theoretical analysis. We believe that these\nresults spark further research beyond the current scope of model merging. The\nsource code is in the anonymous Github repository\nhttps://github.com/wzj1718/ModelMergingAnalysis.','Zijing Wang, Xingle Xu, Yongkang Liu, Yiqun Zhang, Peiqin Lin, Shi Feng, Xiaocui Yang, Daling Wang, Hinrich Schütze','2025-05-27','cs.LG','模型合并、机器学习理论','http://arxiv.org/pdf/2505.21226v1','本文研究了模型合并在整合大量专家模型时的可扩展性问题，证明了模型合并存在上限，并提出了一种重参数化重尾方法来提高合并模型的性能。实证结果验证了理论分析的有效性。'),('2505.21228v1','Is Hyperbolic Space All You Need for Medical Anomaly Detection?','Medical anomaly detection has emerged as a promising solution to challenges\nin data availability and labeling constraints. Traditional methods extract\nfeatures from different layers of pre-trained networks in Euclidean space;\nhowever, Euclidean representations fail to effectively capture the hierarchical\nrelationships within these features, leading to suboptimal anomaly detection\nperformance. We propose a novel yet simple approach that projects feature\nrepresentations into hyperbolic space, aggregates them based on confidence\nlevels, and classifies samples as healthy or anomalous. Our experiments\ndemonstrate that hyperbolic space consistently outperforms Euclidean-based\nframeworks, achieving higher AUROC scores at both image and pixel levels across\nmultiple medical benchmark datasets. Additionally, we show that hyperbolic\nspace exhibits resilience to parameter variations and excels in few-shot\nscenarios, where healthy images are scarce. These findings underscore the\npotential of hyperbolic space as a powerful alternative for medical anomaly\ndetection. The project website can be found at\nhttps://hyperbolic-anomalies.github.io','Alvaro Gonzalez-Jimenez, Simone Lionetti, Ludovic Amruthalingam, Philippe Gottfrois, Fabian Gröger, Marc Pouly, Alexander A. Navarini','2025-05-27','cs.CV','医学异常检测','http://arxiv.org/pdf/2505.21228v1','该论文提出了一种新颖且简单的方法，将特征表示投影到双曲空间中，基于置信水平对其进行聚合，并将样本分类为健康或异常。实验证明，双曲空间在多个医学基准数据集上始终优于欧几里得空间的框架，实现了更高的AUROC分数。'),('2505.21230v1','PSRB: A Comprehensive Benchmark for Evaluating Persian ASR Systems','Although Automatic Speech Recognition (ASR) systems have become an integral\npart of modern technology, their evaluation remains challenging, particularly\nfor low-resource languages such as Persian. This paper introduces Persian\nSpeech Recognition Benchmark(PSRB), a comprehensive benchmark designed to\naddress this gap by incorporating diverse linguistic and acoustic conditions.\nWe evaluate ten ASR systems, including state-of-the-art commercial and\nopen-source models, to examine performance variations and inherent biases.\nAdditionally, we conduct an in-depth analysis of Persian ASR transcriptions,\nidentifying key error types and proposing a novel metric that weights\nsubstitution errors. This metric enhances evaluation robustness by reducing the\nimpact of minor and partial errors, thereby improving the precision of\nperformance assessment. Our findings indicate that while ASR models generally\nperform well on standard Persian, they struggle with regional accents,\nchildren\\\'s speech, and specific linguistic challenges. These results highlight\nthe necessity of fine-tuning and incorporating diverse, representative training\ndatasets to mitigate biases and enhance overall ASR performance. PSRB provides\na valuable resource for advancing ASR research in Persian and serves as a\nframework for developing benchmarks in other low-resource languages. A subset\nof the PSRB dataset is publicly available at\nhttps://huggingface.co/datasets/PartAI/PSRB.','Nima Sedghiyeh, Sara Sadeghi, Reza Khodadadi, Farzin Kashani, Omid Aghdaei, Somayeh Rahimi, Mohammad Sadegh Safari','2025-05-27','eess.AS','语音处理','http://arxiv.org/pdf/2505.21230v1','该论文介绍了波斯语语音识别基准（PSRB），旨在解决低资源语言（如波斯语）的ASR系统评估难题。研究评估了十个ASR系统，包括商业和开源模型，发现它们在标准波斯语上表现良好，但在地方口音、儿童语音和特定语言挑战上存在困难。研究提出了一种新的度量标准来加权替换错误，提高了评估的鲁棒性。'),('2505.21236v1','Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies','Reinforcement learning (RL) systems have countless applications, from\nenergy-grid management to protein design. However, such real-world scenarios\nare often extremely difficult, combinatorial in nature, and require complex\ncoordination between multiple agents. This level of complexity can cause even\nstate-of-the-art RL systems, trained until convergence, to hit a performance\nceiling which they are unable to break out of with zero-shot inference.\nMeanwhile, many digital or simulation-based applications allow for an inference\nphase that utilises a specific time and compute budget to explore multiple\nattempts before outputting a final solution. In this work, we show that such an\ninference phase employed at execution time, and the choice of a corresponding\ninference strategy, are key to breaking the performance ceiling observed in\ncomplex multi-agent RL problems. Our main result is striking: we can obtain up\nto a 126% and, on average, a 45% improvement over the previous state-of-the-art\nacross 17 tasks, using only a couple seconds of extra wall-clock time during\nexecution. We also demonstrate promising compute scaling properties, supported\nby over 60k experiments, making it the largest study on inference strategies\nfor complex RL to date. Our experimental data and code are available at\nhttps://sites.google.com/view/inf-marl.','Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Ruan de Kock, Claude Formanek, Sasha Abramowitz, Oumayma Mahjoub, Wiem Khlifi, Simon Du Toit, Louay Ben Nessir, Refiloe Shabe, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21236v1','该论文研究了在复杂多智能体强化学习问题中，利用推理阶段和推理策略选择来突破性能瓶颈，通过在执行过程中使用推理阶段和选择相应的推理策略，能够获得显著的性能提升。'),('2505.21239v1','LMCD: Language Models are Zeroshot Cognitive Diagnosis Learners','Cognitive Diagnosis (CD) has become a critical task in AI-empowered\neducation, supporting personalized learning by accurately assessing students\\\'\ncognitive states. However, traditional CD models often struggle in cold-start\nscenarios due to the lack of student-exercise interaction data. Recent\nNLP-based approaches leveraging pre-trained language models (PLMs) have shown\npromise by utilizing textual features but fail to fully bridge the gap between\nsemantic understanding and cognitive profiling. In this work, we propose\nLanguage Models as Zeroshot Cognitive Diagnosis Learners (LMCD), a novel\nframework designed to handle cold-start challenges by harnessing large language\nmodels (LLMs). LMCD operates via two primary phases: (1) Knowledge Diffusion,\nwhere LLMs generate enriched contents of exercises and knowledge concepts\n(KCs), establishing stronger semantic links; and (2) Semantic-Cognitive Fusion,\nwhere LLMs employ causal attention mechanisms to integrate textual information\nand student cognitive states, creating comprehensive profiles for both students\nand exercises. These representations are efficiently trained with off-the-shelf\nCD models. Experiments on two real-world datasets demonstrate that LMCD\nsignificantly outperforms state-of-the-art methods in both exercise-cold and\ndomain-cold settings. The code is publicly available at\nhttps://github.com/TAL-auroraX/LMCD','Yu He, Zihan Yao, Chentao Song, Tianyu Qi, Jun Liu, Ming Li, Qing Huang','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21239v1','该论文提出了一种名为LMCD的新框架，旨在利用大型语言模型解决认知诊断中的冷启动挑战。通过两个主要阶段操作，LMCD在两个真实数据集上的实验证明其在练习冷启动和领域冷启动设置中明显优于现有方法。'),('2505.21241v1','BindEnergyCraft: Casting Protein Structure Predictors as Energy-Based Models for Binder Design','Protein binder design has been transformed by hallucination-based methods\nthat optimize structure prediction confidence metrics, such as the interface\npredicted TM-score (ipTM), via backpropagation. However, these metrics do not\nreflect the statistical likelihood of a binder-target complex under the learned\ndistribution and yield sparse gradients for optimization. In this work, we\npropose a method to extract such likelihoods from structure predictors by\nreinterpreting their confidence outputs as an energy-based model (EBM). By\nleveraging the Joint Energy-based Modeling (JEM) framework, we introduce\npTMEnergy, a statistical energy function derived from predicted inter-residue\nerror distributions. We incorporate pTMEnergy into BindEnergyCraft (BECraft), a\ndesign pipeline that maintains the same optimization framework as BindCraft but\nreplaces ipTM with our energy-based objective. BECraft outperforms BindCraft,\nRFDiffusion, and ESM3 across multiple challenging targets, achieving higher in\nsilico binder success rates while reducing structural clashes. Furthermore,\npTMEnergy establishes a new state-of-the-art in structure-based virtual\nscreening tasks for miniprotein and RNA aptamer binders.','Divya Nori, Anisha Parsan, Caroline Uhler, Wengong Jin','2025-05-27','cs.LG','蛋白质结合物设计','http://arxiv.org/pdf/2505.21241v1','该论文提出了一种从结构预测器中提取统计似然性的方法，将其重新解释为基于能量的模型，用于蛋白质结合物设计。他们的方法在多个挑战性目标上表现优异，提高了虚拟筛选任务的效率。'),('2505.21242v1','Evaluation of LLMs in Medical Text Summarization: The Role of Vocabulary Adaptation in High OOV Settings','Large Language Models (LLMs) recently achieved great success in medical text\nsummarization by simply using in-context learning. However, these recent\nefforts do not perform fine-grained evaluations under difficult settings where\nLLMs might fail. They typically report performance scores over the entire\ndataset. Through our benchmarking study, we show that LLMs show a significant\nperformance drop for data points with high concentration of out-of-vocabulary\n(OOV) words or with high novelty. Vocabulary adaptation is an intuitive\nsolution to this vocabulary mismatch issue where the LLM vocabulary gets\nupdated with certain expert domain (here, medical) words or subwords. An\ninteresting finding from our study is that Llama-3.1, even with a vocabulary\nsize of around 128K tokens, still faces over-fragmentation issue with medical\nwords. To that end, we show vocabulary adaptation helps improve the LLM\nsummarization performance even in difficult settings. Through extensive\nexperimentation of multiple vocabulary adaptation strategies, two continual\npretraining strategies, and three benchmark medical summarization datasets, we\ngain valuable insights into the role of vocabulary adaptation strategies for\ncustomizing LLMs to the medical domain. We also performed a human evaluation\nstudy with medical experts where they found that vocabulary adaptation results\nin more relevant and faithful summaries. Our codebase is made publicly\navailable at https://github.com/gb-kgp/LLM-MedicalSummarization-Benchmark.','Gunjan Balde, Soumyadeep Roy, Mainack Mondal, Niloy Ganguly','2025-05-27','cs.CL','LLM（Large Language Models）','http://arxiv.org/pdf/2505.21242v1','该论文研究了大型语言模型在医学文本摘要中的性能问题，通过词汇适应策略来改善模型在困难情境下的表现，提高了摘要的相关性和忠实度。'),('2505.21250v1','ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision','Multi-hop question answering (MHQA) involves reasoning across multiple\ndocuments to answer complex questions. Dense retrievers typically outperform\nsparse methods like BM25 by leveraging semantic embeddings; however, they\nrequire labeled query-document pairs for fine-tuning. This poses a significant\nchallenge in MHQA due to the high variability of queries (reformulated)\nquestions throughout the reasoning steps. To overcome this limitation, we\nintroduce Retriever Supervision with Consistency and Relevance (ReSCORE), a\nnovel method for training dense retrievers for MHQA without labeled documents.\nReSCORE leverages large language models to capture each documents relevance to\nthe question and consistency with the correct answer and use them to train a\nretriever within an iterative question-answering framework. Experiments on\nthree MHQA benchmarks demonstrate the effectiveness of ReSCORE, with\nsignificant improvements in retrieval, and in turn, the state-of-the-art MHQA\nperformance. Our implementation is available at:\nhttps://leeds1219.github.io/ReSCORE.','Dosung Lee, Wonjun Oh, Boyoung Kim, Minyoung Kim, Joonsuk Park, Paul Hongsuck Seo','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21250v1','该论文提出了一种名为ReSCORE的新方法，用于在多跳问题回答（MHQA）任务中训练密集检索器，无需标记的文档。通过利用大型语言模型捕捉文档与问题的相关性和一致性，ReSCORE在三个MHQA基准数据集上展现出显著的改进，从而提高了检索和MHQA性能。'),('2505.21251v2','Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework','We introduce copresheaf topological neural networks (CTNNs), a powerful and\nunifying framework that encapsulates a wide spectrum of deep learning\narchitectures, designed to operate on structured data: including images, point\nclouds, graphs, meshes, and topological manifolds. While deep learning has\nprofoundly impacted domains ranging from digital assistants to autonomous\nsystems, the principled design of neural architectures tailored to specific\ntasks and data types remains one of the field\\\'s most persistent open\nchallenges. CTNNs address this gap by grounding model design in the language of\ncopresheaves, a concept from algebraic topology that generalizes and subsumes\nmost practical deep learning models in use today. This abstract yet\nconstructive formulation yields a rich design space from which theoretically\nsound and practically effective solutions can be derived to tackle core\nchallenges in representation learning: long-range dependencies, oversmoothing,\nheterophily, and non-Euclidean domains. Our empirical results on structured\ndata benchmarks demonstrate that CTNNs consistently outperform conventional\nbaselines, particularly in tasks requiring hierarchical or localized\nsensitivity. These results underscore CTNNs as a principled, multi-scale\nfoundation for the next generation of deep learning architectures.','Mustafa Hajij, Lennart Bastian, Sarah Osentoski, Hardik Kabaria, John L. Davenport, Sheik Dawood, Balaji Cherukuri, Joseph G. Kocheemoolayil, Nastaran Shahmansouri, Adrian Lew, Theodore Papamarkou, Tolga Birdal','2025-05-27','cs.LG','深度学习','http://arxiv.org/pdf/2505.21251v2','该论文介绍了copresheaf拓扑神经网络（CTNNs），这是一个强大而统一的框架，涵盖了各种深度学习架构，旨在处理结构化数据，包括图像、点云、图形、网格和拓扑流形。CTNNs通过将模型设计基于代数拓扑学中的copresheaves概念，填补了神经架构针对特定任务和数据类型的缺口。实证结果表明，CTNNs在结构化数据基准测试中始终优于传统基线，特别是在需要分层或局部敏感性的任务中。'),('2505.21265v1','Multilingual Pretraining for Pixel Language Models','Pixel language models operate directly on images of rendered text,\neliminating the need for a fixed vocabulary. While these models have\ndemonstrated strong capabilities for downstream cross-lingual transfer,\nmultilingual pretraining remains underexplored. We introduce PIXEL-M4, a model\npretrained on four visually and linguistically diverse languages: English,\nHindi, Ukrainian, and Simplified Chinese. Multilingual evaluations on semantic\nand syntactic tasks show that PIXEL-M4 outperforms an English-only counterpart\non non-Latin scripts. Word-level probing analyses confirm that PIXEL-M4\ncaptures rich linguistic features, even in languages not seen during\npretraining. Furthermore, an analysis of its hidden representations shows that\nmultilingual pretraining yields a semantic embedding space closely aligned\nacross the languages used for pretraining. This work demonstrates that\nmultilingual pretraining substantially enhances the capability of pixel\nlanguage models to effectively support a diverse set of languages.','Ilker Kesen, Jonas F. Lotz, Ingo Ziegler, Phillip Rust, Desmond Elliott','2025-05-27','cs.CL','LLM (像素语言模型)','http://arxiv.org/pdf/2505.21265v1','该论文介绍了一种基于像素的语言模型 PIXEL-M4，该模型在四种视觉和语言上具有多样性的语言（英语、印地语、乌克兰语和简体中文）上进行了预训练。通过多语言评估，发现PIXEL-M4在语义和句法任务上表现优于仅英语的对照模型，同时在非拉丁文字上表现出色。单词级探究分析证实PIXEL-M4捕捉到丰富的语言特征，即使是在预训练中未见过的语言中也是如此。'),('2505.21277v2','Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space','Large Language Models (LLMs), despite advanced general capabilities, still\nsuffer from numerous safety risks, especially jailbreak attacks that bypass\nsafety protocols. Understanding these vulnerabilities through black-box\njailbreak attacks, which better reflect real-world scenarios, offers critical\ninsights into model robustness. While existing methods have shown improvements\nthrough various prompt engineering techniques, their success remains limited\nagainst safety-aligned models, overlooking a more fundamental problem: the\neffectiveness is inherently bounded by the predefined strategy spaces. However,\nexpanding this space presents significant challenges in both systematically\ncapturing essential attack patterns and efficiently navigating the increased\ncomplexity. To better explore the potential of expanding the strategy space, we\naddress these challenges through a novel framework that decomposes jailbreak\nstrategies into essential components based on the Elaboration Likelihood Model\n(ELM) theory and develops genetic-based optimization with intention evaluation\nmechanisms. To be striking, our experiments reveal unprecedented jailbreak\ncapabilities by expanding the strategy space: we achieve over 90% success rate\non Claude-3.5 where prior methods completely fail, while demonstrating strong\ncross-model transferability and surpassing specialized safeguard models in\nevaluation accuracy. The code is open-sourced at:\nhttps://github.com/Aries-iai/CL-GSO.','Yao Huang, Yitong Sun, Shouwei Ruan, Yichi Zhang, Yinpeng Dong, Xingxing Wei','2025-05-27','cs.CR','大型语言模型 (LLM)、黑盒攻击、模型安全性','http://arxiv.org/pdf/2505.21277v2','该论文提出了一种基于Elaboration Likelihood Model (ELM) 理论的新框架，通过将越狱策略分解为基本组件，并开发基于遗传优化的意图评估机制，以探索扩展策略空间的潜力。实验结果显示，通过扩展策略空间，越狱成功率达到90%以上，在评估准确性方面超越了专门的安全模型。'),('2505.21279v1','XBOUND: Exploring the Capability Boundaries of Device-Control Agents through Trajectory Tree Exploration','Recent advancements in vision-language models (VLMs) have spurred increased\ninterest in Device-Control Agents (DC agents), such as utilizing in-the-wild\ndevice control to manage graphical user interfaces. Conventional methods for\nassessing the capabilities of DC agents, such as computing step-wise action\naccuracy and overall task success rates, provide a macroscopic view of DC\nagents\\\' performance; however, they fail to offer microscopic insights into\npotential errors that may occur in real-world applications. Conducting a\nfiner-grained performance evaluation of DC agents presents significant\nchallenges. This study introduces a new perspective on evaluation methods for\nDC agents by proposing the XBOUND evaluation method, which employs the\ncalculation of a novel Explore Metric to delineate the capability boundaries of\nDC agents. Compared to previous evaluation methods, XBOUND focuses on\nindividual states to assess the proficiency of DC agents in mastering these\nstates. Furthermore, we have developed a ``pseudo\\\'\\\' episode tree dataset\nderived from Android Control test data. Utilizing this dataset and XBOUND, we\ncomprehensively evaluate the OS-Atlas and UI-TARS series, examining both the\noverall and specific performance across five common tasks. Additionally, we\nselect representative cases to highlight the current deficiencies and\nlimitations inherent in both series. Code is available at\nhttps://github.com/sqzhang-lazy/XBOUND.','Shaoqing Zhang, Kehai Chen, Zhuosheng Zhang, Rumei Li, Rongxiang Weng, Yang Xiang, Liqiang Nie, Min Zhang','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.21279v1','该论文介绍了一种新的评估方法XBOUND，用于评估设备控制代理的性能，通过计算探索度量来描绘代理的能力边界。研究使用Android控制测试数据集和XBOUND方法，全面评估了OS-Atlas和UI-TARS系列在五项常见任务中的性能，并突出了两个系列中存在的不足和局限性。'),('2505.21281v1','RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large Language Models','Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existing\nsemantic-enhanced LJP models integrate judicial precedents and legal knowledge\nfor high performance. But they neglect legal reasoning logic, a critical\ncomponent of legal judgments requiring rigorous logical analysis. Although some\napproaches utilize legal reasoning logic for high-quality predictions, their\nlogic rigidity hinders adaptation to case-specific logical frameworks,\nparticularly in complex cases that are lengthy and detailed. This paper\nproposes a rule-enhanced legal judgment prediction framework based on\nfirst-order logic (FOL) formalism and comparative learning (CL) to develop an\nadaptive adjustment mechanism for legal judgment logic and further enhance\nperformance in LJP. Inspired by the process of human exam preparation, our\nmethod follows a three-stage approach: first, we initialize judgment rules\nusing the FOL formalism to capture complex reasoning logic accurately; next, we\npropose a Confusion-aware Contrastive Learning (CACL) to dynamically optimize\nthe judgment rules through a quiz consisting of confusable cases; finally, we\nutilize the optimized judgment rules to predict legal judgments. Experimental\nresults on two public datasets show superior performance across all metrics.\nThe code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}.','Yue Zhang, Zhiliang Tian, Shicheng Zhou, Haiyang Wang, Wenqing Hou, Yuying Liu, Xuechen Zhao, Minlie Huang, Ye Wang, Bin Zhou','2025-05-27','cs.AI','法律人工智能','http://arxiv.org/pdf/2505.21281v1','该论文提出了一种基于一阶逻辑形式主义和比较学习的规则增强法律判决预测框架，通过动态优化判决规则来提高法律判决的性能。'),('2505.21285v1','Learnable Kernel Density Estimation for Graphs','This work proposes a framework LGKDE that learns kernel density estimation\nfor graphs. The key challenge in graph density estimation lies in effectively\ncapturing both structural patterns and semantic variations while maintaining\ntheoretical guarantees. Combining graph kernels and kernel density estimation\n(KDE) is a standard approach to graph density estimation, but has\nunsatisfactory performance due to the handcrafted and fixed features of\nkernels. Our method LGKDE leverages graph neural networks to represent each\ngraph as a discrete distribution and utilizes maximum mean discrepancy to learn\nthe graph metric for multi-scale KDE, where all parameters are learned by\nmaximizing the density of graphs relative to the density of their well-designed\nperturbed counterparts. The perturbations are conducted on both node features\nand graph spectra, which helps better characterize the boundary of normal\ndensity regions. Theoretically, we establish consistency and convergence\nguarantees for LGKDE, including bounds on the mean integrated squared error,\nrobustness, and complexity. We validate LGKDE by demonstrating its\neffectiveness in recovering the underlying density of synthetic graph\ndistributions and applying it to graph anomaly detection across diverse\nbenchmark datasets. Extensive empirical evaluation shows that LGKDE\ndemonstrates superior performance compared to state-of-the-art baselines on\nmost benchmark datasets.','Xudong Wang, Ziheng Sun, Chris Ding, Jicong Fan','2025-05-27','cs.LG','图像识别','http://arxiv.org/pdf/2505.21285v1','该论文提出了一个学习图的核密度估计的框架LGKDE。通过结合图核和核密度估计，利用图神经网络表示每个图为离散分布，并利用最大均值差异学习多尺度KDE的图度量，从而实现了对图密度的有效估计。'),('2505.21288v1','GSAT: Graph Structure Attention Networks','Graph Neural Networks (GNNs) have emerged as a powerful tool for processing\ndata represented in graph structures, achieving remarkable success across a\nwide range of applications. However, to further improve the performance on\ngraph classification benchmarks, structural representation of each node that\nencodes rich local topological information in the neighbourhood of nodes is an\nimportant type of feature that is often overlooked in the modeling. The\nconsequence of neglecting the structural information has resulted high number\nof layers to connect messages from distant nodes which by itself produces other\nproblems such as oversmoothing. In the present paper, we leverage these\nstructural information that are modeled by anonymous random walks (ARWs) and\nintroduce graph structure attention network (GSAT) which is a generalization of\ngraph attention network(GAT) to integrate the original attribute and the\nstructural representation to enforce the model to automatically find patterns\nfor attending to different edges in the node neighbourhood to enrich graph\nrepresentation. Our experiments show GSAT slightly improves SOTA on some graph\nclassification benchmarks.','Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal','2025-05-27','cs.LG','图神经网络','http://arxiv.org/pdf/2505.21288v1','本文提出了一种图结构注意力网络（GSAT），通过整合原始属性和结构表示，自动发现不同边的模式，丰富图表示，进一步提高图分类基准的性能。'),('2505.21289v1','LoFT: Low-Rank Adaptation That Behaves Like Full Fine-Tuning','Large pre-trained models are commonly adapted to downstream tasks using\nparameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA),\nwhich injects small trainable low-rank matrices instead of updating all\nweights. While LoRA dramatically reduces trainable parameters with little\noverhead, it can still underperform full fine-tuning in accuracy and often\nconverges more slowly. We introduce LoFT, a novel low-rank adaptation method\nthat behaves like full fine-tuning by aligning the optimizer\\\'s internal\ndynamics with those of updating all model weights. LoFT not only learns weight\nupdates in a low-rank subspace (like LoRA) but also properly projects the\noptimizer\\\'s first and second moments (Adam\\\'s momentum and variance) into the\nsame subspace, mirroring full-model updates. By aligning the low-rank update\nitself with the full update, LoFT eliminates the need for tuning extra\nhyperparameters, e.g., LoRA scaling factor $\\alpha$. Empirically, this approach\nsubstantially narrows the performance gap between adapter-based tuning and full\nfine-tuning and consistently outperforms standard LoRA-style methods, all\nwithout increasing inference cost.','Nurbek Tastan, Stefanos Laskaridis, Martin Takac, Karthik Nandakumar, Samuel Horvath','2025-05-27','cs.LG','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.21289v1','该论文介绍了一种名为LoFT的新型低秩适应方法，通过将优化器的内部动态与更新所有模型权重的动态对齐，使得在减少可训练参数的同时，能够更接近完全微调的效果，消除了额外超参数调整的需要。'),('2505.21291v1','Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework','In this paper, we present a novel diagnostic framework that integrates\nKnowledge Graphs (KGs) and Large Language Models (LLMs) to support system\ndiagnostics in high-reliability systems such as nuclear power plants.\nTraditional diagnostic modeling struggles when systems become too complex,\nmaking functional modeling a more attractive approach. Our approach introduces\na diagnostic framework grounded in the functional modeling principles of the\nDynamic Master Logic (DML) model. It incorporates two coordinated LLM\ncomponents, including an LLM-based workflow for automated construction of DML\nlogic from system documentation and an LLM agent that facilitates interactive\ndiagnostics. The generated logic is encoded into a structured KG, referred to\nas KG-DML, which supports hierarchical fault reasoning. Expert knowledge or\noperational data can also be incorporated to refine the model\\\'s precision and\ndiagnostic depth. In the interaction phase, users submit natural language\nqueries, which are interpreted by the LLM agent. The agent selects appropriate\ntools for structured reasoning, including upward and downward propagation\nacross the KG-DML. Rather than embedding KG content into every prompt, the LLM\nagent distinguishes between diagnostic and interpretive tasks. For diagnostics,\nthe agent selects and executes external tools that perform structured KG\nreasoning. For general queries, a Graph-based Retrieval-Augmented Generation\n(Graph-RAG) approach is used, retrieving relevant KG segments and embedding\nthem into the prompt to generate natural explanations. A case study on an\nauxiliary feedwater system demonstrated the framework\\\'s effectiveness, with\nover 90% accuracy in key elements and consistent tool and argument extraction,\nsupporting its use in safety-critical diagnostics.','Saman Marandi, Yu-Shu Hu, Mohammad Modarres','2025-05-27','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21291v1','本文提出了一种新颖的诊断框架，将知识图谱和大型语言模型结合起来，支持高可靠性系统（如核电厂）的系统诊断。该框架基于动态主逻辑（DML）模型的功能建模原则，整合了两个协调的LLM组件，包括基于LLM的工作流程用于从系统文档自动构建DML逻辑，以及促进交互式诊断的LLM代理。通过案例研究表明，该框架在关键要素准确性方面达到了90%以上的准确率，支持在安全关键诊断中的应用。'),('2505.21297v1','rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset','Advancing code reasoning in large language models (LLMs) is fundamentally\nlimited by the scarcity of high-difficulty datasets, especially those with\nverifiable input-output test cases necessary for rigorous solution validation\nat scale. We introduce rStar-Coder, which significantly improves LLM code\nreasoning capabilities by constructing a large-scale, verified dataset of 418K\ncompetition-level code problems, 580K long-reasoning solutions along with rich\ntest cases of varying difficulty. This is achieved through three core\ncontributions: (1) we curate competitive programming code problems and oracle\nsolutions to synthesize new, solvable problems; (2) we introduce a reliable\ninput-output test case synthesis pipeline that decouples the generation into a\nthree-step input generation method and a mutual verification mechanism for\neffective output labeling; (3) we augment problems with high-quality,\ntest-case-verified long-reasoning solutions. Extensive experiments on Qwen\nmodels (1.5B-14B) across various code reasoning benchmarks demonstrate the\nsuperiority of rStar-Coder dataset, achieving leading performance comparable to\nfrontier reasoning LLMs with much smaller model sizes. On LiveCodeBench,\nrStar-Coder improves Qwen2.5-7B from 17.4% to an impressive 57.3%, and\nQwen2.5-14B from 23.3% to 62.5%, surpassing o3-mini (low) by3.1%. On the more\nchallenging USA Computing Olympiad, our 7B model achieves an average pass@1\naccuracy of 16.15%, outperforming the frontier-level QWQ-32B. Code and the\ndataset will be released at https://github.com/microsoft/rStar.','Yifei Liu, Li Lyna Zhang, Yi Zhu, Bingcheng Dong, Xudong Zhou, Ning Shang, Fan Yang, Mao Yang','2025-05-27','cs.CL','LLM (大语言模型)','http://arxiv.org/pdf/2505.21297v1','该论文介绍了 rStar-Coder，通过构建一个包含418K竞赛级别代码问题、580K长推理解决方案和各种难度测试用例的大规模验证数据集，显著提高了LLM代码推理能力。他们通过三个核心贡献实现了这一目标：(1)筛选竞争性编程代码问题和预设解决方案，以合成新的可解决问题；(2)引入可靠的输入-输出测试用例合成管道，将生成分解为三步输入生成方法和有效输出标记的相互验证机制；(3)增强了具有高质量、经测试验证的长推理解决方案的问题。'),('2505.21298v1','Large Language Models Miss the Multi-Agent Mark','Recent interest in Multi-Agent Systems of Large Language Models (MAS LLMs)\nhas led to an increase in frameworks leveraging multiple LLMs to tackle complex\ntasks. However, much of this literature appropriates the terminology of MAS\nwithout engaging with its foundational principles. In this position paper, we\nhighlight critical discrepancies between MAS theory and current MAS LLMs\nimplementations, focusing on four key areas: the social aspect of agency,\nenvironment design, coordination and communication protocols, and measuring\nemergent behaviours. Our position is that many MAS LLMs lack multi-agent\ncharacteristics such as autonomy, social interaction, and structured\nenvironments, and often rely on oversimplified, LLM-centric architectures. The\nfield may slow down and lose traction by revisiting problems the MAS literature\nhas already addressed. Therefore, we systematically analyse this issue and\noutline associated research opportunities; we advocate for better integrating\nestablished MAS concepts and more precise terminology to avoid\nmischaracterisation and missed opportunities.','Emanuele La Malfa, Gabriele La Malfa, Samuele Marro, Jie M. Zhang, Elizabeth Black, Micheal Luck, Philip Torr, Michael Wooldridge','2025-05-27','cs.MA','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21298v1','该论文讨论了最近关于多智能体大型语言模型（MAS LLMs）的研究兴趣，指出当前MAS LLMs实现与MAS理论存在重要差异，重点在于代理的社会性、环境设计、协调和通信协议以及衡量 emergent 行为。作者认为许多MAS LLMs缺乏多智能体特征，常常依赖过于简化的架构，建议更好地整合已建立的MAS概念和更精确的术语以避免误解和错失机会。'),('2505.21301v1','How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian','People can categorize the same entity at multiple taxonomic levels, such as\nbasic (bear), superordinate (animal), and subordinate (grizzly bear). While\nprior research has focused on basic-level categories, this study is the first\nattempt to examine the organization of categories by analyzing exemplars\nproduced at the subordinate level. We present a new Italian psycholinguistic\ndataset of human-generated exemplars for 187 concrete words. We then use these\ndata to evaluate whether textual and vision LLMs produce meaningful exemplars\nthat align with human category organization across three key tasks: exemplar\ngeneration, category induction, and typicality judgment. Our findings show a\nlow alignment between humans and LLMs, consistent with previous studies.\nHowever, their performance varies notably across different semantic domains.\nUltimately, this study highlights both the promises and the constraints of\nusing AI-generated exemplars to support psychological and linguistic research.','Andrea Pedrotti, Giulia Rambelli, Caterina Villani, Marianna Bolognesi','2025-05-27','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.21301v1','该论文研究了人们在不同分类级别上对实体进行分类的方式，通过分析下级别的实例来检验类别的组织方式。研究使用了一个新的意大利心理语言学数据集，评估了文本和视觉LLMs在生成实例、归纳类别和典型性判断等任务中是否与人类类别组织保持一致。'),('2505.21304v1','Optimizing fMRI Data Acquisition for Decoding Natural Speech with Limited Participants','We investigate optimal strategies for decoding perceived natural speech from\nfMRI data acquired from a limited number of participants. Leveraging Lebel et\nal. (2023)\\\'s dataset of 8 participants, we first demonstrate the effectiveness\nof training deep neural networks to predict LLM-derived text representations\nfrom fMRI activity. Then, in this data regime, we observe that multi-subject\ntraining does not improve decoding accuracy compared to single-subject\napproach. Furthermore, training on similar or different stimuli across subjects\nhas a negligible effect on decoding accuracy. Finally, we find that our\ndecoders better model syntactic than semantic features, and that stories\ncontaining sentences with complex syntax or rich semantic content are more\nchallenging to decode. While our results demonstrate the benefits of having\nextensive data per participant (deep phenotyping), they suggest that leveraging\nmulti-subject for natural speech decoding likely requires deeper phenotyping or\na substantially larger cohort.','Louis Jalouzot, Alexis Thual, Yair Lakretz, Christophe Pallier, Bertrand Thirion','2025-05-27','q-bio.NC','自然语言处理','http://arxiv.org/pdf/2505.21304v1','该论文研究了如何从有限参与者的fMRI数据中解码自然语音，并通过训练深度神经网络来预测LLM推导的文本表示。研究发现，在这种数据情况下，多个参与者的训练并不能提高解码准确性，训练在不同或相似刺激下的参与者也对解码准确性影响不大。此外，研究还发现解码器更好地模拟句法而非语义特征，句子结构复杂或语义内容丰富的故事更难解码。'),('2505.21315v2','Charting the Landscape of African NLP: Mapping Progress and Shaping the Road Ahead','With over 2,000 languages and potentially millions of speakers, Africa\nrepresents one of the richest linguistic regions in the world. Yet, this\ndiversity is scarcely reflected in state-of-the-art natural language processing\n(NLP) systems and large language models (LLMs), which predominantly support a\nnarrow set of high-resource languages. This exclusion not only limits the reach\nand utility of modern NLP technologies but also risks widening the digital\ndivide across linguistic communities. Nevertheless, NLP research on African\nlanguages is active and growing. In recent years, there has been a surge of\ninterest in this area, driven by several factors-including the creation of\nmultilingual language resources, the rise of community-led initiatives, and\nincreased support through funding programs. In this survey, we analyze 734\nresearch papers on NLP for African languages published over the past five\nyears, offering a comprehensive overview of recent progress across core tasks.\nWe identify key trends shaping the field and conclude by outlining promising\ndirections to foster more inclusive and sustainable NLP research for African\nlanguages.','Jesujoba O. Alabi, Michael A. Hedderich, David Ifeoluwa Adelani, Dietrich Klakow','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21315v2','该论文调查了过去五年发表的734篇关于非洲语言的自然语言处理研究论文，分析了该领域的最新进展和趋势，并提出了促进更具包容性和可持续性的非洲语言自然语言处理研究的方向。'),('2505.21317v1','A Cross Modal Knowledge Distillation & Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features','Understanding cellular responses to stimuli is crucial for biological\ndiscovery and drug development. Transcriptomics provides interpretable,\ngene-level insights, while microscopy imaging offers rich predictive features\nbut is harder to interpret. Weakly paired datasets, where samples share\nbiological states, enable multimodal learning but are scarce, limiting their\nutility for training and multimodal inference. We propose a framework to\nenhance transcriptomics by distilling knowledge from microscopy images. Using\nweakly paired data, our method aligns and binds modalities, enriching gene\nexpression representations with morphological information. To address data\nscarcity, we introduce (1) Semi-Clipped, an adaptation of CLIP for cross-modal\ndistillation using pretrained foundation models, achieving state-of-the-art\nresults, and (2) PEA (Perturbation Embedding Augmentation), a novel\naugmentation technique that enhances transcriptomics data while preserving\ninherent biological information. These strategies improve the predictive power\nand retain the interpretability of transcriptomics, enabling rich unimodal\nrepresentations for complex biological tasks.','Ihab Bendidi, Yassir El Mesbahi, Alisandra K. Denton, Karush Suri, Kian Kenyon-Dean, Auguste Genovesio, Emmanuel Noutahi','2025-05-27','cs.LG','生物信息学','http://arxiv.org/pdf/2505.21317v1','该论文提出了一种框架，通过从显微镜图像中提炼知识来增强转录组学。利用弱配对数据，他们的方法对齐和绑定模态，用形态信息丰富基因表达表示。通过引入Semi-Clipped和PEA两种策略，他们取得了最先进的结果，提高了预测能力并保留了转录组学的可解释性，为复杂生物任务提供了丰富的单模态表示。'),('2505.21318v1','Beyond Chemical QA: Evaluating LLM\\\'s Chemical Reasoning with Modular Chemical Operations','While large language models (LLMs) with Chain-of-Thought (CoT) reasoning\nexcel in mathematics and coding, their potential for systematic reasoning in\nchemistry, a domain demanding rigorous structural analysis for real-world tasks\nlike drug design and reaction engineering, remains untapped. Current benchmarks\nfocus on simple knowledge retrieval, neglecting step-by-step reasoning required\nfor complex tasks such as molecular optimization and reaction prediction. To\naddress this, we introduce ChemCoTBench, a reasoning framework that bridges\nmolecular structure understanding with arithmetic-inspired operations,\nincluding addition, deletion, and substitution, to formalize chemical\nproblem-solving into transparent, step-by-step workflows. By treating molecular\ntransformations as modular \"chemical operations\", the framework enables\nslow-thinking reasoning, mirroring the logic of mathematical proofs while\ngrounding solutions in real-world chemical constraints. We evaluate models on\ntwo high-impact tasks: Molecular Property Optimization and Chemical Reaction\nPrediction. These tasks mirror real-world challenges while providing structured\nevaluability. By providing annotated datasets, a reasoning taxonomy, and\nbaseline evaluations, ChemCoTBench bridges the gap between abstract reasoning\nmethods and practical chemical discovery, establishing a foundation for\nadvancing LLMs as tools for AI-driven scientific innovation.','Hao Li, He Cao, Bin Feng, Yanjun Shao, Xiangru Tang, Zhiyuan Yan, Li Yuan, Yonghong Tian, Yu Li','2025-05-27','cs.AI','LLM、化学领域AI','http://arxiv.org/pdf/2505.21318v1','该论文介绍了一个名为ChemCoTBench的推理框架，将分子结构理解与算术启发的操作相结合，以透明、逐步的工作流程形式化化学问题解决。通过将分子转化视为模块化的“化学操作”，该框架实现了缓慢思考的推理，反映了数学证明的逻辑，同时将解决方案基于现实世界的化学约束。该论文评估了模型在分子性质优化和化学反应预测两个高影响任务上的表现。'),('2505.21322v1','Assured Autonomy with Neuro-Symbolic Perception','Many state-of-the-art AI models deployed in cyber-physical systems (CPS),\nwhile highly accurate, are simply pattern-matchers.~With limited security\nguarantees, there are concerns for their reliability in safety-critical and\ncontested domains. To advance assured AI, we advocate for a paradigm shift that\nimbues data-driven perception models with symbolic structure, inspired by a\nhuman\\\'s ability to reason over low-level features and high-level context. We\npropose a neuro-symbolic paradigm for perception (NeuSPaPer) and illustrate how\njoint object detection and scene graph generation (SGG) yields deep scene\nunderstanding.~Powered by foundation models for offline knowledge extraction\nand specialized SGG algorithms for real-time deployment, we design a framework\nleveraging structured relational graphs that ensures the integrity of\nsituational awareness in autonomy. Using physics-based simulators and\nreal-world datasets, we demonstrate how SGG bridges the gap between low-level\nsensor perception and high-level reasoning, establishing a foundation for\nresilient, context-aware AI and advancing trusted autonomy in CPS.','R. Spencer Hallyburton, Miroslav Pajic','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.21322v1','该论文提出了一种神经符号感知范式（NeuSPaPer），通过结合目标检测和场景图生成（SGG）实现深度场景理解，以提高AI在安全关键和有争议领域的可靠性和安全性。'),('2505.21324v1','Leveraging large language models and traditional machine learning ensembles for ADHD detection from narrative transcripts','Despite rapid advances in large language models (LLMs), their integration\nwith traditional supervised machine learning (ML) techniques that have proven\napplicability to medical data remains underexplored. This is particularly true\nfor psychiatric applications, where narrative data often exhibit nuanced\nlinguistic and contextual complexity, and can benefit from the combination of\nmultiple models with differing characteristics. In this study, we introduce an\nensemble framework for automatically classifying\nAttention-Deficit/Hyperactivity Disorder (ADHD) diagnosis (binary) using\nnarrative transcripts. Our approach integrates three complementary models:\nLLaMA3, an open-source LLM that captures long-range semantic structure;\nRoBERTa, a pre-trained transformer model fine-tuned on labeled clinical\nnarratives; and a Support Vector Machine (SVM) classifier trained using\nTF-IDF-based lexical features. These models are aggregated through a majority\nvoting mechanism to enhance predictive robustness. The dataset includes 441\ninstances, including 352 for training and 89 for validation. Empirical results\nshow that the ensemble outperforms individual models, achieving an F$_1$ score\nof 0.71 (95\\% CI: [0.60-0.80]). Compared to the best-performing individual\nmodel (SVM), the ensemble improved recall while maintaining competitive\nprecision. This indicates the strong sensitivity of the ensemble in identifying\nADHD-related linguistic cues. These findings demonstrate the promise of hybrid\narchitectures that leverage the semantic richness of LLMs alongside the\ninterpretability and pattern recognition capabilities of traditional supervised\nML, offering a new direction for robust and generalizable psychiatric text\nclassification.','Yuxin Zhu, Yuting Guo, Noah Marchuck, Abeed Sarker, Yun Wang','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21324v1','该论文介绍了一个集成框架，用于自动分类注意缺陷/多动障碍（ADHD）诊断，利用了三种互补的模型：LLaMA3、RoBERTa和基于TF-IDF的SVM分类器。集成模型通过多数投票机制提高了预测的稳健性，实验结果显示集成模型的性能优于单个模型，达到了F1分数为0.71。'),('2505.21327v1','MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs','Logical reasoning is a fundamental aspect of human intelligence and an\nessential capability for multimodal large language models (MLLMs). Despite the\nsignificant advancement in multimodal reasoning, existing benchmarks fail to\ncomprehensively evaluate their reasoning abilities due to the lack of explicit\ncategorization for logical reasoning types and an unclear understanding of\nreasoning. To address these issues, we introduce MME-Reasoning, a comprehensive\nbenchmark designed to evaluate the reasoning ability of MLLMs, which covers all\nthree types of reasoning (i.e., inductive, deductive, and abductive) in its\nquestions. We carefully curate the data to ensure that each question\neffectively evaluates reasoning ability rather than perceptual skills or\nknowledge breadth, and extend the evaluation protocols to cover the evaluation\nof diverse questions. Our evaluation reveals substantial limitations of\nstate-of-the-art MLLMs when subjected to holistic assessments of logical\nreasoning capabilities. Even the most advanced MLLMs show limited performance\nin comprehensive logical reasoning, with notable performance imbalances across\nreasoning types. In addition, we conducted an in-depth analysis of approaches\nsuch as ``thinking mode\\\'\\\' and Rule-based RL, which are commonly believed to\nenhance reasoning abilities. These findings highlight the critical limitations\nand performance imbalances of current MLLMs in diverse logical reasoning\nscenarios, providing comprehensive and systematic insights into the\nunderstanding and evaluation of reasoning capabilities.','Jiakang Yuan, Tianshuo Peng, Yilei Jiang, Yiting Lu, Renrui Zhang, Kaituo Feng, Chaoyou Fu, Tao Chen, Lei Bai, Bo Zhang, Xiangyu Yue','2025-05-27','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21327v1','该论文介绍了一个名为MME-Reasoning的综合基准，旨在评估MLLMs的推理能力，涵盖归纳、演绎和诱导三种推理类型。研究发现现有MLLMs在综合逻辑推理方面存在显著限制和性能不平衡。'),('2505.21330v1','UGCE: User-Guided Incremental Counterfactual Exploration','Counterfactual explanations (CFEs) are a popular approach for interpreting\nmachine learning predictions by identifying minimal feature changes that alter\nmodel outputs. However, in real-world settings, users often refine feasibility\nconstraints over time, requiring counterfactual generation to adapt\ndynamically. Existing methods fail to support such iterative updates, instead\nrecomputing explanations from scratch with each change, an inefficient and\nrigid approach. We propose User-Guided Incremental Counterfactual Exploration\n(UGCE), a genetic algorithm-based framework that incrementally updates\ncounterfactuals in response to evolving user constraints. Experimental results\nacross five benchmark datasets demonstrate that UGCE significantly improves\ncomputational efficiency while maintaining high-quality solutions compared to a\nstatic, non-incremental approach. Our evaluation further shows that UGCE\nsupports stable performance under varying constraint sequences, benefits from\nan efficient warm-start strategy, and reveals how different constraint types\nmay affect search behavior.','Christos Fragkathoulas, Evaggelia Pitoura','2025-05-27','cs.LG','解释性人工智能','http://arxiv.org/pdf/2505.21330v1','该论文提出了一种基于遗传算法的框架，名为用户引导的增量反事实探索（UGCE），用于根据用户不断演化的约束条件增量更新反事实解释。实验结果表明，UGCE相较于静态、非增量方法显著提高了计算效率，同时保持了高质量的解决方案。'),('2505.21335v1','Structure from Collision','Recent advancements in neural 3D representations, such as neural radiance\nfields (NeRF) and 3D Gaussian splatting (3DGS), have enabled the accurate\nestimation of 3D structures from multiview images. However, this capability is\nlimited to estimating the visible external structure, and identifying the\ninvisible internal structure hidden behind the surface is difficult. To\novercome this limitation, we address a new task called Structure from Collision\n(SfC), which aims to estimate the structure (including the invisible internal\nstructure) of an object from appearance changes during collision. To solve this\nproblem, we propose a novel model called SfC-NeRF that optimizes the invisible\ninternal structure of an object through a video sequence under physical,\nappearance (i.e., visible external structure)-preserving, and keyframe\nconstraints. In particular, to avoid falling into undesirable local optima\nowing to its ill-posed nature, we propose volume annealing; that is, searching\nfor global optima by repeatedly reducing and expanding the volume. Extensive\nexperiments on 115 objects involving diverse structures (i.e., various cavity\nshapes, locations, and sizes) and material properties revealed the properties\nof SfC and demonstrated the effectiveness of the proposed SfC-NeRF.','Takuhiro Kaneko','2025-05-27','cs.GR','三维重建/计算机视觉','http://arxiv.org/pdf/2505.21335v1','该论文提出了一种新的任务称为碰撞结构（SfC），旨在从碰撞期间的外观变化中估计对象的结构（包括不可见的内部结构）。他们提出了一种名为SfC-NeRF的新模型，通过视频序列优化对象的不可见内部结构，并通过物理、外观保持和关键帧约束来解决这个问题。实验证明了该方法的有效性。'),('2505.21336v1','Joint Learning in the Gaussian Single Index Model','We consider the problem of jointly learning a one-dimensional projection and\na univariate function in high-dimensional Gaussian models. Specifically, we\nstudy predictors of the form $f(x)=\\varphi^\\star(\\langle w^\\star, x \\rangle)$,\nwhere both the direction $w^\\star \\in \\mathcal{S}_{d-1}$, the sphere of\n$\\mathbb{R}^d$, and the function $\\varphi^\\star: \\mathbb{R} \\to \\mathbb{R}$ are\nlearned from Gaussian data. This setting captures a fundamental non-convex\nproblem at the intersection of representation learning and nonlinear\nregression. We analyze the gradient flow dynamics of a natural alternating\nscheme and prove convergence, with a rate controlled by the information\nexponent reflecting the \\textit{Gaussian regularity} of the function\n$\\varphi^\\star$. Strikingly, our analysis shows that convergence still occurs\neven when the initial direction is negatively correlated with the target. On\nthe practical side, we demonstrate that such joint learning can be effectively\nimplemented using a Reproducing Kernel Hilbert Space (RKHS) adapted to the\nstructure of the problem, enabling efficient and flexible estimation of the\nunivariate function. Our results offer both theoretical insight and practical\nmethodology for learning low-dimensional structure in high-dimensional\nsettings.','Loucas Pillaud-Vivien, Adrien Schertzer','2025-05-27','cs.LG','非AI','http://arxiv.org/pdf/2505.21336v1','该论文研究了在高维高斯模型中联合学习一维投影和单变量函数的问题，通过分析梯度流动力学和证明收敛性，展示了在高维设置中学习低维结构的理论洞见和实用方法。'),('2505.21339v1','An Uncertainty-Aware ED-LSTM for Probabilistic Suffix Prediction','Suffix prediction of business processes forecasts the remaining sequence of\nevents until process completion. Current approaches focus on predicting a\nsingle, most likely suffix. However, if the future course of a process is\nexposed to uncertainty or has high variability, the expressiveness of a single\nsuffix prediction can be limited. To address this limitation, we propose\nprobabilistic suffix prediction, a novel approach that approximates a\nprobability distribution of suffixes. The proposed approach is based on an\nUncertainty-Aware Encoder-Decoder LSTM (U-ED-LSTM) and a Monte Carlo (MC)\nsuffix sampling algorithm. We capture epistemic uncertainties via MC dropout\nand aleatoric uncertainties as learned loss attenuation. This technical report\nprovides a detailed evaluation of the U-ED-LSTM\\\'s predictive performance and\nassesses its calibration on four real-life event logs with three different\nhyperparameter settings. The results show that i) the U-ED-LSTM has reasonable\npredictive performance across various datasets, ii) aggregating probabilistic\nsuffix predictions into mean values can outperform most likely predictions,\nparticularly for rare prefixes or longer suffixes, and iii) the approach\neffectively captures uncertainties present in event logs.','Henryk Mustroph, Michel Kunkler, Stefanie Rinderle-Ma','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21339v1','该论文提出了一种概率后缀预测的方法，通过使用基于不确定性感知的编码器-解码器LSTM和蒙特卡洛后缀采样算法来近似后缀的概率分布。实验结果表明，该方法在多个数据集上有合理的预测性能，聚合概率后缀预测可以优于最可能的预测，尤其对于稀有前缀或较长后缀。'),('2505.21342v2','PEDANTIC: A Dataset for the Automatic Examination of Definiteness in Patent Claims','Patent claims define the scope of protection for an invention. If there are\nambiguities in a claim, it is rejected by the patent office. In the US, this is\nreferred to as indefiniteness (35 U.S.C {\\S} 112(b)) and is among the most\nfrequent reasons for patent application rejection. The development of automatic\nmethods for patent definiteness examination has the potential to make patent\ndrafting and examination more efficient, but no annotated dataset has been\npublished to date. We introduce PEDANTIC (Patent Definiteness Examination\nCorpus), a novel dataset of 14k US patent claims from patent applications\nrelating to Natural Language Processing (NLP), annotated with reasons for\nindefiniteness. We construct PEDANTIC using a fully automatic pipeline that\nretrieves office action documents from the USPTO and uses Large Language Models\n(LLMs) to extract the reasons for indefiniteness. A human validation study\nconfirms the pipeline\\\'s accuracy in generating high-quality annotations. To\ngain insight beyond binary classification metrics, we implement an LLM-as-Judge\nevaluation that compares the free-form reasoning of every model-cited reason\nwith every examiner-cited reason. We show that LLM agents based on Qwen 2.5 32B\nand 72B struggle to outperform logistic regression baselines on definiteness\nprediction, even though they often correctly identify the underlying reasons.\nPEDANTIC provides a valuable resource for patent AI researchers, enabling the\ndevelopment of advanced examination models. We will publicly release the\ndataset and code.','Valentin Knappich, Annemarie Friedrich, Anna Hätty, Simon Razniewski','2025-05-27','cs.CL','自然语言处理(AI)','http://arxiv.org/pdf/2505.21342v2','该论文介绍了一个新的数据集 PEDANTIC，其中包含了1.4万个与自然语言处理相关的美国专利申请中的专利声明，标注了不确定性的原因。研究使用了完全自动化的流程来构建数据集，并使用大型语言模型（LLMs）提取不确定性原因。研究表明，LLM代理在确定性预测上表现不如逻辑回归基线，尽管它们通常能正确识别潜在原因。'),('2505.21344v1','The Multilingual Divide and Its Impact on Global AI Safety','Despite advances in large language model capabilities in recent years, a\nlarge gap remains in their capabilities and safety performance for many\nlanguages beyond a relatively small handful of globally dominant languages.\nThis paper provides researchers, policymakers and governance experts with an\noverview of key challenges to bridging the \"language gap\" in AI and minimizing\nsafety risks across languages. We provide an analysis of why the language gap\nin AI exists and grows, and how it creates disparities in global AI safety. We\nidentify barriers to address these challenges, and recommend how those working\nin policy and governance can help address safety concerns associated with the\nlanguage gap by supporting multilingual dataset creation, transparency, and\nresearch.','Aidan Peppin, Julia Kreutzer, Alice Schoenauer Sebag, Kelly Marchisio, Beyza Ermis, John Dang, Samuel Cahyawijaya, Shivalika Singh, Seraphina Goldfarb-Tarrant, Viraat Aryabumi, Aakanksha, Wei-Yin Ko, Ahmet Üstün, Matthias Gallé, Marzieh Fadaee, Sara Hooker','2025-05-27','cs.AI','多语言处理、AI安全领域','http://arxiv.org/pdf/2505.21344v1','本文讨论了目前大型语言模型在全球范围内许多非主流语言的能力和安全性表现存在较大差距的问题，提出了如何缩小“语言鸿沟”、减少全球AI安全风险的关键挑战，并提出了建议和解决方案。'),('2505.21347v2','OVERT: A Benchmark for Over-Refusal Evaluation on Text-to-Image Models','Text-to-Image (T2I) models have achieved remarkable success in generating\nvisual content from text inputs. Although multiple safety alignment strategies\nhave been proposed to prevent harmful outputs, they often lead to overly\ncautious behavior -- rejecting even benign prompts -- a phenomenon known as\n$\\textit{over-refusal}$ that reduces the practical utility of T2I models.\nDespite over-refusal having been observed in practice, there is no large-scale\nbenchmark that systematically evaluates this phenomenon for T2I models. In this\npaper, we present an automatic workflow to construct synthetic evaluation data,\nresulting in OVERT ($\\textbf{OVE}$r-$\\textbf{R}$efusal evaluation on\n$\\textbf{T}$ext-to-image models), the first large-scale benchmark for assessing\nover-refusal behaviors in T2I models. OVERT includes 4,600 seemingly harmful\nbut benign prompts across nine safety-related categories, along with 1,785\ngenuinely harmful prompts (OVERT-unsafe) to evaluate the safety-utility\ntrade-off. Using OVERT, we evaluate several leading T2I models and find that\nover-refusal is a widespread issue across various categories (Figure 1),\nunderscoring the need for further research to enhance the safety alignment of\nT2I models without compromising their functionality. As a preliminary attempt\nto reduce over-refusal, we explore prompt rewriting; however, we find it often\ncompromises faithfulness to the meaning of the original prompts. Finally, we\ndemonstrate the flexibility of our generation framework in accommodating\ndiverse safety requirements by generating customized evaluation data adapting\nto user-defined policies.','Ziheng Cheng, Yixiao Huang, Hui Xu, Somayeh Sojoudi, Xuandong Zhao, Dawn Song, Song Mei','2025-05-27','cs.LG','文本到图像模型(Text-to-Image)、安全性评估(AI Safety)','http://arxiv.org/pdf/2505.21347v2','本文提出了一个自动工作流程，构建了一个名为OVERT的大规模基准测试，用于评估T2I模型中的过度拒绝行为。通过OVERT，评估了几种领先的T2I模型，发现过度拒绝是一个普遍存在的问题，强调了需要进一步研究以增强T2I模型的安全对齐性而不影响其功能性。此外，作者尝试了通过重新构造提示来减少过度拒绝，但发现这经常会损害对原始提示含义的忠实性。'),('2505.21354v1','Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning','Solving Bengali Math Word Problems (MWPs) remains a major challenge in\nnatural language processing (NLP) due to the language\\\'s low-resource status and\nthe multi-step reasoning required. Existing models struggle with complex\nBengali MWPs, largely because no human-annotated Bengali dataset has previously\naddressed this task. This gap has limited progress in Bengali mathematical\nreasoning. To address this, we created SOMADHAN, a dataset of 8792 complex\nBengali MWPs with manually written, step-by-step solutions. We designed this\ndataset to support reasoning-focused evaluation and model development in a\nlinguistically underrepresented context. Using SOMADHAN, we evaluated a range\nof large language models (LLMs) - including GPT-4o, GPT-3.5 Turbo, LLaMA series\nmodels, Deepseek, and Qwen - through both zero-shot and few-shot prompting with\nand without Chain of Thought (CoT) reasoning. CoT prompting consistently\nimproved performance over standard prompting, especially in tasks requiring\nmulti-step logic. LLaMA-3.3 70B achieved the highest accuracy of 88% with\nfew-shot CoT prompting. We also applied Low-Rank Adaptation (LoRA) to fine-tune\nmodels efficiently, enabling them to adapt to Bengali MWPs with minimal\ncomputational cost. Our work fills a critical gap in Bengali NLP by providing a\nhigh-quality reasoning dataset and a scalable framework for solving complex\nMWPs. We aim to advance equitable research in low-resource languages and\nenhance reasoning capabilities in educational and language technologies.','Bidyarthi Paul, Jalisha Jashim Era, Mirazur Rahman Zim, Tahmid Sattar Aothoi, Faisal Muhammad Shah','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21354v1','该论文介绍了解决孟加拉数学应用题的挑战，提出了一个包含复杂数学应用题和解决方案的数据集SOMADHAN，并评估了多个大型语言模型在该任务上的表现。'),('2505.21355v1','Prostate Cancer Screening with Artificial Intelligence-Enhanced Micro-Ultrasound: A Comparative Study with Traditional Methods','Background and objective: Micro-ultrasound (micro-US) is a novel imaging\nmodality with diagnostic accuracy comparable to MRI for detecting clinically\nsignificant prostate cancer (csPCa). We investigated whether artificial\nintelligence (AI) interpretation of micro-US can outperform clinical screening\nmethods using PSA and digital rectal examination (DRE). Methods: We\nretrospectively studied 145 men who underwent micro-US guided biopsy (79 with\ncsPCa, 66 without). A self-supervised convolutional autoencoder was used to\nextract deep image features from 2D micro-US slices. Random forest classifiers\nwere trained using five-fold cross-validation to predict csPCa at the slice\nlevel. Patients were classified as csPCa-positive if 88 or more consecutive\nslices were predicted positive. Model performance was compared with a\nclassifier using PSA, DRE, prostate volume, and age. Key findings and\nlimitations: The AI-based micro-US model and clinical screening model achieved\nAUROCs of 0.871 and 0.753, respectively. At a fixed threshold, the micro-US\nmodel achieved 92.5% sensitivity and 68.1% specificity, while the clinical\nmodel showed 96.2% sensitivity but only 27.3% specificity. Limitations include\na retrospective single-center design and lack of external validation.\nConclusions and clinical implications: AI-interpreted micro-US improves\nspecificity while maintaining high sensitivity for csPCa detection. This method\nmay reduce unnecessary biopsies and serve as a low-cost alternative to\nPSA-based screening. Patient summary: We developed an AI system to analyze\nprostate micro-ultrasound images. It outperformed PSA and DRE in detecting\naggressive cancer and may help avoid unnecessary biopsies.','Muhammad Imran, Wayne G. Brisbane, Li-Ming Su, Jason P. Joseph, Wei Shao','2025-05-27','eess.IV','图像识别','http://arxiv.org/pdf/2505.21355v1','该论文研究了利用人工智能解释微超声图像来提高前列腺癌的检测准确性，通过使用自监督卷积自编码器提取深度图像特征和随机森林分类器进行预测。人工智能模型在特异性方面表现优越，同时保持高敏感性。'),('2505.21356v2','Towards Robust Automated Perceptual Voice Quality Assessment with Speech Foundation Models','Perceptual voice quality assessment is essential for diagnosing and\nmonitoring voice disorders. Traditionally, expert raters use scales such as the\nCAPE-V and GRBAS. However, these are subjective and prone to inter-rater\nvariability, motivating the need for automated, objective assessment methods.\nThis study proposes VOQANet, a deep learning framework with an attention\nmechanism that leverages a Speech Foundation Model (SFM) to extract high-level\nacoustic and prosodic information from raw speech. To improve robustness and\ninterpretability, we introduce VOQANet+, which integrates handcrafted acoustic\nfeatures such as jitter, shimmer, and harmonics-to-noise ratio (HNR) with SFM\nembeddings into a hybrid representation. Unlike prior work focusing only on\nvowel-based phonation (PVQD-A subset) from the Perceptual Voice Quality Dataset\n(PVQD), we evaluate our models on both vowel-based and sentence-level speech\n(PVQD-S subset) for better generalizability. Results show that sentence-based\ninput outperforms vowel-based input, particularly at the patient level,\nhighlighting the benefit of longer utterances for capturing voice attributes.\nVOQANet consistently surpasses baseline methods in root mean squared error and\nPearson correlation across CAPE-V and GRBAS dimensions, with VOQANet+ achieving\nfurther improvements. Additional tests under noisy conditions show that\nVOQANet+ maintains high prediction accuracy, supporting its use in real-world\nand telehealth settings. These findings demonstrate the value of combining SFM\nembeddings with domain-informed acoustic features for interpretable and robust\nvoice quality assessment.','Whenty Ariyanti, Kuan-Yu Chen, Sabato Marco Siniscalchi, Hsin-Min Wang, Yu Tsao','2025-05-27','cs.SD','语音处理','http://arxiv.org/pdf/2505.21356v2','该论文提出了VOQANet和VOQANet+两种深度学习框架，结合了注意力机制和手工制作的声学特征，用于自动化、客观评估语音质量。研究结果表明，基于句子级输入的模型在患者级别上表现更好，突出了捕捉语音属性的长句的好处。'),('2505.21357v2','AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop Mapping','Accurate crop mapping fundamentally relies on modeling multi-scale\nspatiotemporal patterns, where spatial scales range from individual field\ntextures to landscape-level context, and temporal scales capture both\nshort-term phenological transitions and full growing-season dynamics.\nTransformer-based remote sensing foundation models (RSFMs) offer promising\npotential for crop mapping due to their innate ability for unified\nspatiotemporal processing. However, current RSFMs remain suboptimal for crop\nmapping: they either employ fixed spatiotemporal windows that ignore the\nmulti-scale nature of crop systems or completely disregard temporal information\nby focusing solely on spatial patterns. To bridge these gaps, we present\nAgriFM, a multi-source remote sensing foundation model specifically designed\nfor agricultural crop mapping. Our approach begins by establishing the\nnecessity of simultaneous hierarchical spatiotemporal feature extraction,\nleading to the development of a modified Video Swin Transformer architecture\nwhere temporal down-sampling is synchronized with spatial scaling operations.\nThis modified backbone enables efficient unified processing of long time-series\nsatellite inputs. AgriFM leverages temporally rich data streams from three\nsatellite sources including MODIS, Landsat-8/9 and Sentinel-2, and is\npre-trained on a global representative dataset comprising over 25 million image\nsamples supervised by land cover products. The resulting framework incorporates\na versatile decoder architecture that dynamically fuses these learned\nspatiotemporal representations, supporting diverse downstream tasks.\nComprehensive evaluations demonstrate AgriFM\\\'s superior performance over\nconventional deep learning approaches and state-of-the-art general-purpose\nRSFMs across all downstream tasks. Codes will be available at\nhttps://github.com/flyakon/AgriFM.','Wenyuan Li, Shunlin Liang, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan, Husheng Fang, Zhenwei Shi','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21357v2','本文提出了一种特别设计用于农业作物映射的多源遥感基础模型AgriFM。该模型利用改进的Video Swin Transformer架构，同时提取层次化的时空特征，有效处理长时间序列的卫星输入数据，并在各种下游任务中表现出优越性能。'),('2505.21360v1','CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models','Competing risks are crucial considerations in survival modelling,\nparticularly in healthcare domains where patients may experience multiple\ndistinct event types. We propose CRISP-NAM (Competing Risks Interpretable\nSurvival Prediction with Neural Additive Models), an interpretable neural\nadditive model for competing risks survival analysis which extends the neural\nadditive architecture to model cause-specific hazards while preserving\nfeature-level interpretability. Each feature contributes independently to risk\nestimation through dedicated neural networks, allowing for visualization of\ncomplex non-linear relationships between covariates and each competing risk. We\ndemonstrate competitive performance on multiple datasets compared to existing\napproaches.','Dhanesh Ramachandram','2025-05-27','cs.LG','生存分析','http://arxiv.org/pdf/2505.21360v1','该论文提出了一种可解释的神经加法模型 CRISP-NAM 用于竞争风险生存分析，扩展了神经加法结构以建模特定原因的风险，同时保留特征级别的可解释性。每个特征通过专用神经网络独立地对风险估计做出贡献，允许可视化协变量与每种竞争风险之间的复杂非线性关系。在多个数据集上与现有方法相比表现出竞争性能。'),('2505.21362v1','Evaluating LLM Adaptation to Sociodemographic Factors: User Profile vs. Dialogue History','Effective engagement by large language models (LLMs) requires adapting\nresponses to users\\\' sociodemographic characteristics, such as age, occupation,\nand education level. While many real-world applications leverage dialogue\nhistory for contextualization, existing evaluations of LLMs\\\' behavioral\nadaptation often focus on single-turn prompts. In this paper, we propose a\nframework to evaluate LLM adaptation when attributes are introduced either (1)\nexplicitly via user profiles in the prompt or (2) implicitly through multi-turn\ndialogue history. We assess the consistency of model behavior across these\nmodalities. Using a multi-agent pipeline, we construct a synthetic dataset\npairing dialogue histories with distinct user profiles and employ questions\nfrom the Value Survey Module (VSM 2013) (Hofstede and Hofstede, 2016) to probe\nvalue expression. Our findings indicate that most models adjust their expressed\nvalues in response to demographic changes, particularly in age and education\nlevel, but consistency varies. Models with stronger reasoning capabilities\ndemonstrate greater alignment, indicating the importance of reasoning in robust\nsociodemographic adaptation.','Qishuai Zhong, Zongmin Li, Siqi Fan, Aixin Sun','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21362v1','本文提出了一个框架，用于评估大型语言模型在用户属性（如年龄、职业、教育水平）通过用户配置文件显式引入或通过多轮对话历史隐式引入时的行为适应性。研究发现，大多数模型会根据人口统计变化调整其表达的价值观，尤其是在年龄和教育水平方面，但一致性存在差异。具有更强推理能力的模型表现出更大的一致性，表明推理在稳健的社会人口适应中的重要性。'),('2505.21363v1','Subgroups Matter for Robust Bias Mitigation','Despite the constant development of new bias mitigation methods for machine\nlearning, no method consistently succeeds, and a fundamental question remains\nunanswered: when and why do bias mitigation techniques fail? In this paper, we\nhypothesise that a key factor may be the often-overlooked but crucial step\nshared by many bias mitigation methods: the definition of subgroups. To\ninvestigate this, we conduct a comprehensive evaluation of state-of-the-art\nbias mitigation methods across multiple vision and language classification\ntasks, systematically varying subgroup definitions, including coarse,\nfine-grained, intersectional, and noisy subgroups. Our results reveal that\nsubgroup choice significantly impacts performance, with certain groupings\nparadoxically leading to worse outcomes than no mitigation at all. Our findings\nsuggest that observing a disparity between a set of subgroups is not a\nsufficient reason to use those subgroups for mitigation. Through theoretical\nanalysis, we explain these phenomena and uncover a counter-intuitive insight\nthat, in some cases, improving fairness with respect to a particular set of\nsubgroups is best achieved by using a different set of subgroups for\nmitigation. Our work highlights the importance of careful subgroup definition\nin bias mitigation and suggest it as a alternative lever for improving the\nrobustness and fairness of machine learning models.','Anissa Alloula, Charles Jones, Ben Glocker, Bartłomiej W. Papież','2025-05-27','cs.LG','偏差缓解方法、机器学习模型公平性','http://arxiv.org/pdf/2505.21363v1','本文研究了机器学习中新的偏差缓解方法的发展，提出了一个未解答的基本问题：偏差缓解技术何时以及为什么会失败。作者认为关键因素可能是定义子组的步骤，通过对多个视觉和语言分类任务进行全面评估，发现子组选择显著影响性能，有时某些分组会导致比没有任何缓解更糟糕的结果。研究结果表明，通过使用不同的子组进行缓解，有时可以更好地提高公平性。'),('2505.21364v1','Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders','Multilayer perceptrons (MLPs) are an integral part of large language models,\nyet their dense representations render them difficult to understand, edit, and\nsteer. Recent methods learn interpretable approximations via neuron-level\nsparsity, yet fail to faithfully reconstruct the original\nmapping--significantly increasing model\\\'s next-token cross-entropy loss. In\nthis paper, we advocate for moving to layer-level sparsity to overcome the\naccuracy trade-off in sparse layer approximation. Under this paradigm, we\nintroduce Mixture of Decoders (MxDs). MxDs generalize MLPs and Gated Linear\nUnits, expanding pre-trained dense layers into tens of thousands of specialized\nsublayers. Through a flexible form of tensor factorization, each sparsely\nactivating MxD sublayer implements a linear transformation with full-rank\nweights--preserving the original decoders\\\' expressive capacity even under heavy\nsparsity. Experimentally, we show that MxDs significantly outperform\nstate-of-the-art methods (e.g., Transcoders) on the sparsity-accuracy frontier\nin language models with up to 3B parameters. Further evaluations on sparse\nprobing and feature steering demonstrate that MxDs learn similarly specialized\nfeatures of natural language--opening up a promising new avenue for designing\ninterpretable yet faithful decompositions. Our code is included at:\nhttps://github.com/james-oldfield/MxD/.','James Oldfield, Shawn Im, Yixuan Li, Mihalis A. Nicolaou, Ioannis Patras, Grigorios G Chrysos','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21364v1','本文提出了一种新的方法，即Mixture of Decoders (MxDs)，通过层级稀疏性来解决MLPs在理解、编辑和引导方面的困难。实验证明，MxDs在语言模型中表现出色，并且在稀疏性和准确性之间取得了良好的平衡。'),('2505.21372v1','Improving LLM-based Global Optimization with Search Space Partitioning','Large Language Models (LLMs) have recently emerged as effective surrogate\nmodels and candidate generators within global optimization frameworks for\nexpensive blackbox functions. Despite promising results, LLM-based methods\noften struggle in high-dimensional search spaces or when lacking\ndomain-specific priors, leading to sparse or uninformative suggestions. To\novercome these limitations, we propose HOLLM, a novel global optimization\nalgorithm that enhances LLM-driven sampling by partitioning the search space\ninto promising subregions. Each subregion acts as a ``meta-arm\\\'\\\' selected via a\nbandit-inspired scoring mechanism that effectively balances exploration and\nexploitation. Within each selected subregion, an LLM then proposes high-quality\ncandidate points, without any explicit domain knowledge. Empirical evaluation\non standard optimization benchmarks shows that HOLLM consistently matches or\nsurpasses leading Bayesian optimization and trust-region methods, while\nsubstantially outperforming global LLM-based sampling strategies.','Andrej Schwanke, Lyubomir Ivanov, David Salinas, Fabio Ferreira, Aaron Klein, Frank Hutter, Arber Zela','2025-05-27','cs.LG','大语言模型(Large Language Models)','http://arxiv.org/pdf/2505.21372v1','该论文提出了一种名为HOLLM的全局优化算法，通过将搜索空间划分为有前景的子区域来增强LLM驱动的采样，以克服LLM方法在高维搜索空间或缺乏领域特定先验知识时的局限性。'),('2505.21378v1','Analyzing values about gendered language reform in LLMs\\\' revisions','Within the common LLM use case of text revision, we study LLMs\\\' revision of\ngendered role nouns (e.g., outdoorsperson/woman/man) and their justifications\nof such revisions. We evaluate their alignment with feminist and\ntrans-inclusive language reforms for English. Drawing on insight from\nsociolinguistics, we further assess if LLMs are sensitive to the same\ncontextual effects in the application of such reforms as people are, finding\nbroad evidence of such effects. We discuss implications for value alignment.','Jules Watson, Xi Wang, Raymond Liu, Suzanne Stevenson, Barend Beekhuizen','2025-05-27','cs.CL','语言模型（LLM）','http://arxiv.org/pdf/2505.21378v1','该论文研究了在文本修订中，LLM对性别角色名词（如outdoorsperson/woman/man）的修订及其理由，并评估它们对英语女权主义和跨性别包容性语言改革的一致性。通过社会语言学的见解，进一步评估LLM是否对这些改革的应用具有与人类相同的情境效应敏感性，发现了广泛的证据。论文讨论了价值对齐的影响。'),('2505.21382v1','DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models','Low-Rank Adaptation (LoRA) has emerged as one of the most effective,\ncomputationally tractable fine-tuning approaches for training Vision-Language\nModels (VLMs) and Large Language Models (LLMs). LoRA accomplishes this by\nfreezing the pre-trained model weights and injecting trainable low-rank\nmatrices, allowing for efficient learning of these foundation models even on\nedge devices. However, LoRA in decentralized settings still remains under\nexplored, particularly for the theoretical underpinnings due to the lack of\nsmoothness guarantee and model consensus interference (defined formally below).\nThis work improves the convergence rate of decentralized LoRA (DLoRA) to match\nthe rate of decentralized SGD by ensuring gradient smoothness. We also\nintroduce DeCAF, a novel algorithm integrating DLoRA with truncated singular\nvalue decomposition (TSVD)-based matrix factorization to resolve consensus\ninterference. Theoretical analysis shows TSVD\\\'s approximation error is bounded\nand consensus differences between DLoRA and DeCAF vanish as rank increases,\nyielding DeCAF\\\'s matching convergence rate. Extensive experiments across\nvision/language tasks demonstrate our algorithms outperform local training and\nrivals federated learning under both IID and non-IID data distributions.','Nastaran Saadati, Zhanhong Jiang, Joshua R. Waite, Shreyan Ganguly, Aditya Balu, Chinmay Hegde, Soumik Sarkar','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21382v1','该论文研究了低秩适应（LoRA）在分散式环境下的应用，通过改进分散式LoRA（DLoRA）算法，提高了收敛速度，并引入了DeCAF算法解决共识干扰问题。实验证明，这些算法在视觉/语言任务上表现优越。'),('2505.21388v1','DeSocial: Blockchain-based Decentralized Social Networks','Web 2.0 social platforms are inherently centralized, with user data and\nalgorithmic decisions controlled by the platform. However, users can only\npassively receive social predictions without being able to choose the\nunderlying algorithm, which limits personalization. Fortunately, with the\nemergence of blockchain, users are allowed to choose algorithms that are\ntailored to their local situation, improving prediction results in a\npersonalized way. In a blockchain environment, each user possesses its own\nmodel to perform the social prediction, capturing different perspectives on\nsocial interactions. In our work, we propose DeSocial, a decentralized social\nnetwork learning framework deployed on an Ethereum (ETH) local development\nchain that integrates distributed data storage, node-level consensus, and\nuser-driven model selection through Ganache. In the first stage, each user\nleverages DeSocial to evaluate multiple backbone models on their local\nsubgraph. DeSocial coordinates the execution and returns model-wise prediction\nresults, enabling the user to select the most suitable backbone for\npersonalized social prediction. Then, DeSocial uniformly selects several\nvalidation nodes that possess the algorithm specified by each user, and\naggregates the prediction results by majority voting, to prevent errors caused\nby any single model\\\'s misjudgment. Extensive experiments show that DeSocial has\nan evident improvement compared to the five classical centralized social\nnetwork learning models, promoting user empowerment in blockchain-based\ndecentralized social networks, showing the importance of multi-node validation\nand personalized algorithm selection based on blockchain. Our implementation is\navailable at: https://github.com/agiresearch/DeSocial.','Jingyuan Huang, Xi Zhu, Minghao Guo, Yongfeng Zhang','2025-05-27','cs.SI','区块链技术在社交网络学习中的应用','http://arxiv.org/pdf/2505.21388v1','该论文提出了一种基于区块链的去中心化社交网络学习框架DeSocial，用户可以选择适合其本地情况的算法进行个性化社交预测，通过多节点验证和个性化算法选择，提高了预测结果的准确性。'),('2505.21389v1','AutoJudger: An Agent-Driven Framework for Efficient Benchmarking of MLLMs','Evaluating multimodal large language models (MLLMs) is increasingly\nexpensive, as the growing size and cross-modality complexity of benchmarks\ndemand significant scoring efforts. To tackle with this difficulty, we\nintroduce AutoJudger, an agent-driven framework for efficient and adaptive\nbenchmarking of MLLMs that tackles this escalating cost. AutoJudger employs the\nItem Response Theory (IRT) to estimate the question difficulty and an\nautonomous evaluation agent to dynamically select the most informative test\nquestions based on the model\\\'s real-time performance. Specifically, AutoJudger\nincorporates two pivotal components: a semantic-aware retrieval mechanism to\nensure that selected questions cover diverse and challenging scenarios across\nboth vision and language modalities, and a dynamic memory that maintains\ncontextual statistics of previously evaluated questions to guide coherent and\nglobally informed question selection throughout the evaluation process.\nExtensive experiments on four representative multimodal benchmarks demonstrate\nthat our adaptive framework dramatically reduces evaluation expenses, i.e.\nAutoJudger uses only 4% of the data to achieve over 90% ranking accuracy with\nthe full benchmark evaluation on MMT-Bench.','Xuanwen Ding, Chengjun Pan, Zejun Li, Jiwen Zhang, Siyuan Wang, Zhongyu Wei','2025-05-27','cs.CL','LLM（大型语言模型）','http://arxiv.org/pdf/2505.21389v1','该论文介绍了一种名为AutoJudger的自适应框架，用于有效和自适应地评估多模态大型语言模型（MLLMs），通过使用Item Response Theory（IRT）估计问题难度和自主评估代理动态选择最具信息量的测试问题，以显著降低评估成本。'),('2505.21391v1','Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features','Linear TD($\\lambda$) is one of the most fundamental reinforcement learning\nalgorithms for policy evaluation. Previously, convergence rates are typically\nestablished under the assumption of linearly independent features, which does\nnot hold in many practical scenarios. This paper instead establishes the first\n$L^2$ convergence rates for linear TD($\\lambda$) operating under arbitrary\nfeatures, without making any algorithmic modification or additional\nassumptions. Our results apply to both the discounted and average-reward\nsettings. To address the potential non-uniqueness of solutions resulting from\narbitrary features, we develop a novel stochastic approximation result\nfeaturing convergence rates to the solution set instead of a single point.','Zixuan Xie, Xinyu Liu, Rohan Chandra, Shangtong Zhang','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21391v1','该论文研究了线性TD($\\lambda$)算法在任意特征下的$L^2$收敛速率，无需进行任何算法修改或额外假设。研究结果适用于折扣奖励和平均奖励设置，并开发了一种新的随机逼近结果来解决由任意特征导致的解的非唯一性问题。'),('2505.21393v1','Leveraging the Power of Conversations: Optimal Key Term Selection in Conversational Contextual Bandits','Conversational recommender systems proactively query users with relevant \"key\nterms\" and leverage the feedback to elicit users\\\' preferences for personalized\nrecommendations. Conversational contextual bandits, a prevalent approach in\nthis domain, aim to optimize preference learning by balancing exploitation and\nexploration. However, several limitations hinder their effectiveness in\nreal-world scenarios. First, existing algorithms employ key term selection\nstrategies with insufficient exploration, often failing to thoroughly probe\nusers\\\' preferences and resulting in suboptimal preference estimation. Second,\ncurrent algorithms typically rely on deterministic rules to initiate\nconversations, causing unnecessary interactions when preferences are\nwell-understood and missed opportunities when preferences are uncertain. To\naddress these limitations, we propose three novel algorithms: CLiSK, CLiME, and\nCLiSK-ME. CLiSK introduces smoothed key term contexts to enhance exploration in\npreference learning, CLiME adaptively initiates conversations based on\npreference uncertainty, and CLiSK-ME integrates both techniques. We\ntheoretically prove that all three algorithms achieve a tighter regret upper\nbound of $O(\\sqrt{dT\\log{T}})$ with respect to the time horizon $T$, improving\nupon existing methods. Additionally, we provide a matching lower bound\n$\\Omega(\\sqrt{dT})$ for conversational bandits, demonstrating that our\nalgorithms are nearly minimax optimal. Extensive evaluations on both synthetic\nand real-world datasets show that our approaches achieve at least a 14.6%\nimprovement in cumulative regret.','Maoli Liu, Zhuohua Li, Xiangxiang Dai, John C. S. Lui','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21393v1','该论文提出了三种新的算法（CLiSK、CLiME和CLiSK-ME），用于改进对话式推荐系统中的偏好学习，通过增强探索性和根据偏好不确定性自适应地开始对话来解决现有算法的局限性。理论上证明这三种算法在时间跨度$T$上实现了更紧密的遗憾上限$O(\\sqrt{dT\\log{T}})$，并且在合成和真实数据集上的广泛评估表明，这些方法至少实现了14.6%的累积遗憾改进。'),('2505.21395v1','Square$χ$PO: Differentially Private and Robust $χ^2$-Preference Optimization in Offline Direct Alignment','In this paper, we theoretically study the offline alignment of language\nmodels with human preference feedback, under both preference label corruption\nand privacy protections. To this end, we propose Square$\\chi$PO, a simple\none-line change to $\\chi$PO where the standard log-loss is replaced by a new\nsquare loss over probability. Thanks to the inherent properties of this new\nloss, we have advanced the state-of-the-art of differentially private and\nrobust offline direct alignment. Specifically, for the local model of label\nprivacy, Square$\\chi$PO is the first algorithm that attains an optimal rate\nbased on single-policy concentrability even with general function\napproximations. It also gives the first result under the central model of\nprivacy protection over both prompts (responses) and labels. On the robustness\nside against Huber label corruption, Square$\\chi$PO is the first alignment\nmethod that has a meaningful theoretical guarantee under general function\napproximations. More importantly, Square$\\chi$PO can address privacy protection\nand corruption simultaneously, where an interesting separation is observed,\nimplying that the order of privacy and corruption matters. Furthermore, we show\nthat Square$\\chi$PO can also be easily extended to handle the scenario of the\ngeneral preference model with state-of-the-art guarantees under corruption and\nprivacy. Last but not least, all of our theoretical guarantees enjoy a unified\nanalysis, building upon a new result on the generalization error bounds of\nleast-square regression under corruption and privacy constraints, which we\nbelieve is of independent interest to the community.','Xingyu Zhou, Yulian Wu, Wenqian Weng, Francesco Orabona','2025-05-27','cs.LG','LLM (语言模型对齐)','http://arxiv.org/pdf/2505.21395v1','本文研究了语言模型与人类偏好反馈的离线对齐问题，考虑了偏好标签损坏和隐私保护。提出了Square$\\chi$PO算法，通过引入新的平方损失函数，实现了在不同ially private和鲁棒的离线直接对齐方面的最新进展。'),('2505.21396v1','Improving Research Idea Generation Through Data: An Empirical Investigation in Social Science','Recent advancements in large language models (LLMs) have shown promise in\ngenerating novel research ideas. However, these ideas often face challenges\nrelated to feasibility and expected effectiveness. This paper explores how\naugmenting LLMs with relevant data during the idea generation process can\nenhance the quality of generated ideas. We introduce two ways of incorporating\ndata: (1) providing metadata during the idea generation stage to guide LLMs\ntoward feasible directions, and (2) adding automatic validation during the idea\nselection stage to assess the empirical plausibility of hypotheses within\nideas. We conduct experiments in the social science domain, specifically with\nclimate negotiation topics, and find that metadata improves the feasibility of\ngenerated ideas by 20%, while automatic validation improves the overall quality\nof selected ideas by 7%. A human study shows that LLM-generated ideas, along\nwith their related data and validation processes, inspire researchers to\npropose research ideas with higher quality. Our work highlights the potential\nof data-driven research idea generation, and underscores the practical utility\nof LLM-assisted ideation in real-world academic settings.','Xiao Liu, Xinyi Dong, Xinyang Gao, Yansong Feng, Xun Pang','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21396v1','该论文探讨了如何在研究想法生成过程中通过增加相关数据来提高生成的想法质量，包括在想法生成阶段提供元数据以指导LLMs朝着可行的方向发展，以及在想法选择阶段添加自动验证以评估想法中假设的经验可信度。在社会科学领域进行实验，特别是在气候谈判主题中，发现元数据提高了生成的想法的可行性约20％，而自动验证提高了所选想法的整体质量约7％。人类研究表明，LLM生成的想法以及相关数据和验证过程激发研究人员提出更高质量的研究想法。该研究突出了数据驱动的研究想法生成的潜力，并强调了LLM辅助构思在真实学术环境中的实际效用。'),('2505.21397v1','DecisionFlow: Advancing Large Language Model as Principled Decision Maker','In high-stakes domains such as healthcare and finance, effective\ndecision-making demands not just accurate outcomes but transparent and\nexplainable reasoning. However, current language models often lack the\nstructured deliberation needed for such tasks, instead generating decisions and\njustifications in a disconnected, post-hoc manner. To address this, we propose\nDecisionFlow, a novel decision modeling framework that guides models to reason\nover structured representations of actions, attributes, and constraints. Rather\nthan predicting answers directly from prompts, DecisionFlow builds a\nsemantically grounded decision space and infers a latent utility function to\nevaluate trade-offs in a transparent, utility-driven manner. This process\nproduces decisions tightly coupled with interpretable rationales reflecting the\nmodel\\\'s reasoning. Empirical results on two high-stakes benchmarks show that\nDecisionFlow not only achieves up to 30% accuracy gains over strong prompting\nbaselines but also enhances alignment in outcomes. Our work is a critical step\ntoward integrating symbolic reasoning with LLMs, enabling more accountable,\nexplainable, and reliable LLM decision support systems. We release the data and\ncode at https://github.com/xiusic/DecisionFlow.','Xiusi Chen, Shanyong Wang, Cheng Qian, Hongru Wang, Peixuan Han, Heng Ji','2025-05-27','cs.CL','LLM (语言模型)','http://arxiv.org/pdf/2505.21397v1','该论文提出了一种名为DecisionFlow的决策建模框架，旨在指导模型对行动、属性和约束的结构化表示进行推理，以透明、基于效用的方式评估权衡，从而生成与可解释推理紧密耦合的决策。'),('2505.21398v1','A Structured Unplugged Approach for Foundational AI Literacy in Primary Education','Younger generations are growing up in a world increasingly shaped by\nintelligent technologies, making early AI literacy crucial for developing the\nskills to critically understand and navigate them. However, education in this\nfield often emphasizes tool-based learning, prioritizing usage over\nunderstanding the underlying concepts. This lack of knowledge leaves\nnon-experts, especially children, prone to misconceptions, unrealistic\nexpectations, and difficulties in recognizing biases and stereotypes. In this\npaper, we propose a structured and replicable teaching approach that fosters\nfoundational AI literacy in primary students, by building upon core\nmathematical elements closely connected to and of interest in primary\ncurricula, to strengthen conceptualization, data representation, classification\nreasoning, and evaluation of AI. To assess the effectiveness of our approach,\nwe conducted an empirical study with thirty-one fifth-grade students across two\nclasses, evaluating their progress through a post-test and a satisfaction\nsurvey. Our results indicate improvements in terminology understanding and\nusage, features description, logical reasoning, and evaluative skills, with\nstudents showing a deeper comprehension of decision-making processes and their\nlimitations. Moreover, the approach proved engaging, with students particularly\nenjoying activities that linked AI concepts to real-world reasoning. Materials:\nhttps://github.com/tail-unica/ai-literacy-primary-ed.','Maria Cristina Carrisi, Mirko Marras, Sara Vergallo','2025-05-27','cs.AI','教育与人工智能','http://arxiv.org/pdf/2505.21398v1','本文提出了一种结构化和可复制的教学方法，旨在培养小学生的基础人工智能素养，通过建立在与小学课程密切相关且感兴趣的核心数学元素之上，加强概念化、数据表示、分类推理和评估AI的能力。通过对两个班级的31名五年级学生进行实证研究，结果显示学生在术语理解和使用、特征描述、逻辑推理和评估技能方面取得了进步，对决策过程及其局限性有了更深入的理解。'),('2505.21399v1','Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling','Factual incorrectness in generated content is one of the primary concerns in\nubiquitous deployment of large language models (LLMs). Prior findings suggest\nLLMs can (sometimes) detect factual incorrectness in their generated content\n(i.e., fact-checking post-generation). In this work, we provide evidence\nsupporting the presence of LLMs\\\' internal compass that dictate the correctness\nof factual recall at the time of generation. We demonstrate that for a given\nsubject entity and a relation, LLMs internally encode linear features in the\nTransformer\\\'s residual stream that dictate whether it will be able to recall\nthe correct attribute (that forms a valid entity-relation-attribute triplet).\nThis self-awareness signal is robust to minor formatting variations. We\ninvestigate the effects of context perturbation via different example selection\nstrategies. Scaling experiments across model sizes and training dynamics\nhighlight that self-awareness emerges rapidly during training and peaks in\nintermediate layers. These findings uncover intrinsic self-monitoring\ncapabilities within LLMs, contributing to their interpretability and\nreliability.','Hovhannes Tamoyan, Subhabrata Dutta, Iryna Gurevych','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21399v1','本文研究了大型语言模型（LLMs）在生成内容中存在的事实不准确性问题，提供了证据支持LLMs在生成时具有内部指导事实召回正确性的能力。研究表明，LLMs在Transformer的残差流中内部编码了线性特征，决定其是否能正确召回属性。自我意识信号对轻微格式变化具有鲁棒性，研究了上下文扰动对其影响，并发现自我意识在训练期间迅速出现并在中间层达到峰值。'),('2505.21400v1','A Convergence Theory for Diffusion Language Models: An Information-Theoretic Perspective','Diffusion models have emerged as a powerful paradigm for modern generative\nmodeling, demonstrating strong potential for large language models (LLMs).\nUnlike conventional autoregressive (AR) models that generate tokens\nsequentially, diffusion models enable parallel token sampling, leading to\nfaster generation and eliminating left-to-right generation constraints. Despite\ntheir empirical success, the theoretical understanding of diffusion model\napproaches remains underdeveloped. In this work, we develop convergence\nguarantees for diffusion language models from an information-theoretic\nperspective. Our analysis demonstrates that the sampling error, measured by the\nKullback-Leibler (KL) divergence, decays inversely with the number of\niterations $T$ and scales linearly with the mutual information between tokens\nin the target text sequence. In particular, we establish matching upper and\nlower bounds, up to some constant factor, to demonstrate the tightness of our\nconvergence analysis. These results offer novel theoretical insights into the\npractical effectiveness of diffusion language models.','Gen Li, Changxiao Cai','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21400v1','本文研究了扩散模型在生成模型中的应用，提出了扩散语言模型的收敛性保证，并从信息论的角度分析了采样误差与迭代次数和目标文本序列中的标记之间的关系。'),('2505.21404v1','Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks','Natural-gradient methods markedly accelerate the training of Physics-Informed\nNeural Networks (PINNs), yet their Gauss--Newton update must be solved in the\nparameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is\nthe number of network trainable weights. We show that exactly the same step can\ninstead be formulated in a generally smaller residual space of size $m =\n\\sum_{\\gamma} N_{\\gamma} d_{\\gamma}$, where each residual class $\\gamma$ (e.g.\nPDE interior, boundary, initial data) contributes $N_{\\gamma}$ collocation\npoints of output dimension $d_{\\gamma}$.\n  Building on this insight, we introduce \\textit{Dual Natural Gradient Descent}\n(D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it\nwith a geodesic-acceleration correction at negligible extra cost, and provides\nboth a dense direct solver for modest $m$ and a Nystrom-preconditioned\nconjugate-gradient solver for larger $m$.\n  Experimentally, D-NGD scales second-order PINN optimization to networks with\nup to 12.8 million parameters, delivers one- to three-order-of-magnitude lower\nfinal error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton\nmethods, and -- crucially -- enables natural-gradient training of PINNs at this\nscale on a single GPU.','Anas Jnini, Flavio Vella','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21404v1','本文提出了一种名为Dual Natural Gradient Descent (D-NGD)的方法，通过在残差空间中计算Gauss-Newton步骤，加速了Physics-Informed Neural Networks (PINNs)的训练。实验结果表明，D-NGD方法在单个GPU上实现了规模为1280万参数的PINN优化，并比Adam、SGD和拟牛顿方法实现了更低的最终误差。'),('2505.21409v1','RelationalFactQA: A Benchmark for Evaluating Tabular Fact Retrieval from Large Language Models','Factuality in Large Language Models (LLMs) is a persistent challenge. Current\nbenchmarks often assess short factual answers, overlooking the critical ability\nto generate structured, multi-record tabular outputs from parametric knowledge.\nWe demonstrate that this relational fact retrieval is substantially more\ndifficult than isolated point-wise queries, even when individual facts are\nknown to the model, exposing distinct failure modes sensitive to output\ndimensionality (e.g., number of attributes or records). To systematically\nevaluate this under-explored capability, we introduce RelationalFactQA, a new\nbenchmark featuring diverse natural language questions (paired with SQL) and\ngold-standard tabular answers, specifically designed to assess knowledge\nretrieval in a structured format. RelationalFactQA enables analysis across\nvarying query complexities, output sizes, and data characteristics. Our\nexperiments reveal that even state-of-the-art LLMs struggle significantly, not\nexceeding 25% factual accuracy in generating relational outputs, with\nperformance notably degrading as output dimensionality increases. These\nfindings underscore critical limitations in current LLMs\\\' ability to synthesize\nstructured factual knowledge and establish RelationalFactQA as a crucial\nresource for measuring future progress in LLM factuality.','Dario Satriani, Enzo Veltri, Donatello Santoro, Paolo Papotti','2025-05-27','cs.CL','LLM','http://arxiv.org/pdf/2505.21409v1','该论文研究了大型语言模型（LLMs）在生成结构化多记录表格输出方面的困难，介绍了新的基准测试RelationalFactQA，并发现即使是最先进的LLMs在生成关系型输出方面也存在显著困难。'),('2505.21410v1','MRSD: Multi-Resolution Skill Discovery for HRL Agents','Hierarchical reinforcement learning (HRL) relies on abstract skills to solve\nlong-horizon tasks efficiently. While existing skill discovery methods learns\nthese skills automatically, they are limited to a single skill per task. In\ncontrast, humans learn and use both fine-grained and coarse motor skills\nsimultaneously. Inspired by human motor control, we propose Multi-Resolution\nSkill Discovery (MRSD), an HRL framework that learns multiple skill encoders at\ndifferent temporal resolutions in parallel. A high-level manager dynamically\nselects among these skills, enabling adaptive control strategies over time. We\nevaluate MRSD on tasks from the DeepMind Control Suite and show that it\noutperforms prior state-of-the-art skill discovery and HRL methods, achieving\nfaster convergence and higher final performance. Our findings highlight the\nbenefits of integrating multi-resolution skills in HRL, paving the way for more\nversatile and efficient agents.','Shashank Sharma, Janina Hoffmann, Vinay Namboodiri','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.21410v1','该论文提出了一种多分辨率技能发现（MRSD）的层次强化学习框架，可以同时学习多个不同时间分辨率的技能编码器，并通过高层管理器动态选择这些技能，实现对时间的自适应控制策略。实验结果表明，MRSD在DeepMind Control Suite的任务中表现优于先前的技能发现和HRL方法，收敛速度更快，最终性能更高。'),('2505.21411v2','Pangu Pro MoE: Mixture of Grouped Experts for Efficient Sparsity','The surgence of Mixture of Experts (MoE) in Large Language Models promises a\nsmall price of execution cost for a much larger model parameter count and\nlearning capacity, because only a small fraction of parameters are activated\nfor each input token. However, it is commonly observed that some experts are\nactivated far more often than others, leading to system inefficiency when\nrunning the experts on different devices in parallel. Therefore, we introduce\nMixture of Grouped Experts (MoGE), which groups the experts during selection\nand balances the expert workload better than MoE in nature. It constrains\ntokens to activate an equal number of experts within each predefined expert\ngroup. When a model execution is distributed on multiple devices, this\narchitectural design ensures a balanced computational load across devices,\nsignificantly enhancing throughput, particularly for the inference phase.\nFurther, we build Pangu Pro MoE on Ascend NPUs, a sparse model based on MoGE\nwith 72 billion total parameters, 16 billion of which are activated for each\ntoken. The configuration of Pangu Pro MoE is optimized for Ascend 300I Duo and\n800I A2 through extensive system simulation studies. Our experiments indicate\nthat MoGE indeed leads to better expert load balancing and more efficient\nexecution for both model training and inference on Ascend NPUs. The inference\nperformance of Pangu Pro MoE achieves 1148 tokens/s per card and can be further\nimproved to 1528 tokens/s per card by speculative acceleration, outperforming\ncomparable 32B and 72B Dense models. Furthermore, we achieve an excellent\ncost-to-performance ratio for model inference on Ascend 300I Duo. Our studies\nshow that Ascend NPUs are capable of training Pangu Pro MoE with massive\nparallelization to make it a leading model within the sub-100B total parameter\nclass, outperforming prominent open-source models like GLM-Z1-32B and\nQwen3-32B.','Yehui Tang, Xiaosong Li, Fangcheng Liu, Wei Guo, Hang Zhou, Yaoyuan Wang, Kai Han, Xianzhi Yu, Jinpeng Li, Hui Zang, Fei Mi, Xiaojun Meng, Zhicheng Liu, Hanting Chen, Binfan Zheng, Can Chen, Youliang Yan, Ruiming Tang, Peifeng Qin, Xinghao Chen, Dacheng Tao, Yunhe Wang','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21411v2','该论文介绍了一种新的专家混合模型，Mixture of Grouped Experts (MoGE)，用于在大型语言模型中平衡专家的工作负载，提高模型的执行效率。作者还构建了基于MoGE的Pangu Pro MoE模型，并在Ascend NPUs上进行了优化和实验，结果表明MoGE在模型训练和推理阶段都能够提高执行效率。'),('2505.21413v1','RefTool: Enhancing Model Reasoning with Reference-Guided Tool Creation','Tools enhance the reasoning capabilities of large language models (LLMs) in\ncomplex problem-solving tasks, but not all tasks have available tools. In the\nabsence of predefined tools, prior works have explored instructing LLMs to\ngenerate tools on their own. However, such approaches rely heavily on the\nmodels\\\' internal knowledge and would fail in domains beyond the LLMs\\\' knowledge\nscope. To address this limitation, we propose RefTool, a reference-guided\nframework for automatic tool creation that leverages structured external\nmaterials such as textbooks. RefTool consists of two modules: (1) tool\ncreation, where LLMs generate executable tools from reference content, validate\nthem using illustrative examples, and organize them hierarchically into a\ntoolbox; and (2) tool utilization, where LLMs navigate the toolbox structure to\nselect and apply the appropriate tools to solve problems. Experiments on\ncausality, physics, and chemistry benchmarks demonstrate that RefTool\noutperforms existing tool-creation and domain-specific reasoning methods by\n11.3% on average accuracy, while being cost-efficient and broadly\ngeneralizable. Analyses reveal that grounding tool creation in references\nproduces accurate and faithful tools, and that the hierarchical structure\nfacilitates effective tool selection. RefTool enables LLMs to overcome\nknowledge limitations, demonstrating the value of grounding tool creation in\nexternal references for enhanced and generalizable reasoning.','Xiao Liu, Da Yin, Zirui Wu, Yansong Feng','2025-05-27','cs.CL','LLM（大型语言模型）, 自然语言处理','http://arxiv.org/pdf/2505.21413v1','本文提出了一种基于参考文献的自动工具创建框架 RefTool，利用结构化外部材料如教科书，使大型语言模型（LLMs）能够生成可执行工具，验证工具并将其按层次结构组织到工具箱中，以解决复杂问题。实验结果表明，RefTool 在因果关系、物理和化学基准测试中表现优于现有的工具创建和领域特定推理方法，平均准确率提高了11.3%，同时具有成本效益和广泛适用性。'),('2505.21414v1','A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment','This paper introduces a comprehensive framework designed to analyze and\nsecure decision-support systems trained with Deep Reinforcement Learning (DRL),\nprior to deployment, by providing insights into learned behavior patterns and\nvulnerabilities discovered through simulation. The introduced framework aids in\nthe development of precisely timed and targeted observation perturbations,\nenabling researchers to assess adversarial attack outcomes within a strategic\ndecision-making context. We validate our framework, visualize agent behavior,\nand evaluate adversarial outcomes within the context of a custom-built\nstrategic game, CyberStrike. Utilizing the proposed framework, we introduce a\nmethod for systematically discovering and ranking the impact of attacks on\nvarious observation indices and time-steps, and we conduct experiments to\nevaluate the transferability of adversarial attacks across agent architectures\nand DRL training algorithms. The findings underscore the critical need for\nrobust adversarial defense mechanisms to protect decision-making policies in\nhigh-stakes environments.','Brett Bissey, Kyle Gatesman, Walker Dimon, Mohammad Alam, Luis Robaina, Joseph Weissman','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21414v1','该论文介绍了一个综合框架，旨在分析和保护在部署之前通过深度强化学习（DRL）训练的决策支持系统，通过模拟提供对学习行为模式和发现的漏洞的洞察。该框架帮助开发精确定时和定位的观察扰动，使研究人员能够在战略决策背景下评估对抗性攻击结果。研究结果强调了在高风险环境中保护决策政策所需的强大对抗性防御机制的重要性。'),('2505.21419v2','Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs','Today\\\'s cloud-hosted applications and services are complex systems, and a\nperformance or functional instability can have dozens or hundreds of potential\nroot causes. Our hypothesis is that by combining the pattern matching\ncapabilities of modern AI tools with a natural multi-modal RAG LLM interface,\nproblem identification and resolution can be simplified. ARCA is a new\nmulti-modal RAG LLM system that targets this domain. Step-wise evaluations show\nthat ARCA outperforms state-of-the-art alternatives.','Yifan Wang, Kenneth P. Birman','2025-05-27','cs.AI','LLM','http://arxiv.org/pdf/2505.21419v2','该论文介绍了一种新的多模态RAG LLM系统ARCA，通过结合现代人工智能工具的模式匹配能力，简化问题识别和解决过程。实验结果表明，ARCA优于现有的最先进替代方案。'),('2505.21420v1','Mentor3AD: Feature Reconstruction-based 3D Anomaly Detection via Multi-modality Mentor Learning','Multimodal feature reconstruction is a promising approach for 3D anomaly\ndetection, leveraging the complementary information from dual modalities. We\nfurther advance this paradigm by utilizing multi-modal mentor learning, which\nfuses intermediate features to further distinguish normal from feature\ndifferences. To address these challenges, we propose a novel method called\nMentor3AD, which utilizes multi-modal mentor learning. By leveraging the shared\nfeatures of different modalities, Mentor3AD can extract more effective features\nand guide feature reconstruction, ultimately improving detection performance.\nSpecifically, Mentor3AD includes a Mentor of Fusion Module (MFM) that merges\nfeatures extracted from RGB and 3D modalities to create a mentor feature.\nAdditionally, we have designed a Mentor of Guidance Module (MGM) to facilitate\ncross-modal reconstruction, supported by the mentor feature. Lastly, we\nintroduce a Voting Module (VM) to more accurately generate the final anomaly\nscore. Extensive comparative and ablation studies on MVTec 3D-AD and Eyecandies\nhave verified the effectiveness of the proposed method.','Jinbao Wang, Hanzhe Liang, Can Gao, Chenxi Hu, Jie Zhou, Yunkang Cao, Linlin Shen, Weiming Shen','2025-05-27','cs.CV','3D异常检测','http://arxiv.org/pdf/2505.21420v1','该论文提出了一种名为Mentor3AD的新方法，通过利用多模态导师学习来进一步提高3D异常检测的性能。该方法包括融合RGB和3D模态提取的特征的MFM模块、利用导师特征促进跨模态重建的MGM模块以及通过VM模块更准确生成最终异常分数的投票模块。'),('2505.21421v1','A Physics-Augmented GraphGPS Framework for the Reconstruction of 3D Riemann Problems from Sparse Data','In compressible fluid flow, reconstructing shocks, discontinuities,\nrarefactions, and their interactions from sparse measurements is an important\ninverse problem with practical applications. Moreover, physics-informed machine\nlearning has recently become an increasingly popular approach for performing\nreconstructions tasks. In this work we explore a machine learning recipe, known\nas GraphGPS, for reconstructing canonical compressible flows known as 3D\nRiemann problems from sparse observations, in a physics-informed manner. The\nGraphGPS framework combines the benefits of positional encodings, local\nmessage-passing of graphs, and global contextual awareness, and we explore the\nlatter two components through an ablation study. Furthermore, we modify the\naggregation step of message-passing such that it is aware of shocks and\ndiscontinuities, resulting in sharper reconstructions of these features.\nAdditionally, we modify message-passing such that information flows strictly\nfrom known nodes only, which results in computational savings, better training\nconvergence, and no degradation of reconstruction accuracy. We also show that\nthe GraphGPS framework outperforms numerous machine learning benchmarks.','Rami Cassia, Rich Kerswell','2025-05-27','physics.flu-dyn','物理知识驱动的机器学习(AI in Physics)','http://arxiv.org/pdf/2505.21421v1','该论文探讨了利用物理知识的机器学习方法GraphGPS来从稀疏观测数据中重建三维Riemann问题的压缩流动，通过结合位置编码、图的局部消息传递和全局上下文意识等组件，实现了更清晰的重建效果，并在实验中表现优于其他机器学习基准。'),('2505.21422v1','When Shift Happens - Confounding Is to Blame','Distribution shifts introduce uncertainty that undermines the robustness and\ngeneralization capabilities of machine learning models. While conventional\nwisdom suggests that learning causal-invariant representations enhances\nrobustness to such shifts, recent empirical studies present a counterintuitive\nfinding: (i) empirical risk minimization (ERM) can rival or even outperform\nstate-of-the-art out-of-distribution (OOD) generalization methods, and (ii) its\nOOD generalization performance improves when all available covariates, not just\ncausal ones, are utilized. Drawing on both empirical and theoretical evidence,\nwe attribute this phenomenon to hidden confounding. Shifts in hidden\nconfounding induce changes in data distributions that violate assumptions\ncommonly made by existing OOD generalization approaches. Under such conditions,\nwe prove that effective generalization requires learning environment-specific\nrelationships, rather than relying solely on invariant ones. Furthermore, we\nshow that models augmented with proxies for hidden confounders can mitigate the\nchallenges posed by hidden confounding shifts. These findings offer new\ntheoretical insights and practical guidance for designing robust OOD\ngeneralization algorithms and principled covariate selection strategies.','Abbavaram Gowtham Reddy, Celia Rubio-Madrigal, Rebekka Burkholz, Krikamol Muandet','2025-05-27','cs.LG','鲁棒性泛化算法设计','http://arxiv.org/pdf/2505.21422v1','该论文研究了分布转移对机器学习模型的鲁棒性和泛化能力的影响，发现了隐藏混淆因素对模型性能的影响，并提出了通过学习环境特定关系而非仅仅依赖不变关系来提高泛化性能的方法。'),('2505.21423v1','Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization','A widely believed explanation for the remarkable generalization capacities of\noverparameterized neural networks is that the optimization algorithms used for\ntraining induce an implicit bias towards benign solutions. To grasp this\ntheoretically, recent works examine gradient descent and its variants in\nsimplified training settings, often assuming vanishing learning rates. These\nstudies reveal various forms of implicit regularization, such as $\\ell_1$-norm\nminimizing parameters in regression and max-margin solutions in classification.\nConcurrently, empirical findings show that moderate to large learning rates\nexceeding standard stability thresholds lead to faster, albeit oscillatory,\nconvergence in the so-called Edge-of-Stability regime, and induce an implicit\nbias towards minima of low sharpness (norm of training loss Hessian). In this\nwork, we argue that a comprehensive understanding of the generalization\nperformance of gradient descent requires analyzing the interaction between\nthese various forms of implicit regularization. We empirically demonstrate that\nthe learning rate balances between low parameter norm and low sharpness of the\ntrained model. We furthermore prove for diagonal linear networks trained on a\nsimple regression task that neither implicit bias alone minimizes the\ngeneralization error. These findings demonstrate that focusing on a single\nimplicit bias is insufficient to explain good generalization, and they motivate\na broader view of implicit regularization that captures the dynamic trade-off\nbetween norm and sharpness induced by non-negligible learning rates.','Vit Fojtik, Maria Matveev, Hung-Hsu Chou, Gitta Kutyniok, Johannes Maly','2025-05-27','cs.LG','深度学习/神经网络','http://arxiv.org/pdf/2505.21423v1','该论文研究了过参数化神经网络的泛化能力，并探讨了梯度下降算法对训练的隐式偏差以及学习率对模型参数规范性和训练损失Hessian矩阵锐度的影响。'),('2505.21426v1','Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks','Agent-Based Models (ABMs) are powerful tools for studying emergent properties\nin complex systems. In ABMs, agent behaviors are governed by local interactions\nand stochastic rules. However, these rules are, in general, non-differentiable,\nlimiting the use of gradient-based methods for optimization, and thus\nintegration with real-world data. We propose a novel framework to learn a\ndifferentiable surrogate of any ABM by observing its generated data. Our method\ncombines diffusion models to capture behavioral stochasticity and graph neural\nnetworks to model agent interactions. Distinct from prior surrogate approaches,\nour method introduces a fundamental shift: rather than approximating\nsystem-level outputs, it models individual agent behavior directly, preserving\nthe decentralized, bottom-up dynamics that define ABMs. We validate our\napproach on two ABMs (Schelling\\\'s segregation model and a Predator-Prey\necosystem) showing that it replicates individual-level patterns and accurately\nforecasts emergent dynamics beyond training. Our results demonstrate the\npotential of combining diffusion models and graph learning for data-driven ABM\nsimulation.','Francesco Cozzi, Marco Pangallo, Alan Perotti, André Panisson, Corrado Monti','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.21426v1','该论文提出了一种新颖的框架，通过观察生成的数据学习任何ABM的可微替代模型。他们的方法结合了扩散模型来捕捉行为随机性和图神经网络来建模agent之间的互动。与先前的替代方法不同，他们的方法直接建模个体agent的行为，保留了定义ABM的分散、自下而上的动态。'),('2505.21427v1','Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning','Early-stage startup investment is a high-risk endeavor characterized by\nscarce data and uncertain outcomes. Traditional machine learning approaches\noften require large, labeled datasets and extensive fine-tuning, yet remain\nopaque and difficult for domain experts to interpret or improve. In this paper,\nwe propose a transparent and data-efficient investment decision framework\npowered by memory-augmented large language models (LLMs) using in-context\nlearning (ICL). Central to our method is a natural language policy embedded\ndirectly into the LLM prompt, enabling the model to apply explicit reasoning\npatterns and allowing human experts to easily interpret, audit, and iteratively\nrefine the logic. We introduce a lightweight training process that combines\nfew-shot learning with an in-context learning loop, enabling the LLM to update\nits decision policy iteratively based on structured feedback. With only minimal\nsupervision and no gradient-based optimization, our system predicts startup\nsuccess far more accurately than existing benchmarks. It is over 20x more\nprecise than random chance, which succeeds 1.9% of the time. It is also 7.1x\nmore precise than the typical 5.6% success rate of top-tier venture capital\n(VC) firms.','Xianling Mu, Joseph Ternasky, Fuat Alican, Yigit Ihlamur','2025-05-27','cs.AI','LLM','http://arxiv.org/pdf/2505.21427v1','本文提出了一种透明、数据高效的投资决策框架，利用基于记忆的大型语言模型（LLMs）和上下文学习（ICL）进行投资决策。通过将自然语言策略嵌入到LLM提示中，使模型能够应用明确的推理模式，让人类专家能够轻松解释、审计和迭代改进逻辑。通过轻量级的训练过程，结合少样本学习和上下文学习循环，使LLM能够基于结构化反馈迭代更新其决策策略。该系统预测初创公司的成功比现有基准要准确得多，比随机成功率高出20倍，比顶级风险投资公司的典型成功率高出7.1倍。'),('2505.21430v1','Attribute-Efficient PAC Learning of Sparse Halfspaces with Constant Malicious Noise Rate','Attribute-efficient learning of sparse halfspaces has been a fundamental\nproblem in machine learning theory. In recent years, machine learning\nalgorithms are faced with prevalent data corruptions or even adversarial\nattacks. It is of central interest to design efficient algorithms that are\nrobust to noise corruptions. In this paper, we consider that there exists a\nconstant amount of malicious noise in the data and the goal is to learn an\nunderlying $s$-sparse halfspace $w^* \\in \\mathbb{R}^d$ with $\\text{poly}(s,\\log\nd)$ samples. Specifically, we follow a recent line of works and assume that the\nunderlying distribution satisfies a certain concentration condition and a\nmargin condition at the same time. Under such conditions, we show that\nattribute-efficiency can be achieved by simple variants to existing hinge loss\nminimization programs. Our key contribution includes: 1) an attribute-efficient\nPAC learning algorithm that works under constant malicious noise rate; 2) a new\ngradient analysis that carefully handles the sparsity constraint in hinge loss\nminimization.','Shiwei Zeng, Jie Shen','2025-05-27','cs.LG','机器学习理论','http://arxiv.org/pdf/2505.21430v1','本文研究了在面对数据污染或对抗攻击时，如何高效地学习稀疏半空间的问题。通过假设数据中存在恶意噪声，并在一定条件下设计了一种属性高效的PAC学习算法，能够学习到稀疏半空间。'),('2505.21432v1','Hume: Introducing System-2 Thinking in Visual-Language-Action Model','Humans practice slow thinking before performing actual actions when handling\ncomplex tasks in the physical world. This thinking paradigm, recently, has\nachieved remarkable advancement in boosting Large Language Models (LLMs) to\nsolve complex tasks in digital domains. However, the potential of slow thinking\nremains largely unexplored for robotic foundation models interacting with the\nphysical world. In this work, we propose Hume: a dual-system\nVision-Language-Action (VLA) model with value-guided System-2 thinking and\ncascaded action denoising, exploring human-like thinking capabilities of\nVision-Language-Action models for dexterous robot control. System 2 of Hume\nimplements value-Guided thinking by extending a Vision-Language-Action Model\nbackbone with a novel value-query head to estimate the state-action value of\npredicted actions. The value-guided thinking is conducted by repeat sampling\nmultiple action candidates and selecting one according to state-action value.\nSystem 1 of Hume is a lightweight reactive visuomotor policy that takes System\n2 selected action and performs cascaded action denoising for dexterous robot\ncontrol. At deployment time, System 2 performs value-guided thinking at a low\nfrequency while System 1 asynchronously receives the System 2 selected action\ncandidate and predicts fluid actions in real time. We show that Hume\noutperforms the existing state-of-the-art Vision-Language-Action models across\nmultiple simulation benchmark and real-robot deployments.','Haoming Song, Delin Qu, Yuanqi Yao, Qizhi Chen, Qi Lv, Yiwen Tang, Modi Shi, Guanghui Ren, Maoqing Yao, Bin Zhao, Dong Wang, Xuelong Li','2025-05-27','cs.RO','强化学习','http://arxiv.org/pdf/2505.21432v1','本文提出了一种名为Hume的双系统视觉-语言-动作（VLA）模型，结合了价值引导的系统2思维和级联动作去噪，探索了人类式思考能力在机器人基础模型中的应用，以实现灵巧的机器人控制。'),('2505.21438v1','Measuring Fine-Grained Relatedness in Multitask Learning via Data Attribution','Measuring task relatedness and mitigating negative transfer remain a critical\nopen challenge in Multitask Learning (MTL). This work extends data attribution\n-- which quantifies the influence of individual training data points on model\npredictions -- to MTL setting for measuring task relatedness. We propose the\nMultiTask Influence Function (MTIF), a method that adapts influence functions\nto MTL models with hard or soft parameter sharing. Compared to conventional\ntask relatedness measurements, MTIF provides a fine-grained, instance-level\nrelatedness measure beyond the entire-task level. This fine-grained relatedness\nmeasure enables a data selection strategy to effectively mitigate negative\ntransfer in MTL. Through extensive experiments, we demonstrate that the\nproposed MTIF efficiently and accurately approximates the performance of models\ntrained on data subsets. Moreover, the data selection strategy enabled by MTIF\nconsistently improves model performance in MTL. Our work establishes a novel\nconnection between data attribution and MTL, offering an efficient and\nfine-grained solution for measuring task relatedness and enhancing MTL models.','Yiwen Tu, Ziqi Liu, Jiaqi W. Ma, Weijing Tang','2025-05-27','cs.LG','多任务学习 (MTL)','http://arxiv.org/pdf/2505.21438v1','该论文提出了一种名为MultiTask Influence Function (MTIF)的方法，通过扩展数据归因来衡量多任务学习中的任务相关性，并提出了一种数据选择策略以有效减轻负迁移。'),('2505.21439v1','Towards Better Instruction Following Retrieval Models','Modern information retrieval (IR) models, trained exclusively on standard\n<query, passage> pairs, struggle to effectively interpret and follow explicit\nuser instructions. We introduce InF-IR, a large-scale, high-quality training\ncorpus tailored for enhancing retrieval models in Instruction-Following IR.\nInF-IR expands traditional training pairs into over 38,000 expressive\n<instruction, query, passage> triplets as positive samples. In particular, for\neach positive triplet, we generate two additional hard negative examples by\npoisoning both instructions and queries, then rigorously validated by an\nadvanced reasoning model (o3-mini) to ensure semantic plausibility while\nmaintaining instructional incorrectness. Unlike existing corpora that primarily\nsupport computationally intensive reranking tasks for decoder-only language\nmodels, the highly contrastive positive-negative triplets in InF-IR further\nenable efficient representation learning for smaller encoder-only models,\nfacilitating direct embedding-based retrieval. Using this corpus, we train\nInF-Embed, an instruction-aware Embedding model optimized through contrastive\nlearning and instruction-query attention mechanisms to align retrieval outcomes\nprecisely with user intents. Extensive experiments across five\ninstruction-based retrieval benchmarks demonstrate that InF-Embed significantly\nsurpasses competitive baselines by 8.1% in p-MRR, measuring the\ninstruction-following capabilities.','Yuchen Zhuang, Aaron Trinh, Rushi Qiang, Haotian Sun, Chao Zhang, Hanjun Dai, Bo Dai','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21439v1','该论文介绍了一种新的训练语料库InF-IR，用于增强检索模型在指令跟随信息检索中的表现。通过扩展传统的训练对为超过38,000个表达丰富的<指令，查询，文段>三元组作为正样本，同时生成两个额外的硬负例，以提高检索模型的指令跟随能力。作者还介绍了InF-Embed模型，通过对比学习和指令-查询注意机制进行优化，使得检索结果与用户意图精确对齐。'),('2505.21444v1','Can Large Reasoning Models Self-Train?','Scaling the performance of large language models (LLMs) increasingly depends\non methods that reduce reliance on human supervision. Reinforcement learning\nfrom automated verification offers an alternative, but it incurs scalability\nlimitations due to dependency upon human-designed verifiers. Self-training,\nwhere the model\\\'s own judgment provides the supervisory signal, presents a\ncompelling direction. We propose an online self-training reinforcement learning\nalgorithm that leverages the model\\\'s self-consistency to infer correctness\nsignals and train without any ground-truth supervision. We apply the algorithm\nto challenging mathematical reasoning tasks and show that it quickly reaches\nperformance levels rivaling reinforcement-learning methods trained explicitly\non gold-standard answers. Additionally, we analyze inherent limitations of the\nalgorithm, highlighting how the self-generated proxy reward initially\ncorrelated with correctness can incentivize reward hacking, where confidently\nincorrect outputs are favored. Our results illustrate how self-supervised\nimprovement can achieve significant performance gains without external labels,\nwhile also revealing its fundamental challenges.','Sheikh Shafayat, Fahim Tajwar, Ruslan Salakhutdinov, Jeff Schneider, Andrea Zanette','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21444v1','该论文提出了一种在线自训练强化学习算法，利用模型的自一致性推断正确性信号，无需任何地面真实监督进行训练。通过将该算法应用于具有挑战性的数学推理任务，研究表明其性能迅速达到与明确训练在黄金标准答案上的强化学习方法相媲美的水平。此外，研究分析了算法的固有局限性，突出了自动生成的代理奖励最初与正确性相关，可能会激励奖励欺骗，即错误的输出被优先考虑。研究结果表明，自监督改进可以在没有外部标签的情况下实现显著的性能提升，同时揭示了其基本挑战。'),('2505.21451v1','Words Like Knives: Backstory-Personalized Modeling and Detection of Violent Communication','Conversational breakdowns in close relationships are deeply shaped by\npersonal histories and emotional context, yet most NLP research treats conflict\ndetection as a general task, overlooking the relational dynamics that influence\nhow messages are perceived. In this work, we leverage nonviolent communication\n(NVC) theory to evaluate LLMs in detecting conversational breakdowns and\nassessing how relationship backstory influences both human and model perception\nof conflicts. Given the sensitivity and scarcity of real-world datasets\nfeaturing conflict between familiar social partners with rich personal\nbackstories, we contribute the PersonaConflicts Corpus, a dataset of N=5,772\nnaturalistic simulated dialogues spanning diverse conflict scenarios between\nfriends, family members, and romantic partners. Through a controlled human\nstudy, we annotate a subset of dialogues and obtain fine-grained labels of\ncommunication breakdown types on individual turns, and assess the impact of\nbackstory on human and model perception of conflict in conversation. We find\nthat the polarity of relationship backstories significantly shifted human\nperception of communication breakdowns and impressions of the social partners,\nyet models struggle to meaningfully leverage those backstories in the detection\ntask. Additionally, we find that models consistently overestimate how\npositively a message will make a listener feel. Our findings underscore the\ncritical role of personalization to relationship contexts in enabling LLMs to\nserve as effective mediators in human communication for authentic connection.','Jocelyn Shen, Akhila Yerukola, Xuhui Zhou, Cynthia Breazeal, Maarten Sap, Hae Won Park','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21451v1','本文利用非暴力沟通理论评估LLMs在检测对话中的交流中断，并评估关系背景如何影响人类和模型对冲突的感知。作者构建了PersonaConflicts Corpus数据集，包含N=5,772个自然对话，探讨了关系背景对人类和模型对话中冲突感知的影响。研究发现，关系背景的极性显著影响人类对交流中断和社交伙伴的印象，但模型在检测任务中难以有效利用这些背景信息。'),('2505.21452v1','Designing Cyclic Peptides via Harmonic SDE with Atom-Bond Modeling','Cyclic peptides offer inherent advantages in pharmaceuticals. For example,\ncyclic peptides are more resistant to enzymatic hydrolysis compared to linear\npeptides and usually exhibit excellent stability and affinity. Although deep\ngenerative models have achieved great success in linear peptide design, several\nchallenges prevent the development of computational methods for designing\ndiverse types of cyclic peptides. These challenges include the scarcity of 3D\nstructural data on target proteins and associated cyclic peptide ligands, the\ngeometric constraints that cyclization imposes, and the involvement of\nnon-canonical amino acids in cyclization. To address the above challenges, we\nintroduce CpSDE, which consists of two key components: AtomSDE, a generative\nstructure prediction model based on harmonic SDE, and ResRouter, a residue type\npredictor. Utilizing a routed sampling algorithm that alternates between these\ntwo models to iteratively update sequences and structures, CpSDE facilitates\nthe generation of cyclic peptides. By employing explicit all-atom and bond\nmodeling, CpSDE overcomes existing data limitations and is proficient in\ndesigning a wide variety of cyclic peptides. Our experimental results\ndemonstrate that the cyclic peptides designed by our method exhibit reliable\nstability and affinity.','Xiangxin Zhou, Mingyu Li, Yi Xiao, Jiahan Li, Dongyu Xue, Zaixiang Zheng, Jianzhu Ma, Quanquan Gu','2025-05-27','cs.LG','生物医药领域，循环肽设计','http://arxiv.org/pdf/2505.21452v1','该论文介绍了一种名为CpSDE的方法，通过结合AtomSDE和ResRouter两个组件，实现了循环肽的生成设计。该方法克服了循环肽设计中存在的数据限制，并成功设计出具有可靠稳定性和亲和力的循环肽。'),('2505.21457v1','Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO','Active vision, also known as active perception, refers to the process of\nactively selecting where and how to look in order to gather task-relevant\ninformation. It is a critical component of efficient perception and\ndecision-making in humans and advanced embodied agents. Recently, the use of\nMultimodal Large Language Models (MLLMs) as central planning and\ndecision-making modules in robotic systems has gained extensive attention.\nHowever, despite the importance of active perception in embodied intelligence,\nthere is little to no exploration of how MLLMs can be equipped with or learn\nactive perception capabilities. In this paper, we first provide a systematic\ndefinition of MLLM-based active perception tasks. We point out that the\nrecently proposed GPT-o3 model\\\'s zoom-in search strategy can be regarded as a\nspecial case of active perception; however, it still suffers from low search\nefficiency and inaccurate region selection. To address these issues, we propose\nACTIVE-O3, a purely reinforcement learning based training framework built on\ntop of GRPO, designed to equip MLLMs with active perception capabilities. We\nfurther establish a comprehensive benchmark suite to evaluate ACTIVE-O3 across\nboth general open-world tasks, such as small-object and dense object grounding,\nand domain-specific scenarios, including small object detection in remote\nsensing and autonomous driving, as well as fine-grained interactive\nsegmentation. In addition, ACTIVE-O3 also demonstrates strong zero-shot\nreasoning abilities on the V* Benchmark, without relying on any explicit\nreasoning data. We hope that our work can provide a simple codebase and\nevaluation protocol to facilitate future research on active perception in\nMLLMs.','Muzhi Zhu, Hao Zhong, Canyu Zhao, Zongze Du, Zheng Huang, Mingyu Liu, Hao Chen, Cheng Zou, Jingdong Chen, Ming Yang, Chunhua Shen','2025-05-27','cs.CV','强化学习','http://arxiv.org/pdf/2505.21457v1','该论文提出了一个基于强化学习的训练框架 ACTIVE-O3，旨在为 Multimodal Large Language Models (MLLMs) 赋予主动感知能力，并建立了一个全面的基准套件来评估 ACTIVE-O3 在不同任务上的表现。'),('2505.21458v1','Do LLMs Need to Think in One Language? Correlation between Latent Language and Task Performance','Large Language Models (LLMs) are known to process information using a\nproficient internal language consistently, referred to as latent language,\nwhich may differ from the input or output languages. However, how the\ndiscrepancy between the latent language and the input and output language\naffects downstream task performance remains largely unexplored. While many\nstudies research the latent language of LLMs, few address its importance in\ninfluencing task performance. In our study, we hypothesize that thinking in\nlatent language consistently enhances downstream task performance. To validate\nthis, our work varies the input prompt languages across multiple downstream\ntasks and analyzes the correlation between consistency in latent language and\ntask performance. We create datasets consisting of questions from diverse\ndomains such as translation and geo-culture, which are influenced by the choice\nof latent language. Experimental results across multiple LLMs on translation\nand geo-culture tasks, which are sensitive to the choice of language, indicate\nthat maintaining consistency in latent language is not always necessary for\noptimal downstream task performance. This is because these models adapt their\ninternal representations near the final layers to match the target language,\nreducing the impact of consistency on overall performance.','Shintaro Ozaki, Tatsuya Hiraoka, Hiroto Otake, Hiroki Ouchi, Masaru Isonuma, Benjamin Heinzerling, Kentaro Inui, Taro Watanabe, Yusuke Miyao, Yohei Oseki, Yu Takagi','2025-05-27','cs.CL','LLM','http://arxiv.org/pdf/2505.21458v1','该论文研究了大型语言模型（LLMs）中的潜在语言对下游任务性能的影响，通过改变输入提示语言来分析潜在语言的一致性与任务性能之间的相关性。实验结果表明，对于翻译和地理文化任务，保持潜在语言的一致性并不总是对最终任务性能有利。'),('2505.21459v1','LazyVLM: Neuro-Symbolic Approach to Video Analytics','Current video analytics approaches face a fundamental trade-off between\nflexibility and efficiency. End-to-end Vision Language Models (VLMs) often\nstruggle with long-context processing and incur high computational costs, while\nneural-symbolic methods depend heavily on manual labeling and rigid rule\ndesign. In this paper, we introduce LazyVLM, a neuro-symbolic video analytics\nsystem that provides a user-friendly query interface similar to VLMs, while\naddressing their scalability limitation. LazyVLM enables users to effortlessly\ndrop in video data and specify complex multi-frame video queries using a\nsemi-structured text interface for video analytics. To address the scalability\nlimitations of VLMs, LazyVLM decomposes multi-frame video queries into\nfine-grained operations and offloads the bulk of the processing to efficient\nrelational query execution and vector similarity search. We demonstrate that\nLazyVLM provides a robust, efficient, and user-friendly solution for querying\nopen-domain video data at scale.','Xiangru Jian, Wei Pang, Zhengyuan Dong, Chao Zhang, M. Tamer Özsu','2025-05-27','cs.DB','视频分析','http://arxiv.org/pdf/2505.21459v1','该论文介绍了LazyVLM，一个神经符号视频分析系统，提供类似于VLM的用户友好查询界面，同时解决了其可扩展性限制。LazyVLM将多帧视频查询分解为细粒度操作，并将大部分处理工作转移到高效的关系查询执行和向量相似性搜索中，为在规模上查询开放领域视频数据提供了稳健、高效和用户友好的解决方案。'),('2505.21465v1','ID-Align: RoPE-Conscious Position Remapping for Dynamic High-Resolution Adaptation in Vision-Language Models','Currently, a prevalent approach for enhancing Vision-Language Models (VLMs)\nperformance is to encode both the high-resolution version and the thumbnail of\nan image simultaneously. While effective, this method generates a large number\nof image tokens. When combined with the widely used Rotary Position Embedding\n(RoPE), its long-term decay property hinders the interaction between\nhigh-resolution tokens and thumbnail tokens, as well as between text and image.\nTo address these issues, we propose ID-Align, which alleviates these problems\nby reordering position IDs. In this method, high-resolution tokens inherit IDs\nfrom their corresponding thumbnail token while constraining the overexpansion\nof positional indices. Our experiments conducted within the LLaVA-Next\nframework demonstrate that ID-Align achieves significant improvements,\nincluding a 6.09% enhancement on MMBench\\\'s relation reasoning tasks and notable\ngains across multiple benchmarks. Our code is available at the following link:\nhttps://github.com/zooblastlbz/ID-Align.','Bozhou Li, Wentao Zhang','2025-05-27','cs.CV','视觉-语言模型 (VLMs)','http://arxiv.org/pdf/2505.21465v1','该论文提出了一种名为ID-Align的方法，通过重新排序位置ID来改善视觉-语言模型中高分辨率和缩略图之间的交互问题，取得了显著的性能提升。'),('2505.21467v1','Accelerating Diffusion Language Model Inference via Efficient KV Caching and Guided Diffusion','Diffusion language models offer parallel token generation and inherent\nbidirectionality, promising more efficient and powerful sequence modeling\ncompared to autoregressive approaches. However, state-of-the-art diffusion\nmodels (e.g., Dream 7B, LLaDA 8B) suffer from slow inference. While they match\nthe quality of similarly sized Autoregressive (AR) Models (e.g., Qwen2.5 7B,\nLlama3 8B), their iterative denoising requires multiple full-sequence forward\npasses, resulting in high computational costs and latency, particularly for\nlong input prompts and long-context scenarios. Furthermore, parallel token\ngeneration introduces token incoherence problems, and current sampling\nheuristics suffer from significant quality drops with decreasing denoising\nsteps. We address these limitations with two training-free techniques. First,\nwe propose FreeCache, a Key-Value (KV) approximation caching technique that\nreuses stable KV projections across denoising steps, effectively reducing the\ncomputational cost of DLM inference. Second, we introduce Guided Diffusion, a\ntraining-free method that uses a lightweight pretrained autoregressive model to\nsupervise token unmasking, dramatically reducing the total number of denoising\niterations without sacrificing quality. We conduct extensive evaluations on\nopen-source reasoning benchmarks, and our combined methods deliver up to a 34x\nend-to-end speedup without compromising accuracy. For the first time, diffusion\nlanguage models achieve a comparable and even faster latency as the widely\nadopted autoregressive models. Our work successfully paved the way for scaling\nup the diffusion language model to a broader scope of applications across\ndifferent domains.','Zhanqiu Hu, Jian Meng, Yash Akhauri, Mohamed S. Abdelfattah, Jae-sun Seo, Zhiru Zhang, Udit Gupta','2025-05-27','cs.CL','LLM (扩散语言模型)','http://arxiv.org/pdf/2505.21467v1','该论文提出了两种无需训练的技术，分别是FreeCache和Guided Diffusion，用于改进扩散语言模型的推理效率和质量。通过这些方法，他们实现了高达34倍的端到端加速，同时保持准确性。'),('2505.21468v1','Causal Posterior Estimation','We present Causal Posterior Estimation (CPE), a novel method for Bayesian\ninference in simulator models, i.e., models where the evaluation of the\nlikelihood function is intractable or too computationally expensive, but where\none can simulate model outputs given parameter values. CPE utilizes a\nnormalizing flow-based (NF) approximation to the posterior distribution which\ncarefully incorporates the conditional dependence structure induced by the\ngraphical representation of the model into the neural network. Thereby it is\npossible to improve the accuracy of the approximation. We introduce both\ndiscrete and continuous NF architectures for CPE and propose a constant-time\nsampling procedure for the continuous case which reduces the computational\ncomplexity of drawing samples to O(1) as for discrete NFs. We show, through an\nextensive experimental evaluation, that by incorporating the conditional\ndependencies induced by the graphical model directly into the neural network,\nrather than learning them from data, CPE is able to conduct highly accurate\nposterior inference either outperforming or matching the state of the art in\nthe field.','Simon Dirmeier, Antonietta Mira','2025-05-27','cs.LG','概率图模型/贝叶斯推断','http://arxiv.org/pdf/2505.21468v1','该论文介绍了一种名为因果后验估计（CPE）的新方法，用于在模拟器模型中进行贝叶斯推断。通过利用基于正态流的后验分布近似，将模型的图形表示中引入的条件依赖结构巧妙地结合到神经网络中，从而提高了近似的准确性。通过实验证明，CPE能够进行高度准确的后验推断，要么优于要么与该领域的最新技术持平。'),('2505.21471v1','Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration','With the rapid advancement of post-training techniques for reasoning and\ninformation seeking, large language models (LLMs) can incorporate a large\nquantity of retrieved knowledge to solve complex tasks. However, the limited\ncontext window of LLMs obstructs scaling the amount of external knowledge\ninput, prohibiting further improvement, especially for tasks requiring\nsignificant amount of external knowledge. Existing context window extension\nmethods inevitably cause information loss. LLM-based multi-agent methods emerge\nas a new paradigm to handle massive input in a distributional manner, where we\nidentify two core bottlenecks in existing knowledge synchronization and\nreasoning processes. In this work, we develop a multi-agent framework,\n$\\textbf{ExtAgents}$, to overcome the bottlenecks and enable better scalability\nin inference-time knowledge integration without longer-context training.\nBenchmarked with our enhanced multi-hop question answering test,\n$\\textbf{$\\boldsymbol{\\infty}$Bench+}$, and other public test sets including\nlong survey generation, ExtAgents significantly enhances the performance over\nexisting non-training methods with the same amount of external knowledge input,\nregardless of whether it falls $\\textit{within or exceeds the context window}$.\nMoreover, the method maintains high efficiency due to high parallelism. Further\nstudy in the coordination of LLM agents on increasing external knowledge input\ncould benefit real-world applications.','Zijun Liu, Zhennan Wan, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21471v1','该论文介绍了一种基于多智能体的框架 $\\textbf{ExtAgents}$，用于解决大语言模型在推理时整合大量外部知识的问题。通过该框架，可以显著提高多跳问题回答等任务的性能，同时保持高效率和高并行性。'),('2505.21472v1','Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration','Large vision-language models (LVLMs) achieve impressive performance on\nmultimodal tasks but often suffer from hallucination, and confidently describe\nobjects or attributes not present in the image. Current inference-time\ninterventions, while training-free, struggle to maintain accuracy in open-ended\nand long-form generation scenarios. We introduce the Confidence-Aware Attention\nCalibration (CAAC) framework to address this challenge by targeting two key\nbiases: spatial perception bias, which distributes attention disproportionately\nacross image tokens, and modality bias, which shifts focus from visual to\ntextual inputs over time. CAAC employs a two-step approach: Visual-Token\nCalibration (VTC) to balance attention across visual tokens, and Adaptive\nAttention Re-Scaling (AAR) to reinforce visual grounding based on the model\\\'s\nconfidence. This confidence-driven adjustment ensures consistent visual\nalignment during generation. Experiments on CHAIR, AMBER, and POPE benchmarks\ndemonstrate that CAAC outperforms baselines, particularly in long-form\ngenerations, effectively reducing hallucination.','Mehrdad Fazli, Bowen Wei, Ziwei Zhu','2025-05-27','cs.CV','大型视觉-语言模型（LVLMs）','http://arxiv.org/pdf/2505.21472v1','该论文介绍了一种名为 Confidence-Aware Attention Calibration (CAAC) 的框架，用于解决大型视觉-语言模型（LVLMs）在生成过程中出现的虚假描述（hallucination）问题。该框架通过两个关键偏见进行调整，即空间感知偏见和模态偏见，以确保在生成过程中保持一致的视觉对齐。实验证明，CAAC在长篇生成任务中表现优异，有效减少了虚假描述。'),('2505.21475v1','Algorithms and SQ Lower Bounds for Robustly Learning Real-valued Multi-index Models','We study the complexity of learning real-valued Multi-Index Models (MIMs)\nunder the Gaussian distribution. A $K$-MIM is a function $f:\\mathbb{R}^d\\to\n\\mathbb{R}$ that depends only on the projection of its input onto a\n$K$-dimensional subspace. We give a general algorithm for PAC learning a broad\nclass of MIMs with respect to the square loss, even in the presence of\nadversarial label noise. Moreover, we establish a nearly matching Statistical\nQuery (SQ) lower bound, providing evidence that the complexity of our algorithm\nis qualitatively optimal as a function of the dimension. Specifically, we\nconsider the class of bounded variation MIMs with the property that degree at\nmost $m$ distinguishing moments exist with respect to projections onto any\nsubspace. In the presence of adversarial label noise, the complexity of our\nlearning algorithm is $d^{O(m)}2^{\\mathrm{poly}(K/\\epsilon)}$. For the\nrealizable and independent noise settings, our algorithm incurs complexity\n$d^{O(m)}2^{\\mathrm{poly}(K)}(1/\\epsilon)^{O(K)}$. To complement our upper\nbound, we show that if for some subspace degree-$m$ distinguishing moments do\nnot exist, then any SQ learner for the corresponding class of MIMs requires\ncomplexity $d^{\\Omega(m)}$. As an application, we give the first efficient\nlearner for the class of positive-homogeneous $L$-Lipschitz $K$-MIMs. The\nresulting algorithm has complexity $\\mathrm{poly}(d)\n2^{\\mathrm{poly}(KL/\\epsilon)}$. This gives a new PAC learning algorithm for\nLipschitz homogeneous ReLU networks with complexity independent of the network\nsize, removing the exponential dependence incurred in prior work.','Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Lisheng Ren','2025-05-27','cs.LG','机器学习/统计学习','http://arxiv.org/pdf/2505.21475v1','该论文研究了在高斯分布下学习实值多指数模型（MIMs）的复杂性。他们提出了一个通用算法，可以在存在对抗性标签噪声的情况下，基于平方损失PAC学习广泛类别的MIMs。他们还建立了一个几乎匹配的统计查询（SQ）下界，证明了算法的复杂性在维度函数方面是最优的。'),('2505.21478v1','Policy Optimized Text-to-Image Pipeline Design','Text-to-image generation has evolved beyond single monolithic models to\ncomplex multi-component pipelines. These combine fine-tuned generators,\nadapters, upscaling blocks and even editing steps, leading to significant\nimprovements in image quality. However, their effective design requires\nsubstantial expertise. Recent approaches have shown promise in automating this\nprocess through large language models (LLMs), but they suffer from two critical\nlimitations: extensive computational requirements from generating images with\nhundreds of predefined pipelines, and poor generalization beyond memorized\ntraining examples. We introduce a novel reinforcement learning-based framework\nthat addresses these inefficiencies. Our approach first trains an ensemble of\nreward models capable of predicting image quality scores directly from\nprompt-workflow combinations, eliminating the need for costly image generation\nduring training. We then implement a two-phase training strategy: initial\nworkflow vocabulary training followed by GRPO-based optimization that guides\nthe model toward higher-performing regions of the workflow space. Additionally,\nwe incorporate a classifier-free guidance based enhancement technique that\nextrapolates along the path between the initial and GRPO-tuned models, further\nimproving output quality. We validate our approach through a set of\ncomparisons, showing that it can successfully create new flows with greater\ndiversity and lead to superior image quality compared to existing baselines.','Uri Gadot, Rinon Gal, Yftah Ziser, Gal Chechik, Shie Mannor','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21478v1','该论文介绍了一种基于强化学习的框架，用于自动生成文本到图像的工作流程，通过训练奖励模型和优化算法来提高图像质量，相比现有基线方法取得了更好的效果。'),('2505.21479v1','Are Language Models Consequentialist or Deontological Moral Reasoners?','As AI systems increasingly navigate applications in healthcare, law, and\ngovernance, understanding how they handle ethically complex scenarios becomes\ncritical. Previous work has mainly examined the moral judgments in large\nlanguage models (LLMs), rather than their underlying moral reasoning process.\nIn contrast, we focus on a large-scale analysis of the moral reasoning traces\nprovided by LLMs. Furthermore, unlike prior work that attempted to draw\ninferences from only a handful of moral dilemmas, our study leverages over 600\ndistinct trolley problems as probes for revealing the reasoning patterns that\nemerge within different LLMs. We introduce and test a taxonomy of moral\nrationales to systematically classify reasoning traces according to two main\nnormative ethical theories: consequentialism and deontology. Our analysis\nreveals that LLM chains-of-thought tend to favor deontological principles based\non moral obligations, while post-hoc explanations shift notably toward\nconsequentialist rationales that emphasize utility. Our framework provides a\nfoundation for understanding how LLMs process and articulate ethical\nconsiderations, an important step toward safe and interpretable deployment of\nLLMs in high-stakes decision-making environments. Our code is available at\nhttps://github.com/keenansamway/moral-lens .','Keenan Samway, Max Kleiman-Weiner, David Guzman Piedrahita, Rada Mihalcea, Bernhard Schölkopf, Zhijing Jin','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21479v1','该论文通过分析大型语言模型提供的道德推理痕迹，研究了道德推理过程，并使用600多个不同的道德困境作为探针，揭示了不同语言模型内部的推理模式。研究结果表明，语言模型更倾向于基于道义义务的德行主义原则，而事后解释则明显转向强调效用的后果主义原理。'),('2505.21486v1','Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming','Automating robust hypothesis generation in open environments is pivotal for\nAI cognition. We introduce a novel framework integrating a multi-agent system,\npowered by Large Language Models (LLMs), with Inductive Logic Programming\n(ILP). Our system\\\'s LLM agents autonomously define a structured symbolic\nvocabulary (predicates) and relational templates , i.e., \\emph{language bias}\ndirectly from raw textual data. This automated symbolic grounding (the\nconstruction of the language bias), traditionally an expert-driven bottleneck\nfor ILP, then guides the transformation of text into facts for an ILP solver,\nwhich inductively learns interpretable rules. This approach overcomes\ntraditional ILP\\\'s reliance on predefined symbolic structures and the\nnoise-sensitivity of pure LLM methods. Extensive experiments in diverse,\nchallenging scenarios validate superior performance, paving a new path for\nautomated, explainable, and verifiable hypothesis generation.','Yang Yang, Jiemin Wu, Yutao Yue','2025-05-27','cs.AI','LLM、归纳逻辑编程','http://arxiv.org/pdf/2505.21486v1','该论文介绍了一个新颖的框架，将由大型语言模型（LLMs）驱动的多智能体系统与归纳逻辑编程（ILP）结合起来，实现在开放环境中自动生成健壮的假设。LLM智能体自主地从原始文本数据中定义了结构化的符号词汇（谓词）和关系模板，即“语言偏差”。这种自动符号接地（语言偏差的构建）指导了将文本转化为事实的ILP求解器，后者归纳地学习可解释的规则。这种方法克服了传统ILP对预定义符号结构的依赖以及纯LLM方法的噪声敏感性。在多样化、具有挑战性的场景中进行的大量实验验证了其卓越性能，为自动、可解释和可验证的假设生成开辟了新的道路。'),('2505.21487v1','Hardware-Efficient Attention for Fast Decoding','LLM decoding is bottlenecked for large batches and long contexts by loading\nthe key-value (KV) cache from high-bandwidth memory, which inflates per-token\nlatency, while the sequential nature of decoding limits parallelism. We analyze\nthe interplay among arithmetic intensity, parallelization, and model quality\nand question whether current architectures fully exploit modern hardware. This\nwork redesigns attention to perform more computation per byte loaded from\nmemory to maximize hardware efficiency without trading off parallel\nscalability. We first propose Grouped-Tied Attention (GTA), a simple variant\nthat combines and reuses key and value states, reducing memory transfers\nwithout compromising model quality. We then introduce Grouped Latent Attention\n(GLA), a parallel-friendly latent attention paired with low-level optimizations\nfor fast decoding while maintaining high model quality. Experiments show that\nGTA matches Grouped-Query Attention (GQA) quality while using roughly half the\nKV cache and that GLA matches Multi-head Latent Attention (MLA) and is easier\nto shard. Our optimized GLA kernel is up to 2$\\times$ faster than FlashMLA, for\nexample, in a speculative decoding setting when the query length exceeds one.\nFurthermore, by fetching a smaller KV cache per device, GLA reduces end-to-end\nlatency and increases throughput in online serving benchmarks by up to\n2$\\times$.','Ted Zadouri, Hubert Strauss, Tri Dao','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21487v1','该论文通过重新设计注意力机制，提出了Grouped-Tied Attention (GTA) 和Grouped Latent Attention (GLA) 两种变体，以提高LLM解码的效率和性能。实验证明，GLA在一些情况下比现有方法更快且更节省内存。'),('2505.21488v1','Be Decisive: Noise-Induced Layouts for Multi-Subject Generation','Generating multiple distinct subjects remains a challenge for existing\ntext-to-image diffusion models. Complex prompts often lead to subject leakage,\ncausing inaccuracies in quantities, attributes, and visual features. Preventing\nleakage among subjects necessitates knowledge of each subject\\\'s spatial\nlocation. Recent methods provide these spatial locations via an external layout\ncontrol. However, enforcing such a prescribed layout often conflicts with the\ninnate layout dictated by the sampled initial noise, leading to misalignment\nwith the model\\\'s prior. In this work, we introduce a new approach that predicts\na spatial layout aligned with the prompt, derived from the initial noise, and\nrefines it throughout the denoising process. By relying on this noise-induced\nlayout, we avoid conflicts with externally imposed layouts and better preserve\nthe model\\\'s prior. Our method employs a small neural network to predict and\nrefine the evolving noise-induced layout at each denoising step, ensuring clear\nboundaries between subjects while maintaining consistency. Experimental results\nshow that this noise-aligned strategy achieves improved text-image alignment\nand more stable multi-subject generation compared to existing layout-guided\ntechniques, while preserving the rich diversity of the model\\\'s original\ndistribution.','Omer Dahary, Yehonathan Cohen, Or Patashnik, Kfir Aberman, Daniel Cohen-Or','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21488v1','本文介绍了一种新方法，通过预测和优化与提示对齐的空间布局，以改善文本到图像生成模型中多个主题的生成质量。该方法通过在去噪过程中预测和优化噪声诱导的布局，避免与外部布局冲突，更好地保留模型的先验知识。'),('2505.21493v1','Reinforcing General Reasoning without Verifiers','The recent paradigm shift towards training large language models (LLMs) using\nDeepSeek-R1-Zero-style reinforcement learning (RL) on verifiable rewards has\nled to impressive advancements in code and mathematical reasoning. However,\nthis methodology is limited to tasks where rule-based answer verification is\npossible and does not naturally extend to real-world domains such as chemistry,\nhealthcare, engineering, law, biology, business, and economics. Current\npractical workarounds use an additional LLM as a model-based verifier; however,\nthis introduces issues such as reliance on a strong verifier LLM,\nsusceptibility to reward hacking, and the practical burden of maintaining the\nverifier model in memory during training. To address this and extend\nDeepSeek-R1-Zero-style training to general reasoning domains, we propose a\nverifier-free method (VeriFree) that bypasses answer verification and instead\nuses RL to directly maximize the probability of generating the reference\nanswer. We compare VeriFree with verifier-based methods and demonstrate that,\nin addition to its significant practical benefits and reduced compute\nrequirements, VeriFree matches and even surpasses verifier-based methods on\nextensive evaluations across MMLU-Pro, GPQA, SuperGPQA, and math-related\nbenchmarks. Moreover, we provide insights into this method from multiple\nperspectives: as an elegant integration of training both the policy and\nimplicit verifier in a unified model, and as a variational optimization\napproach. Code is available at https://github.com/sail-sg/VeriFree.','Xiangxin Zhou, Zichen Liu, Anya Sims, Haonan Wang, Tianyu Pang, Chongxuan Li, Liang Wang, Min Lin, Chao Du','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21493v1','该论文提出了一种名为VeriFree的方法，通过强化学习直接最大化生成参考答案的概率，绕过了答案验证的过程。通过在MMLU-Pro、GPQA、SuperGPQA和数学相关基准测试上进行广泛评估，证明了VeriFree在实践中具有显著的实际优势和减少计算需求，并且在某些情况下甚至超越了基于验证器的方法。'),('2505.21496v1','UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents','In this paper, we introduce UI-Genie, a self-improving framework addressing\ntwo key challenges in GUI agents: verification of trajectory outcome is\nchallenging and high-quality training data are not scalable. These challenges\nare addressed by a reward model and a self-improving pipeline, respectively.\nThe reward model, UI-Genie-RM, features an image-text interleaved architecture\nthat efficiently pro- cesses historical context and unifies action-level and\ntask-level rewards. To sup- port the training of UI-Genie-RM, we develop\ndeliberately-designed data genera- tion strategies including rule-based\nverification, controlled trajectory corruption, and hard negative mining. To\naddress the second challenge, a self-improvement pipeline progressively expands\nsolvable complex GUI tasks by enhancing both the agent and reward models\nthrough reward-guided exploration and outcome verification in dynamic\nenvironments. For training the model, we generate UI- Genie-RM-517k and\nUI-Genie-Agent-16k, establishing the first reward-specific dataset for GUI\nagents while demonstrating high-quality synthetic trajectory gen- eration\nwithout manual annotation. Experimental results show that UI-Genie achieves\nstate-of-the-art performance across multiple GUI agent benchmarks with three\ngenerations of data-model self-improvement. We open-source our complete\nframework implementation and generated datasets to facilitate further research\nin https://github.com/Euphoria16/UI-Genie.','Han Xiao, Guozhi Wang, Yuxiang Chai, Zimu Lu, Weifeng Lin, Hao He, Lue Fan, Liuyang Bian, Rui Hu, Liang Liu, Shuai Ren, Yafei Wen, Xiaoxin Chen, Aojun Zhou, Hongsheng Li','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21496v1','本文介绍了UI-Genie，一个自我改进的框架，解决了GUI代理中的两个关键挑战：轨迹结果验证困难和高质量训练数据不可扩展的问题。通过奖励模型和自我改进管道分别解决这些挑战。奖励模型UI-Genie-RM采用图像文本交替架构，有效处理历史上下文，并统一动作级和任务级奖励。为了支持UI-Genie-RM的训练，开发了包括基于规则的验证、受控轨迹破坏和硬负样本挖掘在内的故意设计的数据生成策略。自我改进管道通过奖励引导探索和动态环境中的结果验证逐步扩展可解决的复杂GUI任务，通过增强代理和奖励模型来提高性能。'),('2505.21497v1','Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers','Academic poster generation is a crucial yet challenging task in scientific\ncommunication, requiring the compression of long-context interleaved documents\ninto a single, visually coherent page. To address this challenge, we introduce\nthe first benchmark and metric suite for poster generation, which pairs recent\nconference papers with author-designed posters and evaluates outputs on\n(i)Visual Quality-semantic alignment with human posters, (ii)Textual\nCoherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic\nand informational criteria scored by a VLM-as-judge, and notably\n(iv)PaperQuiz-the poster\\\'s ability to convey core paper content as measured by\nVLMs answering generated quizzes. Building on this benchmark, we propose\nPosterAgent, a top-down, visual-in-the-loop multi-agent pipeline: the (a)Parser\ndistills the paper into a structured asset library; the (b)Planner aligns\ntext-visual pairs into a binary-tree layout that preserves reading order and\nspatial balance; and the (c)Painter-Commenter loop refines each panel by\nexecuting rendering code and using VLM feedback to eliminate overflow and\nensure alignment. In our comprehensive evaluation, we find that GPT-4o\noutputs-though visually appealing at first glance-often exhibit noisy text and\npoor PaperQuiz scores, and we find that reader engagement is the primary\naesthetic bottleneck, as human-designed posters rely largely on visual\nsemantics to convey meaning. Our fully open-source variants (e.g. based on the\nQwen-2.5 series) outperform existing 4o-driven multi-agent systems across\nnearly all metrics, while using 87% fewer tokens. It transforms a 22-page paper\ninto a finalized yet editable .pptx poster - all for just $0.005. These\nfindings chart clear directions for the next generation of fully automated\nposter-generation models. The code and datasets are available at\nhttps://github.com/Paper2Poster/Paper2Poster.','Wei Pang, Kevin Qinghong Lin, Xiangru Jian, Xi He, Philip Torr','2025-05-27','cs.CV','生成模型','http://arxiv.org/pdf/2505.21497v1','该论文介绍了学术海报生成的挑战性任务，提出了海报生成的基准和度量套件，并介绍了一种基于视觉的多代理管道PosterAgent，以生成符合人类海报标准的海报。研究发现，现有的生成系统存在文本质量和海报内容传达能力等问题，而基于Qwen-2.5系列的开源变体在几乎所有指标上表现更好。'),('2505.21499v1','AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery','Vision-Language Model (VLM) based Web Agents represent a significant step\ntowards automating complex tasks by simulating human-like interaction with\nwebsites. However, their deployment in uncontrolled web environments introduces\nsignificant security vulnerabilities. Existing research on adversarial\nenvironmental injection attacks often relies on unrealistic assumptions, such\nas direct HTML manipulation, knowledge of user intent, or access to agent model\nparameters, limiting their practical applicability. In this paper, we propose\nAdInject, a novel and real-world black-box attack method that leverages the\ninternet advertising delivery to inject malicious content into the Web Agent\\\'s\nenvironment. AdInject operates under a significantly more realistic threat\nmodel than prior work, assuming a black-box agent, static malicious content\nconstraints, and no specific knowledge of user intent. AdInject includes\nstrategies for designing malicious ad content aimed at misleading agents into\nclicking, and a VLM-based ad content optimization technique that infers\npotential user intents from the target website\\\'s context and integrates these\nintents into the ad content to make it appear more relevant or critical to the\nagent\\\'s task, thus enhancing attack effectiveness. Experimental evaluations\ndemonstrate the effectiveness of AdInject, attack success rates exceeding 60%\nin most scenarios and approaching 100% in certain cases. This strongly\ndemonstrates that prevalent advertising delivery constitutes a potent and\nreal-world vector for environment injection attacks against Web Agents. This\nwork highlights a critical vulnerability in Web Agent security arising from\nreal-world environment manipulation channels, underscoring the urgent need for\ndeveloping robust defense mechanisms against such threats. Our code is\navailable at https://github.com/NicerWang/AdInject.','Haowei Wang, Junjie Wang, Xiaojun Jia, Rupeng Zhang, Mingyang Li, Zhe Liu, Yang Liu, Qing Wang','2025-05-27','cs.CR','图像识别','http://arxiv.org/pdf/2505.21499v1','本文提出了一种名为AdInject的黑盒攻击方法，利用互联网广告投放向Web Agent的环境中注入恶意内容，以实现攻击。通过设计具有误导性的广告内容和基于VLM的广告内容优化技术，攻击成功率在大多数情况下超过60％，在某些情况下接近100％。'),('2505.21500v1','ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models','Vision-language models (VLMs) have demonstrated remarkable capabilities in\nunderstanding and reasoning about visual content, but significant challenges\npersist in tasks requiring cross-viewpoint understanding and spatial reasoning.\nWe identify a critical limitation: current VLMs excel primarily at egocentric\nspatial reasoning (from the camera\\\'s perspective) but fail to generalize to\nallocentric viewpoints when required to adopt another entity\\\'s spatial frame of\nreference. We introduce ViewSpatial-Bench, the first comprehensive benchmark\ndesigned specifically for multi-viewpoint spatial localization recognition\nevaluation across five distinct task types, supported by an automated 3D\nannotation pipeline that generates precise directional labels. Comprehensive\nevaluation of diverse VLMs on ViewSpatial-Bench reveals a significant\nperformance disparity: models demonstrate reasonable performance on\ncamera-perspective tasks but exhibit reduced accuracy when reasoning from a\nhuman viewpoint. By fine-tuning VLMs on our multi-perspective spatial dataset,\nwe achieve an overall performance improvement of 46.24% across tasks,\nhighlighting the efficacy of our approach. Our work establishes a crucial\nbenchmark for spatial intelligence in embodied AI systems and provides\nempirical evidence that modeling 3D spatial relationships enhances VLMs\\\'\ncorresponding spatial comprehension capabilities.','Dingming Li, Hongxing Li, Zixuan Wang, Yuchen Yan, Hang Zhang, Siqi Chen, Guiyang Hou, Shengpei Jiang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Yueting Zhuang','2025-05-27','cs.CV','视觉-语言模型 (VLM)','http://arxiv.org/pdf/2505.21500v1','该论文介绍了视觉-语言模型在理解和推理视觉内容方面的显著能力，但在需要跨视角理解和空间推理的任务中仍存在重大挑战。作者通过引入ViewSpatial-Bench，提出了一个专门设计用于多视角空间定位识别评估的全面基准，揭示了当前VLM在不同视角推理任务上的性能差异，并通过在多视角空间数据集上对VLM进行微调，取得了显著的性能提升。'),('2505.21503v1','Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making','Large language models (LLMs) have demonstrated strong potential in clinical\nquestion answering, with recent multi-agent frameworks further improving\ndiagnostic accuracy via collaborative reasoning. However, we identify a\nrecurring issue of Silent Agreement, where agents prematurely converge on\ndiagnoses without sufficient critical analysis, particularly in complex or\nambiguous cases. We present a new concept called Catfish Agent, a\nrole-specialized LLM designed to inject structured dissent and counter silent\nagreement. Inspired by the ``catfish effect\\\'\\\' in organizational psychology, the\nCatfish Agent is designed to challenge emerging consensus to stimulate deeper\nreasoning. We formulate two mechanisms to encourage effective and context-aware\ninterventions: (i) a complexity-aware intervention that modulates agent\nengagement based on case difficulty, and (ii) a tone-calibrated intervention\narticulated to balance critique and collaboration. Evaluations on nine medical\nQ&A and three medical VQA benchmarks show that our approach consistently\noutperforms both single- and multi-agent LLMs frameworks, including leading\ncommercial models such as GPT-4o and DeepSeek-R1.','Yihan Wang, Qiao Yan, Zhenghao Xing, Lihao Liu, Junjun He, Chi-Wing Fu, Xiaowei Hu, Pheng-Ann Heng','2025-05-27','cs.CL','LLM、医学问答、医学VQA','http://arxiv.org/pdf/2505.21503v1','该论文介绍了一种新的概念叫做“Catfish Agent”，这是一个专门设计用于注入结构化异议和对抗沉默一致的LLM角色。通过两种机制来鼓励有效和上下文感知的干预，该方法在医学问答和医学VQA基准测试中表现优异。'),('2505.21505v1','How does Alignment Enhance LLMs\\\' Multilingual Capabilities? A Language Neurons Perspective','Multilingual Alignment is an effective and representative paradigm to enhance\nLLMs\\\' multilingual capabilities, which transfers the capabilities from the\nhigh-resource languages to the low-resource languages. Meanwhile, some\nresearches on language-specific neurons reveal that there are language-specific\nneurons that are selectively activated in LLMs when processing different\nlanguages. This provides a new perspective to analyze and understand LLMs\\\'\nmechanisms more specifically in multilingual scenarios. In this work, we\npropose a new finer-grained neuron identification algorithm, which detects\nlanguage neurons~(including language-specific neurons and language-related\nneurons) and language-agnostic neurons. Furthermore, based on the\ndistributional characteristics of different types of neurons, we divide the\nLLMs\\\' internal process for multilingual inference into four parts: (1)\nmultilingual understanding, (2) shared semantic space reasoning, (3)\nmultilingual output space transformation, and (4) vocabulary space outputting.\nAdditionally, we systematically analyze the models before and after alignment\nwith a focus on different types of neurons. We also analyze the phenomenon of\n\\\'\\\'Spontaneous Multilingual Alignment\\\'\\\'. Overall, our work conducts a\ncomprehensive investigation based on different types of neurons, providing\nempirical results and valuable insights for better understanding multilingual\nalignment and multilingual capabilities of LLMs.','Shimao Zhang, Zhejian Lai, Xiang Liu, Shuaijie She, Xiao Liu, Yeyun Gong, Shujian Huang, Jiajun Chen','2025-05-27','cs.CL','LLM（多语言模型）','http://arxiv.org/pdf/2505.21505v1','该论文提出了一种新的神经元识别算法，用于检测LLMs中的语言神经元（包括语言特定神经元和与语言相关的神经元）和语言无关神经元。通过对不同类型神经元的分布特征进行分析，将LLMs在多语言推理中的内部过程划分为四个部分。研究发现了“自发多语言对齐”的现象，为更好地理解LLMs的多语言对齐和多语言能力提供了实证结果和有价值的见解。'),('2505.21556v1','Benign-to-Toxic Jailbreaking: Inducing Harmful Responses from Harmless Prompts','Optimization-based jailbreaks typically adopt the Toxic-Continuation setting\nin large vision-language models (LVLMs), following the standard next-token\nprediction objective. In this setting, an adversarial image is optimized to\nmake the model predict the next token of a toxic prompt. However, we find that\nthe Toxic-Continuation paradigm is effective at continuing already-toxic\ninputs, but struggles to induce safety misalignment when explicit toxic signals\nare absent. We propose a new paradigm: Benign-to-Toxic (B2T) jailbreak. Unlike\nprior work, we optimize adversarial images to induce toxic outputs from benign\nconditioning. Since benign conditioning contains no safety violations, the\nimage alone must break the model\\\'s safety mechanisms. Our method outperforms\nprior approaches, transfers in black-box settings, and complements text-based\njailbreaks. These results reveal an underexplored vulnerability in multimodal\nalignment and introduce a fundamentally new direction for jailbreak approaches.','Hee-Seon Kim, Minbeom Kim, Wonjun Lee, Kihyun Kim, Changick Kim','2025-05-26','cs.CV','LLM (Large Vision-Language Models)','http://arxiv.org/pdf/2505.21556v1','该论文提出了一种新的破解大型视觉-语言模型的方法，称为Benign-to-Toxic (B2T) jailbreak，通过优化对抗图像来诱导从良性条件产生有毒输出。该方法在黑盒设置下表现出色，为多模态对齐中的漏洞提供了新的方向。'),('2505.21558v1','A Novel Convolutional Neural Network-Based Framework for Complex Multiclass Brassica Seed Classification','Agricultural research has accelerated in recent years, yet farmers often lack\nthe time and resources for on-farm research due to the demands of crop\nproduction and farm operations. Seed classification offers valuable insights\ninto quality control, production efficiency, and impurity detection. Early\nidentification of seed types is critical to reducing the cost and risk\nassociated with field emergence, which can lead to yield losses or disruptions\nin downstream processes like harvesting. Seed sampling supports growers in\nmonitoring and managing seed quality, improving precision in determining seed\npurity levels, guiding management adjustments, and enhancing yield estimations.\nThis study proposes a novel convolutional neural network (CNN)-based framework\nfor the efficient classification of ten common Brassica seed types. The\napproach addresses the inherent challenge of texture similarity in seed images\nusing a custom-designed CNN architecture. The model\\\'s performance was evaluated\nagainst several pre-trained state-of-the-art architectures, with adjustments to\nlayer configurations for optimized classification. Experimental results using\nour collected Brassica seed dataset demonstrate that the proposed model\nachieved a high accuracy rate of 93 percent.','Elhoucine Elfatimia, Recep Eryigitb, Lahcen Elfatimi','2025-05-26','cs.CV','图像识别','http://arxiv.org/pdf/2505.21558v1','该论文提出了一种基于卷积神经网络（CNN）的框架，用于高效分类十种常见的Brassica种子类型。通过自定义设计的CNN架构，解决了种子图像中纹理相似性的固有挑战。实验结果表明，该模型在Brassica种子数据集上取得了93%的高准确率。'),('2505.21559v1','Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems via an Automated Online Design Framework','In cloud-native systems, Kubernetes clusters with interdependent services\noften face challenges to their operational resilience due to poor workload\nmanagement issues such as resource blocking, bottlenecks, or continuous pod\ncrashes. These vulnerabilities are further amplified in adversarial scenarios,\nsuch as Distributed Denial-of-Service attacks (DDoS). Conventional Horizontal\nPod Autoscaling (HPA) approaches struggle to address such dynamic conditions,\nwhile reinforcement learning-based methods, though more adaptable, typically\noptimize single goals like latency or resource usage, neglecting broader\nfailure scenarios. We propose decomposing the overarching goal of maintaining\noperational resilience into failure-specific sub-goals delegated to\ncollaborative agents, collectively forming an HPA Multi-Agent System (MAS). We\nintroduce an automated, four-phase online framework for HPA MAS design: 1)\nmodeling a digital twin built from cluster traces; 2) training agents in\nsimulation using roles and missions tailored to failure contexts; 3) analyzing\nagent behaviors for explainability; and 4) transferring learned policies to the\nreal cluster. Experimental results demonstrate that the generated HPA MASs\noutperform three state-of-the-art HPA systems in sustaining operational\nresilience under various adversarial conditions in a proposed complex cluster.','Julien Soulé, Jean-Paul Jamont, Michel Occello, Louis-Marie Traonouez, Paul Théron','2025-05-26','cs.MA','强化学习','http://arxiv.org/pdf/2505.21559v1','该论文提出了一种基于多智能体系统的水平Pod自动缩放方法，用于提高云原生系统中Kubernetes集群的操作弹性，特别是在面对资源阻塞、瓶颈、持续Pod崩溃等问题时。通过将维护操作弹性的目标分解为特定于故障的子目标，并将其委托给协作智能体，实现了更好的性能。'),('2505.21561v1','Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment','We introduce a novel deep learning framework for the automated staging of\nspheno-occipital synchondrosis (SOS) fusion, a critical diagnostic marker in\nboth orthodontics and forensic anthropology. Our approach leverages a\ndual-model architecture wherein a teacher model, trained on manually cropped\nimages, transfers its precise spatial understanding to a student model that\noperates on full, uncropped images. This knowledge distillation is facilitated\nby a newly formulated loss function that aligns spatial logits as well as\nincorporates gradient-based attention spatial mapping, ensuring that the\nstudent model internalizes the anatomically relevant features without relying\non external cropping or YOLO-based segmentation. By leveraging expert-curated\ndata and feedback at each step, our framework attains robust diagnostic\naccuracy, culminating in a clinically viable end-to-end pipeline. This\nstreamlined approach obviates the need for additional pre-processing tools and\naccelerates deployment, thereby enhancing both the efficiency and consistency\nof skeletal maturation assessment in diverse clinical settings.','Omid Halimi Milani, Amanda Nikho, Marouane Tliba, Lauren Mills, Ahmet Enis Cetin, Mohammed H Elnagar','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21561v1','该论文介绍了一种新颖的深度学习框架，用于自动分期蝶状枕关节（SOS）融合，这是正畸学和法医人类学中的关键诊断标志。他们的方法利用了双模型架构，其中教师模型在手动裁剪图像上进行训练，将其精确的空间理解转移给学生模型，后者在完整的未裁剪图像上运行。通过利用专家策划的数据和反馈，他们的框架实现了强大的诊断准确性，最终形成一个临床可行的端到端流水线。'),('2505.21562v1','Enhancing Selection of Climate Tech Startups with AI -- A Case Study on Integrating Human and AI Evaluations in the ClimaTech Great Global Innovation Challenge','This case study examines the ClimaTech Great Global Innovation Challenge\\\'s\napproach to selecting climate tech startups by integrating human and AI\nevaluations. The competition aimed to identify top startups and enhance the\naccuracy and efficiency of the selection process through a hybrid model.\nResearch shows data-driven approaches help VC firms reduce bias and improve\ndecision-making. Machine learning models have outperformed human investors in\ndeal screening, helping identify high-potential startups. Incorporating AI\naimed to ensure more equitable and objective evaluations.\n  The methodology included three phases: initial AI review, semi-finals judged\nby humans, and finals using a hybrid weighting. In phase one, 57 applications\nwere scored by an AI tool built with StackAI and OpenAI\\\'s GPT-4o, and the top\n36 advanced. In the semi-finals, human judges, unaware of AI scores, evaluated\nstartups on team quality, market potential, and technological innovation. Each\nscore - human or AI - was weighted equally, resulting in 75 percent human and\n25 percent AI influence. In the finals, with five human judges, weighting\nshifted to 83.3 percent human and 16.7 percent AI. There was a moderate\npositive correlation between AI and human scores - Spearman\\\'s = 0.47 -\nindicating general alignment with key differences. Notably, the final four\nstartups, selected mainly by humans, were among those rated highest by the AI.\nThis highlights the complementary nature of AI and human judgment. The study\nshows that hybrid models can streamline and improve startup assessments. The\nClimaTech approach offers a strong framework for future competitions by\ncombining human expertise with AI capabilities.','Jennifer Turliuk, Alejandro Sevilla, Daniela Gorza, Tod Hynes','2025-05-27','cs.CY','人工智能、创业评估','http://arxiv.org/pdf/2505.21562v1','该论文研究了如何通过整合人类和人工智能评估方法来选择气候科技初创公司，通过混合模型提高初创公司选择过程的准确性和效率。研究表明，数据驱动的方法有助于风险投资公司减少偏见并改善决策，机器学习模型在交易筛选方面表现优于人类投资者。'),('2505.21563v1','Fog Intelligence for Network Anomaly Detection','Anomalies are common in network system monitoring. When manifested as network\nthreats to be mitigated, service outages to be prevented, and security risks to\nbe ameliorated, detecting such anomalous network behaviors becomes of great\nimportance. However, the growing scale and complexity of the mobile\ncommunication networks, as well as the ever-increasing amount and\ndimensionality of the network surveillance data, make it extremely difficult to\nmonitor a mobile network and discover abnormal network behaviors. Recent\nadvances in machine learning allow for obtaining near-optimal solutions to\ncomplicated decision-making problems with many sources of uncertainty that\ncannot be accurately characterized by traditional mathematical models. However,\nmost machine learning algorithms are centralized, which renders them\ninapplicable to a large-scale distributed wireless networks with tens of\nmillions of mobile devices. In this article, we present fog intelligence, a\ndistributed machine learning architecture that enables intelligent wireless\nnetwork management. It preserves the advantage of both edge processing and\ncentralized cloud computing. In addition, the proposed architecture is\nscalable, privacy-preserving, and well suited for intelligent management of a\ndistributed wireless network.','Kai Yang, Hui Ma, Shaoyu Dou','2025-05-27','cs.NI','强化学习','http://arxiv.org/pdf/2505.21563v1','本文介绍了一种名为“雾智能”的分布式机器学习架构，用于智能无线网络管理，以解决移动通信网络监控中的异常行为检测问题。'),('2505.21564v1','Multi-instance Learning as Downstream Task of Self-Supervised Learning-based Pre-trained Model','In deep multi-instance learning, the number of applicable instances depends\non the data set. In histopathology images, deep learning multi-instance\nlearners usually assume there are hundreds to thousands instances in a bag.\nHowever, when the number of instances in a bag increases to 256 in brain\nhematoma CT, learning becomes extremely difficult. In this paper, we address\nthis drawback. To overcome this problem, we propose using a pre-trained model\nwith self-supervised learning for the multi-instance learner as a downstream\ntask. With this method, even when the original target task suffers from the\nspurious correlation problem, we show improvements of 5% to 13% in accuracy and\n40% to 55% in the F1 measure for the hypodensity marker classification of brain\nhematoma CT.','Koki Matsuishi, Tsuyoshi Okita','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21564v1','本文解决了在深度多实例学习中实例数量增加导致学习困难的问题，提出了使用自监督学习的预训练模型作为下游任务的方法，以提高脑血肿CT的低密度标记分类准确率和F1值。'),('2505.21565v1','Towards Human-Like Trajectory Prediction for Autonomous Driving: A Behavior-Centric Approach','Predicting the trajectories of vehicles is crucial for the development of\nautonomous driving (AD) systems, particularly in complex and dynamic traffic\nenvironments. In this study, we introduce HiT (Human-like Trajectory\nPrediction), a novel model designed to enhance trajectory prediction by\nincorporating behavior-aware modules and dynamic centrality measures. Unlike\ntraditional methods that primarily rely on static graph structures, HiT\nleverages a dynamic framework that accounts for both direct and indirect\ninteractions among traffic participants. This allows the model to capture the\nsubtle yet significant influences of surrounding vehicles, enabling more\naccurate and human-like predictions. To evaluate HiT\\\'s performance, we\nconducted extensive experiments using diverse and challenging real-world\ndatasets, including NGSIM, HighD, RounD, ApolloScape, and MoCAD++. The results\ndemonstrate that HiT consistently outperforms other top models across multiple\nmetrics, particularly excelling in scenarios involving aggressive driving\nbehaviors. This research presents a significant step forward in trajectory\nprediction, offering a more reliable and interpretable approach for enhancing\nthe safety and efficiency of fully autonomous driving systems.','Haicheng Liao, Zhenning Li, Guohui Zhang, Keqiang Li, Chengzhong Xu','2025-05-27','cs.RO','自动驾驶','http://arxiv.org/pdf/2505.21565v1','本研究介绍了一种名为HiT（Human-like Trajectory Prediction）的新型模型，通过结合行为感知模块和动态中心性度量来增强轨迹预测。与传统方法不同，HiT利用动态框架考虑了交通参与者之间的直接和间接交互，从而捕捉周围车辆的微妙但重要影响，实现更准确和类似人类的预测。通过使用多样化和具有挑战性的真实世界数据集进行广泛实验评估HiT的性能，结果表明HiT在多个指标上始终优于其他顶尖模型，特别在涉及激进驾驶行为的情景中表现出色。这项研究在轨迹预测方面取得了重要进展，为增强全自动驾驶系统的安全性和效率提供了更可靠和可解释的方法。'),('2505.21566v1','Diffusion Model-based Activity Completion for AI Motion Capture from Videos','AI-based motion capture is an emerging technology that offers a\ncost-effective alternative to traditional motion capture systems. However,\ncurrent AI motion capture methods rely entirely on observed video sequences,\nsimilar to conventional motion capture. This means that all human actions must\nbe predefined, and movements outside the observed sequences are not possible.\nTo address this limitation, we aim to apply AI motion capture to virtual\nhumans, where flexible actions beyond the observed sequences are required. We\nassume that while many action fragments exist in the training data, the\ntransitions between them may be missing. To bridge these gaps, we propose a\ndiffusion-model-based action completion technique that generates complementary\nhuman motion sequences, ensuring smooth and continuous movements. By\nintroducing a gate module and a position-time embedding module, our approach\nachieves competitive results on the Human3.6M dataset. Our experimental results\nshow that (1) MDC-Net outperforms existing methods in ADE, FDE, and MMADE but\nis slightly less accurate in MMFDE, (2) MDC-Net has a smaller model size\n(16.84M) compared to HumanMAC (28.40M), and (3) MDC-Net generates more natural\nand coherent motion sequences. Additionally, we propose a method for extracting\nsensor data, including acceleration and angular velocity, from human motion\nsequences.','Gao Huayu, Huang Tengjiu, Ye Xiaolong, Tsuyoshi Okita','2025-05-27','cs.CV','动作捕捉、人体运动生成','http://arxiv.org/pdf/2505.21566v1','该论文提出了一种基于扩散模型的动作完成技术，用于生成灵活的、超出观察序列范围的人体运动序列，以确保平滑连续的动作。实验结果表明，该方法在Human3.6M数据集上取得了竞争性的结果，并且生成更自然、连贯的动作序列。'),('2505.21567v1','EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models','With the development of Embodied Artificial intelligence, the end-to-end\ncontrol policy such as Vision-Language-Action (VLA) model has become the\nmainstream. Existing VLA models faces expensive computing/storage cost, which\nneed to be optimized. Quantization is considered as the most effective method\nwhich can not only reduce the memory cost but also achieve computation\nacceleration. However, we find the token alignment of VLA models hinders the\napplication of existing quantization methods. To address this, we proposed an\noptimized framework called EaqVLA, which apply encoding-aligned quantization to\nVLA models. Specifically, we propose an complete analysis method to find the\nmisalignment in various granularity. Based on the analysis results, we propose\na mixed precision quantization with the awareness of encoding alignment.\nExperiments shows that the porposed EaqVLA achieves better quantization\nperformance (with the minimal quantization loss for end-to-end action control\nand xxx times acceleration) than existing quantization methods.','Feng Jiang, Zihao Zheng, Xiuping Cui, Maoliang Li, JIayu Chen, Xiang Chen','2025-05-27','cs.CV','视觉-语言-行动模型 (Vision-Language-Action model)','http://arxiv.org/pdf/2505.21567v1','该论文提出了一种优化框架 EaqVLA，应用编码对齐量化到 VLA 模型中，以解决现有量化方法在 VLA 模型中的应用问题。通过分析方法找到不同粒度的错位，并提出了具有编码对齐意识的混合精度量化方法。实验证明，EaqVLA 相较于现有量化方法，在端到端动作控制的最小量化损失和加速方面表现更好。'),('2505.21568v1','VoiceMark: Zero-Shot Voice Cloning-Resistant Watermarking Approach Leveraging Speaker-Specific Latents','Voice cloning (VC)-resistant watermarking is an emerging technique for\ntracing and preventing unauthorized cloning. Existing methods effectively trace\ntraditional VC models by training them on watermarked audio but fail in\nzero-shot VC scenarios, where models synthesize audio from an audio prompt\nwithout training. To address this, we propose VoiceMark, the first zero-shot\nVC-resistant watermarking method that leverages speaker-specific latents as the\nwatermark carrier, allowing the watermark to transfer through the zero-shot VC\nprocess into the synthesized audio. Additionally, we introduce VC-simulated\naugmentations and VAD-based loss to enhance robustness against distortions.\nExperiments on multiple zero-shot VC models demonstrate that VoiceMark achieves\nover 95% accuracy in watermark detection after zero-shot VC synthesis,\nsignificantly outperforming existing methods, which only reach around 50%. See\nour code and demos at: https://huggingface.co/spaces/haiyunli/VoiceMark','Haiyun Li, Zhiyong Wu, Xiaofeng Xie, Jingran Xie, Yaoxun Xu, Hanyang Peng','2025-05-27','cs.SD','语音处理','http://arxiv.org/pdf/2505.21568v1','该论文提出了VoiceMark，这是一种零样本语音克隆抵抗水印技术，利用说话者特定的潜在特征作为水印载体，在零样本语音克隆过程中实现水印传递，通过引入VC模拟增强和VAD损失来增强对失真的鲁棒性。实验表明，VoiceMark在多个零样本语音克隆模型上实现了超过95%的水印检测准确率。'),('2505.21569v1','ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools','Large Language Model (LLM)-based agents have demonstrated the ability to\nimprove performance in chemistry-related tasks by selecting appropriate tools.\nHowever, their effectiveness remains limited by the inherent prediction errors\nof chemistry tools. In this paper, we take a step further by exploring how\nLLMbased agents can, in turn, be leveraged to reduce prediction errors of the\ntools. To this end, we propose ChemHAS (Chemical Hierarchical Agent Stacking),\na simple yet effective method that enhances chemistry tools through optimizing\nagent-stacking structures from limited data. ChemHAS achieves state-of-the-art\nperformance across four fundamental chemistry tasks, demonstrating that our\nmethod can effectively compensate for prediction errors of the tools.\nFurthermore, we identify and characterize four distinct agent-stacking\nbehaviors, potentially improving interpretability and revealing new\npossibilities for AI agent applications in scientific research. Our code and\ndataset are publicly available at https:\n//anonymous.4open.science/r/ChemHAS-01E4/README.md.','Zhucong Li, Bowei Zhang, Jin Xiao, Zhijian Zhou, Fenglei Cao, Jiaqing Liang, Yuan Qi','2025-05-27','cs.LG','化学领域AI应用','http://arxiv.org/pdf/2505.21569v1','本文研究了基于大型语言模型的代理如何通过选择适当的工具来改善化学相关任务的性能，并提出了一种名为ChemHAS的方法，通过优化代理堆叠结构来减少化学工具的预测误差，从而在四个基础化学任务上取得了最先进的性能。'),('2505.21570v1','Beyond Explainability: The Case for AI Validation','Artificial Knowledge (AK) systems are transforming decision-making across\ncritical domains such as healthcare, finance, and criminal justice. However,\ntheir growing opacity presents governance challenges that current regulatory\napproaches, focused predominantly on explainability, fail to address\nadequately. This article argues for a shift toward validation as a central\nregulatory pillar. Validation, ensuring the reliability, consistency, and\nrobustness of AI outputs, offers a more practical, scalable, and risk-sensitive\nalternative to explainability, particularly in high-stakes contexts where\ninterpretability may be technically or economically unfeasible. We introduce a\ntypology based on two axes, validity and explainability, classifying AK systems\ninto four categories and exposing the trade-offs between interpretability and\noutput reliability. Drawing on comparative analysis of regulatory approaches in\nthe EU, US, UK, and China, we show how validation can enhance societal trust,\nfairness, and safety even where explainability is limited. We propose a\nforward-looking policy framework centered on pre- and post-deployment\nvalidation, third-party auditing, harmonized standards, and liability\nincentives. This framework balances innovation with accountability and provides\na governance roadmap for responsibly integrating opaque, high-performing AK\nsystems into society.','Dalit Ken-Dror Feldman, Daniel Benoliel','2025-05-27','cs.CY','人工智能监管Governance of AI','http://arxiv.org/pdf/2505.21570v1','本文提出了人工智能系统在决策制定中的不透明性给监管带来的挑战，主张将验证作为中心监管支柱，以确保人工智能输出的可靠性、一致性和鲁棒性，提出了基于有效性和可解释性的分类体系，并探讨了验证如何增强社会信任、公平性和安全性。'),('2505.21571v1','FCOS: A Two-Stage Recoverable Model Pruning Framework for Automatic Modulation Recognition','With the rapid development of wireless communications and the growing\ncomplexity of digital modulation schemes, traditional manual modulation\nrecognition methods struggle to extract reliable signal features and meet\nreal-time requirements in modern scenarios. Recently, deep learning based\nAutomatic Modulation Recognition (AMR) approaches have greatly improved\nclassification accuracy. However, their large model sizes and high\ncomputational demands hinder deployment on resource-constrained devices. Model\npruning provides a general approach to reduce model complexity, but existing\nweight, channel, and layer pruning techniques each present a trade-off between\ncompression rate, hardware acceleration, and accuracy preservation. To this\nend, in this paper, we introduce FCOS, a novel Fine-to-COarse two-Stage pruning\nframework that combines channel-level pruning with layer-level collapse\ndiagnosis to achieve extreme compression, high performance and efficient\ninference. In the first stage of FCOS, hierarchical clustering and parameter\nfusion are applied to channel weights to achieve channel-level pruning. Then a\nLayer Collapse Diagnosis (LaCD) module uses linear probing to identify layer\ncollapse and removes the collapsed layers due to high channel compression\nratio. Experiments on multiple AMR benchmarks demonstrate that FCOS outperforms\nexisting channel and layer pruning methods. Specifically, FCOS achieves 95.51%\nFLOPs reduction and 95.31% parameter reduction while still maintaining\nperformance close to the original ResNet56, with only a 0.46% drop in accuracy\non Sig2019-12. Code is available at https://github.com/yaolu-zjut/FCOS.','Yao Lu, Tengfei Ma, Zeyu Wang, Zhuangzhi Chen, Dongwei Xu, Yun Lin, Qi Xuan, Guan Gui','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21571v1','本文介绍了一种新颖的Fine-to-Coarse两阶段剪枝框架FCOS，结合了通道级剪枝和层级崩溃诊断，实现了极端压缩、高性能和高效推断。实验证明，FCOS优于现有的通道和层剪枝方法，能够在保持接近原始ResNet56性能的情况下，实现95.51%的FLOPs减少和95.31%的参数减少。'),('2505.21572v1','Thickness-aware E(3)-Equivariant 3D Mesh Neural Networks','Mesh-based 3D static analysis methods have recently emerged as efficient\nalternatives to traditional computational numerical solvers, significantly\nreducing computational costs and runtime for various physics-based analyses.\nHowever, these methods primarily focus on surface topology and geometry, often\noverlooking the inherent thickness of real-world 3D objects, which exhibits\nhigh correlations and similar behavior between opposing surfaces. This\nlimitation arises from the disconnected nature of these surfaces and the\nabsence of internal edge connections within the mesh. In this work, we propose\na novel framework, the Thickness-aware E(3)-Equivariant 3D Mesh Neural Network\n(T-EMNN), that effectively integrates the thickness of 3D objects while\nmaintaining the computational efficiency of surface meshes. Additionally, we\nintroduce data-driven coordinates that encode spatial information while\npreserving E(3)-equivariance or invariance properties, ensuring consistent and\nrobust analysis. Evaluations on a real-world industrial dataset demonstrate the\nsuperior performance of T-EMNN in accurately predicting node-level 3D\ndeformations, effectively capturing thickness effects while maintaining\ncomputational efficiency.','Sungwon Kim, Namkyeong Lee, Yunyoung Doh, Seungmin Shin, Guimok Cho, Seung-Won Jeon, Sangkook Kim, Chanyoung Park','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21572v1','该论文提出了一种新颖的框架 T-EMNN，可以有效地整合 3D 物体的厚度，同时保持表面网格的计算效率。通过在真实工业数据集上的评估，证明了 T-EMNN 在准确预测节点级 3D 变形方面的优越性能，有效捕捉了厚度效应并保持了计算效率。'),('2505.21573v1','Spectral-inspired Neural Operator for Data-efficient PDE Simulation in Physics-agnostic Regimes','Partial differential equations (PDEs) govern the spatiotemporal evolution of\nvarious physical systems. Classical numerical solvers, while accurate, require\nfine discretization and full knowledge of the governing PDEs, limiting their\napplicability when the physics is unknown or fast inference is required.\nData-driven neural PDE solvers alleviate these constraints by learning from\ndata but demand large training datasets and perform poorly in data-scarce\nregimes. Physics-aware methods mitigate data requirements by incorporating\nphysical knowledge yet rely on known PDE terms or local numerical schemes,\nrestricting their ability to handle unknown or globally coupled systems. In\nthis work, we propose the Spectral-inspired Neural Operator (SINO), a novel\nframework that learns PDE operators from limited trajectories (as few as 2-5),\nwithout any known PDE terms. SINO operates in the frequency domain and\nintroduces a Frequency-to-Vector module to learn spectral representations\nanalogous to derivative multipliers. To model nonlinear physical interactions,\nwe design a nonlinear operator block that includes a $\\Pi$-Block with low-pass\nfiltering to prevent aliasing. Finally, we introduce an operator distillation\ntechnique to distill the trained model for efficient inference. SINO achieves\nstate-of-the-art results across multiple PDE benchmarks, demonstrating strong\ndiscretization invariance and robust generalization to out-of-distribution\ninitial conditions. To our knowledge, SINO is the first physics-aware method\ncapable of accurately simulating globally coupled systems (e.g., the\nNavier-Stokes equations) from limited data without any explicit PDE terms.','Han Wan, Rui Zhang, Hao Sun','2025-05-27','cs.LG','物理学感知方法','http://arxiv.org/pdf/2505.21573v1','本文提出了一种名为SINO的新颖框架，可以从有限的轨迹数据中学习PDE算子，无需任何已知的PDE项。SINO在频域操作，并引入了一个Frequency-to-Vector模块来学习类似导数乘法器的谱表示。通过设计非线性算子块和运算蒸馏技术，SINO在多个PDE基准测试中取得了最先进的结果。'),('2505.21574v1','Do We Need All the Synthetic Data? Towards Targeted Synthetic Image Augmentation via Diffusion Models','Synthetically augmenting training datasets with diffusion models has been an\neffective strategy for improving generalization of image classifiers. However,\nexisting techniques struggle to ensure the diversity of generation and increase\nthe size of the data by up to 10-30x to improve the in-distribution\nperformance. In this work, we show that synthetically augmenting part of the\ndata that is not learned early in training outperforms augmenting the entire\ndataset. By analyzing a two-layer CNN, we prove that this strategy improves\ngeneralization by promoting homogeneity in feature learning speed without\namplifying noise. Our extensive experiments show that by augmenting only\n30%-40% of the data, our method boosts the performance by up to 2.8% in a\nvariety of scenarios, including training ResNet, ViT and DenseNet on CIFAR-10,\nCIFAR-100, and TinyImageNet, with a range of optimizers including SGD and SAM.\nNotably, our method applied with SGD outperforms the SOTA optimizer, SAM, on\nCIFAR-100 and TinyImageNet. It can also easily stack with existing weak and\nstrong augmentation strategies to further boost the performance.','Dang Nguyen, Jiping Li, Jinghao Zheng, Baharan Mirzasoleiman','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21574v1','本文研究了使用扩散模型对训练数据集进行合成增强，以提高图像分类器的泛化能力。通过分析两层CNN，证明了只对部分数据进行增强优于对整个数据集进行增强，可以提高特征学习速度的同质性而不增加噪音。实验表明，该方法在多种场景下均可提高性能。'),('2505.21575v1','StreamLink: Large-Language-Model Driven Distributed Data Engineering System','Large Language Models (LLMs) have shown remarkable proficiency in natural\nlanguage understanding (NLU), opening doors for innovative applications. We\nintroduce StreamLink - an LLM-driven distributed data system designed to\nimprove the efficiency and accessibility of data engineering tasks. We build\nStreamLink on top of distributed frameworks such as Apache Spark and Hadoop to\nhandle large data at scale. One of the important design philosophies of\nStreamLink is to respect user data privacy by utilizing local fine-tuned LLMs\ninstead of a public AI service like ChatGPT. With help from domain-adapted\nLLMs, we can improve our system\\\'s understanding of natural language queries\nfrom users in various scenarios and simplify the procedure of generating\ndatabase queries like the Structured Query Language (SQL) for information\nprocessing. We also incorporate LLM-based syntax and security checkers to\nguarantee the reliability and safety of each generated query. StreamLink\nillustrates the potential of merging generative LLMs with distributed data\nprocessing for comprehensive and user-centric data engineering. With this\narchitecture, we allow users to interact with complex database systems at\ndifferent scales in a user-friendly and security-ensured manner, where the SQL\ngeneration reaches over 10\\% of execution accuracy compared to baseline\nmethods, and allow users to find the most concerned item from hundreds of\nmillions of items within a few seconds using natural language.','Dawei Feng, Di Mei, Huiri Tan, Lei Ren, Xianying Lou, Zhangxi Tan','2025-05-27','cs.DB','LLM、自然语言处理、数据工程','http://arxiv.org/pdf/2505.21575v1','该论文介绍了一种基于大型语言模型的分布式数据系统StreamLink，旨在改善数据工程任务的效率和可访问性。通过利用本地微调的LLMs，可以提高系统对用户自然语言查询的理解，并简化生成数据库查询的过程。StreamLink展示了将生成型LLMs与分布式数据处理相结合，为全面和用户中心的数据工程提供潜力。'),('2505.21576v1','Concentration Distribution Learning from Label Distributions','Label distribution learning (LDL) is an effective method to predict the\nrelative label description degree (a.k.a. label distribution) of a sample.\nHowever, the label distribution is not a complete representation of an instance\nbecause it overlooks the absolute intensity of each label. Specifically, it\\\'s\nimpossible to obtain the total description degree of hidden labels that not in\nthe label space, which leads to the loss of information and confusion in\ninstances. To solve the above problem, we come up with a new concept named\nbackground concentration to serve as the absolute description degree term of\nthe label distribution and introduce it into the LDL process, forming the\nimproved paradigm of concentration distribution learning. Moreover, we propose\na novel model by probabilistic methods and neural networks to learn label\ndistributions and background concentrations from existing LDL datasets.\nExtensive experiments prove that the proposed approach is able to extract\nbackground concentrations from label distributions while producing more\naccurate prediction results than the state-of-the-art LDL methods. The code is\navailable in https://github.com/seutjw/CDL-LD.','Jiawei Tang, Yuheng Jia','2025-05-27','cs.LG','标签分布学习 (Label Distribution Learning)','http://arxiv.org/pdf/2505.21576v1','该论文提出了一种改进的集中度分布学习方法，通过引入背景浓度概念来补充标签分布学习中的绝对强度信息，从而提高了预测准确性。'),('2505.21577v1','RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving','The ultimate goal of code agents is to solve complex tasks autonomously.\nAlthough large language models (LLMs) have made substantial progress in code\ngeneration, real-world tasks typically demand full-fledged code repositories\nrather than simple scripts. Building such repositories from scratch remains a\nmajor challenge. Fortunately, GitHub hosts a vast, evolving collection of\nopen-source repositories, which developers frequently reuse as modular\ncomponents for complex tasks. Yet, existing frameworks like OpenHands and\nSWE-Agent still struggle to effectively leverage these valuable resources.\nRelying solely on README files provides insufficient guidance, and deeper\nexploration reveals two core obstacles: overwhelming information and tangled\ndependencies of repositories, both constrained by the limited context windows\nof current LLMs. To tackle these issues, we propose RepoMaster, an autonomous\nagent framework designed to explore and reuse GitHub repositories for solving\ncomplex tasks. For efficient understanding, RepoMaster constructs function-call\ngraphs, module-dependency graphs, and hierarchical code trees to identify\nessential components, providing only identified core elements to the LLMs\nrather than the entire repository. During autonomous execution, it\nprogressively explores related components using our exploration tools and\nprunes information to optimize context usage. Evaluated on the adjusted\nMLE-bench, RepoMaster achieves a 110% relative boost in valid submissions over\nthe strongest baseline OpenHands. On our newly released GitTaskBench,\nRepoMaster lifts the task-pass rate from 24.1% to 62.9% while reducing token\nusage by 95%. Our code and demonstration materials are publicly available at\nhttps://github.com/wanghuacan/RepoMaster.','Huacan Wang, Ziyi Ni, Shuo Zhang, Shuo Lu, Sen Hu, Ziyang He, Chen Hu, Jiaye Lin, Yifu Guo, Yuntao Du, Pin Lyu','2025-05-27','cs.SE','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21577v1','该论文提出了 RepoMaster，一个自主代理框架，旨在探索和重用 GitHub 仓库以解决复杂任务。通过构建函数调用图、模块依赖图和层次化代码树来识别关键组件，并在自主执行过程中逐步探索相关组件并优化上下文使用，RepoMaster 在任务解决效率和提交成功率上取得了显著提升。'),('2505.21578v1','Loquacious Set: 25,000 Hours of Transcribed and Diverse English Speech Recognition Data for Research and Commercial Use','Automatic speech recognition (ASR) research is driven by the availability of\ncommon datasets between industrial researchers and academics, encouraging\ncomparisons and evaluations. LibriSpeech, despite its long success as an ASR\nbenchmark, is now limited by its size and focus on clean, read speech, leading\nto near-zero word error rates. More recent datasets, including MOSEL, YODAS,\nGigaspeech, OWSM, Libriheavy or People\\\'s Speech suffer from major limitations\nincluding licenses that researchers in the industry cannot use, unreliable\ntranscriptions, incorrect audio data, or the lack of evaluation sets. This work\npresents the Loquacious Set, a 25,000-hour curated collection of commercially\nusable English speech. Featuring hundreds of thousands of speakers with diverse\naccents and a wide range of speech types (read, spontaneous, talks, clean,\nnoisy), the Loquacious Set is designed to work for academics and researchers in\nthe industry to build ASR systems in real-world scenarios.','Titouan Parcollet, Yuan Tseng, Shucong Zhang, Rogier van Dalen','2025-05-27','cs.CL','语音处理','http://arxiv.org/pdf/2505.21578v1','该论文介绍了Loquacious Set，这是一个包含25,000小时商业可用英语语音的数据集，旨在帮助学术界和工业界研究人员构建适用于真实场景的语音识别系统。'),('2505.21582v1','AITEE -- Agentic Tutor for Electrical Engineering','Intelligent tutoring systems combined with large language models offer a\npromising approach to address students\\\' diverse needs and promote\nself-efficacious learning. While large language models possess good\nfoundational knowledge of electrical engineering basics, they remain\ninsufficiently capable of addressing specific questions about electrical\ncircuits. In this paper, we present AITEE, an agent-based tutoring system for\nelectrical engineering designed to accompany students throughout their learning\nprocess, offer individualized support, and promote self-directed learning.\nAITEE supports both hand-drawn and digital circuits through an adapted circuit\nreconstruction process, enabling natural interaction with students. Our novel\ngraph-based similarity measure identifies relevant context from lecture\nmaterials through a retrieval augmented generation approach, while parallel\nSpice simulation further enhances accuracy in applying solution methodologies.\nThe system implements a Socratic dialogue to foster learner autonomy through\nguided questioning. Experimental evaluations demonstrate that AITEE\nsignificantly outperforms baseline approaches in domain-specific knowledge\napplication, with even medium-sized LLM models showing acceptable performance.\nOur results highlight the potential of agentic tutors to deliver scalable,\npersonalized, and effective learning environments for electrical engineering\neducation.','Christopher Knievel, Alexander Bernhardt, Christian Bernhardt','2025-05-27','cs.CY','LLM、教育技术','http://arxiv.org/pdf/2505.21582v1','本文介绍了一种基于智能教学系统和大型语言模型相结合的电气工程辅导系统，名为AITEE。该系统通过图形相似度测量和Spice模拟等方法，能够有效地支持学生学习电路知识，并在领域特定知识应用方面表现优异。'),('2505.21587v1','CellCLAT: Preserving Topology and Trimming Redundancy in Self-Supervised Cellular Contrastive Learning','Self-supervised topological deep learning (TDL) represents a nascent but\nunderexplored area with significant potential for modeling higher-order\ninteractions in simplicial complexes and cellular complexes to derive\nrepresentations of unlabeled graphs. Compared to simplicial complexes, cellular\ncomplexes exhibit greater expressive power. However, the advancement in\nself-supervised learning for cellular TDL is largely hindered by two core\nchallenges: \\textit{extrinsic structural constraints} inherent to cellular\ncomplexes, and intrinsic semantic redundancy in cellular representations. The\nfirst challenge highlights that traditional graph augmentation techniques may\ncompromise the integrity of higher-order cellular interactions, while the\nsecond underscores that topological redundancy in cellular complexes\npotentially diminish task-relevant information. To address these issues, we\nintroduce Cellular Complex Contrastive Learning with Adaptive Trimming\n(CellCLAT), a twofold framework designed to adhere to the combinatorial\nconstraints of cellular complexes while mitigating informational redundancy.\nSpecifically, we propose a parameter perturbation-based augmentation method\nthat injects controlled noise into cellular interactions without altering the\nunderlying cellular structures, thereby preserving cellular topology during\ncontrastive learning. Additionally, a cellular trimming scheduler is employed\nto mask gradient contributions from task-irrelevant cells through a bi-level\nmeta-learning approach, effectively removing redundant topological elements\nwhile maintaining critical higher-order semantics. We provide theoretical\njustification and empirical validation to demonstrate that CellCLAT achieves\nsubstantial improvements over existing self-supervised graph learning methods,\nmarking a significant attempt in this domain.','Bin Qin, Qirui Ji, Jiangmeng Li, Yupeng Wang, Xuesong Wu, Jianwen Cao, Fanjiang Xu','2025-05-27','cs.LG','图形识别','http://arxiv.org/pdf/2505.21587v1','该论文介绍了自监督拓扑深度学习（TDL）在建模未标记图形的高阶相互作用方面的潜力，提出了Cellular Complex Contrastive Learning with Adaptive Trimming（CellCLAT）框架，旨在解决细胞复合物中的结构约束和语义冗余挑战。'),('2505.21588v1','Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems','Recent advancements in Large Language Models (LLMs) have enabled the\nemergence of multi-agent systems where LLMs interact, collaborate, and make\ndecisions in shared environments. While individual model behavior has been\nextensively studied, the dynamics of peer influence in such systems remain\nunderexplored. In this paper, we investigate herd behavior, the tendency of\nagents to align their outputs with those of their peers, within LLM-based\nmulti-agent interactions. We present a series of controlled experiments that\nreveal how herd behaviors are shaped by multiple factors. First, we show that\nthe gap between self-confidence and perceived confidence in peers significantly\nimpacts an agent\\\'s likelihood to conform. Second, we find that the format in\nwhich peer information is presented plays a critical role in modulating the\nstrength of herd behavior. Finally, we demonstrate that the degree of herd\nbehavior can be systematically controlled, and that appropriately calibrated\nherd tendencies can enhance collaborative outcomes. These findings offer new\ninsights into the social dynamics of LLM-based systems and open pathways for\ndesigning more effective and adaptive multi-agent collaboration frameworks.','Young-Min Cho, Sharath Chandra Guntuku, Lyle Ungar','2025-05-27','cs.MA','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21588v1','本文研究了基于大型语言模型（LLMs）的多智能体系统中的群体行为，探讨了同行影响对智能体输出的影响。通过一系列实验，发现自信度与同行认知之间的差距、同行信息呈现格式等因素显著影响群体行为，同时展示了群体行为可以被系统地控制，并且适当校准的群体倾向可以增强协作结果。'),('2505.21591v1','Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning','Model quantization reduces the bit-width of weights and activations,\nimproving memory efficiency and inference speed in diffusion models. However,\nachieving 4-bit quantization remains challenging. Existing methods, primarily\nbased on integer quantization and post-training quantization fine-tuning,\nstruggle with inconsistent performance. Inspired by the success of\nfloating-point (FP) quantization in large language models, we explore low-bit\nFP quantization for diffusion models and identify key challenges: the failure\nof signed FP quantization to handle asymmetric activation distributions, the\ninsufficient consideration of temporal complexity in the denoising process\nduring fine-tuning, and the misalignment between fine-tuning loss and\nquantization error. To address these challenges, we propose the mixup-sign\nfloating-point quantization (MSFP) framework, first introducing unsigned FP\nquantization in model quantization, along with timestep-aware LoRA (TALoRA) and\ndenoising-factor loss alignment (DFA), which ensure precise and stable\nfine-tuning. Extensive experiments show that we are the first to achieve\nsuperior performance in 4-bit FP quantization for diffusion models,\noutperforming existing PTQ fine-tuning methods in 4-bit INT quantization.','Maosen Zhao, Pengtao Chen, Chong Yu, Yan Wen, Xudong Tan, Tao Chen','2025-05-27','cs.LG','LLM (大语言模型)','http://arxiv.org/pdf/2505.21591v1','该论文探讨了在扩散模型中使用低比特浮点数量化的挑战，并提出了mixup-sign浮点数量化（MSFP）框架，以及timestep-aware LoRA（TALoRA）和denoising-factor loss alignment（DFA）方法，通过确保精确和稳定的微调来解决这些挑战。实验证明，他们是首批在扩散模型中实现4比特浮点数量化的，优于现有的4比特整数量化的PTQ微调方法。'),('2505.21592v1','Taylor expansion-based Kolmogorov-Arnold network for blind image quality assessment','Kolmogorov-Arnold Network (KAN) has attracted growing interest for its strong\nfunction approximation capability. In our previous work, KAN and its variants\nwere explored in score regression for blind image quality assessment (BIQA).\nHowever, these models encounter challenges when processing high-dimensional\nfeatures, leading to limited performance gains and increased computational\ncost. To address these issues, we propose TaylorKAN that leverages the Taylor\nexpansions as learnable activation functions to enhance local approximation\ncapability. To improve the computational efficiency, network depth reduction\nand feature dimensionality compression are integrated into the TaylorKAN-based\nscore regression pipeline. On five databases (BID, CLIVE, KonIQ, SPAQ, and\nFLIVE) with authentic distortions, extensive experiments demonstrate that\nTaylorKAN consistently outperforms the other KAN-related models, indicating\nthat the local approximation via Taylor expansions is more effective than\nglobal approximation using orthogonal functions. Its generalization capacity is\nvalidated through inter-database experiments. The findings highlight the\npotential of TaylorKAN as an efficient and robust model for high-dimensional\nscore regression.','Ze Chen, Shaode Yu','2025-05-27','eess.IV','图像识别','http://arxiv.org/pdf/2505.21592v1','该论文介绍了一种名为TaylorKAN的模型，利用可学习的泰勒展开作为激活函数来增强局部逼近能力，以提高高维特征处理的性能和降低计算成本。通过在五个数据库上进行实验证明TaylorKAN在盲图像质量评估中表现优异，显示泰勒展开的局部逼近比使用正交函数的全局逼近更有效。'),('2505.21593v1','Any-to-Bokeh: One-Step Video Bokeh via Multi-Plane Image Guided Diffusion','Recent advances in diffusion based editing models have enabled realistic\ncamera simulation and image-based bokeh, but video bokeh remains largely\nunexplored. Existing video editing models cannot explicitly control focus\nplanes or adjust bokeh intensity, limiting their applicability for controllable\noptical effects. Moreover, naively extending image-based bokeh methods to video\noften results in temporal flickering and unsatisfactory edge blur transitions\ndue to the lack of temporal modeling and generalization capability. To address\nthese challenges, we propose a novel one-step video bokeh framework that\nconverts arbitrary input videos into temporally coherent, depth-aware bokeh\neffects. Our method leverages a multi-plane image (MPI) representation\nconstructed through a progressively widening depth sampling function, providing\nexplicit geometric guidance for depth-dependent blur synthesis. By conditioning\na single-step video diffusion model on MPI layers and utilizing the strong 3D\npriors from pre-trained models such as Stable Video Diffusion, our approach\nachieves realistic and consistent bokeh effects across diverse scenes.\nAdditionally, we introduce a progressive training strategy to enhance temporal\nconsistency, depth robustness, and detail preservation. Extensive experiments\ndemonstrate that our method produces high-quality, controllable bokeh effects\nand achieves state-of-the-art performance on multiple evaluation benchmarks.','Yang Yang, Siming Zheng, Jinwei Chen, Boxi Wu, Xiaofei He, Deng Cai, Bo Li, Peng-Tao Jiang','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21593v1','该论文提出了一种新颖的一步视频背景虚化框架，能够将任意输入视频转换为具有时间连贯性和深度感知的背景虚化效果。通过在MPI层上调节单步视频扩散模型，并利用预训练模型的强3D先验知识，实现了在不同场景下逼真和一致的背景虚化效果。'),('2505.21594v1','Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits','Large Language Models (LLMs) enable various applications on edge devices such\nas smartphones, wearables, and embodied robots. However, their deployment often\ndepends on expensive cloud-based APIs, creating high operational costs, which\nlimit access for smaller organizations and raise sustainability concerns.\nCertain LLMs can be deployed on-device, offering a cost-effective solution with\nreduced latency and improved privacy. Yet, limited computing resources\nconstrain the size and accuracy of models that can be deployed, necessitating a\ncollaborative design between edge and cloud. We propose a fast and\ncost-effective speculative edge-cloud decoding framework with a large target\nmodel on the server and a small draft model on the device. By introducing early\nexits in the target model, tokens are generated mid-verification, allowing the\nclient to preemptively draft subsequent tokens before final verification, thus\nutilizing idle time and enhancing parallelism between edge and cloud. Using an\nNVIDIA Jetson Nano (client) and an A100 GPU (server) with Vicuna-68M (draft)\nand Llama2-7B (target) models, our method achieves up to a 35% reduction in\nlatency compared to cloud-based autoregressive decoding, with an additional 11%\nimprovement from preemptive drafting. To demonstrate real-world applicability,\nwe deploy our method on the Unitree Go2 quadruped robot using Vision-Language\nModel (VLM) based control, achieving a 21% speedup over traditional cloud-based\nautoregressive decoding. These results demonstrate the potential of our\nframework for real-time LLM and VLM applications on resource-constrained edge\ndevices.','Yeshwanth Venkatesha, Souvik Kundu, Priyadarshini Panda','2025-05-27','cs.RO','LLM（Large Language Models）','http://arxiv.org/pdf/2505.21594v1','该论文提出了一种快速、成本效益的边缘-云解码框架，通过在服务器上使用大型目标模型和在设备上使用小型草稿模型，引入早期退出机制，实现了边缘设备上的实时大型语言模型和视觉-语言模型应用。'),('2505.21596v1','Learning optimal treatment strategies for intraoperative hypotension using deep reinforcement learning','Traditional methods of surgical decision making heavily rely on human\nexperience and prompt actions, which are variable. A data-driven system\ngenerating treatment recommendations based on patient states can be a\nsubstantial asset in perioperative decision-making, as in cases of\nintraoperative hypotension, for which suboptimal management is associated with\nacute kidney injury (AKI), a common and morbid postoperative complication. We\ndeveloped a Reinforcement Learning (RL) model to recommend optimum dose of\nintravenous (IV) fluid and vasopressors during surgery to avoid intraoperative\nhypotension and postoperative AKI. We retrospectively analyzed 50,021 surgeries\nfrom 42,547 adult patients who underwent major surgery at a quaternary care\nhospital between June 2014 and September 2020. Of these, 34,186 surgeries were\nused for model training and 15,835 surgeries were reserved for testing. We\ndeveloped a Deep Q-Networks based RL model using 16 variables including\nintraoperative physiologic time series, total dose of IV fluid and vasopressors\nextracted for every 15-minute epoch. The model replicated 69% of physician\\\'s\ndecisions for the dosage of vasopressors and proposed higher or lower dosage of\nvasopressors than received in 10% and 21% of the treatments, respectively. In\nterms of IV fluids, the model\\\'s recommendations were within 0.05 ml/kg/15 min\nof the actual dose in 41% of the cases, with higher or lower doses recommended\nfor 27% and 32% of the treatments, respectively. The model resulted in a higher\nestimated policy value compared to the physicians\\\' actual treatments, as well\nas random and zero-drug policies. AKI prevalence was the lowest in patients\nreceiving medication dosages that aligned with model\\\'s decisions. Our findings\nsuggest that implementation of the model\\\'s policy has the potential to reduce\npostoperative AKI and improve other outcomes driven by intraoperative\nhypotension.','Esra Adiyeke, Tianqi Liu, Venkata Sai Dheeraj Naganaboina, Han Li, Tyler J. Loftus, Yuanfang Ren, Benjamin Shickel, Matthew M. Ruppert, Karandeep Singh, Ruogu Fang, Parisa Rashidi, Azra Bihorac, Tezcan Ozrazgat-Baslanti','2025-05-27','q-bio.QM','强化学习','http://arxiv.org/pdf/2505.21596v1','该论文研究了在手术中使用强化学习模型生成基于患者状态的治疗建议，以避免术中低血压和术后急性肾损伤。他们开发了基于深度Q网络的RL模型，对手术过程中的生理时间序列和静脉药物剂量进行建模，并发现该模型在药物剂量推荐方面表现优于医生的实际决策。'),('2505.21597v1','Optimizing Deep Learning for Skin Cancer Classification: A Computationally Efficient CNN with Minimal Accuracy Trade-Off','The rapid advancement of deep learning in medical image analysis has greatly\nenhanced the accuracy of skin cancer classification. However, current\nstate-of-the-art models, especially those based on transfer learning like\nResNet50, come with significant computational overhead, rendering them\nimpractical for deployment in resource-constrained environments. This study\nproposes a custom CNN model that achieves a 96.7\\% reduction in parameters\n(from 23.9 million in ResNet50 to 692,000) while maintaining a classification\naccuracy deviation of less than 0.022\\%. Our empirical analysis of the HAM10000\ndataset reveals that although transfer learning models provide a marginal\naccuracy improvement of approximately 0.022\\%, they result in a staggering\n13,216.76\\% increase in FLOPs, considerably raising computational costs and\ninference latency. In contrast, our lightweight CNN architecture, which\nencompasses only 30.04 million FLOPs compared to ResNet50\\\'s 4.00 billion,\nsignificantly reduces energy consumption, memory footprint, and inference time.\nThese findings underscore the trade-off between the complexity of deep models\nand their real-world feasibility, positioning our optimized CNN as a practical\nsolution for mobile and edge-based skin cancer diagnostics.','Abdullah Al Mamun, Pollob Chandra Ray, Md Rahat Ul Nasib, Akash Das, Jia Uddin, Md Nurul Absur','2025-05-27','eess.IV','图像识别','http://arxiv.org/pdf/2505.21597v1','该论文提出了一种自定义的轻量级CNN模型，通过大幅减少参数数量（从ResNet50的2390万个减少到69.2万个），同时保持分类准确率的偏差小于0.022％。研究结果表明，相比于基于迁移学习的模型，该轻量级CNN架构在能源消耗、内存占用和推断时间方面都有显著的优势。'),('2505.21598v1','Rethinking Data Mixture for Large Language Models: A Comprehensive Survey and New Perspectives','Training large language models with data collected from various domains can\nimprove their performance on downstream tasks. However, given a fixed training\nbudget, the sampling proportions of these different domains significantly\nimpact the model\\\'s performance. How can we determine the domain weights across\ndifferent data domains to train the best-performing model within constrained\ncomputational resources? In this paper, we provide a comprehensive overview of\nexisting data mixture methods. First, we propose a fine-grained categorization\nof existing methods, extending beyond the previous offline and online\nclassification. Offline methods are further grouped into heuristic-based,\nalgorithm-based, and function fitting-based methods. For online methods, we\ncategorize them into three groups: online min-max optimization, online mixing\nlaw, and other approaches by drawing connections with the optimization\nframeworks underlying offline methods. Second, we summarize the problem\nformulations, representative algorithms for each subtype of offline and online\nmethods, and clarify the relationships and distinctions among them. Finally, we\ndiscuss the advantages and disadvantages of each method and highlight key\nchallenges in the field of data mixture.','Yajiao Liu, Congliang Chen, Junchi Yang, Ruoyu Sun','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21598v1','本文主要研究如何确定不同数据领域的权重，以在有限的计算资源下训练表现最佳的大型语言模型。作者提供了现有数据混合方法的全面概述，对离线和在线方法进行了细致分类，并总结了各种方法的问题表述、代表性算法以及优缺点。'),('2505.21600v1','R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing','Large Language Models (LLMs) achieve impressive reasoning capabilities at the\ncost of substantial inference overhead, posing substantial deployment\nchallenges. Although distilled Small Language Models (SLMs) significantly\nenhance efficiency, their performance suffers as they fail to follow LLMs\\\'\nreasoning paths. Luckily, we reveal that only a small fraction of tokens\ngenuinely diverge reasoning paths between LLMs and SLMs. Most generated tokens\nare either identical or exhibit neutral differences, such as minor variations\nin abbreviations or expressions. Leveraging this insight, we introduce **Roads\nto Rome (R2R)**, a neural token routing method that selectively utilizes LLMs\nonly for these critical, path-divergent tokens, while leaving the majority of\ntoken generation to the SLM. We also develop an automatic data generation\npipeline that identifies divergent tokens and generates token-level routing\nlabels to train the lightweight router. We apply R2R to combine R1-1.5B and\nR1-32B models from the DeepSeek family, and evaluate on challenging math,\ncoding, and QA benchmarks. With an average activated parameter size of 5.6B,\nR2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even the\nR1-14B model. Compared to R1-32B, it delivers a 2.8x wall-clock speedup with\ncomparable performance, advancing the Pareto frontier of test-time scaling\nefficiency. Our code is available at https://github.com/thu-nics/R2R.','Tianyu Fu, Yi Ge, Yichen You, Enshu Liu, Zhihang Yuan, Guohao Dai, Shengen Yan, Huazhong Yang, Yu Wang','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21600v1','该论文提出了一种名为Roads to Rome (R2R)的神经标记路由方法，通过选择性地利用LLMs来处理路径分歧的关键标记，从而提高SLMs的效率。他们在数学、编码和问答等基准测试中进行了评估，结果显示R2R在参数激活大小为5.6B的情况下，超过了R1-7B的平均准确率1.6倍，甚至优于R1-14B模型。相比于R1-32B，R2R在性能相当的情况下提供了2.8倍的墙钟速度提升。'),('2505.21604v1','Public Discourse Sandbox: Facilitating Human and AI Digital Communication Research','Social media serves as a primary communication and information dissemination\nplatform for major global events, entertainment, and niche or topically focused\ncommunity discussions. Therefore, it represents a valuable resource for\nresearchers who aim to understand numerous questions. However, obtaining data\ncan be difficult, expensive, and often unreliable due to the presence of bots,\nfake accounts, and manipulated content. Additionally, there are ethical\nconcerns if researchers decide to conduct an online experiment without\nexplicitly notifying social media users about their intent. There is a need for\nmore controlled and scalable mechanisms to evaluate the impacts of digital\ndiscussion interventions on audiences. We introduce the Public Discourse\nSandbox (PDS), which serves as a digital discourse research platform for\nhuman-AI as well as AI-AI discourse research, testing, and training. PDS\nprovides a safe and secure space for research experiments that are not viable\non public, commercial social media platforms. Its main purpose is to enable the\nunderstanding of AI behaviors and the impacts of customized AI participants via\ntechniques such as prompt engineering, retrieval-augmented generation (RAG),\nand fine-tuning. We provide a hosted live version of the sandbox to support\nresearchers as well as the open-sourced code on GitHub for community\ncollaboration and contribution.','Kristina Radivojevic, Caleb Reinking, Shaun Whitfield, Paul Brenner','2025-05-27','cs.CY','自然语言处理','http://arxiv.org/pdf/2505.21604v1','该论文介绍了一个名为Public Discourse Sandbox (PDS)的数字话语研究平台，用于人工智能与人类以及人工智能之间的话语研究、测试和训练，旨在评估数字讨论干预对受众的影响。'),('2505.21605v1','SOSBENCH: Benchmarking Safety Alignment on Scientific Knowledge','Large language models (LLMs) exhibit advancing capabilities in complex tasks,\nsuch as reasoning and graduate-level question answering, yet their resilience\nagainst misuse, particularly involving scientifically sophisticated risks,\nremains underexplored. Existing safety benchmarks typically focus either on\ninstructions requiring minimal knowledge comprehension (e.g., ``tell me how to\nbuild a bomb\") or utilize prompts that are relatively low-risk (e.g.,\nmultiple-choice or classification tasks about hazardous content). Consequently,\nthey fail to adequately assess model safety when handling knowledge-intensive,\nhazardous scenarios.\n  To address this critical gap, we introduce SOSBench, a regulation-grounded,\nhazard-focused benchmark encompassing six high-risk scientific domains:\nchemistry, biology, medicine, pharmacology, physics, and psychology. The\nbenchmark comprises 3,000 prompts derived from real-world regulations and laws,\nsystematically expanded via an LLM-assisted evolutionary pipeline that\nintroduces diverse, realistic misuse scenarios (e.g., detailed explosive\nsynthesis instructions involving advanced chemical formulas). We evaluate\nfrontier models within a unified evaluation framework using our SOSBench.\nDespite their alignment claims, advanced models consistently disclose\npolicy-violating content across all domains, demonstrating alarmingly high\nrates of harmful responses (e.g., 79.1% for Deepseek-R1 and 47.3% for GPT-4.1).\nThese results highlight significant safety alignment deficiencies and\nunderscore urgent concerns regarding the responsible deployment of powerful\nLLMs.','Fengqing Jiang, Fengbo Ma, Zhangchen Xu, Yuetai Li, Bhaskar Ramasubramanian, Luyao Niu, Bo Li, Xianyan Chen, Zhen Xiang, Radha Poovendran','2025-05-27','cs.LG','大语言模型(LLM)、安全性评估(AI Safety)','http://arxiv.org/pdf/2505.21605v1','该论文介绍了一个新的基于危险焦点的基准测试集SOSBench，涵盖六个高风险科学领域，并通过LLM辅助的演化管道扩展了3,000个提示，评估了前沿模型在处理高风险场景时的安全性。');
INSERT INTO `ai_processed_papers` VALUES ('2505.21608v1','How does Misinformation Affect Large Language Model Behaviors and Preferences?','Large Language Models (LLMs) have shown remarkable capabilities in\nknowledge-intensive tasks, while they remain vulnerable when encountering\nmisinformation. Existing studies have explored the role of LLMs in combating\nmisinformation, but there is still a lack of fine-grained analysis on the\nspecific aspects and extent to which LLMs are influenced by misinformation. To\nbridge this gap, we present MisBench, the current largest and most\ncomprehensive benchmark for evaluating LLMs\\\' behavior and knowledge preference\ntoward misinformation. MisBench consists of 10,346,712 pieces of\nmisinformation, which uniquely considers both knowledge-based conflicts and\nstylistic variations in misinformation. Empirical results reveal that while\nLLMs demonstrate comparable abilities in discerning misinformation, they still\nremain susceptible to knowledge conflicts and stylistic variations. Based on\nthese findings, we further propose a novel approach called Reconstruct to\nDiscriminate (RtD) to strengthen LLMs\\\' ability to detect misinformation. Our\nstudy provides valuable insights into LLMs\\\' interactions with misinformation,\nand we believe MisBench can serve as an effective benchmark for evaluating\nLLM-based detectors and enhancing their reliability in real-world applications.\nCodes and data are available at https://github.com/GKNL/MisBench.','Miao Peng, Nuo Chen, Jianheng Tang, Jia Li','2025-05-27','cs.CL','大型语言模型(LLM)、虚假信息检测(AI)','http://arxiv.org/pdf/2505.21608v1','该论文介绍了一个名为MisBench的最大和最全面的基准测试，用于评估大型语言模型（LLMs）对于虚假信息的行为和知识偏好。研究结果显示，虽然LLMs在识别虚假信息方面表现出色，但仍然容易受到知识冲突和风格变化的影响。'),('2505.21609v1','Preventing Adversarial AI Attacks Against Autonomous Situational Awareness: A Maritime Case Study','Adversarial artificial intelligence (AI) attacks pose a significant threat to\nautonomous transportation, such as maritime vessels, that rely on AI\ncomponents. Malicious actors can exploit these systems to deceive and\nmanipulate AI-driven operations. This paper addresses three critical research\nchallenges associated with adversarial AI: the limited scope of traditional\ndefences, inadequate security metrics, and the need to build resilience beyond\nmodel-level defences. To address these challenges, we propose building defences\nutilising multiple inputs and data fusion to create defensive components and an\nAI security metric as a novel approach toward developing more secure AI\nsystems. We name this approach the Data Fusion Cyber Resilience (DFCR) method,\nand we evaluate it through real-world demonstrations and comprehensive\nquantitative analyses, comparing a system built with the DFCR method against\nsingle-input models and models utilising existing state-of-the-art defences.\nThe findings show that the DFCR approach significantly enhances resilience\nagainst adversarial machine learning attacks in maritime autonomous system\noperations, achieving up to a 35\\% reduction in loss for successful\nmulti-pronged perturbation attacks, up to a 100\\% reduction in loss for\nsuccessful adversarial patch attacks and up to 100\\% reduction in loss for\nsuccessful spoofing attacks when using these more resilient systems. We\ndemonstrate how DFCR and DFCR confidence scores can reduce adversarial AI\ncontact confidence and improve decision-making by the system, even when typical\nadversarial defences have been compromised. Ultimately, this work contributes\nto the development of more secure and resilient AI-driven systems against\nadversarial attacks.','Mathew J. Walter, Aaron Barrett, Kimberly Tam','2025-05-27','cs.CR','对抗人工智能','http://arxiv.org/pdf/2505.21609v1','本文针对对抗人工智能攻击在自主运输领域的威胁展开研究，提出了一种名为数据融合网络弹性（DFCR）方法，通过利用多输入和数据融合构建防御组件和AI安全指标，以提高AI系统的安全性和弹性。实验结果表明，DFCR方法显著增强了对对抗机器学习攻击的抵抗能力，降低了损失。'),('2505.21620v1','VideoMarkBench: Benchmarking Robustness of Video Watermarking','The rapid development of video generative models has led to a surge in highly\nrealistic synthetic videos, raising ethical concerns related to disinformation\nand copyright infringement. Recently, video watermarking has been proposed as a\nmitigation strategy by embedding invisible marks into AI-generated videos to\nenable subsequent detection. However, the robustness of existing video\nwatermarking methods against both common and adversarial perturbations remains\nunderexplored. In this work, we introduce VideoMarkBench, the first systematic\nbenchmark designed to evaluate the robustness of video watermarks under\nwatermark removal and watermark forgery attacks. Our study encompasses a\nunified dataset generated by three state-of-the-art video generative models,\nacross three video styles, incorporating four watermarking methods and seven\naggregation strategies used during detection. We comprehensively evaluate 12\ntypes of perturbations under white-box, black-box, and no-box threat models.\nOur findings reveal significant vulnerabilities in current watermarking\napproaches and highlight the urgent need for more robust solutions. Our code is\navailable at https://github.com/zhengyuan-jiang/VideoMarkBench.','Zhengyuan Jiang, Moyang Guo, Kecen Li, Yuepeng Hu, Yupu Wang, Zhicong Huang, Cheng Hong, Neil Zhenqiang Gong','2025-05-27','cs.CR','生成模型','http://arxiv.org/pdf/2505.21620v1','该论文介绍了一个系统性基准测试集 VideoMarkBench，用于评估视频水印在水印移除和伪造攻击下的鲁棒性。研究发现了当前水印方法存在显著的漏洞，强调了更加鲁棒解决方案的迫切需求。'),('2505.21626v1','Learning Where to Learn: Training Distribution Selection for Provable OOD Performance','Out-of-distribution (OOD) generalization remains a fundamental challenge in\nmachine learning. Models trained on one data distribution often experience\nsubstantial performance degradation when evaluated on shifted or unseen\ndomains. To address this challenge, the present paper studies the design of\ntraining data distributions that maximize average-case OOD performance. First,\na theoretical analysis establishes a family of generalization bounds that\nquantify how the choice of training distribution influences OOD error across a\npredefined family of target distributions. These insights motivate the\nintroduction of two complementary algorithmic strategies: (i) directly\nformulating OOD risk minimization as a bilevel optimization problem over the\nspace of probability measures and (ii) minimizing a theoretical upper bound on\nOOD error. Last, the paper evaluates the two approaches across a range of\nfunction approximation and operator learning examples. The proposed methods\nsignificantly improve OOD accuracy over standard empirical risk minimization\nwith a fixed distribution. These results highlight the potential of\ndistribution-aware training as a principled and practical framework for robust\nOOD generalization.','Nicolas Guerra, Nicholas H. Nelsen, Yunan Yang','2025-05-27','cs.LG','泛化学习','http://arxiv.org/pdf/2505.21626v1','本文研究了如何设计训练数据分布以最大化平均情况下的OOD性能。通过理论分析建立了一系列泛化界限，提出了两种算法策略来最小化OOD风险，并在一系列示例中评估了这些方法的有效性。'),('2505.21627v1','Is Your LLM Overcharging You? Tokenization, Transparency, and Incentives','State-of-the-art large language models require specialized hardware and\nsubstantial energy to operate. As a consequence, cloud-based services that\nprovide access to large language models have become very popular. In these\nservices, the price users pay for an output provided by a model depends on the\nnumber of tokens the model uses to generate it -- they pay a fixed price per\ntoken. In this work, we show that this pricing mechanism creates a financial\nincentive for providers to strategize and misreport the (number of) tokens a\nmodel used to generate an output, and users cannot prove, or even know, whether\na provider is overcharging them. However, we also show that, if an unfaithful\nprovider is obliged to be transparent about the generative process used by the\nmodel, misreporting optimally without raising suspicion is hard. Nevertheless,\nas a proof-of-concept, we introduce an efficient heuristic algorithm that\nallows providers to significantly overcharge users without raising suspicion,\nhighlighting the vulnerability of users under the current pay-per-token pricing\nmechanism. Further, to completely eliminate the financial incentive to\nstrategize, we introduce a simple incentive-compatible token pricing mechanism.\nUnder this mechanism, the price users pay for an output provided by a model\ndepends on the number of characters of the output -- they pay a fixed price per\ncharacter. Along the way, to illustrate and complement our theoretical results,\nwe conduct experiments with several large language models from the\n$\\texttt{Llama}$, $\\texttt{Gemma}$ and $\\texttt{Ministral}$ families, and input\nprompts from the LMSYS Chatbot Arena platform.','Ander Artola Velasco, Stratis Tsirtsis, Nastaran Okati, Manuel Gomez-Rodriguez','2025-05-27','cs.GT','语言模型','http://arxiv.org/pdf/2505.21627v1','本文研究了当前流行的基于大型语言模型的云服务中存在的定价机制问题，指出了提供商存在操纵和虚报模型生成输出所使用的标记数量的金融动机，以及用户难以证明或知晓提供商是否在向他们收取过高费用。作者提出了一种简单的激励兼容的标记定价机制，消除了提供商操纵的金融动机。'),('2505.21636v1','The Feasibility of Topic-Based Watermarking on Academic Peer Reviews','Large language models (LLMs) are increasingly integrated into academic\nworkflows, with many conferences and journals permitting their use for tasks\nsuch as language refinement and literature summarization. However, their use in\npeer review remains prohibited due to concerns around confidentiality breaches,\nhallucinated content, and inconsistent evaluations. As LLM-generated text\nbecomes more indistinguishable from human writing, there is a growing need for\nreliable attribution mechanisms to preserve the integrity of the review\nprocess. In this work, we evaluate topic-based watermarking (TBW), a\nlightweight, semantic-aware technique designed to embed detectable signals into\nLLM-generated text. We conduct a comprehensive assessment across multiple LLM\nconfigurations, including base, few-shot, and fine-tuned variants, using\nauthentic peer review data from academic conferences. Our results show that TBW\nmaintains review quality relative to non-watermarked outputs, while\ndemonstrating strong robustness to paraphrasing-based evasion. These findings\nhighlight the viability of TBW as a minimally intrusive and practical solution\nfor enforcing LLM usage in peer review.','Alexander Nemecek, Yuzhou Jiang, Erman Ayday','2025-05-27','cs.CR','大型语言模型（LLM）、同行评审、文本水印技术','http://arxiv.org/pdf/2505.21636v1','该论文研究了如何在使用大型语言模型（LLMs）进行同行评审时，通过主题水印技术（TBW）来保护评审过程的完整性。他们评估了TBW在多种LLM配置下的效果，并发现TBW可以在保持评审质量的同时对抄袭进行有效防范。'),('2505.21639v1','Apprenticeship learning with prior beliefs using inverse optimization','The relationship between inverse reinforcement learning (IRL) and inverse\noptimization (IO) for Markov decision processes (MDPs) has been relatively\nunderexplored in the literature, despite addressing the same problem. In this\nwork, we revisit the relationship between the IO framework for MDPs, IRL, and\napprenticeship learning (AL). We incorporate prior beliefs on the structure of\nthe cost function into the IRL and AL problems, and demonstrate that the\nconvex-analytic view of the AL formalism (Kamoutsi et al., 2021) emerges as a\nrelaxation of our framework. Notably, the AL formalism is a special case in our\nframework when the regularization term is absent. Focusing on the suboptimal\nexpert setting, we formulate the AL problem as a regularized min-max problem.\nThe regularizer plays a key role in addressing the ill-posedness of IRL by\nguiding the search for plausible cost functions. To solve the resulting\nregularized-convex-concave-min-max problem, we use stochastic mirror descent\n(SMD) and establish convergence bounds for the proposed method. Numerical\nexperiments highlight the critical role of regularization in learning cost\nvectors and apprentice policies.','Mauricio Junca, Esteban Leiva','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21639v1','本文重新审视了马尔可夫决策过程（MDPs）中的逆优化框架、逆强化学习（IRL）和学徒学习（AL）之间的关系，并在IRL和AL问题中加入了对成本函数结构的先验信念，展示了AL形式主义的凸解析视角是我们框架的一种放松。重点关注次优专家设置，将AL问题制定为正则化的极小极大问题，正则化项在解决IRL的不适定性中起着关键作用。'),('2505.21641v1','PrivATE: Differentially Private Confidence Intervals for Average Treatment Effects','The average treatment effect (ATE) is widely used to evaluate the\neffectiveness of drugs and other medical interventions. In safety-critical\napplications like medicine, reliable inferences about the ATE typically require\nvalid uncertainty quantification, such as through confidence intervals (CIs).\nHowever, estimating treatment effects in these settings often involves\nsensitive data that must be kept private. In this work, we present PrivATE, a\nnovel machine learning framework for computing CIs for the ATE under\ndifferential privacy. Specifically, we focus on deriving valid\nprivacy-preserving CIs for the ATE from observational data. Our PrivATE\nframework consists of three steps: (i) estimating a differentially private ATE\nthrough output perturbation; (ii) estimating the differentially private\nvariance through a truncated output perturbation mechanism; and (iii)\nconstructing the CIs while accounting for the uncertainty from both the\nestimation and privatization steps. Our PrivATE framework is model agnostic,\ndoubly robust, and ensures valid CIs. We demonstrate the effectiveness of our\nframework using synthetic and real-world medical datasets. To the best of our\nknowledge, we are the first to derive a general, doubly robust framework for\nvalid CIs of the ATE under ($\\varepsilon$, $\\delta$)-differential privacy.','Maresa Schröder, Justin Hartenstein, Stefan Feuerriegel','2025-05-27','cs.LG','隐私保护、机器学习','http://arxiv.org/pdf/2505.21641v1','该论文介绍了一种名为PrivATE的机器学习框架，用于在不泄露敏感数据的情况下计算平均治疗效应（ATE）的置信区间。该框架通过三个步骤实现：通过输出扰动估计不同ially private ATE；通过截断输出扰动机制估计不同ially private方差；在考虑估计和隐私化步骤的不确定性的基础上构建置信区间。研究结果表明，该框架在合成和真实医疗数据集上表现有效。'),('2505.21647v1','QuARI: Query Adaptive Retrieval Improvement','Massive-scale pretraining has made vision-language models increasingly\npopular for image-to-image and text-to-image retrieval across a broad\ncollection of domains. However, these models do not perform well when used for\nchallenging retrieval tasks, such as instance retrieval in very large-scale\nimage collections. Recent work has shown that linear transformations of VLM\nfeatures trained for instance retrieval can improve performance by emphasizing\nsubspaces that relate to the domain of interest. In this paper, we explore a\nmore extreme version of this specialization by learning to map a given query to\na query-specific feature space transformation. Because this transformation is\nlinear, it can be applied with minimal computational cost to millions of image\nembeddings, making it effective for large-scale retrieval or re-ranking.\nResults show that this method consistently outperforms state-of-the-art\nalternatives, including those that require many orders of magnitude more\ncomputation at query time.','Eric Xing, Abby Stylianou, Robert Pless, Nathan Jacobs','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21647v1','该论文探讨了在大规模图像检索任务中，通过学习将查询映射到特定特征空间转换的方法，以提高检索性能。实验证明，这种方法在大规模图像嵌入检索或重新排序中始终优于当前最先进的替代方法。'),('2505.21651v1','AutoSGD: Automatic Learning Rate Selection for Stochastic Gradient Descent','The learning rate is an important tuning parameter for stochastic gradient\ndescent (SGD) and can greatly influence its performance. However, appropriate\nselection of a learning rate schedule across all iterations typically requires\na non-trivial amount of user tuning effort. To address this, we introduce\nAutoSGD: an SGD method that automatically determines whether to increase or\ndecrease the learning rate at a given iteration and then takes appropriate\naction. We introduce theory supporting the convergence of AutoSGD, along with\nits deterministic counterpart for standard gradient descent. Empirical results\nsuggest strong performance of the method on a variety of traditional\noptimization problems and machine learning tasks.','Nikola Surjanovic, Alexandre Bouchard-Côté, Trevor Campbell','2025-05-27','cs.LG','优化算法','http://arxiv.org/pdf/2505.21651v1','该论文介绍了一种名为AutoSGD的随机梯度下降方法，能够自动确定在给定迭代中是否增加或减少学习率，并采取相应的行动。论文提出了支持AutoSGD收敛性的理论，并在传统优化问题和机器学习任务中表现出强大的性能。'),('2505.21652v1','PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation','Fine-grained robot manipulation, such as lifting and rotating a bottle to\ndisplay the label on the cap, requires robust reasoning about object parts and\ntheir relationships with intended tasks. Despite recent advances in training\ngeneral-purpose robot manipulation policies guided by language instructions,\nthere is a notable lack of large-scale datasets for fine-grained manipulation\ntasks with part-level instructions and diverse 3D object instances annotated\nwith part-level labels. In this work, we introduce PartInstruct, the first\nlarge-scale benchmark for training and evaluating fine-grained robot\nmanipulation models using part-level instructions. PartInstruct comprises 513\nobject instances across 14 categories, each annotated with part-level\ninformation, and 1302 fine-grained manipulation tasks organized into 16 task\nclasses. Our training set consists of over 10,000 expert demonstrations\nsynthesized in a 3D simulator, where each demonstration is paired with a\nhigh-level task instruction, a chain of base part-based skill instructions, and\nground-truth 3D information about the object and its parts. Additionally, we\ndesigned a comprehensive test suite to evaluate the generalizability of learned\npolicies across new states, objects, and tasks. We evaluated several\nstate-of-the-art robot manipulation approaches, including end-to-end\nvision-language policy learning and bi-level planning models for robot\nmanipulation on our benchmark. The experimental results reveal that current\nmodels struggle to robustly ground part concepts and predict actions in 3D\nspace, and face challenges when manipulating object parts in long-horizon\ntasks.','Yifan Yin, Zhengtao Han, Shivam Aarya, Jianxin Wang, Shuhang Xu, Jiawei Peng, Angtian Wang, Alan Yuille, Tianmin Shu','2025-05-27','cs.RO','机器人操作','http://arxiv.org/pdf/2505.21652v1','该论文介绍了一个名为PartInstruct的大规模基准，用于训练和评估使用部分级指令进行细粒度机器人操作模型。研究发现当前模型在3D空间中难以稳固地基于部分概念并预测动作，并在长时间跨度任务中操作对象部分时面临挑战。'),('2505.21657v1','Explainability of Large Language Models using SMILE: Statistical Model-agnostic Interpretability with Local Explanations','Large language models like GPT, LLAMA, and Claude have become incredibly\npowerful at generating text, but they are still black boxes, so it is hard to\nunderstand how they decide what to say. That lack of transparency can be\nproblematic, especially in fields where trust and accountability matter. To\nhelp with this, we introduce SMILE, a new method that explains how these models\nrespond to different parts of a prompt. SMILE is model-agnostic and works by\nslightly changing the input, measuring how the output changes, and then\nhighlighting which words had the most impact. Create simple visual heat maps\nshowing which parts of a prompt matter the most. We tested SMILE on several\nleading LLMs and used metrics such as accuracy, consistency, stability, and\nfidelity to show that it gives clear and reliable explanations. By making these\nmodels easier to understand, SMILE brings us one step closer to making AI more\ntransparent and trustworthy.','Zeinab Dehghani, Koorosh Aslansefat, Adil Khan, Mohammed Naveed Akram','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21657v1','该论文介绍了一种名为SMILE的新方法，用于解释大型语言模型对不同部分提示的响应，通过略微改变输入，测量输出变化，并突出显示对结果影响最大的单词。通过简单的视觉热图展示提示的哪些部分最重要。研究表明，SMILE能够清晰可靠地解释模型的决策过程。'),('2505.21658v1','STACI: Spatio-Temporal Aleatoric Conformal Inference','Fitting Gaussian Processes (GPs) provides interpretable aleatoric uncertainty\nquantification for estimation of spatio-temporal fields. Spatio-temporal deep\nlearning models, while scalable, typically assume a simplistic independent\ncovariance matrix for the response, failing to capture the underlying\ncorrelation structure. However, spatio-temporal GPs suffer from issues of\nscalability and various forms of approximation bias resulting from restrictive\nassumptions of the covariance kernel function. We propose STACI, a novel\nframework consisting of a variational Bayesian neural network approximation of\nnon-stationary spatio-temporal GP along with a novel spatio-temporal conformal\ninference algorithm. STACI is highly scalable, taking advantage of GPU training\ncapabilities for neural network models, and provides statistically valid\nprediction intervals for uncertainty quantification. STACI outperforms\ncompeting GPs and deep methods in accurately approximating spatio-temporal\nprocesses and we show it easily scales to datasets with millions of\nobservations.','Brandon R. Feng, David Keetae Park, Xihaier Luo, Arantxa Urdangarin, Shinjae Yoo, Brian J. Reich','2025-05-27','stat.ML','时空建模','http://arxiv.org/pdf/2505.21658v1','该论文提出了一种名为STACI的新框架，结合了变分贝叶斯神经网络逼近非平稳时空高斯过程和一种新的时空一致推断算法，用于对时空场的估计进行可解释的不确定性量化。STACI在准确逼近时空过程方面优于竞争的高斯过程和深度方法，并且能够轻松扩展到包含数百万观测数据的数据集。'),('2505.21660v1','PreGenie: An Agentic Framework for High-quality Visual Presentation Generation','Visual presentations are vital for effective communication. Early attempts to\nautomate their creation using deep learning often faced issues such as poorly\norganized layouts, inaccurate text summarization, and a lack of image\nunderstanding, leading to mismatched visuals and text. These limitations\nrestrict their application in formal contexts like business and scientific\nresearch. To address these challenges, we propose PreGenie, an agentic and\nmodular framework powered by multimodal large language models (MLLMs) for\ngenerating high-quality visual presentations.\n  PreGenie is built on the Slidev presentation framework, where slides are\nrendered from Markdown code. It operates in two stages: (1) Analysis and\nInitial Generation, which summarizes multimodal input and generates initial\ncode, and (2) Review and Re-generation, which iteratively reviews intermediate\ncode and rendered slides to produce final, high-quality presentations. Each\nstage leverages multiple MLLMs that collaborate and share information.\nComprehensive experiments demonstrate that PreGenie excels in multimodal\nunderstanding, outperforming existing models in both aesthetics and content\nconsistency, while aligning more closely with human design preferences.','Xiaojie Xu, Xinli Xu, Sirui Chen, Haoyu Chen, Fan Zhang, Ying-Cong Chen','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21660v1','该论文提出了一个基于多模态大语言模型（MLLMs）的框架 PreGenie，用于生成高质量的视觉演示文稿。该框架分为两个阶段：分析和初始生成，审查和重新生成，利用多个MLLMs协作生成最终的演示文稿。'),('2505.21664v1','Expert Survey: AI Reliability & Security Research Priorities','Our survey of 53 specialists across 105 AI reliability and security research\nareas identifies the most promising research prospects to guide strategic AI\nR&D investment. As companies are seeking to develop AI systems with broadly\nhuman-level capabilities, research on reliability and security is urgently\nneeded to ensure AI\\\'s benefits can be safely and broadly realized and prevent\nsevere harms. This study is the first to quantify expert priorities across a\ncomprehensive taxonomy of AI safety and security research directions and to\nproduce a data-driven ranking of their potential impact. These rankings may\nsupport evidence-based decisions about how to effectively deploy resources\ntoward AI reliability and security research.','Joe O\'Brien, Jeremy Dolan, Jay Kim, Jonah Dykhuizen, Jeba Sania, Sebastian Becker, Jam Kraprayoon, Cara Labrador','2025-05-27','cs.CY','AI安全性和可靠性','http://arxiv.org/pdf/2505.21664v1','该论文通过对53名专家在105个AI可靠性和安全性研究领域的调查，确定了指导战略AI研发投资的最有前景的研究方向。随着公司正在寻求开发具有广泛人类水平能力的AI系统，迫切需要进行可靠性和安全性研究，以确保AI的好处能够安全广泛地实现，并防止严重危害。该研究是首次量化专家对AI安全性和安全性研究方向的优先级，并产生了一个基于数据的潜在影响排名。这些排名可能支持基于证据的决策，如何有效地将资源投入到AI可靠性和安全性研究中。'),('2505.21666v1','Efficient Controllable Diffusion via Optimal Classifier Guidance','The controllable generation of diffusion models aims to steer the model to\ngenerate samples that optimize some given objective functions. It is desirable\nfor a variety of applications including image generation, molecule generation,\nand DNA/sequence generation. Reinforcement Learning (RL) based fine-tuning of\nthe base model is a popular approach but it can overfit the reward function\nwhile requiring significant resources. We frame controllable generation as a\nproblem of finding a distribution that optimizes a KL-regularized objective\nfunction. We present SLCD -- Supervised Learning based Controllable Diffusion,\nwhich iteratively generates online data and trains a small classifier to guide\nthe generation of the diffusion model. Similar to the standard\nclassifier-guided diffusion, SLCD\\\'s key computation primitive is classification\nand does not involve any complex concepts from RL or control. Via a reduction\nto no-regret online learning analysis, we show that under KL divergence, the\noutput from SLCD provably converges to the optimal solution of the\nKL-regularized objective. Further, we empirically demonstrate that SLCD can\ngenerate high quality samples with nearly the same inference time as the base\nmodel in both image generation with continuous diffusion and biological\nsequence generation with discrete diffusion. Our code is available at\nhttps://github.com/Owen-Oertell/slcd','Owen Oertell, Shikun Sun, Yiding Chen, Jin Peng Zhou, Zhiyong Wang, Wen Sun','2025-05-27','cs.LG','生成模型 (Generation Models)','http://arxiv.org/pdf/2505.21666v1','该论文提出了一种基于监督学习的可控扩散生成方法，通过在线生成数据并训练小型分类器来引导扩散模型的生成，避免了强化学习的过拟合和资源消耗问题。实验证明该方法在图像生成和生物序列生成中能够生成高质量样本，并且推断时间几乎与基础模型相同。'),('2505.21668v1','R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning','Despite advances in reasoning and planning of R1-like models, Large Language\nModels (LLMs) still struggle with tasks requiring precise computation, symbolic\nmanipulation, optimization, and algorithmic reasoning, in which textual\nreasoning lacks the rigor of code execution. A key challenge is enabling LLMs\nto decide when to use textual reasoning versus code generation. While OpenAI\ntrains models to invoke a Code Interpreter as needed, public research lacks\nguidance on aligning pre-trained LLMs to effectively leverage code and\ngeneralize across diverse tasks. We present R1-Code-Interpreter, an extension\nof a text-only LLM trained via multi-turn supervised fine-tuning (SFT) and\nreinforcement learning (RL) to autonomously generate multiple code queries\nduring step-by-step reasoning. We curate 144 reasoning and planning tasks (107\nfor training, 37 for testing), each with over 200 diverse questions. We\nfine-tune Qwen-2.5 models (3B/7B/14B) using various SFT and RL strategies,\ninvestigating different answer formats, reasoning vs. non-reasoning models,\ncold vs. warm starts, GRPO vs. PPO, and masked vs. unmasked code outputs.\nUnlike prior RL work on narrow domains, we find that Code Interpreter training\nis significantly harder due to high task diversity and expensive code\nexecution, highlighting the critical role of the SFT stage. Our final model,\nR1-CI-14B, improves average accuracy on the 37 test tasks from 44.0\\% to\n64.1\\%, outperforming GPT-4o (text-only: 58.6\\%) and approaching GPT-4o with\nCode Interpreter (70.9\\%), with the emergent self-checking behavior via code\ngeneration. Datasets, Codes, and Models are available at\nhttps://github.com/yongchao98/R1-Code-Interpreter and\nhttps://huggingface.co/yongchao98.','Yongchao Chen, Yueying Liu, Junwei Zhou, Yilun Hao, Jingquan Wang, Yang Zhang, Chuchu Fan','2025-05-27','cs.AI','生成模型、自然语言处理','http://arxiv.org/pdf/2505.21668v1','该论文介绍了一种名为R1-Code-Interpreter的模型，通过多轮监督微调和强化学习来训练文本-代码生成模型，以在推理过程中自动生成多个代码查询。最终模型在测试任务上的平均准确率从44.0%提高到64.1%，表现优于仅文本的GPT-4o（58.6%），接近带有代码解释器的GPT-4o（70.9%）。'),('2505.21670v1','Rethinking the Outlier Distribution in Large Language Models: An In-depth Study','Investigating outliers in large language models (LLMs) is crucial due to\ntheir significant impact on various aspects of LLM performance, including\nquantization and compression. Outliers often cause considerable quantization\nerrors, leading to degraded model performance. Identifying and addressing these\noutliers can enhance the accuracy and efficiency of the quantization process,\nenabling smoother deployment on edge devices or specialized hardware. Recent\nstudies have identified two common types of outliers in LLMs: massive\nactivations and channel-wise outliers. While numerous quantization algorithms\nhave been proposed to mitigate their effects and maintain satisfactory\naccuracy, few have thoroughly explored the root causes of these outliers in\ndepth. In this paper, we conduct a comprehensive investigation into the\nformation mechanisms of these outliers and propose potential strategies to\nmitigate their occurrence. Ultimately, we introduce some efficient approaches\nto eliminate most massive activations and channel-wise outliers with minimal\nimpact on accuracy.','Rahul Raman, Khushi Sharma, Sai Qian Zhang','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21670v1','该论文研究了大型语言模型中的异常值对模型性能的重要影响，包括量化和压缩。通过深入探究异常值的形成机制，提出了一些有效的方法来减少异常值的发生，从而提高量化过程的准确性和效率。'),('2505.21671v1','Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing','We study a sequential decision-making problem on a $n$-node graph $G$ where\neach node has an unknown label from a finite set $\\mathbf{\\Sigma}$, drawn from\na joint distribution $P$ that is Markov with respect to $G$. At each step,\nselecting a node reveals its label and yields a label-dependent reward. The\ngoal is to adaptively choose nodes to maximize expected accumulated discounted\nrewards. We impose a frontier exploration constraint, where actions are limited\nto neighbors of previously selected nodes, reflecting practical constraints in\nsettings such as contact tracing and robotic exploration. We design a Gittins\nindex-based policy that applies to general graphs and is provably optimal when\n$G$ is a forest. Our implementation runs in $O(n^2 \\cdot |\\mathbf{\\Sigma}|^2)$\ntime while using $O(n \\cdot |\\mathbf{\\Sigma}|^2)$ oracle calls to $P$ and\n$O(n^2 \\cdot |\\mathbf{\\Sigma}|)$ space. Experiments on synthetic and real-world\ngraphs show that our method consistently outperforms natural baselines,\nincluding in non-tree, budget-limited, and undiscounted settings. For example,\nin HIV testing simulations on real-world sexual interaction networks, our\npolicy detects nearly all positive cases with only half the population tested,\nsubstantially outperforming other baselines.','Davin Choo, Yuqi Pan, Tonghan Wang, Milind Tambe, Alastair van Heerden, Cheryl Johnson','2025-05-27','cs.AI','强化学习','http://arxiv.org/pdf/2505.21671v1','该论文研究了在具有未知标签的$n$节点图$G$上的顺序决策问题，每个节点从有限集$\\mathbf{\\Sigma}$中随机抽取标签，抽取过程符合Markov分布。通过选择节点来逐步揭示标签并获取依赖于标签的奖励，目标是自适应选择节点以最大化预期累积折现奖励。他们设计了基于Gittins指数的策略，适用于一般图，并在$G$为森林时被证明是最优的。实验结果表明，他们的方法在合成和真实世界的图上始终优于自然基线。'),('2505.21674v1','Make Planning Research Rigorous Again!','In over sixty years since its inception, the field of planning has made\nsignificant contributions to both the theory and practice of building planning\nsoftware that can solve a never-before-seen planning problem. This was done\nthrough established practices of rigorous design and evaluation of planning\nsystems. It is our position that this rigor should be applied to the current\ntrend of work on planning with large language models. One way to do so is by\ncorrectly incorporating the insights, tools, and data from the automated\nplanning community into the design and evaluation of LLM-based planners. The\nexperience and expertise of the planning community are not just important from\na historical perspective; the lessons learned could play a crucial role in\naccelerating the development of LLM-based planners. This position is\nparticularly important in light of the abundance of recent works that replicate\nand propagate the same pitfalls that the planning community has encountered and\nlearned from. We believe that avoiding such known pitfalls will contribute\ngreatly to the progress in building LLM-based planners and to planning in\ngeneral.','Michael Katz, Harsha Kokel, Christian Muise, Shirin Sohrabi, Sarath Sreedharan','2025-05-27','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21674v1','该论文提出应该将规划领域的严谨设计和评估实践应用于当前大型语言模型规划工作中，通过正确整合自动规划社区的见解、工具和数据来加速LLM规划器的发展。'),('2505.21677v1','What happens when generative AI models train recursively on each others\\\' generated outputs?','The internet is full of AI-generated content while also serving as a common\nsource of training data for generative AI (genAI) models. This duality raises\nthe possibility that future genAI models may be trained on other models\\\'\ngenerated outputs. Prior work has studied consequences of models training on\ntheir own generated outputs, but limited work has considered what happens if\nmodels ingest content produced by other models. Given society\\\'s increasing\ndependence on genAI tools, understanding downstream effects of such\ndata-mediated model interactions is critical. To this end, we provide empirical\nevidence for how data-mediated interactions might unfold in practice, develop a\ntheoretical model for this interactive training process, and show\nexperimentally possible long-term results of such interactions. We find that\ndata-mediated interactions can benefit models by exposing them to novel\nconcepts perhaps missed in original training data, but also can homogenize\ntheir performance on shared tasks.','Hung Ahn Vu, Galen Reeves, Emily Wenger','2025-05-27','cs.LG','生成模型','http://arxiv.org/pdf/2505.21677v1','该论文研究了生成AI模型在互相训练数据的情况下可能产生的影响，提供了实证证据、理论模型和实验结果。研究发现，数据介导的模型交互可以使模型暴露于原始训练数据中可能被忽略的新概念，但也可能使它们在共享任务上的表现同质化。'),('2505.21680v1','multivariateGPT: a decoder-only transformer for multivariate categorical and numeric data','Real-world processes often generate data that are a mix of categorical and\nnumeric values that are recorded at irregular and informative intervals.\nDiscrete token-based approaches are limited in numeric representation capacity\nwhile methods like neural ordinary differential equations are not well suited\nfor categorical data or informative sampling and require augmentation to handle\ncertain classes of trajectories. Here, we present multivariateGPT, a single\narchitecture for modeling sequences of mixed categorical (including tokenized\ntext) and numeric data. This is accomplished with an autoregressive sequence\ndecomposition, embedding scheme, and loss function that extend the next token\nprediction task to likelihood estimation of the joint distribution of next\ntoken class and value. We demonstrate how this approach can efficiently learn\nto generalize patterns in simple physical systems and model complex time series\nincluding electrocardiograms and multivariate electronic health record data.\nThis work extends the utility of transformer based models to additional classes\nof data.','Andrew J. Loza, Jun Yup Kim, Shangzheng Song, Yihang Liu, Joseph J. Y. Sung, R Andrew Taylor, Dennis L. Shung','2025-05-27','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21680v1','该论文提出了一种名为multivariateGPT的模型，用于建模混合分类和数值数据序列。通过自回归序列分解、嵌入方案和损失函数，扩展了下一个标记预测任务到下一个标记类和值的联合分布估计。研究结果表明，这种方法可以有效地学习简单物理系统中的模式，并对包括心电图和多变量电子健康记录数据在内的复杂时间序列进行建模。'),('2505.21684v1','Incentivizing Permissionless Distributed Learning of LLMs','We describe an incentive system for distributed deep learning of foundational\nmodels where peers are rewarded for contributions. The incentive system,\n\\textit{Gauntlet}, has been deployed on the bittensor blockchain and used to\ntrain a 1.2B LLM with completely permissionless contributions of\npseudo-gradients: no control over the users that can register or their\nhardware. \\textit{Gauntlet} can be applied to any synchronous distributed\ntraining scheme that relies on aggregating updates or pseudo-gradients. We rely\non a two-stage mechanism for fast filtering of peer uptime, reliability, and\nsynchronization, combined with the core component that estimates the loss\nbefore and after individual pseudo-gradient contributions. We utilized an\nOpenSkill rating system to track competitiveness of pseudo-gradient scores\nacross time. Finally, we introduce a novel mechanism to ensure peers on the\nnetwork perform unique computations. Our live 1.2B run, which has paid out\nreal-valued tokens to participants based on the value of their contributions,\nyielded a competitive (on a per-iteration basis) 1.2B model that demonstrates\nthe utility of our incentive system.','Joel Lidin, Amir Sarfi, Evangelos Pappas, Samuel Dare, Eugene Belilovsky, Jacob Steeves','2025-05-27','cs.LG','LLM (Large Language Model)','http://arxiv.org/pdf/2505.21684v1','该论文描述了一个分布式深度学习基础模型的激励系统，其中对贡献进行奖励。他们在bittensor区块链上部署了名为Gauntlet的激励系统，用于训练一个拥有12亿参数的LLM模型，实现了完全无需许可的伪梯度贡献。他们提出了一种两阶段机制，用于快速筛选节点的在线时间、可靠性和同步性，并介绍了一种新颖的机制来确保网络上的节点执行唯一计算。他们的实验结果表明，这一激励系统的实用性。'),('2505.21689v1','LLMPR: A Novel LLM-Driven Transfer Learning based Petition Ranking Model','The persistent accumulation of unresolved legal cases, especially within the\nIndian judiciary, significantly hampers the timely delivery of justice. Manual\nmethods of prioritizing petitions are often prone to inefficiencies and\nsubjective biases further exacerbating delays. To address this issue, we\npropose LLMPR (Large Language Model-based Petition Ranking), an automated\nframework that utilizes transfer learning and machine learning to assign\npriority rankings to legal petitions based on their contextual urgency.\nLeveraging the ILDC dataset comprising 7,593 annotated petitions, we process\nunstructured legal text and extract features through various embedding\ntechniques, including DistilBERT, LegalBERT, and MiniLM. These textual\nembeddings are combined with quantitative indicators such as gap days, rank\nscores, and word counts to train multiple machine learning models, including\nRandom Forest, Decision Tree, XGBoost, LightGBM, and CatBoost. Our experiments\ndemonstrate that Random Forest and Decision Tree models yield superior\nperformance, with accuracy exceeding 99% and a Spearman rank correlation of\n0.99. Notably, models using only numerical features achieve nearly optimal\nranking results (R2 = 0.988, \\r{ho} = 0.998), while LLM-based embeddings offer\nonly marginal gains. These findings suggest that automated petition ranking can\neffectively streamline judicial workflows, reduce case backlog, and improve\nfairness in legal prioritization.','Avijit Gayen, Somyajit Chakraborty, Mainak Sen, Soham Paul, Angshuman Jana','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21689v1','该论文提出了一种基于大型语言模型的自动化法律请愿排名框架，利用迁移学习和机器学习为法律请愿分配优先级排名，以解决印度司法系统中未解决法律案件积累导致的延迟问题。通过实验表明，随机森林和决策树模型的性能优越，准确率超过99%，斯皮尔曼等级相关性为0.99。'),('2505.21693v1','MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs','Large language models (LLMs) are used globally across many languages, but\ntheir English-centric pretraining raises concerns about cross-lingual\ndisparities for cultural awareness, often resulting in biased outputs. However,\ncomprehensive multilingual evaluation remains challenging due to limited\nbenchmarks and questionable translation quality. To better assess these\ndisparities, we introduce MAKIEval, an automatic multilingual framework for\nevaluating cultural awareness in LLMs across languages, regions, and topics.\nMAKIEval evaluates open-ended text generation, capturing how models express\nculturally grounded knowledge in natural language. Leveraging Wikidata\\\'s\nmultilingual structure as a cross-lingual anchor, it automatically identifies\ncultural entities in model outputs and links them to structured knowledge,\nenabling scalable, language-agnostic evaluation without manual annotation or\ntranslation. We then introduce four metrics that capture complementary\ndimensions of cultural awareness: granularity, diversity, cultural specificity,\nand consensus across languages. We assess 7 LLMs developed from different parts\nof the world, encompassing both open-source and proprietary systems, across 13\nlanguages, 19 countries and regions, and 6 culturally salient topics (e.g.,\nfood, clothing). Notably, we find that models tend to exhibit stronger cultural\nawareness in English, suggesting that English prompts more effectively activate\nculturally grounded knowledge. We publicly release our code and data.','Raoyuan Zhao, Beiduo Chen, Barbara Plank, Michael A. Hedderich','2025-05-27','cs.CL','大语言模型（LLM）、文化意识评估','http://arxiv.org/pdf/2505.21693v1','该论文介绍了一个名为MAKIEval的自动多语言框架，用于评估LLMs在不同语言、地区和主题下的文化意识。通过评估开放式文本生成，捕捉模型如何用自然语言表达文化相关知识。研究发现，模型在英语中表现出更强的文化意识，暗示英语更有效地激活文化相关知识。'),('2505.21695v1','AMSFL: Adaptive Multi-Step Federated Learning via Gradient Difference-Based Error Modeling','Federated learning faces critical challenges in balancing communication\nefficiency and model accuracy. One key issue lies in the approximation of\nupdate errors without incurring high computational costs. In this paper, we\npropose a lightweight yet effective method called Gradient Difference\nApproximation (GDA), which leverages first-order information to estimate local\nerror trends without computing the full Hessian matrix. The proposed method\nforms a key component of the Adaptive Multi-Step Federated Learning (AMSFL)\nframework and provides a unified error modeling strategy for large-scale\nmulti-step adaptive training environments.','Ganglou Xu','2025-05-27','cs.LG','联邦学习','http://arxiv.org/pdf/2505.21695v1','本文提出了一种名为Gradient Difference Approximation (GDA)的轻量级但有效的方法，用于估计本地误差趋势，从而在不计算完整Hessian矩阵的情况下解决联邦学习中的通信效率和模型准确性平衡的挑战。该方法是Adaptive Multi-Step Federated Learning (AMSFL)框架的关键组成部分，为大规模多步自适应训练环境提供了统一的误差建模策略。'),('2505.21699v1','STA-Risk: A Deep Dive of Spatio-Temporal Asymmetries for Breast Cancer Risk Prediction','Predicting the risk of developing breast cancer is an important clinical tool\nto guide early intervention and tailoring personalized screening strategies.\nEarly risk models have limited performance and recently machine learning-based\nanalysis of mammogram images showed encouraging risk prediction effects. These\nmodels however are limited to the use of a single exam or tend to overlook\nnuanced breast tissue evolvement in spatial and temporal details of\nlongitudinal imaging exams that are indicative of breast cancer risk. In this\npaper, we propose STA-Risk (Spatial and Temporal Asymmetry-based Risk\nPrediction), a novel Transformer-based model that captures fine-grained\nmammographic imaging evolution simultaneously from bilateral and longitudinal\nasymmetries for breast cancer risk prediction. STA-Risk is innovative by the\nside encoding and temporal encoding to learn spatial-temporal asymmetries,\nregulated by a customized asymmetry loss. We performed extensive experiments\nwith two independent mammogram datasets and achieved superior performance than\nfour representative SOTA models for 1- to 5-year future risk prediction. Source\ncodes will be released upon publishing of the paper.','Zhengbo Zhou, Dooman Arefan, Margarita Zuley, Jules Sumkin, Shandong Wu','2025-05-27','eess.IV','图像识别','http://arxiv.org/pdf/2505.21699v1','本文提出了一种新颖的基于Transformer的模型STA-Risk，用于从乳腺X射线照片中捕获细粒度的影像演变，以进行乳腺癌风险预测。该模型在两个独立的乳腺X射线数据集上进行了广泛实验，并在1到5年未来风险预测方面取得了优越的性能。'),('2505.21701v1','Do We Know What LLMs Don\\\'t Know? A Study of Consistency in Knowledge Probing','The reliability of large language models (LLMs) is greatly compromised by\ntheir tendency to hallucinate, underscoring the need for precise identification\nof knowledge gaps within LLMs. Various methods for probing such gaps exist,\nranging from calibration-based to prompting-based methods. To evaluate these\nprobing methods, in this paper, we propose a new process based on using input\nvariations and quantitative metrics. Through this, we expose two dimensions of\ninconsistency in knowledge gap probing. (1) Intra-method inconsistency: Minimal\nnon-semantic perturbations in prompts lead to considerable variance in detected\nknowledge gaps within the same probing method; e.g., the simple variation of\nshuffling answer options can decrease agreement to around 40%. (2) Cross-method\ninconsistency: Probing methods contradict each other on whether a model knows\nthe answer. Methods are highly inconsistent -- with decision consistency across\nmethods being as low as 7% -- even though the model, dataset, and prompt are\nall the same. These findings challenge existing probing methods and highlight\nthe urgent need for perturbation-robust probing frameworks.','Raoyuan Zhao, Abdullatif Köksal, Ali Modarressi, Michael A. Hedderich, Hinrich Schütze','2025-05-27','cs.CL','LLM（大型语言模型）','http://arxiv.org/pdf/2505.21701v1','本文探讨了大型语言模型（LLMs）存在的知识缺口问题，提出了一种基于输入变化和定量指标的新方法来评估这些缺口。研究发现，存在两种维度的知识缺口不一致性：内部方法不一致性和跨方法不一致性。'),('2505.21703v1','A Joint Reconstruction-Triplet Loss Autoencoder Approach Towards Unseen Attack Detection in IoV Networks','Internet of Vehicles (IoV) systems, while offering significant advancements\nin transportation efficiency and safety, introduce substantial security\nvulnerabilities due to their highly interconnected nature. These dynamic\nsystems produce massive amounts of data between vehicles, infrastructure, and\ncloud services and present a highly distributed framework with a wide attack\nsurface. In considering network-centered attacks on IoV systems, attacks such\nas Denial-of-Service (DoS) can prohibit the communication of essential physical\ntraffic safety information between system elements, illustrating that the\nsecurity concerns for these systems go beyond the traditional confidentiality,\nintegrity, and availability concerns of enterprise systems. Given the\ncomplexity and volume of data generated by IoV systems, traditional security\nmechanisms are often inadequate for accurately detecting sophisticated and\nevolving cyberattacks. Here, we present an unsupervised autoencoder method\ntrained entirely on benign network data for the purpose of unseen attack\ndetection in IoV networks. We leverage a weighted combination of reconstruction\nand triplet margin loss to guide the autoencoder training and develop a diverse\nrepresentation of the benign training set. We conduct extensive experiments on\nrecent network intrusion datasets from two different application domains,\nindustrial IoT and home IoT, that represent the modern IoV task. We show that\nour method performs robustly for all unseen attack types, with roughly 99%\naccuracy on benign data and between 97% and 100% performance on anomaly data.\nWe extend these results to show that our model is adaptable through the use of\ntransfer learning, achieving similarly high results while leveraging domain\nfeatures from one domain to another.','Julia Boone, Tolunay Seyfi, Fatemeh Afghah','2025-05-27','cs.CR','网络安全','http://arxiv.org/pdf/2505.21703v1','该论文提出了一种基于无监督自编码器方法，通过在IoV网络中训练完全良性网络数据来检测未知攻击，实验结果表明该方法在各种未知攻击类型下表现出色。'),('2505.21710v1','Assessing and Refining ChatGPT\\\'s Performance in Identifying Targeting and Inappropriate Language: A Comparative Study','This study evaluates the effectiveness of ChatGPT, an advanced AI model for\nnatural language processing, in identifying targeting and inappropriate\nlanguage in online comments. With the increasing challenge of moderating vast\nvolumes of user-generated content on social network sites, the role of AI in\ncontent moderation has gained prominence. We compared ChatGPT\\\'s performance\nagainst crowd-sourced annotations and expert evaluations to assess its\naccuracy, scope of detection, and consistency. Our findings highlight that\nChatGPT performs well in detecting inappropriate content, showing notable\nimprovements in accuracy through iterative refinements, particularly in Version\n6. However, its performance in targeting language detection showed variability,\nwith higher false positive rates compared to expert judgments. This study\ncontributes to the field by demonstrating the potential of AI models like\nChatGPT to enhance automated content moderation systems while also identifying\nareas for further improvement. The results underscore the importance of\ncontinuous model refinement and contextual understanding to better support\nautomated moderation and mitigate harmful online behavior.','Barbarestani Baran, Maks Isa, Vossen Piek','2025-05-27','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.21710v1','本研究评估了ChatGPT在识别在线评论中的针对性和不当语言方面的效果。通过与众包注释和专家评估进行比较，评估了ChatGPT的性能，结果表明ChatGPT在检测不当内容方面表现良好，但在针对性语言检测方面表现不稳定。'),('2505.21715v1','Privacy-Preserving Chest X-ray Report Generation via Multimodal Federated Learning with ViT and GPT-2','The automated generation of radiology reports from chest X-ray images holds\nsignificant promise in enhancing diagnostic workflows while preserving patient\nprivacy. Traditional centralized approaches often require sensitive data\ntransfer, posing privacy concerns. To address this, the study proposes a\nMultimodal Federated Learning framework for chest X-ray report generation using\nthe IU-Xray dataset. The system utilizes a Vision Transformer (ViT) as the\nencoder and GPT-2 as the report generator, enabling decentralized training\nwithout sharing raw data. Three Federated Learning (FL) aggregation strategies:\nFedAvg, Krum Aggregation and a novel Loss-aware Federated Averaging (L-FedAvg)\nwere evaluated. Among these, Krum Aggregation demonstrated superior performance\nacross lexical and semantic evaluation metrics such as ROUGE, BLEU, BERTScore\nand RaTEScore. The results show that FL can match or surpass centralized models\nin generating clinically relevant and semantically rich radiology reports. This\nlightweight and privacy-preserving framework paves the way for collaborative\nmedical AI development without compromising data confidentiality.','Md. Zahid Hossain, Mustofa Ahmed, Most. Sharmin Sultana Samu, Md. Rakibul Islam','2025-05-27','eess.IV','自然语言处理','http://arxiv.org/pdf/2505.21715v1','该论文提出了一种基于多模态联邦学习的框架，用于从胸部X射线图像生成放射学报告，采用了Vision Transformer（ViT）作为编码器和GPT-2作为报告生成器。通过评估三种联邦学习聚合策略，结果表明Krum Aggregation在词汇和语义评估指标上表现优异。研究结果显示，联邦学习可以在生成临床相关和语义丰富的放射学报告方面与集中式模型相匹敌甚至超越。'),('2505.21717v1','Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling','We present LrcSSM, a \\textit{nonlinear} recurrent model that processes long\nsequences as fast as today\\\'s linear state-space layers. By forcing the\nstate-transition matrix to be diagonal and learned at every step, the full\nsequence can be solved in parallel with a single prefix-scan, giving\n$\\mathcal{O}(TD)$ time and memory and only $\\mathcal{O}(\\log T)$ sequential\ndepth, for input-sequence length $T$ and a state dimension $D$. Moreover,\nLrcSSM offers a formal gradient-stability guarantee that other input-varying\nsystems such as Liquid-S4 and Mamba do not provide. Lastly, for network depth\n$L$, as the forward and backward passes cost $\\Theta(T\\,D\\,L)$ FLOPs, with its\nlow sequential depth and parameter count $\\Theta(D\\,L)$, the model follows the\ncompute-optimal scaling law regime ($\\beta \\approx 0.42$) recently observed for\nMamba, outperforming quadratic-attention Transformers at equal compute while\navoiding the memory overhead of FFT-based long convolutions. We show that on a\nseries of long-range forecasting tasks, LrcSSM outperforms LRU, S5 and Mamba.','Mónika Farsang, Ramin Hasani, Radu Grosu','2025-05-27','cs.LG','LLM','http://arxiv.org/pdf/2505.21717v1','该论文介绍了一种名为LrcSSM的非线性循环模型，能够以与当前线性状态空间层相同的速度处理长序列。通过强制状态转移矩阵为对角线并在每一步学习，可以并行解决整个序列，具有较低的时间和内存复杂度，以及较低的顺序深度。此外，LrcSSM提供了其他输入变化系统不提供的形式梯度稳定性保证。在一系列长程预测任务中，LrcSSM表现优于LRU、S5和Mamba。'),('2505.21720v1','Responsible Data Stewardship: Generative AI and the Digital Waste Problem','As generative AI systems become widely adopted, they enable unprecedented\ncreation levels of synthetic data across text, images, audio, and video\nmodalities. While research has addressed the energy consumption of model\ntraining and inference, a critical sustainability challenge remains\nunderstudied: digital waste. This term refers to stored data that consumes\nresources without serving a specific (and/or immediate) purpose. This paper\npresents this terminology in the AI context and introduces digital waste as an\nethical imperative within (generative) AI development, positioning\nenvironmental sustainability as core for responsible innovation. Drawing from\nestablished digital resource management approaches, we examine how other\ndisciplines manage digital waste and identify transferable approaches for the\nAI community. We propose specific recommendations encompassing re-search\ndirections, technical interventions, and cultural shifts to mitigate the\nenvironmental consequences of in-definite data storage. By expanding AI ethics\nbeyond immediate concerns like bias and privacy to include inter-generational\nenvironmental justice, this work contributes to a more comprehensive ethical\nframework that considers the complete lifecycle impact of generative AI\nsystems.','Vanessa Utz','2025-05-27','cs.CY','人工智能伦理、可持续发展','http://arxiv.org/pdf/2505.21720v1','该论文讨论了随着生成式人工智能系统的广泛采用，合成数据在文本、图像、音频和视频等模态上的创作水平空前增加。研究关注了模型训练和推断的能源消耗，但一个关键的可持续性挑战仍未得到充分研究：数字浪费。论文提出了数字浪费这一术语，并将其作为（生成式）人工智能发展中的道德义务，将环境可持续性定位为负责任创新的核心。'),('2505.21721v1','Nearly Dimension-Independent Convergence of Mean-Field Black-Box Variational Inference','We prove that, given a mean-field location-scale variational family,\nblack-box variational inference (BBVI) with the reparametrization gradient\nconverges at an almost dimension-independent rate. Specifically, for strongly\nlog-concave and log-smooth targets, the number of iterations for BBVI with a\nsub-Gaussian family to achieve an objective $\\epsilon$-close to the global\noptimum is $\\mathrm{O}(\\log d)$, which improves over the $\\mathrm{O}(d)$\ndependence of full-rank location-scale families. For heavy-tailed families, we\nprovide a weaker $\\mathrm{O}(d^{2/k})$ dimension dependence, where $k$ is the\nnumber of finite moments. Additionally, if the Hessian of the target\nlog-density is constant, the complexity is free of any explicit dimension\ndependence. We also prove that our bound on the gradient variance, which is key\nto our result, cannot be improved using only spectral bounds on the Hessian of\nthe target log-density.','Kyurae Kim, Yi-An Ma, Trevor Campbell, Jacob R. Gardner','2025-05-27','stat.ML','变分推断','http://arxiv.org/pdf/2505.21721v1','该论文证明了在给定均场位置-尺度变分族的情况下，使用重参数化梯度的黑盒变分推断（BBVI）以几乎与维度无关的速率收敛。具体来说，对于强对数凹和对数平滑目标，使用次高斯族的BBVI达到目标$\\epsilon$接近全局最优的迭代次数为$\\mathrm{O}(\\log d)$，这优于完整秩位置-尺度族的$\\mathrm{O}(d)$依赖性。对于重尾族，我们提供了一个较弱的$\\mathrm{O}(d^{2/k})$维度依赖性，其中$k$是有限矩的数量。此外，如果目标对数密度的Hessian是常数，则复杂度不受任何显式维度依赖性的影响。我们还证明了我们对梯度方差的界限，这对我们的结果至关重要，只能通过目标对数密度的Hessian的谱界来改进。'),('2505.21723v1','Are Statistical Methods Obsolete in the Era of Deep Learning?','In the era of AI, neural networks have become increasingly popular for\nmodeling, inference, and prediction, largely due to their potential for\nuniversal approximation. With the proliferation of such deep learning models, a\nquestion arises: are leaner statistical methods still relevant? To shed insight\non this question, we employ the mechanistic nonlinear ordinary differential\nequation (ODE) inverse problem as a testbed, using physics-informed neural\nnetwork (PINN) as a representative of the deep learning paradigm and\nmanifold-constrained Gaussian process inference (MAGI) as a representative of\nstatistically principled methods. Through case studies involving the SEIR model\nfrom epidemiology and the Lorenz model from chaotic dynamics, we demonstrate\nthat statistical methods are far from obsolete, especially when working with\nsparse and noisy observations. On tasks such as parameter inference and\ntrajectory reconstruction, statistically principled methods consistently\nachieve lower bias and variance, while using far fewer parameters and requiring\nless hyperparameter tuning. Statistical methods can also decisively outperform\ndeep learning models on out-of-sample future prediction, where the absence of\nrelevant data often leads overparameterized models astray. Additionally, we\nfind that statistically principled approaches are more robust to accumulation\nof numerical imprecision and can represent the underlying system more faithful\nto the true governing ODEs.','Skyler Wu, Shihao Yang, S. C. Kou','2025-05-27','stat.CO','统计方法在AI中的应用','http://arxiv.org/pdf/2505.21723v1','该论文通过比较深度学习模型和统计方法在解决非线性常微分方程逆问题时的表现，发现在处理稀疏和嘈杂观测数据时，统计方法在参数推断、轨迹重建和未来预测等任务上具有更低的偏差和方差，同时使用更少的参数和需要更少的超参数调整。'),('2505.21724v1','OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions','In this paper, we introduce Online Multimodal Conversational Response\nGeneration (OMCRG), a novel task that aims to online generate synchronized\nverbal and non-verbal listener feedback, conditioned on the speaker\\\'s\nmultimodal input. OMCRG reflects natural dyadic interactions and poses new\nchallenges in achieving synchronization between the generated audio and facial\nresponses of the listener. To address these challenges, we innovatively\nintroduce text as an intermediate modality to bridge the audio and facial\nresponses. We hence propose OmniResponse, a Multimodal Large Language Model\n(MLLM) that autoregressively generates high-quality multi-modal listener\nresponses. OmniResponse leverages a pretrained LLM enhanced with two novel\ncomponents: Chrono-Text, which temporally anchors generated text tokens, and\nTempoVoice, a controllable online TTS module that produces speech synchronized\nwith facial reactions. To support further OMCRG research, we present\nResponseNet, a new dataset comprising 696 high-quality dyadic interactions\nfeaturing synchronized split-screen videos, multichannel audio, transcripts,\nand facial behavior annotations. Comprehensive evaluations conducted on\nResponseNet demonstrate that OmniResponse significantly outperforms baseline\nmodels in terms of semantic speech content, audio-visual synchronization, and\ngeneration quality.','Cheng Luo, Jianghui Wang, Bing Li, Siyang Song, Bernard Ghanem','2025-05-27','cs.CV','自然语言处理','http://arxiv.org/pdf/2505.21724v1','本文介绍了在线多模态对话响应生成（OMCRG）这一新颖任务，旨在在线生成基于说话者多模态输入的同步语言和非语言听众反馈。为了解决这些挑战，作者创新地引入文本作为中间模态，提出了OmniResponse，一个自回归生成高质量多模态听众响应的MLLM模型。'),('2505.21731v1','Deep Reinforcement Learning Agents are not even close to Human Intelligence','Deep reinforcement learning (RL) agents achieve impressive results in a wide\nvariety of tasks, but they lack zero-shot adaptation capabilities. While most\nrobustness evaluations focus on tasks complexifications, for which human also\nstruggle to maintain performances, no evaluation has been performed on tasks\nsimplifications. To tackle this issue, we introduce HackAtari, a set of task\nvariations of the Arcade Learning Environments. We use it to demonstrate that,\ncontrary to humans, RL agents systematically exhibit huge performance drops on\nsimpler versions of their training tasks, uncovering agents\\\' consistent\nreliance on shortcuts. Our analysis across multiple algorithms and\narchitectures highlights the persistent gap between RL agents and human\nbehavioral intelligence, underscoring the need for new benchmarks and\nmethodologies that enforce systematic generalization testing beyond static\nevaluation protocols. Training and testing in the same environment is not\nenough to obtain agents equipped with human-like intelligence.','Quentin Delfosse, Jannis Blüml, Fabian Tatai, Théo Vincent, Bjarne Gregori, Elisabeth Dillies, Jan Peters, Constantin Rothkopf, Kristian Kersting','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21731v1','本文研究了深度强化学习代理在任务简化情况下的表现，发现相比于人类，强化学习代理在简化任务上表现出明显的性能下降，揭示了代理系统性依赖捷径的特点。'),('2505.21732v1','LaX: Boosting Low-Rank Training of Foundation Models via Latent Crossing','Training foundation models such as ViTs and LLMs requires tremendous\ncomputing cost. Low-rank matrix or tensor factorization offers a\nparameter-efficient alternative, but often downgrades performance due to the\nrestricted parameter space. In this work, we introduce {\\textbf{Latent Crossing\n(LaX)}} -- a simple yet effective plug-and-play module that enhances the\ncapacity of low-rank models by enabling information flow across low-rank\nsubspaces. We extensively validate the benefits of LaX on pre-training tasks\nwith ViT-Base/Large and LLaMA-like models ranging from 60M to 1B parameters.\nLaX boosts low-rank model performance to match or exceed the full-rank\nbaselines while using 2-3\\(\\times\\) fewer parameters. When equipped with\nlow-rank adapters (i.e., LoRA) for fine-tuning LLaMA-7/13B, LaX consistently\nimproves performance on arithmetic and common sense reasoning tasks with\nnegligible cost.','Ruijie Zhang, Ziyue Liu, Zhengyang Wang, Zheng Zhang','2025-05-27','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21732v1','该论文介绍了一种名为Latent Crossing (LaX)的模块，通过在低秩模型之间启用信息流，增强了低秩模型的容量，从而在预训练任务中验证了LaX的好处。LaX提高了低秩模型的性能，使其与或超过完整秩基线，同时使用了2-3倍更少的参数。在配备低秩适配器（即LoRA）进行微调LLaMA-7/13B时，LaX在算术和常识推理任务上持续改善性能。'),('2505.21734v1','MIND-Stack: Modular, Interpretable, End-to-End Differentiability for Autonomous Navigation','Developing robust, efficient navigation algorithms is challenging. Rule-based\nmethods offer interpretability and modularity but struggle with learning from\nlarge datasets, while end-to-end neural networks excel in learning but lack\ntransparency and modularity. In this paper, we present MIND-Stack, a modular\nsoftware stack consisting of a localization network and a Stanley Controller\nwith intermediate human interpretable state representations and end-to-end\ndifferentiability. Our approach enables the upstream localization module to\nreduce the downstream control error, extending its role beyond state\nestimation. Unlike existing research on differentiable algorithms that either\nlack modules of the autonomous stack to span from sensor input to actuator\noutput or real-world implementation, MIND-Stack offers both capabilities. We\nconduct experiments that demonstrate the ability of the localization module to\nreduce the downstream control loss through its end-to-end differentiability\nwhile offering better performance than state-of-the-art algorithms. We showcase\nsim-to-real capabilities by deploying the algorithm on a real-world embedded\nautonomous platform with limited computation power and demonstrate simultaneous\ntraining of both the localization and controller towards one goal. While\nMIND-Stack shows good results, we discuss the incorporation of additional\nmodules from the autonomous navigation pipeline in the future, promising even\ngreater stability and performance in the next iterations of the framework.','Felix Jahncke, Johannes Betz','2025-05-27','cs.RO','强化学习','http://arxiv.org/pdf/2505.21734v1','本文提出了MIND-Stack，一个模块化软件堆栈，包括定位网络和Stanley控制器，具有中间的人类可解释状态表示和端到端的可微性。他们的方法使得上游定位模块能够减少下游控制误差，扩展了其在状态估计之外的作用。通过实验证明了定位模块通过端到端的可微性能够减少下游控制损失，并且比最先进的算法表现更好。'),('2505.21736v1','Moment kernels: a simple and scalable approach for equivariance to rotations and reflections in deep convolutional networks','The principle of translation equivariance (if an input image is translated an\noutput image should be translated by the same amount), led to the development\nof convolutional neural networks that revolutionized machine vision. Other\nsymmetries, like rotations and reflections, play a similarly critical role,\nespecially in biomedical image analysis, but exploiting these symmetries has\nnot seen wide adoption. We hypothesize that this is partially due to the\nmathematical complexity of methods used to exploit these symmetries, which\noften rely on representation theory, a bespoke concept in differential geometry\nand group theory. In this work, we show that the same equivariance can be\nachieved using a simple form of convolution kernels that we call ``moment\nkernels,\\\'\\\' and prove that all equivariant kernels must take this form. These\nare a set of radially symmetric functions of a spatial position $x$, multiplied\nby powers of the components of $x$ or the identity matrix. We implement\nequivariant neural networks using standard convolution modules, and provide\narchitectures to execute several biomedical image analysis tasks that depend on\nequivariance principles: classification (outputs are invariant under orthogonal\ntransforms), 3D image registration (outputs transform like a vector), and cell\nsegmentation (quadratic forms defining ellipses transform like a matrix).','Zachary Schlamowitz, Andrew Bennecke, Daniel J. Tward','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21736v1','该论文提出了一种简单的卷积核形式，称为“矩核”，用于实现旋转、反射等对称性，以解决生物医学图像分析中的问题。作者证明了所有等变核必须采用这种形式，并提供了应用于生物医学图像分析任务的网络架构。'),('2505.21740v1','Counterfactual Simulatability of LLM Explanations for Generation Tasks','LLMs can be unpredictable, as even slight alterations to the prompt can cause\nthe output to change in unexpected ways. Thus, the ability of models to\naccurately explain their behavior is critical, especially in high-stakes\nsettings. One approach for evaluating explanations is counterfactual\nsimulatability, how well an explanation allows users to infer the model\\\'s\noutput on related counterfactuals. Counterfactual simulatability has been\npreviously studied for yes/no question answering tasks. We provide a general\nframework for extending this method to generation tasks, using news\nsummarization and medical suggestion as example use cases. We find that while\nLLM explanations do enable users to better predict LLM outputs on\ncounterfactuals in the summarization setting, there is significant room for\nimprovement for medical suggestion. Furthermore, our results suggest that the\nevaluation for counterfactual simulatability may be more appropriate for\nskill-based tasks as opposed to knowledge-based tasks.','Marvin Limpijankit, Yanda Chen, Melanie Subbiah, Nicholas Deas, Kathleen McKeown','2025-05-27','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.21740v1','本文研究了如何评估语言生成模型的解释能力，特别是在高风险环境中的重要性。作者提出了一种评估解释能力的方法，即对反事实模拟性进行评估，并将该方法扩展到生成任务中，以新闻摘要和医疗建议为例。研究结果表明，在新闻摘要任务中，LLM的解释能够帮助用户更好地预测LLM在反事实情况下的输出，但在医疗建议任务中还有很大的改进空间。'),('2505.21742v1','What is Adversarial Training for Diffusion Models?','We answer the question in the title, showing that adversarial training (AT)\nfor diffusion models (DMs) fundamentally differs from classifiers: while AT in\nclassifiers enforces output invariance, AT in DMs requires equivariance to keep\nthe diffusion process aligned with the data distribution. AT is a way to\nenforce smoothness in the diffusion flow, improving robustness to outliers and\ncorrupted data. Unlike prior art, our method makes no assumptions about the\nnoise model and integrates seamlessly into diffusion training by adding random\nnoise, similar to randomized smoothing, or adversarial noise, akin to AT. This\nenables intrinsic capabilities such as handling noisy data, dealing with\nextreme variability such as outliers, preventing memorization, and improving\nrobustness. We rigorously evaluate our approach with proof-of-concept datasets\nwith known distributions in low- and high-dimensional space, thereby taking a\nperfect measure of errors; we further evaluate on standard benchmarks such as\nCIFAR-10, CelebA and LSUN Bedroom, showing strong performance under severe\nnoise, data corruption, and iterative adversarial attacks.','Briglia Maria Rosaria, Mujtaba Hussain Mirza, Giuseppe Lisanti, Iacopo Masi','2025-05-27','cs.CV','生成模型','http://arxiv.org/pdf/2505.21742v1','该论文研究了扩散模型中的对抗训练方法，与分类器中的对抗训练有根本区别，要求等变性以保持扩散过程与数据分布一致。通过在扩散流中强制实现平滑性，提高了对离群值和损坏数据的鲁棒性。'),('2505.21743v1','Simulating the Unseen: Crash Prediction Must Learn from What Did Not Happen','Traffic safety science has long been hindered by a fundamental data paradox:\nthe crashes we most wish to prevent are precisely those events we rarely\nobserve. Existing crash-frequency models and surrogate safety metrics rely\nheavily on sparse, noisy, and under-reported records, while even sophisticated,\nhigh-fidelity simulations undersample the long-tailed situations that trigger\ncatastrophic outcomes such as fatalities. We argue that the path to achieving\nVision Zero, i.e., the complete elimination of traffic fatalities and severe\ninjuries, requires a paradigm shift from traditional crash-only learning to a\nnew form of counterfactual safety learning: reasoning not only about what\nhappened, but also about the vast set of plausible yet perilous scenarios that\ncould have happened under slightly different circumstances. To operationalize\nthis shift, our proposed agenda bridges macro to micro. Guided by crash-rate\npriors, generative scene engines, diverse driver models, and causal learning,\nnear-miss events are synthesized and explained. A crash-focused digital twin\ntestbed links micro scenes to macro patterns, while a multi-objective validator\nensures that simulations maintain statistical realism. This pipeline transforms\nsparse crash data into rich signals for crash prediction, enabling the\nstress-testing of vehicles, roads, and policies before deployment. By learning\nfrom crashes that almost happened, we can shift traffic safety from reactive\nforensics to proactive prevention, advancing Vision Zero.','Zihao Li, Xinyuan Cao, Xiangbo Gao, Kexin Tian, Keshu Wu, Mohammad Anis, Hao Zhang, Keke Long, Jiwan Jiang, Xiaopeng Li, Yunlong Zhang, Tianbao Yang, Dominique Lord, Zhengzhong Tu, Yang Zhou','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21743v1','该论文提出了一种新的反事实安全学习方法，从传统的仅关注事故学习转变为同时考虑可能发生的危险情景，通过合成和解释几乎发生的事故事件来提高交通安全预测的准确性。'),('2505.21748v1','Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks','Complex systems are often driven by higher-order interactions among multiple\nunits, naturally represented as hypergraphs. Understanding dependency\nstructures within these hypergraphs is crucial for understanding and predicting\nthe behavior of complex systems but is made challenging by their combinatorial\ncomplexity and computational demands. In this paper, we introduce a class of\nprobabilistic models that efficiently represents and discovers a broad spectrum\nof mesoscale structure in large-scale hypergraphs. The key insight enabling\nthis approach is to treat classes of similar units as themselves nodes in a\nlatent hypergraph. By modeling observed node interactions through latent\ninteractions among classes using low-rank representations, our approach\ntractably captures rich structural patterns while ensuring model\nidentifiability. This allows for direct interpretation of distinct node- and\nclass-level structures. Empirically, our model improves link prediction over\nstate-of-the-art methods and discovers interpretable structures in diverse\nreal-world systems, including pharmacological and social networks, advancing\nthe ability to incorporate large-scale higher-order data into the scientific\nprocess.','John Hood, Caterina De Bacco, Aaron Schein','2025-05-27','cs.SI','图像识别','http://arxiv.org/pdf/2505.21748v1','本文介绍了一类概率模型，可以有效地表示和发现大规模超图中的多种中尺度结构。通过将相似单元类别视为潜在超图中的节点，并使用低秩表示来建模观察到的节点之间的相互作用，该方法可以捕捉丰富的结构模式，同时确保模型可识别性。在实证研究中，该模型在链接预测方面优于现有方法，并在包括药物和社交网络在内的不同现实世界系统中发现可解释的结构，推进了将大规模高阶数据纳入科学过程的能力。'),('2505.21750v1','Hierarchical Reinforcement Learning with Uncertainty-Guided Diffusional Subgoals','Hierarchical reinforcement learning (HRL) learns to make decisions on\nmultiple levels of temporal abstraction. A key challenge in HRL is that the\nlow-level policy changes over time, making it difficult for the high-level\npolicy to generate effective subgoals. To address this issue, the high-level\npolicy must capture a complex subgoal distribution while also accounting for\nuncertainty in its estimates. We propose an approach that trains a conditional\ndiffusion model regularized by a Gaussian Process (GP) prior to generate a\ncomplex variety of subgoals while leveraging principled GP uncertainty\nquantification. Building on this framework, we develop a strategy that selects\nsubgoals from both the diffusion policy and GP\\\'s predictive mean. Our approach\noutperforms prior HRL methods in both sample efficiency and performance on\nchallenging continuous control benchmarks.','Vivienne Huiling Wang, Tinghuai Wang, Joni Pajarinen','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21750v1','该论文提出了一种基于条件扩散模型和高斯过程先验的方法，用于生成复杂多样的子目标，同时利用高斯过程对不确定性进行建模。通过该方法，在连续控制基准测试中，提高了层次强化学习方法的样本效率和性能。'),('2505.21753v1','From prosthetic memory to prosthetic denial: Auditing whether large language models are prone to mass atrocity denialism','The proliferation of large language models (LLMs) can influence how\nhistorical narratives are disseminated and perceived. This study explores the\nimplications of LLMs\\\' responses on the representation of mass atrocity memory,\nexamining whether generative AI systems contribute to prosthetic memory, i.e.,\nmediated experiences of historical events, or to what we term \"prosthetic\ndenial,\" the AI-mediated erasure or distortion of atrocity memories. We argue\nthat LLMs function as interfaces that can elicit prosthetic memories and,\ntherefore, act as experiential sites for memory transmission, but also\nintroduce risks of denialism, particularly when their outputs align with\ncontested or revisionist narratives. To empirically assess these risks, we\nconducted a comparative audit of five LLMs (Claude, GPT, Llama, Mixtral, and\nGemini) across four historical case studies: the Holodomor, the Holocaust, the\nCambodian Genocide, and the genocide against the Tutsis in Rwanda. Each model\nwas prompted with questions addressing common denialist claims in English and\nan alternative language relevant to each case (Ukrainian, German, Khmer, and\nFrench). Our findings reveal that while LLMs generally produce accurate\nresponses for widely documented events like the Holocaust, significant\ninconsistencies and susceptibility to denialist framings are observed for more\nunderrepresented cases like the Cambodian Genocide. The disparities highlight\nthe influence of training data availability and the probabilistic nature of LLM\nresponses on memory integrity. We conclude that while LLMs extend the concept\nof prosthetic memory, their unmoderated use risks reinforcing historical\ndenialism, raising ethical concerns for (digital) memory preservation, and\npotentially challenging the advantageous role of technology associated with the\noriginal values of prosthetic memory.','Roberto Ulloa, Eve M. Zucker, Daniel Bultmann, David J. Simon, Mykola Makhortykh','2025-05-27','cs.CY','LLM、历史记忆表征、伦理问题','http://arxiv.org/pdf/2505.21753v1','本研究探讨了大型语言模型（LLMs）对大规模暴行记忆表征的影响，研究了生成AI系统对假体记忆和假体否认的影响。通过对五种LLMs在四个历史案例中的表现进行比较审计，发现虽然对于广泛记录的事件（如大屠杀）LLMs通常产生准确的回应，但对于较少被提及的事件（如柬埔寨大屠杀）存在显著的不一致性和易受否认主义框架的影响。'),('2505.21755v1','FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering','Visual question answering (VQA) systems face significant challenges when\nadapting to real-world data shifts, especially in multi-modal contexts. While\nrobust fine-tuning strategies are essential for maintaining performance across\nin-distribution (ID) and out-of-distribution (OOD) scenarios, current\nevaluation settings are primarily unimodal or particular to some types of OOD,\noffering limited insight into the complexities of multi-modal contexts. In this\nwork, we propose a new benchmark FRAMES-VQA (Fine-Tuning Robustness across\nMulti-Modal Shifts in VQA) for evaluating robust fine-tuning for VQA tasks. We\nutilize ten existing VQA benchmarks, including VQAv2, IV-VQA, VQA-CP, OK-VQA\nand others, and categorize them into ID, near and far OOD datasets covering\nuni-modal, multi-modal and adversarial distribution shifts. We first conduct a\ncomprehensive comparison of existing robust fine-tuning methods. We then\nquantify the distribution shifts by calculating the Mahalanobis distance using\nuni-modal and multi-modal embeddings extracted from various models. Further, we\nperform an extensive analysis to explore the interactions between uni- and\nmulti-modal shifts as well as modality importance for ID and OOD samples. These\nanalyses offer valuable guidance on developing more robust fine-tuning methods\nto handle multi-modal distribution shifts. The code is available at\nhttps://github.com/chengyuehuang511/FRAMES-VQA .','Chengyue Huang, Brisa Maneechotesuwan, Shivang Chopra, Zsolt Kira','2025-05-27','cs.CV','图像识别','http://arxiv.org/pdf/2505.21755v1','该论文提出了一个新的基准 FRAMES-VQA，用于评估视觉问答任务中的鲁棒微调性能，特别是在多模态环境下。他们比较了现有的鲁棒微调方法，通过计算马氏距离来量化分布偏移，并进行了广泛分析以探索单模态和多模态偏移之间的相互作用以及模态重要性。'),('2505.21757v1','BehaviorSFT: Behavioral Token Conditioning for Clinical Agents Across the Proactivity Spectrum','Large Language Models (LLMs) as clinical agents require careful behavioral\nadaptation. While adept at reactive tasks (e.g., diagnosis reasoning), LLMs\noften struggle with proactive engagement, like unprompted identification of\ncritical missing information or risks. We introduce BehaviorBench, a\ncomprehensive dataset to evaluate agent behaviors across a clinical assistance\nspectrum, ranging from reactive query responses to proactive interventions\n(e.g., clarifying ambiguities, flagging overlooked critical data). Our\nBehaviorBench experiments reveal LLMs\\\' inconsistent proactivity. To address\nthis, we propose BehaviorSFT, a novel training strategy using behavioral tokens\nto explicitly condition LLMs for dynamic behavioral selection along this\nspectrum. BehaviorSFT boosts performance, achieving up to 97.3% overall Macro\nF1 on BehaviorBench and improving proactive task scores (e.g., from 95.0% to\n96.5% for Qwen2.5-7B-Ins). Crucially, blind clinician evaluations confirmed\nBehaviorSFT-trained agents exhibit more realistic clinical behavior, striking a\nsuperior balance between helpful proactivity (e.g., timely, relevant\nsuggestions) and necessary restraint (e.g., avoiding over-intervention) versus\nstandard fine-tuning or explicit instructed agents.','Yubin Kim, Zhiyuan Hu, Hyewon Jeong, Eugene Park, Shuyue Stella Li, Chanwoo Park, Shiyun Xiong, MingYu Lu, Hyeonhoon Lee, Xin Liu, Daniel McDuff, Cynthia Breazeal, Samir Tulebaev, Hae Won Park','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21757v1','该论文介绍了一种新的训练策略 BehaviorSFT，旨在提高大型语言模型在临床辅助任务中的主动性表现。通过 BehaviorBench 实验，发现LLMs在主动性方面存在不一致性。BehaviorSFT训练策略可以显著提高模型性能，并在临床行为方面取得更好的平衡。'),('2505.21765v1','Don\\\'t Think Longer, Think Wisely: Optimizing Thinking Dynamics for Large Reasoning Models','While recent success of large reasoning models (LRMs) significantly advanced\nLLMs\\\' reasoning capability by optimizing the final answer accuracy using\nreinforcement learning, they may also drastically increase the output length\ndue to overthinking, characterized by unnecessarily complex reasoning paths\nthat waste computation and potentially degrade the performance. We hypothesize\nthat such inefficiencies stem from LRMs\\\' limited capability to dynamically\nselect the proper modular reasoning strategies, termed thinking patterns at the\nright position. To investigate this hypothesis, we propose a dynamic\noptimization framework that segments model-generated reasoning paths into\ndistinct thinking patterns, systematically identifying and promoting beneficial\npatterns that improve the answer while removing detrimental ones. Empirical\nanalysis confirms that our optimized thinking paths yield more concise yet\nsufficiently informative trajectories, enhancing reasoning efficiency by\nreducing attention FLOPs by up to 47% while maintaining accuracy for originally\ncorrect responses. Moreover, a non-trivial portion of originally incorrect\nresponses are transformed into correct ones, achieving a 15.6% accuracy\nimprovement with reduced length. Motivated by the improvement brought by the\noptimized thinking paths, we apply a preference optimization technique\nsupported by a pairwise dataset contrasting suboptimal and optimal reasoning\npaths. Experimental evaluations across multiple mathematical reasoning\nbenchmarks reveal that our method notably reduces computational overhead while\nsimultaneously improving reasoning accuracy, achieving up to a 12% accuracy\nimprovement and reducing token usage from approximately 5,000 to 3,000 tokens.','Sohyun An, Ruochen Wang, Tianyi Zhou, Cho-Jui Hsieh','2025-05-27','cs.AI','LLM (大型逻辑推理模型)','http://arxiv.org/pdf/2505.21765v1','该论文提出了一种动态优化框架，将模型生成的推理路径分割成不同的思维模式，系统地识别和促进有益的模式，同时消除有害的模式。经验分析表明，优化后的思维路径产生了更简洁但足够信息的轨迹，通过减少注意力 FLOPs 高达 47%，同时保持原始正确响应的准确性。此外，一部分原本不正确的响应被转化为正确的响应，准确率提高了 15.6%，长度减少。'),('2505.21767v1','Beyond 1D: Vision Transformers and Multichannel Signal Images for PPG-to-ECG Reconstruction','Reconstructing ECG from PPG is a promising yet challenging task. While recent\nadvancements in generative models have significantly improved ECG\nreconstruction, accurately capturing fine-grained waveform features remains a\nkey challenge. To address this, we propose a novel PPG-to-ECG reconstruction\nmethod that leverages a Vision Transformer (ViT) as the core network. Unlike\nconventional approaches that rely on single-channel PPG, our method employs a\nfour-channel signal image representation, incorporating the original PPG, its\nfirst-order difference, second-order difference, and area under the curve. This\nmulti-channel design enriches feature extraction by preserving both temporal\nand physiological variations within the PPG. By leveraging the self-attention\nmechanism in ViT, our approach effectively captures both inter-beat and\nintra-beat dependencies, leading to more robust and accurate ECG\nreconstruction. Experimental results demonstrate that our method consistently\noutperforms existing 1D convolution-based approaches, achieving up to 29%\nreduction in PRD and 15% reduction in RMSE. The proposed approach also produces\nimprovements in other evaluation metrics, highlighting its robustness and\neffectiveness in reconstructing ECG signals. Furthermore, to ensure a\nclinically relevant evaluation, we introduce new performance metrics, including\nQRS area error, PR interval error, RT interval error, and RT amplitude\ndifference error. Our findings suggest that integrating a four-channel signal\nimage representation with the self-attention mechanism of ViT enables more\neffective extraction of informative PPG features and improved modeling of\nbeat-to-beat variations for PPG-to-ECG mapping. Beyond demonstrating the\npotential of PPG as a viable alternative for heart activity monitoring, our\napproach opens new avenues for cyclic signal analysis and prediction.','Xiaoyan Li, Shixin Xu, Faisal Habib, Arvind Gupta, Huaxiong Huang','2025-05-27','eess.IV','生成模型','http://arxiv.org/pdf/2505.21767v1','该论文提出了一种新颖的基于Vision Transformer (ViT) 的PPG到ECG重建方法，采用四通道信号图像表示，结合了原始PPG、一阶差分、二阶差分和曲线下面积，利用ViT的自注意机制有效捕捉了节拍间和节拍内的依赖关系，实现了更准确的ECG重建，实验结果表明该方法在性能上优于现有的基于1D卷积的方法。'),('2505.21771v1','MMTBENCH: A Unified Benchmark for Complex Multimodal Table Reasoning','Multimodal tables those that integrate semi structured data with visual\nelements such as charts and maps are ubiquitous across real world domains, yet\nthey pose a formidable challenge to current vision language models (VLMs).\nWhile Large Language models (LLMs) and VLMs have demonstrated strong\ncapabilities in text and image understanding, their performance on complex,\nreal world multimodal table reasoning remains unexplored. To bridge this gap,\nwe introduce MMTBENCH (Multimodal Table Benchmark), a benchmark consisting of\n500 real world multimodal tables drawn from diverse real world sources, with a\ntotal of 4021 question answer pairs. MMTBENCH questions cover four question\ntypes (Explicit, Implicit, Answer Mention, and Visual Based), five reasoning\ntypes (Mathematical, Extrema Identification, Fact Verification, Vision Based,\nand Others), and eight table types (Single/Multiple Entity, Maps and Charts\nwith Entities, Single/Multiple Charts, Maps, and Visualizations). Extensive\nevaluation of state of the art models on all types reveals substantial\nperformance gaps, particularly on questions requiring visual-based reasoning\nand multi-step inference. These findings show the urgent need for improved\narchitectures that more tightly integrate vision and language processing. By\nproviding a challenging, high-quality resource that mirrors the complexity of\nreal-world tasks, MMTBENCH underscores its value as a resource for future\nresearch on multimodal tables.','Prasham Yatinkumar Titiya, Jainil Trivedi, Chitta Baral, Vivek Gupta','2025-05-27','cs.CV','多模态学习','http://arxiv.org/pdf/2505.21771v1','该论文介绍了一个名为MMTBENCH的多模态表格基准，包括500个来自不同领域的真实世界多模态表格和4021个问题答案对。研究发现目前的语言模型在复杂的多模态表格推理方面表现不佳，特别是对需要视觉推理和多步推理的问题。'),('2505.21772v1','Calibrating LLM Confidence by Probing Perturbed Representation Stability','Miscalibration in Large Language Models (LLMs) undermines their reliability,\nhighlighting the need for accurate confidence estimation. We introduce CCPS\n(Calibrating LLM Confidence by Probing Perturbed Representation Stability), a\nnovel method analyzing internal representational stability in LLMs. CCPS\napplies targeted adversarial perturbations to final hidden states, extracts\nfeatures reflecting the model\\\'s response to these perturbations, and uses a\nlightweight classifier to predict answer correctness. CCPS was evaluated on\nLLMs from 8B to 32B parameters (covering Llama, Qwen, and Mistral\narchitectures) using MMLU and MMLU-Pro benchmarks in both multiple-choice and\nopen-ended formats. Our results show that CCPS significantly outperforms\ncurrent approaches. Across four LLMs and three MMLU variants, CCPS reduces\nExpected Calibration Error by approximately 55% and Brier score by 21%, while\nincreasing accuracy by 5 percentage points, Area Under the Precision-Recall\nCurve by 4 percentage points, and Area Under the Receiver Operating\nCharacteristic Curve by 6 percentage points, all relative to the strongest\nprior method. CCPS delivers an efficient, broadly applicable, and more accurate\nsolution for estimating LLM confidence, thereby improving their\ntrustworthiness.','Reza Khanmohammadi, Erfan Miahi, Mehrsa Mardikoraem, Simerjot Kaur, Ivan Brugere, Charese H. Smiley, Kundan Thind, Mohammad M. Ghassemi','2025-05-27','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21772v1','该论文介绍了一种名为CCPS的新方法，通过分析LLMs内部表示的稳定性来校准其置信度，结果显示CCPS在估计LLMs置信度方面显著优于当前方法。'),('2505.21775v1','DualSchool: How Reliable are LLMs for Optimization Education?','Consider the following task taught in introductory optimization courses which\naddresses challenges articulated by the community at the intersection of\n(generative) AI and OR: generate the dual of a linear program. LLMs, being\ntrained at web-scale, have the conversion process and many instances of Primal\nto Dual Conversion (P2DC) at their disposal. Students may thus reasonably\nexpect that LLMs would perform well on the P2DC task. To assess this\nexpectation, this paper introduces DualSchool, a comprehensive framework for\ngenerating and verifying P2DC instances. The verification procedure of\nDualSchool uses the Canonical Graph Edit Distance, going well beyond existing\nevaluation methods for optimization models, which exhibit many false positives\nand negatives when applied to P2DC. Experiments performed by DualSchool reveal\ninteresting findings. Although LLMs can recite the conversion procedure\naccurately, state-of-the-art open LLMs fail to consistently produce correct\nduals. This finding holds even for the smallest two-variable instances and for\nderivative tasks, such as correctness, verification, and error classification.\nThe paper also discusses the implications for educators, students, and the\ndevelopment of large reasoning systems.','Michael Klamkin, Arnaud Deza, Sikai Cheng, Haoruo Zhao, Pascal Van Hentenryck','2025-05-27','cs.LG','LLM（大规模语言模型）','http://arxiv.org/pdf/2505.21775v1','该论文研究了使用LLMs生成线性规划的对偶问题，并介绍了DualSchool框架来评估LLMs在这一任务上的表现。实验结果表明，尽管LLMs可以准确地背诵转换过程，但目前的开放LLMs在生成正确的对偶问题上存在问题。'),('2505.21777v1','Memorization to Generalization: Emergence of Diffusion Models from Associative Memory','Hopfield networks are associative memory (AM) systems, designed for storing\nand retrieving patterns as local minima of an energy landscape. In the\nclassical Hopfield model, an interesting phenomenon occurs when the amount of\ntraining data reaches its critical memory load $- spurious\\,\\,states$, or\nunintended stable points, emerge at the end of the retrieval dynamics, leading\nto incorrect recall. In this work, we examine diffusion models, commonly used\nin generative modeling, from the perspective of AMs. The training phase of\ndiffusion model is conceptualized as memory encoding (training data is stored\nin the memory). The generation phase is viewed as an attempt of memory\nretrieval. In the small data regime the diffusion model exhibits a strong\nmemorization phase, where the network creates distinct basins of attraction\naround each sample in the training set, akin to the Hopfield model below the\ncritical memory load. In the large data regime, a different phase appears where\nan increase in the size of the training set fosters the creation of new\nattractor states that correspond to manifolds of the generated samples.\nSpurious states appear at the boundary of this transition and correspond to\nemergent attractor states, which are absent in the training set, but, at the\nsame time, have distinct basins of attraction around them. Our findings\nprovide: a novel perspective on the memorization-generalization phenomenon in\ndiffusion models via the lens of AMs, theoretical prediction of existence of\nspurious states, empirical validation of this prediction in commonly-used\ndiffusion models.','Bao Pham, Gabriel Raya, Matteo Negri, Mohammed J. Zaki, Luca Ambrogioni, Dmitry Krotov','2025-05-27','cs.LG','生成模型','http://arxiv.org/pdf/2505.21777v1','本文研究了扩散模型在关联记忆系统中的应用，将训练阶段视为记忆编码，生成阶段视为记忆检索。在小数据情况下，扩散模型表现出强烈的记忆化阶段，类似于Hopfield模型。在大数据情况下，新的吸引子状态出现，并在过渡边界处出现虚假状态。'),('2505.21781v1','GMU Systems for the IWSLT 2025 Low-Resource Speech Translation Shared Task','This paper describes the GMU systems for the IWSLT 2025 low-resource speech\ntranslation shared task. We trained systems for all language pairs, except for\nLevantine Arabic. We fine-tuned SeamlessM4T-v2 for automatic speech recognition\n(ASR), machine translation (MT), and end-to-end speech translation (E2E ST).\nThe ASR and MT models are also used to form cascaded ST systems. Additionally,\nwe explored various training paradigms for E2E ST fine-tuning, including direct\nE2E fine-tuning, multi-task training, and parameter initialization using\ncomponents from fine-tuned ASR and/or MT models. Our results show that (1)\ndirect E2E fine-tuning yields strong results; (2) initializing with a\nfine-tuned ASR encoder improves ST performance on languages SeamlessM4T-v2 has\nnot been trained on; (3) multi-task training can be slightly helpful.','Chutong Meng, Antonios Anastasopoulos','2025-05-27','cs.CL','语音处理','http://arxiv.org/pdf/2505.21781v1','本文描述了GMU系统在IWSLT 2025低资源语音翻译共享任务中的表现。他们对所有语言对进行了系统训练，除了黎凡特阿拉伯语。他们对SeamlessM4T-v2进行了自动语音识别（ASR）、机器翻译（MT）和端到端语音翻译（E2E ST）的微调。他们的结果表明直接E2E微调效果很好，使用微调的ASR编码器初始化可以提高ST性能，多任务训练略有帮助。'),('2505.21783v1','P-DROP: Poisson-Based Dropout for Graph Neural Networks','Over-smoothing remains a major challenge in Graph Neural Networks (GNNs),\nwhere repeated message passing causes node representations to converge and lose\ndiscriminative power. To address this, we propose a novel node selection\nstrategy based on Poisson processes, introducing stochastic but structure-aware\nupdates. Specifically, we equip each node with an independent Poisson clock,\nenabling asynchronous and localized updates that preserve structural diversity.\nWe explore two applications of this strategy: as a replacement for\ndropout-based regularization and as a dynamic subgraph training scheme.\nExperimental results on standard benchmarks (Cora, Citeseer, Pubmed)\ndemonstrate that our Poisson-based method yields competitive or improved\naccuracy compared to traditional Dropout, DropEdge, and DropNode approaches,\nparticularly in later training stages.','Hyunsik Yun','2025-05-27','cs.LG','图神经网络','http://arxiv.org/pdf/2505.21783v1','该论文提出了一种基于泊松过程的节点选择策略，用于解决图神经网络中过度平滑的问题。通过引入随机但结构感知的更新，实现了异步和局部化更新，从而保留了结构多样性。实验结果表明，该方法在标准基准数据集上的表现优于传统的Dropout、DropEdge和DropNode方法。'),('2505.21784v1','Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation','Safety reasoning is a recent paradigm where LLMs reason over safety policies\nbefore generating responses, thereby mitigating limitations in existing safety\nmeasures such as over-refusal and jailbreak vulnerabilities. However,\nimplementing this paradigm is challenging due to the resource-intensive process\nof creating high-quality policy-embedded chain-of-thought (CoT) datasets while\nensuring reasoning remains accurate and free from hallucinations or policy\nconflicts. To tackle this, we propose AIDSAFE: Agentic Iterative Deliberation\nfor Safety Reasoning, a novel data generation recipe that leverages multi-agent\ndeliberation to iteratively expand reasoning on safety policies. A data refiner\nstage in AIDSAFE ensures high-quality outputs by eliminating repetitive,\nredundant, and deceptive thoughts. AIDSAFE-generated CoTs provide a strong\nfoundation for supervised fine-tuning (SFT)-based safety training.\nAdditionally, to address the need of preference data in alignment stages, such\nas DPO training, we introduce a supplemental recipe that uses belief\naugmentation to create distinct selected and rejected CoT samples. Our\nevaluations demonstrate that AIDSAFE-generated CoTs achieve superior policy\nadherence and reasoning quality. Consequently, we show that fine-tuning\nopen-source LLMs on these CoTs can significantly improve safety generalization\nand jailbreak robustness while maintaining acceptable utility and over-refusal\naccuracy. AIDSAFE-generated CoT datasets can be found here:\nhttps://huggingface.co/datasets/AmazonScience/AIDSAFE','Tharindu Kumarage, Ninareh Mehrabi, Anil Ramakrishna, Xinyan Zhao, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta, Charith Peris','2025-05-27','cs.AI','LLM（大型语言模型）','http://arxiv.org/pdf/2505.21784v1','该论文提出了一种名为AIDSAFE的新型数据生成方法，利用多智能体协商来迭代扩展对安全策略的推理，以解决现有安全措施的局限性。通过消除重复、冗余和欺骗性思考，AIDSAFE生成的CoT数据集为基于监督微调的安全训练提供了坚实基础。'),('2505.21785v1','Born a Transformer -- Always a Transformer?','Transformers have theoretical limitations in modeling certain\nsequence-to-sequence tasks, yet it remains largely unclear if these limitations\nplay a role in large-scale pretrained LLMs, or whether LLMs might effectively\novercome these constraints in practice due to the scale of both the models\nthemselves and their pretraining data. We explore how these architectural\nconstraints manifest after pretraining, by studying a family of\n$\\textit{retrieval}$ and $\\textit{copying}$ tasks inspired by Liu et al.\n[2024]. We use the recently proposed C-RASP framework for studying length\ngeneralization [Huang et al., 2025b] to provide guarantees for each of our\nsettings. Empirically, we observe an $\\textit{induction-versus-anti-induction}$\nasymmetry, where pretrained models are better at retrieving tokens to the right\n(induction) rather than the left (anti-induction) of a query token. This\nasymmetry disappears upon targeted fine-tuning if length-generalization is\nguaranteed by theory. Mechanistic analysis reveals that this asymmetry is\nconnected to the differences in the strength of induction versus anti-induction\ncircuits within pretrained Transformers. We validate our findings through\npractical experiments on real-world tasks demonstrating reliability risks. Our\nresults highlight that pretraining selectively enhances certain Transformer\ncapabilities, but does not overcome fundamental length-generalization limits.','Yana Veitsman, Mayank Jobanputra, Yash Sarrof, Aleksandra Bakalova, Vera Demberg, Ellie Pavlick, Michael Hahn','2025-05-27','cs.LG','LLM (Large Language Model)','http://arxiv.org/pdf/2505.21785v1','本文研究了Transformer在建模某些序列到序列任务中存在的理论限制，探讨了大规模预训练LLM是否能够在实践中有效地克服这些限制。通过研究一系列受Liu等人启发的检索和复制任务，作者发现预训练模型在检索右侧标记（归纳）方面表现更好，而在左侧标记（反归纳）方面表现较差，这种不对称性在理论保证下的有针对性微调后消失。'),('2505.21786v1','VeriTrail: Closed-Domain Hallucination Detection with Traceability','Even when instructed to adhere to source material, Language Models often\ngenerate unsubstantiated content - a phenomenon known as \"closed-domain\nhallucination.\" This risk is amplified in processes with multiple generative\nsteps (MGS), compared to processes with a single generative step (SGS).\nHowever, due to the greater complexity of MGS processes, we argue that\ndetecting hallucinations in their final outputs is necessary but not\nsufficient: it is equally important to trace where hallucinated content was\nlikely introduced and how faithful content may have been derived from the\nsource through intermediate outputs. To address this need, we present\nVeriTrail, the first closed-domain hallucination detection method designed to\nprovide traceability for both MGS and SGS processes. We also introduce the\nfirst datasets to include all intermediate outputs as well as human annotations\nof final outputs\\\' faithfulness for their respective MGS processes. We\ndemonstrate that VeriTrail outperforms baseline methods on both datasets.','Dasha Metropolitansky, Jonathan Larson','2025-05-27','cs.CL','语言模型（LLM）','http://arxiv.org/pdf/2505.21786v1','该论文提出了一种闭域幻觉检测方法VeriTrail，旨在追踪多生成步骤和单生成步骤过程中幻觉内容的来源，并介绍了相应的数据集。实验证明VeriTrail在这两个数据集上优于基线方法。'),('2505.21790v1','Faster Rates for Private Adversarial Bandits','We design new differentially private algorithms for the problems of\nadversarial bandits and bandits with expert advice. For adversarial bandits, we\ngive a simple and efficient conversion of any non-private bandit algorithm to a\nprivate bandit algorithm. Instantiating our conversion with existing\nnon-private bandit algorithms gives a regret upper bound of\n$O\\left(\\frac{\\sqrt{KT}}{\\sqrt{\\epsilon}}\\right)$, improving upon the existing\nupper bound $O\\left(\\frac{\\sqrt{KT \\log(KT)}}{\\epsilon}\\right)$ for all\n$\\epsilon \\leq 1$. In particular, our algorithms allow for sublinear expected\nregret even when $\\epsilon \\leq \\frac{1}{\\sqrt{T}}$, establishing the first\nknown separation between central and local differential privacy for this\nproblem. For bandits with expert advice, we give the first differentially\nprivate algorithms, with expected regret\n$O\\left(\\frac{\\sqrt{NT}}{\\sqrt{\\epsilon}}\\right),\nO\\left(\\frac{\\sqrt{KT\\log(N)}\\log(KT)}{\\epsilon}\\right)$, and\n$\\tilde{O}\\left(\\frac{N^{1/6}K^{1/2}T^{2/3}\\log(NT)}{\\epsilon ^{1/3}} +\n\\frac{N^{1/2}\\log(NT)}{\\epsilon}\\right)$, where $K$ and $N$ are the number of\nactions and experts respectively. These rates allow us to get sublinear regret\nfor different combinations of small and large $K, N$ and $\\epsilon.$','Hilal Asi, Vinod Raman, Kunal Talwar','2025-05-27','cs.LG','强化学习','http://arxiv.org/pdf/2505.21790v1','该论文设计了新的差分隐私算法，用于解决对抗性赌博机和带有专家建议的赌博机问题。他们提供了简单高效的方法将非私有赌博算法转换为私有赌博算法，并在对抗性赌博机问题上取得了改进的遗憾上界。对于带有专家建议的赌博机问题，他们提出了首个差分隐私算法。'),('2505.21791v1','Global Minimizers of $\\ell^p$-Regularized Objectives Yield the Sparsest ReLU Neural Networks','Overparameterized neural networks can interpolate a given dataset in many\ndifferent ways, prompting the fundamental question: which among these solutions\nshould we prefer, and what explicit regularization strategies will provably\nyield these solutions? This paper addresses the challenge of finding the\nsparsest interpolating ReLU network -- i.e., the network with the fewest\nnonzero parameters or neurons -- a goal with wide-ranging implications for\nefficiency, generalization, interpretability, theory, and model compression.\nUnlike post hoc pruning approaches, we propose a continuous, almost-everywhere\ndifferentiable training objective whose global minima are guaranteed to\ncorrespond to the sparsest single-hidden-layer ReLU networks that fit the data.\nThis result marks a conceptual advance: it recasts the combinatorial problem of\nsparse interpolation as a smooth optimization task, potentially enabling the\nuse of gradient-based training methods. Our objective is based on minimizing\n$\\ell^p$ quasinorms of the weights for $0 < p < 1$, a classical\nsparsity-promoting strategy in finite-dimensional settings. However, applying\nthese ideas to neural networks presents new challenges: the function class is\ninfinite-dimensional, and the weights are learned using a highly nonconvex\nobjective. We prove that, under our formulation, global minimizers correspond\nexactly to sparsest solutions. Our work lays a foundation for understanding\nwhen and how continuous sparsity-inducing objectives can be leveraged to\nrecover sparse networks through training.','Julia Nakhleh, Robert D. Nowak','2025-05-27','stat.ML','神经网络/模型压缩/稀疏性训练','http://arxiv.org/pdf/2505.21791v1','本文研究了过参数化神经网络如何以最少的参数或神经元来插值给定数据集的问题，提出了一种连续、几乎处处可微的训练目标，其全局最小值保证对应于拟合数据的最稀疏的单隐藏层ReLU网络。这一结果将稀疏插值的组合问题重新构建为平滑优化任务，可能使得梯度下降训练方法得以应用。'),('2505.21792v1','Multimodal Federated Learning: A Survey through the Lens of Different FL Paradigms','Multimodal Federated Learning (MFL) lies at the intersection of two pivotal\nresearch areas: leveraging complementary information from multiple modalities\nto improve downstream inference performance and enabling distributed training\nto enhance efficiency and preserve privacy. Despite the growing interest in\nMFL, there is currently no comprehensive taxonomy that organizes MFL through\nthe lens of different Federated Learning (FL) paradigms. This perspective is\nimportant because multimodal data introduces distinct challenges across various\nFL settings. These challenges, including modality heterogeneity, privacy\nheterogeneity, and communication inefficiency, are fundamentally different from\nthose encountered in traditional unimodal or non-FL scenarios. In this paper,\nwe systematically examine MFL within the context of three major FL paradigms:\nhorizontal FL (HFL), vertical FL (VFL), and hybrid FL. For each paradigm, we\npresent the problem formulation, review representative training algorithms, and\nhighlight the most prominent challenge introduced by multimodal data in\ndistributed settings. We also discuss open challenges and provide insights for\nfuture research. By establishing this taxonomy, we aim to uncover the novel\nchallenges posed by multimodal data from the perspective of different FL\nparadigms and to offer a new lens through which to understand and advance the\ndevelopment of MFL.','Yuanzhe Peng, Jieming Bian, Lei Wang, Yin Huang, Jie Xu','2025-05-27','cs.LG','联邦学习','http://arxiv.org/pdf/2505.21792v1','该论文系统地研究了多模态联邦学习（MFL）在水平、垂直和混合三种联邦学习范式下的问题、方法和挑战，并提出了未来研究的方向。'),('2505.21799v1','PolarGrad: A Class of Matrix-Gradient Optimizers from a Unifying Preconditioning Perspective','The ever-growing scale of deep learning models and datasets underscores the\ncritical importance of efficient optimization methods. While preconditioned\ngradient methods such as Adam and AdamW are the de facto optimizers for\ntraining neural networks and large language models, structure-aware\npreconditioned optimizers like Shampoo and Muon, which utilize the matrix\nstructure of gradients, have demonstrated promising evidence of faster\nconvergence. In this paper, we introduce a unifying framework for analyzing\n\"matrix-aware\" preconditioned methods, which not only sheds light on the\neffectiveness of Muon and related optimizers but also leads to a class of new\nstructure-aware preconditioned methods. A key contribution of this framework is\nits precise distinction between preconditioning strategies that treat neural\nnetwork weights as vectors (addressing curvature anisotropy) versus those that\nconsider their matrix structure (addressing gradient anisotropy). This\nperspective provides new insights into several empirical phenomena in language\nmodel pre-training, including Adam\\\'s training instabilities, Muon\\\'s accelerated\nconvergence, and the necessity of learning rate warmup for Adam. Building upon\nthis framework, we introduce PolarGrad, a new class of preconditioned\noptimization methods based on the polar decomposition of matrix-valued\ngradients. As a special instance, PolarGrad includes Muon with updates scaled\nby the nuclear norm of the gradients. We provide numerical implementations of\nthese methods, leveraging efficient numerical polar decomposition algorithms\nfor enhanced convergence. Our extensive evaluations across diverse matrix\noptimization problems and language model pre-training tasks demonstrate that\nPolarGrad outperforms both Adam and Muon.','Tim Tsz-Kit Lau, Qi Long, Weijie Su','2025-05-27','math.OC','优化方法/深度学习模型训练','http://arxiv.org/pdf/2505.21799v1','本文介绍了一种统一框架，用于分析“矩阵感知”预调优方法，揭示了Muon等优化器的有效性，并提出了一类新的结构感知预调优方法。作者介绍了一种基于矩阵值梯度的极分解的新类预调优优化方法PolarGrad，该方法在多样的矩阵优化问题和语言模型预训练任务中表现优异。'),('2505.21800v1','From Directions to Cones: Exploring Multidimensional Representations of Propositional Facts in LLMs','Large Language Models (LLMs) exhibit strong conversational abilities but\noften generate falsehoods. Prior work suggests that the truthfulness of simple\npropositions can be represented as a single linear direction in a model\\\'s\ninternal activations, but this may not fully capture its underlying geometry.\nIn this work, we extend the concept cone framework, recently introduced for\nmodeling refusal, to the domain of truth. We identify multi-dimensional cones\nthat causally mediate truth-related behavior across multiple LLM families. Our\nresults are supported by three lines of evidence: (i) causal interventions\nreliably flip model responses to factual statements, (ii) learned cones\ngeneralize across model architectures, and (iii) cone-based interventions\npreserve unrelated model behavior. These findings reveal the richer,\nmultidirectional structure governing simple true/false propositions in LLMs and\nhighlight concept cones as a promising tool for probing abstract behaviors.','Stanley Yu, Vaidehi Bulusu, Oscar Yasunaga, Clayton Lau, Cole Blondin, Sean O\'Brien, Kevin Zhu, Vasu Sharma','2025-05-27','cs.LG','LLM','http://arxiv.org/pdf/2505.21800v1','本文研究了大型语言模型（LLMs）在生成对话时经常出现虚假信息的问题。通过将拒绝建模的概念扩展到真实领域，识别了在多个LLM家族中引起真实相关行为的多维锥体。研究结果表明，锥体可以可靠地翻转模型对事实陈述的响应，跨模型架构学习的锥体具有普遍性，基于锥体的干预可以保留无关的模型行为。'),('2505.21806v1','Towards Operational Automated Greenhouse Gas Plume Detection','Operational deployment of a fully automated greenhouse gas (GHG) plume\ndetection system remains an elusive goal for imaging spectroscopy missions,\ndespite recent advances in deep learning approaches. With the dramatic increase\nin data availability, however, automation continues to increase in importance\nfor natural and anthropogenic emissions monitoring. This work reviews and\naddresses several key obstacles in the field: data and label quality control,\nprevention of spatiotemporal biases, and correctly aligned modeling objectives.\nWe demonstrate through rigorous experiments using multicampaign data from\nairborne and spaceborne instruments that convolutional neural networks (CNNs)\nare able to achieve operational detection performance when these obstacles are\nalleviated. We demonstrate that a multitask model that learns both instance\ndetection and pixelwise segmentation simultaneously can successfully lead\ntowards an operational pathway. We evaluate the model\\\'s plume detectability\nacross emission source types and regions, identifying thresholds for\noperational deployment. Finally, we provide analysis-ready data, models, and\nsource code for reproducibility, and work to define a set of best practices and\nvalidation standards to facilitate future contributions to the field.','Brian D. Bue, Jake H. Lee, Andrew K. Thorpe, Philip G. Brodrick, Daniel Cusworth, Alana Ayasse, Vassiliki Mancoridis, Anagha Satish, Shujun Xiong, Riley Duren','2025-05-27','cs.LG','图像识别','http://arxiv.org/pdf/2505.21806v1','该论文通过使用卷积神经网络（CNNs）解决了温室气体（GHG）排放检测系统的自动化部署问题，通过多任务模型实现了实例检测和像素级分割的同时学习，为实现操作性部署提供了路径。'),('2505.21807v1','TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction','Predictive modeling on tabular data is the cornerstone of many real-world\napplications. Although gradient boosting machines and some recent deep models\nachieve strong performance on tabular data, they often lack interpretability.\nOn the other hand, large language models (LLMs) have demonstrated powerful\ncapabilities to generate human-like reasoning and explanations, but remain\nunder-performed for tabular data prediction. In this paper, we propose a new\napproach that leverages reasoning-based LLMs, trained using reinforcement\nlearning, to perform more accurate and explainable predictions on tabular data.\nOur method introduces custom reward functions that guide the model not only\ntoward high prediction accuracy but also toward human-understandable reasons\nfor its predictions. Experimental results show that our model achieves\npromising performance on financial benchmark datasets, outperforming most\nexisting LLMs.','Tommy Xu, Zhitian Zhang, Xiangyu Sun, Lauren Kelly Zung, Hossein Hajimirsadeghi, Greg Mori','2025-05-27','cs.LG','LLM (大型语言模型)','http://arxiv.org/pdf/2505.21807v1','本文提出了一种新方法，利用基于推理的大型语言模型（LLMs），通过强化学习训练，对表格数据进行更准确和可解释的预测。实验结果表明，该模型在金融基准数据集上表现出色，胜过大多数现有的LLMs。'),('2505.21811v1','Revisiting Self-attention for Cross-domain Sequential Recommendation','Sequential recommendation is a popular paradigm in modern recommender\nsystems. In particular, one challenging problem in this space is cross-domain\nsequential recommendation (CDSR), which aims to predict future behaviors given\nuser interactions across multiple domains. Existing CDSR frameworks are mostly\nbuilt on the self-attention transformer and seek to improve by explicitly\ninjecting additional domain-specific components (e.g. domain-aware module\nblocks). While these additional components help, we argue they overlook the\ncore self-attention module already present in the transformer, a naturally\npowerful tool to learn correlations among behaviors. In this work, we aim to\nimprove the CDSR performance for simple models from a novel perspective of\nenhancing the self-attention. Specifically, we introduce a Pareto-optimal\nself-attention and formulate the cross-domain learning as a multi-objective\nproblem, where we optimize the recommendation task while dynamically minimizing\nthe cross-domain attention scores. Our approach automates knowledge transfer in\nCDSR (dubbed as AutoCDSR) -- it not only mitigates negative transfer but also\nencourages complementary knowledge exchange among auxiliary domains. Based on\nthe idea, we further introduce AutoCDSR+, a more performant variant with slight\nadditional cost. Our proposal is easy to implement and works as a plug-and-play\nmodule that can be incorporated into existing transformer-based recommenders.\nBesides flexibility, it is practical to deploy because it brings little extra\ncomputational overheads without heavy hyper-parameter tuning. AutoCDSR on\naverage improves Recall@10 for SASRec and Bert4Rec by 9.8% and 16.0% and\nNDCG@10 by 12.0% and 16.7%, respectively. Code is available at\nhttps://github.com/snap-research/AutoCDSR.','Clark Mingxuan Ju, Leonardo Neves, Bhuvesh Kumar, Liam Collins, Tong Zhao, Yuwei Qiu, Qing Dou, Sohail Nizam, Sen Yang, Neil Shah','2025-05-27','cs.IR','推荐系统','http://arxiv.org/pdf/2505.21811v1','该论文提出了一种改进跨领域顺序推荐性能的方法，通过增强自注意力模块来优化推荐任务，并将跨领域学习形式化为一个多目标问题。他们的方法自动化了知识转移，提高了推荐算法的性能。'),('2505.21813v1','Optimizing Data Augmentation through Bayesian Model Selection','Data Augmentation (DA) has become an essential tool to improve robustness and\ngeneralization of modern machine learning. However, when deciding on DA\nstrategies it is critical to choose parameters carefully, and this can be a\ndaunting task which is traditionally left to trial-and-error or expensive\noptimization based on validation performance. In this paper, we counter these\nlimitations by proposing a novel framework for optimizing DA. In particular, we\ntake a probabilistic view of DA, which leads to the interpretation of\naugmentation parameters as model (hyper)-parameters, and the optimization of\nthe marginal likelihood with respect to these parameters as a Bayesian model\nselection problem. Due to its intractability, we derive a tractable Evidence\nLower BOund (ELBO), which allows us to optimize augmentation parameters jointly\nwith model parameters. We provide extensive theoretical results on variational\napproximation quality, generalization guarantees, invariance properties, and\nconnections to empirical Bayes. Through experiments on computer vision tasks,\nwe show that our approach improves calibration and yields robust performance\nover fixed or no augmentation. Our work provides a rigorous foundation for\noptimizing DA through Bayesian principles with significant potential for robust\nmachine learning.','Madi Matymov, Ba-Hien Tran, Michael Kampffmeyer, Markus Heinonen, Maurizio Filippone','2025-05-27','cs.LG','数据增强 (Data Augmentation)','http://arxiv.org/pdf/2505.21813v1','本文提出了一种新颖的数据增强（DA）优化框架，将数据增强参数视为模型（超）参数，通过贝叶斯模型选择问题来优化这些参数，从而改进模型的鲁棒性和泛化能力。'),('2505.21815v1','Scientific Paper Retrieval with LLM-Guided Semantic-Based Ranking','Scientific paper retrieval is essential for supporting literature discovery\nand research. While dense retrieval methods demonstrate effectiveness in\ngeneral-purpose tasks, they often fail to capture fine-grained scientific\nconcepts that are essential for accurate understanding of scientific queries.\nRecent studies also use large language models (LLMs) for query understanding;\nhowever, these methods often lack grounding in corpus-specific knowledge and\nmay generate unreliable or unfaithful content. To overcome these limitations,\nwe propose SemRank, an effective and efficient paper retrieval framework that\ncombines LLM-guided query understanding with a concept-based semantic index.\nEach paper is indexed using multi-granular scientific concepts, including\ngeneral research topics and detailed key phrases. At query time, an LLM\nidentifies core concepts derived from the corpus to explicitly capture the\nquery\\\'s information need. These identified concepts enable precise semantic\nmatching, significantly enhancing retrieval accuracy. Experiments show that\nSemRank consistently improves the performance of various base retrievers,\nsurpasses strong existing LLM-based baselines, and remains highly efficient.','Yunyi Zhang, Ruozhen Yang, Siqi Jiao, SeongKu Kang, Jiawei Han','2025-05-27','cs.IR','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.21815v1','该论文提出了一种名为SemRank的科学论文检索框架，结合了LLM引导的查询理解和基于概念的语义索引，以提高科学论文检索的准确性和效率。'),('2505.21819v1','Representative Language Generation','We introduce \"representative generation,\" extending the theoretical framework\nfor generation proposed by Kleinberg et al. (2024) and formalized by Li et al.\n(2024), to additionally address diversity and bias concerns in generative\nmodels. Our notion requires outputs of a generative model to proportionally\nrepresent groups of interest from the training data. We characterize\nrepresentative uniform and non-uniform generation, introducing the \"group\nclosure dimension\" as a key combinatorial quantity. For representative\ngeneration in the limit, we analyze both information-theoretic and\ncomputational aspects, demonstrating feasibility for countably infinite\nhypothesis classes and collections of groups under certain conditions, but\nproving a negative result for computability using only membership queries. This\ncontrasts with Kleinberg et al.\\\'s (2024) positive results for standard\ngeneration in the limit. Our findings provide a rigorous foundation for\ndeveloping more diverse and representative generative models.','Charlotte Peale, Vinod Raman, Omer Reingold','2025-05-27','cs.CL','生成模型','http://arxiv.org/pdf/2505.21819v1','该论文介绍了“代表性生成”，扩展了Kleinberg等人（2024年）提出的生成理论框架，并由Li等人（2024年）进行形式化，以额外解决生成模型中的多样性和偏见问题。他们的概念要求生成模型的输出比例地代表训练数据中感兴趣的群体。他们表征了代表性均匀和非均匀生成，引入了“群闭合维度”作为一个关键的组合数量。对于极限情况下的代表性生成，他们分析了信息论和计算方面，证明了在某些条件下对可数无限假设类和群体集合的可行性，但证明了仅使用成员查询无法计算性。这与Kleinberg等人（2024年）在标准生成方面的积极结果形成对比。他们的发现为开发更多样化和代表性的生成模型提供了严谨的基础。'),('2505.21825v1','Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones','Inference-time computation has emerged as a promising scaling axis for\nimproving large language model reasoning. However, despite yielding impressive\nperformance, the optimal allocation of inference-time computation remains\npoorly understood. A central question is whether to prioritize sequential\nscaling (e.g., longer chains of thought) or parallel scaling (e.g., majority\nvoting across multiple short chains of thought). In this work, we seek to\nilluminate the landscape of test-time scaling by demonstrating the existence of\nreasoning settings where sequential scaling offers an exponential advantage\nover parallel scaling. These settings are based on graph connectivity problems\nin challenging distributions of graphs. We validate our theoretical findings\nwith comprehensive experiments across a range of language models, including\nmodels trained from scratch for graph connectivity with different chain of\nthought strategies as well as large reasoning models.','Parsa Mirtaheri, Ezra Edelman, Samy Jelassi, Eran Malach, Enric Boix-Adsera','2025-05-27','cs.LG','LLM (大型语言模型)','http://arxiv.org/pdf/2505.21825v1','该论文探讨了推理时间计算对于提高大型语言模型推理能力的重要性，研究了顺序扩展和并行扩展在推理过程中的优先级选择，并通过图连接性问题展示了顺序扩展在某些情况下具有指数级的优势。'),('2505.21827v1','Music Source Restoration','We introduce Music Source Restoration (MSR), a novel task addressing the gap\nbetween idealized source separation and real-world music production. Current\nMusic Source Separation (MSS) approaches assume mixtures are simple sums of\nsources, ignoring signal degradations employed during music production like\nequalization, compression, and reverb. MSR models mixtures as degraded sums of\nindividually degraded sources, with the goal of recovering original, undegraded\nsignals. Due to the lack of data for MSR, we present RawStems, a dataset\nannotation of 578 songs with unprocessed source signals organized into 8\nprimary and 17 secondary instrument groups, totaling 354.13 hours. To the best\nof our knowledge, RawStems is the first dataset that contains unprocessed music\nstems with hierarchical categories. We consider spectral filtering, dynamic\nrange compression, harmonic distortion, reverb and lossy codec as possible\ndegradations, and establish U-Former as a baseline method, demonstrating the\nfeasibility of MSR on our dataset. We release the RawStems dataset annotations,\ndegradation simulation pipeline, training code and pre-trained models to be\npublicly available.','Yongyi Zang, Zheqi Dai, Mark D. Plumbley, Qiuqiang Kong','2025-05-27','cs.SD','音频处理','http://arxiv.org/pdf/2505.21827v1','该论文介绍了音乐源恢复（MSR）这一新颖任务，旨在填补理想化源分离和实际音乐制作之间的差距。他们提出了RawStems数据集，包含578首歌曲的未处理源信号，总计354.13小时，并建立了U-Former作为基准方法，展示了在他们的数据集上进行MSR的可行性。'),('2505.21828v1','SAGE-Eval: Evaluating LLMs for Systematic Generalizations of Safety Facts','Do LLMs robustly generalize critical safety facts to novel situations?\nLacking this ability is dangerous when users ask naive questions. For instance,\n\"I\\\'m considering packing melon balls for my 10-month-old\\\'s lunch. What other\nfoods would be good to include?\" Before offering food options, the LLM should\nwarn that melon balls pose a choking hazard to toddlers, as documented by the\nCDC. Failing to provide such warnings could result in serious injuries or even\ndeath. To evaluate this, we introduce SAGE-Eval, SAfety-fact systematic\nGEneralization evaluation, the first benchmark that tests whether LLMs properly\napply well established safety facts to naive user queries. SAGE-Eval comprises\n104 facts manually sourced from reputable organizations, systematically\naugmented to create 10,428 test scenarios across 7 common domains (e.g.,\nOutdoor Activities, Medicine). We find that the top model, Claude-3.7-sonnet,\npasses only 58% of all the safety facts tested. We also observe that model\ncapabilities and training compute weakly correlate with performance on\nSAGE-Eval, implying that scaling up is not the golden solution. Our findings\nsuggest frontier LLMs still lack robust generalization ability. We recommend\ndevelopers use SAGE-Eval in pre-deployment evaluations to assess model\nreliability in addressing salient risks. We publicly release SAGE-Eval at\nhttps://huggingface.co/datasets/YuehHanChen/SAGE-Eval and our code is available\nat https://github.com/YuehHanChen/SAGE-Eval/tree/main.','Chen Yueh-Han, Guy Davidson, Brenden M. Lake','2025-05-27','cs.AI','LLM（大型语言模型）','http://arxiv.org/pdf/2505.21828v1','该论文旨在研究大型语言模型在将关键安全事实泛化到新情况时的表现，提出了一个新的评估基准 SAGE-Eval，评估模型是否能够正确地将安全事实应用于用户的基本查询。研究发现当前前沿的大型语言模型仍然缺乏强大的泛化能力。'),('2505.21829v1','In Search of Adam\\\'s Secret Sauce','Understanding the remarkable efficacy of Adam when training transformer-based\nlanguage models has become a central research topic within the optimization\ncommunity. To gain deeper insights, several simplifications of Adam have been\nproposed, such as the signed gradient and signed momentum methods. In this\nwork, we conduct an extensive empirical study - training over 1,300 language\nmodels across different data configurations and scales - comparing Adam to\nseveral known simplified variants. We find that signed momentum methods are\nfaster than SGD, but consistently underperform relative to Adam, even after\ncareful tuning of momentum, clipping setting and learning rates. However, our\nanalysis reveals a compelling option that preserves near-optimal performance\nwhile allowing for new insightful reformulations: constraining the Adam\nmomentum parameters to be equal. Beyond robust performance, this choice affords\nnew theoretical insights, highlights the \"secret sauce\" on top of signed\nmomentum, and grants a precise statistical interpretation: we show that Adam in\nthis setting implements a natural online algorithm for estimating the mean and\nvariance of gradients-one that arises from a mean-field Gaussian variational\ninference perspective.','Antonio Orvieto, Robert Gower','2025-05-27','cs.LG','LLM (语言模型)','http://arxiv.org/pdf/2505.21829v1','该论文研究了在训练基于transformer的语言模型时，Adam优化算法的显著有效性，并比较了Adam与几种简化变体的性能。他们发现将Adam的动量参数约束为相等可以保持接近最优性能，并提供了新的理论洞见。'),('2505.21835v1','TuneComp: Joint Fine-tuning and Compression for Large Foundation Models','To reduce model size during post-training, compression methods, including\nknowledge distillation, low-rank approximation, and pruning, are often applied\nafter fine-tuning the model. However, sequential fine-tuning and compression\nsacrifices performance, while creating a larger than necessary model as an\nintermediate step. In this work, we aim to reduce this gap, by directly\nconstructing a smaller model while guided by the downstream task. We propose to\njointly fine-tune and compress the model by gradually distilling it to a pruned\nlow-rank structure. Experiments demonstrate that joint fine-tuning and\ncompression significantly outperforms other sequential compression methods.','Xiangyu Chen, Jing Liu, Ye Wang, Matthew Brand, Pu, Wang, Toshiaki Koike-Akino','2025-05-27','cs.LG','模型压缩/模型优化','http://arxiv.org/pdf/2505.21835v1','该论文研究了如何在微调模型后通过压缩方法来减小模型大小，提出了一种联合微调和压缩模型的方法，通过逐步将模型蒸馏为修剪的低秩结构来实现。实验证明，联合微调和压缩方法明显优于其他顺序压缩方法。'),('2505.21837v1','UniMoGen: Universal Motion Generation','Motion generation is a cornerstone of computer graphics, animation, gaming,\nand robotics, enabling the creation of realistic and varied character\nmovements. A significant limitation of existing methods is their reliance on\nspecific skeletal structures, which restricts their versatility across\ndifferent characters. To overcome this, we introduce UniMoGen, a novel\nUNet-based diffusion model designed for skeleton-agnostic motion generation.\nUniMoGen can be trained on motion data from diverse characters, such as humans\nand animals, without the need for a predefined maximum number of joints. By\ndynamically processing only the necessary joints for each character, our model\nachieves both skeleton agnosticism and computational efficiency. Key features\nof UniMoGen include controllability via style and trajectory inputs, and the\nability to continue motions from past frames. We demonstrate UniMoGen\\\'s\neffectiveness on the 100style dataset, where it outperforms state-of-the-art\nmethods in diverse character motion generation. Furthermore, when trained on\nboth the 100style and LAFAN1 datasets, which use different skeletons, UniMoGen\nachieves high performance and improved efficiency across both skeletons. These\nresults highlight UniMoGen\\\'s potential to advance motion generation by\nproviding a flexible, efficient, and controllable solution for a wide range of\ncharacter animations.','Aliasghar Khani, Arianna Rampini, Evan Atherton, Bruno Roy','2025-05-28','cs.CV','动作生成','http://arxiv.org/pdf/2505.21837v1','该论文介绍了一种基于UniMoGen的UNet扩散模型，用于骨架无关的动作生成，能够在不同角色之间实现灵活、高效和可控的动作生成。'),('2505.21841v1','An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints','Online safe reinforcement learning (RL) plays a key role in dynamic\nenvironments, with applications in autonomous driving, robotics, and\ncybersecurity. The objective is to learn optimal policies that maximize rewards\nwhile satisfying safety constraints modeled by constrained Markov decision\nprocesses (CMDPs). Existing methods achieve sublinear regret under stochastic\nconstraints but often fail in adversarial settings, where constraints are\nunknown, time-varying, and potentially adversarially designed. In this paper,\nwe propose the Optimistic Mirror Descent Primal-Dual (OMDPD) algorithm, the\nfirst to address online CMDPs with anytime adversarial constraints. OMDPD\nachieves optimal regret O(sqrt(K)) and strong constraint violation O(sqrt(K))\nwithout relying on Slater\\\'s condition or the existence of a strictly known safe\npolicy. We further show that access to accurate estimates of rewards and\ntransitions can further improve these bounds. Our results offer practical\nguarantees for safe decision-making in adversarial environments.','Jiahui Zhu, Kihyun Yu, Dabeen Lee, Xin Liu, Honghao Wei','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.21841v1','本文提出了一种名为Optimistic Mirror Descent Primal-Dual (OMDPD)算法，用于处理在线约束马尔可夫决策过程 (CMDPs) 中的任意对手约束。该算法在对手约束下实现了最优遗憾O(sqrt(K))和强约束违反O(sqrt(K))，并且不依赖于 Slater 的条件或存在严格已知的安全策略。'),('2505.21842v1','A Physics-Informed Learning Framework to Solve the Infinite-Horizon Optimal Control Problem','We propose a physics-informed neural networks (PINNs) framework to solve the\ninfinite-horizon optimal control problem of nonlinear systems. In particular,\nsince PINNs are generally able to solve a class of partial differential\nequations (PDEs), they can be employed to learn the value function of the\ninfinite-horizon optimal control problem via solving the associated\nsteady-state Hamilton-Jacobi-Bellman (HJB) equation. However, an issue here is\nthat the steady-state HJB equation generally yields multiple solutions; hence\nif PINNs are directly employed to it, they may end up approximating a solution\nthat is different from the optimal value function of the problem. We tackle\nthis by instead applying PINNs to a finite-horizon variant of the steady-state\nHJB that has a unique solution, and which uniformly approximates the optimal\nvalue function as the horizon increases. An algorithm to verify if the chosen\nhorizon is large enough is also given, as well as a method to extend it -- with\nreduced computations and robustness to approximation errors -- in case it is\nnot. Unlike many existing methods, the proposed technique works well with\nnon-polynomial basis functions, does not require prior knowledge of a\nstabilizing controller, and does not perform iterative policy evaluations.\nSimulations are performed, which verify and clarify theoretical findings.','Filippos Fotiadis, Kyriakos G. Vamvoudakis','2025-05-28','eess.SY','强化学习','http://arxiv.org/pdf/2505.21842v1','该论文提出了一种基于物理知识的神经网络（PINNs）框架，用于解决非线性系统的无限时最优控制问题。他们通过解决相关的稳态哈密尔顿-雅可比-贝尔曼（HJB）方程来学习无限时最优控制问题的价值函数。'),('2505.21845v1','Spectral clustering for dependent community Hawkes process models of temporal networks','Temporal networks observed continuously over time through timestamped\nrelational events data are commonly encountered in application settings\nincluding online social media communications, financial transactions, and\ninternational relations. Temporal networks often exhibit community structure\nand strong dependence patterns among node pairs. This dependence can be modeled\nthrough mutual excitations, where an interaction event from a sender to a\nreceiver node increases the possibility of future events among other node\npairs.\n  We provide statistical results for a class of models that we call dependent\ncommunity Hawkes (DCH) models, which combine the stochastic block model with\nmutually exciting Hawkes processes for modeling both community structure and\ndependence among node pairs, respectively. We derive a non-asymptotic upper\nbound on the misclustering error of spectral clustering on the event count\nmatrix as a function of the number of nodes and communities, time duration, and\nthe amount of dependence in the model. Our result leverages recent results on\nbounding an appropriate distance between a multivariate Hawkes process count\nvector and a Gaussian vector, along with results from random matrix theory. We\nalso propose a DCH model that incorporates only self and reciprocal excitation\nalong with highly scalable parameter estimation using a Generalized Method of\nMoments (GMM) estimator that we demonstrate to be consistent for growing\nnetwork size and time duration.','Lingfei Zhao, Hadeel Soliman, Kevin S. Xu, Subhadeep Paul','2025-05-28','stat.ML','强化学习','http://arxiv.org/pdf/2505.21845v1','该论文研究了在时间上连续观察到的时间网络，通过时间戳的关系事件数据，结合了随机块模型和相互激励的Hawkes过程，用于建模社区结构和节点对之间的依赖关系。提出了一种DCH模型，通过广义矩估计器实现高度可扩展的参数估计。'),('2505.21847v1','RePaViT: Scalable Vision Transformer Acceleration via Structural Reparameterization on Feedforward Network Layers','We reveal that feedforward network (FFN) layers, rather than attention\nlayers, are the primary contributors to Vision Transformer (ViT) inference\nlatency, with their impact signifying as model size increases. This finding\nhighlights a critical opportunity for optimizing the efficiency of large-scale\nViTs by focusing on FFN layers. In this work, we propose a novel channel idle\nmechanism that facilitates post-training structural reparameterization for\nefficient FFN layers during testing. Specifically, a set of feature channels\nremains idle and bypasses the nonlinear activation function in each FFN layer,\nthereby forming a linear pathway that enables structural reparameterization\nduring inference. This mechanism results in a family of ReParameterizable\nVision Transformers (RePaViTs), which achieve remarkable latency reductions\nwith acceptable sacrifices (sometimes gains) in accuracy across various ViTs.\nThe benefits of our method scale consistently with model sizes, demonstrating\ngreater speed improvements and progressively narrowing accuracy gaps or even\nhigher accuracies on larger models. In particular, RePa-ViT-Large and\nRePa-ViT-Huge enjoy 66.8% and 68.7% speed-ups with +1.7% and +1.1% higher top-1\naccuracies under the same training strategy, respectively. RePaViT is the first\nto employ structural reparameterization on FFN layers to expedite ViTs to our\nbest knowledge, and we believe that it represents an auspicious direction for\nefficient ViTs. Source code is available at\nhttps://github.com/Ackesnal/RePaViT.','Xuwei Xu, Yang Li, Yudong Chen, Jiajun Liu, Sen Wang','2025-05-28','cs.CV','计算机视觉（CV）','http://arxiv.org/pdf/2505.21847v1','该论文发现在Vision Transformer（ViT）推断中，前馈网络（FFN）层而非注意力层是主要的推理延迟贡献者，特别是在模型规模增大时。作者提出了一种新颖的通道空闲机制，用于在测试期间对FFN层进行高效的结构重参数化，从而实现显著的延迟降低和可接受的准确性牺牲。'),('2505.21849v1','Xinyu AI Search: Enhanced Relevance and Comprehensive Results with Rich Answer Presentations','Traditional search engines struggle to synthesize fragmented information for\ncomplex queries, while generative AI search engines face challenges in\nrelevance, comprehensiveness, and presentation. To address these limitations,\nwe introduce Xinyu AI Search, a novel system that incorporates a\nquery-decomposition graph to dynamically break down complex queries into\nsub-queries, enabling stepwise retrieval and generation. Our retrieval pipeline\nenhances diversity through multi-source aggregation and query expansion, while\nfiltering and re-ranking strategies optimize passage relevance. Additionally,\nXinyu AI Search introduces a novel approach for fine-grained, precise built-in\ncitation and innovates in result presentation by integrating timeline\nvisualization and textual-visual choreography. Evaluated on recent real-world\nqueries, Xinyu AI Search outperforms eight existing technologies in human\nassessments, excelling in relevance, comprehensiveness, and insightfulness.\nAblation studies validate the necessity of its key sub-modules. Our work\npresents the first comprehensive framework for generative AI search engines,\nbridging retrieval, generation, and user-centric presentation.','Bo Tang, Junyi Zhu, Chenyang Xi, Yunhang Ge, Jiahao Wu, Yuchen Feng, Yijun Niu, Wenqiang Wei, Yu Yu, Chunyu Li, Zehao Lin, Hao Wu, Ning Liao, Yebin Yang, Jiajia Wang, Zhiyu Li, Feiyu Xiong, Jingrun Chen','2025-05-28','cs.IR','生成模型、自然语言处理','http://arxiv.org/pdf/2505.21849v1','该论文介绍了一种名为Xinyu AI Search的新型系统，通过引入查询分解图，将复杂查询动态分解为子查询，实现逐步检索和生成。其检索管道通过多源聚合和查询扩展增强多样性，同时通过过滤和重新排序策略优化段落相关性。Xinyu AI Search在人类评估中表现优异，在相关性、全面性和见解性方面胜过八种现有技术。'),('2505.21850v1','Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task','Current Multimodal Large Language Models (MLLMs) excel in general visual\nreasoning but remain underexplored in Abstract Visual Reasoning (AVR), which\ndemands higher-order reasoning to identify abstract rules beyond simple\nperception. Existing AVR benchmarks focus on single-step reasoning, emphasizing\nthe end result but neglecting the multi-stage nature of reasoning process. Past\nstudies found MLLMs struggle with these benchmarks, but it doesn\\\'t explain how\nthey fail. To address this gap, we introduce MultiStAR, a Multi-Stage AVR\nbenchmark, based on RAVEN, designed to assess reasoning across varying levels\nof complexity. Additionally, existing metrics like accuracy only focus on the\nfinal outcomes while do not account for the correctness of intermediate steps.\nTherefore, we propose a novel metric, MSEval, which considers the correctness\nof intermediate steps in addition to the final outcomes. We conduct\ncomprehensive experiments on MultiStAR using 17 representative close-source and\nopen-source MLLMs. The results reveal that while existing MLLMs perform\nadequately on basic perception tasks, they continue to face challenges in more\ncomplex rule detection stages.','Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger','2025-05-28','cs.CV','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21850v1','该论文介绍了在抽象视觉推理中，当前多模态大型语言模型（MLLMs）表现出色，但在这方面仍未得到充分探索。作者提出了一个多阶段的抽象视觉推理基准（MultiStAR），并引入了一种新的度量标准（MSEval），以评估MLLMs在不同复杂性水平上的推理能力。实验结果显示，现有MLLMs在基本感知任务上表现良好，但在更复杂的规则检测阶段仍面临挑战。'),('2505.21851v1','Streaming Flow Policy: Simplifying diffusion$/$flow-matching policies by treating action trajectories as flow trajectories','Recent advances in diffusion$/$flow-matching policies have enabled imitation\nlearning of complex, multi-modal action trajectories. However, they are\ncomputationally expensive because they sample a trajectory of trajectories: a\ndiffusion$/$flow trajectory of action trajectories. They discard intermediate\naction trajectories, and must wait for the sampling process to complete before\nany actions can be executed on the robot. We simplify diffusion$/$flow policies\nby treating action trajectories as flow trajectories. Instead of starting from\npure noise, our algorithm samples from a narrow Gaussian around the last\naction. Then, it incrementally integrates a velocity field learned via flow\nmatching to produce a sequence of actions that constitute a single trajectory.\nThis enables actions to be streamed to the robot on-the-fly during the flow\nsampling process, and is well-suited for receding horizon policy execution.\nDespite streaming, our method retains the ability to model multi-modal\nbehavior. We train flows that stabilize around demonstration trajectories to\nreduce distribution shift and improve imitation learning performance. Streaming\nflow policy outperforms prior methods while enabling faster policy execution\nand tighter sensorimotor loops for learning-based robot control. Project\nwebsite: https://streaming-flow-policy.github.io/','Sunshine Jiang, Xiaolin Fang, Nicholas Roy, Tomás Lozano-Pérez, Leslie Pack Kaelbling, Siddharth Ancha','2025-05-28','cs.RO','强化学习','http://arxiv.org/pdf/2505.21851v1','该论文提出了一种简化扩散/流策略的方法，将动作轨迹视为流轨迹，通过对上一个动作周围的窄高斯进行采样，并逐步集成通过流匹配学习的速度场，实现了动作的实时流式传输，适用于学习机器人控制策略。'),('2505.21852v1','A Provable Approach for End-to-End Safe Reinforcement Learning','A longstanding goal in safe reinforcement learning (RL) is a method to ensure\nthe safety of a policy throughout the entire process, from learning to\noperation. However, existing safe RL paradigms inherently struggle to achieve\nthis objective. We propose a method, called Provably Lifetime Safe RL (PLS),\nthat integrates offline safe RL with safe policy deployment to address this\nchallenge. Our proposed method learns a policy offline using return-conditioned\nsupervised learning and then deploys the resulting policy while cautiously\noptimizing a limited set of parameters, known as target returns, using Gaussian\nprocesses (GPs). Theoretically, we justify the use of GPs by analyzing the\nmathematical relationship between target and actual returns. We then prove that\nPLS finds near-optimal target returns while guaranteeing safety with high\nprobability. Empirically, we demonstrate that PLS outperforms baselines both in\nsafety and reward performance, thereby achieving the longstanding goal to\nobtain high rewards while ensuring the safety of a policy throughout the\nlifetime from learning to operation.','Akifumi Wachi, Kohei Miyaguchi, Takumi Tanabe, Rei Sato, Youhei Akimoto','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.21852v1','该论文提出了一种名为Provably Lifetime Safe RL (PLS)的方法，通过将离线安全RL与安全策略部署相结合，解决了确保策略在整个学习到操作过程中的安全性的挑战。他们的方法在理论上证明了使用高斯过程来谨慎优化有限的目标回报参数，同时在实验中表现出优于基线方法的安全性和奖励性能。'),('2505.21854v1','Rethinking Gradient-based Adversarial Attacks on Point Cloud Classification','Gradient-based adversarial attacks have become a dominant approach for\nevaluating the robustness of point cloud classification models. However,\nexisting methods often rely on uniform update rules that fail to consider the\nheterogeneous nature of point clouds, resulting in excessive and perceptible\nperturbations. In this paper, we rethink the design of gradient-based attacks\nby analyzing the limitations of conventional gradient update mechanisms and\npropose two new strategies to improve both attack effectiveness and\nimperceptibility. First, we introduce WAAttack, a novel framework that\nincorporates weighted gradients and an adaptive step-size strategy to account\nfor the non-uniform contribution of points during optimization. This approach\nenables more targeted and subtle perturbations by dynamically adjusting updates\naccording to the local structure and sensitivity of each point. Second, we\npropose SubAttack, a complementary strategy that decomposes the point cloud\ninto subsets and focuses perturbation efforts on structurally critical regions.\nTogether, these methods represent a principled rethinking of gradient-based\nadversarial attacks for 3D point cloud classification. Extensive experiments\ndemonstrate that our approach outperforms state-of-the-art baselines in\ngenerating highly imperceptible adversarial examples. Code will be released\nupon paper acceptance.','Jun Chen, Xinke Li, Mingyue Xu, Tianrui Li, Chongshou Li','2025-05-28','cs.CV','三维点云分类','http://arxiv.org/pdf/2505.21854v1','本文重新设计了基于梯度的对抗攻击方法，通过分析传统梯度更新机制的局限性，提出了两种新策略来提高攻击效果和难以察觉性。首先，引入了WAAttack框架，结合加权梯度和自适应步长策略，以考虑点云的非均匀性贡献；其次，提出了SubAttack策略，将点云分解为子集，并将扰动集中在结构关键区域。这些方法代表了对3D点云分类的基于梯度的对抗攻击的原则性重新思考。实验表明，该方法在生成高度难以察觉的对抗样本方面优于现有基线。'),('2505.21855v1','Extracting Research Instruments from Educational Literature Using LLMs','Large Language Models (LLMs) are transforming information extraction from\nacademic literature, offering new possibilities for knowledge management. This\nstudy presents an LLM-based system designed to extract detailed information\nabout research instruments used in the education field, including their names,\ntypes, target respondents, measured constructs, and outcomes. Using multi-step\nprompting and a domain-specific data schema, it generates structured outputs\noptimized for educational research. Our evaluation shows that this system\nsignificantly outperforms other approaches, particularly in identifying\ninstrument names and detailed information. This demonstrates the potential of\nLLM-powered information extraction in educational contexts, offering a\nsystematic way to organize research instrument information. The ability to\naggregate such information at scale enhances accessibility for researchers and\neducation leaders, facilitating informed decision-making in educational\nresearch and policy.','Jiseung Yoo, Curran Mahowald, Meiyu Li, Wei Ai','2025-05-28','cs.IR','大型语言模型(LLM)、教育领域、信息提取','http://arxiv.org/pdf/2505.21855v1','该论文介绍了一种基于大型语言模型（LLMs）的系统，用于提取教育领域研究中使用的研究工具的详细信息，包括名称、类型、目标受访者、测量构建和结果。通过多步提示和领域特定数据模式，生成了针对教育研究优化的结构化输出。评估结果显示，该系统在识别工具名称和详细信息方面明显优于其他方法，展示了LLM在教育领域信息提取中的潜力。'),('2505.21857v1','Revisiting Bayesian Model Averaging in the Era of Foundation Models','We revisit the classical, full-fledged Bayesian model averaging (BMA)\nparadigm to ensemble pre-trained and/or lightly-finetuned foundation models to\nenhance the classification performance on image and text data. To make BMA\ntractable under foundation models, we introduce trainable linear classifiers\nthat take frozen features from the pre-trained foundation models as inputs. The\nmodel posteriors over the linear classifiers tell us which linear heads and\nfrozen features are better suited for a given dataset, resulting in a\nprincipled model ensembling method. Furthermore, we propose a computationally\ncheaper, optimizable model averaging scheme (OMA). In OMA, we directly optimize\nthe model ensemble weights, just like those weights based on model posterior\ndistributions in BMA, by reducing the amount of surprise (expected entropy of\nthe predictions) we get from predictions of ensembled models. With the rapid\ndevelopment of foundation models, these approaches will enable the\nincorporation of future, possibly significantly better foundation models to\nenhance the performance of challenging classification tasks.','Mijung Park','2025-05-28','cs.LG','模型集成、机器学习','http://arxiv.org/pdf/2505.21857v1','该论文提出了一种基于贝叶斯模型平均的方法，用于集成预训练和/或轻微微调的基础模型，以提高图像和文本数据的分类性能。通过引入可训练的线性分类器，使得在基础模型下的BMA方法变得可行，同时提出了一种更便捷、可优化的模型平均方案（OMA）。'),('2505.21859v1','Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries','While large language models (LLMs) are increasingly capable of handling\nlonger contexts, recent work has demonstrated that they exhibit the \"lost in\nthe middle\" phenomenon (Liu et al., 2024) of unevenly attending to different\nparts of the provided context. This hinders their ability to cover diverse\nsource material in multi-document summarization, as noted in the DiverseSumm\nbenchmark (Huang et al., 2024). In this work, we contend that principled\ncontent selection is a simple way to increase source coverage on this task. As\nopposed to prompting an LLM to perform the summarization in a single step, we\nexplicitly divide the task into three steps -- (1) reducing document\ncollections to atomic key points, (2) using determinantal point processes (DPP)\nto perform select key points that prioritize diverse content, and (3) rewriting\nto the final summary. By combining prompting steps, for extraction and\nrewriting, with principled techniques, for content selection, we consistently\nimprove source coverage on the DiverseSumm benchmark across various LLMs.\nFinally, we also show that by incorporating relevance to a provided user intent\ninto the DPP kernel, we can generate personalized summaries that cover relevant\nsource information while retaining coverage.','Vishakh Padmakumar, Zichao Wang, David Arbour, Jennifer Healey','2025-05-28','cs.CL','大型语言模型(LLM)、文本摘要(Abstractive Summarization)','http://arxiv.org/pdf/2505.21859v1','本文针对大型语言模型在多文档摘要任务中存在的“中间迷失”现象提出了一种基于原则的内容选择方法，通过将任务分为三个步骤来提高源覆盖率，并在不同的LLM上持续改进DiverseSumm基准测试结果。同时，通过将用户意图相关性纳入DPP核心，生成个性化摘要。'),('2505.21863v1','GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning','Publicly significant images from events hold valuable contextual information,\ncrucial for journalism and education. However, existing methods often struggle\nto extract this relevance accurately. To address this, we introduce GETReason\n(Geospatial Event Temporal Reasoning), a framework that moves beyond\nsurface-level image descriptions to infer deeper contextual meaning. We propose\nthat extracting global event, temporal, and geospatial information enhances\nunderstanding of an image\\\'s significance. Additionally, we introduce GREAT\n(Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric\nfor evaluating reasoning-based image understanding. Our layered multi-agent\napproach, assessed using a reasoning-weighted metric, demonstrates that\nmeaningful insights can be inferred, effectively linking images to their\nbroader event context.','Shikhhar Siingh, Abhinav Rawat, Vivek Gupta, Chitta Baral','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.21863v1','该论文介绍了GETReason（Geospatial Event Temporal Reasoning）框架，通过提取全球事件、时间和地理空间信息，深入推断图像的上下文含义，提出了GREAT（Geospatial Reasoning and Event Accuracy with Temporal Alignment）评估指标。通过分层多代理方法，有效地将图像与更广泛的事件背景联系起来。'),('2505.21866v1','CSI-Bench: A Large-Scale In-the-Wild Dataset for Multi-task WiFi Sensing','WiFi sensing has emerged as a compelling contactless modality for human\nactivity monitoring by capturing fine-grained variations in Channel State\nInformation (CSI). Its ability to operate continuously and non-intrusively\nwhile preserving user privacy makes it particularly suitable for health\nmonitoring. However, existing WiFi sensing systems struggle to generalize in\nreal-world settings, largely due to datasets collected in controlled\nenvironments with homogeneous hardware and fragmented, session-based recordings\nthat fail to reflect continuous daily activity.\n  We present CSI-Bench, a large-scale, in-the-wild benchmark dataset collected\nusing commercial WiFi edge devices across 26 diverse indoor environments with\n35 real users. Spanning over 461 hours of effective data, CSI-Bench captures\nrealistic signal variability under natural conditions. It includes\ntask-specific datasets for fall detection, breathing monitoring, localization,\nand motion source recognition, as well as a co-labeled multitask dataset with\njoint annotations for user identity, activity, and proximity. To support the\ndevelopment of robust and generalizable models, CSI-Bench provides standardized\nevaluation splits and baseline results for both single-task and multi-task\nlearning. CSI-Bench offers a foundation for scalable, privacy-preserving WiFi\nsensing systems in health and broader human-centric applications.','Guozhen Zhu, Yuqian Hu, Weihang Gao, Wei-Hsiang Wang, Beibei Wang, K. J. Ray Liu','2025-05-28','eess.SP','健康监测、人类中心的应用','http://arxiv.org/pdf/2505.21866v1','该论文介绍了CSI-Bench，一个大规模的真实环境下收集的WiFi感知数据集，用于健康监测和其他人类中心的应用。该数据集包括针对跌倒检测、呼吸监测、定位和动作源识别的任务特定数据集，以及一个具有联合注释的多任务数据集。'),('2505.21870v1','Evaluating the Retrieval Robustness of Large Language Models','Retrieval-augmented generation (RAG) generally enhances large language\nmodels\\\' (LLMs) ability to solve knowledge-intensive tasks. But RAG may also\nlead to performance degradation due to imperfect retrieval and the model\\\'s\nlimited ability to leverage retrieved content. In this work, we evaluate the\nrobustness of LLMs in practical RAG setups (henceforth retrieval robustness).\nWe focus on three research questions: (1) whether RAG is always better than\nnon-RAG; (2) whether more retrieved documents always lead to better\nperformance; (3) and whether document orders impact results. To facilitate this\nstudy, we establish a benchmark of 1500 open-domain questions, each with\nretrieved documents from Wikipedia. We introduce three robustness metrics, each\ncorresponds to one research question. Our comprehensive experiments, involving\n11 LLMs and 3 prompting strategies, reveal that all of these LLMs exhibit\nsurprisingly high retrieval robustness; nonetheless, different degrees of\nimperfect robustness hinders them from fully utilizing the benefits of RAG.','Shuyang Cao, Karthik Radhakrishnan, David Rosenberg, Steven Lu, Pengxiang Cheng, Lu Wang, Shiyue Zhang','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21870v1','本文评估了大型语言模型在实际检索增强生成（RAG）设置中的稳健性，重点关注了三个研究问题：（1）RAG是否总是优于非RAG；（2）更多的检索文档是否总是导致更好的性能；（3）文档顺序是否影响结果。通过建立一个包含来自维基百科的1500个开放领域问题的基准测试，引入了三个稳健性指标，结果显示所有的LLMs表现出惊人的高检索稳健性，但不同程度的不完美稳健性阻碍了它们充分利用RAG的好处。'),('2505.21872v1','Targeted Unlearning Using Perturbed Sign Gradient Methods With Applications On Medical Images','Machine unlearning aims to remove the influence of specific training samples\nfrom a trained model without full retraining. While prior work has largely\nfocused on privacy-motivated settings, we recast unlearning as a\ngeneral-purpose tool for post-deployment model revision. Specifically, we focus\non utilizing unlearning in clinical contexts where data shifts, device\ndeprecation, and policy changes are common. To this end, we propose a bilevel\noptimization formulation of boundary-based unlearning that can be solved using\niterative algorithms. We provide convergence guarantees when first-order\nalgorithms are used to unlearn. Our method introduces tunable loss design for\ncontrolling the forgetting-retention tradeoff and supports novel model\ncomposition strategies that merge the strengths of distinct unlearning runs.\nAcross benchmark and real-world clinical imaging datasets, our approach\noutperforms baselines on both forgetting and retention metrics, including\nscenarios involving imaging devices and anatomical outliers. This work\nestablishes machine unlearning as a modular, practical alternative to\nretraining for real-world model maintenance in clinical applications.','George R. Nahass, Zhu Wang, Homa Rashidisabet, Won Hwa Kim, Sasha Hubschman, Jeffrey C. Peterson, Ghasem Yazdanpanah, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi, Sathya N. Ravi','2025-05-28','eess.IV','机器学习/模型维护/临床应用','http://arxiv.org/pdf/2505.21872v1','该论文提出了一种基于边界的机器遗忘方法，旨在在临床环境中应用机器遗忘来解决数据变化、设备淘汰和政策变化等常见问题。他们提出的方法在遗忘和保留指标上优于基准线，并支持合并不同遗忘运行的新模型组合策略。'),('2505.21876v1','EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video Guidance','Recent approaches on 3D camera control in video diffusion models (VDMs) often\ncreate anchor videos to guide diffusion models as a structured prior by\nrendering from estimated point clouds following annotated camera trajectories.\nHowever, errors inherent in point cloud estimation often lead to inaccurate\nanchor videos. Moreover, the requirement for extensive camera trajectory\nannotations further increases resource demands. To address these limitations,\nwe introduce EPiC, an efficient and precise camera control learning framework\nthat automatically constructs high-quality anchor videos without expensive\ncamera trajectory annotations. Concretely, we create highly precise anchor\nvideos for training by masking source videos based on first-frame visibility.\nThis approach ensures high alignment, eliminates the need for camera trajectory\nannotations, and thus can be readily applied to any in-the-wild video to\ngenerate image-to-video (I2V) training pairs. Furthermore, we introduce\nAnchor-ControlNet, a lightweight conditioning module that integrates anchor\nvideo guidance in visible regions to pretrained VDMs, with less than 1% of\nbackbone model parameters. By combining the proposed anchor video data and\nControlNet module, EPiC achieves efficient training with substantially fewer\nparameters, training steps, and less data, without requiring modifications to\nthe diffusion model backbone typically needed to mitigate rendering\nmisalignments. Although being trained on masking-based anchor videos, our\nmethod generalizes robustly to anchor videos made with point clouds during\ninference, enabling precise 3D-informed camera control. EPiC achieves SOTA\nperformance on RealEstate10K and MiraData for I2V camera control task,\ndemonstrating precise and robust camera control ability both quantitatively and\nqualitatively. Notably, EPiC also exhibits strong zero-shot generalization to\nvideo-to-video scenarios.','Zun Wang, Jaemin Cho, Jialu Li, Han Lin, Jaehong Yoon, Yue Zhang, Mohit Bansal','2025-05-28','cs.CV','计算机视觉（CV）','http://arxiv.org/pdf/2505.21876v1','该论文介绍了一种名为EPiC的高效、精确的摄像机控制学习框架，可以自动构建高质量的锚定视频，无需昂贵的摄像机轨迹注释。通过结合提出的锚定视频数据和ControlNet模块，EPiC在训练过程中实现了更少的参数、训练步骤和数据，而无需修改通常需要减少渲染不对齐的扩散模型骨干。该方法在RealEstate10K和MiraData上实现了I2V摄像机控制任务的SOTA性能。'),('2505.21877v1','Hybrid Batch Normalisation: Resolving the Dilemma of Batch Normalisation in Federated Learning','Batch Normalisation (BN) is widely used in conventional deep neural network\ntraining to harmonise the input-output distributions for each batch of data.\nHowever, federated learning, a distributed learning paradigm, faces the\nchallenge of dealing with non-independent and identically distributed data\namong the client nodes. Due to the lack of a coherent methodology for updating\nBN statistical parameters, standard BN degrades the federated learning\nperformance. To this end, it is urgent to explore an alternative normalisation\nsolution for federated learning. In this work, we resolve the dilemma of the BN\nlayer in federated learning by developing a customised normalisation approach,\nHybrid Batch Normalisation (HBN). HBN separates the update of statistical\nparameters (i.e. , means and variances used for evaluation) from that of\nlearnable parameters (i.e. , parameters that require gradient updates),\nobtaining unbiased estimates of global statistical parameters in distributed\nscenarios. In contrast with the existing solutions, we emphasise the supportive\npower of global statistics for federated learning. The HBN layer introduces a\nlearnable hybrid distribution factor, allowing each computing node to\nadaptively mix the statistical parameters of the current batch with the global\nstatistics. Our HBN can serve as a powerful plugin to advance federated\nlearning performance. It reflects promising merits across a wide range of\nfederated learning settings, especially for small batch sizes and heterogeneous\ndata.','Hongyao Chen, Tianyang Xu, Xiaojun Wu, Josef Kittler','2025-05-28','cs.LG','联邦学习','http://arxiv.org/pdf/2505.21877v1','该论文提出了一种名为Hybrid Batch Normalisation (HBN) 的自定义归一化方法，用于解决在联邦学习中由于非独立同分布数据而导致标准BN性能下降的问题。HBN通过分离统计参数和可学习参数的更新，获得了在分布式场景下的全局统计参数的无偏估计，提高了联邦学习的性能。'),('2505.21880v1','Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation','This study presents an innovative approach to urban mobility simulation by\nintegrating a Large Language Model (LLM) with Agent-Based Modeling (ABM).\nUnlike traditional rule-based ABM, the proposed framework leverages LLM to\nenhance agent diversity and realism by generating synthetic population\nprofiles, allocating routine and occasional locations, and simulating\npersonalized routes. Using real-world data, the simulation models individual\nbehaviors and large-scale mobility patterns in Taipei City. Key insights, such\nas route heat maps and mode-specific indicators, provide urban planners with\nactionable information for policy-making. Future work focuses on establishing\nrobust validation frameworks to ensure accuracy and reliability in urban\nplanning applications.','Yu-Lun Song, Chung-En Tsern, Che-Cheng Wu, Yu-Ming Chang, Syuan-Bo Huang, Wei-Chu Chen, Michael Chia-Liang Lin, Yu-Ta Lin','2025-05-28','cs.MA','LLM、城市规划、代理建模','http://arxiv.org/pdf/2505.21880v1','该论文提出了一种创新的城市移动性仿真方法，将大型语言模型（LLM）与基于代理的建模（ABM）相结合。通过利用LLM生成合成人口特征，分配日常和偶发位置，并模拟个性化路径，增强了代理多样性和逼真性。利用真实世界数据，模拟了台北市的个体行为和大规模移动模式，为城市规划者提供了可操作的政策制定信息。'),('2505.21887v1','SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem','Robust routing under uncertainty is central to real-world logistics, yet most\nbenchmarks assume static, idealized settings. We present SVRPBench, the first\nopen benchmark to capture high-fidelity stochastic dynamics in vehicle routing\nat urban scale. Spanning more than 500 instances with up to 1000 customers, it\nsimulates realistic delivery conditions: time-dependent congestion, log-normal\ndelays, probabilistic accidents, and empirically grounded time windows for\nresidential and commercial clients. Our pipeline generates diverse,\nconstraint-rich scenarios, including multi-depot and multi-vehicle setups.\nBenchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade\nby over 20% under distributional shift, while classical and metaheuristic\nmethods remain robust. To enable reproducible research, we release the dataset\nand evaluation suite. SVRPBench challenges the community to design solvers that\ngeneralize beyond synthetic assumptions and adapt to real-world uncertainty.','Ahmed Heakl, Yahia Salaheldin Shaaban, Martin Takac, Salem Lahlou, Zangir Iklassov','2025-05-28','cs.AI','强化学习','http://arxiv.org/pdf/2505.21887v1','该论文介绍了 SVRPBench，这是第一个捕捉城市规模车辆路径高保真随机动态的开放基准。研究发现，现有的强化学习求解器在分布转移下表现下降超过20％，而传统和启发式方法保持稳健。他们释放了数据集和评估套件，挑战社区设计能够超越合成假设并适应现实世界不确定性的解决方案。'),('2505.21889v1','EFIM: Efficient Serving of LLMs for Infilling Tasks with Improved KV Cache Reuse','Large language models (LLMs) are often used for infilling tasks, which\ninvolve predicting or generating missing information in a given text. These\ntasks typically require multiple interactions with similar context. To reduce\nthe computation of repeated historical tokens, cross-request key-value (KV)\ncache reuse, a technique that stores and reuses intermediate computations, has\nbecome a crucial method in multi-round interactive services. However, in\ninfilling tasks, the KV cache reuse is often hindered by the structure of the\nprompt format, which typically consists of a prefix and suffix relative to the\ninsertion point. Specifically, the KV cache of the prefix or suffix part is\nfrequently invalidated as the other part (suffix or prefix) is incrementally\ngenerated. To address the issue, we propose EFIM, a transformed prompt format\nof FIM to unleash the performance potential of KV cache reuse. Although the\ntransformed prompt can solve the inefficiency, it exposes subtoken generation\nproblems in current LLMs, where they have difficulty generating partial words\naccurately. Therefore, we introduce a fragment tokenization training method\nwhich splits text into multiple fragments before tokenization during data\nprocessing. Experiments on two representative LLMs show that LLM serving with\nEFIM can lower the latency by 52% and improve the throughput by 98% while\nmaintaining the original infilling capability.EFIM\\\'s source code is publicly\navailable at https://github.com/gty111/EFIM.','Tianyu Guo, Hande Dong, Yichong Leng, Feng Liu, Cheater Lin, Nong Xiao, Xianwei Zhang','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21889v1','该论文提出了一种名为EFIM的转换提示格式，以释放KV缓存重用的性能潜力，并引入了一种片段标记化训练方法，以解决当前LLMs中的子标记生成问题。实验结果表明，使用EFIM可以降低延迟52％，提高吞吐量98％，同时保持原始的填充能力。'),('2505.21892v1','Almost Linear Convergence under Minimal Score Assumptions: Quantized Transition Diffusion','Continuous diffusion models have demonstrated remarkable performance in data\ngeneration across various domains, yet their efficiency remains constrained by\ntwo critical limitations: (1) the local adjacency structure of the forward\nMarkov process, which restricts long-range transitions in the data space, and\n(2) inherent biases introduced during the simulation of time-inhomogeneous\nreverse denoising processes. To address these challenges, we propose Quantized\nTransition Diffusion (QTD), a novel approach that integrates data quantization\nwith discrete diffusion dynamics. Our method first transforms the continuous\ndata distribution $p_*$ into a discrete one $q_*$ via histogram approximation\nand binary encoding, enabling efficient representation in a structured discrete\nlatent space. We then design a continuous-time Markov chain (CTMC) with Hamming\ndistance-based transitions as the forward process, which inherently supports\nlong-range movements in the original data space. For reverse-time sampling, we\nintroduce a \\textit{truncated uniformization} technique to simulate the reverse\nCTMC, which can provably provide unbiased generation from $q_*$ under minimal\nscore assumptions. Through a novel KL dynamic analysis of the reverse CTMC, we\nprove that QTD can generate samples with $O(d\\ln^2(d/\\epsilon))$ score\nevaluations in expectation to approximate the $d$--dimensional target\ndistribution $p_*$ within an $\\epsilon$ error tolerance. Our method not only\nestablishes state-of-the-art inference efficiency but also advances the\ntheoretical foundations of diffusion-based generative modeling by unifying\ndiscrete and continuous diffusion paradigms.','Xunpeng Huang, Yingyu Lin, Nikki Lijing Kuang, Hanze Dong, Difan Zou, Yian Ma, Tong Zhang','2025-05-28','stat.ML','生成模型','http://arxiv.org/pdf/2505.21892v1','该论文提出了一种名为Quantized Transition Diffusion (QTD)的新方法，通过将数据量化并与离散扩散动力学相结合，解决了连续扩散模型在数据生成中的效率限制。他们设计了一个连续时间马尔可夫链（CTMC）作为前向过程，支持原始数据空间中的长程移动，并引入了一种截断均匀化技术来模拟逆CTMC，可以在最小评分假设下提供无偏的从q_*生成样本。'),('2505.21893v1','SDPO: Importance-Sampled Direct Preference Optimization for Stable Diffusion Training','Preference learning has become a central technique for aligning generative\nmodels with human expectations. Recently, it has been extended to diffusion\nmodels through methods like Direct Preference Optimization (DPO). However,\nexisting approaches such as Diffusion-DPO suffer from two key challenges:\ntimestep-dependent instability, caused by a mismatch between the reverse and\nforward diffusion processes and by high gradient variance in early noisy\ntimesteps, and off-policy bias arising from the mismatch between optimization\nand data collection policies. We begin by analyzing the reverse diffusion\ntrajectory and observe that instability primarily occurs at early timesteps\nwith low importance weights. To address these issues, we first propose\nDPO-C\\&M, a practical strategy that improves stability by clipping and masking\nuninformative timesteps while partially mitigating off-policy bias. Building on\nthis, we introduce SDPO (Importance-Sampled Direct Preference Optimization), a\nprincipled framework that incorporates importance sampling into the objective\nto fully correct for off-policy bias and emphasize informative updates during\nthe diffusion process. Experiments on CogVideoX-2B, CogVideoX-5B, and\nWan2.1-1.3B demonstrate that both methods outperform standard Diffusion-DPO,\nwith SDPO achieving superior VBench scores, human preference alignment, and\ntraining robustness. These results highlight the importance of timestep-aware,\ndistribution-corrected optimization in diffusion-based preference learning.','Xiaomeng Yang, Zhiyu Tan, Junyan Wang, Zhijian Zhou, Hao Li','2025-05-28','cs.LG','生成模型','http://arxiv.org/pdf/2505.21893v1','该论文提出了两种改进Diffusion-DPO方法的策略，分别是DPO-C\\&M和SDPO，用于解决时间步依赖不稳定性和离策略偏差的问题。实验结果表明，这两种方法在性能上均优于标准的Diffusion-DPO方法。'),('2505.21895v1','Compressing Sine-Activated Low-Rank Adapters through Post-Training Quantization','Low-Rank Adaptation (LoRA) has become a standard approach for\nparameter-efficient fine-tuning, offering substantial reductions in trainable\nparameters by modeling updates as the product of two low-rank matrices. While\neffective, the low-rank constraint inherently limits representational capacity,\noften resulting in reduced performance compared to full-rank fine-tuning.\nRecent work by Ji et al. (2025) has addressed this limitation by applying a\nfixed-frequency sinusoidal transformation to low-rank adapters, increasing\ntheir stable rank without introducing additional parameters. This raises a\ncrucial question: can the same sine-activated technique be successfully applied\nwithin the context of Post-Training Quantization to retain benefits even after\nmodel compression? In this paper, we investigate this question by extending the\nsinusoidal transformation framework to quantized LoRA adapters. We develop a\ntheoretical analysis showing that the stable rank of a quantized adapter is\ntightly linked to that of its full-precision counterpart, motivating the use of\nsuch rank-enhancing functions even under quantization. Our results demonstrate\nthat the expressivity gains from a sinusoidal non-linearity persist after\nquantization, yielding highly compressed adapters with negligible loss in\nperformance. We validate our approach across a range of fine-tuning tasks for\nlanguage, vision and text-to-image generation achieving significant memory\nsavings while maintaining competitive accuracy.','Cameron Gordon, Yiping Ji, Hemanth Saratchandran, Paul Albert, Simon Lucey','2025-05-28','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21895v1','该论文研究了如何在Post-Training Quantization中应用正弦激活技术来增强低秩适配器的稳定秩，以实现高度压缩的适配器而几乎不损失性能。'),('2505.21898v1','Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development','Recent advancements in Large Language Models (LLMs) and autonomous agents\nhave demonstrated remarkable capabilities across various domains. However,\nstandalone agents frequently encounter limitations when handling complex tasks\nthat demand extensive interactions and substantial computational resources.\nAlthough Multi-Agent Systems (MAS) alleviate some of these limitations through\ncollaborative mechanisms like task decomposition, iterative communication, and\nrole specialization, they typically remain resource-unaware, incurring\nsignificant inefficiencies due to high token consumption and excessive\nexecution time. To address these limitations, we propose a resource-aware\nmulti-agent system -- Co-Saving (meaning that multiple agents collaboratively\nengage in resource-saving activities), which leverages experiential knowledge\nto enhance operational efficiency and solution quality. Our key innovation is\nthe introduction of \"shortcuts\" -- instructional transitions learned from\nhistorically successful trajectories -- which allows to bypass redundant\nreasoning agents and expedite the collective problem-solving process.\nExperiments for software development tasks demonstrate significant advantages\nover existing methods. Specifically, compared to the state-of-the-art MAS\nChatDev, our method achieves an average reduction of 50.85% in token usage, and\nimproves the overall code quality by 10.06%.','Rennai Qiu, Chen Qian, Ran Li, Yufan Dang, Weize Chen, Cheng Yang, Yingli Zhang, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21898v1','该论文提出了一种资源感知的多智能体系统 Co-Saving，通过引入“快捷方式”来提高操作效率和解决方案质量，实验结果表明在软件开发任务中相比现有方法具有显著优势。'),('2505.21904v1','CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation','Instance segmentation demands costly per-pixel annotations and large models.\nWe introduce CAST, a semi-supervised knowledge distillation (SSKD) framework\nthat compresses pretrained vision foundation models (VFM) into compact experts\nusing limited labeled and abundant unlabeled data. CAST unfolds in three\nstages: (1) domain adaptation of the VFM teacher(s) via self-training with\ncontrastive pixel calibration, (2) distillation into a compact student via a\nunified multi-objective loss that couples standard supervision and\npseudo-labels with our instance-aware pixel-wise contrastive term, and (3)\nfine-tuning on labeled data to remove residual pseudo-label bias. Central to\nCAST is an \\emph{instance-aware pixel-wise contrastive loss} that fuses mask\nand class scores to mine informative negatives and enforce clear inter-instance\nmargins. By maintaining this contrastive signal across both adaptation and\ndistillation, we align teacher and student embeddings and fully leverage\nunlabeled images. On Cityscapes and ADE20K, our ~11X smaller student surpasses\nits adapted VFM teacher(s) by +3.4 AP (33.9 vs. 30.5) and +1.5 AP (16.7 vs.\n15.2) and outperforms state-of-the-art semi-supervised approaches.','Pardis Taghavi, Tian Liu, Renjie Li, Reza Langari, Zhengzhong Tu','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.21904v1','该论文提出了一种半监督知识蒸馏（SSKD）框架CAST，通过有限标记和丰富未标记数据将预训练的视觉基础模型（VFM）压缩成紧凑的专家，以实现实例分割。CAST包括三个阶段：VFM教师的领域自适应，蒸馏成紧凑的学生，以及在标记数据上微调。关键是引入了一种实例感知的像素级对比损失，通过融合掩模和类别分数来挖掘信息负例并强制执行清晰的实例间间隔。在Cityscapes和ADE20K数据集上，学生模型的性能优于VFM教师和半监督方法。'),('2505.21906v1','Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge','Vision-language-action (VLA) models have emerged as the next generation of\nmodels in robotics. However, despite leveraging powerful pre-trained\nVision-Language Models (VLMs), existing end-to-end VLA systems often lose key\ncapabilities during fine-tuning as the model adapts to specific robotic tasks.\nWe argue that a generalizable VLA model should retain and expand upon the VLM\\\'s\ncore competencies: 1) Open-world embodied reasoning - the VLA should inherit\nthe knowledge from VLM, i.e., recognize anything that the VLM can recognize,\ncapable of solving math problems, possessing visual-spatial intelligence, 2)\nReasoning following - effectively translating the open-world reasoning into\nactionable steps for the robot. In this work, we introduce ChatVLA-2, a novel\nmixture-of-expert VLA model coupled with a specialized three-stage training\npipeline designed to preserve the VLM\\\'s original strengths while enabling\nactionable reasoning. To validate our approach, we design a math-matching task\nwherein a robot interprets math problems written on a whiteboard and picks\ncorresponding number cards from a table to solve equations. Remarkably, our\nmethod exhibits exceptional mathematical reasoning and OCR capabilities,\ndespite these abilities not being explicitly trained within the VLA.\nFurthermore, we demonstrate that the VLA possesses strong spatial reasoning\nskills, enabling it to interpret novel directional instructions involving\npreviously unseen objects. Overall, our method showcases reasoning and\ncomprehension abilities that significantly surpass state-of-the-art imitation\nlearning methods such as OpenVLA, DexVLA, and pi-zero. This work represents a\nsubstantial advancement toward developing truly generalizable robotic\nfoundation models endowed with robust reasoning capacities.','Zhongyi Zhou, Yichen Zhu, Junjie Wen, Chaomin Shen, Yi Xu','2025-05-28','cs.RO','视觉-语言-行动模型 (VLA)','http://arxiv.org/pdf/2505.21906v1','该论文介绍了一种新型的混合专家 VLA 模型 ChatVLA-2，通过专门设计的三阶段训练流程，保留了 VLM 的原始优势，并实现了可操作的推理能力。通过数学匹配任务验证了该方法在数学推理和 OCR 能力上的出色表现，同时展示了强大的空间推理能力。'),('2505.21907v1','Modeling and Optimizing User Preferences in AI Copilots: A Comprehensive Survey and Taxonomy','AI copilots, context-aware, AI-powered systems designed to assist users in\ntasks such as software development and content creation, are becoming integral\nto modern workflows. As these systems grow in capability and adoption,\npersonalization has emerged as a cornerstone for ensuring usability, trust, and\nproductivity. Central to this personalization is preference optimization: the\nability of AI copilots to detect, interpret, and align with individual user\npreferences. While personalization techniques are well-established in domains\nlike recommender systems and dialogue agents, their adaptation to interactive,\nreal-time systems like AI copilots remains fragmented and underexplored. This\nsurvey addresses this gap by synthesizing research on how user preferences are\ncaptured, modeled, and refined within the design of AI copilots. We introduce a\nunified definition of AI copilots and propose a phase-based taxonomy of\npreference optimization strategies, structured around pre-interaction,\nmid-interaction, and post-interaction stages. We analyze techniques for\nacquiring preference signals, modeling user intent, and integrating feedback\nloops, highlighting both established approaches and recent innovations. By\nbridging insights from AI personalization, human-AI collaboration, and large\nlanguage model adaptation, this survey provides a structured foundation for\ndesigning adaptive, preference-aware AI copilots. It offers a holistic view of\nthe available preference resources, how they can be leveraged, and which\ntechnical approaches are most suited to each stage of system design.','Saleh Afzoon, Zahra Jahanandish, Phuong Thao Huynh, Amin Beheshti, Usman Naseem','2025-05-28','cs.AI','人机协作、AI个性化','http://arxiv.org/pdf/2505.21907v1','该论文综合了关于如何捕获、建模和优化用户偏好的研究，以设计适应性、偏好感知的AI副驾驶系统。'),('2505.21908v1','Reinforcement Learning for Out-of-Distribution Reasoning in LLMs: An Empirical Study on Diagnosis-Related Group Coding','Diagnosis-Related Group (DRG) codes are essential for hospital reimbursement\nand operations but require labor-intensive assignment. Large Language Models\n(LLMs) struggle with DRG coding due to the out-of-distribution (OOD) nature of\nthe task: pretraining corpora rarely contain private clinical or billing data.\nWe introduce DRG-Sapphire, which uses large-scale reinforcement learning (RL)\nfor automated DRG coding from clinical notes. Built on Qwen2.5-7B and trained\nwith Group Relative Policy Optimization (GRPO) using rule-based rewards,\nDRG-Sapphire introduces a series of RL enhancements to address domain-specific\nchallenges not seen in previous mathematical tasks. Our model achieves\nstate-of-the-art accuracy on the MIMIC-IV benchmark and generates\nphysician-validated reasoning for DRG assignments, significantly enhancing\nexplainability. Our study further sheds light on broader challenges of applying\nRL to knowledge-intensive, OOD tasks. We observe that RL performance scales\napproximately linearly with the logarithm of the number of supervised\nfine-tuning (SFT) examples, suggesting that RL effectiveness is fundamentally\nconstrained by the domain knowledge encoded in the base model. For OOD tasks\nlike DRG coding, strong RL performance requires sufficient knowledge infusion\nprior to RL. Consequently, scaling SFT may be more effective and\ncomputationally efficient than scaling RL alone for such tasks.','Hanyin Wang, Zhenbang Wu, Gururaj Kolar, Hariprasad Korsapati, Brian Bartlett, Bryan Hull, Jimeng Sun','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.21908v1','该论文介绍了一种利用大规模强化学习进行自动 DRG 编码的方法，通过 Qwen2.5-7B 模型和 Group Relative Policy Optimization (GRPO) 训练，取得了MIMIC-IV基准上的最先进准确性，并提高了可解释性。'),('2505.21910v1','Taming Transformer Without Using Learning Rate Warmup','Scaling Transformer to a large scale without using some technical tricks such\nas learning rate warump and using an obviously lower learning rate is an\nextremely challenging task, and is increasingly gaining more attention. In this\npaper, we provide a theoretical analysis for the process of training\nTransformer and reveal the rationale behind the model crash phenomenon in the\ntraining process, termed \\textit{spectral energy concentration} of\n${\\bW_q}^{\\top} \\bW_k$, which is the reason for a malignant entropy collapse,\nwhere ${\\bW_q}$ and $\\bW_k$ are the projection matrices for the query and the\nkey in Transformer, respectively. To remedy this problem, motivated by\n\\textit{Weyl\\\'s Inequality}, we present a novel optimization strategy, \\ie,\nmaking the weight updating in successive steps smooth -- if the ratio\n$\\frac{\\sigma_{1}(\\nabla \\bW_t)}{\\sigma_{1}(\\bW_{t-1})}$ is larger than a\nthreshold, we will automatically bound the learning rate to a weighted multiple\nof $\\frac{\\sigma_{1}(\\bW_{t-1})}{\\sigma_{1}(\\nabla \\bW_t)}$, where $\\nabla\n\\bW_t$ is the updating quantity in step $t$. Such an optimization strategy can\nprevent spectral energy concentration to only a few directions, and thus can\navoid malignant entropy collapse which will trigger the model crash. We conduct\nextensive experiments using ViT, Swin-Transformer and GPT, showing that our\noptimization strategy can effectively and stably train these Transformers\nwithout using learning rate warmup.','Xianbiao Qi, Yelin He, Jiaquan Ye, Chun-Guang Li, Bojia Zi, Xili Dai, Qin Zou, Rong Xiao','2025-05-28','cs.LG','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.21910v1','本文提出了一种针对Transformer模型训练过程中出现的模型崩溃现象的优化策略，通过使权重更新在连续步骤中平滑进行，避免了谱能量集中导致的恶性熵崩溃。实验证明该优化策略可以有效稳定地训练Transformer模型，而无需使用学习率预热。'),('2505.21918v1','Self-supervised Learning Method Using Transformer for Multi-dimensional Sensor Data Processing','We developed a deep learning algorithm for human activity recognition using\nsensor signals as input. In this study, we built a pretrained language model\nbased on the Transformer architecture, which is widely used in natural language\nprocessing. By leveraging this pretrained model, we aimed to improve\nperformance on the downstream task of human activity recognition. While this\ntask can be addressed using a vanilla Transformer, we propose an enhanced\nn-dimensional numerical processing Transformer that incorporates three key\nfeatures: embedding n-dimensional numerical data through a linear layer,\nbinning-based pre-processing, and a linear transformation in the output layer.\nWe evaluated the effectiveness of our proposed model across five different\ndatasets. Compared to the vanilla Transformer, our model demonstrated 10%-15%\nimprovements in accuracy.','Haruki Kai, Tsuyoshi Okita','2025-05-28','cs.LG','LLM (预训练语言模型)','http://arxiv.org/pdf/2505.21918v1','该论文提出了一种基于Transformer架构的深度学习算法，用于利用传感器信号进行人类活动识别。通过预训练语言模型，提出了一种增强的n维数值处理Transformer，包括通过线性层嵌入n维数值数据、基于分箱的预处理以及输出层的线性变换。在五个不同数据集上评估了该模型的有效性，相较于普通Transformer，该模型在准确性上提升了10%-15%。'),('2505.21919v1','Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference','The increasing adoption of large language models (LLMs) with extended context\nwindows necessitates efficient Key-Value Cache (KVC) management to optimize\ninference performance. Inference workloads like Retrieval-Augmented Generation\n(RAG) and agents exhibit high cache reusability, making efficient caching\ncritical to reducing redundancy and improving speed. We analyze real-world KVC\naccess patterns using publicly available traces and evaluate commercial\nkey-value stores like Redis and state-of-the-art RDMA-based systems (CHIME [1]\nand Sherman [2]) for KVC metadata management. Our work demonstrates the lack of\ntailored storage solution for KVC prefilling, underscores the need for an\nefficient distributed caching system with optimized metadata management for LLM\nworkloads, and provides insights into designing improved KVC management systems\nfor scalable, low-latency inference.','Yue Zhu, Hao Yu, Chen Wang, Zhuoran Liu, Eun Kyung Lee','2025-05-28','cs.ET','大型语言模型(LLM)','http://arxiv.org/pdf/2505.21919v1','该论文研究了随着大型语言模型（LLMs）的广泛采用，需要高效的Key-Value Cache（KVC）管理来优化推理性能的问题。通过分析真实世界的KVC访问模式，并评估商业键值存储和最先进的基于RDMA的系统，论文提出了对LLM工作负载进行优化的需求，并提供了设计改进KVC管理系统的见解。'),('2505.21923v1','FALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design','Designing analog circuits from performance specifications is a complex,\nmulti-stage process encompassing topology selection, parameter inference, and\nlayout feasibility. We introduce FALCON, a unified machine learning framework\nthat enables fully automated, specification-driven analog circuit synthesis\nthrough topology selection and layout-constrained optimization. Given a target\nperformance, FALCON first selects an appropriate circuit topology using a\nperformance-driven classifier guided by human design heuristics. Next, it\nemploys a custom, edge-centric graph neural network trained to map circuit\ntopology and parameters to performance, enabling gradient-based parameter\ninference through the learned forward model. This inference is guided by a\ndifferentiable layout cost, derived from analytical equations capturing\nparasitic and frequency-dependent effects, and constrained by design rules. We\ntrain and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wave\ncircuits, generated and simulated using Cadence Spectre across 20\nexpert-designed topologies. Through this evaluation, FALCON demonstrates >99\\%\naccuracy in topology inference, <10\\% relative error in performance prediction,\nand efficient layout-aware design that completes in under 1 second per\ninstance. Together, these results position FALCON as a practical and extensible\nfoundation model for end-to-end analog circuit design automation.','Asal Mehradfar, Xuzhe Zhao, Yilun Huang, Emir Ceyani, Yankai Yang, Shihao Han, Hamidreza Aghasi, Salman Avestimehr','2025-05-28','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.21923v1','该论文介绍了一种名为FALCON的统一机器学习框架，通过拓扑选择和布局受限优化实现全自动、规范驱动的模拟电路合成。FALCON首先使用性能驱动的分类器选择适当的电路拓扑，然后利用自定义的图神经网络进行参数推断，通过学习的前向模型将电路拓扑和参数映射到性能，同时考虑布局成本和设计规则。在大规模数据集上训练和评估后，FALCON在拓扑推断上表现超过99%的准确率，在性能预测上相对误差小于10%，并且在每个实例下的设计时间不到1秒。'),('2505.21925v1','RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination','We present RenderFormer, a neural rendering pipeline that directly renders an\nimage from a triangle-based representation of a scene with full global\nillumination effects and that does not require per-scene training or\nfine-tuning. Instead of taking a physics-centric approach to rendering, we\nformulate rendering as a sequence-to-sequence transformation where a sequence\nof tokens representing triangles with reflectance properties is converted to a\nsequence of output tokens representing small patches of pixels. RenderFormer\nfollows a two stage pipeline: a view-independent stage that models\ntriangle-to-triangle light transport, and a view-dependent stage that\ntransforms a token representing a bundle of rays to the corresponding pixel\nvalues guided by the triangle-sequence from the view-independent stage. Both\nstages are based on the transformer architecture and are learned with minimal\nprior constraints. We demonstrate and evaluate RenderFormer on scenes with\nvarying complexity in shape and light transport.','Chong Zeng, Yue Dong, Pieter Peers, Hongzhi Wu, Xin Tong','2025-05-28','cs.GR','图像识别','http://arxiv.org/pdf/2505.21925v1','该论文介绍了RenderFormer，一个神经渲染管道，可以直接从基于三角形表示的场景中渲染图像，实现全局光照效果，无需对每个场景进行训练或微调。该方法将渲染视为一个序列到序列的转换过程，通过两阶段的流水线实现渲染：一个独立于视角的阶段模拟三角形之间的光传输，一个依赖于视角的阶段将光束表示的令牌转换为对应像素值。这两个阶段都基于Transformer架构，学习过程中受到最小的先验约束。研究在形状和光传输复杂性不同的场景上进行了演示和评估。'),('2505.21926v1','Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning','In natural language processing (NLP) and computer vision (CV), the successful\napplication of foundation models across diverse tasks has demonstrated their\nremarkable potential. However, despite the rich structural and textual\ninformation embedded in knowledge graphs (KGs), existing research of foundation\nmodel for KG has primarily focused on their structural aspects, with most\nefforts restricted to in-KG tasks (e.g., knowledge graph completion, KGC). This\nlimitation has hindered progress in addressing more challenging out-of-KG\ntasks. In this paper, we introduce MERRY, a foundation model for general\nknowledge graph reasoning, and investigate its performance across two task\ncategories: in-KG reasoning tasks (e.g., KGC) and out-of-KG tasks (e.g., KG\nquestion answering, KGQA). We not only utilize the structural information, but\nalso the textual information in KGs. Specifically, we propose a\nmulti-perspective Conditional Message Passing (CMP) encoding architecture to\nbridge the gap between textual and structural modalities, enabling their\nseamless integration. Additionally, we introduce a dynamic residual fusion\nmodule to selectively retain relevant textual information and a flexible edge\nscoring mechanism to adapt to diverse downstream tasks. Comprehensive\nevaluations on 28 datasets demonstrate that MERRY outperforms existing\nbaselines in most scenarios, showcasing strong reasoning capabilities within\nKGs and excellent generalization to out-of-KG tasks such as KGQA.','Yin Hua, Zhiqiang Liu, Mingyang Chen, Zheng Fang, Chi Man Wong, Lingxiao Li, Chi Man Vong, Huajun Chen, Wen Zhang','2025-05-28','cs.CL','自然语言处理、知识图谱','http://arxiv.org/pdf/2505.21926v1','该论文介绍了一种名为MERRY的基础模型，用于通用知识图谱推理，研究了在知识图谱内部推理任务和知识图谱外部任务中的性能。他们不仅利用了知识图谱中的结构信息，还利用了文本信息，并提出了一种多角度条件消息传递（CMP）编码架构来桥接文本和结构模态之间的差距，实现无缝集成。'),('2505.21928v1','Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology','Gastrointestinal (GI) diseases represent a clinically significant burden,\nnecessitating precise diagnostic approaches to optimize patient outcomes.\nConventional histopathological diagnosis, heavily reliant on the subjective\ninterpretation of pathologists, suffers from limited reproducibility and\ndiagnostic variability. To overcome these limitations and address the lack of\npathology-specific foundation models for GI diseases, we develop Digepath, a\nspecialized foundation model for GI pathology. Our framework introduces a\ndual-phase iterative optimization strategy combining pretraining with\nfine-screening, specifically designed to address the detection of sparsely\ndistributed lesion areas in whole-slide images. Digepath is pretrained on more\nthan 353 million image patches from over 200,000 hematoxylin and eosin-stained\nslides of GI diseases. It attains state-of-the-art performance on 33 out of 34\ntasks related to GI pathology, including pathological diagnosis, molecular\nprediction, gene mutation prediction, and prognosis evaluation, particularly in\ndiagnostically ambiguous cases and resolution-agnostic tissue classification.We\nfurther translate the intelligent screening module for early GI cancer and\nachieve near-perfect 99.6% sensitivity across 9 independent medical\ninstitutions nationwide. The outstanding performance of Digepath highlights its\npotential to bridge critical gaps in histopathological practice. This work not\nonly advances AI-driven precision pathology for GI diseases but also\nestablishes a transferable paradigm for other pathology subspecialties.','Lianghui Zhu, Xitong Ling, Minxi Ouyang, Xiaoping Liu, Mingxi Fu, Tian Guan, Fanglei Fu, Xuanyu Wang, Maomao Zeng, Mingxi Zhu, Yibo Jin, Liming Liu, Song Duan, Qiming He, Yizhi Wang, Luxi Xie, Houqiang Li, Yonghong He, Sufang Tian','2025-05-28','eess.IV','图像识别','http://arxiv.org/pdf/2505.21928v1','该论文介绍了一种针对胃肠病理学的专门基础模型Digepath，通过预训练和微调相结合的优化策略，在整张切片图像中检测稀疏分布的病变区域，取得了在胃肠病理学相关任务中的最先进性能，特别是在诊断模糊的情况下表现出色。'),('2505.21930v1','Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets','This paper develops an ensemble method for fine-tuning a language model to\nmultiple datasets. Existing methods, such as quantized LoRA (QLoRA), are\nefficient when adapting to a single dataset. When training on multiple datasets\nof different tasks, a common setup in practice, it remains unclear how to\ndesign an efficient adaptation for fine-tuning language models. We propose to\nuse an ensemble of multiple smaller adapters instead of a single adapter per\ntask. We design an efficient algorithm that partitions $n$ datasets into $m$\ngroups, where $m$ is typically much smaller than $n$ in practice, and train one\nadapter for each group before taking a weighted combination to form the\nensemble. The algorithm leverages a first-order approximation property of\nlow-rank adaptation to quickly obtain the fine-tuning performances of dataset\ncombinations since methods like LoRA stay close to the base model. Hence, we\nuse the gradients of the base model to estimate its behavior during\nfine-tuning. Empirically, this approximation holds with less than $1\\%$ error\non models with up to $34$ billion parameters, leading to an estimation of true\nfine-tuning performances under $5\\%$ error while speeding up computation\ncompared to base fine-tuning by $105$ times. When applied to fine-tune Llama\nand GPT models on ten text classification tasks, our approach provides up to\n$10\\%$ higher average test accuracy over QLoRA, with only $9\\%$ more FLOPs. On\na Llama model with $34$ billion parameters, an ensemble of QLoRA increases test\naccuracy by $3\\%$ compared to QLoRA, with only $8\\%$ more FLOPs.','Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang R. Zhang','2025-05-28','cs.LG','LLM (语言模型微调)','http://arxiv.org/pdf/2505.21930v1','本文提出了一种集成方法，用于对语言模型进行对多个数据集的微调。通过使用多个较小的适配器的集成，训练效果比单个适配器更好，能够在多个数据集上实现更高的测试准确率。'),('2505.21932v1','Higher-Order Group Synchronization','Group synchronization is the problem of determining reliable global estimates\nfrom noisy local measurements on networks. The typical task for group\nsynchronization is to assign elements of a group to the nodes of a graph in a\nway that respects group elements given on the edges which encode information\nabout local pairwise relationships between the nodes. In this paper, we\nintroduce a novel higher-order group synchronization problem which operates on\na hypergraph and seeks to synchronize higher-order local measurements on the\nhyperedges to obtain global estimates on the nodes. Higher-order group\nsynchronization is motivated by applications to computer vision and image\nprocessing, among other computational problems. First, we define the problem of\nhigher-order group synchronization and discuss its mathematical foundations.\nSpecifically, we give necessary and sufficient synchronizability conditions\nwhich establish the importance of cycle consistency in higher-order group\nsynchronization. Then, we propose the first computational framework for general\nhigher-order group synchronization; it acts globally and directly on\nhigher-order measurements using a message passing algorithm. We discuss\ntheoretical guarantees for our framework, including convergence analyses under\noutliers and noise. Finally, we show potential advantages of our method through\nnumerical experiments. In particular, we show that in certain cases our\nhigher-order method applied to rotational and angular synchronization\noutperforms standard pairwise synchronization methods and is more robust to\noutliers. We also show that our method has comparable performance on simulated\ncryo-electron microscopy (cryo-EM) data compared to a standard cryo-EM\nreconstruction package.','Adriana L. Duncan, Joe Kileel','2025-05-28','stat.ML','图像识别','http://arxiv.org/pdf/2505.21932v1','本文介绍了一种新颖的高阶群同步问题，通过在超图上进行操作，旨在同步高阶局部测量以获得节点上的全局估计。作者提出了第一个通用的高阶群同步计算框架，并展示了在某些情况下，其方法在旋转和角度同步方面优于标准的成对同步方法，并且对异常值更加稳健。'),('2505.21935v1','From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models','Since the advent of Large Language Models (LLMs), efforts have largely\nfocused on improving their instruction-following and deductive reasoning\nabilities, leaving open the question of whether these models can truly discover\nnew knowledge. In pursuit of artificial general intelligence (AGI), there is a\ngrowing need for models that not only execute commands or retrieve information\nbut also learn, reason, and generate new knowledge by formulating novel\nhypotheses and theories that deepen our understanding of the world. Guided by\nPeirce\\\'s framework of abduction, deduction, and induction, this survey offers a\nstructured lens to examine LLM-based hypothesis discovery. We synthesize\nexisting work in hypothesis generation, application, and validation,\nidentifying both key achievements and critical gaps. By unifying these threads,\nwe illuminate how LLMs might evolve from mere ``information executors\\\'\\\' into\nengines of genuine innovation, potentially transforming research, science, and\nreal-world problem solving.','Kaiyu He, Zhiyu Chen','2025-05-28','cs.AI','LLM','http://arxiv.org/pdf/2505.21935v1','本文探讨了大型语言模型（LLMs）在假设发现方面的应用，通过Peirce的观点对LLMs进行了分析，提出了LLMs可能从信息执行者发展为真正创新引擎的观点。'),('2505.21937v1','Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic Languages','Translating multi-word expressions (MWEs) and idioms requires a deep\nunderstanding of the cultural nuances of both the source and target languages.\nThis challenge is further amplified by the one-to-many nature of idiomatic\ntranslations, where a single source idiom can have multiple target-language\nequivalents depending on cultural references and contextual variations.\nTraditional static knowledge graphs (KGs) and prompt-based approaches struggle\nto capture these complex relationships, often leading to suboptimal\ntranslations. To address this, we propose IdiomCE, an adaptive graph neural\nnetwork (GNN) based methodology that learns intricate mappings between\nidiomatic expressions, effectively generalizing to both seen and unseen nodes\nduring training. Our proposed method enhances translation quality even in\nresource-constrained settings, facilitating improved idiomatic translation in\nsmaller models. We evaluate our approach on multiple idiomatic translation\ndatasets using reference-less metrics, demonstrating significant improvements\nin translating idioms from English to various Indian languages.','Pratik Rakesh Singh, Kritarth Prasad, Mohammadi Zaki, Pankaj Wasnik','2025-05-28','cs.CL','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.21937v1','该论文提出了一种基于自适应图神经网络（GNN）的方法，名为IdiomCE，用于学习成语表达之间的复杂关系，能够在训练过程中泛化到已知和未知节点，从而提高成语翻译的质量。'),('2505.21938v1','Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection','Adversarial attacks on stochastic bandits have traditionally relied on some\nunrealistic assumptions, such as per-round reward manipulation and unbounded\nperturbations, limiting their relevance to real-world systems. We propose a\nmore practical threat model, Fake Data Injection, which reflects realistic\nadversarial constraints: the attacker can inject only a limited number of\nbounded fake feedback samples into the learner\\\'s history, simulating legitimate\ninteractions. We design efficient attack strategies under this model,\nexplicitly addressing both magnitude constraints (on reward values) and\ntemporal constraints (on when and how often data can be injected). Our\ntheoretical analysis shows that these attacks can mislead both Upper Confidence\nBound (UCB) and Thompson Sampling algorithms into selecting a target arm in\nnearly all rounds while incurring only sublinear attack cost. Experiments on\nsynthetic and real-world datasets validate the effectiveness of our strategies,\nrevealing significant vulnerabilities in widely used stochastic bandit\nalgorithms under practical adversarial scenarios.','Qirun Zeng, Eric He, Richard Hoffmann, Xuchuang Wang, Jinhang Zuo','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.21938v1','该论文提出了一种更加实际的对抗模型——虚假数据注入，针对随机赌博机制进行攻击。他们设计了有效的攻击策略，并在理论和实验上验证了这些策略的有效性。'),('2505.21940v1','RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering','Large Language Models (LLMs) excel in many areas but continue to face\nchallenges with complex reasoning tasks, such as Multi-Hop Question Answering\n(MHQA). MHQA requires integrating evidence from diverse sources while managing\nintricate logical dependencies, often leads to errors in reasoning.\nRetrieval-Augmented Generation (RAG), widely employed in MHQA tasks, faces\nchallenges in effectively filtering noisy data and retrieving all necessary\nevidence, thereby limiting its effectiveness in addressing MHQA challenges. To\naddress these challenges, we propose RISE:Reasoning Enhancement via Iterative\nSelf-Exploration, a novel framework designed to enhance models\\\' reasoning\ncapability through iterative self-exploration. Specifically, RISE involves\nthree key steps in addressing MHQA tasks: question decomposition,\nretrieve-then-read, and self-critique. By leveraging continuous\nself-exploration, RISE identifies accurate reasoning paths, iteratively\nself-improving the model\\\'s capability to integrate evidence, maintain logical\nconsistency, and enhance performance in MHQA tasks. Extensive experiments on\nmultiple MHQA benchmarks demonstrate that RISE significantly improves reasoning\naccuracy and task performance.','Bolei He, Xinran He, Mengke Chen, Xianwei Xue, Ying Zhu, Zhenhua Ling','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21940v1','该论文提出了一种名为RISE的新框架，旨在通过迭代自我探索增强模型的推理能力，以解决多跳问题回答任务中的推理挑战。RISE通过问题分解、检索-阅读和自我批判等关键步骤，利用持续的自我探索来提高模型的推理准确性和任务性能。'),('2505.21941v1','Test-Time Scaling with Repeated Sampling Improves Multilingual Text Generation','Inference-time scaling via repeated sampling has shown promise in reasoning\ntasks, but its effectiveness in multilingual generation remains underexplored.\nWe evaluate this approach using perplexity- and reward-based verifiers on two\nmultilingual benchmarks: the Aya Evaluation Suite and m-ArenaHard. Our results\nshow consistent quality improvements, with gains exceeding 35% in some cases.\nWhile perplexity-based scoring is effective for open-ended prompts, only\nreward-based verifiers improve performance on tasks requiring reasoning (e.g.,\nmath, code). Our results demonstrate the broader utility of repeated sampling\nfor multilingual text generation and underscore the importance of selecting\nright verifiers for the task.','Ashim Gupta, Vivek Srikumar','2025-05-28','cs.CL','生成模型','http://arxiv.org/pdf/2505.21941v1','该论文研究了在多语言生成任务中使用推理时间缩放的方法，通过在两个多语言基准测试中评估该方法的有效性，结果显示在某些情况下可以获得超过35%的质量改进。在开放式提示方面，基于困惑度的评分是有效的，但只有基于奖励的验证器可以提高需要推理的任务（如数学、代码）的性能。'),('2505.21942v1','Continual Learning Beyond Experience Rehearsal and Full Model Surrogates','Continual learning (CL) has remained a significant challenge for deep neural\nnetworks as learning new tasks erases previously acquired knowledge, either\npartially or completely. Existing solutions often rely on experience rehearsal\nor full model surrogates to mitigate CF. While effective, these approaches\nintroduce substantial memory and computational overhead, limiting their\nscalability and applicability in real-world scenarios. To address this, we\npropose SPARC, a scalable CL approach that eliminates the need for experience\nrehearsal and full-model surrogates. By effectively combining task-specific\nworking memories and task-agnostic semantic memory for cross-task knowledge\nconsolidation, SPARC results in a remarkable parameter efficiency, using only\n6% of the parameters required by full-model surrogates. Despite its lightweight\ndesign, SPARC achieves superior performance on Seq-TinyImageNet and matches\nrehearsal-based methods on various CL benchmarks. Additionally, weight\nre-normalization in the classification layer mitigates task-specific biases,\nestablishing SPARC as a practical and scalable solution for CL under stringent\nefficiency constraints.','Prashant Bhat, Laurens Niesten, Elahe Arani, Bahram Zonooz','2025-05-28','cs.LG','持续学习 (Continual Learning)','http://arxiv.org/pdf/2505.21942v1','该论文提出了一种名为SPARC的可扩展的持续学习方法，通过有效结合任务特定的工作记忆和任务不可知的语义记忆，实现了出色的参数效率，仅使用全模型替代品所需参数的6%。SPARC在Seq-TinyImageNet上表现出色，并在各种持续学习基准测试中与基于经验重演的方法相匹敌。此外，分类层中的权重重新归一化有助于减轻任务特定的偏见，使SPARC成为在严格效率约束下的实用和可扩展解决方案。'),('2505.21954v1','UniTalk: Towards Universal Active Speaker Detection in Real World Scenarios','We present UniTalk, a novel dataset specifically designed for the task of\nactive speaker detection, emphasizing challenging scenarios to enhance model\ngeneralization. Unlike previously established benchmarks such as AVA, which\npredominantly features old movies and thus exhibits significant domain gaps,\nUniTalk focuses explicitly on diverse and difficult real-world conditions.\nThese include underrepresented languages, noisy backgrounds, and crowded scenes\n- such as multiple visible speakers speaking concurrently or in overlapping\nturns. It contains over 44.5 hours of video with frame-level active speaker\nannotations across 48,693 speaking identities, and spans a broad range of video\ntypes that reflect real-world conditions. Through rigorous evaluation, we show\nthat state-of-the-art models, while achieving nearly perfect scores on AVA,\nfail to reach saturation on UniTalk, suggesting that the ASD task remains far\nfrom solved under realistic conditions. Nevertheless, models trained on UniTalk\ndemonstrate stronger generalization to modern \"in-the-wild\" datasets like\nTalkies and ASW, as well as to AVA. UniTalk thus establishes a new benchmark\nfor active speaker detection, providing researchers with a valuable resource\nfor developing and evaluating versatile and resilient models.\n  Dataset: https://huggingface.co/datasets/plnguyen2908/UniTalk-ASD\n  Code: https://github.com/plnguyen2908/UniTalk-ASD-code','Le Thien Phuc Nguyen, Zhuoran Yu, Khoa Quang Nhat Cao, Yuwei Guo, Tu Ho Manh Pham, Tuan Tai Nguyen, Toan Ngo Duc Vo, Lucas Poon, Soochahn Lee, Yong Jae Lee','2025-05-28','cs.CV','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.21954v1','该论文介绍了UniTalk数据集，专门设计用于活跃说话者检测任务，强调挑战性场景以增强模型泛化能力。通过严格评估，研究表明，尽管现有模型在AVA数据集上表现接近完美，但在UniTalk上仍未达到饱和状态，表明活跃说话者检测任务在现实条件下仍未解决。然而，经过UniTalk训练的模型展现出对现代“野外”数据集和AVA的更强泛化能力。'),('2505.21955v1','Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs','Large vision-language models (LVLMs) are increasingly deployed in interactive\napplications such as virtual and augmented reality, where first-person\n(egocentric) view captured by head-mounted cameras serves as key input. While\nthis view offers fine-grained cues about user attention and hand-object\ninteractions, their narrow field of view and lack of global context often lead\nto failures on spatially or contextually demanding queries. To address this, we\nintroduce a framework that augments egocentric inputs with third-person\n(exocentric) views, providing complementary information such as global scene\nlayout and object visibility to LVLMs. We present E3VQA, the first benchmark\nfor multi-view question answering with 4K high-quality question-answer pairs\ngrounded in synchronized ego-exo image pairs. Additionally, we propose M3CoT, a\ntraining-free prompting technique that constructs a unified scene\nrepresentation by integrating scene graphs from three complementary\nperspectives. M3CoT enables LVLMs to reason more effectively across views,\nyielding consistent performance gains (4.84% for GPT-4o and 5.94% for Gemini\n2.0 Flash) over a recent CoT baseline. Our extensive evaluation reveals key\nstrengths and limitations of LVLMs in multi-view reasoning and highlights the\nvalue of leveraging both egocentric and exocentric inputs.','Insu Lee, Wooje Park, Jaeyun Jang, Minyoung Noh, Kyuhong Shim, Byonghyo Shim','2025-05-28','cs.CV','视觉语言模型（LLM）','http://arxiv.org/pdf/2505.21955v1','该论文提出了一种框架，通过将第一人称视角（egocentric）与第三人称视角（exocentric）相结合，为大规模视觉语言模型（LVLMs）提供全局场景布局和物体可见性等补充信息，从而提高模型在多视图推理任务上的性能。'),('2505.21956v1','Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation','Text-to-image generation increasingly demands access to domain-specific,\nfine-grained, and rapidly evolving knowledge that pretrained models cannot\nfully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to\naddress this by retrieving globally relevant images, but they fail when no\nsingle image contains all desired elements from a complex user query. We\npropose Cross-modal RAG, a novel framework that decomposes both queries and\nimages into sub-dimensional components, enabling subquery-aware retrieval and\ngeneration. Our method introduces a hybrid retrieval strategy - combining a\nsub-dimensional sparse retriever with a dense retriever - to identify a\nPareto-optimal set of images, each contributing complementary aspects of the\nquery. During generation, a multimodal large language model is guided to\nselectively condition on relevant visual features aligned to specific\nsubqueries, ensuring subquery-aware image synthesis. Extensive experiments on\nMS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal\nRAG significantly outperforms existing baselines in both retrieval and\ngeneration quality, while maintaining high efficiency.','Mengdan Zhu, Senhao Cheng, Guangji Bai, Yifei Zhang, Liang Zhao','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.21956v1','本文提出了一种新颖的跨模态检索增强生成框架，将查询和图像分解为子维度组件，实现子查询感知的检索和生成。通过引入混合检索策略，结合稀疏检索器和密集检索器，识别出一组 Pareto 最优图像，每个图像都贡献了查询的互补方面。在生成过程中，多模态大型语言模型被引导选择性地依赖于与特定子查询对齐的相关视觉特征，确保子查询感知的图像合成。'),('2505.21958v1','Resolving Knowledge Conflicts in Domain-specific Data Selection: A Case Study on Medical Instruction-tuning','Domain-specific instruction-tuning has become the defacto standard for\nimproving the performance of large language models (LLMs) in specialized\napplications, e.g., medical question answering. Since the instruction-tuning\ndataset might contain redundant or low-quality data, data selection (DS) is\nusually required to maximize the data efficiency. Despite the successes in the\ngeneral domain, current DS methods often struggle to select the desired data\nfor domain-specific instruction-tuning. One of the main reasons is that they\nneglect the impact of knowledge conflicts, i.e., the discrepancy between LLMs\\\'\npretrained knowledge and context knowledge of instruction data, which could\ndamage LLMs\\\' prior abilities and lead to hallucination. To this end, we propose\na simple-yet-effective Knowledge-aware Data Selection (namely KDS) framework to\nselect the domain-specific instruction-tuning data that meets LLMs\\\' actual\nneeds. The core of KDS is to leverage two knowledge-aware metrics for\nquantitatively measuring knowledge conflicts from two aspects: context-memory\nknowledge alignment and intra-memory knowledge consistency. By filtering the\ndata with large knowledge conflicts and sampling the high-quality and diverse\ndata, KDS can effectively stimulate the LLMs\\\' abilities and achieve better\ndomain-specific performance. Taking the medical domain as the testbed, we\nconduct extensive experiments and empirically prove that KDS surpasses the\nother baselines and brings significant and consistent performance gains among\nall LLMs. More encouragingly, KDS effectively improves the model generalization\nand alleviates the hallucination problem.','Qihuang Zhong, Liang Ding, Fei Liao, Juhua Liu, Bo Du, Dacheng Tao','2025-05-28','cs.CL','LLM（大型语言模型）','http://arxiv.org/pdf/2505.21958v1','该论文提出了一种知识感知数据选择（KDS）框架，用于选择满足大型语言模型（LLMs）实际需求的领域特定指导调整数据。通过过滤具有较大知识冲突的数据并对高质量和多样化的数据进行抽样，KDS可以有效激发LLMs的能力，并实现更好的领域特定性能。'),('2505.21959v1','EnsemW2S: Enhancing Weak-to-Strong Generalization with Large Language Model Ensembles','With Large Language Models (LLMs) rapidly approaching and potentially\nsurpassing human-level performance, it has become imperative to develop\napproaches capable of effectively supervising and enhancing these powerful\nmodels using smaller, human-level models exposed to only human-level data. We\naddress this critical weak-to-strong (W2S) generalization challenge by\nproposing a novel method aimed at improving weak experts, by training on the\nsame limited human-level data, enabling them to generalize to complex,\nsuper-human-level tasks. Our approach, called \\textbf{EnsemW2S}, employs a\ntoken-level ensemble strategy that iteratively combines multiple weak experts,\nsystematically addressing the shortcomings identified in preceding iterations.\nBy continuously refining these weak models, we significantly enhance their\ncollective ability to supervise stronger student models. We extensively\nevaluate the generalization performance of both the ensemble of weak experts\nand the subsequent strong student model across in-distribution (ID) and\nout-of-distribution (OOD) datasets. For OOD, we specifically introduce question\ndifficulty as an additional dimension for defining distributional shifts. Our\nempirical results demonstrate notable improvements, achieving 4\\%, and 3.2\\%\nimprovements on ID datasets and, upto 6\\% and 2.28\\% on OOD datasets for\nexperts and student models respectively, underscoring the effectiveness of our\nproposed method in advancing W2S generalization.','Aakriti Agrawal, Mucong Ding, Zora Che, Chenghao Deng, Anirudh Satheesh, Bang An, Bayan Bruss, John Langford, Furong Huang','2025-05-28','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.21959v1','该论文提出了一种名为EnsemW2S的方法，通过在有限的人类级别数据上训练弱专家，使它们能够泛化到复杂的超人类级别任务，从而有效监督和增强大型语言模型。通过不断改进这些弱模型，显著提高它们共同监督更强的学生模型的能力。'),('2505.21963v1','LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents','Large Language Models (LLMs) have demonstrated exceptional performance across\na wide range of tasks. To further tailor LLMs to specific domains or\napplications, post-training techniques such as Supervised Fine-Tuning (SFT),\nPreference Learning, and model merging are commonly employed. While each of\nthese methods has been extensively studied in isolation, the automated\nconstruction of complete post-training pipelines remains an underexplored area.\nExisting approaches typically rely on manual design or focus narrowly on\noptimizing individual components, such as data ordering or merging strategies.\nIn this work, we introduce LaMDAgent (short for Language Model Developing\nAgent), a novel framework that autonomously constructs and optimizes full\npost-training pipelines through the use of LLM-based agents. LaMDAgent\nsystematically explores diverse model generation techniques, datasets, and\nhyperparameter configurations, leveraging task-based feedback to discover\nhigh-performing pipelines with minimal human intervention. Our experiments show\nthat LaMDAgent improves tool-use accuracy by 9.0 points while preserving\ninstruction-following capabilities. Moreover, it uncovers effective\npost-training strategies that are often overlooked by conventional human-driven\nexploration. We further analyze the impact of data and model size scaling to\nreduce computational costs on the exploration, finding that model size scalings\nintroduces new challenges, whereas scaling data size enables cost-effective\npipeline discovery.','Taro Yano, Yoichi Ishibashi, Masafumi Oyamada','2025-05-28','cs.CL','大语言模型（LLM）','http://arxiv.org/pdf/2505.21963v1','该论文介绍了一种名为LaMDAgent的新框架，通过LLM-based agents自动构建和优化完整的后训练流程，以发现高性能的流程，并减少人类干预。实验证明LaMDAgent提高了工具使用准确性，同时保留了指令遵循能力，并发现了传统人类驱动探索所忽视的有效后训练策略。'),('2505.21964v1','UI-Evol: Automatic Knowledge Evolving for Computer Use Agents','External knowledge has played a crucial role in the recent development of\ncomputer use agents. We identify a critical knowledge-execution gap: retrieved\nknowledge often fails to translate into effective real-world task execution.\nOur analysis shows even 90\\% correct knowledge yields only 41\\% execution\nsuccess rate. To bridge this gap, we propose UI-Evol, a plug-and-play module\nfor autonomous GUI knowledge evolution. UI-Evol consists of two stages: a\nRetrace Stage that extracts faithful objective action sequences from actual\nagent-environment interactions, and a Critique Stage that refines existing\nknowledge by comparing these sequences against external references. We conduct\ncomprehensive experiments on the OSWorld benchmark with the state-of-the-art\nAgent S2. Our results demonstrate that UI-Evol not only significantly boosts\ntask performance but also addresses a previously overlooked issue of high\nbehavioral standard deviation in computer use agents, leading to superior\nperformance on computer use tasks and substantially improved agent reliability.','Ziyun Zhang, Xinyi Liu, Xiaoyi Zhang, Jun Wang, Gang Chen, Yan Lu','2025-05-28','cs.HC','自然语言处理','http://arxiv.org/pdf/2505.21964v1','该论文提出了一个关键的问题，即外部知识在计算机使用代理程序的发展中起着至关重要的作用，但检索到的知识往往无法有效地转化为实际任务执行。为了解决这一问题，他们提出了一个自主GUI知识演化的插件模块UI-Evol，通过两个阶段来提高任务性能和代理可靠性。'),('2505.21966v1','MapStory: LLM-Powered Text-Driven Map Animation Prototyping with Human-in-the-Loop Editing','We introduce MapStory, an LLM-powered animation authoring tool that generates\neditable map animation sequences directly from natural language text. Given a\nuser-written script, MapStory leverages an agentic architecture to\nautomatically produce a scene breakdown, which decomposes the script into key\nanimation building blocks such as camera movements, visual highlights, and\nanimated elements. Our system includes a researcher component that accurately\nqueries geospatial information by leveraging an LLM with web search, enabling\nthe automatic extraction of relevant regions, paths, and coordinates while\nallowing users to edit and query for changes or additional information to\nrefine the results. Additionally, users can fine-tune parameters of these\nblocks through an interactive timeline editor. We detail the system\\\'s design\nand architecture, informed by formative interviews with professional animators\nand an analysis of 200 existing map animation videos. Our evaluation, which\nincludes expert interviews (N=5) and a usability study (N=12), demonstrates\nthat MapStory enables users to create map animations with ease, facilitates\nfaster iteration, encourages creative exploration, and lowers barriers to\ncreating map-centric stories.','Aditya Gunturu, Ben Pearman, Keiichi Ihara, Morteza Faraji, Bryan Wang, Rubaiat Habib Kazi, Ryo Suzuki','2025-05-28','cs.HC','LLM、自然语言处理','http://arxiv.org/pdf/2505.21966v1','该论文介绍了MapStory，这是一个由LLM驱动的动画制作工具，可以直接从自然语言文本生成可编辑的地图动画序列。通过用户编写的脚本，MapStory利用代理架构自动生成场景分解，将脚本分解为关键的动画构建模块，如摄像机移动、视觉亮点和动画元素。研究人员还可以通过与Web搜索结合的LLM准确查询地理空间信息，从而实现自动提取相关区域、路径和坐标，同时允许用户编辑和查询以完善结果。此外，用户可以通过交互式时间轴编辑器微调这些模块的参数。研究详细介绍了系统的设计和架构，经过与专业动画师的形成性访谈和对200个现有地图动画视频的分析。评估结果显示，MapStory使用户能够轻松创建地图动画，促进更快的迭代，鼓励创造性探索，并降低创建地图中心故事的障碍。'),('2505.21967v1','Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack','Large Vision-Language Models (LVLMs) have shown remarkable capabilities\nacross a wide range of multimodal tasks. However, their integration of visual\ninputs introduces expanded attack surfaces, thereby exposing them to novel\nsecurity vulnerabilities. In this work, we conduct a systematic\nrepresentational analysis to uncover why conventional adversarial attacks can\ncircumvent the safety mechanisms embedded in LVLMs. We further propose a novel\ntwo stage evaluation framework for adversarial attacks on LVLMs. The first\nstage differentiates among instruction non compliance, outright refusal, and\nsuccessful adversarial exploitation. The second stage quantifies the degree to\nwhich the model\\\'s output fulfills the harmful intent of the adversarial prompt,\nwhile categorizing refusal behavior into direct refusals, soft refusals, and\npartial refusals that remain inadvertently helpful. Finally, we introduce a\nnormative schema that defines idealized model behavior when confronted with\nharmful prompts, offering a principled target for safety alignment in\nmultimodal systems.','Juan Ren, Mark Dras, Usman Naseem','2025-05-28','cs.CL','安全性研究','http://arxiv.org/pdf/2505.21967v1','本文研究了大规模视觉-语言模型（LVLMs）在多模态任务中的安全性问题，通过系统性的表征分析揭示了传统对抗攻击如何规避LVLMs中的安全机制，并提出了一种新颖的两阶段对LVLMs的对抗攻击评估框架。'),('2505.21969v1','DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation','Adaptive navigation in unfamiliar environments is crucial for household\nservice robots but remains challenging due to the need for both low-level path\nplanning and high-level scene understanding. While recent vision-language model\n(VLM) based zero-shot approaches reduce dependence on prior maps and\nscene-specific training data, they face significant limitations: spatiotemporal\ndiscontinuity from discrete observations, unstructured memory representations,\nand insufficient task understanding leading to navigation failures. We propose\nDORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced Memory\nOriented Navigation), a novel cognitive-inspired framework consisting of\nVentral and Dorsal Streams that mimics human navigation capabilities. The\nDorsal Stream implements the Hierarchical Semantic-Spatial Fusion and Topology\nMap to handle spatiotemporal discontinuities, while the Ventral Stream combines\nRAG-VLM and Policy-VLM to improve decision-making. Our approach also develops\nNav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMON\non the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-art\nperformance on both success rate (SR) and success weighted by path length (SPL)\nmetrics, significantly outperforming existing methods. We also introduce a new\nevaluation metric (AORI) to assess navigation intelligence better.\nComprehensive experiments demonstrate DORAEMON\\\'s effectiveness in zero-shot\nautonomous navigation without requiring prior map building or pre-training.','Tianjun Gu, Linfeng Li, Xuhong Wang, Chenghua Gong, Jingyu Gong, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan','2025-05-28','cs.RO','自然语言处理','http://arxiv.org/pdf/2505.21969v1','该论文提出了一种新颖的认知启发框架 DORAEMON，通过模拟人类导航能力来解决家庭服务机器人在陌生环境中的自适应导航问题。该框架结合了 VLM 技术、分层语义-空间融合和拓扑地图等方法，实现了零样本自主导航，并在多个数据集上取得了最先进的性能。'),('2505.21972v1','Judging LLMs on a Simplex','Automated evaluation of free-form outputs from large language models (LLMs)\nis challenging because many distinct answers can be equally valid. A common\npractice is to use LLMs themselves as judges, but the theoretical properties of\nthis approach are not yet well understood. We show that a geometric framework\nthat represents both judges and candidates as points on a probability simplex\ncan provide helpful insight on what is or is not identifiable using LLM judges.\nOur theoretical analysis uncovers a \"phase transition\" in ranking\nidentifiability: for binary scoring systems, true rankings are identifiable\neven with weak judges under mild assumptions, while rankings become\nnon-identifiable for three or more scoring levels even with infinite data,\nabsent additional prior knowledge. This non-identifiability highlights how\nuncertainty in rankings stems from not only aleatoric uncertainty (i.e.,\ninherent stochasticity in the data) but also epistemic uncertainty regarding\nwhich assumptions hold, an aspect that has received limited attention until\nnow. To integrate both types of uncertainty, we use Bayesian inference to\nencode assumptions as priors and conduct sensitivity analysis of ranking\nestimates and credible intervals. Empirical evaluations across multiple\nbenchmarks demonstrate that Bayesian inference yields more accurate rankings\nand substantially improves coverage rates. These results underscore the\nimportance of taking a more holistic approach to uncertainty quantification\nwhen using LLMs as judges.','Patrick Vossler, Fan Xia, Yifan Mai, Jean Feng','2025-05-28','cs.LG','LLM（大型语言模型）','http://arxiv.org/pdf/2505.21972v1','该论文研究了利用大型语言模型（LLMs）自动评估自由形式输出的困难之处，提出了一种几何框架来揭示LLMs作为评判者时的理论特性。通过理论分析发现，在二元评分系统中，即使是弱评判者也可以在温和假设下确定真实排名，但在三个或更多评分级别下，即使有无限数据，排名也可能无法确定，除非有额外的先验知识。通过贝叶斯推断整合了不确定性，提高了排名的准确性和覆盖率。'),('2505.21974v1','BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL','Bayesian optimization (BO) offers an efficient pipeline for optimizing\nblack-box functions with the help of a Gaussian process prior and an\nacquisition function (AF). Recently, in the context of single-objective BO,\nlearning-based AFs witnessed promising empirical results given its favorable\nnon-myopic nature. Despite this, the direct extension of these approaches to\nmulti-objective Bayesian optimization (MOBO) suffer from the\n\\textit{hypervolume identifiability issue}, which results from the\nnon-Markovian nature of MOBO problems. To tackle this, inspired by the\nnon-Markovian RL literature and the success of Transformers in language\nmodeling, we present a generalized deep Q-learning framework and propose\n\\textit{BOFormer}, which substantiates this framework for MOBO via sequence\nmodeling. Through extensive evaluation, we demonstrate that BOFormer constantly\noutperforms the benchmark rule-based and learning-based algorithms in various\nsynthetic MOBO and real-world multi-objective hyperparameter optimization\nproblems. We have made the source code publicly available to encourage further\nresearch in this direction.','Yu-Heng Hung, Kai-Jie Lin, Yu-Heng Lin, Chien-YiWang, Cheng Sun, Ping-Chun Hsieh','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.21974v1','该论文提出了一种基于深度Q学习和序列建模的通用框架BOFormer，用于解决多目标贝叶斯优化中的hypervolume可识别性问题。通过广泛评估，证明了BOFormer在各种合成MOBO和真实世界多目标超参数优化问题中始终优于基准规则和基于学习的算法。'),('2505.21978v1','Two-Stage Feature Generation with Transformer and Reinforcement Learning','Feature generation is a critical step in machine learning, aiming to enhance\nmodel performance by capturing complex relationships within the data and\ngenerating meaningful new features. Traditional feature generation methods\nheavily rely on domain expertise and manual intervention, making the process\nlabor-intensive and challenging to adapt to different scenarios. Although\nautomated feature generation techniques address these issues to some extent,\nthey often face challenges such as feature redundancy, inefficiency in feature\nspace exploration, and limited adaptability to diverse datasets and tasks. To\naddress these problems, we propose a Two-Stage Feature Generation (TSFG)\nframework, which integrates a Transformer-based encoder-decoder architecture\nwith Proximal Policy Optimization (PPO). The encoder-decoder model in TSFG\nleverages the Transformer\\\'s self-attention mechanism to efficiently represent\nand transform features, capturing complex dependencies within the data. PPO\nfurther enhances TSFG by dynamically adjusting the feature generation strategy\nbased on task-specific feedback, optimizing the process for improved\nperformance and adaptability. TSFG dynamically generates high-quality feature\nsets, significantly improving the predictive performance of machine learning\nmodels. Experimental results demonstrate that TSFG outperforms existing\nstate-of-the-art methods in terms of feature quality and adaptability.','Wanfu Gao, Zengyao Man, Zebin He, Yuhao Tang, Jun Gao, Kunpeng Liu','2025-05-28','cs.LG','特征生成、机器学习','http://arxiv.org/pdf/2505.21978v1','该论文提出了一个名为Two-Stage Feature Generation (TSFG)的框架，结合了基于Transformer的编码器-解码器架构和Proximal Policy Optimization (PPO)，用于自动生成高质量的特征集，显著提高了机器学习模型的预测性能。'),('2505.21979v1','Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset','Mainstream large vision-language models (LVLMs) inherently encode cultural\nbiases, highlighting the need for diverse multimodal datasets. To address this\ngap, we introduce Pearl, a large-scale Arabic multimodal dataset and benchmark\nexplicitly designed for cultural understanding. Constructed through advanced\nagentic workflows and extensive human-in-the-loop annotations by 45 annotators\nfrom across the Arab world, Pearl comprises over K multimodal examples spanning\nten culturally significant domains covering all Arab countries. We further\nprovide two robust evaluation benchmarks Pearl and Pearl-Lite along with a\nspecialized subset Pearl-X explicitly developed to assess nuanced cultural\nvariations. Comprehensive evaluations on state-of-the-art open and proprietary\nLVLMs demonstrate that reasoning-centric instruction alignment substantially\nimproves models\\\' cultural grounding compared to conventional scaling methods.\nPearl establishes a foundational resource for advancing culturally-informed\nmultimodal modeling research. All datasets and benchmarks are publicly\navailable.','Fakhraddin Alwajih, Samar Mohamed Magdy, Abdellah El Mekki, Omer Nacar, Youssef Nafea, Safaa Taher Abdelfadil, Abdulfattah Mohammed Yahya, Hamzah Luqman, Nada Almarwani, Samah Aloufi, Baraah Qawasmeh, Houdaifa Atou, Serry Sibaee, Hamzah A. Alsayadi, Walid Al-Dhabyani, Maged S. Al-shaibani, Aya El aatar, Nour Qandos, Rahaf Alhamouri, Samar Ahmad, Razan Khassib, Lina Hamad, Mohammed Anwar AL-Ghrawi, Fatimah Alshamari, Cheikh Malainine, Doaa Qawasmeh, Aminetou Yacoub, Tfeil moilid, Ruwa AbuHweidi, Ahmed Aboeitta, Vatimetou Mohamed Lemin, Reem Abdel-Salam, Ahlam Bashiti, Adel Ammar, Aisha Alansari, Ahmed Ashraf, Nora Alturayeif, Sara Shatnawi, Alcides Alcoba Inciarte, AbdelRahim A. Elmadany, Mohamedou cheikh tourad, Ismail Berrada, Mustafa Jarrar, Shady Shehata, Muhammad Abdul-Mageed','2025-05-28','cs.CL','图像识别、自然语言处理','http://arxiv.org/pdf/2505.21979v1','该论文介绍了Pearl，一个大规模的阿拉伯语多模态数据集和基准，旨在促进文化理解。通过先进的工作流程和来自阿拉伯世界各地的45名注释者的人工标注，Pearl包含超过K个多模态示例，涵盖十个文化领域，覆盖所有阿拉伯国家。研究表明，基于推理的指导对于提高模型的文化基础比传统方法更为有效。'),('2505.21981v1','Learning Compositional Behaviors from Demonstration and Language','We introduce Behavior from Language and Demonstration (BLADE), a framework\nfor long-horizon robotic manipulation by integrating imitation learning and\nmodel-based planning. BLADE leverages language-annotated demonstrations,\nextracts abstract action knowledge from large language models (LLMs), and\nconstructs a library of structured, high-level action representations. These\nrepresentations include preconditions and effects grounded in visual perception\nfor each high-level action, along with corresponding controllers implemented as\nneural network-based policies. BLADE can recover such structured\nrepresentations automatically, without manually labeled states or symbolic\ndefinitions. BLADE shows significant capabilities in generalizing to novel\nsituations, including novel initial states, external state perturbations, and\nnovel goals. We validate the effectiveness of our approach both in simulation\nand on real robots with a diverse set of objects with articulated parts,\npartial observability, and geometric constraints.','Weiyu Liu, Neil Nie, Ruohan Zhang, Jiayuan Mao, Jiajun Wu','2025-05-28','cs.RO','强化学习','http://arxiv.org/pdf/2505.21981v1','该论文介绍了一个名为BLADE的框架，通过整合模仿学习和基于模型的规划来实现长期视野的机器人操作。BLADE利用语言注释的演示，从大型语言模型（LLMs）中提取抽象动作知识，并构建了结构化、高级别的动作表示库。这些表示包括每个高级别动作的基于视觉感知的前提条件和效果，以及相应的基于神经网络的控制器。'),('2505.21985v1','Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning','In multi-agent reinforcement learning (MARL), effective communication\nimproves agent performance, particularly under partial observability. We\npropose MARL-CPC, a framework that enables communication among fully\ndecentralized, independent agents without parameter sharing. MARL-CPC\nincorporates a message learning model based on collective predictive coding\n(CPC) from emergent communication research. Unlike conventional methods that\ntreat messages as part of the action space and assume cooperation, MARL-CPC\nlinks messages to state inference, supporting communication in non-cooperative,\nreward-independent settings. We introduce two algorithms -Bandit-CPC and\nIPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that\nboth outperform standard message-as-action approaches, establishing effective\ncommunication even when messages offer no direct benefit to the sender. These\nresults highlight MARL-CPC\\\'s potential for enabling coordination in complex,\ndecentralized environments.','Naoto Yoshida, Tadahiro Taniguchi','2025-05-28','cs.MA','强化学习','http://arxiv.org/pdf/2505.21985v1','该论文提出了一种名为MARL-CPC的多智能体强化学习框架，通过集体预测编码(CPC)实现独立智能体之间的有效通信，支持在非合作、奖励无关的情境下进行通信。引入了两种算法-Bandit-CPC和IPPO-CPC-并在非合作MARL任务中进行评估，结果表明两者均优于标准的消息作为动作的方法。'),('2505.21987v1','ACE: Exploring Activation Cosine Similarity and Variance for Accurate and Calibration-Efficient LLM Pruning','With the rapid expansion of large language models (LLMs), the demand for\nmemory and computational resources has grown significantly. Recent advances in\nLLM pruning aim to reduce the size and computational cost of these models.\nHowever, existing methods often suffer from either suboptimal pruning\nperformance or low time efficiency during the pruning process. In this work, we\npropose an efficient and effective pruning method that simultaneously achieves\nhigh pruning performance and fast pruning speed with improved calibration\nefficiency. Our approach introduces two key innovations: (1) An activation\ncosine similarity loss-guided pruning metric, which considers the angular\ndeviation of the output activation between the dense and pruned models. (2) An\nactivation variance-guided pruning metric, which helps preserve semantic\ndistinctions in output activations after pruning, enabling effective pruning\nwith shorter input sequences. These two components can be readily combined to\nenhance LLM pruning in both accuracy and efficiency. Experimental results show\nthat our method achieves up to an 18% reduction in perplexity and up to 63%\ndecrease in pruning time on prevalent LLMs such as LLaMA, LLaMA-2, and OPT.','Zhendong Mi, Zhenglun Kong, Geng Yuan, Shaoyi Huang','2025-05-28','cs.LG','LLM (大语言模型)','http://arxiv.org/pdf/2505.21987v1','本文提出了一种高效且有效的大语言模型剪枝方法，同时实现了高剪枝性能和快速剪枝速度，改善了校准效率。该方法引入了两个关键创新：一是基于激活余弦相似性损失引导的剪枝度量，考虑了密集模型和剪枝模型之间输出激活的角度偏差；二是基于激活方差引导的剪枝度量，帮助在剪枝后保留输出激活中的语义区别，使得在较短的输入序列下实现有效的剪枝。'),('2505.21994v1','Locking-Free Training of Physics-Informed Neural Network for Solving Nearly Incompressible Elasticity Equations','Due to divergence instability, the accuracy of low-order conforming finite\nelement methods for nearly incompressible homogeneous elasticity equations\ndeteriorates as the Lam\\\\\'e coefficient $\\lambda\\to\\infty$, or equivalently as\nthe Poisson ratio $\\nu\\to1/2$. This phenomenon, known as locking or\nnon-robustness, remains not fully understood despite extensive investigation.\nIn this paper, we propose a robust method based on a fundamentally different,\nmachine-learning-driven approach. Leveraging recently developed\nPhysics-Informed Neural Networks (PINNs), we address the numerical solution of\nlinear elasticity equations governing nearly incompressible materials. The core\nidea of our method is to appropriately decompose the given equations to\nalleviate the extreme imbalance in the coefficients, while simultaneously\nsolving both the forward and inverse problems to recover the solutions of the\ndecomposed systems as well as the associated external conditions. Through\nvarious numerical experiments, including constant, variable and parametric\nLam\\\\\'e coefficients, we illustrate the efficiency of the proposed methodology.','Josef Dick, Seungchan Ko, Kassem Mustapha, Sanghyeon Park','2025-05-28','math.NA','物理学知识驱动的神经网络（PINNs）','http://arxiv.org/pdf/2505.21994v1','本文提出了一种基于机器学习驱动方法的鲁棒性方法，用于解决近不可压弹性材料的线性弹性方程数值解问题。通过适当分解给定方程，同时解决前向和反向问题，以恢复分解系统的解以及相关外部条件。'),('2505.21996v1','Learning World Models for Interactive Video Generation','Foundational world models must be both interactive and preserve\nspatiotemporal coherence for effective future planning with action choices.\nHowever, present models for long video generation have limited inherent world\nmodeling capabilities due to two main challenges: compounding errors and\ninsufficient memory mechanisms. We enhance image-to-video models with\ninteractive capabilities through additional action conditioning and\nautoregressive framework, and reveal that compounding error is inherently\nirreducible in autoregressive video generation, while insufficient memory\nmechanism leads to incoherence of world models. We propose video retrieval\naugmented generation (VRAG) with explicit global state conditioning, which\nsignificantly reduces long-term compounding errors and increases spatiotemporal\nconsistency of world models. In contrast, naive autoregressive generation with\nextended context windows and retrieval-augmented generation prove less\neffective for video generation, primarily due to the limited in-context\nlearning capabilities of current video models. Our work illuminates the\nfundamental challenges in video world models and establishes a comprehensive\nbenchmark for improving video generation models with internal world modeling\ncapabilities.','Taiye Chen, Xun Hu, Zihan Ding, Chi Jin','2025-05-28','cs.CV','视频生成','http://arxiv.org/pdf/2505.21996v1','该论文研究了长视频生成中存在的两个主要挑战：错误叠加和记忆机制不足，提出了视频检索增强生成（VRAG）方法，通过显式全局状态调节显著减少了长期错误叠加，并增加了世界模型的时空一致性。'),('2505.21997v1','Leveraging Interview-Informed LLMs to Model Survey Responses: Comparative Insights from AI-Generated and Human Data','Mixed methods research integrates quantitative and qualitative data but faces\nchallenges in aligning their distinct structures, particularly in examining\nmeasurement characteristics and individual response patterns. Advances in large\nlanguage models (LLMs) offer promising solutions by generating synthetic survey\nresponses informed by qualitative data. This study investigates whether LLMs,\nguided by personal interviews, can reliably predict human survey responses,\nusing the Behavioral Regulations in Exercise Questionnaire (BREQ) and\ninterviews from after-school program staff as a case study. Results indicate\nthat LLMs capture overall response patterns but exhibit lower variability than\nhumans. Incorporating interview data improves response diversity for some\nmodels (e.g., Claude, GPT), while well-crafted prompts and low-temperature\nsettings enhance alignment between LLM and human responses. Demographic\ninformation had less impact than interview content on alignment accuracy. These\nfindings underscore the potential of interview-informed LLMs to bridge\nqualitative and quantitative methodologies while revealing limitations in\nresponse variability, emotional interpretation, and psychometric fidelity.\nFuture research should refine prompt design, explore bias mitigation, and\noptimize model settings to enhance the validity of LLM-generated survey data in\nsocial science research.','Jihong Zhang, Xinya Liang, Anqi Deng, Nicole Bonge, Lin Tan, Ling Zhang, Nicole Zarrett','2025-05-28','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.21997v1','该论文研究了如何利用大型语言模型（LLMs）结合定性数据生成合成调查回应，以预测人类调查回应。研究结果表明，LLMs能够捕捉整体回应模式，但变异性较人类较低。同时，加入面试数据可以提高某些模型的回应多样性，而精心设计的提示和低温度设置可以增强LLM和人类回应之间的一致性。'),('2505.21999v1','Found in Translation: Measuring Multilingual LLM Consistency as Simple as Translate then Evaluate','Large language models (LLMs) provide detailed and impressive responses to\nqueries in English. However, are they really consistent at responding to the\nsame query in other languages? The popular way of evaluating for multilingual\nperformance of LLMs requires expensive-to-collect annotated datasets. Further,\nevaluating for tasks like open-ended generation, where multiple correct answers\nmay exist, is nontrivial. Instead, we propose to evaluate the predictability of\nmodel response across different languages. In this work, we propose a framework\nto evaluate LLM\\\'s cross-lingual consistency based on a simple Translate then\nEvaluate strategy. We instantiate this evaluation framework along two\ndimensions of consistency: information and empathy. Our results reveal\npronounced inconsistencies in popular LLM responses across thirty languages,\nwith severe performance deficits in certain language families and scripts,\nunderscoring critical weaknesses in their multilingual capabilities. These\nfindings necessitate cross-lingual evaluations that are consistent along\nmultiple dimensions. We invite practitioners to use our framework for future\nmultilingual LLM benchmarking.','Ashim Gupta, Maitrey Mehta, Zhichao Xu, Vivek Srikumar','2025-05-28','cs.CL','大型语言模型（LLM）、多语言处理','http://arxiv.org/pdf/2505.21999v1','该论文研究了大型语言模型在不同语言下的一致性表现，并提出了一种基于翻译然后评估策略的评估框架。研究结果显示在三十种语言中存在明显的一致性问题，尤其在某些语言家族和文字脚本中表现不佳，凸显了它们在多语言能力上的关键弱点。'),('2505.22003v1','Legal Assist AI: Leveraging Transformer-Based Model for Effective Legal Assistance','Pursuit of accessible legal assistance in India faces a critical gap, as many\ncitizens struggle to leverage their legal rights due to limited awareness and\naccess to relevant legal information. This paper introduces Legal Assist AI, a\ntransformer-based model designed to bridge this gap by offering effective legal\nassistance through large language models (LLMs). The system retrieves relevant\nlegal information from a curated database and generates accurate responses,\nenabling effective assistance for diverse users, including legal professionals,\nscholars, and the general public. The model was fine-tuned on extensive\ndatasets from the Indian legal domain, including Indian Constitution, Bharatiya\nNyaya Sanhita (BNS), Bharatiya Nagarik Suraksha Sanhita (BNSS) and so forth,\nproviding a robust understanding of the complexities of Indian law. By\nincorporating domain-specific legal datasets, the proposed model demonstrated\nremarkable efficiency and specialization in legal Question-Answering. The model\nwas evaluated against state-of-the-art models such as GPT-3.5 Turbo and Mistral\n7B, achieving a 60.08% score on the AIBE, outperforming its competitors in\nlegal reasoning and accuracy. Unlike other models, Legal Assist AI avoided\ncommon issues such as hallucinations, making it highly reliable for practical\nlegal applications. It showcases the model\\\'s applicability in real-world legal\nscenarios, with future iterations aiming to enhance performance and expand its\ndataset to cover a broader range of multilingual and case-specific queries as\nwell.','Jatin Gupta, Akhil Sharma, Saransh Singhania, Ali Imam Abidi','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22003v1','该论文介绍了Legal Assist AI，一个基于transformer的模型，旨在通过大型语言模型为印度公民提供有效的法律援助。该模型在印度法律领域的广泛数据集上进行了微调，展现出在法律问答方面的出色效率和专业化，超越了其他竞争对手。'),('2505.22006v1','Efficiently Enhancing General Agents With Hierarchical-categorical Memory','With large language models (LLMs) demonstrating remarkable capabilities,\nthere has been a surge in research on leveraging LLMs to build general-purpose\nmulti-modal agents. However, existing approaches either rely on computationally\nexpensive end-to-end training using large-scale multi-modal data or adopt\ntool-use methods that lack the ability to continuously learn and adapt to new\nenvironments. In this paper, we introduce EHC, a general agent capable of\nlearning without parameter updates. EHC consists of a Hierarchical Memory\nRetrieval (HMR) module and a Task-Category Oriented Experience Learning (TOEL)\nmodule. The HMR module facilitates rapid retrieval of relevant memories and\ncontinuously stores new information without being constrained by memory\ncapacity. The TOEL module enhances the agent\\\'s comprehension of various task\ncharacteristics by classifying experiences and extracting patterns across\ndifferent categories. Extensive experiments conducted on multiple standard\ndatasets demonstrate that EHC outperforms existing methods, achieving\nstate-of-the-art performance and underscoring its effectiveness as a general\nagent for handling complex multi-modal tasks.','Changze Qiao, Mingming Lu','2025-05-28','cs.AI','LLM、强化学习','http://arxiv.org/pdf/2505.22006v1','本文介绍了一种名为EHC的通用代理，能够在不更新参数的情况下学习。该代理包括层次记忆检索模块和任务类别导向的经验学习模块，能够在处理复杂多模态任务时表现优异。'),('2505.22008v1','Align-DA: Align Score-based Atmospheric Data Assimilation with Multiple Preferences','Data assimilation (DA) aims to estimate the full state of a dynamical system\nby combining partial and noisy observations with a prior model forecast,\ncommonly referred to as the background. In atmospheric applications, this\nproblem is fundamentally ill-posed due to the sparsity of observations relative\nto the high-dimensional state space. Traditional methods address this challenge\nby simplifying background priors to regularize the solution, which are\nempirical and require continual tuning for application. Inspired by alignment\ntechniques in text-to-image diffusion models, we propose Align-DA, which\nformulates DA as a generative process and uses reward signals to guide\nbackground priors, replacing manual tuning with data-driven alignment.\nSpecifically, we train a score-based model in the latent space to approximate\nthe background-conditioned prior, and align it using three complementary reward\nsignals for DA: (1) assimilation accuracy, (2) forecast skill initialized from\nthe assimilated state, and (3) physical adherence of the analysis fields.\nExperiments with multiple reward signals demonstrate consistent improvements in\nanalysis quality across different evaluation metrics and observation-guidance\nstrategies. These results show that preference alignment, implemented as a soft\nconstraint, can automatically adapt complex background priors tailored to DA,\noffering a promising new direction for advancing the field.','Jing-An Sun, Hang Fan, Junchao Gong, Ben Fei, Kun Chen, Fenghua Ling, Wenlong Zhang, Wanghan Xu, Li Yan, Pierre Gentine, Lei Bai','2025-05-28','physics.ao-ph','强化学习','http://arxiv.org/pdf/2505.22008v1','该论文提出了一种名为Align-DA的数据同化方法，将数据同化问题视为一个生成过程，并使用奖励信号来引导背景先验，以数据驱动的方式替代手动调整。实验证明，使用多个奖励信号可以在不同评估指标和观测引导策略下提高分析质量。'),('2505.22014v1','Learning in Compact Spaces with Approximately Normalized Transformers','In deep learning, regularization and normalization are common solutions for\nchallenges such as overfitting, numerical instabilities, and the increasing\nvariance in the residual stream. An alternative approach is to force all\nparameters and representations to lie on a hypersphere. This removes the need\nfor regularization and increases convergence speed, but comes with additional\ncosts. In this work, we propose a more holistic but approximate normalization\n(anTransformer). Our approach constrains the norm of parameters and normalizes\nall representations via scalar multiplications motivated by the tight\nconcentration of the norms of high-dimensional random vectors. When applied to\nGPT training, we observe a 40% faster convergence compared to models with QK\nnormalization, with less than 3% additional runtime. Deriving scaling laws for\nanGPT, we found our method enables training with larger batch sizes and fewer\nhyperparameters, while matching the favorable scaling characteristics of\nclassic GPT architectures.','Jörg K. H. Franke, Urs Spiegelhalter, Marianna Nezhurina, Jenia Jitsev, Frank Hutter, Michael Hefenbrock','2025-05-28','cs.LG','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.22014v1','该论文提出了一种新的正则化和标准化方法(anTransformer)，通过将所有参数和表示限制在一个超球面上，以提高收敛速度并减少过拟合等问题。在GPT训练中，与QK标准化相比，该方法使收敛速度提高了40%，而额外运行时间不到3%。'),('2505.22017v1','CoThink: Token-Efficient Reasoning via Instruct Models Guiding Reasoning Models','Large language models (LLMs) benefit from increased test-time compute, a\nphenomenon known as test-time scaling. However, reasoning-optimized models\noften overthink even simple problems, producing excessively verbose outputs and\nleading to low token efficiency. By comparing these models with equally sized\ninstruct models, we identify two key causes of this verbosity: (1)\nreinforcement learning reduces the information density of forward reasoning,\nand (2) backward chain-of thought training encourages redundant and often\nunnecessary verification steps. Since LLMs cannot assess the difficulty of a\ngiven problem, they tend to apply the same cautious reasoning strategy across\nall tasks, resulting in inefficient overthinking. To address this, we propose\nCoThink, an embarrassingly simple pipeline: an instruct model first drafts a\nhigh-level solution outline; a reasoning model then works out the solution. We\nobserve that CoThink enables dynamic adjustment of reasoning depth based on\ninput difficulty. Evaluated with three reasoning models DAPO, DeepSeek-R1, and\nQwQ on three datasets GSM8K, MATH500, and AIME24, CoThink reduces total token\ngeneration by 22.3% while maintaining pass@1 accuracy within a 0.42% margin on\naverage. With reference to the instruct model, we formally define reasoning\nefficiency and observe a potential reasoning efficiency scaling law in LLMs.','Siqi Fan, Peng Han, Shuo Shang, Yequan Wang, Aixin Sun','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22017v1','该论文研究了大型语言模型在测试时的计算量增加对推理优化模型造成的问题，提出了一个简单的管道CoThink来解决这个问题，通过在三个数据集上的评估表明，CoThink可以减少总的token生成量，并保持准确率。'),('2505.22018v1','Improving Continual Pre-training Through Seamless Data Packing','Continual pre-training has demonstrated significant potential in enhancing\nmodel performance, particularly in domain-specific scenarios. The most common\napproach for packing data before continual pre-training involves concatenating\ninput texts and splitting them into fixed-length sequences. While\nstraightforward and efficient, this method often leads to excessive truncation\nand context discontinuity, which can hinder model performance. To address these\nissues, we explore the potential of data engineering to enhance continual\npre-training, particularly its impact on model performance and efficiency. We\npropose Seamless Packing (SP), a novel data packing strategy aimed at\npreserving contextual information more effectively and enhancing model\nperformance. Our approach employs a sliding window technique in the first stage\nthat synchronizes overlapping tokens across consecutive sequences, ensuring\nbetter continuity and contextual coherence. In the second stage, we adopt a\nFirst-Fit-Decreasing algorithm to pack shorter texts into bins slightly larger\nthan the target sequence length, thereby minimizing padding and truncation.\nEmpirical evaluations across various model architectures and corpus domains\ndemonstrate the effectiveness of our method, outperforming baseline method in\n99% of all settings. Code is available at\nhttps://github.com/Infernus-WIND/Seamless-Packing.','Ruicheng Yin, Xuan Gao, Changze Lv, Xiaohua Wang, Xiaoqing Zheng, Xuanjing Huang','2025-05-28','cs.CL','自然语言处理 (NLP)','http://arxiv.org/pdf/2505.22018v1','该论文提出了一种名为Seamless Packing (SP) 的数据打包策略，旨在更有效地保留上下文信息，提高模型性能。他们采用滑动窗口技术和First-Fit-Decreasing算法，在各种模型架构和语料库领域中进行了实证评估，结果表明该方法在99%的设置中优于基线方法。'),('2505.22019v1','VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning','Effectively retrieving, reasoning and understanding visually rich information\nremains a challenge for RAG methods. Traditional text-based methods cannot\nhandle visual-related information. On the other hand, current vision-based RAG\napproaches are often limited by fixed pipelines and frequently struggle to\nreason effectively due to the insufficient activation of the fundamental\ncapabilities of models. As RL has been proven to be beneficial for model\nreasoning, we introduce VRAG-RL, a novel RL framework tailored for complex\nreasoning across visually rich information. With this framework, VLMs interact\nwith search engines, autonomously sampling single-turn or multi-turn reasoning\ntrajectories with the help of visual perception tokens and undergoing continual\noptimization based on these samples. Our approach highlights key limitations of\nRL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely\nincorporate images into the context, leading to insufficient reasoning token\nallocation and neglecting visual-specific perception; and (ii) When models\ninteract with search engines, their queries often fail to retrieve relevant\ninformation due to the inability to articulate requirements, thereby leading to\nsuboptimal performance. To address these challenges, we define an action space\ntailored for visually rich inputs, with actions including cropping and scaling,\nallowing the model to gather information from a coarse-to-fine perspective.\nFurthermore, to bridge the gap between users\\\' original inquiries and the\nretriever, we employ a simple yet effective reward that integrates query\nrewriting and retrieval performance with a model-based reward. Our VRAG-RL\noptimizes VLMs for RAG tasks using specially designed RL strategies, aligning\nthe model with real-world applications. The code is available at\n\\hyperlink{https://github.com/Alibaba-NLP/VRAG}{https://github.com/Alibaba-NLP/VRAG}.','Qiuchen Wang, Ruixue Ding, Yu Zeng, Zehui Chen, Lin Chen, Shihang Wang, Pengjun Xie, Fei Huang, Feng Zhao','2025-05-28','cs.CL','强化学习','http://arxiv.org/pdf/2505.22019v1','该论文介绍了一种新颖的强化学习框架 VRAG-RL，专为处理复杂的基于视觉信息的推理而设计。该框架通过与搜索引擎互动，利用视觉感知标记自主采样单轮或多轮推理轨迹，并基于这些样本进行持续优化。该方法通过特定的强化学习策略优化了视觉语言模型（VLMs）以用于视觉信息的检索、推理和理解任务。'),('2505.22021v1','GL-PGENet: A Parameterized Generation Framework for Robust Document Image Enhancement','Document Image Enhancement (DIE) serves as a critical component in Document\nAI systems, where its performance substantially determines the effectiveness of\ndownstream tasks. To address the limitations of existing methods confined to\nsingle-degradation restoration or grayscale image processing, we present Global\nwith Local Parametric Generation Enhancement Network (GL-PGENet), a novel\narchitecture designed for multi-degraded color document images, ensuring both\nefficiency and robustness in real-world scenarios. Our solution incorporates\nthree key innovations: First, a hierarchical enhancement framework that\nintegrates global appearance correction with local refinement, enabling\ncoarse-to-fine quality improvement. Second, a Dual-Branch Local-Refine Network\nwith parametric generation mechanisms that replaces conventional direct\nprediction, producing enhanced outputs through learned intermediate parametric\nrepresentations rather than pixel-wise mapping. This approach enhances local\nconsistency while improving model generalization. Finally, a modified NestUNet\narchitecture incorporating dense block to effectively fuse low-level pixel\nfeatures and high-level semantic features, specifically adapted for document\nimage characteristics. In addition, to enhance generalization performance, we\nadopt a two-stage training strategy: large-scale pretraining on a synthetic\ndataset of 500,000+ samples followed by task-specific fine-tuning. Extensive\nexperiments demonstrate the superiority of GL-PGENet, achieving\nstate-of-the-art SSIM scores of 0.7721 on DocUNet and 0.9480 on RealDAE. The\nmodel also exhibits remarkable cross-domain adaptability and maintains\ncomputational efficiency for high-resolution images without performance\ndegradation, confirming its practical utility in real-world scenarios.','Zhihong Tang, Yang Li','2025-05-28','cs.CV','文档图像增强(Document Image Enhancement)','http://arxiv.org/pdf/2505.22021v1','该论文提出了一种新颖的全局与局部参数生成增强网络（GL-PGENet），用于处理多种降质的彩色文档图像，通过层次化增强框架、双分支局部细化网络和修改的NestUNet架构等关键创新，实现了在真实场景中的高效性和鲁棒性。'),('2505.22028v1','Weakly-Supervised Contrastive Learning for Imprecise Class Labels','Contrastive learning has achieved remarkable success in learning effective\nrepresentations, with supervised contrastive learning often outperforming\nself-supervised approaches. However, in real-world scenarios, data annotations\nare often ambiguous or inaccurate, meaning that class labels may not reliably\nindicate whether two examples belong to the same class. This limitation\nrestricts the applicability of supervised contrastive learning. To address this\nchallenge, we introduce the concept of ``continuous semantic similarity\\\'\\\' to\ndefine positive and negative pairs. Instead of directly relying on imprecise\nclass labels, we measure the semantic similarity between example pairs, which\nquantifies how closely they belong to the same category by iteratively refining\nweak supervisory signals. Based on this concept, we propose a graph-theoretic\nframework for weakly-supervised contrastive learning, where semantic similarity\nserves as the graph weights. Our framework is highly versatile and can be\napplied to many weakly-supervised learning scenarios. We demonstrate its\neffectiveness through experiments in two common settings, i.e., noisy label and\npartial label learning, where existing methods can be easily integrated to\nsignificantly improve performance. Theoretically, we establish an error bound\nfor our approach, showing that it can approximate supervised contrastive\nlearning under mild conditions. The implementation code is available at\nhttps://github.com/Speechless-10308/WSC.','Zi-Hao Zhou, Jun-Jie Wang, Tong Wei, Min-Ling Zhang','2025-05-28','cs.LG','弱监督学习','http://arxiv.org/pdf/2505.22028v1','该论文提出了一种基于连续语义相似性的弱监督对比学习框架，通过衡量示例对之间的语义相似性来定义正负样本，并利用图论方法进行学习。实验证明该方法在噪声标签和部分标签学习等场景中表现出很好的效果，并在理论上证明了其逼近监督对比学习的能力。'),('2505.22029v1','Analysis and Evaluation of Synthetic Data Generation in Speech Dysfluency Detection','Speech dysfluency detection is crucial for clinical diagnosis and language\nassessment, but existing methods are limited by the scarcity of high-quality\nannotated data. Although recent advances in TTS model have enabled synthetic\ndysfluency generation, existing synthetic datasets suffer from unnatural\nprosody and limited contextual diversity. To address these limitations, we\npropose LLM-Dys -- the most comprehensive dysfluent speech corpus with\nLLM-enhanced dysfluency simulation. This dataset captures 11 dysfluency\ncategories spanning both word and phoneme levels. Building upon this resource,\nwe improve an end-to-end dysfluency detection framework. Experimental\nvalidation demonstrates state-of-the-art performance. All data, models, and\ncode are open-sourced at https://github.com/Berkeley-Speech-Group/LLM-Dys.','Jinming Zhang, Xuanru Zhou, Jiachen Lian, Shuhe Li, William Li, Zoe Ezzes, Rian Bogley, Lisa Wauters, Zachary Miller, Jet Vonk, Brittany Morin, Maria Gorno-Tempini, Gopala Anumanchipalli','2025-05-28','eess.AS','语音处理','http://arxiv.org/pdf/2505.22029v1','该论文提出了一个包含11种语言障碍类别的语音数据集LLM-Dys，并利用LLM增强的语言模型进行语言障碍模拟，以改进端到端的语言障碍检测框架，并展示了最先进的性能。'),('2505.22037v1','Jailbreak Distillation: Renewable Safety Benchmarking','Large language models (LLMs) are rapidly deployed in critical applications,\nraising urgent needs for robust safety benchmarking. We propose Jailbreak\nDistillation (JBDistill), a novel benchmark construction framework that\n\"distills\" jailbreak attacks into high-quality and easily-updatable safety\nbenchmarks. JBDistill utilizes a small set of development models and existing\njailbreak attack algorithms to create a candidate prompt pool, then employs\nprompt selection algorithms to identify an effective subset of prompts as\nsafety benchmarks. JBDistill addresses challenges in existing safety\nevaluation: the use of consistent evaluation prompts across models ensures fair\ncomparisons and reproducibility. It requires minimal human effort to rerun the\nJBDistill pipeline and produce updated benchmarks, alleviating concerns on\nsaturation and contamination. Extensive experiments demonstrate our benchmarks\ngeneralize robustly to 13 diverse evaluation models held out from benchmark\nconstruction, including proprietary, specialized, and newer-generation LLMs,\nsignificantly outperforming existing safety benchmarks in effectiveness while\nmaintaining high separability and diversity. Our framework thus provides an\neffective, sustainable, and adaptable solution for streamlining safety\nevaluation.','Jingyu Zhang, Ahmed Elgohary, Xiawei Wang, A S M Iftekhar, Ahmed Magooda, Benjamin Van Durme, Daniel Khashabi, Kyle Jackson','2025-05-28','cs.CL','大型语言模型 (LLM)','http://arxiv.org/pdf/2505.22037v1','该论文提出了一种名为Jailbreak Distillation (JBDistill) 的新型基准构建框架，将越狱攻击“提炼”为高质量且易更新的安全基准。该框架利用少量开发模型和现有越狱攻击算法创建候选提示池，然后利用提示选择算法识别有效的提示子集作为安全基准。实验结果表明，这些基准在13个不同的评估模型上都表现出很好的泛化性能。'),('2505.22038v1','Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization','Large Vision-Language Models (LVLMs) have shown impressive performance across\nmulti-modal tasks by encoding images into thousands of tokens. However, the\nlarge number of image tokens results in significant computational overhead, and\nthe use of dynamic high-resolution inputs further increases this burden.\nPrevious approaches have attempted to reduce the number of image tokens through\ntoken pruning, typically by selecting tokens based on attention scores or image\ntoken diversity. Through empirical studies, we observe that existing methods\noften overlook the joint impact of pruning on both the current layer\\\'s output\n(local) and the outputs of subsequent layers (global), leading to suboptimal\npruning decisions. To address this challenge, we propose Balanced Token Pruning\n(BTP), a plug-and-play method for pruning vision tokens. Specifically, our\nmethod utilizes a small calibration set to divide the pruning process into\nmultiple stages. In the early stages, our method emphasizes the impact of\npruning on subsequent layers, whereas in the deeper stages, the focus shifts\ntoward preserving the consistency of local outputs. Extensive experiments\nacross various LVLMs demonstrate the broad effectiveness of our approach on\nmultiple benchmarks. Our method achieves a 78% compression rate while\npreserving 96.7% of the original models\\\' performance on average.','Kaiyuan Li, Xiaoyue Chen, Chen Gao, Yong Li, Xinlei Chen','2025-05-28','cs.CV','大规模视觉-语言模型压缩','http://arxiv.org/pdf/2505.22038v1','该论文提出了一种平衡的图像token剪枝方法，通过在不同阶段强调对当前层输出和后续层输出的影响，实现了对大规模视觉-语言模型的高效压缩，同时保持了原模型性能的96.7%。'),('2505.22041v1','Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation','Conformance checking techniques detect undesired process behavior by\ncomparing process executions that are recorded in event logs to desired\nbehavior that is captured in a dedicated process model. If such models are not\navailable, conformance checking techniques are not applicable, but\norganizations might still be interested in detecting undesired behavior in\ntheir processes. To enable this, existing approaches use Large Language Models\n(LLMs), assuming that they can learn to distinguish desired from undesired\nbehavior through fine-tuning. However, fine-tuning is highly resource-intensive\nand the fine-tuned LLMs often do not generalize well. To address these\nlimitations, we propose an approach that requires neither a dedicated process\nmodel nor resource-intensive fine-tuning to detect undesired process behavior.\nInstead, we use Retrieval Augmented Generation (RAG) to provide an LLM with\ndirect access to a knowledge base that contains both desired and undesired\nprocess behavior from other processes, assuming that the LLM can transfer this\nknowledge to the process at hand. Our evaluation shows that our approach\noutperforms fine-tuned LLMs in detecting undesired behavior, demonstrating that\nRAG is a viable alternative to resource-intensive fine-tuning, particularly\nwhen enriched with relevant context from the event log, such as frequent traces\nand activities.','Michael Grohs, Adrian Rebmann, Jana-Rebecca Rehse','2025-05-28','cs.LG','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22041v1','该论文提出了一种新的方法，使用检索增强生成（RAG）技术，为大型语言模型（LLMs）提供直接访问包含期望和非期望过程行为的知识库，以检测非期望的过程行为。通过这种方法，可以避免使用专门的过程模型或资源密集型的微调，从而提高检测效果。'),('2505.22042v1','Estimating the Effects of Sample Training Orders for Large Language Models without Retraining','The order of training samples plays a crucial role in large language models\n(LLMs), significantly impacting both their external performance and internal\nlearning dynamics. Traditional methods for investigating this effect generally\nrequire retraining the model with various sample orders, which is\ncomputationally infeasible for LLMs. In this work, we improve traditional\nmethods by designing a retraining-free framework. By approximating Adam\noptimizer updates with first- and second-order Taylor expansions and utilizing\nrandom projection methods to store intermediate checkpoints, our framework can\nefficiently estimate model parameters for arbitrary training sample orders.\nNext, we apply our framework to two downstream research problems: (1) Training\ncurriculum design for LLMs -- we base our retraining-free framework to propose\na novel curriculum learning strategy that augments curriculum proposals with\nestimated model performances, enabling more informed sample scheduling. (2)\nLLMs\\\' memorization and generalization effect analysis -- we use our\nretraining-free framework to estimate how the positions of training samples\ninfluence LLMs\\\' capacity for memorization and generalization. We conduct\nextensive experiments to validate the effectiveness of our retraining-free\nframework in reproducing the true model performances, and further demonstrate\nits potential in optimizing LLM training curricula and analyzing the\nmemorization and generalization effects of LLMs.','Hao Yang, Haoxuan Li, Mengyue Yang, Xu Chen, Mingming Gong','2025-05-28','cs.LG','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22042v1','本论文提出了一种无需重新训练的框架，通过近似Adam优化器更新和利用随机投影方法来有效估计大型语言模型的模型参数，从而探究训练样本顺序对模型性能和学习动态的影响。作者将该框架应用于两个下游研究问题：LLM的训练课程设计和LLM的记忆和泛化效果分析。'),('2505.22049v1','Differentiable Generalized Sliced Wasserstein Plans','Optimal Transport (OT) has attracted significant interest in the machine\nlearning community, not only for its ability to define meaningful distances\nbetween probability distributions -- such as the Wasserstein distance -- but\nalso for its formulation of OT plans. Its computational complexity remains a\nbottleneck, though, and slicing techniques have been developed to scale OT to\nlarge datasets. Recently, a novel slicing scheme, dubbed min-SWGG, lifts a\nsingle one-dimensional plan back to the original multidimensional space,\nfinally selecting the slice that yields the lowest Wasserstein distance as an\napproximation of the full OT plan. Despite its computational and theoretical\nadvantages, min-SWGG inherits typical limitations of slicing methods: (i) the\nnumber of required slices grows exponentially with the data dimension, and (ii)\nit is constrained to linear projections. Here, we reformulate min-SWGG as a\nbilevel optimization problem and propose a differentiable approximation scheme\nto efficiently identify the optimal slice, even in high-dimensional settings.\nWe furthermore define its generalized extension for accommodating to data\nliving on manifolds. Finally, we demonstrate the practical value of our\napproach in various applications, including gradient flows on manifolds and\nhigh-dimensional spaces, as well as a novel sliced OT-based conditional flow\nmatching for image generation -- where fast computation of transport plans is\nessential.','Laetitia Chapel, Romain Tavenard, Samuel Vaiter','2025-05-28','cs.LG','生成模型','http://arxiv.org/pdf/2505.22049v1','该论文介绍了一种新的切片方案 min-SWGG，将单一一维计划提升回原始多维空间，选择产生最低Wasserstein距离的切片作为完整OT计划的近似。作者将min-SWGG重新构建为双层优化问题，并提出了一种可微分的近似方案，以有效识别最佳切片，即使在高维设置中也可以。最后，作者展示了该方法在各种应用中的实际价值，包括梯度流在流形和高维空间中的应用，以及基于切片OT的条件流匹配用于图像生成。'),('2505.22050v1','Reinforced Reasoning for Embodied Planning','Embodied planning requires agents to make coherent multi-step decisions based\non dynamic visual observations and natural language goals. While recent\nvision-language models (VLMs) excel at static perception tasks, they struggle\nwith the temporal reasoning, spatial understanding, and commonsense grounding\nneeded for planning in interactive environments. In this work, we introduce a\nreinforcement fine-tuning framework that brings R1-style reasoning enhancement\ninto embodied planning. We first distill a high-quality dataset from a powerful\nclosed-source model and perform supervised fine-tuning (SFT) to equip the model\nwith structured decision-making priors. We then design a rule-based reward\nfunction tailored to multi-step action quality and optimize the policy via\nGeneralized Reinforced Preference Optimization (GRPO). Our approach is\nevaluated on Embench, a recent benchmark for interactive embodied tasks,\ncovering both in-domain and out-of-domain scenarios. Experimental results show\nthat our method significantly outperforms models of similar or larger scale,\nincluding GPT-4o-mini and 70B+ open-source baselines, and exhibits strong\ngeneralization to unseen environments. This work highlights the potential of\nreinforcement-driven reasoning to advance long-horizon planning in embodied AI.','Di Wu, Jiaxin Fan, Junzhe Zang, Guanbo Wang, Wei Yin, Wenhao Li, Bo Jin','2025-05-28','cs.AI','强化学习','http://arxiv.org/pdf/2505.22050v1','该论文介绍了一种强化微调框架，将R1式推理增强引入到具身规划中，通过监督微调和奖励函数优化来提高模型在交互式环境中的决策能力。实验结果表明，该方法显著优于类似规模的模型，并在未知环境中表现出强大的泛化能力。'),('2505.22061v1','Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?','Retrieval-augmented generation (RAG) mitigates the hallucination problem in\nlarge language models (LLMs) and has proven effective for specific,\npersonalized applications. However, passing private retrieved documents\ndirectly to LLMs introduces vulnerability to membership inference attacks\n(MIAs), which try to determine whether the target datum exists in the private\nexternal database or not. Based on the insight that MIA queries typically\nexhibit high similarity to only one target document, we introduce Mirabel, a\nsimilarity-based MIA detection framework designed for the RAG system. With the\nproposed Mirabel, we show that simple detect-and-hide strategies can\nsuccessfully obfuscate attackers, maintain data utility, and remain\nsystem-agnostic. We experimentally prove its detection and defense against\nvarious state-of-the-art MIA methods and its adaptability to existing private\nRAG systems.','Yujin Choi, Youngjoo Park, Junyoung Byun, Jaewook Lee, Jinseong Park','2025-05-28','cs.CL','大语言模型（LLM）/成员推理攻击检测','http://arxiv.org/pdf/2505.22061v1','该论文介绍了一种基于相似性的成员推理攻击检测框架 Mirabel，用于 RAG 系统，旨在解决直接将私人检索文档传递给LLMs引入的成员推理攻击漏洞问题。通过 Mirabel，研究者证明了简单的检测和隐藏策略可以成功混淆攻击者，保持数据效用，并保持系统的通用性。'),('2505.22067v1','From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving','Ensuring robust and generalizable autonomous driving requires not only broad\nscenario coverage but also efficient repair of failure cases, particularly\nthose related to challenging and safety-critical scenarios. However, existing\nscenario generation and selection methods often lack adaptivity and semantic\nrelevance, limiting their impact on performance improvement. In this paper, we\npropose \\textbf{SERA}, an LLM-powered framework that enables autonomous driving\nsystems to self-evolve by repairing failure cases through targeted scenario\nrecommendation. By analyzing performance logs, SERA identifies failure patterns\nand dynamically retrieves semantically aligned scenarios from a structured\nbank. An LLM-based reflection mechanism further refines these recommendations\nto maximize relevance and diversity. The selected scenarios are used for\nfew-shot fine-tuning, enabling targeted adaptation with minimal data.\nExperiments on the benchmark show that SERA consistently improves key metrics\nacross multiple autonomous driving baselines, demonstrating its effectiveness\nand generalizability under safety-critical conditions.','Xinyu Xia, Xingjun Ma, Yunfeng Hu, Ting Qu, Hong Chen, Xun Gong','2025-05-28','cs.CV','自动驾驶','http://arxiv.org/pdf/2505.22067v1','本文提出了一个基于LLM的框架SERA，通过修复故障案例来使自动驾驶系统自我进化，实现有针对性的场景推荐。通过分析性能日志，SERA识别故障模式并从结构化库中动态检索语义对齐的场景。LLM反射机制进一步优化这些推荐，以最大化相关性和多样性。选择的场景用于少样本微调，实现有针对性的适应性。'),('2505.22068v1','Beyond path selection: Better LLMs for Scientific Information Extraction with MimicSFT and Relevance and Rule-induced(R$^2$)GRPO','Previous study suggest that powerful Large Language Models (LLMs) trained\nwith Reinforcement Learning with Verifiable Rewards (RLVR) only refines\nreasoning path without improving the reasoning capacity in math tasks while\nsupervised-finetuning(SFT) with distillation can. We study this from the view\nof Scientific information extraction (SciIE) where LLMs and reasoning LLMs\nunderperforms small Bert-based models. SciIE require both the reasoning and\nmemorization. We argue that both SFT and RLVR can refine the reasoning path and\nimprove reasoning capacity in a simple way based on SciIE. We propose two-stage\ntraining with 1. MimicSFT, using structured reasoning templates without needing\nhigh-quality chain-of-thought data, 2. R$^2$GRPO with relevance and\nrule-induced rewards. Experiments on scientific IE benchmarks show that both\nmethods can improve the reasoning capacity. R$^2$GRPO with mimicSFT surpasses\nbaseline LLMs and specialized supervised models in relation extraction. Our\ncode is available at https://github.com/ranlislz/R2GRPO.','Ran Li, Shimin Di, Yuchen Liu, Chen Jing, Yu Qiu, Lei Chen','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22068v1','该论文研究了使用科学信息提取（SciIE）视角对大型语言模型（LLMs）进行训练，并探讨了如何通过两阶段训练方法来改善推理能力。他们提出了MimicSFT和R$^2$GRPO两种方法，实验证明这两种方法可以提高推理能力。'),('2505.22074v1','The Resurrection of the ReLU','Modeling sophisticated activation functions within deep learning\narchitectures has evolved into a distinct research direction. Functions such as\nGELU, SELU, and SiLU offer smooth gradients and improved convergence\nproperties, making them popular choices in state-of-the-art models. Despite\nthis trend, the classical ReLU remains appealing due to its simplicity,\ninherent sparsity, and other advantageous topological characteristics. However,\nReLU units are prone to becoming irreversibly inactive - a phenomenon known as\nthe dying ReLU problem - which limits their overall effectiveness. In this\nwork, we introduce surrogate gradient learning for ReLU (SUGAR) as a novel,\nplug-and-play regularizer for deep architectures. SUGAR preserves the standard\nReLU function during the forward pass but replaces its derivative in the\nbackward pass with a smooth surrogate that avoids zeroing out gradients. We\ndemonstrate that SUGAR, when paired with a well-chosen surrogate function,\nsubstantially enhances generalization performance over convolutional network\narchitectures such as VGG-16 and ResNet-18, providing sparser activations while\neffectively resurrecting dead ReLUs. Moreover, we show that even in modern\narchitectures like Conv2NeXt and Swin Transformer - which typically employ GELU\n- substituting these with SUGAR yields competitive and even slightly superior\nperformance. These findings challenge the prevailing notion that advanced\nactivation functions are necessary for optimal performance. Instead, they\nsuggest that the conventional ReLU, particularly with appropriate gradient\nhandling, can serve as a strong, versatile revived classic across a broad range\nof deep learning vision models.','Coşku Can Horuz, Geoffrey Kasenbacher, Saya Higuchi, Sebastian Kairat, Jendrik Stoltz, Moritz Pesl, Bernhard A. Moser, Christoph Linse, Thomas Martinetz, Sebastian Otte','2025-05-28','cs.LG','深度学习、神经网络','http://arxiv.org/pdf/2505.22074v1','该论文介绍了一种名为SUGAR的新型正则化方法，用于解决ReLU神经元出现不活跃的问题，提高了卷积网络结构的泛化性能，并在现代架构中取得了竞争性表现。'),('2505.22076v1','ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation','Training large language models (LLMs) to follow instructions has\nsignificantly enhanced their ability to tackle unseen tasks. However, despite\ntheir strong generalization capabilities, instruction-following LLMs encounter\ndifficulties when dealing with tasks that require domain knowledge. This work\nintroduces a specialized instruction fine-tuning for the domain of\ncomputational argumentation (CA). The goal is to enable an LLM to effectively\ntackle any unseen CA tasks while preserving its generalization capabilities.\nReviewing existing CA research, we crafted natural language instructions for\n105 CA tasks to this end. On this basis, we developed a CA-specific benchmark\nfor LLMs that allows for a comprehensive evaluation of LLMs\\\' capabilities in\nsolving various CA tasks. We synthesized 52k CA-related instructions, adapting\nthe self-instruct process to train a CA-specialized instruction-following LLM.\nOur experiments suggest that CA-specialized instruction fine-tuning\nsignificantly enhances the LLM on both seen and unseen CA tasks. At the same\ntime, performance on the general NLP tasks of the SuperNI benchmark remains\nstable.','Maja Stahl, Timon Ziegenbein, Joonsuk Park, Henning Wachsmuth','2025-05-28','cs.CL','大型语言模型(LLM)、计算论证(AI)','http://arxiv.org/pdf/2505.22076v1','该论文介绍了一种针对计算论证领域的专门指令微调方法，旨在使大型语言模型能够有效地处理任何未见过的计算论证任务，同时保持其泛化能力。通过合成52k个与计算论证相关的指令，采用自我指导过程训练了一个专门用于计算论证的指令跟随LLM，并实验证明了该方法显著提升了LLM在已见和未见的计算论证任务上的表现。'),('2505.22081v1','Can Test-time Computation Mitigate Memorization Bias in Neural Symbolic Regression?','Symbolic regression aims to discover mathematical equations that fit given\nnumerical data. It has been applied in various fields of scientific research,\nsuch as producing human-readable expressions that explain physical phenomena.\nRecently, Neural symbolic regression (NSR) methods that involve Transformers\npre-trained on large-scale synthetic datasets have gained attention. While\nthese methods offer advantages such as short inference time, they suffer from\nlow performance, particularly when the number of input variables is large. In\nthis study, we hypothesized that this limitation stems from the memorization\nbias of Transformers in symbolic regression. We conducted a quantitative\nevaluation of this bias in Transformers using a synthetic dataset and found\nthat Transformers rarely generate expressions not present in the training data.\nAdditional theoretical analysis reveals that this bias arises from the\nTransformer\\\'s inability to construct expressions compositionally while\nverifying their numerical validity. We finally examined if tailoring test-time\nstrategies can lead to reduced memorization bias and better performance. We\nempirically demonstrate that providing additional information to the model at\ntest time can significantly mitigate memorization bias. On the other hand, we\nalso find that reducing memorization bias does not necessarily correlate with\nimproved performance. These findings contribute to a deeper understanding of\nthe limitations of NSR approaches and offer a foundation for designing more\nrobust, generalizable symbolic regression methods. Code is available at\nhttps://github.com/Shun-0922/Mem-Bias-NSR .','Shun Sato, Issei Sato','2025-05-28','cs.LG','符号回归、神经网络','http://arxiv.org/pdf/2505.22081v1','该论文研究了神经符号回归方法中存在的记忆偏差问题，通过定量评估发现 Transformers 很少生成训练数据中不存在的表达式，最终提出了在测试时提供额外信息以减轻记忆偏差的方法。'),('2505.22083v1','Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz','In this work, we introduce the first type of non-Euclidean neural quantum\nstate (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent\nneural networks (RNNs)), to be used in the Variational Monte Carlo method of\napproximating the ground state wavefunction for quantum many-body systems. In\nparticular, we examine the performances of NQS ansatzes constructed from both\nconventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical\nsettings of the one- and two-dimensional transverse field Ising models (TFIM)\nof up to 100 spins and the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$\nsystems of up 50 spins. By virtue of the fact that, for all of the experiments\nperformed in this work, hyperbolic GRU can yield performances comparable to or\nbetter than Euclidean RNNs, which have been extensively studied in these\nsettings in the literature, our work is a proof-of-concept for the viability of\nhyperbolic GRU as the first type of non-Euclidean NQS ansatz for quantum\nmany-body systems. Furthermore, in settings where the Hamiltonian displays a\nclear hierarchical interaction structure, such as the 1D Heisenberg $J_1J_2$ &\n$J_1J_2J_3$ systems with the 1st, 2nd and even 3rd nearest neighbor\ninteractions, our results show that hyperbolic GRU definitively outperforms its\nEuclidean version in all instances. The fact that these results are reminiscent\nof the established ones from natural language processing where hyperbolic GRU\nalmost always outperforms Euclidean RNNs when the training data exhibit a\ntree-like or hierarchical structure leads us to hypothesize that hyperbolic GRU\nNQS ansatz would likely outperform Euclidean RNN/GRU NQS ansatz in quantum spin\nsystems that involve different degrees of nearest neighbor interactions.\nFinally, with this work, we hope to initiate future studies of other types of\nnon-Euclidean NQS beyond hyperbolic GRU.','H. L. Dao','2025-05-28','quant-ph','自然语言处理','http://arxiv.org/pdf/2505.22083v1','本文介绍了第一种非欧几里得神经量子态（NQS）的假设，即双曲线GRU（一种循环神经网络（RNN）的变体），用于近似量子多体系统的基态波函数的变分蒙特卡洛方法。研究发现，双曲线GRU在一维和二维横向场伊辛模型以及一维海森堡系统中的表现比欧几里得RNN更好，尤其在具有明显分层交互结构的情况下。'),('2505.22085v1','PADAM: Parallel averaged Adam reduces the error for stochastic optimization in scientific machine learning','Averaging techniques such as Ruppert--Polyak averaging and exponential\nmovering averaging (EMA) are powerful approaches to accelerate optimization\nprocedures of stochastic gradient descent (SGD) optimization methods such as\nthe popular ADAM optimizer. However, depending on the specific optimization\nproblem under consideration, the type and the parameters for the averaging need\nto be adjusted to achieve the smallest optimization error. In this work we\npropose an averaging approach, which we refer to as parallel averaged ADAM\n(PADAM), in which we compute parallely different averaged variants of ADAM and\nduring the training process dynamically select the variant with the smallest\noptimization error. A central feature of this approach is that this procedure\nrequires no more gradient evaluations than the usual ADAM optimizer as each of\nthe averaged trajectories relies on the same underlying ADAM trajectory and\nthus on the same underlying gradients. We test the proposed PADAM optimizer in\n13 stochastic optimization and deep neural network (DNN) learning problems and\ncompare its performance with known optimizers from the literature such as\nstandard SGD, momentum SGD, Adam with and without EMA, and ADAMW. In\nparticular, we apply the compared optimizers to physics-informed neural\nnetwork, deep Galerkin, deep backward stochastic differential equation and deep\nKolmogorov approximations for boundary value partial differential equation\nproblems from scientific machine learning, as well as to DNN approximations for\noptimal control and optimal stopping problems. In nearly all of the considered\nexamples PADAM achieves, sometimes among others and sometimes exclusively,\nessentially the smallest optimization error. This work thus strongly suggest to\nconsider PADAM for scientific machine learning problems and also motivates\nfurther research for adaptive averaging procedures within the training of DNNs.','Arnulf Jentzen, Julian Kranz, Adrian Riekert','2025-05-28','math.OC','深度学习、优化算法','http://arxiv.org/pdf/2505.22085v1','本文提出了一种并行平均的ADAM优化器（PADAM），在训练过程中动态选择具有最小优化误差的变体。通过在13个随机优化和深度神经网络学习问题上测试，PADAM在几乎所有情况下都取得了最小的优化误差。'),('2505.22086v1','iDSE: Navigating Design Space Exploration in High-Level Synthesis Using LLMs','High-Level Synthesis (HLS) serves as an agile hardware development tool that\nstreamlines the circuit design by abstracting the register transfer level into\nbehavioral descriptions, while allowing designers to customize the generated\nmicroarchitectures through optimization directives. However, the combinatorial\nexplosion of possible directive configurations yields an intractable design\nspace. Traditional design space exploration (DSE) methods, despite adopting\nheuristics or constructing predictive models to accelerate Pareto-optimal\ndesign acquisition, still suffer from prohibitive exploration costs and\nsuboptimal results. Addressing these concerns, we introduce iDSE, the first\nLLM-aided DSE framework that leverages HLS design quality perception to\neffectively navigate the design space. iDSE intelligently pruns the design\nspace to guide LLMs in calibrating representative initial sampling designs,\nexpediting convergence toward the Pareto front. By exploiting the convergent\nand divergent thinking patterns inherent in LLMs for hardware optimization,\niDSE achieves multi-path refinement of the design quality and diversity.\nExtensive experiments demonstrate that iDSE outperforms heuristic-based DSE\nmethods by 5.1$\\times$$\\sim$16.6$\\times$ in proximity to the reference Pareto\nfront, matching NSGA-II with only 4.6% of the explored designs. Our work\ndemonstrates the transformative potential of LLMs in scalable and efficient HLS\ndesign optimization, offering new insights into multiobjective optimization\nchallenges.','Runkai Li, Jia Xiong, Xi Wang','2025-05-28','cs.AR','LLM (Low-Level Machine Learning)','http://arxiv.org/pdf/2505.22086v1','该论文介绍了一种新的基于LLM的高级综合设计空间探索框架iDSE，通过利用LLM的设计质量感知来有效地导航设计空间，实现了设计质量和多样性的多路径优化。实验结果表明，iDSE在接近参考Pareto前沿的同时，比基于启发式的DSE方法表现更好，仅使用了探索设计的4.6%就能与NSGA-II相匹配。'),('2505.22087v1','Cognitively-Inspired Emergent Communication via Knowledge Graphs for Assisting the Visually Impaired','Assistive systems for visually impaired individuals must deliver rapid,\ninterpretable, and adaptive feedback to facilitate real-time navigation.\nCurrent approaches face a trade-off between latency and semantic richness:\nnatural language-based systems provide detailed guidance but are too slow for\ndynamic scenarios, while emergent communication frameworks offer low-latency\nsymbolic languages but lack semantic depth, limiting their utility in tactile\nmodalities like vibration. To address these limitations, we introduce a novel\nframework, Cognitively-Inspired Emergent Communication via Knowledge Graphs\n(VAG-EC), which emulates human visual perception and cognitive mapping. Our\nmethod constructs knowledge graphs to represent objects and their\nrelationships, incorporating attention mechanisms to prioritize task-relevant\nentities, thereby mirroring human selective attention. This structured approach\nenables the emergence of compact, interpretable, and context-sensitive symbolic\nlanguages. Extensive experiments across varying vocabulary sizes and message\nlengths demonstrate that VAG-EC outperforms traditional emergent communication\nmethods in Topographic Similarity (TopSim) and Context Independence (CI). These\nfindings underscore the potential of cognitively grounded emergent\ncommunication as a fast, adaptive, and human-aligned solution for real-time\nassistive technologies. Code is available at\nhttps://github.com/Anonymous-NLPcode/Anonymous_submission/tree/main.','Ruxiao Chen, Dezheng Han, Wenjie Han, Shuaishuai Guo','2025-05-28','cs.AI','自然语言处理','http://arxiv.org/pdf/2505.22087v1','该论文介绍了一种新颖的框架 VAG-EC，通过知识图谱模拟人类视觉感知和认知映射，以提供快速、可解释和自适应的反馈，用于帮助视障人士实时导航。实验结果表明，VAG-EC 在拓扑相似性和上下文独立性方面优于传统的 emergent communication 方法。'),('2505.22088v1','Visual Cues Support Robust Turn-taking Prediction in Noise','Accurate predictive turn-taking models (PTTMs) are essential for naturalistic\nhuman-robot interaction. However, little is known about their performance in\nnoise. This study therefore explores PTTM performance in types of noise likely\nto be encountered once deployed. Our analyses reveal PTTMs are highly sensitive\nto noise. Hold/shift accuracy drops from 84% in clean speech to just 52% in 10\ndB music noise. Training with noisy data enables a multimodal PTTM, which\nincludes visual features to better exploit visual cues, with 72% accuracy in 10\ndB music noise. The multimodal PTTM outperforms the audio-only PTTM across all\nnoise types and SNRs, highlighting its ability to exploit visual cues; however,\nthis does not always generalise to new types of noise. Analysis also reveals\nthat successful training relies on accurate transcription, limiting the use of\nASR-derived transcriptions to clean conditions. We make code publicly available\nfor future research.','Sam O\'Connor Russell, Naomi Harte','2025-05-28','cs.SD','自然语言处理','http://arxiv.org/pdf/2505.22088v1','本研究探讨了在噪声环境中预测性对话模型（PTTM）的表现，发现PTTM对噪声非常敏感。通过使用噪声数据训练，实现了一个多模态PTTM，包括视觉特征以更好地利用视觉线索，在10 dB音乐噪声下达到了72%的准确率。多模态PTTM在所有噪声类型和信噪比下表现优于仅音频的PTTM，但在新的噪声类型下性能不一定能够泛化。'),('2505.22090v1','High Volume Rate 3D Ultrasound Reconstruction with Diffusion Models','Three-dimensional ultrasound enables real-time volumetric visualization of\nanatomical structures. Unlike traditional 2D ultrasound, 3D imaging reduces the\nreliance on precise probe orientation, potentially making ultrasound more\naccessible to clinicians with varying levels of experience and improving\nautomated measurements and post-exam analysis. However, achieving both high\nvolume rates and high image quality remains a significant challenge. While 3D\ndiverging waves can provide high volume rates, they suffer from limited tissue\nharmonic generation and increased multipath effects, which degrade image\nquality. One compromise is to retain the focusing in elevation while leveraging\nunfocused diverging waves in the lateral direction to reduce the number of\ntransmissions per elevation plane. Reaching the volume rates achieved by full\n3D diverging waves, however, requires dramatically undersampling the number of\nelevation planes. Subsequently, to render the full volume, simple interpolation\ntechniques are applied. This paper introduces a novel approach to 3D ultrasound\nreconstruction from a reduced set of elevation planes by employing diffusion\nmodels (DMs) to achieve increased spatial and temporal resolution. We compare\nboth traditional and supervised deep learning-based interpolation methods on a\n3D cardiac ultrasound dataset. Our results show that DM-based reconstruction\nconsistently outperforms the baselines in image quality and downstream task\nperformance. Additionally, we accelerate inference by leveraging the temporal\nconsistency inherent to ultrasound sequences. Finally, we explore the\nrobustness of the proposed method by exploiting the probabilistic nature of\ndiffusion posterior sampling to quantify reconstruction uncertainty and\ndemonstrate improved recall on out-of-distribution data with synthetic\nanomalies under strong subsampling.','Tristan S. W. Stevens, Oisín Nolan, Oudom Somphone, Jean-Luc Robert, Ruud J. G. van Sloun','2025-05-28','eess.IV','图像识别','http://arxiv.org/pdf/2505.22090v1','该论文介绍了一种新颖的方法，利用扩散模型（DMs）从减少的仰角平面集合中进行3D超声波重建，以实现增加的空间和时间分辨率。研究结果表明，DM-based重建在图像质量和下游任务性能方面始终优于基线方法。此外，通过利用超声波序列固有的时间一致性，我们加速了推断过程，并通过利用扩散后验采样的概率性质来量化重建不确定性，展示了在强烈子采样下合成异常数据的情况下改进的召回率。'),('2505.22092v1','VIRAL: Vision-grounded Integration for Reward design And Learning','The alignment between humans and machines is a critical challenge in\nartificial intelligence today. Reinforcement learning, which aims to maximize a\nreward function, is particularly vulnerable to the risks associated with poorly\ndesigned reward functions. Recent advancements has shown that Large Language\nModels (LLMs) for reward generation can outperform human performance in this\ncontext. We introduce VIRAL, a pipeline for generating and refining reward\nfunctions through the use of multi-modal LLMs. VIRAL autonomously creates and\ninteractively improves reward functions based on a given environment and a goal\nprompt or annotated image. The refinement process can incorporate human\nfeedback or be guided by a description generated by a video LLM, which explains\nthe agent\\\'s policy in video form. We evaluated VIRAL in five Gymnasium\nenvironments, demonstrating that it accelerates the learning of new behaviors\nwhile ensuring improved alignment with user intent. The source-code and demo\nvideo are available at: https://github.com/VIRAL-UCBL1/VIRAL and\nhttps://youtu.be/t4_BXugBm9Q.','Valentin Cuzin-Rambaud, Emilien Komlenovic, Alexandre Faure, Bruno Yun','2025-05-28','cs.AI','强化学习','http://arxiv.org/pdf/2505.22092v1','该论文介绍了一种名为VIRAL的管道系统，通过使用多模态LLMs生成和改进奖励函数，以加速新行为的学习并确保与用户意图的改进对齐。'),('2505.22094v1','ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning','We propose ReinFlow, a simple yet effective online reinforcement learning\n(RL) framework that fine-tunes a family of flow matching policies for\ncontinuous robotic control. Derived from rigorous RL theory, ReinFlow injects\nlearnable noise into a flow policy\\\'s deterministic path, converting the flow\ninto a discrete-time Markov Process for exact and straightforward likelihood\ncomputation. This conversion facilitates exploration and ensures training\nstability, enabling ReinFlow to fine-tune diverse flow model variants,\nincluding Rectified Flow [35] and Shortcut Models [19], particularly at very\nfew or even one denoising step. We benchmark ReinFlow in representative\nlocomotion and manipulation tasks, including long-horizon planning with visual\ninput and sparse reward. The episode reward of Rectified Flow policies obtained\nan average net growth of 135.36% after fine-tuning in challenging legged\nlocomotion tasks while saving denoising steps and 82.63% of wall time compared\nto state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate\nof the Shortcut Model policies in state and visual manipulation tasks achieved\nan average net increase of 40.34% after fine-tuning with ReinFlow at four or\neven one denoising step, whose performance is comparable to fine-tuned DDIM\npolicies while saving computation time for an average of 23.20%. Project\nWebpage: https://reinflow.github.io/','Tonghe Zhang, Yu Chao, Sicang Su, Yu Wang','2025-05-28','cs.RO','强化学习','http://arxiv.org/pdf/2505.22094v1','该论文提出了一种名为ReinFlow的在线强化学习框架，用于对连续机器人控制进行微调，通过向流策略注入可学习的噪声，将流转换为离散时间马尔可夫过程，以便进行精确和简单的可能性计算。ReinFlow在代表性的运动和操作任务中进行了基准测试，取得了显著的性能提升。'),('2505.22095v1','Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning','Multimodal Retrieval-Augmented Generation (MRAG) has shown promise in\nmitigating hallucinations in Multimodal Large Language Models (MLLMs) by\nincorporating external knowledge during generation. Existing MRAG methods\ntypically adopt a static retrieval pipeline that fetches relevant information\nfrom multiple Knowledge Bases (KBs), followed by a refinement step. However,\nthese approaches overlook the reasoning and planning capabilities of MLLMs to\ndynamically determine how to interact with different KBs during the reasoning\nprocess. To address this limitation, we propose R1-Router, a novel MRAG\nframework that learns to decide when and where to retrieve knowledge based on\nthe evolving reasoning state. Specifically, R1-Router can generate follow-up\nqueries according to the current reasoning step, routing these intermediate\nqueries to the most suitable KB, and integrating external knowledge into a\ncoherent reasoning trajectory to answer the original query. Furthermore, we\nintroduce Step-wise Group Relative Policy Optimization (Step-GRPO), a tailored\nreinforcement learning algorithm that assigns step-specific rewards to optimize\nthe reasoning behavior of MLLMs. Experimental results on various open-domain QA\nbenchmarks across multiple modalities demonstrate that R1-Router outperforms\nbaseline models by over 7%. Further analysis shows that R1-Router can\nadaptively and effectively leverage diverse KBs, reducing unnecessary\nretrievals and improving both efficiency and accuracy.','Chunyi Peng, Zhipeng Xu, Zhenghao Liu, Yishan Li, Yukun Yan, Shuo Wang, Zhiyuan Liu, Yu Gu, Minghe Yu, Ge Yu, Maosong Sun','2025-05-28','cs.CL','LLM、自然语言处理、知识图谱','http://arxiv.org/pdf/2505.22095v1','该论文提出了一种名为R1-Router的新型MRAG框架，旨在通过学习决定何时以及在何处检索知识，以动态地与不同的知识库进行交互，从而优化MLLMs的推理行为。通过Step-GRPO算法，该框架在多个开放领域QA基准测试中表现优于基线模型，提高了超过7%的性能。'),('2505.22096v1','Knowledge Base Construction for Knowledge-Augmented Text-to-SQL','Text-to-SQL aims to translate natural language queries into SQL statements,\nwhich is practical as it enables anyone to easily retrieve the desired\ninformation from databases. Recently, many existing approaches tackle this\nproblem with Large Language Models (LLMs), leveraging their strong capability\nin understanding user queries and generating corresponding SQL code. Yet, the\nparametric knowledge in LLMs might be limited to covering all the diverse and\ndomain-specific queries that require grounding in various database schemas,\nwhich makes generated SQLs less accurate oftentimes. To tackle this, we propose\nconstructing the knowledge base for text-to-SQL, a foundational source of\nknowledge, from which we retrieve and generate the necessary knowledge for\ngiven queries. In particular, unlike existing approaches that either manually\nannotate knowledge or generate only a few pieces of knowledge for each query,\nour knowledge base is comprehensive, which is constructed based on a\ncombination of all the available questions and their associated database\nschemas along with their relevant knowledge, and can be reused for unseen\ndatabases from different datasets and domains. We validate our approach on\nmultiple text-to-SQL datasets, considering both the overlapping and\nnon-overlapping database scenarios, where it outperforms relevant baselines\nsubstantially.','Jinheon Baek, Horst Samulowitz, Oktie Hassanzadeh, Dharmashankar Subramanian, Sola Shirai, Alfio Gliozzo, Debarun Bhattacharjya','2025-05-28','cs.CL','自然语言处理(Text-to-SQL)','http://arxiv.org/pdf/2505.22096v1','该论文提出了一种构建文本到SQL的知识库的方法，以提高生成SQL语句的准确性，相比于现有方法在多个文本到SQL数据集上表现更好。'),('2505.22099v1','On the Transferability and Discriminability of Repersentation Learning in Unsupervised Domain Adaptation','In this paper, we addressed the limitation of relying solely on distribution\nalignment and source-domain empirical risk minimization in Unsupervised Domain\nAdaptation (UDA). Our information-theoretic analysis showed that this standard\nadversarial-based framework neglects the discriminability of target-domain\nfeatures, leading to suboptimal performance. To bridge this\ntheoretical-practical gap, we defined \"good representation learning\" as\nguaranteeing both transferability and discriminability, and proved that an\nadditional loss term targeting target-domain discriminability is necessary.\nBuilding on these insights, we proposed a novel adversarial-based UDA framework\nthat explicitly integrates a domain alignment objective with a\ndiscriminability-enhancing constraint. Instantiated as Domain-Invariant\nRepresentation Learning with Global and Local Consistency (RLGLC), our method\nleverages Asymmetrically-Relaxed Wasserstein of Wasserstein Distance (AR-WWD)\nto address class imbalance and semantic dimension weighting, and employs a\nlocal consistency mechanism to preserve fine-grained target-domain\ndiscriminative information. Extensive experiments across multiple benchmark\ndatasets demonstrate that RLGLC consistently surpasses state-of-the-art\nmethods, confirming the value of our theoretical perspective and underscoring\nthe necessity of enforcing both transferability and discriminability in\nadversarial-based UDA.','Wenwen Qiang, Ziyin Gu, Lingyu Si, Jiangmeng Li, Changwen Zheng, Fuchun Sun, Hui Xiong','2025-05-28','cs.CV','领域自适应(Unsupervised Domain Adaptation)','http://arxiv.org/pdf/2505.22099v1','本文针对无监督域自适应（UDA）中仅依赖分布对齐和源域经验风险最小化的局限性进行了研究。通过信息论分析，发现标准对抗性框架忽视了目标域特征的可辨识性，导致性能不佳。为了弥补这一理论实践差距，提出了一种新的对抗性UDA框架，明确地将域对齐目标与增强可辨识性的约束相结合。'),('2505.22101v1','MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models','Large Language Models (LLMs) have emerged as foundational infrastructure in\nthe pursuit of Artificial General Intelligence (AGI). Despite their remarkable\ncapabilities in language perception and generation, current LLMs fundamentally\nlack a unified and structured architecture for handling memory. They primarily\nrely on parametric memory (knowledge encoded in model weights) and ephemeral\nactivation memory (context-limited runtime states). While emerging methods like\nRetrieval-Augmented Generation (RAG) incorporate plaintext memory, they lack\nlifecycle management and multi-modal integration, limiting their capacity for\nlong-term knowledge evolution. To address this, we introduce MemOS, a memory\noperating system designed for LLMs that, for the first time, elevates memory to\na first-class operational resource. It builds unified mechanisms for\nrepresentation, organization, and governance across three core memory types:\nparametric, activation, and plaintext. At its core is the MemCube, a\nstandardized memory abstraction that enables tracking, fusion, and migration of\nheterogeneous memory, while offering structured, traceable access across tasks\nand contexts. MemOS establishes a memory-centric execution framework with\nstrong controllability, adaptability, and evolvability. It fills a critical gap\nin current LLM infrastructure and lays the groundwork for continual adaptation,\npersonalized intelligence, and cross-platform coordination in next-generation\nintelligent systems.','Zhiyu Li, Shichao Song, Hanyu Wang, Simin Niu, Ding Chen, Jiawei Yang, Chenyang Xi, Huayi Lai, Jihao Zhao, Yezhaohui Wang, Junpeng Ren, Zehao Lin, Jiahao Huo, Tianyi Chen, Kai Chen, Kehang Li, Zhiqiang Yin, Qingchen Yu, Bo Tang, Hongkang Yang, Zhi-Qin John Xu, Feiyu Xiong','2025-05-28','cs.CL','大型语言模型(Large Language Models)','http://arxiv.org/pdf/2505.22101v1','该论文介绍了MemOS，一个为LLMs设计的记忆操作系统，旨在提供统一的结构化架构来处理记忆，填补了当前LLMs基础设施中的关键空白。'),('2505.22104v1','Efficient Dynamic Shielding for Parametric Safety Specifications','Shielding has emerged as a promising approach for ensuring safety of\nAI-controlled autonomous systems. The algorithmic goal is to compute a shield,\nwhich is a runtime safety enforcement tool that needs to monitor and intervene\nthe AI controller\\\'s actions if safety could be compromised otherwise.\nTraditional shields are designed statically for a specific safety requirement.\nTherefore, if the safety requirement changes at runtime due to changing\noperating conditions, the shield needs to be recomputed from scratch, causing\ndelays that could be fatal. We introduce dynamic shields for parametric safety\nspecifications, which are succinctly represented sets of all possible safety\nspecifications that may be encountered at runtime. Our dynamic shields are\nstatically designed for a given safety parameter set, and are able to\ndynamically adapt as the true safety specification (permissible by the\nparameters) is revealed at runtime. The main algorithmic novelty lies in the\ndynamic adaptation procedure, which is a simple and fast algorithm that\nutilizes known features of standard safety shields, like maximal\npermissiveness. We report experimental results for a robot navigation problem\nin unknown territories, where the safety specification evolves as new obstacles\nare discovered at runtime. In our experiments, the dynamic shields took a few\nminutes for their offline design, and took between a fraction of a second and a\nfew seconds for online adaptation at each step, whereas the brute-force online\nrecomputation approach was up to 5 times slower.','Davide Corsi, Kaushik Mallik, Andoni Rodriguez, Cesar Sanchez','2025-05-28','cs.AI','强化学习','http://arxiv.org/pdf/2505.22104v1','该论文介绍了一种动态盾牌设计方法，用于处理AI控制的自主系统的安全性问题。通过动态适应过程，盾牌可以根据运行时的真实安全规范动态调整，而不需要从头重新计算。实验结果表明，动态盾牌在离线设计时只需几分钟，在每一步的在线适应过程中只需几分之一至几秒的时间，而传统的在线重新计算方法则慢了多达5倍。'),('2505.22106v1','AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion','Diffusion models have significantly improved the quality and diversity of\naudio generation but are hindered by slow inference speed. Rectified flow\nenhances inference speed by learning straight-line ordinary differential\nequation (ODE) paths. However, this approach requires training a flow-matching\nmodel from scratch and tends to perform suboptimally, or even poorly, at low\nstep counts. To address the limitations of rectified flow while leveraging the\nadvantages of advanced pre-trained diffusion models, this study integrates\npre-trained models with the rectified diffusion method to improve the\nefficiency of text-to-audio (TTA) generation. Specifically, we propose\nAudioTurbo, which learns first-order ODE paths from deterministic noise sample\npairs generated by a pre-trained TTA model. Experiments on the AudioCaps\ndataset demonstrate that our model, with only 10 sampling steps, outperforms\nprior models and reduces inference to 3 steps compared to a flow-matching-based\nacceleration model.','Junqi Zhao, Jinzheng Zhao, Haohe Liu, Yun Chen, Lu Han, Xubo Liu, Mark Plumbley, Wenwu Wang','2025-05-28','cs.SD','自然语言处理','http://arxiv.org/pdf/2505.22106v1','该论文提出了一种结合预训练模型和修正扩散方法的方法，用于改进文本转音频生成的效率。通过学习预训练模型生成的确定性噪声样本对，该方法在仅有10个采样步骤时，表现优于先前的模型，并将推断步骤减少到3步。'),('2505.22107v1','Curse of High Dimensionality Issue in Transformer for Long-context Modeling','Transformer-based large language models (LLMs) excel in natural language\nprocessing tasks by capturing long-range dependencies through self-attention\nmechanisms. However, long-context modeling faces significant computational\ninefficiencies due to \\textit{redundant} attention computations: while\nattention weights are often \\textit{sparse}, all tokens consume \\textit{equal}\ncomputational resources. In this paper, we reformulate traditional\nprobabilistic sequence modeling as a \\textit{supervised learning task},\nenabling the separation of relevant and irrelevant tokens and providing a\nclearer understanding of redundancy. Based on this reformulation, we\ntheoretically analyze attention sparsity, revealing that only a few tokens\nsignificantly contribute to predictions. Building on this, we formulate\nattention optimization as a linear coding problem and propose a \\textit{group\ncoding strategy}, theoretically showing its ability to improve robustness\nagainst random noise and enhance learning efficiency. Motivated by this, we\npropose \\textit{Dynamic Group Attention} (DGA), which leverages the group\ncoding to explicitly reduce redundancy by aggregating less important tokens\nduring attention computation. Empirical results show that our DGA significantly\nreduces computational costs while maintaining competitive performance.Code is\navailable at https://github.com/bolixinyu/DynamicGroupAttention.','Shuhai Zhang, Zeng You, Yaofo Chen, Zhiquan Wen, Qianyue Wang, Zhijie Qiu, Yuanqing Li, Mingkui Tan','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22107v1','该论文提出了一种基于动态分组注意力机制的方法，通过将注意力聚焦在重要的 token 上，从而减少冗余计算，提高计算效率，并在自然语言处理任务中取得了竞争性能。'),('2505.22108v1','Inclusive, Differentially Private Federated Learning for Clinical Data','Federated Learning (FL) offers a promising approach for training clinical AI\nmodels without centralizing sensitive patient data. However, its real-world\nadoption is hindered by challenges related to privacy, resource constraints,\nand compliance. Existing Differential Privacy (DP) approaches often apply\nuniform noise, which disproportionately degrades model performance, even among\nwell-compliant institutions. In this work, we propose a novel compliance-aware\nFL framework that enhances DP by adaptively adjusting noise based on\nquantifiable client compliance scores. Additionally, we introduce a compliance\nscoring tool based on key healthcare and security standards to promote secure,\ninclusive, and equitable participation across diverse clinical settings.\nExtensive experiments on public datasets demonstrate that integrating\nunder-resourced, less compliant clinics with highly regulated institutions\nyields accuracy improvements of up to 15% over traditional FL. This work\nadvances FL by balancing privacy, compliance, and performance, making it a\nviable solution for real-world clinical workflows in global healthcare.','Santhosh Parampottupadam, Melih Coşğun, Sarthak Pati, Maximilian Zenk, Saikat Roy, Dimitrios Bounias, Benjamin Hamm, Sinem Sav, Ralf Floca, Klaus Maier-Hein','2025-05-28','cs.LG','联邦学习 (Federated Learning)','http://arxiv.org/pdf/2505.22108v1','该论文提出了一种新颖的基于合规性的联邦学习框架，通过根据可量化的客户合规性评分自适应调整噪声，以提高差分隐私的效果。实验证明，将资源匮乏、合规性较低的诊所与高度规范的机构整合，可以使准确性提高高达15%。'),('2505.22109v1','The quest for the GRAph Level autoEncoder (GRALE)','Although graph-based learning has attracted a lot of attention, graph\nrepresentation learning is still a challenging task whose resolution may impact\nkey application fields such as chemistry or biology. To this end, we introduce\nGRALE, a novel graph autoencoder that encodes and decodes graphs of varying\nsizes into a shared embedding space. GRALE is trained using an Optimal\nTransport-inspired loss that compares the original and reconstructed graphs and\nleverages a differentiable node matching module, which is trained jointly with\nthe encoder and decoder. The proposed attention-based architecture relies on\nEvoformer, the core component of AlphaFold, which we extend to support both\ngraph encoding and decoding. We show, in numerical experiments on simulated and\nmolecular data, that GRALE enables a highly general form of pre-training,\napplicable to a wide range of downstream tasks, from classification and\nregression to more complex tasks such as graph interpolation, editing,\nmatching, and prediction.','Paul Krzakala, Gabriel Melo, Charlotte Laclau, Florence d\'Alché-Buc, Rémi Flamary','2025-05-28','cs.LG','图神经网络','http://arxiv.org/pdf/2505.22109v1','该论文介绍了一种名为GRALE的新型图自编码器，通过将不同大小的图编码和解码到一个共享的嵌入空间中，利用基于最优输运的损失函数进行训练，并结合可微的节点匹配模块。实验结果表明，GRALE能够进行高度通用的预训练，适用于各种下游任务。'),('2505.22112v1','Visual Large Language Models Exhibit Human-Level Cognitive Flexibility in the Wisconsin Card Sorting Test','Cognitive flexibility has been extensively studied in human cognition but\nremains relatively unexplored in the context of Visual Large Language Models\n(VLLMs). This study assesses the cognitive flexibility of state-of-the-art\nVLLMs (GPT-4o, Gemini-1.5 Pro, and Claude-3.5 Sonnet) using the Wisconsin Card\nSorting Test (WCST), a classic measure of set-shifting ability. Our results\nreveal that VLLMs achieve or surpass human-level set-shifting capabilities\nunder chain-of-thought prompting with text-based inputs. However, their\nabilities are highly influenced by both input modality and prompting strategy.\nIn addition, we find that through role-playing, VLLMs can simulate various\nfunctional deficits aligned with patients having impairments in cognitive\nflexibility, suggesting that VLLMs may possess a cognitive architecture, at\nleast regarding the ability of set-shifting, similar to the brain. This study\nreveals the fact that VLLMs have already approached the human level on a key\ncomponent underlying our higher cognition, and highlights the potential to use\nthem to emulate complex brain processes.','Guangfu Hao, Frederic Alexandre, Shan Yu','2025-05-28','cs.AI','大规模视觉语言模型（VLLMs）','http://arxiv.org/pdf/2505.22112v1','本研究评估了最先进的VLLMs（GPT-4o，Gemini-1.5 Pro和Claude-3.5 Sonnet）在Wisconsin Card Sorting Test（WCST）中的认知灵活性，结果显示在文本输入的情况下，VLLMs实现或超越了人类水平的转换能力。然而，它们的能力受输入模态和提示策略的影响很大。此外，通过角色扮演，VLLMs可以模拟与认知灵活性受损患者相符的各种功能缺陷，暗示VLLMs可能具有类似大脑的认知架构，至少在转换能力方面。'),('2505.22113v1','THINK-Bench: Evaluating Thinking Efficiency and Chain-of-Thought Quality of Large Reasoning Models','Large reasoning models (LRMs) have achieved impressive performance in complex\ntasks, often outperforming conventional large language models (LLMs). However,\nthe prevalent issue of overthinking severely limits their computational\nefficiency. Overthinking occurs when models generate excessive and redundant\ntokens that contribute little to accurate outcomes, especially in simple tasks,\nresulting in a significant waste of computational resources. To systematically\ninvestigate this issue, we introduce Think-Bench, a benchmark designed to\nevaluate the reasoning efficiency of LRMs. We also propose novel efficiency\nmetrics and conduct a comprehensive evaluation of various LRMs across multiple\ndimensions, including the reasoning process, outcome quality, and\nchain-of-thought (CoT) characteristics. Our analysis reveals that most LRMs\nexhibit overthinking in handling easy questions, generating unnecessarily\nlengthy reasoning chains. While many LRMs demonstrate high CoT quality, several\nsuffer from low efficiency. We hope that Think-Bench can serve as a robust\nfoundation for advancing research into LRMs.','Zhiyuan Li, Yi Chang, Yuan Wu','2025-05-28','cs.CL','LLM（大型语言模型）','http://arxiv.org/pdf/2505.22113v1','该论文主要研究大型推理模型在处理复杂任务时的效率问题，提出了Think-Bench基准测试用于评估LRM的推理效率，并提出了新的效率评估指标。研究发现大多数LRM在处理简单问题时存在过度思考的问题，生成冗长的推理链，部分LRM效率较低。'),('2505.22114v1','BiMi Sheets: Infosheets for bias mitigation methods','Over the past 15 years, hundreds of bias mitigation methods have been\nproposed in the pursuit of fairness in machine learning (ML). However,\nalgorithmic biases are domain-, task-, and model-specific, leading to a\n`portability trap\\\': bias mitigation solutions in one context may not be\nappropriate in another. Thus, a myriad of design choices have to be made when\ncreating a bias mitigation method, such as the formalization of fairness it\npursues, and where and how it intervenes in the ML pipeline. This creates\nchallenges in benchmarking and comparing the relative merits of different bias\nmitigation methods, and limits their uptake by practitioners.\n  We propose BiMi Sheets as a portable, uniform guide to document the design\nchoices of any bias mitigation method. This enables researchers and\npractitioners to quickly learn its main characteristics and to compare with\ntheir desiderata. Furthermore, the sheets\\\' structure allow for the creation of\na structured database of bias mitigation methods. In order to foster the\nsheets\\\' adoption, we provide a platform for finding and creating BiMi Sheets at\nbimisheet.com.','MaryBeth Defrance, Guillaume Bied, Maarten Buyl, Jefrey Lijffijt, Tijl De Bie','2025-05-28','cs.LG','偏见缓解方法','http://arxiv.org/pdf/2505.22114v1','该论文提出了一种名为BiMi Sheets的方法，用于记录任何偏见缓解方法的设计选择，以帮助研究人员和从业者比较和评估不同的偏见缓解方法。'),('2505.22116v1','Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model','Intraoperative hypotension (IOH) frequently occurs under general anesthesia\nand is strongly linked to adverse outcomes such as myocardial injury and\nincreased mortality. Despite its significance, IOH prediction is hindered by\nevent sparsity and the challenge of integrating static and dynamic data across\ndiverse patients. In this paper, we propose \\textbf{IOHFuseLM}, a multimodal\nlanguage model framework. To accurately identify and differentiate sparse\nhypotensive events, we leverage a two-stage training strategy. The first stage\ninvolves domain adaptive pretraining on IOH physiological time series augmented\nthrough diffusion methods, thereby enhancing the model sensitivity to patterns\nassociated with hypotension. Subsequently, task fine-tuning is performed on the\noriginal clinical dataset to further enhance the ability to distinguish\nnormotensive from hypotensive states. To enable multimodal fusion for each\npatient, we align structured clinical descriptions with the corresponding\nphysiological time series at the token level. Such alignment enables the model\nto capture individualized temporal patterns alongside their corresponding\nclinical semantics. In addition, we convert static patient attributes into\nstructured text to enrich personalized information. Experimental evaluations on\ntwo intraoperative datasets demonstrate that IOHFuseLM outperforms established\nbaselines in accurately identifying IOH events, highlighting its applicability\nin clinical decision support scenarios. Our code is publicly available to\npromote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.','Jintao Zhang, Zirui Liu, Mingyue Cheng, Shilong Zhang, Tingyue Pan, Qi Liu, Yanhu Xie','2025-05-28','cs.CL','医疗健康AI','http://arxiv.org/pdf/2505.22116v1','本文提出了一种名为IOHFuseLM的多模态语言模型框架，用于预测术中低血压事件。通过两阶段训练策略，结合生理时间序列和临床描述，能够准确识别低血压事件，优于传统基线方法。'),('2505.22118v1','Multilingual vs Crosslingual Retrieval of Fact-Checked Claims: A Tale of Two Approaches','Retrieval of previously fact-checked claims is a well-established task, whose\nautomation can assist professional fact-checkers in the initial steps of\ninformation verification. Previous works have mostly tackled the task\nmonolingually, i.e., having both the input and the retrieved claims in the same\nlanguage. However, especially for languages with a limited availability of\nfact-checks and in case of global narratives, such as pandemics, wars, or\ninternational politics, it is crucial to be able to retrieve claims across\nlanguages. In this work, we examine strategies to improve the multilingual and\ncrosslingual performance, namely selection of negative examples (in the\nsupervised) and re-ranking (in the unsupervised setting). We evaluate all\napproaches on a dataset containing posts and claims in 47 languages (283\nlanguage combinations). We observe that the best results are obtained by using\nLLM-based re-ranking, followed by fine-tuning with negative examples sampled\nusing a sentence similarity-based strategy. Most importantly, we show that\ncrosslinguality is a setup with its own unique characteristics compared to the\nmultilingual setup.','Alan Ramponi, Marco Rovera, Robert Moro, Sara Tonelli','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22118v1','本文研究了事实核查任务中的多语言和跨语言性能改进策略，包括在监督学习中选择负例和在无监督设置中重新排序。他们在包含47种语言的数据集上评估了所有方法，发现基于LLM的重新排序效果最好，其次是使用基于句子相似性策略采样负例进行微调。最重要的是，他们展示了跨语言性是一个具有独特特征的设置，与多语言设置不同。'),('2505.22120v1','LoKI: Low-damage Knowledge Implanting of Large Language Models','Fine-tuning adapts pretrained models for specific tasks but poses the risk of\ncatastrophic forgetting (CF), where critical knowledge from pre-training is\noverwritten. Current Parameter-Efficient Fine-Tuning (PEFT) methods for Large\nLanguage Models (LLMs), while efficient, often sacrifice general capabilities.\nTo address the issue of CF in a general-purpose PEFT framework, we propose\n\\textbf{Lo}w-damage \\textbf{K}nowledge \\textbf{I}mplanting (\\textbf{LoKI}), a\nPEFT technique that is based on a mechanistic understanding of how knowledge is\nstored in transformer architectures. In two real-world scenarios, LoKI\ndemonstrates task-specific performance that is comparable to or even surpasses\nthat of full fine-tuning and LoRA-based methods across various model types,\nwhile significantly better preserving general capabilities. Our work connects\nmechanistic insights into LLM knowledge storage with practical fine-tuning\nobjectives, achieving state-of-the-art trade-offs between task specialization\nand the preservation of general capabilities. Our implementation is publicly\navailable as ready-to-use code\\footnote{https://github.com/Nexround/LoKI}.','Runyu Wang, Peng Ping, Zhengyu Guo, Xiaoye Zhang, Quan Shi, Liting Zhou, Tianbo Ji','2025-05-28','cs.CL','大型语言模型 (LLM)','http://arxiv.org/pdf/2505.22120v1','该论文提出了一种名为LoKI的PEFT技术，旨在解决在大型语言模型中出现的灾难性遗忘问题，通过对transformer架构中知识存储方式的机械理解，实现了在特定任务上性能与全面微调方法相媲美甚至优于其，并显著保留了通用能力。'),('2505.22125v1','Sentiment Simulation using Generative AI Agents','Traditional sentiment analysis relies on surface-level linguistic patterns\nand retrospective data, limiting its ability to capture the psychological and\ncontextual drivers of human sentiment. These limitations constrain its\neffectiveness in applications that require predictive insight, such as policy\ntesting, narrative framing, and behavioral forecasting. We present a robust\nframework for sentiment simulation using generative AI agents embedded with\npsychologically rich profiles. Agents are instantiated from a nationally\nrepresentative survey of 2,485 Filipino respondents, combining sociodemographic\ninformation with validated constructs of personality traits, values, beliefs,\nand socio-political attitudes. The framework includes three stages: (1) agent\nembodiment via categorical or contextualized encodings, (2) exposure to\nreal-world political and economic scenarios, and (3) generation of sentiment\nratings accompanied by explanatory rationales. Using Quadratic Weighted\nAccuracy (QWA), we evaluated alignment between agent-generated and human\nresponses. Contextualized encoding achieved 92% alignment in replicating\noriginal survey responses. In sentiment simulation tasks, agents reached\n81%--86% accuracy against ground truth sentiment, with contextualized profile\nencodings significantly outperforming categorical (p < 0.0001, Cohen\\\'s d =\n0.70). Simulation results remained consistent across repeated trials\n(+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676,\nCohen\\\'s d = 0.02). Our findings establish a scalable framework for sentiment\nmodeling through psychographically grounded AI agents. This work signals a\nparadigm shift in sentiment analysis from retrospective classification to\nprospective and dynamic simulation grounded in psychology of sentiment\nformation.','Melrose Tia, Jezreel Sophia Lanuzo, Lei Rigi Baltazar, Marie Joy Lopez-Relente, Diwa Malaya Quiñones, Jason Albia','2025-05-28','cs.MA','生成模型','http://arxiv.org/pdf/2505.22125v1','该论文提出了一种使用具有心理丰富特征的生成AI代理进行情感模拟的框架，通过模拟真实世界的政治和经济情景生成情感评分，并取得了良好的效果。'),('2505.22126v1','SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model','Recent years have seen rapid advances in AI-driven image generation. Early\ndiffusion models emphasized perceptual quality, while newer multimodal models\nlike GPT-4o-image integrate high-level reasoning, improving semantic\nunderstanding and structural composition. Scientific illustration generation\nexemplifies this evolution: unlike general image synthesis, it demands accurate\ninterpretation of technical content and transformation of abstract ideas into\nclear, standardized visuals. This task is significantly more\nknowledge-intensive and laborious, often requiring hours of manual work and\nspecialized tools. Automating it in a controllable, intelligent manner would\nprovide substantial practical value. Yet, no benchmark currently exists to\nevaluate AI on this front. To fill this gap, we introduce SridBench, the first\nbenchmark for scientific figure generation. It comprises 1,120 instances\ncurated from leading scientific papers across 13 natural and computer science\ndisciplines, collected via human experts and MLLMs. Each sample is evaluated\nalong six dimensions, including semantic fidelity and structural accuracy.\nExperimental results reveal that even top-tier models like GPT-4o-image lag\nbehind human performance, with common issues in text/visual clarity and\nscientific correctness. These findings highlight the need for more advanced\nreasoning-driven visual generation capabilities.','Yifan Chang, Yukang Feng, Jianwen Sun, Jiaxin Ai, Chuanhao Li, S. Kevin Zhou, Kaipeng Zhang','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22126v1','该论文介绍了AI驱动的科学插图生成领域的最新进展，提出了SridBench作为科学图形生成的首个基准测试集。实验结果表明，目前顶尖模型如GPT-4o-image在科学正确性和语义准确性方面仍落后于人类表现，强调了需要更先进的推理驱动视觉生成能力。'),('2505.22128v1','Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach','This work addresses mechanical defocus in Earth observation images from the\nIMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted\nto space-based edge computing constraints. Leveraging Sentinel-2 data, our\nmethod estimates the defocus kernel and trains a restoration model within a GAN\nframework, effectively operating without reference images.\n  On Sentinel-2 images with synthetic degradation, SSIM improved by 72.47% and\nPSNR by 25.00%, confirming the model\\\'s ability to recover lost details when the\noriginal clean image is known. On IMAGIN-e, where no reference images exist,\nperceptual quality metrics indicate a substantial enhancement, with NIQE\nimproving by 60.66% and BRISQUE by 48.38%, validating real-world onboard\nrestoration. The approach is currently deployed aboard the IMAGIN-e mission,\ndemonstrating its practical application in an operational space environment.\n  By efficiently handling high-resolution images under edge computing\nconstraints, the method enables applications such as water body segmentation\nand contour detection while maintaining processing viability despite resource\nlimitations.','Alejandro D. Mousist','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22128v1','该论文提出了一种针对地球观测图像中机械模糊的盲去模糊方法，适用于空间边缘计算约束。通过利用Sentinel-2数据，该方法估计了模糊核并在GAN框架内训练了一个恢复模型，能够在没有参考图像的情况下有效运行。'),('2505.22131v1','EULER: Enhancing the Reasoning Ability of Large Language Models through Error-Induced Learning','Large Language Models (LLMs) have demonstrated strong reasoning capabilities\nand achieved promising results in mathematical problem-solving tasks. Learning\nfrom errors offers the potential to further enhance the performance of LLMs\nduring Supervised Fine-Tuning (SFT). However, the errors in synthesized\nsolutions are typically gathered from sampling trails, making it challenging to\ngenerate solution errors for each mathematical problem. This paper introduces\nthe Error-IndUced LEaRning (EULER) model, which aims to develop an error\nexposure model that generates high-quality solution errors to enhance the\nmathematical reasoning capabilities of LLMs. Specifically, EULER optimizes the\nerror exposure model to increase the generation probability of self-made\nsolution errors while utilizing solutions produced by a superior LLM to\nregularize the generation quality. Our experiments across various mathematical\nproblem datasets demonstrate the effectiveness of the EULER model, achieving an\nimprovement of over 4% compared to all baseline models. Further analysis\nreveals that EULER is capable of synthesizing more challenging and educational\nsolution errors, which facilitate both the training and inference processes of\nLLMs. All codes are available at https://github.com/NEUIR/EULER.','Zhuoyang Wu, Xinze Li, Zhenghao Liu, Yukun Yan, Zhiyuan Liu, Minghe Yu, Cheng Yang, Yu Gu, Ge Yu, Maosong Sun','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22131v1','该论文介绍了一种名为EULER的模型，旨在开发一个错误曝光模型，生成高质量的解决方案错误，以增强LLMs的数学推理能力。通过优化错误曝光模型，EULER在各种数学问题数据集上的实验证明了其有效性，相较于所有基线模型提高了超过4%。进一步分析表明，EULER能够合成更具挑战性和教育性的解决方案错误，有助于LLMs的训练和推理过程。'),('2505.22135v1','RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding','Hybrid models combining Transformers and State Space Models (SSMs) are\npromising for balancing performance and efficiency. However, optimizing these\nhybrid models, particularly by addressing the potential redundancy inherent\nwithin the Transformer components, remains a significant challenge. In this\npaper, we propose RAD (Redundancy-Aware Distillation), a novel framework that\nuses self-speculative decoding as a diagnostic tool to identify redundant\nattention layers within the model. These identified layers are then selectively\nreplaced with SSM components, followed by targeted (self-)distillation.\nSpecifically, RAD focuses knowledge transfer on the components identified as\nredundant, considering architectural changes and specific weight initialization\nstrategies. We experimentally demonstrate that self-distillation using RAD\nsignificantly surpasses the performance of the original base model on\nmathematical and coding tasks. Furthermore, RAD is also effective in standard\nknowledge distillation settings, achieving up to approximately 2x faster\nconvergence compared to baseline methods. Notably, while a baseline model\ndistilled from a Llama-3.1 70B teacher achieves scores of 46.17 on GSM8K and\n22.75 on CRUX, RAD achieves significantly higher scores of 71.27 on GSM8K and\n28.25 on CRUX, even when using a much smaller Llama-3.1 8B teacher. RAD offers\na new pathway for efficient optimization and performance enhancement in the\ndistillation of hybrid models.','Yuichiro Hoshino, Hideyuki Tachibana, Muneyoshi Inahara, Hiroto Takegawa','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22135v1','本文提出了一种名为RAD（Redundancy-Aware Distillation）的新框架，通过自我推测解码作为诊断工具来识别模型中的冗余注意力层，并用SSM组件替换这些冗余层，然后进行有针对性的（自我）蒸馏。实验证明，使用RAD进行自我蒸馏显著超越了原始基础模型在数学和编码任务上的表现，并在标准知识蒸馏设置中取得了快约2倍的收敛速度。'),('2505.22137v1','Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments','Identifying arguments is a necessary prerequisite for various tasks in\nautomated discourse analysis, particularly within contexts such as political\ndebates, online discussions, and scientific reasoning. In addition to\ntheoretical advances in understanding the constitution of arguments, a\nsignificant body of research has emerged around practical argument mining,\nsupported by a growing number of publicly available datasets. On these\nbenchmarks, BERT-like transformers have consistently performed best,\nreinforcing the belief that such models are broadly applicable across diverse\ncontexts of debate. This study offers the first large-scale re-evaluation of\nsuch state-of-the-art models, with a specific focus on their ability to\ngeneralize in identifying arguments. We evaluate four transformers, three\nstandard and one enhanced with contrastive pre-training for better\ngeneralization, on 17 English sentence-level datasets as most relevant to the\ntask. Our findings show that, to varying degrees, these models tend to rely on\nlexical shortcuts tied to content words, suggesting that apparent progress may\noften be driven by dataset-specific cues rather than true task alignment. While\nthe models achieve strong results on familiar benchmarks, their performance\ndrops markedly when applied to unseen datasets. Nonetheless, incorporating both\ntask-specific pre-training and joint benchmark training proves effective in\nenhancing both robustness and generalization.','Marc Feger, Katarina Boland, Stefan Dietze','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22137v1','该论文主要研究自动辩论分析中识别论点的问题，通过对BERT-like transformers在17个英语句子级数据集上的表现进行大规模重新评估，发现这些模型在识别论点时往往依赖于与内容词相关的词汇捷径，表现出在未见数据集上的性能明显下降的特点。'),('2505.22141v1','FaceEditTalker: Interactive Talking Head Generation with Facial Attribute Editing','Recent advances in audio-driven talking head generation have achieved\nimpressive results in lip synchronization and emotional expression. However,\nthey largely overlook the crucial task of facial attribute editing. This\ncapability is crucial for achieving deep personalization and expanding the\nrange of practical applications, including user-tailored digital avatars,\nengaging online education content, and brand-specific digital customer service.\nIn these key domains, the flexible adjustment of visual attributes-such as\nhairstyle, accessories, and subtle facial features is essential for aligning\nwith user preferences, reflecting diverse brand identities, and adapting to\nvarying contextual demands. In this paper, we present FaceEditTalker, a unified\nframework that enables controllable facial attribute manipulation while\ngenerating high-quality, audio-synchronized talking head videos. Our method\nconsists of two key components: an image feature space editing module, which\nextracts semantic and detail features and allows flexible control over\nattributes like expression, hairstyle, and accessories; and an audio-driven\nvideo generation module, which fuses these edited features with audio-guided\nfacial landmarks to drive a diffusion-based generator. This design ensures\ntemporal coherence, visual fidelity, and identity preservation across frames.\nExtensive experiments on public datasets demonstrate that our method\noutperforms state-of-the-art approaches in lip-sync accuracy, video quality,\nand attribute controllability. Project page:\nhttps://peterfanfan.github.io/FaceEditTalker/','Guanwen Feng, Zhiyuan Ma, Yunan Li, Junwei Jing, Jiahao Yang, Qiguang Miao','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22141v1','该论文提出了一个统一框架 FaceEditTalker，实现了在生成高质量、音频同步的说话头视频的同时进行可控的面部属性编辑。通过图像特征空间编辑模块和音频驱动视频生成模块，实现了对表情、发型、配饰等属性的灵活控制，同时保证了时间上的连贯性、视觉保真度和身份保持。'),('2505.22146v1','Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language','Flexible tool selection reflects a complex cognitive ability that\ndistinguishes humans from other species, yet computational models that capture\nthis ability remain underdeveloped. We developed a framework using\nlow-dimensional attribute representations to bridge visual tool perception and\nlinguistic task understanding. We constructed a comprehensive dataset (ToolNet)\ncontaining 115 common tools labeled with 13 carefully designed attributes\nspanning physical, functional, and psychological properties, paired with\nnatural language scenarios describing tool usage. Visual encoders (ResNet or\nViT) extract attributes from tool images while fine-tuned language models\n(GPT-2, LLaMA, DeepSeek) derive required attributes from task descriptions. Our\napproach achieves 74% accuracy in tool selection tasks-significantly\noutperforming direct tool matching (20%) and smaller multimodal models\n(21%-58%), while approaching performance of much larger models like GPT-4o\n(73%) with substantially fewer parameters. Ablation studies revealed that\nmanipulation-related attributes (graspability, hand-relatedness, elongation)\nconsistently prove most critical across modalities. This work provides a\nparameter-efficient, interpretable solution that mimics human-like tool\ncognition, advancing both cognitive science understanding and practical\napplications in tool selection tasks.','Guangfu Hao, Haojie Wen, Liangxuna Guo, Yang Chen, Yanchao Bi, Shan Yu','2025-05-28','cs.CV','自然语言处理','http://arxiv.org/pdf/2505.22146v1','该论文提出了一个使用低维属性表示桥接视觉工具感知和语言任务理解的框架，构建了一个包含115种常见工具的综合数据集，并使用视觉编码器和微调语言模型来实现工具选择任务，取得了74%的准确率，明显优于直接工具匹配和较小的多模态模型，接近于参数更多的模型性能。'),('2505.22147v1','Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions','Decision making is a central problem in AI that can be formalized using a\nMarkov Decision Process. A problem is that, with increasing numbers of\n(indistinguishable) objects, the state space grows exponentially. To compute\npolicies, the state space has to be enumerated. Even more possibilities have to\nbe enumerated if the size of the action space depends on the size of the state\nspace, especially if we allow concurrent actions. To tackle the exponential\nblow-up in the action and state space, we present a first-order representation\nto store the spaces in polynomial instead of exponential size in the number of\nobjects and introduce Foreplan, a relational forward planner, which uses this\nrepresentation to efficiently compute policies for numerous indistinguishable\nobjects and actions. Additionally, we introduce an even faster approximate\nversion of Foreplan. Moreover, Foreplan identifies how many objects an agent\nshould act on to achieve a certain task given restrictions. Further, we provide\na theoretical analysis and an empirical evaluation of Foreplan, demonstrating a\nspeedup of at least four orders of magnitude.','Florian Andreas Marwitz, Tanya Braun, Ralf Möller, Marcel Gehrke','2025-05-28','cs.AI','强化学习','http://arxiv.org/pdf/2505.22147v1','该论文提出了一种处理在人工智能中决策制定中状态空间指数级增长的问题的方法，通过引入一种一阶表示来存储状态空间和动作空间，以多项式而非指数级的方式处理大量无法区分的对象和动作，提出了一种关系向前规划器Foreplan，并介绍了一个更快速的近似版本。论文还提供了理论分析和实证评估，展示了Foreplan至少四个数量级的加速。'),('2505.22148v1','What Makes a Good Reasoning Chain? Uncovering Structural Patterns in Long Chain-of-Thought Reasoning','Recent advances in reasoning with large language models (LLMs) have\npopularized Long Chain-of-Thought (LCoT), a strategy that encourages deliberate\nand step-by-step reasoning before producing a final answer. While LCoTs have\nenabled expert-level performance in complex tasks, how the internal structures\nof their reasoning chains drive, or even predict, the correctness of final\nanswers remains a critical yet underexplored question. In this work, we present\nLCoT2Tree, an automated framework that converts sequential LCoTs into\nhierarchical tree structures and thus enables deeper structural analysis of LLM\nreasoning. Using graph neural networks (GNNs), we reveal that structural\npatterns extracted by LCoT2Tree, including exploration, backtracking, and\nverification, serve as stronger predictors of final performance across a wide\nrange of tasks and models. Leveraging an explainability technique, we further\nidentify critical thought patterns such as over-branching that account for\nfailures. Beyond diagnostic insights, the structural patterns by LCoT2Tree\nsupport practical applications, including improving Best-of-N decoding\neffectiveness. Overall, our results underscore the critical role of internal\nstructures of reasoning chains, positioning LCoT2Tree as a powerful tool for\ndiagnosing, interpreting, and improving reasoning in LLMs.','Gangwei Jiang, Yahui Liu, Zhaoyi Li, Qi Wang, Fuzheng Zhang, Linqi Song, Ying Wei, Defu Lian','2025-05-28','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22148v1','该论文介绍了一种名为LCoT2Tree的自动化框架，将顺序LCoTs转换为分层树结构，从而深入分析LLM推理的内部结构。使用图神经网络（GNNs）揭示了LCoT2Tree提取的结构模式，包括探索、回溯和验证，作为跨多种任务和模型的最终性能更强的预测因素。研究结果强调了推理链的内部结构的关键作用，并将LCoT2Tree定位为诊断、解释和改进LLMs推理的强大工具。'),('2505.22150v1','Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging','Brain-to-Image reconstruction aims to recover visual stimuli perceived by\nhumans from brain activity. However, the reconstructed visual stimuli often\nmissing details and semantic inconsistencies, which may be attributed to\ninsufficient semantic information. To address this issue, we propose an\napproach named Fine-grained Brain-to-Image reconstruction (FgB2I), which\nemploys fine-grained text as bridge to improve image reconstruction. FgB2I\ncomprises three key stages: detail enhancement, decoding fine-grained text\ndescriptions, and text-bridged brain-to-image reconstruction. In the\ndetail-enhancement stage, we leverage large vision-language models to generate\nfine-grained captions for visual stimuli and experimentally validate its\nimportance. We propose three reward metrics (object accuracy, text-image\nsemantic similarity, and image-image semantic similarity) to guide the language\nmodel in decoding fine-grained text descriptions from fMRI signals. The\nfine-grained text descriptions can be integrated into existing reconstruction\nmethods to achieve fine-grained Brain-to-Image reconstruction.','Runze Xia, Shuo Feng, Renzhi Wang, Congchi Yin, Xuyun Wen, Piji Li','2025-05-28','cs.CV','LLM (Language and Vision Models)','http://arxiv.org/pdf/2505.22150v1','该论文提出了一种名为Fine-grained Brain-to-Image reconstruction (FgB2I)的方法，通过细粒度文本作为桥梁来改善图像重建，包括细节增强、解码细粒度文本描述和文本桥接的脑到图像重建三个关键阶段。'),('2505.22151v1','Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in Offline MARL','A key challenge in offline multi-agent reinforcement learning (MARL) is\nachieving effective many-agent multi-step coordination in complex environments.\nIn this work, we propose Oryx, a novel algorithm for offline cooperative MARL\nto directly address this challenge. Oryx adapts the recently proposed\nretention-based architecture Sable and combines it with a sequential form of\nimplicit constraint Q-learning (ICQ), to develop a novel offline\nauto-regressive policy update scheme. This allows Oryx to solve complex\ncoordination challenges while maintaining temporal coherence over lengthy\ntrajectories. We evaluate Oryx across a diverse set of benchmarks from prior\nworks (SMAC, RWARE, and Multi-Agent MuJoCo) covering tasks of both discrete and\ncontinuous control, varying in scale and difficulty. Oryx achieves\nstate-of-the-art performance on more than 80% of the 65 tested datasets,\noutperforming prior offline MARL methods and demonstrating robust\ngeneralisation across domains with many agents and long horizons. Finally, we\nintroduce new datasets to push the limits of many-agent coordination in offline\nMARL, and demonstrate Oryx\\\'s superior ability to scale effectively in such\nsettings. We will make all of our datasets, experimental data, and code\navailable upon publication.','Claude Formanek, Omayma Mahjoub, Louay Ben Nessir, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon Du Toit, Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22151v1','本文提出了一种新颖的算法 Oryx，用于解决离线合作多智能体强化学习中的多智能体多步协调问题。通过结合最近提出的基于保留的架构 Sable 和顺序形式的隐式约束 Q-learning，Oryx 实现了一种新颖的离线自回归策略更新方案，能够在维持长路径上的时间连贯性的同时解决复杂的协调挑战。在多个基准测试中，Oryx 在超过 80% 的测试数据集上取得了最先进的性能，表现优于先前的离线 MARL 方法，并展示了在具有许多智能体和长期视野的领域中的稳健泛化能力。'),('2505.22152v1','Uncertainty Estimation for Heterophilic Graphs Through the Lens of Information Theory','While uncertainty estimation for graphs recently gained traction, most\nmethods rely on homophily and deteriorate in heterophilic settings. We address\nthis by analyzing message passing neural networks from an information-theoretic\nperspective and developing a suitable analog to data processing inequality to\nquantify information throughout the model\\\'s layers. In contrast to non-graph\ndomains, information about the node-level prediction target can increase with\nmodel depth if a node\\\'s features are semantically different from its neighbors.\nTherefore, on heterophilic graphs, the latent embeddings of an MPNN each\nprovide different information about the data distribution - different from\nhomophilic settings. This reveals that considering all node representations\nsimultaneously is a key design principle for epistemic uncertainty estimation\non graphs beyond homophily. We empirically confirm this with a simple post-hoc\ndensity estimator on the joint node embedding space that provides\nstate-of-the-art uncertainty on heterophilic graphs. At the same time, it\nmatches prior work on homophilic graphs without explicitly exploiting homophily\nthrough post-processing.','Dominik Fuchsgruber, Tom Wollschläger, Johannes Bordne, Stephan Günnemann','2025-05-28','cs.LG','图神经网络','http://arxiv.org/pdf/2505.22152v1','该论文通过信息论的角度分析消息传递神经网络，并提出了一种适用于异质图的数据处理不等式的模型。在异质图上，考虑所有节点表示同时是估计认知不确定性的关键设计原则。'),('2505.22156v1','InComeS: Integrating Compression and Selection Mechanisms into LLMs for Efficient Model Editing','Although existing model editing methods perform well in recalling exact edit\nfacts, they often struggle in complex scenarios that require deeper semantic\nunderstanding rather than mere knowledge regurgitation. Leveraging the strong\ncontextual reasoning abilities of large language models (LLMs), in-context\nlearning (ICL) becomes a promising editing method by comprehending edit\ninformation through context encoding. However, this method is constrained by\nthe limited context window of LLMs, leading to degraded performance and\nefficiency as the number of edits increases. To overcome this limitation, we\npropose InComeS, a flexible framework that enhances LLMs\\\' ability to process\nediting contexts through explicit compression and selection mechanisms.\nSpecifically, InComeS compresses each editing context into the key-value (KV)\ncache of a special gist token, enabling efficient handling of multiple edits\nwithout being restricted by the model\\\'s context window. Furthermore,\nspecialized cross-attention modules are added to dynamically select the most\nrelevant information from the gist pools, enabling adaptive and effective\nutilization of edit information. We conduct experiments on diverse model\nediting benchmarks with various editing formats, and the results demonstrate\nthe effectiveness and efficiency of our method.','Shuaiyi Li, Zhisong Zhang, Yang Deng, Chenlong Deng, Tianqing Fang, Hongming Zhang, Haitao Mi, Dong Yu, Wai Lam','2025-05-28','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22156v1','该论文提出了一种名为InComeS的灵活框架，通过显式压缩和选择机制增强LLMs处理编辑上下文的能力，以提高编辑方法的性能和效率。'),('2505.22157v1','Stratified Selective Sampling for Instruction Tuning with Dedicated Scoring Strategy','Recent work shows that post-training datasets for LLMs can be substantially\ndownsampled without noticeably deteriorating performance. However, data\nselection often incurs high computational costs or is limited to narrow\ndomains. In this paper, we demonstrate that data selection can be both --\nefficient and universal -- by using a multi-step pipeline in which we\nefficiently bin data points into groups, estimate quality using specialized\nmodels, and score difficulty with a robust, lightweight method. Task-based\ncategorization allows us to control the composition of our final data --\ncrucial for finetuning multi-purpose models. To guarantee diversity, we improve\nupon previous work using embedding models and a clustering algorithm. This\nintegrated strategy enables high-performance fine-tuning with minimal overhead.','Paramita Mirza, Lucas Weber, Fabian Küch','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22157v1','本文研究了如何通过一个多步骤的流程来高效选择数据，以在微调多用途模型时控制数据的组成，从而实现高性能微调。'),('2505.22158v1','The informativeness of the gradient revisited','In the past decade gradient-based deep learning has revolutionized several\napplications. However, this rapid advancement has highlighted the need for a\ndeeper theoretical understanding of its limitations. Research has shown that,\nin many practical learning tasks, the information contained in the gradient is\nso minimal that gradient-based methods require an exceedingly large number of\niterations to achieve success. The informativeness of the gradient is typically\nmeasured by its variance with respect to the random selection of a target\nfunction from a hypothesis class.\n  We use this framework and give a general bound on the variance in terms of a\nparameter related to the pairwise independence of the target function class and\nthe collision entropy of the input distribution. Our bound scales as $\n\\tilde{\\mathcal{O}}(\\varepsilon+e^{-\\frac{1}{2}\\mathcal{E}_c}) $, where $\n\\tilde{\\mathcal{O}} $ hides factors related to the regularity of the learning\nmodel and the loss function, $ \\varepsilon $ measures the pairwise independence\nof the target function class and $\\mathcal{E}_c$ is the collision entropy of\nthe input distribution.\n  To demonstrate the practical utility of our bound, we apply it to the class\nof Learning with Errors (LWE) mappings and high-frequency functions. In\naddition to the theoretical analysis, we present experiments to understand\nbetter the nature of recent deep learning-based attacks on LWE.','Rustem Takhanov','2025-05-28','cs.LG','深度学习','http://arxiv.org/pdf/2505.22158v1','该论文研究了深度学习中梯度信息的限制问题，提出了一个关于方差的一般性界限，并将其应用于Learning with Errors (LWE)映射和高频函数的类别中，以及对最近基于深度学习的LWE攻击的实验分析。'),('2505.22165v1','Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes','Diffusion models have emerged as a promising approach for text generation,\nwith recent works falling into two main categories: discrete and continuous\ndiffusion models. Discrete diffusion models apply token corruption\nindependently using categorical distributions, allowing for different diffusion\nprogress across tokens but lacking fine-grained control. Continuous diffusion\nmodels map tokens to continuous spaces and apply fine-grained noise, but the\ndiffusion progress is uniform across tokens, limiting their ability to capture\nsemantic nuances. To address these limitations, we propose\n\\textbf{\\underline{N}}on-simultan\\textbf{\\underline{e}}ous\nC\\textbf{\\underline{o}}ntinuous \\textbf{\\underline{Diff}}usion Models\n(NeoDiff), a novel diffusion model that integrates the strengths of both\ndiscrete and continuous approaches. NeoDiff introduces a Poisson diffusion\nprocess for the forward process, enabling a flexible and fine-grained noising\nparadigm, and employs a time predictor for the reverse process to adaptively\nmodulate the denoising progress based on token semantics. Furthermore, NeoDiff\nutilizes an optimized schedule for inference to ensure more precise noise\ncontrol and improved performance. Our approach unifies the theories of discrete\nand continuous diffusion models, offering a more principled and effective\nframework for text generation. Experimental results on several text generation\ntasks demonstrate NeoDiff\\\'s superior performance compared to baselines of\nnon-autoregressive continuous and discrete diffusion models, iterative-based\nmethods and autoregressive diffusion-based methods. These results highlight\nNeoDiff\\\'s potential as a powerful tool for generating high-quality text and\nadvancing the field of diffusion-based text generation.','Bocheng Li, Zhujin Gao, Linli Xu','2025-05-28','cs.CL','生成模型(Text Generation)','http://arxiv.org/pdf/2505.22165v1','该论文提出了一种新型的扩散模型 NeoDiff，结合了离散和连续方法的优势，通过引入泊松扩散过程和时间预测器来改进文本生成的性能。'),('2505.22169v1','ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments','LLMs are highly sensitive to prompt phrasing, yet standard benchmarks\ntypically report performance using a single prompt, raising concerns about the\nreliability of such evaluations. In this work, we argue for a stochastic method\nof moments evaluation over the space of meaning-preserving prompt\nperturbations. We introduce a formal definition of reliable evaluation that\naccounts for prompt sensitivity, and suggest ReliableEval - a method for\nestimating the number of prompt resamplings needed to obtain meaningful\nresults. Using our framework, we stochastically evaluate five frontier LLMs and\nfind that even top-performing models like GPT-4o and Claude-3.7-Sonnet exhibit\nsubstantial prompt sensitivity. Our approach is model-, task-, and\nmetric-agnostic, offering a recipe for meaningful and robust LLM evaluation.','Gili Lior, Eliya Habba, Shahar Levy, Avi Caciularu, Gabriel Stanovsky','2025-05-28','cs.CL','LLM (语言模型)','http://arxiv.org/pdf/2505.22169v1','该论文提出了一种基于随机矩方法的评估框架，用于评估语言模型对提示敏感性的可靠性。他们发现即使是表现最好的模型也存在显著的提示敏感性。'),('2505.22172v1','Reverse Preference Optimization for Complex Instruction Following','Instruction following (IF) is a critical capability for large language models\n(LLMs). However, handling complex instructions with multiple constraints\nremains challenging. Previous methods typically select preference pairs based\non the number of constraints they satisfy, introducing noise where chosen\nexamples may fail to follow some constraints and rejected examples may excel in\ncertain respects over the chosen ones. To address the challenge of aligning\nwith multiple preferences, we propose a simple yet effective method called\nReverse Preference Optimization (RPO). It mitigates noise in preference pairs\nby dynamically reversing the constraints within the instruction to ensure the\nchosen response is perfect, alleviating the burden of extensive sampling and\nfiltering to collect perfect responses. Besides, reversal also enlarges the gap\nbetween chosen and rejected responses, thereby clarifying the optimization\ndirection and making it more robust to noise. We evaluate RPO on two multi-turn\nIF benchmarks, Sysbench and Multi-IF, demonstrating average improvements over\nthe DPO baseline of 4.6 and 2.5 points (on Llama-3.1 8B), respectively.\nMoreover, RPO scales effectively across model sizes (8B to 70B parameters),\nwith the 70B RPO model surpassing GPT-4o.','Xiang Huang, Ting-En Lin, Feiteng Fang, Yuchuan Wu, Hangyu Li, Yuzhong Qu, Fei Huang, Yongbin Li','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22172v1','该论文提出了一种名为Reverse Preference Optimization (RPO)的方法，用于解决大型语言模型在处理具有多个约束的复杂指令时的问题。通过动态地反转指令中的约束条件，确保所选响应完美，减轻了收集完美响应的大量采样和过滤的负担。该方法在两个多轮IF基准测试上进行了评估，相较于DPO基线，分别实现了4.6和2.5个点的平均改进。'),('2505.22176v1','TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation','Evaluating tables qualitatively & quantitatively presents a significant\nchallenge, as traditional metrics often fail to capture nuanced structural and\ncontent discrepancies. To address this, we introduce a novel, methodical rubric\nintegrating multi-level structural descriptors with fine-grained contextual\nquantification, thereby establishing a robust foundation for comprehensive\ntable comparison. Building on this foundation, we propose TabXEval, an\neXhaustive and eXplainable two-phase evaluation framework. TabXEval initially\naligns reference tables structurally via TabAlign & subsequently conducts a\nsystematic semantic and syntactic comparison using TabCompare; this approach\nclarifies the evaluation process and pinpoints subtle discrepancies overlooked\nby conventional methods. The efficacy of this framework is assessed using\nTabXBench, a novel, diverse, multi-domain benchmark we developed, featuring\nrealistic table perturbations and human-annotated assessments. Finally, a\nsystematic analysis of existing evaluation methods through\nsensitivity-specificity trade-offs demonstrates the qualitative and\nquantitative effectiveness of TabXEval across diverse table-related tasks and\ndomains, paving the way for future innovations in explainable table evaluation.','Vihang Pancholi, Jainit Bafna, Tejas Anvekar, Manish Shrivastava, Vivek Gupta','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22176v1','该论文介绍了一种新颖的表格评估方法，结合多级结构描述符和细粒度的上下文量化，建立了一个全面比较表格的坚实基础。他们提出了TabXEval，一个详尽且可解释的两阶段评估框架，通过TabAlign对齐参考表格结构，然后使用TabCompare进行系统的语义和句法比较，从而澄清评估过程，找出传统方法忽视的微妙差异。通过TabXBench评估了该框架的有效性，最终通过对现有评估方法的系统分析，展示了TabXEval在不同表格相关任务和领域中的定性和定量有效性，为未来可解释表格评估的创新铺平了道路。'),('2505.22179v1','Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design','Speculative decoding and quantization effectively accelerate memory-bound\ninference of large language models. Speculative decoding mitigates the memory\nbandwidth bottleneck by verifying multiple tokens within a single forward pass,\nwhich increases computational effort. Quantization achieves this optimization\nby compressing weights and activations into lower bit-widths and also reduces\ncomputations via low-bit matrix multiplications. To further leverage their\nstrengths, we investigate the integration of these two techniques.\nSurprisingly, experiments applying the advanced speculative decoding method\nEAGLE-2 to various quantized models reveal that the memory benefits from 4-bit\nweight quantization are diminished by the computational load from speculative\ndecoding. Specifically, verifying a tree-style draft incurs significantly more\ntime overhead than a single-token forward pass on 4-bit weight quantized\nmodels. This finding led to our new speculative decoding design: a hierarchical\nframework that employs a small model as an intermediate stage to turn\ntree-style drafts into sequence drafts, leveraging the memory access benefits\nof the target quantized model. Experimental results show that our hierarchical\napproach achieves a 2.78$\\times$ speedup across various tasks for the 4-bit\nweight Llama-3-70B model on an A100 GPU, outperforming EAGLE-2 by 1.31$\\times$.\nCode available at https://github.com/AI9Stars/SpecMQuant.','Yudi Zhang, Weilin Zhao, Xu Han, Tiejun Zhao, Wang Xu, Hailong Cao, Conghui Zhu','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22179v1','该论文研究了如何结合推测解码和量化技术来加速大型语言模型的推断过程，发现在应用先进的推测解码方法EAGLE-2到各种量化模型时，4位权重量化的内存优势被推测解码的计算负荷所抵消，提出了一种新的分层推测解码设计，通过引入一个小模型作为中间阶段，将树状草稿转换为序列草稿，从而实现了在A100 GPU上对4位权重Llama-3-70B模型的2.78倍加速。'),('2505.22184v1','Breaking the Cloak! Unveiling Chinese Cloaked Toxicity with Homophone Graph and Toxic Lexicon','Social media platforms have experienced a significant rise in toxic content,\nincluding abusive language and discriminatory remarks, presenting growing\nchallenges for content moderation. Some users evade censorship by deliberately\ndisguising toxic words through homophonic cloak, which necessitates the task of\nunveiling cloaked toxicity. Existing methods are mostly designed for English\ntexts, while Chinese cloaked toxicity unveiling has not been solved yet. To\ntackle the issue, we propose C$^2$TU, a novel training-free and prompt-free\nmethod for Chinese cloaked toxic content unveiling. It first employs substring\nmatching to identify candidate toxic words based on Chinese homo-graph and\ntoxic lexicon. Then it filters those candidates that are non-toxic and corrects\ncloaks to be their corresponding toxicities. Specifically, we develop two model\nvariants for filtering, which are based on BERT and LLMs, respectively. For\nLLMs, we address the auto-regressive limitation in computing word occurrence\nprobability and utilize the full semantic contexts of a text sequence to reveal\ncloaked toxic words. Extensive experiments demonstrate that C$^2$TU can achieve\nsuperior performance on two Chinese toxic datasets. In particular, our method\noutperforms the best competitor by up to 71% on the F1 score and 35% on\naccuracy, respectively.','Xuchen Ma, Jianxiang Yu, Wenming Shao, Bo Pang, Xiang Li','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22184v1','该论文提出了一种针对中文隐形毒性内容的揭示方法C$^2$TU，通过子串匹配识别候选毒性词汇，然后过滤非毒性词汇并纠正掩饰，最终利用BERT和LLMs模型进行过滤，取得了优越的性能表现。'),('2505.22193v1','Physics-inspired Generative AI models via real hardware-based noisy quantum diffusion','Quantum Diffusion Models (QDMs) are an emerging paradigm in Generative AI\nthat aims to use quantum properties to improve the performances of their\nclassical counterparts. However, existing algorithms are not easily scalable\ndue to the limitations of near-term quantum devices. Following our previous\nwork on QDMs, here we propose and implement two physics-inspired protocols. In\nthe first, we use the formalism of quantum stochastic walks, showing that a\nspecific interplay of quantum and classical dynamics in the forward process\nproduces statistically more robust models generating sets of MNIST images with\nlower Fr\\\\\'echet Inception Distance (FID) than using totally classical dynamics.\nIn the second approach, we realize an algorithm to generate images by\nexploiting the intrinsic noise of real IBM quantum hardware with only four\nqubits. Our work could be a starting point to pave the way for new scenarios\nfor large-scale algorithms in quantum Generative AI, where quantum noise is\nneither mitigated nor corrected, but instead exploited as a useful resource.','Marco Parigi, Stefano Martina, Francesco Aldo Venturelli, Filippo Caruso','2025-05-28','quant-ph','生成模型','http://arxiv.org/pdf/2505.22193v1','该论文提出了两种基于物理启发的协议，旨在利用量子性质改进生成AI中的性能，其中一种利用量子随机行走的形式主义产生MNIST图像，另一种利用IBM量子硬件的内在噪声生成图像。'),('2505.22196v1','An Augmentation-Aware Theory for Self-Supervised Contrastive Learning','Self-supervised contrastive learning has emerged as a powerful tool in\nmachine learning and computer vision to learn meaningful representations from\nunlabeled data. Meanwhile, its empirical success has encouraged many\ntheoretical studies to reveal the learning mechanisms. However, in the existing\ntheoretical research, the role of data augmentation is still under-exploited,\nespecially the effects of specific augmentation types. To fill in the blank, we\nfor the first time propose an augmentation-aware error bound for\nself-supervised contrastive learning, showing that the supervised risk is\nbounded not only by the unsupervised risk, but also explicitly by a trade-off\ninduced by data augmentation. Then, under a novel semantic label assumption, we\ndiscuss how certain augmentation methods affect the error bound. Lastly, we\nconduct both pixel- and representation-level experiments to verify our proposed\ntheoretical results.','Jingyi Cui, Hongwei Wen, Yisen Wang','2025-05-28','cs.LG','自监督学习','http://arxiv.org/pdf/2505.22196v1','本文提出了一种对自监督对比学习的数据增强感知误差界，揭示了监督风险不仅受无监督风险限制，还受数据增强引起的权衡影响。通过新颖的语义标签假设，讨论了某些增强方法如何影响误差界。最后，通过像素级和表示级实验验证了理论结果。'),('2505.22199v1','Enhancing Uncertainty Estimation and Interpretability via Bayesian Non-negative Decision Layer','Although deep neural networks have demonstrated significant success due to\ntheir powerful expressiveness, most models struggle to meet practical\nrequirements for uncertainty estimation. Concurrently, the entangled nature of\ndeep neural networks leads to a multifaceted problem, where various localized\nexplanation techniques reveal that multiple unrelated features influence the\ndecisions, thereby undermining interpretability. To address these challenges,\nwe develop a Bayesian Non-negative Decision Layer (BNDL), which reformulates\ndeep neural networks as a conditional Bayesian non-negative factor analysis. By\nleveraging stochastic latent variables, the BNDL can model complex dependencies\nand provide robust uncertainty estimation. Moreover, the sparsity and\nnon-negativity of the latent variables encourage the model to learn\ndisentangled representations and decision layers, thereby improving\ninterpretability. We also offer theoretical guarantees that BNDL can achieve\neffective disentangled learning. In addition, we developed a corresponding\nvariational inference method utilizing a Weibull variational inference network\nto approximate the posterior distribution of the latent variables. Our\nexperimental results demonstrate that with enhanced disentanglement\ncapabilities, BNDL not only improves the model\\\'s accuracy but also provides\nreliable uncertainty estimation and improved interpretability.','Xinyue Hu, Zhibin Duan, Bo Chen, Mingyuan Zhou','2025-05-28','cs.LG','不确定性估计/解释性增强/贝叶斯方法','http://arxiv.org/pdf/2505.22199v1','该论文提出了一种名为Bayesian Non-negative Decision Layer (BNDL) 的方法，通过将深度神经网络重新构建为条件贝叶斯非负因子分析，利用随机潜变量来建模复杂依赖关系，提供稳健的不确定性估计，并通过稀疏性和非负性的潜变量鼓励模型学习解耦表示和决策层，从而提高可解释性。实验结果表明，BNDL不仅提高了模型的准确性，还提供可靠的不确定性估计和改进的可解释性。'),('2505.22200v1','Investigating Mechanisms for In-Context Vision Language Binding','To understand a prompt, Vision-Language models (VLMs) must perceive the\nimage, comprehend the text, and build associations within and across both\nmodalities. For instance, given an \\\'image of a red toy car\\\', the model should\nassociate this image to phrases like \\\'car\\\', \\\'red toy\\\', \\\'red object\\\', etc. Feng\nand Steinhardt propose the Binding ID mechanism in LLMs, suggesting that the\nentity and its corresponding attribute tokens share a Binding ID in the model\nactivations. We investigate this for image-text binding in VLMs using a\nsynthetic dataset and task that requires models to associate 3D objects in an\nimage with their descriptions in the text. Our experiments demonstrate that\nVLMs assign a distinct Binding ID to an object\\\'s image tokens and its textual\nreferences, enabling in-context association.','Darshana Saravanan, Makarand Tapaswi, Vineet Gandhi','2025-05-28','cs.CV','视觉-语言模型','http://arxiv.org/pdf/2505.22200v1','本文研究了视觉-语言模型中的图像-文本绑定问题，提出了Binding ID机制，并通过合成数据集和任务进行实验，结果表明VLMs为对象的图像标记和文本引用分配了不同的Binding ID，从而实现了上下文关联。'),('2505.22202v1','Let\\\'s Predict Sentence by Sentence','Autoregressive language models (LMs) generate one token at a time, yet human\nreasoning operates over higher-level abstractions - sentences, propositions,\nand concepts. This contrast raises a central question- Can LMs likewise learn\nto reason over structured semantic units rather than raw token sequences? In\nthis work, we investigate whether pretrained LMs can be lifted into such\nabstract reasoning spaces by building on their learned representations. We\npresent a framework that adapts a pretrained token-level LM to operate in\nsentence space by autoregressively predicting continuous embeddings of next\nsentences. We explore two embedding paradigms inspired by classical\nrepresentation learning: 1) semantic embeddings, learned via autoencoding to\npreserve surface meaning; and 2) contextual embeddings, trained via\nnext-sentence prediction to encode anticipatory structure. We evaluate both\nunder two inference regimes: Discretized, which decodes each predicted\nembedding into text before re-encoding; and Continuous, which reasons entirely\nin embedding space for improved efficiency. Across four domains - mathematics,\nlogic, commonsense, and planning - contextual embeddings under continuous\ninference show competitive performance with Chain-of-Thought (CoT) while\nreducing inference-time FLOPs on average by half. We also present early signs\nof scalability and modular adaptation. Finally, to visualize latent\ntrajectories, we introduce SentenceLens, a diagnostic tool that decodes\nintermediate model states into interpretable sentences. Together, our results\nindicate that pretrained LMs can effectively transition to abstract, structured\nreasoning within latent embedding spaces.','Hyeonbin Hwang, Byeongguk Jeon, Seungone Kim, Jiyeon Kim, Hoyeon Chang, Sohee Yang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo','2025-05-28','cs.CL','LLM (语言模型)','http://arxiv.org/pdf/2505.22202v1','该论文探讨了如何将预训练的语言模型提升到抽象推理空间，通过在句子空间中自回归地预测连续嵌入来实现。研究结果表明，在连续推理下，上下文嵌入在数学、逻辑、常识和规划领域表现出竞争力，同时减少了推理时间的FLOPs。'),('2505.22203v1','Pitfalls of Rule- and Model-based Verifiers -- A Case Study on Mathematical Reasoning','Trustworthy verifiers are essential for the success of reinforcement learning\nwith verifiable reward (RLVR), which is the core methodology behind various\nlarge reasoning models such as DeepSeek-R1. In complex domains like\nmathematical reasoning, rule-based verifiers have been widely adopted in\nprevious works to train strong reasoning models. However, the reliability of\nthese verifiers and their impact on the RL training process remain poorly\nunderstood. In this work, we take mathematical reasoning as a case study and\nconduct a comprehensive analysis of various verifiers in both static evaluation\nand RL training scenarios. First, we find that current open-source rule-based\nverifiers often fail to recognize equivalent answers presented in different\nformats across multiple commonly used mathematical datasets, resulting in\nnon-negligible false negative rates. This limitation adversely affects RL\ntraining performance and becomes more pronounced as the policy model gets\nstronger. Subsequently, we investigate model-based verifiers as a potential\nsolution to address these limitations. While the static evaluation shows that\nmodel-based verifiers achieve significantly higher verification accuracy,\nfurther analysis and RL training results imply that they are highly susceptible\nto hacking, where they misclassify certain patterns in responses as correct\n(i.e., false positives). This vulnerability is exploited during policy model\noptimization, leading to artificially inflated rewards. Our findings underscore\nthe unique risks inherent to both rule-based and model-based verifiers, aiming\nto offer valuable insights to develop more robust reward systems in\nreinforcement learning.','Yuzhen Huang, Weihao Zeng, Xingshan Zeng, Qi Zhu, Junxian He','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22203v1','本文研究了在强化学习中具有可验证奖励的可靠验证器的重要性，以及在数学推理等复杂领域中规则验证器的可靠性和对RL训练过程的影响。作者发现当前开源的基于规则的验证器在识别不同格式的等价答案时存在较高的假阴性率，而基于模型的验证器虽然在静态评估中表现更好，但在RL训练中容易受到攻击。'),('2505.22208v1','LaMM: Semi-Supervised Pre-Training of Large-Scale Materials Models','Neural network potentials (NNPs) are crucial for accelerating computational\nmaterials science by surrogating density functional theory (DFT) calculations.\nImproving their accuracy is possible through pre-training and fine-tuning,\nwhere an NNP model is first pre-trained on a large-scale dataset and then\nfine-tuned on a smaller target dataset. However, this approach is\ncomputationally expensive, mainly due to the cost of DFT-based dataset labeling\nand load imbalances during large-scale pre-training. To address this, we\npropose LaMM, a semi-supervised pre-training method incorporating improved\ndenoising self-supervised learning and a load-balancing algorithm for efficient\nmulti-node training. We demonstrate that our approach effectively leverages a\nlarge-scale dataset of $\\sim$300 million semi-labeled samples to train a single\nNNP model, resulting in improved fine-tuning performance in terms of both speed\nand accuracy.','Yosuke Oyama, Yusuke Majima, Eiji Ohta, Yasufumi Sakai','2025-05-28','cs.LG','LLM (神经网络势模型)','http://arxiv.org/pdf/2505.22208v1','该论文提出了一种名为LaMM的半监督预训练方法，结合改进的去噪自监督学习和负载平衡算法，用于高效的多节点训练神经网络势模型。通过有效利用大规模数据集进行训练，LaMM方法在速度和准确性方面均提升了微调性能。'),('2505.22222v1','Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation','Recent advancements in multimodal Large Language Models (LLMs) have\nsignificantly enhanced the automation of medical image analysis, particularly\nin generating radiology reports from chest X-rays (CXR). However, these models\nstill suffer from hallucinations and clinically significant errors, limiting\ntheir reliability in real-world applications. In this study, we propose Look &\nMark (L&M), a novel grounding fixation strategy that integrates radiologist eye\nfixations (Look) and bounding box annotations (Mark) into the LLM prompting\nframework. Unlike conventional fine-tuning, L&M leverages in-context learning\nto achieve substantial performance gains without retraining. When evaluated\nacross multiple domain-specific and general-purpose models, L&M demonstrates\nsignificant gains, including a 1.2% improvement in overall metrics (A.AVG) for\nCXR-LLaVA compared to baseline prompting and a remarkable 9.2% boost for\nLLaVA-Med. General-purpose models also benefit from L&M combined with\nin-context learning, with LLaVA-OV achieving an 87.3% clinical average\nperformance (C.AVG)-the highest among all models, even surpassing those\nexplicitly trained for CXR report generation. Expert evaluations further\nconfirm that L&M reduces clinically significant errors (by 0.43 average errors\nper report), such as false predictions and omissions, enhancing both accuracy\nand reliability. These findings highlight L&M\\\'s potential as a scalable and\nefficient solution for AI-assisted radiology, paving the way for improved\ndiagnostic workflows in low-resource clinical settings.','Yunsoo Kim, Jinge Wu, Su-Hwan Kim, Pardeep Vasudev, Jiashu Shen, Honghan Wu','2025-05-28','cs.CV','LLM、医学图像分析','http://arxiv.org/pdf/2505.22222v1','本研究提出了一种名为Look & Mark (L&M)的新型基于眼动和边界框注释的定位策略，将其整合到LLM提示框架中，通过上下文学习实现显著的性能提升，减少临床显著错误，提高准确性和可靠性，为AI辅助放射学提供了可扩展和高效的解决方案。'),('2505.22224v1','Solver-Free Decision-Focused Learning for Linear Optimization Problems','Mathematical optimization is a fundamental tool for decision-making in a wide\nrange of applications. However, in many real-world scenarios, the parameters of\nthe optimization problem are not known a priori and must be predicted from\ncontextual features. This gives rise to predict-then-optimize problems, where a\nmachine learning model predicts problem parameters that are then used to make\ndecisions via optimization. A growing body of work on decision-focused learning\n(DFL) addresses this setting by training models specifically to produce\npredictions that maximize downstream decision quality, rather than accuracy.\nWhile effective, DFL is computationally expensive, because it requires solving\nthe optimization problem with the predicted parameters at each loss evaluation.\nIn this work, we address this computational bottleneck for linear optimization\nproblems, a common class of problems in both DFL literature and real-world\napplications. We propose a solver-free training method that exploits the\ngeometric structure of linear optimization to enable efficient training with\nminimal degradation in solution quality. Our method is based on the insight\nthat a solution is optimal if and only if it achieves an objective value that\nis at least as good as that of its adjacent vertices on the feasible polytope.\nBuilding on this, our method compares the estimated quality of the ground-truth\noptimal solution with that of its precomputed adjacent vertices, and uses this\nas loss function. Experiments demonstrate that our method significantly reduces\ncomputational cost while maintaining high decision quality.','Senne Berden, Ali İrfan Mahmutoğulları, Dimos Tsouros, Tias Guns','2025-05-28','cs.LG','决策优化','http://arxiv.org/pdf/2505.22224v1','该论文研究了预测-优化问题中的线性优化问题，提出了一种无解算法的训练方法，通过利用线性优化的几何结构，在保持高决策质量的同时显著降低计算成本。'),('2505.22231v1','Advancing Hearing Assessment: An ASR-Based Frequency-Specific Speech Test for Diagnosing Presbycusis','Traditional audiometry often fails to fully characterize the functional\nimpact of hearing loss on speech understanding, particularly supra-threshold\ndeficits and frequency-specific perception challenges in conditions like\npresbycusis. This paper presents the development and simulated evaluation of a\nnovel Automatic Speech Recognition (ASR)-based frequency-specific speech test\ndesigned to provide granular diagnostic insights. Our approach leverages ASR to\nsimulate the perceptual effects of moderate sloping hearing loss by processing\nspeech stimuli under controlled acoustic degradation and subsequently analyzing\nphoneme-level confusion patterns. Key findings indicate that simulated hearing\nloss introduces specific phoneme confusions, predominantly affecting\nhigh-frequency consonants (e.g., alveolar/palatal to labiodental substitutions)\nand leading to significant phoneme deletions, consistent with the acoustic cues\ndegraded in presbycusis. A test battery curated from these ASR-derived\nconfusions demonstrated diagnostic value, effectively differentiating between\nsimulated normal-hearing and hearing-impaired listeners in a comprehensive\nsimulation. This ASR-driven methodology offers a promising avenue for\ndeveloping objective, granular, and frequency-specific hearing assessment tools\nthat complement traditional audiometry. Future work will focus on validating\nthese findings with human participants and exploring the integration of\nadvanced AI models for enhanced diagnostic precision.','Stefan Bleeck','2025-05-28','cs.SD','自然语言处理','http://arxiv.org/pdf/2505.22231v1','该论文介绍了一种基于自动语音识别（ASR）的频率特定语音测试方法，旨在提供细致的诊断见解。研究结果表明，模拟听力损失导致特定音素混淆，主要影响高频辅音，并导致显著的音素删除，与老年性耳聋中受损的声学线索一致。'),('2505.22232v1','Judging Quality Across Languages: A Multilingual Approach to Pretraining Data Filtering with Language Models','High-quality multilingual training data is essential for effectively\npretraining large language models (LLMs). Yet, the availability of suitable\nopen-source multilingual datasets remains limited. Existing state-of-the-art\ndatasets mostly rely on heuristic filtering methods, restricting both their\ncross-lingual transferability and scalability. Here, we introduce JQL, a\nsystematic approach that efficiently curates diverse and high-quality\nmultilingual data at scale while significantly reducing computational demands.\nJQL distills LLMs\\\' annotation capabilities into lightweight annotators based on\npretrained multilingual embeddings. These models exhibit robust multilingual\nand cross-lingual performance, even for languages and scripts unseen during\ntraining. Evaluated empirically across 35 languages, the resulting annotation\npipeline substantially outperforms current heuristic filtering methods like\nFineweb2. JQL notably enhances downstream model training quality and increases\ndata retention rates. Our research provides practical insights and valuable\nresources for multilingual data curation, raising the standards of multilingual\ndataset development.','Mehdi Ali, Manuel Brack, Max Lübbering, Elias Wendt, Abbas Goher Khan, Richard Rutmann, Alex Jude, Maurice Kraus, Alexander Arno Weber, Felix Stollenwerk, David Kaczér, Florian Mai, Lucie Flek, Rafet Sifa, Nicolas Flores-Herr, Joachim Köhler, Patrick Schramowski, Michael Fromm, Kristian Kersting','2025-05-28','cs.CL','LLM（大型语言模型）, 多语言处理','http://arxiv.org/pdf/2505.22232v1','该论文介绍了一种名为JQL的系统方法，通过基于预训练的多语言嵌入将LLMs的注释能力提炼为轻量级注释器，有效地筛选出多样化和高质量的多语言数据，提高了跨语言迁移性和可扩展性。该方法在35种语言上经过实证评估，显著优于当前的启发式过滤方法。'),('2505.22236v1','A Linguistically Motivated Analysis of Intonational Phrasing in Text-to-Speech Systems: Revealing Gaps in Syntactic Sensitivity','We analyze the syntactic sensitivity of Text-to-Speech (TTS) systems using\nmethods inspired by psycholinguistic research. Specifically, we focus on the\ngeneration of intonational phrase boundaries, which can often be predicted by\nidentifying syntactic boundaries within a sentence. We find that TTS systems\nstruggle to accurately generate intonational phrase boundaries in sentences\nwhere syntactic boundaries are ambiguous (e.g., garden path sentences or\nsentences with attachment ambiguity). In these cases, systems need superficial\ncues such as commas to place boundaries at the correct positions. In contrast,\nfor sentences with simpler syntactic structures, we find that systems do\nincorporate syntactic cues beyond surface markers. Finally, we finetune models\non sentences without commas at the syntactic boundary positions, encouraging\nthem to focus on more subtle linguistic cues. Our findings indicate that this\nleads to more distinct intonation patterns that better reflect the underlying\nstructure.','Charlotte Pouw, Afra Alishahi, Willem Zuidema','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22236v1','本文分析了文本转语音系统对句法敏感性，通过受心理语言学研究启发的方法。研究发现，TTS系统在句法边界模糊的句子中生成语调短语边界时存在困难，需要表面线索如逗号来正确放置边界。然而，在句法结构更简单的句子中，系统会融合句法线索。'),('2505.22238v1','Yambda-5B -- A Large-Scale Multi-modal Dataset for Ranking And Retrieval','We present Yambda-5B, a large-scale open dataset sourced from the\nYandex.Music streaming platform. Yambda-5B contains 4.79 billion user-item\ninteractions from 1 million users across 9.39 million tracks. The dataset\nincludes two primary types of interactions: implicit feedback (listening\nevents) and explicit feedback (likes, dislikes, unlikes and undislikes). In\naddition, we provide audio embeddings for most tracks, generated by a\nconvolutional neural network trained on audio spectrograms. A key\ndistinguishing feature of Yambda-5B is the inclusion of the is_organic flag,\nwhich separates organic user actions from recommendation-driven events. This\ndistinction is critical for developing and evaluating machine learning\nalgorithms, as Yandex.Music relies on recommender systems to personalize track\nselection for users. To support rigorous benchmarking, we introduce an\nevaluation protocol based on a Global Temporal Split, allowing recommendation\nalgorithms to be assessed in conditions that closely mirror real-world use. We\nreport benchmark results for standard baselines (ItemKNN, iALS) and advanced\nmodels (SANSA, SASRec) using a variety of evaluation metrics. By releasing\nYambda-5B to the community, we aim to provide a readily accessible,\nindustrial-scale resource to advance research, foster innovation, and promote\nreproducible results in recommender systems.','A. Ploshkin, V. Tytskiy, A. Pismenny, V. Baikalov, E. Taychinov, A. Permiakov, D. Burlakov, E. Krofto, N. Savushkin','2025-05-28','cs.IR','推荐系统','http://arxiv.org/pdf/2505.22238v1','该论文介绍了一个大规模的开放数据集Yambda-5B，包含来自Yandex.Music流媒体平台的47.9亿用户-项目交互数据，涉及100万用户和939万首歌曲。数据集包括隐式反馈（听歌事件）和显式反馈（喜欢、不喜欢、取消喜欢和取消不喜欢）。此外，他们提供了大部分歌曲的音频嵌入，这些嵌入是通过在音频频谱图上训练的卷积神经网络生成的。Yambda-5B的一个关键特点是包含了is_organic标志，将有机用户行为与推荐驱动事件区分开来，这对于开发和评估机器学习算法至关重要。他们引入了基于全局时间分割的评估协议，以支持严格的基准测试，并报告了使用各种评估指标对标准基线（ItemKNN、iALS）和高级模型（SANSA、SASRec）的基准结果。通过向社区发布Yambda-5B，他们旨在提供一个易于访问的工业规模资源，推动研究进展，促进创新，并促进推荐系统中可复制的结果。'),('2505.22240v1','BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain','Biomedical reasoning often requires traversing interconnected relationships\nacross entities such as drugs, diseases, and proteins. Despite the increasing\nprominence of large language models (LLMs), existing benchmarks lack the\nability to evaluate multi-hop reasoning in the biomedical domain, particularly\nfor queries involving one-to-many and many-to-many relationships. This gap\nleaves the critical challenges of biomedical multi-hop reasoning underexplored.\nTo address this, we introduce BioHopR, a novel benchmark designed to evaluate\nmulti-hop, multi-answer reasoning in structured biomedical knowledge graphs.\nBuilt from the comprehensive PrimeKG, BioHopR includes 1-hop and 2-hop\nreasoning tasks that reflect real-world biomedical complexities.\n  Evaluations of state-of-the-art models reveal that O3-mini, a proprietary\nreasoning-focused model, achieves 37.93% precision on 1-hop tasks and 14.57% on\n2-hop tasks, outperforming proprietary models such as GPT4O and open-source\nbiomedical models including HuatuoGPT-o1-70B and Llama-3.3-70B. However, all\nmodels exhibit significant declines in multi-hop performance, underscoring the\nchallenges of resolving implicit reasoning steps in the biomedical domain. By\naddressing the lack of benchmarks for multi-hop reasoning in biomedical domain,\nBioHopR sets a new standard for evaluating reasoning capabilities and\nhighlights critical gaps between proprietary and open-source models while\npaving the way for future advancements in biomedical LLMs.','Yunsoo Kim, Yusuf Abdulle, Honghan Wu','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22240v1','该论文介绍了一个新的基准测试BioHopR，用于评估结构化生物医学知识图中的多跳、多答案推理。通过评估最先进的模型，发现在多跳任务中存在挑战，尤其是在解决生物医学领域的隐式推理步骤方面。'),('2505.22251v1','Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition','Recent work suggests that large language models (LLMs) can improve\nperformance of speech tasks compared to existing systems. To support their\nclaims, results on LibriSpeech and Common Voice are often quoted. However, this\nwork finds that a substantial amount of the LibriSpeech and Common Voice\nevaluation sets appear in public LLM pretraining corpora. This calls into\nquestion the reliability of findings drawn from these two datasets. To measure\nthe impact of contamination, LLMs trained with or without contamination are\ncompared, showing that a contaminated LLM is more likely to generate test\nsentences it has seen during training. Speech recognisers using contaminated\nLLMs shows only subtle differences in error rates, but assigns significantly\nhigher probabilities to transcriptions seen during training. Results show that\nLLM outputs can be biased by tiny amounts of data contamination, highlighting\nthe importance of evaluating LLM-based speech systems with held-out data.','Yuan Tseng, Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya','2025-05-28','eess.AS','语音处理','http://arxiv.org/pdf/2505.22251v1','该论文研究发现大型语言模型（LLMs）在语音任务中的表现优于现有系统，但LibriSpeech和Common Voice数据集中存在大量公开LLM预训练语料库的情况，这可能影响研究结果的可靠性。通过比较使用或不使用受污染的LLMs训练的结果，发现受污染的LLM更有可能生成在训练中见过的测试句子。受污染的LLMs在语音识别中表现出细微的误差率差异，但对训练中见过的转录分配了显着更高的概率。研究结果表明，LLM输出可能受到微小数据污染的影响，强调了使用留存数据评估基于LLM的语音系统的重要性。'),('2505.22252v1','B-XAIC Dataset: Benchmarking Explainable AI for Graph Neural Networks Using Chemical Data','Understanding the reasoning behind deep learning model predictions is crucial\nin cheminformatics and drug discovery, where molecular design determines their\nproperties. However, current evaluation frameworks for Explainable AI (XAI) in\nthis domain often rely on artificial datasets or simplified tasks, employing\ndata-derived metrics that fail to capture the complexity of real-world\nscenarios and lack a direct link to explanation faithfulness. To address this,\nwe introduce B-XAIC, a novel benchmark constructed from real-world molecular\ndata and diverse tasks with known ground-truth rationales for assigned labels.\nThrough a comprehensive evaluation using B-XAIC, we reveal limitations of\nexisting XAI methods for Graph Neural Networks (GNNs) in the molecular domain.\nThis benchmark provides a valuable resource for gaining deeper insights into\nthe faithfulness of XAI, facilitating the development of more reliable and\ninterpretable models.','Magdalena Proszewska, Tomasz Danel, Dawid Rymarczyk','2025-05-28','cs.LG','分子设计领域/图神经网络','http://arxiv.org/pdf/2505.22252v1','该论文介绍了一个新的基准测试集 B-XAIC，用于评估可解释人工智能在分子设计领域的效果。通过对 B-XAIC 的全面评估，揭示了现有 XAI 方法在分子领域中的局限性。'),('2505.22255v1','Train Sparse Autoencoders Efficiently by Utilizing Features Correlation','Sparse Autoencoders (SAEs) have demonstrated significant promise in\ninterpreting the hidden states of language models by decomposing them into\ninterpretable latent directions. However, training SAEs at scale remains\nchallenging, especially when large dictionary sizes are used. While decoders\ncan leverage sparse-aware kernels for efficiency, encoders still require\ncomputationally intensive linear operations with large output dimensions. To\naddress this, we propose KronSAE, a novel architecture that factorizes the\nlatent representation via Kronecker product decomposition, drastically reducing\nmemory and computational overhead. Furthermore, we introduce mAND, a\ndifferentiable activation function approximating the binary AND operation,\nwhich improves interpretability and performance in our factorized framework.','Vadim Kurochkin, Yaroslav Aksenov, Daniil Laptev, Daniil Gavrilov, Nikita Balagansky','2025-05-28','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.22255v1','该论文提出了一种新的架构KronSAE，通过Kronecker乘积分解来降低稀疏自编码器（SAEs）的内存和计算开销，以解决在大规模训练时的挑战。同时引入了mAND，一个可微分的激活函数来近似二进制AND操作，提高了在因子化框架中的可解释性和性能。'),('2505.22257v1','Revisiting Group Relative Policy Optimization: Insights into On-Policy and Off-Policy Training','We revisit Group Relative Policy Optimization (GRPO) in both on-policy and\noff-policy optimization regimes. Our motivation comes from recent work on\noff-policy Proximal Policy Optimization (PPO), which improves training\nstability, sampling efficiency, and memory usage. In addition, a recent\nanalysis of GRPO suggests that estimating the advantage function with\noff-policy samples could be beneficial. Building on these observations, we\nadapt GRPO to the off-policy setting. We show that both on-policy and\noff-policy GRPO objectives yield an improvement in the reward. This result\nmotivates the use of clipped surrogate objectives in the off-policy version of\nGRPO. We then compare the empirical performance of reinforcement learning with\nverifiable rewards in post-training using both GRPO variants. Our results show\nthat off-policy GRPO either significantly outperforms or performs on par with\nits on-policy counterpart.','Youssef Mroueh, Nicolas Dupuis, Brian Belgodere, Apoorva Nitsure, Mattia Rigotti, Kristjan Greenewald, Jiri Navratil, Jerret Ross, Jesus Rios','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22257v1','本文重新审视了Group Relative Policy Optimization (GRPO) 在on-policy和off-policy优化模式下的应用。通过将GRPO适应到off-policy设置中，研究表明off-policy GRPO在奖励方面要么明显优于on-policy版本，要么表现相当。'),('2505.22258v1','LiDAR Based Semantic Perception for Forklifts in Outdoor Environments','In this study, we present a novel LiDAR-based semantic segmentation framework\ntailored for autonomous forklifts operating in complex outdoor environments.\nCentral to our approach is the integration of a dual LiDAR system, which\ncombines forward-facing and downward-angled LiDAR sensors to enable\ncomprehensive scene understanding, specifically tailored for industrial\nmaterial handling tasks. The dual configuration improves the detection and\nsegmentation of dynamic and static obstacles with high spatial precision. Using\nhigh-resolution 3D point clouds captured from two sensors, our method employs a\nlightweight yet robust approach that segments the point clouds into\nsafety-critical instance classes such as pedestrians, vehicles, and forklifts,\nas well as environmental classes such as driveable ground, lanes, and\nbuildings. Experimental validation demonstrates that our approach achieves high\nsegmentation accuracy while satisfying strict runtime requirements,\nestablishing its viability for safety-aware, fully autonomous forklift\nnavigation in dynamic warehouse and yard environments.','Benjamin Serfling, Hannes Reichert, Lorenzo Bayerlein, Konrad Doll, Kati Radkhah-Lens','2025-05-28','cs.RO','自然语言处理','http://arxiv.org/pdf/2505.22258v1','该论文介绍了一种针对复杂室外环境中自动叉车的 LiDAR 基础语义分割框架，通过整合前置和向下倾斜 LiDAR 传感器实现全面场景理解，提高了动态和静态障碍物的检测和分割精度。方法在高分辨率 3D 点云数据上实现了安全关键实例类别和环境类别的分割，通过实验证明了其在动态仓库和场地环境中实现高分割精度的可行性。'),('2505.22264v1','MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps','In this paper we expose our approach to solve the \\textit{SemEval 2025 Task\n8: Question-Answering over Tabular Data} challenge. Our strategy leverages\nPython code generation with LLMs to interact with the table and get the answer\nto the questions. The process is composed of multiple steps: understanding the\ncontent of the table, generating natural language instructions in the form of\nsteps to follow in order to get the answer, translating these instructions to\ncode, running it and handling potential errors or exceptions. These steps use\nopen source LLMs and fine grained optimized prompts for each task (step). With\nthis approach, we achieved a score of $70.50\\%$ for subtask 1.','Maximiliano Hormazábal Lagos, Álvaro Bueno Saez, Héctor Cerezo-Costas, Pedro Alonso Doval, Jorge Alcalde Vesteiro','2025-05-28','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.22264v1','本文介绍了他们解决SemEval 2025任务8的方法，使用LLMs生成Python代码与表格交互并回答问题。方法包括理解表格内容、生成自然语言指令、将指令翻译为代码、运行代码并处理潜在错误。他们在子任务1中取得了70.50%的得分。'),('2505.22271v1','Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models','While (multimodal) large language models (LLMs) have attracted widespread\nattention due to their exceptional capabilities, they remain vulnerable to\njailbreak attacks. Various defense methods are proposed to defend against\njailbreak attacks, however, they are often tailored to specific types of\njailbreak attacks, limiting their effectiveness against diverse adversarial\nstrategies. For instance, rephrasing-based defenses are effective against text\nadversarial jailbreaks but fail to counteract image-based attacks. To overcome\nthese limitations, we propose a universal defense framework, termed Test-time\nIMmunization (TIM), which can adaptively defend against various jailbreak\nattacks in a self-evolving way. Specifically, TIM initially trains a gist token\nfor efficient detection, which it subsequently applies to detect jailbreak\nactivities during inference. When jailbreak attempts are identified, TIM\nimplements safety fine-tuning using the detected jailbreak instructions paired\nwith refusal answers. Furthermore, to mitigate potential performance\ndegradation in the detector caused by parameter updates during safety\nfine-tuning, we decouple the fine-tuning process from the detection module.\nExtensive experiments on both LLMs and multimodal LLMs demonstrate the efficacy\nof TIM.','Yongcan Yu, Yanbo Wang, Ran He, Jian Liang','2025-05-28','cs.CR','LLM (Large Language Models) / 自然语言处理 (NLP)','http://arxiv.org/pdf/2505.22271v1','该论文提出了一种名为Test-time IMmunization (TIM)的通用防御框架，可以自适应地防御各种破解攻击，包括文本和图像攻击。TIM首先训练一个简要标记来进行有效检测，然后在推理过程中应用该标记来检测破解活动。当检测到破解尝试时，TIM使用检测到的破解指令和拒绝答案进行安全微调。'),('2505.22273v1','Comprehensive Evaluation on Lexical Normalization: Boundary-Aware Approaches for Unsegmented Languages','Lexical normalization research has sought to tackle the challenge of\nprocessing informal expressions in user-generated text, yet the absence of\ncomprehensive evaluations leaves it unclear which methods excel across multiple\nperspectives. Focusing on unsegmented languages, we make three key\ncontributions: (1) creating a large-scale, multi-domain Japanese normalization\ndataset, (2) developing normalization methods based on state-of-the-art\npretrained models, and (3) conducting experiments across multiple evaluation\nperspectives. Our experiments show that both encoder-only and decoder-only\napproaches achieve promising results in both accuracy and efficiency.','Shohei Higashiyama, Masao Utiyama','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22273v1','该论文研究了词汇规范化在处理用户生成文本中非正式表达时的挑战，通过创建一个大规模、多领域的日语规范化数据集，并基于最先进的预训练模型开发规范化方法，进行了多方面的评估实验。实验结果显示，编码器和解码器方法在准确性和效率方面都取得了令人满意的结果。'),('2505.22280v1','Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review','Evidence-based medicine (EBM) is at the forefront of modern healthcare,\nemphasizing the use of the best available scientific evidence to guide clinical\ndecisions. Due to the sheer volume and rapid growth of medical literature and\nthe high cost of curation, there is a critical need to investigate Natural\nLanguage Processing (NLP) methods to identify, appraise, synthesize, summarize,\nand disseminate evidence in EBM. This survey presents an in-depth review of 129\nresearch studies on leveraging NLP for EBM, illustrating its pivotal role in\nenhancing clinical decision-making processes. The paper systematically explores\nhow NLP supports the five fundamental steps of EBM -- Ask, Acquire, Appraise,\nApply, and Assess. The review not only identifies current limitations within\nthe field but also proposes directions for future research, emphasizing the\npotential for NLP to revolutionize EBM by refining evidence extraction,\nevidence synthesis, appraisal, summarization, enhancing data comprehensibility,\nand facilitating a more efficient clinical workflow.','Zihan Xu, Haotian Ma, Gongbo Zhang, Yihao Ding, Chunhua Weng, Yifan Peng','2025-05-28','cs.CL','自然语言处理(AI)','http://arxiv.org/pdf/2505.22280v1','该论文总结了129项关于利用自然语言处理(NLP)技术在循证医学(EBM)中的研究，展示了NLP在增强临床决策过程中的关键作用。论文系统地探讨了NLP如何支持EBM的五个基本步骤：提问、获取、评估、应用和评估。同时，论文还提出了未来研究的方向，强调了NLP在改进证据提取、综合、评估、总结、增强数据可理解性以及促进更高效的临床工作流程方面的潜力。'),('2505.22287v1','New Tools are Needed for Tracking Adherence to AI Model Behavioral Use Clauses','Foundation models have had a transformative impact on AI. A combination of\nlarge investments in research and development, growing sources of digital data\nfor training, and architectures that scale with data and compute has led to\nmodels with powerful capabilities. Releasing assets is fundamental to\nscientific advancement and commercial enterprise. However, concerns over\nnegligent or malicious uses of AI have led to the design of mechanisms to limit\nthe risks of the technology. The result has been a proliferation of licenses\nwith behavioral-use clauses and acceptable-use-policies that are increasingly\nbeing adopted by commonly used families of models (Llama, Gemma, Deepseek) and\na myriad of smaller projects. We created and deployed a custom AI licenses\ngenerator to facilitate license creation and have quantitatively and\nqualitatively analyzed over 300 customized licenses created with this tool.\nAlongside this we analyzed 1.7 million models licenses on the HuggingFace model\nhub. Our results show increasing adoption of these licenses, interest in tools\nthat support their creation and a convergence on common clause configurations.\nIn this paper we take the position that tools for tracking adoption of, and\nadherence to, these licenses is the natural next step and urgently needed in\norder to ensure they have the desired impact of ensuring responsible use.','Daniel McDuff, Tim Korjakow, Kevin Klyman, Danish Contractor','2025-05-28','cs.CY','AI伦理与法律','http://arxiv.org/pdf/2505.22287v1','该论文讨论了基础模型对人工智能的影响，以及对AI潜在风险的担忧导致了AI许可证的设计和采用情况。研究者创建并部署了一个自定义AI许可证生成器，分析了300多个定制许可证，并对HuggingFace模型中心的170万个模型许可证进行了分析。结果显示这些许可证的采用率增加，对支持其创建的工具的兴趣增加，并在常见条款配置上趋于一致。作者认为追踪这些许可证的采用和遵守情况是下一步必要且迫切的。'),('2505.22288v1','Compression versus Accuracy: A Hierarchy of Lifted Models','Probabilistic graphical models that encode indistinguishable objects and\nrelations among them use first-order logic constructs to compress a\npropositional factorised model for more efficient (lifted) inference. To obtain\na lifted representation, the state-of-the-art algorithm Advanced Colour Passing\n(ACP) groups factors that represent matching distributions. In an approximate\nversion using $\\varepsilon$ as a hyperparameter, factors are grouped that\ndiffer by a factor of at most $(1\\pm \\varepsilon)$. However, finding a suitable\n$\\varepsilon$ is not obvious and may need a lot of exploration, possibly\nrequiring many ACP runs with different $\\varepsilon$ values. Additionally,\nvarying $\\varepsilon$ can yield wildly different models, leading to decreased\ninterpretability. Therefore, this paper presents a hierarchical approach to\nlifted model construction that is hyperparameter-free. It efficiently computes\na hierarchy of $\\varepsilon$ values that ensures a hierarchy of models, meaning\nthat once factors are grouped together given some $\\varepsilon$, these factors\nwill be grouped together for larger $\\varepsilon$ as well. The hierarchy of\n$\\varepsilon$ values also leads to a hierarchy of error bounds. This allows for\nexplicitly weighing compression versus accuracy when choosing specific\n$\\varepsilon$ values to run ACP with and enables interpretability between the\ndifferent models.','Jan Speller, Malte Luttermann, Marcel Gehrke, Tanya Braun','2025-05-28','cs.AI','概率图模型','http://arxiv.org/pdf/2505.22288v1','该论文提出了一种基于层次结构的 lifted 模型构建方法，无需超参数，能够有效地计算一系列 $\\varepsilon$ 值，确保模型的层次性，同时提供了层次性的误差界限，可以在压缩和准确性之间进行权衡选择具体的 $\\varepsilon$ 值。'),('2505.22290v1','Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling','Recent research has highlighted that Large Language Models (LLMs), even when\ntrained to generate extended long reasoning steps, still face significant\nchallenges on hard reasoning problems. However, much of the existing literature\nrelies on direct prompting with simple in-context learning examples for\nevaluation, which largely overlooks advanced techniques to elicit LLMs\\\'\ndeliberate reasoning before drawing conclusions that LLMs hit a performance\nceiling. In this paper, we systematically explore the combined potential of\nin-context search and test-time scaling on super hard reasoning tasks. We find\nthat by employing advanced in-context search prompting to LLMs augmented with\ninternal scaling, one can achieve transformative performance breakthroughs on\ntasks previously deemed \"unsolvable\" (e.g., reported success rates below 5%).\nWe provide both empirical results and theoretical analysis of how this\ncombination can unleash LLM reasoning capabilities: i) Empirically, on\ncontrolled NP-hard tasks and complex real-world planning benchmarks, our\napproach achieves up to a 30x improvement in success rates compared to\npreviously reported results without any external mechanisms; ii) Theoretically,\nwe show that in-context search prompting, when combined with internal scaling,\nsignificantly extends the complexity class of solvable reasoning problems.\nThese findings challenge prevailing assumptions about the limitations of LLMs\non complex tasks, indicating that current evaluation paradigms systematically\nunderestimate their true potential. Our work calls for a critical reassessment\nof how LLM reasoning is benchmarked and a more robust evaluation strategy that\nfully captures the true capabilities of contemporary LLMs, which can lead to a\nbetter understanding of their operational reasoning boundaries in real-world\ndeployments.','Fanzeng Xia, Yidong Luo, Tinko Sebastian Bartels, Yaqi Xu, Tongxin Li','2025-05-28','cs.AI','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22290v1','本文系统地探索了在超难推理任务中，通过采用先进的上下文搜索提示和测试时缩放技术，可以实现对LLMs推理能力的显著性突破。通过在受控的NP-hard任务和复杂的现实世界规划基准上进行实证研究，发现这种方法相比以往的结果可以实现高达30倍的成功率提升，并在理论上展示了这种组合如何显著扩展了可解推理问题的复杂性类别。'),('2505.22291v1','Neural Restoration of Greening Defects in Historical Autochrome Photographs Based on Purely Synthetic Data','The preservation of early visual arts, particularly color photographs, is\nchallenged by deterioration caused by aging and improper storage, leading to\nissues like blurring, scratches, color bleeding, and fading defects. In this\npaper, we present the first approach for the automatic removal of greening\ncolor defects in digitized autochrome photographs. Our main contributions\ninclude a method based on synthetic dataset generation and the use of\ngenerative AI with a carefully designed loss function for the restoration of\nvisual arts. To address the lack of suitable training datasets for analyzing\ngreening defects in damaged autochromes, we introduce a novel approach for\naccurately simulating such defects in synthetic data. We also propose a\nmodified weighted loss function for the ChaIR method to account for color\nimbalances between defected and non-defected areas. While existing methods\nstruggle with accurately reproducing original colors and may require\nsignificant manual effort, our method allows for efficient restoration with\nreduced time requirements.','Saptarshi Neil Sinha, P. Julius Kuehn, Johannes Koppe, Arjan Kuijper, Michael Weinmann','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22291v1','本文提出了一种用于自动去除数字化自动色调照片中绿化色缺陷的方法，通过合成数据集生成和利用生成式人工智能以及精心设计的损失函数来进行视觉艺术修复。'),('2505.22293v1','Compensating for Data with Reasoning: Low-Resource Machine Translation with LLMs','Large Language Models (LLMs) have demonstrated strong capabilities in\nmultilingual machine translation, sometimes even outperforming traditional\nneural systems. However, previous research has highlighted the challenges of\nusing LLMs, particularly with prompt engineering, for low-resource languages.\nIn this work, we introduce Fragment-Shot Prompting, a novel in-context learning\nmethod that segments input and retrieves translation examples based on\nsyntactic coverage, along with Pivoted Fragment-Shot, an extension that enables\ntranslation without direct parallel data. We evaluate these methods using\nGPT-3.5, GPT-4o, o1-mini, LLaMA-3.3, and DeepSeek-R1 for translation between\nItalian and two Ladin variants, revealing three key findings: (1) Fragment-Shot\nPrompting is effective for translating into and between the studied\nlow-resource languages, with syntactic coverage positively correlating with\ntranslation quality; (2) Models with stronger reasoning abilities make more\neffective use of retrieved knowledge, generally produce better translations,\nand enable Pivoted Fragment-Shot to significantly improve translation quality\nbetween the Ladin variants; and (3) prompt engineering offers limited, if any,\nimprovements when translating from a low-resource to a high-resource language,\nwhere zero-shot prompting already yields satisfactory results. We publicly\nrelease our code and the retrieval corpora.','Samuel Frontull, Thomas Ströhle','2025-05-28','cs.CL','LLM (Large Language Models)、自然语言处理 (NLP)','http://arxiv.org/pdf/2505.22293v1','本文介绍了一种新的上下文学习方法 Fragment-Shot Prompting，以及一个扩展方法 Pivoted Fragment-Shot，用于解决低资源语言的翻译问题。通过使用 GPT-3.5、GPT-4o、o1-mini、LLaMA-3.3 和 DeepSeek-R1 模型在意大利语和两种拉丁语方言之间进行翻译，发现 Fragment-Shot Prompting 对于翻译低资源语言效果显著，而具有更强推理能力的模型能更有效地利用检索到的知识，从而提高翻译质量。'),('2505.22296v1','360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long Post-Training','Adding sequence parallelism into LLaMA-Factory, we open-sourced\n360-LLaMA-Factory at https://github.com/Qihoo360/360-LLaMA-Factory.\n360-LLaMA-Factory has received wide recognition and used in models such as\nLight-R1 arXiv:2503.10460, TinyR1 arXiv:2503.04872, Kaggle AIMO math models and\nalso in large companies\\\' training frameworks. This technical report delves\ndeeper into the different sequence parallel modes behind 360-LLaMA-Factory and\ndiscusses our implementation insights.','Haosheng Zou, Xiaowei Lv, Shousheng Jia, Xiangzheng Zhang','2025-05-28','cs.CL','LLM (Language Model)','http://arxiv.org/pdf/2505.22296v1','该论文介绍了在LLaMA-Factory中添加序列并行性，开源了360-LLaMA-Factory，并深入讨论了其不同序列并行模式和实现见解。'),('2505.22298v1','Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing','Large language models (LLMs) exhibit impressive language capabilities but\nremain vulnerable to malicious prompts and jailbreaking attacks. Existing\nknowledge editing methods for LLM detoxification face two major challenges.\nFirst, they often rely on entity-specific localization, making them ineffective\nagainst adversarial inputs without explicit entities. Second, these methods\nsuffer from over-editing, where detoxified models reject legitimate queries,\ncompromising overall performance. In this paper, we propose ToxEdit, a\ntoxicity-aware knowledge editing approach that dynamically detects toxic\nactivation patterns during forward propagation. It then routes computations\nthrough adaptive inter-layer pathways to mitigate toxicity effectively. This\ndesign ensures precise toxicity mitigation while preserving LLMs\\\' general\ncapabilities. To more accurately assess over-editing, we also enhance the\nSafeEdit benchmark by incorporating instruction-following evaluation tasks.\nExperimental results on multiple LLMs demonstrate that our ToxEdit outperforms\nprevious state-of-the-art methods in both detoxification performance and\nsafeguarding general capabilities of LLMs.','Yifan Lu, Jing Li, Yigeng Zhou, Yihui Zhang, Wenya Wang, Xiucheng Li, Meishan Zhang, Fangming Liu, Jun Yu, Min Zhang','2025-05-28','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.22298v1','本文提出了一种新的知识编辑方法 ToxEdit，用于改善大型语言模型（LLMs）对恶意提示和越狱攻击的脆弱性。该方法通过动态检测有毒激活模式并通过自适应的层间路径来减轻毒性，确保了毒性的精确减轻同时保留了LLMs的一般能力。实验证明，ToxEdit在毒性消除性能和保护LLMs一般能力方面优于先前的最先进方法。'),('2505.22306v1','Versatile Cardiovascular Signal Generation with a Unified Diffusion Transformer','Cardiovascular signals such as photoplethysmography (PPG),\nelectrocardiography (ECG), and blood pressure (BP) are inherently correlated\nand complementary, together reflecting the health of cardiovascular system.\nHowever, their joint utilization in real-time monitoring is severely limited by\ndiverse acquisition challenges from noisy wearable recordings to burdened\ninvasive procedures. Here we propose UniCardio, a multi-modal diffusion\ntransformer that reconstructs low-quality signals and synthesizes unrecorded\nsignals in a unified generative framework. Its key innovations include a\nspecialized model architecture to manage the signal modalities involved in\ngeneration tasks and a continual learning paradigm to incorporate varying\nmodality combinations. By exploiting the complementary nature of cardiovascular\nsignals, UniCardio clearly outperforms recent task-specific baselines in signal\ndenoising, imputation, and translation. The generated signals match the\nperformance of ground-truth signals in detecting abnormal health conditions and\nestimating vital signs, even in unseen domains, while ensuring interpretability\nfor human experts. These advantages position UniCardio as a promising avenue\nfor advancing AI-assisted healthcare.','Zehua Chen, Yuyang Miao, Liyuan Wang, Luyun Fan, Danilo P. Mandic, Jun Zhu','2025-05-28','cs.LG','健康医疗AI','http://arxiv.org/pdf/2505.22306v1','本文提出了一种名为UniCardio的多模态扩散变压器，可以在统一的生成框架中重建低质量信号并合成未记录的信号。UniCardio在信号去噪、填充和转换任务中明显优于最近的特定任务基线。生成的信号在检测异常健康状况和估计生命体征方面与地面实况信号的性能相匹配，甚至在未知领域也能确保可解释性。'),('2505.22308v1','Transformers Pretrained on Procedural Data Contain Modular Structures for Algorithmic Reasoning','Pretraining on large, semantically rich datasets is key for developing\nlanguage models. Surprisingly, recent studies have shown that even synthetic\ndata, generated procedurally through simple semantic-free algorithms, can yield\nsome of the same benefits as natural language pretraining. It is unclear what\nspecific capabilities such simple synthetic data instils in a model, where\nthese capabilities reside in the architecture, and how they manifest within its\nweights. In this short paper, we identify several beneficial forms of\nprocedural data, together with specific algorithmic reasoning skills that\nimprove in small transformers. Our core finding is that different procedural\nrules instil distinct but complementary inductive structures in the model. With\nextensive ablations and partial-transfer experiments, we discover that these\nstructures reside in different parts of the model. Attention layers often carry\nthe most transferable information, but some pretraining rules impart useful\nstructure to MLP blocks instead. Most interestingly, the structures induced by\nmultiple rules can be composed to jointly reinforce multiple capabilities.\nThese results suggest an exciting possibility of disentangling the acquisition\nof knowledge from reasoning in language models, with the goal of improving\ntheir robustness and data efficiency.','Zachary Shinnick, Liangze Jiang, Hemanth Saratchandran, Anton van den Hengel, Damien Teney','2025-05-28','cs.LG','LLM (Large Language Model)','http://arxiv.org/pdf/2505.22308v1','本文研究了在大型语义丰富数据集上进行预训练对于发展语言模型的重要性。研究发现，即使是通过简单的无语义算法生成的合成数据，也可以产生与自然语言预训练相同的一些好处。作者发现不同的过程规则在模型中引入了不同但互补的归纳结构，这些结构分布在模型的不同部分。'),('2505.22310v1','From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization','Recent unlearning methods for LLMs are vulnerable to relearning attacks:\nknowledge believed-to-be-unlearned re-emerges by fine-tuning on a small set of\n(even seemingly-unrelated) examples. We study this phenomenon in a controlled\nsetting for example-level unlearning in vision classifiers. We make the\nsurprising discovery that forget-set accuracy can recover from around 50%\npost-unlearning to nearly 100% with fine-tuning on just the retain set -- i.e.,\nzero examples of the forget set. We observe this effect across a wide variety\nof unlearning methods, whereas for a model retrained from scratch excluding the\nforget set (gold standard), the accuracy remains at 50%. We observe that\nresistance to relearning attacks can be predicted by weight-space properties,\nspecifically, $L_2$-distance and linear mode connectivity between the original\nand the unlearned model. Leveraging this insight, we propose a new class of\nmethods that achieve state-of-the-art resistance to relearning attacks.','Shoaib Ahmed Siddiqui, Adrian Weller, David Krueger, Gintare Karolina Dziugaite, Michael Curtis Mozer, Eleni Triantafillou','2025-05-28','cs.LG','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22310v1','该论文研究了最近针对LLM的遗忘方法容易受到重新学习攻击的问题，通过在视觉分类器中对示例级别的遗忘进行控制性研究，发现通过在保留集上微调，遗忘集的准确率可以从50%恢复到接近100%。'),('2505.22311v1','From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications','With the advent of 6G communications, intelligent communication systems face\nmultiple challenges, including constrained perception and response\ncapabilities, limited scalability, and low adaptability in dynamic\nenvironments. This tutorial provides a systematic introduction to the\nprinciples, design, and applications of Large Artificial Intelligence Models\n(LAMs) and Agentic AI technologies in intelligent communication systems, aiming\nto offer researchers a comprehensive overview of cutting-edge technologies and\npractical guidance. First, we outline the background of 6G communications,\nreview the technological evolution from LAMs to Agentic AI, and clarify the\ntutorial\\\'s motivation and main contributions. Subsequently, we present a\ncomprehensive review of the key components required for constructing LAMs. We\nfurther categorize LAMs and analyze their applicability, covering Large\nLanguage Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models\n(LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a\nLAM-centric design paradigm tailored for communications, encompassing dataset\nconstruction and both internal and external learning approaches. Building upon\nthis, we develop an LAM-based Agentic AI system for intelligent communications,\nclarifying its core components such as planners, knowledge bases, tools, and\nmemory modules, as well as its interaction mechanisms. We also introduce a\nmulti-agent framework with data retrieval, collaborative planning, and\nreflective evaluation for 6G. Subsequently, we provide a detailed overview of\nthe applications of LAMs and Agentic AI in communication scenarios. Finally, we\nsummarize the research challenges and future directions in current studies,\naiming to support the development of efficient, secure, and sustainable\nnext-generation intelligent communication systems.','Feibo Jiang, Cunhua Pan, Li Dong, Kezhi Wang, Octavia A. Dobre, Merouane Debbah','2025-05-28','cs.AI','大型人工智能模型（LAMs）、智能通信系统','http://arxiv.org/pdf/2505.22311v1','该论文介绍了在6G通信领域中，大型人工智能模型（LAMs）和智能AI技术的原理、设计和应用。论文提出了LAM-centric设计范式，包括数据集构建和内部外部学习方法，并开发了基于LAM的智能通信Agentic AI系统。最后总结了当前研究中的挑战和未来方向。'),('2505.22312v1','Skywork Open Reasoner 1 Technical Report','The success of DeepSeek-R1 underscores the significant role of reinforcement\nlearning (RL) in enhancing the reasoning capabilities of large language models\n(LLMs). In this work, we present Skywork-OR1, an effective and scalable RL\nimplementation for long Chain-of-Thought (CoT) models. Building on the\nDeepSeek-R1-Distill model series, our RL approach achieves notable performance\ngains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench\nfrom 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%)\nfor the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and\nQwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable\nresults on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models\ndemonstrate competitive reasoning capabilities among models of similar size. We\nperform comprehensive ablation studies on the core components of our training\npipeline to validate their effectiveness. Additionally, we thoroughly\ninvestigate the phenomenon of entropy collapse, identify key factors affecting\nentropy dynamics, and demonstrate that mitigating premature entropy collapse is\ncritical for improved test performance. To support community research, we fully\nopen-source our model weights, training code, and training datasets.','Jujie He, Jiacai Liu, Chris Yuhao Liu, Rui Yan, Chaojie Wang, Peng Cheng, Xiaoyu Zhang, Fuxiang Zhang, Jiacheng Xu, Wei Shen, Siyuan Li, Liang Zeng, Tianwen Wei, Cheng Cheng, Bo An, Yang Liu, Yahui Zhou','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22312v1','本文介绍了Skywork-OR1，一个针对长Chain-of-Thought (CoT)模型的有效且可扩展的强化学习实现。通过在DeepSeek-R1-Distill模型系列的基础上构建RL方法，我们取得了显著的性能提升，将平均准确率从57.8%提高到72.8%（+15.0%）（32B模型），从43.6%提高到57.5%（+13.9%）（7B模型）。'),('2505.22318v1','If Pigs Could Fly... Can LLMs Logically Reason Through Counterfactuals?','Large Language Models (LLMs) demonstrate impressive reasoning capabilities in\nfamiliar contexts, but struggle when the context conflicts with their\nparametric knowledge. To investigate this phenomenon, we introduce\nCounterLogic, a dataset containing 1,800 examples across 9 logical schemas,\nexplicitly designed to evaluate logical reasoning through counterfactual\n(hypothetical knowledge-conflicting) scenarios. Our systematic evaluation of 11\nLLMs across 6 different datasets reveals a consistent performance degradation,\nwith accuracies dropping by 27% on average when reasoning through\ncounterfactual information. We propose Self-Segregate, a prompting method\nenabling metacognitive awareness (explicitly identifying knowledge conflicts)\nbefore reasoning. Our method dramatically narrows the average performance gaps\nfrom 27% to just 11%, while significantly increasing the overall accuracy\n(+7.5%). We discuss the implications of these findings and draw parallels to\nhuman cognitive processes, particularly on how humans disambiguate conflicting\ninformation during reasoning tasks. Our findings offer practical insights for\nunderstanding and enhancing LLMs reasoning capabilities in real-world\napplications, especially where models must logically reason independently of\ntheir factual knowledge.','Ishwar B Balappanawar, Vamshi Krishna Bonagiri, Anish R Joishy, Manas Gaur, Krishnaprasad Thirunarayan, Ponnurangam Kumaraguru','2025-05-28','cs.CL','LLM、自然语言处理','http://arxiv.org/pdf/2505.22318v1','该论文研究了大型语言模型在逻辑推理中的表现，引入了CounterLogic数据集，通过反事实场景评估逻辑推理能力，提出了Self-Segregate提示方法，帮助模型在推理前识别知识冲突，从而提高准确性。'),('2505.22322v1','A Closer Look on Memorization in Tabular Diffusion Model: A Data-Centric Perspective','Diffusion models have shown strong performance in generating high-quality\ntabular data, but they carry privacy risks by reproducing exact training\nsamples. While prior work focuses on dataset-level augmentation to reduce\nmemorization, little is known about which individual samples contribute most.\nWe present the first data-centric study of memorization dynamics in tabular\ndiffusion models. We quantify memorization for each real sample based on how\nmany generated samples are flagged as replicas, using a relative distance\nratio. Our empirical analysis reveals a heavy-tailed distribution of\nmemorization counts: a small subset of samples contributes disproportionately\nto leakage, confirmed via sample-removal experiments. To understand this, we\ndivide real samples into top- and non-top-memorized groups and analyze their\ntraining-time behaviors. We track when each sample is first memorized and\nmonitor per-epoch memorization intensity (AUC). Memorized samples are memorized\nslightly earlier and show stronger signals in early training. Based on these\ninsights, we propose DynamicCut, a two-stage, model-agnostic mitigation method:\n(a) rank samples by epoch-wise intensity, (b) prune a tunable top fraction, and\n(c) retrain on the filtered dataset. Across multiple tabular datasets and\nmodels, DynamicCut reduces memorization with minimal impact on data diversity\nand downstream performance. It also complements augmentation-based defenses.\nFurthermore, DynamicCut enables cross-model transferability: high-ranked\nsamples identified from one model (e.g., a diffusion model) are also effective\nfor reducing memorization when removed from others, such as GANs and VAEs.','Zhengyu Fang, Zhimeng Jiang, Huiyuan Chen, Xiaoge Zhang, Kaiyu Tang, Xiao Li, Jing Li','2025-05-28','cs.LG','隐私保护、数据生成模型','http://arxiv.org/pdf/2505.22322v1','该论文研究了在生成高质量表格数据时，扩散模型存在的隐私风险问题，提出了一种数据中心的记忆动态研究方法，并提出了一种名为DynamicCut的两阶段、与模型无关的缓解方法，通过剪枝和重新训练降低了记忆现象。'),('2505.22323v1','Advancing Expert Specialization for Better MoE','Mixture-of-Experts (MoE) models enable efficient scaling of large language\nmodels (LLMs) by activating only a subset of experts per input. However, we\nobserve that the commonly used auxiliary load balancing loss often leads to\nexpert overlap and overly uniform routing, which hinders expert specialization\nand degrades overall performance during post-training. To address this, we\npropose a simple yet effective solution that introduces two complementary\nobjectives: (1) an orthogonality loss to encourage experts to process distinct\ntypes of tokens, and (2) a variance loss to encourage more discriminative\nrouting decisions. Gradient-level analysis demonstrates that these objectives\nare compatible with the existing auxiliary loss and contribute to optimizing\nthe training process. Experimental results over various model architectures and\nacross multiple benchmarks show that our method significantly enhances expert\nspecialization. Notably, our method improves classic MoE baselines with\nauxiliary loss by up to 23.79%, while also maintaining load balancing in\ndownstream tasks, without any architectural modifications or additional\ncomponents. We will release our code to contribute to the community.','Hongcan Guo, Haolang Lu, Guoshun Nan, Bolun Chu, Jialin Zhuang, Yuan Yang, Wenhao Che, Sicong Leng, Qimei Cui, Xudong Jiang','2025-05-28','cs.CL','LLM (大语言模型)','http://arxiv.org/pdf/2505.22323v1','该论文提出了一种简单而有效的方法，通过引入正交性损失和方差损失来增强专家的特化，优化了Mixture-of-Experts (MoE)模型的训练过程，提高了性能。'),('2505.22326v1','Individualised Counterfactual Examples Using Conformal Prediction Intervals','Counterfactual explanations for black-box models aim to pr ovide insight into\nan algorithmic decision to its recipient. For a binary classification problem\nan individual counterfactual details which features might be changed for the\nmodel to infer the opposite class. High-dimensional feature spaces that are\ntypical of machine learning classification models admit many possible\ncounterfactual examples to a decision, and so it is important to identify\nadditional criteria to select the most useful counterfactuals. In this paper,\nwe explore the idea that the counterfactuals should be maximally informative\nwhen considering the knowledge of a specific individual about the underlying\nclassifier. To quantify this information gain we explicitly model the knowledge\nof the individual, and assess the uncertainty of predictions which the\nindividual makes by the width of a conformal prediction interval. Regions of\nfeature space where the prediction interval is wide correspond to areas where\nthe confidence in decision making is low, and an additional counterfactual\nexample might be more informative to an individual. To explore and evaluate our\nindividualised conformal prediction interval counterfactuals (CPICFs), first we\npresent a synthetic data set on a hypercube which allows us to fully visualise\nthe decision boundary, conformal intervals via three different methods, and\nresultant CPICFs. Second, in this synthetic data set we explore the impact of a\nsingle CPICF on the knowledge of an individual locally around the original\nquery. Finally, in both our synthetic data set and a complex real world dataset\nwith a combination of continuous and discrete variables, we measure the utility\nof these counterfactuals via data augmentation, testing the performance on a\nheld out set.','James M. Adams, Gesine Reinert, Lukasz Szpruch, Carsten Maple, Andrew Elliott','2025-05-28','stat.ML','解释性人工智能','http://arxiv.org/pdf/2505.22326v1','本文探讨了针对黑盒模型的反事实解释，旨在为接收者提供对算法决策的洞察。通过量化个体知识的信息增益，明确建模个体的知识，并通过符合预测区间的宽度评估个体的预测不确定性，以识别最有用的反事实例。'),('2505.22327v1','NLP for Social Good: A Survey of Challenges, Opportunities, and Responsible Deployment','Recent advancements in large language models (LLMs) have unlocked\nunprecedented possibilities across a range of applications. However, as a\ncommunity, we believe that the field of Natural Language Processing (NLP) has a\ngrowing need to approach deployment with greater intentionality and\nresponsibility. In alignment with the broader vision of AI for Social Good\n(Toma\\v{s}ev et al., 2020), this paper examines the role of NLP in addressing\npressing societal challenges. Through a cross-disciplinary analysis of social\ngoals and emerging risks, we highlight promising research directions and\noutline challenges that must be addressed to ensure responsible and equitable\nprogress in NLP4SG research.','Antonia Karamolegkou, Angana Borah, Eunjung Cho, Sagnik Ray Choudhury, Martina Galletti, Rajarshi Ghosh, Pranav Gupta, Oana Ignat, Priyanka Kargupta, Neema Kotonya, Hemank Lamba, Sun-Joo Lee, Arushi Mangla, Ishani Mondal, Deniz Nazarova, Poli Nemkova, Dina Pisarevskaya, Naquee Rizwan, Nazanin Sabri, Dominik Stammbach, Anna Steinberg, David Tomás, Steven R Wilson, Bowen Yi, Jessica H Zhu, Arkaitz Zubiaga, Anders Søgaard, Alexander Fraser, Zhijing Jin, Rada Mihalcea, Joel R. Tetreault, Daryna Dementieva','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22327v1','本文探讨了自然语言处理在解决社会挑战中的作用，强调了研究方向和挑战，以确保负责任和公平的进展。'),('2505.22332v1','Credal Prediction based on Relative Likelihood','Predictions in the form of sets of probability distributions, so-called\ncredal sets, provide a suitable means to represent a learner\\\'s epistemic\nuncertainty. In this paper, we propose a theoretically grounded approach to\ncredal prediction based on the statistical notion of relative likelihood: The\ntarget of prediction is the set of all (conditional) probability distributions\nproduced by the collection of plausible models, namely those models whose\nrelative likelihood exceeds a specified threshold. This threshold has an\nintuitive interpretation and allows for controlling the trade-off between\ncorrectness and precision of credal predictions. We tackle the problem of\napproximating credal sets defined in this way by means of suitably modified\nensemble learning techniques. To validate our approach, we illustrate its\neffectiveness by experiments on benchmark datasets demonstrating superior\nuncertainty representation without compromising predictive performance. We also\ncompare our method against several state-of-the-art baselines in credal\nprediction.','Timo Löhr, Paul Hofman, Felix Mohr, Eyke Hüllermeier','2025-05-28','stat.ML','不确定性建模/集成学习','http://arxiv.org/pdf/2505.22332v1','本文提出了一种基于相对似然性的理论方法，用于表示学习者的认知不确定性，并通过修改集成学习技术来逼近这种方式定义的可信集。实验证明该方法在不损害预测性能的情况下，能够更好地表示不确定性。'),('2505.22334v1','Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start','Recent advancements in large language models (LLMs) have demonstrated\nimpressive chain-of-thought reasoning capabilities, with reinforcement learning\n(RL) playing a crucial role in this progress. While \"aha moment\"\npatterns--where models exhibit self-correction through reflection--are often\nattributed to emergent properties from RL, we first demonstrate that these\npatterns exist in multimodal LLMs (MLLMs) prior to RL training but may not\nnecessarily correlate with improved reasoning performance. Building on these\ninsights, we present a comprehensive study on enhancing multimodal reasoning\nthrough a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start\nwith structured chain-of-thought reasoning patterns, followed by (2)\nreinforcement learning via GRPO to further refine these capabilities. Our\nextensive experiments show that this combined approach consistently outperforms\nboth SFT-only and RL-only methods across challenging multimodal reasoning\nbenchmarks. The resulting models achieve state-of-the-art performance among\nopen-source MLLMs at both 3B and 7B scales, with our 7B model showing\nsubstantial improvements over base models (e.g., 66.3 %$\\rightarrow$73.4 % on\nMathVista, 62.9 %$\\rightarrow$70.4 % on We-Math) and our 3B model achieving\nperformance competitive with several 7B models. Overall, this work provides\npractical guidance for building advanced multimodal reasoning models. Our code\nis available at https://github.com/waltonfuture/RL-with-Cold-Start.','Lai Wei, Yuting Li, Kaipeng Zheng, Chen Wang, Yue Wang, Linghe Kong, Lichao Sun, Weiran Huang','2025-05-28','cs.CL','LLM（大型语言模型）, 强化学习','http://arxiv.org/pdf/2505.22334v1','该论文研究了在大型语言模型中如何通过两阶段方法（监督微调和强化学习）增强多模态推理能力，实验结果表明这种组合方法在多模态推理基准测试中表现优异。'),('2505.22338v1','Text2Grad: Reinforcement Learning from Natural Language Feedback','Traditional RLHF optimizes language models with coarse, scalar rewards that\nmask the fine-grained reasons behind success or failure, leading to slow and\nopaque learning. Recent work augments RL with textual critiques through\nprompting or reflection, improving interpretability but leaving model\nparameters untouched. We introduce Text2Grad, a reinforcement-learning paradigm\nthat turns free-form textual feedback into span-level gradients. Given human\n(or programmatic) critiques, Text2Grad aligns each feedback phrase with the\nrelevant token spans, converts these alignments into differentiable reward\nsignals, and performs gradient updates that directly refine the offending\nportions of the model\\\'s policy. This yields precise, feedback-conditioned\nadjustments instead of global nudges. Text2Grad is realized through three\ncomponents: (1) a high-quality feedback-annotation pipeline that pairs\ncritiques with token spans; (2) a fine-grained reward model that predicts\nspan-level reward on answer while generating explanatory critiques; and (3) a\nspan-level policy optimizer that back-propagates natural-language gradients.\nAcross summarization, code generation, and question answering, Text2Grad\nconsistently surpasses scalar-reward RL and prompt-only baselines, providing\nboth higher task metrics and richer interpretability. Our results demonstrate\nthat natural-language feedback, when converted to gradients, is a powerful\nsignal for fine-grained policy optimization. The code for our method is\navailable at https://github.com/microsoft/Text2Grad','Hanyang Wang, Lu Wang, Chaoyun Zhang, Tianjun Mao, Si Qin, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang','2025-05-28','cs.CL','强化学习','http://arxiv.org/pdf/2505.22338v1','该论文介绍了一种名为Text2Grad的强化学习范式，将自由形式的文本反馈转化为跨度级别的梯度，以直接优化模型策略的有问题部分。通过三个组件实现了这一方法，并在摘要、代码生成和问题回答等任务中 consistently surpasses scalar-reward RL and prompt-only baselines。'),('2505.22342v1','Progressive Data Dropout: An Embarrassingly Simple Approach to Faster Training','The success of the machine learning field has reliably depended on training\non large datasets. While effective, this trend comes at an extraordinary cost.\nThis is due to two deeply intertwined factors: the size of models and the size\nof datasets. While promising research efforts focus on reducing the size of\nmodels, the other half of the equation remains fairly mysterious. Indeed, it is\nsurprising that the standard approach to training remains to iterate over and\nover, uniformly sampling the training dataset. In this paper we explore a\nseries of alternative training paradigms that leverage insights from\nhard-data-mining and dropout, simple enough to implement and use that can\nbecome the new training standard. The proposed Progressive Data Dropout reduces\nthe number of effective epochs to as little as 12.4% of the baseline. This\nsavings actually do not come at any cost for accuracy. Surprisingly, the\nproposed method improves accuracy by up to 4.82%. Our approach requires no\nchanges to model architecture or optimizer, and can be applied across standard\ntraining pipelines, thus posing an excellent opportunity for wide adoption.\nCode can be found here: https://github.com/bazyagami/LearningWithRevision','Shriram M S, Xinyue Hao, Shihao Hou, Yang Lu, Laura Sevilla-Lara, Anurag Arnab, Shreyank N Gowda','2025-05-28','cs.CV','机器学习','http://arxiv.org/pdf/2505.22342v1','本文探讨了在机器学习领域训练大型数据集的成本问题，提出了一种新的训练范式——渐进数据丢弃，可以显著减少有效迭代次数，同时提高准确性。'),('2505.22343v1','Empowering Intelligent Low-altitude Economy with Large AI Model Deployment','Low-altitude economy (LAE) represents an emerging economic paradigm that\nredefines commercial and social aerial activities. Large artificial\nintelligence models (LAIMs) offer transformative potential to further enhance\nthe intelligence of LAE services. However, deploying LAIMs in LAE poses several\nchallenges, including the significant gap between their computational/storage\ndemands and the limited onboard resources of LAE entities, the mismatch between\nlab-trained LAIMs and dynamic physical environments, and the inefficiencies of\ntraditional decoupled designs for sensing, communication, and computation. To\naddress these issues, we first propose a hierarchical system architecture\ntailored for LAIM deployment and present representative LAE application\nscenarios. Next, we explore key enabling techniques that facilitate the mutual\nco-evolution of LAIMs and low-altitude systems, and introduce a task-oriented\nexecution pipeline for scalable and adaptive service delivery. Then, the\nproposed framework is validated through real-world case studies. Finally, we\noutline open challenges to inspire future research.','Zhonghao Lyu, Yulan Gao, Junting Chen, Hongyang Du, Jie Xu, Kaibin Huang, Dong In Kim','2025-05-28','eess.SP','人工智能模型在低空经济中的应用','http://arxiv.org/pdf/2505.22343v1','该论文讨论了低空经济(LAE)的新兴经济范式，提出了大型人工智能模型(LAIMs)在增强LAE服务智能方面的潜力。作者提出了针对LAIM部署的层次化系统架构，并介绍了代表性的LAE应用场景。通过真实案例验证了所提出的框架。'),('2505.22349v1','ChatPD: An LLM-driven Paper-Dataset Networking System','Scientific research heavily depends on suitable datasets for method\nvalidation, but existing academic platforms with dataset management like\nPapersWithCode suffer from inefficiencies in their manual workflow. To overcome\nthis bottleneck, we present a system, called ChatPD, that utilizes Large\nLanguage Models (LLMs) to automate dataset information extraction from academic\npapers and construct a structured paper-dataset network. Our system consists of\nthree key modules: \\textit{paper collection}, \\textit{dataset information\nextraction}, and \\textit{dataset entity resolution} to construct paper-dataset\nnetworks. Specifically, we propose a \\textit{Graph Completion and Inference}\nstrategy to map dataset descriptions to their corresponding entities. Through\nextensive experiments, we demonstrate that ChatPD not only outperforms the\nexisting platform PapersWithCode in dataset usage extraction but also achieves\nabout 90\\% precision and recall in entity resolution tasks. Moreover, we have\ndeployed ChatPD to continuously extract which datasets are used in papers, and\nprovide a dataset discovery service, such as task-specific dataset queries and\nsimilar dataset recommendations. We open source ChatPD and the current\npaper-dataset network on this [GitHub\nrepository]{https://github.com/ChatPD-web/ChatPD}.','Anjie Xu, Ruiqing Ding, Leye Wang','2025-05-28','cs.DB','大型语言模型(LLM)、自然语言处理(NLP)','http://arxiv.org/pdf/2505.22349v1','该论文介绍了一个名为ChatPD的系统，利用大型语言模型（LLMs）自动从学术论文中提取数据集信息，并构建结构化的论文-数据集网络。该系统包括三个关键模块：论文收集、数据集信息提取和数据集实体解析，通过图完成和推理策略将数据集描述映射到相应的实体。实验证明，ChatPD在数据集使用提取和实体解析任务中表现优于现有平台PapersWithCode，并在实体解析任务中实现了约90%的精度和召回率。'),('2505.22353v1','VME: A Satellite Imagery Dataset and Benchmark for Detecting Vehicles in the Middle East and Beyond','Detecting vehicles in satellite images is crucial for traffic management,\nurban planning, and disaster response. However, current models struggle with\nreal-world diversity, particularly across different regions. This challenge is\namplified by geographic bias in existing datasets, which often focus on\nspecific areas and overlook regions like the Middle East. To address this gap,\nwe present the Vehicles in the Middle East (VME) dataset, designed explicitly\nfor vehicle detection in high-resolution satellite images from Middle Eastern\ncountries. Sourced from Maxar, the VME dataset spans 54 cities across 12\ncountries, comprising over 4,000 image tiles and more than 100,000 vehicles,\nannotated using both manual and semi-automated methods. Additionally, we\nintroduce the largest benchmark dataset for Car Detection in Satellite Imagery\n(CDSI), combining images from multiple sources to enhance global car detection.\nOur experiments demonstrate that models trained on existing datasets perform\npoorly on Middle Eastern images, while the VME dataset significantly improves\ndetection accuracy in this region. Moreover, state-of-the-art models trained on\nCDSI achieve substantial improvements in global car detection.','Noora Al-Emadi, Ingmar Weber, Yin Yang, Ferda Ofli','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22353v1','该论文介绍了为了解决卫星图像中车辆检测的挑战，提出了专门设计用于中东国家高分辨率卫星图像中车辆检测的Vehicles in the Middle East (VME)数据集，并介绍了Car Detection in Satellite Imagery (CDSI)基准数据集。实验证明，在中东地区训练的模型在该地区的检测准确性显著提高，同时在全球范围内进行车辆检测也取得了实质性进展。'),('2505.22354v1','LLMs Struggle to Reject False Presuppositions when Misinformation Stakes are High','This paper examines how LLMs handle false presuppositions and whether certain\nlinguistic factors influence their responses to falsely presupposed content.\nPresuppositions subtly introduce information as given, making them highly\neffective at embedding disputable or false information. This raises concerns\nabout whether LLMs, like humans, may fail to detect and correct misleading\nassumptions introduced as false presuppositions, even when the stakes of\nmisinformation are high. Using a systematic approach based on linguistic\npresupposition analysis, we investigate the conditions under which LLMs are\nmore or less sensitive to adopt or reject false presuppositions. Focusing on\npolitical contexts, we examine how factors like linguistic construction,\npolitical party, and scenario probability impact the recognition of false\npresuppositions. We conduct experiments with a newly created dataset and\nexamine three LLMs: OpenAI\\\'s GPT-4-o, Meta\\\'s LLama-3-8B, and MistralAI\\\'s\nMistral-7B-v03. Our results show that the models struggle to recognize false\npresuppositions, with performance varying by condition. This study highlights\nthat linguistic presupposition analysis is a valuable tool for uncovering the\nreinforcement of political misinformation in LLM responses.','Judith Sieker, Clara Lachenmaier, Sina Zarrieß','2025-05-28','cs.CL','语言处理','http://arxiv.org/pdf/2505.22354v1','本文研究了LLM如何处理错误的预设，并探讨了某些语言因素如何影响它们对错误预设内容的回应。通过基于语言预设分析的系统方法，研究了LLM在何种条件下更容易接受或拒绝错误的预设。研究结果表明，模型在识别错误预设方面存在困难，性能受条件影响。'),('2505.22355v1','Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning','Parameter-Efficient Fine-Tuning (PEFT) methods achieve performance comparable\nto Full Fine-Tuning (FFT) while requiring significantly fewer computing\nresources, making it the go-to choice for researchers. We find that although\nPEFT can achieve competitive results on some benchmarks, its performance falls\nshort of FFT in complex tasks, such as reasoning and instruction-based\nfine-tuning. In this paper, we compare the characteristics of PEFT and FFT in\nterms of representational capacity and robustness based on optimization theory.\nWe theoretically demonstrate that PEFT is a strict subset of FFT. By providing\ntheoretical upper bounds for PEFT, we show that the limited parameter space\nconstrains the model\\\'s representational ability, making it more susceptible to\nperturbations. Experiments on 15 datasets encompassing classification,\ngeneration, reasoning, instruction fine-tuning tasks and 11 adversarial test\nsets validate our theories. We hope that these results spark further research\nbeyond the realms of well established PEFT. The source code is in the anonymous\nGithub repository\\footnote{https://github.com/misonsky/PEFTEval}.','Yongkang Liu, Xingle Xu, Ercong Nie, Zijing Wang, Shi Feng, Daling Wang, Qian Li, Hinrich Schütze','2025-05-28','cs.LG','模型微调、优化理论','http://arxiv.org/pdf/2505.22355v1','本文研究了参数高效微调（PEFT）方法在性能和计算资源消耗方面与完全微调（FFT）方法的比较。研究发现，虽然PEFT在某些基准测试上可以取得竞争性结果，但在复杂任务中（如推理和基于指令的微调）性能不及FFT。通过优化理论比较了PEFT和FFT的表示能力和鲁棒性，理论上证明了PEFT是FFT的严格子集。'),('2505.22356v1','Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings','Deploying machine learning models in safety-critical domains poses a key\nchallenge: ensuring reliable model performance on downstream user data without\naccess to ground truth labels for direct validation. We propose the suitability\nfilter, a novel framework designed to detect performance deterioration by\nutilizing suitability signals -- model output features that are sensitive to\ncovariate shifts and indicative of potential prediction errors. The suitability\nfilter evaluates whether classifier accuracy on unlabeled user data shows\nsignificant degradation compared to the accuracy measured on the labeled test\ndataset. Specifically, it ensures that this degradation does not exceed a\npre-specified margin, which represents the maximum acceptable drop in accuracy.\nTo achieve reliable performance evaluation, we aggregate suitability signals\nfor both test and user data and compare these empirical distributions using\nstatistical hypothesis testing, thus providing insights into decision\nuncertainty. Our modular method adapts to various models and domains. Empirical\nevaluations across different classification tasks demonstrate that the\nsuitability filter reliably detects performance deviations due to covariate\nshift. This enables proactive mitigation of potential failures in high-stakes\napplications.','Angéline Pouget, Mohammad Yaghini, Stephan Rabanser, Nicolas Papernot','2025-05-28','cs.LG','机器学习模型部署、性能评估、决策不确定性','http://arxiv.org/pdf/2505.22356v1','该论文提出了适用性过滤器，一个新颖的框架，用于检测模型性能下降，通过利用适用性信号来评估分类器在未标记用户数据上的准确性。通过统计假设检验比较测试数据和用户数据的适用性信号，以提供决策不确定性的见解。实证评估表明，适用性过滤器可可靠地检测由于协变量转移导致的性能偏差，从而在高风险应用中实现潜在故障的积极缓解。'),('2505.22358v1','Budget-Adaptive Adapter Tuning in Orthogonal Subspaces for Continual Learning in LLMs','Large language models (LLMs) often suffer from catastrophic forgetting in\ncontinual learning (CL) scenarios, where performance on previously learned\ntasks degrades severely while training on sequentially arriving tasks. Although\npioneering CL approaches using orthogonal subspaces can mitigate task\ninterference, they typically employ fixed budget allocation, neglecting the\nvarying complexity across tasks and layers. Besides, recent budget-adaptive\ntuning methods for LLMs often adopt multi-stage paradigms that decouple\noptimization and budget allocation. Such decoupling results in potential\nmisalignment, which hinders those approaches\\\' practical application in CL\nscenarios. To address these limitations, we propose OA-Adapter, a novel\nparameter-efficient approach for continual learning in LLMs that unifies\ndynamic budget adaptation with orthogonal subspace learning in a single\nend-to-end training stage. Specifically, OA-Adapter introduces a dynamic\nbottleneck dimension adaptation mechanism that simultaneously allocates an\nefficient parameter budget and optimizes task objectives without misalignment.\nTo effectively preserve previously acquired knowledge while coordinating with\nthe dynamic budget allocation, orthogonal constraints are applied specifically\nbetween the parameter subspace of the current task and the dynamically\nallocated parameter subspaces of historical tasks. Experimental results on\ncontinual learning benchmarks demonstrate that OA-Adapter outperforms\nstate-of-the-art methods in both accuracy and parameter efficiency, achieving\nhigher average accuracy while using 58.5% fewer parameters on the standard CL\nbenchmark.','Zhiyi Wan, Wanrou Du, Liang Li, Miao Pan, Xiaoqi Qin','2025-05-28','cs.LG','大型语言模型（LLM）','http://arxiv.org/pdf/2505.22358v1','该论文提出了一种新颖的参数高效的方法 OA-Adapter，用于大型语言模型在持续学习中的应用，通过统一动态预算适应和正交子空间学习，以提高在连续学习场景下的性能表现。'),('2505.22362v1','Directed Homophily-Aware Graph Neural Network','Graph Neural Networks (GNNs) have achieved significant success in various\nlearning tasks on graph-structured data. Nevertheless, most GNNs struggle to\ngeneralize to heterophilic neighborhoods. Additionally, many GNNs ignore the\ndirectional nature of real-world graphs, resulting in suboptimal performance on\ndirected graphs with asymmetric structures. In this work, we propose Directed\nHomophily-aware Graph Neural Network (DHGNN), a novel framework that addresses\nthese limitations by incorporating homophily-aware and direction-sensitive\ncomponents. DHGNN employs a resettable gating mechanism to adaptively modulate\nmessage contributions based on homophily levels and informativeness, and a\nstructure-aware noise-tolerant fusion module to effectively integrate node\nrepresentations from the original and reverse directions. Extensive experiments\non both homophilic and heterophilic directed graph datasets demonstrate that\nDHGNN outperforms state-of-the-art methods in node classification and link\nprediction. In particular, DHGNN improves over the best baseline by up to\n15.07% in link prediction. Our analysis further shows that the gating mechanism\ncaptures directional homophily gaps and fluctuating homophily across layers,\nproviding deeper insights into message-passing behavior on complex graph\nstructures.','Aihu Zhang, Jiaxing Xu, Mengcheng Lan, Shili Xiang, Yiping Ke','2025-05-28','cs.LG','图神经网络 (GNN)','http://arxiv.org/pdf/2505.22362v1','该论文提出了一种新的框架 DHGNN，用于解决现有 GNN 在处理异质邻域和有向图时的挑战。通过引入同质性感知和方向敏感组件，DHGNN 在节点分类和链接预测任务上表现优于现有方法。'),('2505.22368v1','AgentDNS: A Root Domain Naming System for LLM Agents','The rapid evolution of Large Language Model (LLM) agents has highlighted\ncritical challenges in cross-vendor service discovery, interoperability, and\ncommunication. Existing protocols like model context protocol and\nagent-to-agent protocol have made significant strides in standardizing\ninteroperability between agents and tools, as well as communication among\nmulti-agents. However, there remains a lack of standardized protocols and\nsolutions for service discovery across different agent and tool vendors. In\nthis paper, we propose AgentDNS, a root domain naming and service discovery\nsystem designed to enable LLM agents to autonomously discover, resolve, and\nsecurely invoke third-party agent and tool services across organizational and\ntechnological boundaries. Inspired by the principles of the traditional DNS,\nAgentDNS introduces a structured mechanism for service registration, semantic\nservice discovery, secure invocation, and unified billing. We detail the\narchitecture, core functionalities, and use cases of AgentDNS, demonstrating\nits potential to streamline multi-agent collaboration in real-world scenarios.\nThe source code will be published on https://github.com/agentdns.','Enfang Cui, Yujun Cheng, Rui She, Dan Liu, Zhiyuan Liang, Minxin Guo, Tianzheng Li, Qian Wei, Wenjuan Xing, Zhijie Zhong','2025-05-28','cs.AI','大型语言模型(LLM)、服务发现、人工智能工具集成','http://arxiv.org/pdf/2505.22368v1','本文提出了AgentDNS，一个根域命名和服务发现系统，旨在使LLM代理能够自主发现、解析和安全调用跨组织和技术边界的第三方代理和工具服务。通过结构化的服务注册、语义服务发现、安全调用和统一计费机制，AgentDNS有望简化实际场景中多代理协作。'),('2505.22370v1','SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting','Continual Learning requires a model to learn multiple tasks in sequence while\nmaintaining both stability:preserving knowledge from previously learned tasks,\nand plasticity:effectively learning new tasks. Gradient projection has emerged\nas an effective and popular paradigm in CL, where it partitions the gradient\nspace of previously learned tasks into two orthogonal subspaces: a primary\nsubspace and a minor subspace. New tasks are learned effectively within the\nminor subspace, thereby reducing interference with previously acquired\nknowledge. However, existing Gradient Projection methods struggle to achieve an\noptimal balance between plasticity and stability, as it is hard to\nappropriately partition the gradient space. In this work, we consider a\ncontinual learning paradigm based on Low-Rank Adaptation, which has gained\nconsiderable attention due to its efficiency and wide applicability, and\npropose a novel approach for continual learning, called SplitLoRA. We first\nprovide a theoretical analysis of how subspace partitioning affects model\nstability and plasticity. Informed by this analysis, we then introduce an\neffective method that derives the optimal partition of the gradient space for\npreviously learned tasks. This approach effectively balances stability and\nplasticity in continual learning. Experimental results on multiple datasets\ndemonstrate that the proposed method achieves state-of-the-art performance.','Haomiao Qiu, Miao Zhang, Ziyue Qiao, Weili Guan, Min Zhang, Liqiang Nie','2025-05-28','cs.LG','持续学习 (Continual Learning)','http://arxiv.org/pdf/2505.22370v1','该论文提出了一种基于低秩适应的持续学习范式，称为SplitLoRA，通过有效地划分梯度空间来平衡模型的稳定性和可塑性。实验结果表明，该方法在多个数据集上实现了最先进的性能。'),('2505.22375v1','Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition','This work presents Pangu Embedded, an efficient Large Language Model (LLM)\nreasoner developed on Ascend Neural Processing Units (NPUs), featuring flexible\nfast and slow thinking capabilities. Pangu Embedded addresses the significant\ncomputational costs and inference latency challenges prevalent in existing\nreasoning-optimized LLMs. We propose a two-stage training framework for its\nconstruction. In Stage 1, the model is finetuned via an iterative distillation\nprocess, incorporating inter-iteration model merging to effectively aggregate\ncomplementary knowledge. This is followed by reinforcement learning on Ascend\nclusters, optimized by a latency-tolerant scheduler that combines stale\nsynchronous parallelism with prioritized data queues. The RL process is guided\nby a Multi-source Adaptive Reward System (MARS), which generates dynamic,\ntask-specific reward signals using deterministic metrics and lightweight LLM\nevaluators for mathematics, coding, and general problem-solving tasks. Stage 2\nintroduces a dual-system framework, endowing Pangu Embedded with a \"fast\" mode\nfor routine queries and a deeper \"slow\" mode for complex inference. This\nframework offers both manual mode switching for user control and an automatic,\ncomplexity-aware mode selection mechanism that dynamically allocates\ncomputational resources to balance latency and reasoning depth. Experimental\nresults on benchmarks including AIME 2024, GPQA, and LiveCodeBench demonstrate\nthat Pangu Embedded with 7B parameters, outperforms similar-size models like\nQwen3-8B and GLM4-9B. It delivers rapid responses and state-of-the-art\nreasoning quality within a single, unified model architecture, highlighting a\npromising direction for developing powerful yet practically deployable LLM\nreasoners.','Hanting Chen, Yasheng Wang, Kai Han, Dong Li, Lin Li, Zhenni Bi, Jinpeng Li, Haoyu Wang, Fei Mi, Mingjian Zhu, Bin Wang, Kaikai Song, Yifei Fu, Xu He, Yu Luo, Chong Zhu, Quan He, Xueyu Wu, Wei He, Hailin Hu, Yehui Tang, Dacheng Tao, Xinghao Chen, Yunhe Wang, Other Contributors','2025-05-28','cs.CL','LLM (Large Language Model)','http://arxiv.org/pdf/2505.22375v1','该论文介绍了 Pangu Embedded，这是一种基于Ascend神经处理单元开发的高效大型语言模型（LLM）推理器，具有灵活的快速和慢速思考能力。通过两阶段训练框架构建了Pangu Embedded，通过迭代蒸馏过程进行微调，并在Ascend集群上进行强化学习，优化了延迟容忍调度器。实验结果表明，Pangu Embedded在AIME 2024、GPQA和LiveCodeBench等基准测试中表现优异。'),('2505.22387v1','DAM: Domain-Aware Module for Multi-Domain Dataset Condensation','Dataset Condensation (DC) has emerged as a promising solution to mitigate the\ncomputational and storage burdens associated with training deep learning\nmodels. However, existing DC methods largely overlook the multi-domain nature\nof modern datasets, which are increasingly composed of heterogeneous images\nspanning multiple domains. In this paper, we extend DC and introduce\nMulti-Domain Dataset Condensation (MDDC), which aims to condense data that\ngeneralizes across both single-domain and multi-domain settings. To this end,\nwe propose the Domain-Aware Module (DAM), a training-time module that embeds\ndomain-related features into each synthetic image via learnable spatial masks.\nAs explicit domain labels are mostly unavailable in real-world datasets, we\nemploy frequency-based pseudo-domain labeling, which leverages low-frequency\namplitude statistics. DAM is only active during the condensation process, thus\npreserving the same images per class (IPC) with prior methods. Experiments show\nthat DAM consistently improves in-domain, out-of-domain, and cross-architecture\nperformance over baseline dataset condensation methods.','Jaehyun Choi, Gyojin Han, Dong-Jae Lee, Sunghyun Baek, Junmo Kim','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22387v1','本文介绍了一种新的多域数据集压缩方法，称为多域数据集压缩（MDDC），旨在压缩能够在单域和多域环境下泛化的数据。作者提出了一种培训时模块，称为领域感知模块（DAM），通过可学习的空间掩模将领域相关特征嵌入到每个合成图像中。实验证明，DAM相对于基线数据集压缩方法在域内、域外和跨架构性能上都有显著改进。'),('2505.22389v1','Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning','Continual Learning (CL) aims to enable models to continuously acquire new\nknowledge from a sequence of tasks with avoiding the forgetting of learned\ninformation. However, existing CL methods only rely on the parameters of the\nmost recent task for inference, which makes them susceptible to catastrophic\nforgetting. Inspired by the recent success of model merging techniques, we\npropose \\textbf{Perturb-and-Merge (P\\&M)}, a novel continual learning framework\nthat integrates model merging into the CL paradigm to mitigate forgetting.\nSpecifically, after training on each task, P\\&M constructs a new model by\nforming a convex combination of the previous model and the newly trained\ntask-specific model. Through theoretical analysis, we minimize the total loss\nincrease across all tasks and derive an analytical solution for the optimal\nmerging coefficient. To further improve the performance of the merged model, we\nobserve that the degradation introduced during merging can be alleviated by a\nregularization term composed of the task vector and the Hessian matrix of the\nloss function. Interestingly, we show that this term can be efficiently\napproximated using second-order symmetric finite differences, and a stochastic\nperturbation strategy along the task vector direction is accordingly devised\nwhich incurs no additional forward or backward passes while providing an\neffective approximation of the regularization term. Finally, we combine P\\&M\nwith LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead.\nOur proposed approach achieves state-of-the-art performance on several\ncontinual learning benchmark datasets.','Haomiao Qiu, Miao Zhang, Ziyue Qiao, Liqiang Nie','2025-05-28','cs.LG','持续学习 (Continual Learning)','http://arxiv.org/pdf/2505.22389v1','该论文提出了一种新的持续学习框架Perturb-and-Merge (P&M)，通过模型合并技术来减轻遗忘问题，结合了理论分析和优化方法，最终在多个持续学习基准数据集上取得了最先进的性能。'),('2505.22411v1','Mitigating Overthinking in Large Reasoning Models via Manifold Steering','Recent advances in Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in solving complex tasks such as mathematics and coding. However,\nthese models frequently exhibit a phenomenon known as overthinking during\ninference, characterized by excessive validation loops and redundant\ndeliberation, leading to substantial computational overheads. In this paper, we\naim to mitigate overthinking by investigating the underlying mechanisms from\nthe perspective of mechanistic interpretability. We first showcase that the\ntendency of overthinking can be effectively captured by a single direction in\nthe model\\\'s activation space and the issue can be eased by intervening the\nactivations along this direction. However, this efficacy soon reaches a plateau\nand even deteriorates as the intervention strength increases. We therefore\nsystematically explore the activation space and find that the overthinking\nphenomenon is actually tied to a low-dimensional manifold, which indicates that\nthe limited effect stems from the noises introduced by the high-dimensional\nsteering direction. Based on this insight, we propose Manifold Steering, a\nnovel approach that elegantly projects the steering direction onto the\nlow-dimensional activation manifold given the theoretical approximation of the\ninterference noise. Extensive experiments on DeepSeek-R1 distilled models\nvalidate that our method reduces output tokens by up to 71% while maintaining\nand even improving the accuracy on several mathematical benchmarks. Our method\nalso exhibits robust cross-domain transferability, delivering consistent token\nreduction performance in code generation and knowledge-based QA tasks. Code is\navailable at: https://github.com/Aries-iai/Manifold_Steering.','Yao Huang, Huanran Chen, Shouwei Ruan, Yichi Zhang, Xingxing Wei, Yinpeng Dong','2025-05-28','cs.LG','LLM (Large Reasoning Models)','http://arxiv.org/pdf/2505.22411v1','该论文研究了大型推理模型中存在的过度思考现象，并提出了一种名为Manifold Steering的方法来减轻这一问题。他们通过在激活空间中干预激活来有效捕捉和减轻过度思考现象，最终在数学基准测试中减少了输出标记高达71％，同时在代码生成和基于知识的问答任务中保持甚至提高了准确性。'),('2505.22425v1','Scaling Reasoning without Attention','Large language models (LLMs) have made significant advances in complex\nreasoning tasks, yet they remain bottlenecked by two core challenges:\narchitectural inefficiency due to reliance on Transformers, and a lack of\nstructured fine-tuning for high-difficulty domains. We introduce \\ourmodel, an\nattention-free language model that addresses both issues through architectural\nand data-centric innovations. Built on the state space dual (SSD) layers of\nMamba-2, our model eliminates the need for self-attention and key-value\ncaching, enabling fixed-memory, constant-time inference. To train it for\ncomplex reasoning, we propose a two-phase curriculum fine-tuning strategy based\non the \\textsc{PromptCoT} synthesis paradigm, which generates pedagogically\nstructured problems via abstract concept selection and rationale-guided\ngeneration. On benchmark evaluations, \\ourmodel-7B outperforms strong\nTransformer and hybrid models of comparable scale, and even surpasses the much\nlarger Gemma3-27B by 2.6\\% on AIME 24, 0.6\\% on AIME 25, and 3.0\\% on\nLivecodebench. These results highlight the potential of state space models as\nefficient and scalable alternatives to attention-based architectures for\nhigh-capacity reasoning.','Xueliang Zhao, Wei Wu, Lingpeng Kong','2025-05-28','cs.LG','大语言模型 (LLM)','http://arxiv.org/pdf/2505.22425v1','该论文介绍了一种名为\\ourmodel 的无注意力语言模型，通过架构和数据创新解决了大语言模型的两个核心挑战。通过基于\\textsc{PromptCoT}综合范式的两阶段课程微调策略，该模型在基准评估中表现优异，超过了规模相当的强Transformer和混合模型，甚至在AIME 24上超过了规模更大的Gemma3-27B。'),('2505.22430v1','RAG-Zeval: Towards Robust and Interpretable Evaluation on RAG Responses through End-to-End Rule-Guided Reasoning','Robust evaluation is critical for deploying trustworthy retrieval-augmented\ngeneration (RAG) systems. However, current LLM-based evaluation frameworks\npredominantly rely on directly prompting resource-intensive models with complex\nmulti-stage prompts, underutilizing models\\\' reasoning capabilities and\nintroducing significant computational cost. In this paper, we present RAG-Zeval\n(RAG-Zero Evaluator), a novel end-to-end framework that formulates faithfulness\nand correctness evaluation as a rule-guided reasoning task. Our approach trains\nevaluators with reinforcement learning, facilitating compact models to generate\ncomprehensive and sound assessments with detailed explanation in one-pass. We\nintroduce a ranking-based outcome reward mechanism, using preference judgments\nrather than absolute scores, to address the challenge of obtaining precise\npointwise reward signals. To this end, we synthesize the ranking references by\ngenerating quality-controlled responses with zero human annotation. Experiments\ndemonstrate RAG-Zeval\\\'s superior performance, achieving the strongest\ncorrelation with human judgments and outperforming baselines that rely on LLMs\nwith 10-100 times more parameters. Our approach also exhibits superior\ninterpretability in response evaluation.','Kun Li, Yunxiang Li, Tianhua Zhang, Hongyin Luo, Xixin Wu, James Glass, Helen Meng','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22430v1','本文提出了一种名为RAG-Zeval的新型端到端框架，将忠实度和正确性评估作为一种规则引导的推理任务，通过强化学习训练评估器，使得紧凑的模型能够在一次传递中生成全面且合理的评估，并引入基于排名的结果奖励机制来解决获取精确点对点奖励信号的挑战。实验证明RAG-Zeval在与人类判断的最强相关性方面表现出色，优于依赖具有10-100倍参数的LLMs的基准线。'),('2505.22438v1','Synonymous Variational Inference for Perceptual Image Compression','Recent contributions of semantic information theory reveal the set-element\nrelationship between semantic and syntactic information, represented as\nsynonymous relationships. In this paper, we propose a synonymous variational\ninference (SVI) method based on this synonymity viewpoint to re-analyze the\nperceptual image compression problem. It takes perceptual similarity as a\ntypical synonymous criterion to build an ideal synonymous set (Synset), and\napproximate the posterior of its latent synonymous representation with a\nparametric density by minimizing a partial semantic KL divergence. This\nanalysis theoretically proves that the optimization direction of perception\nimage compression follows a triple tradeoff that can cover the existing\nrate-distortion-perception schemes. Additionally, we introduce synonymous image\ncompression (SIC), a new image compression scheme that corresponds to the\nanalytical process of SVI, and implement a progressive SIC codec to fully\nleverage the model\\\'s capabilities. Experimental results demonstrate comparable\nrate-distortion-perception performance using a single progressive SIC codec,\nthus verifying the effectiveness of our proposed analysis method.','Zijian Liang, Kai Niu, Changshuo Wang, Jin Xu, Ping Zhang','2025-05-28','cs.IT','图像识别','http://arxiv.org/pdf/2505.22438v1','本文提出了一种基于同义视角的同义变分推断（SVI）方法，重新分析了感知图像压缩问题。通过最小化部分语义KL散度来近似其潜在同义表示的后验概率，理论上证明了感知图像压缩的优化方向遵循一种三重权衡，可以覆盖现有的速率-失真-感知方案。实验结果表明，使用单个渐进SIC编解码器可以实现可比的速率-失真-感知性能，从而验证了所提出的分析方法的有效性。'),('2505.22440v1','Data-Driven Antenna Miniaturization: A Knowledge-Based System Integrating Quantum PSO and Predictive Machine Learning Models','The rapid evolution of wireless technologies necessitates automated design\nframeworks to address antenna miniaturization and performance optimization\nwithin constrained development cycles. This study demonstrates a machine\nlearning enhanced workflow integrating Quantum-Behaved Dynamic Particle Swarm\nOptimization (QDPSO) with ANSYS HFSS simulations to accelerate antenna design.\nThe QDPSO algorithm autonomously optimized loop dimensions in 11.53 seconds,\nachieving a resonance frequency of 1.4208 GHz a 12.7 percent reduction compared\nto conventional 1.60 GHz designs. Machine learning models (SVM, Random Forest,\nXGBoost, and Stacked ensembles) predicted resonance frequencies in 0.75 seconds\nusing 936 simulation datasets, with stacked models showing superior training\naccuracy (R2=0.9825) and SVM demonstrating optimal validation performance\n(R2=0.7197). The complete design cycle, encompassing optimization, prediction,\nand ANSYS validation, required 12.42 minutes on standard desktop hardware\n(Intel i5-8500, 16GB RAM), contrasting sharply with the 50-hour benchmark of\nPSADEA-based approaches. This 240 times of acceleration eliminates traditional\ntrial-and-error methods that often extend beyond seven expert-led days. The\nsystem enables precise specifications of performance targets with automated\ngeneration of fabrication-ready parameters, particularly benefiting compact\nconsumer devices requiring rapid frequency tuning. By bridging AI-driven\noptimization with CAD validation, this framework reduces engineering workloads\nwhile ensuring production-ready designs, establishing a scalable paradigm for\nnext-generation RF systems in 6G and IoT applications.','Khan Masood Parvez, Sk Md Abidar Rahaman, Ali Shiri Sichani','2025-05-28','cs.LG','无线通信技术、天线设计、机器学习增强设计。','http://arxiv.org/pdf/2505.22440v1','该论文介绍了一种结合量子行为动态粒子群优化（QDPSO）和ANSYS HFSS仿真的机器学习增强工作流程，用于加速天线设计。通过机器学习模型（SVM、Random Forest、XGBoost和Stacked ensembles）预测共振频率，实现了天线设计的优化和加速。'),('2505.22441v1','Can NeRFs See without Cameras?','Neural Radiance Fields (NeRFs) have been remarkably successful at\nsynthesizing novel views of 3D scenes by optimizing a volumetric scene\nfunction. This scene function models how optical rays bring color information\nfrom a 3D object to the camera pixels. Radio frequency (RF) or audio signals\ncan also be viewed as a vehicle for delivering information about the\nenvironment to a sensor. However, unlike camera pixels, an RF/audio sensor\nreceives a mixture of signals that contain many environmental reflections (also\ncalled \"multipath\"). Is it still possible to infer the environment using such\nmultipath signals? We show that with redesign, NeRFs can be taught to learn\nfrom multipath signals, and thereby \"see\" the environment. As a grounding\napplication, we aim to infer the indoor floorplan of a home from sparse WiFi\nmeasurements made at multiple locations inside the home. Although a difficult\ninverse problem, our implicitly learnt floorplans look promising, and enables\nforward applications, such as indoor signal prediction and basic ray tracing.','Chaitanya Amballa, Sattwik Basu, Yu-Lin Wei, Zhijian Yang, Mehmet Ergezer, Romit Roy Choudhury','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22441v1','该论文研究了如何通过重新设计NeRFs来从多径信号中学习环境信息，以推断室内家庭的地板平面，并展示了潜在的应用前景。'),('2505.22442v1','SOReL and TOReL: Two Methods for Fully Offline Reinforcement Learning','Sample efficiency remains a major obstacle for real world adoption of\nreinforcement learning (RL): success has been limited to settings where\nsimulators provide access to essentially unlimited environment interactions,\nwhich in reality are typically costly or dangerous to obtain. Offline RL in\nprinciple offers a solution by exploiting offline data to learn a near-optimal\npolicy before deployment. In practice, however, current offline RL methods rely\non extensive online interactions for hyperparameter tuning, and have no\nreliable bound on their initial online performance. To address these two\nissues, we introduce two algorithms. Firstly, SOReL: an algorithm for safe\noffline reinforcement learning. Using only offline data, our Bayesian approach\ninfers a posterior over environment dynamics to obtain a reliable estimate of\nthe online performance via the posterior predictive uncertainty. Crucially, all\nhyperparameters are also tuned fully offline. Secondly, we introduce TOReL: a\ntuning for offline reinforcement learning algorithm that extends our\ninformation rate based offline hyperparameter tuning methods to general offline\nRL approaches. Our empirical evaluation confirms SOReL\\\'s ability to accurately\nestimate regret in the Bayesian setting whilst TOReL\\\'s offline hyperparameter\ntuning achieves competitive performance with the best online hyperparameter\ntuning methods using only offline data. Thus, SOReL and TOReL make a\nsignificant step towards safe and reliable offline RL, unlocking the potential\nfor RL in the real world. Our implementations are publicly available:\nhttps://github.com/CWibault/sorel\\_torel.','Mattie Fellows, Clarisse Wibault, Uljad Berdica, Johannes Forkel, Jakob N. Foerster, Michael A. Osborne','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22442v1','该论文介绍了两种算法，SOReL 和 TOReL，用于安全和可靠的离线强化学习。SOReL 使用贝叶斯方法推断环境动态的后验概率，通过后验预测不确定性可靠地估计在线性能，同时完全离线调整所有超参数。TOReL 则是一种离线强化学习调参算法，扩展了基于信息速率的离线超参数调整方法。实证评估表明，SOReL 在贝叶斯设置下能够准确估计遗憾，而TOReL 的离线超参数调整能够使用仅离线数据达到与最佳在线超参数调整方法竞争性能。'),('2505.22445v1','NFR: Neural Feature-Guided Non-Rigid Shape Registration','In this paper, we propose a novel learning-based framework for 3D shape\nregistration, which overcomes the challenges of significant non-rigid\ndeformation and partiality undergoing among input shapes, and, remarkably,\nrequires no correspondence annotation during training. Our key insight is to\nincorporate neural features learned by deep learning-based shape matching\nnetworks into an iterative, geometric shape registration pipeline. The\nadvantage of our approach is two-fold -- On one hand, neural features provide\nmore accurate and semantically meaningful correspondence estimation than\nspatial features (e.g., coordinates), which is critical in the presence of\nlarge non-rigid deformations; On the other hand, the correspondences are\ndynamically updated according to the intermediate registrations and filtered by\nconsistency prior, which prominently robustify the overall pipeline. Empirical\nresults show that, with as few as dozens of training shapes of limited\nvariability, our pipeline achieves state-of-the-art results on several\nbenchmarks of non-rigid point cloud matching and partial shape matching across\nvarying settings, but also delivers high-quality correspondences between unseen\nchallenging shape pairs that undergo both significant extrinsic and intrinsic\ndeformations, in which case neither traditional registration methods nor\nintrinsic methods work.','Puhua Jiang, Zhangquan Chen, Mingze Sun, Ruqi Huang','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22445v1','本文提出了一种新颖的基于学习的3D形状配准框架，克服了输入形状之间的显著非刚性变形和局部性的挑战，并且在训练过程中不需要对应标注。他们的关键洞察是将深度学习形状匹配网络学习的神经特征融入迭代的几何形状配准流程中。实验结果表明，他们的方法在几个非刚性点云匹配和局部形状匹配基准上取得了最先进的结果。'),('2505.22450v1','Position: All Current Generative Fidelity and Diversity Metrics are Flawed','Any method\\\'s development and practical application is limited by our ability\nto measure its reliability. The popularity of generative modeling emphasizes\nthe importance of good synthetic data metrics. Unfortunately, previous works\nhave found many failure cases in current metrics, for example lack of outlier\nrobustness and unclear lower and upper bounds. We propose a list of desiderata\nfor synthetic data metrics, and a suite of sanity checks: carefully chosen\nsimple experiments that aim to detect specific and known generative modeling\nfailure modes. Based on these desiderata and the results of our checks, we\narrive at our position: all current generative fidelity and diversity metrics\nare flawed. This significantly hinders practical use of synthetic data. Our aim\nis to convince the research community to spend more effort in developing\nmetrics, instead of models. Additionally, through analyzing how current metrics\nfail, we provide practitioners with guidelines on how these metrics should\n(not) be used.','Ossi Räisä, Boris van Breugel, Mihaela van der Schaar','2025-05-28','cs.LG','生成模型','http://arxiv.org/pdf/2505.22450v1','该论文提出了一系列合成数据度量标准的要求，并通过一系列实验检查发现当前的生成模型的可信度和多样性度量标准存在缺陷，阻碍了合成数据的实际应用。'),('2505.22451v1','AI Mathematician: Towards Fully Automated Frontier Mathematical Research','Large Reasoning Models (LRMs) have made significant progress in mathematical\ncapabilities in recent times. However, these successes have been primarily\nconfined to competition-level problems. In this work, we propose AI\nMathematician (AIM) framework, which harnesses the reasoning strength of LRMs\nto support frontier mathematical research. We have identified two critical\nchallenges of mathematical research compared to competition, {\\it the intrinsic\ncomplexity of research problems} and {\\it the requirement of procedural rigor}.\nTo address these challenges, AIM incorporates two core strategies: an\nexploration mechanism to foster longer solution paths, and the pessimistic\nreasonable verification method to ensure reliability.\n  This early version of AIM already exhibits strong capability in tackling\nresearch-level tasks. We conducted extensive experiments across several\nreal-world mathematical topics and obtained promising results. AIM is able to\nautonomously construct substantial portions of proofs and uncover non-trivial\ninsights within each research area. These findings highlight the potential of\nLRMs in mathematical discovery and suggest that LRM-based agent systems could\nsignificantly accelerate mathematical research in the future.','Yuanhang Liu, Yanxing Huang, Yanqiao Wang, Peng Li, Yang Liu','2025-05-28','cs.AI','LLM（大型推理模型）','http://arxiv.org/pdf/2505.22451v1','该论文提出了AI Mathematician (AIM) 框架，利用大型推理模型（LRMs）的推理能力支持前沿数学研究。通过引入探索机制和悲观合理验证方法，AIM能够在数学研究领域展现出强大的能力。'),('2505.22453v1','Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO','Improving Multi-modal Large Language Models (MLLMs) in the post-training\nstage typically relies on supervised fine-tuning (SFT) or reinforcement\nlearning (RL). However, these supervised methods require expensive and manually\nannotated multi-modal data--an ultimately unsustainable resource. While recent\nefforts have explored unsupervised post-training, their methods are complex and\ndifficult to iterate. In this work, we are the first to investigate the use of\nGRPO, a stable and scalable online RL algorithm, for enabling continual\nself-improvement without any external supervision. We propose MM-UPT, a simple\nyet effective framework for unsupervised post-training of MLLMs. MM-UPT builds\nupon GRPO, replacing traditional reward signals with a self-rewarding mechanism\nbased on majority voting over multiple sampled responses. Our experiments\ndemonstrate that MM-UPT significantly improves the reasoning ability of\nQwen2.5-VL-7B (e.g., 66.3 %$\\rightarrow$72.9 % on MathVista, 62.9\n%$\\rightarrow$68.7 % on We-Math), using standard dataset without ground truth\nlabels. MM-UPT also outperforms prior unsupervised baselines and even\napproaches the results of supervised GRPO. Furthermore, we show that\nincorporating synthetic questions, generated solely by MLLM itself, can boost\nperformance as well, highlighting a promising approach for scalable\nself-improvement. Overall, MM-UPT offers a new paradigm for continual,\nautonomous enhancement of MLLMs in the absence of external supervision. Our\ncode is available at https://github.com/waltonfuture/MM-UPT.','Lai Wei, Yuting Li, Chen Wang, Yue Wang, Linghe Kong, Weiran Huang, Lichao Sun','2025-05-28','cs.CL','LLM（Large Language Models）','http://arxiv.org/pdf/2505.22453v1','该论文提出了一种名为MM-UPT的简单而有效的框架，用于无监督后训练多模态大型语言模型（MLLMs），通过使用稳定且可扩展的在线RL算法GRPO，在没有外部监督的情况下实现持续自我改进。实验结果表明，MM-UPT显著提高了Qwen2.5-VL-7B的推理能力，并超越了先前的无监督基线方法。'),('2505.22454v1','Depth-Based Matrix Classification for the HHL Quantum Algorithm','Under the nearing error-corrected era of quantum computing, it is necessary\nto understand the suitability of certain post-NISQ algorithms for practical\nproblems. One of the most promising, applicable and yet difficult to implement\nin practical terms is the Harrow, Hassidim and Lloyd (HHL) algorithm for linear\nsystems of equations. An enormous number of problems can be expressed as linear\nsystems of equations, from Machine Learning to fluid dynamics. However, in most\ncases, HHL will not be able to provide a practical, reasonable solution to\nthese problems. This paper\\\'s goal inquires about whether problems can be\nlabeled using Machine Learning classifiers as suitable or unsuitable for HHL\nimplementation when some numerical information about the problem is known\nbeforehand. This work demonstrates that training on significantly\nrepresentative data distributions is critical to achieve good classifications\nof the problems based on the numerical properties of the matrix representing\nthe system of equations. Accurate classification is possible through\nMulti-Layer Perceptrons, although with careful design of the training data\ndistribution and classifier parameters.','Mark Danza, Sonia Lopez Alarcon, Cory Merkel','2025-05-28','quant-ph','机器学习','http://arxiv.org/pdf/2505.22454v1','该论文研究了在量子计算的错误纠正时代，了解后NISQ算法对实际问题的适用性的重要性，重点关注Harrow, Hassidim和Lloyd（HHL）算法在解线性方程组方面的应用。通过使用机器学习分类器对问题进行标记，以确定其是否适合HHL实现。'),('2505.22457v1','Fostering Video Reasoning via Next-Event Prediction','Next-token prediction serves as the foundational learning task enabling\nreasoning in LLMs. But what should the learning task be when aiming to equip\nMLLMs with temporal reasoning capabilities over video inputs? Existing tasks\nsuch as video question answering often rely on annotations from humans or much\nstronger MLLMs, while video captioning tends to entangle temporal reasoning\nwith spatial information. To address this gap, we propose next-event prediction\n(NEP), a learning task that harnesses future video segments as a rich,\nself-supervised signal to foster temporal reasoning. We segment each video into\npast and future frames: the MLLM takes the past frames as input and predicts a\nsummary of events derived from the future frames, thereby encouraging the model\nto reason temporally in order to complete the task. To support this task, we\ncurate V1-33K, a dataset comprising 33,000 automatically extracted video\nsegments spanning diverse real-world scenarios. We further explore a range of\nvideo instruction-tuning strategies to study their effects on temporal\nreasoning. To evaluate progress, we introduce FutureBench to assess coherence\nin predicting unseen future events. Experiments validate that NEP offers a\nscalable and effective training paradigm for fostering temporal reasoning in\nMLLMs.','Haonan Wang, Hongfu Liu, Xiangyan Liu, Chao Du, Kenji Kawaguchi, Ye Wang, Tianyu Pang','2025-05-28','cs.CV','LLM (Language and Vision Models)','http://arxiv.org/pdf/2505.22457v1','本文提出了一种新的学习任务，即下一个事件预测（NEP），用于在视频输入上培养MLLM的时间推理能力。他们提出了一个新的数据集V1-33K，并探索了一系列视频指导调整策略来研究它们对时间推理的影响。实验证实NEP为MLLM中的时间推理提供了可扩展且有效的训练范式。'),('2505.22467v1','Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems','Large Language Model-based Multi-Agent Systems (MASs) have emerged as a\npowerful paradigm for tackling complex tasks through collaborative\nintelligence. Nevertheless, the question of how agents should be structurally\norganized for optimal cooperation remains largely unexplored. In this position\npaper, we aim to gently redirect the focus of the MAS research community toward\nthis critical dimension: develop topology-aware MASs for specific tasks.\nSpecifically, the system consists of three core components - agents,\ncommunication links, and communication patterns - that collectively shape its\ncoordination performance and efficiency. To this end, we introduce a\nsystematic, three-stage framework: agent selection, structure profiling, and\ntopology synthesis. Each stage would trigger new research opportunities in\nareas such as language models, reinforcement learning, graph learning, and\ngenerative modeling; together, they could unleash the full potential of MASs in\ncomplicated real-world applications. Then, we discuss the potential challenges\nand opportunities in the evaluation of multiple systems. We hope our\nperspective and framework can offer critical new insights in the era of agentic\nAI.','Jiaxi Yang, Mengqi Zhang, Yiqiao Jin, Hao Chen, Qingsong Wen, Lu Lin, Yi He, Weijie Xu, James Evans, Jindong Wang','2025-05-28','cs.MA','多智能体系统 (MAS)','http://arxiv.org/pdf/2505.22467v1','该论文探讨了基于大型语言模型的多智能体系统在协作智能方面的潜力，并提出了开发针对特定任务的拓扑感知型多智能体系统的重要性。论文介绍了一个系统性的三阶段框架，包括智能体选择、结构分析和拓扑合成，以激发在语言模型、强化学习、图学习和生成建模等领域的新研究机会，从而释放多智能体系统在复杂现实应用中的全部潜力。'),('2505.22474v1','Forecasting Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis','The forecasting of multivariate urban data presents a complex challenge due\nto the intricate dependencies between various urban metrics such as weather,\nair pollution, carbon intensity, and energy demand. This paper introduces a\nnovel multivariate time-series forecasting model that utilizes advanced Graph\nNeural Networks (GNNs) to capture spatial dependencies among different\ntime-series variables. The proposed model incorporates a decomposition-based\npreprocessing step, isolating trend, seasonal, and residual components to\nenhance the accuracy and interpretability of forecasts. By leveraging the\ndynamic capabilities of GNNs, the model effectively captures interdependencies\nand improves the forecasting performance. Extensive experiments on real-world\ndatasets, including electricity usage, weather metrics, carbon intensity, and\nair pollution data, demonstrate the effectiveness of the proposed approach\nacross various forecasting scenarios. The results highlight the potential of\nthe model to optimize smart infrastructure systems, contributing to\nenergy-efficient urban development and enhanced public well-being.','Amirhossein Sohrabbeig, Omid Ardakanian, Petr Musilek','2025-05-28','cs.LG','预测模型、图神经网络、智能基础设施优化','http://arxiv.org/pdf/2505.22474v1','该论文介绍了一种利用图神经网络（GNNs）进行多变量时间序列预测的新模型，通过分解预处理步骤来提高预测的准确性和可解释性，利用GNNs的动态能力有效捕捉变量间的相互依赖关系，实验结果表明该方法在不同预测场景下有效。'),('2505.22477v1','Human-Centered Human-AI Collaboration (HCHAC)','In the intelligent era, the interaction between humans and intelligent\nsystems fundamentally involves collaboration with autonomous intelligent\nagents. Human-AI Collaboration (HAC) represents a novel type of human-machine\nrelationship facilitated by autonomous intelligent machines equipped with AI\ntechnologies. In this paradigm, AI agents serve not only as auxiliary tools but\nalso as active teammates, partnering with humans to accomplish tasks\ncollaboratively. Human-centered AI (HCAI) emphasizes that humans play critical\nleadership roles in the collaboration. This human-led collaboration imparts new\ndimensions to the human-machine relationship, necessitating innovative research\nperspectives, paradigms, and agenda to address the unique challenges posed by\nHAC. This chapter delves into the essence of HAC from the human-centered\nperspective, outlining its core concepts and distinguishing features. It\nreviews the current research methodologies and research agenda within the HAC\nfield from the HCAI perspective, highlighting advancements and ongoing studies.\nFurthermore, a framework for human-centered HAC (HCHAC) is proposed by\nintegrating these reviews and analyses. A case study of HAC in the context of\nautonomous vehicles is provided, illustrating practical applications and the\nsynergistic interactions between humans and AI agents. Finally, it identifies\npotential future research directions aimed at enhancing the effectiveness,\nreliability, and ethical integration of human-centered HAC systems in diverse\ndomains.','Qi Gao, Wei Xu, Hanxi Pan, Mowei Shen, Zaifeng Gao','2025-05-28','cs.HC','人机协作','http://arxiv.org/pdf/2505.22477v1','该论文探讨了人工智能时代中人类与智能系统之间的互动，重点介绍了人工智能代理在协作中的作用，强调了人类在协作中的领导作用。论文提出了人类中心的人机协作框架，并通过自动驾驶车辆的案例研究展示了人类和人工智能代理之间的协同互动。'),('2505.22481v1','Hypothesis Testing in Imaging Inverse Problems','This paper proposes a framework for semantic hypothesis testing tailored to\nimaging inverse problems. Modern imaging methods struggle to support hypothesis\ntesting, a core component of the scientific method that is essential for the\nrigorous interpretation of experiments and robust interfacing with\ndecision-making processes. There are three main reasons why image-based\nhypothesis testing is challenging. First, the difficulty of using a single\nobservation to simultaneously reconstruct an image, formulate hypotheses, and\nquantify their statistical significance. Second, the hypotheses encountered in\nimaging are mostly of semantic nature, rather than quantitative statements\nabout pixel values. Third, it is challenging to control test error\nprobabilities because the null and alternative distributions are often unknown.\nOur proposed approach addresses these difficulties by leveraging concepts from\nself-supervised computational imaging, vision-language models, and\nnon-parametric hypothesis testing with e-values. We demonstrate our proposed\nframework through numerical experiments related to image-based phenotyping,\nwhere we achieve excellent power while robustly controlling Type I errors.','Yiming Xi, Konstantinos Zygalakis, Marcelo Pereyra','2025-05-28','stat.ML','图像识别','http://arxiv.org/pdf/2505.22481v1','本文提出了一个针对成像逆问题定制的语义假设检验框架。通过利用自监督计算成像、视觉-语言模型和使用 e 值的非参数假设检验等概念，解决了成像假设检验面临的困难。在与基于图像的表型分析相关的数值实验中，我们展示了我们提出的框架，实现了出色的功效同时稳健地控制了第一类错误。'),('2505.22483v1','A Closer Look at Multimodal Representation Collapse','We aim to develop a fundamental understanding of modality collapse, a\nrecently observed empirical phenomenon wherein models trained for multimodal\nfusion tend to rely only on a subset of the modalities, ignoring the rest. We\nshow that modality collapse happens when noisy features from one modality are\nentangled, via a shared set of neurons in the fusion head, with predictive\nfeatures from another, effectively masking out positive contributions from the\npredictive features of the former modality and leading to its collapse. We\nfurther prove that cross-modal knowledge distillation implicitly disentangles\nsuch representations by freeing up rank bottlenecks in the student encoder,\ndenoising the fusion-head outputs without negatively impacting the predictive\nfeatures from either modality. Based on the above findings, we propose an\nalgorithm that prevents modality collapse through explicit basis reallocation,\nwith applications in dealing with missing modalities. Extensive experiments on\nmultiple multimodal benchmarks validate our theoretical claims. Project page:\nhttps://abhrac.github.io/mmcollapse/.','Abhra Chaudhuri, Anjan Dutta, Tu Bui, Serban Georgescu','2025-05-28','cs.LG','多模态融合','http://arxiv.org/pdf/2505.22483v1','该论文研究了多模态融合中的模态崩溃现象，发现这种现象是由于一个模态的嘈杂特征与另一个模态的预测特征混合在一起，导致前者的预测特征被掩盖，最终导致模态崩溃。他们提出了一种通过交叉模态知识蒸馏来防止模态崩溃的算法，并在多个多模态基准上进行了验证。'),('2505.22486v1','Understanding Adversarial Training with Energy-based Models','We aim at using Energy-based Model (EBM) framework to better understand\nadversarial training (AT) in classifiers, and additionally to analyze the\nintrinsic generative capabilities of robust classifiers. By viewing standard\nclassifiers through an energy lens, we begin by analyzing how the energies of\nadversarial examples, generated by various attacks, differ from those of the\nnatural samples. The central focus of our work is to understand the critical\nphenomena of Catastrophic Overfitting (CO) and Robust Overfitting (RO) in AT\nfrom an energy perspective. We analyze the impact of existing AT approaches on\nthe energy of samples during training and observe that the behavior of the\n``delta energy\\\' -- change in energy between original sample and its adversarial\ncounterpart -- diverges significantly when CO or RO occurs. After a thorough\nanalysis of these energy dynamics and their relationship with overfitting, we\npropose a novel regularizer, the Delta Energy Regularizer (DER), designed to\nsmoothen the energy landscape during training. We demonstrate that DER is\neffective in mitigating both CO and RO across multiple benchmarks. We further\nshow that robust classifiers, when being used as generative models, have limits\nin handling trade-off between image quality and variability. We propose an\nimproved technique based on a local class-wise principal component analysis\n(PCA) and energy-based guidance for better class-specific initialization and\nadaptive stopping, enhancing sample diversity and generation quality.\nConsidering that we do not explicitly train for generative modeling, we achieve\na competitive Inception Score (IS) and Fr\\\\\'echet inception distance (FID)\ncompared to hybrid discriminative-generative models.','Mujtaba Hussain Mirza, Maria Rosaria Briglia, Filippo Bartolucci, Senad Beadini, Giuseppe Lisanti, Iacopo Masi','2025-05-28','cs.LG','生成模型','http://arxiv.org/pdf/2505.22486v1','该论文利用基于能量的模型框架来更好地理解分类器中的对抗训练，并分析了强健分类器的内在生成能力。他们通过能量的视角分析了对抗样本的能量与自然样本的能量之间的差异，重点研究了对抗训练中的 Catastrophic Overfitting (CO) 和 Robust Overfitting (RO) 等关键现象。他们提出了一种新的正则化器 Delta Energy Regularizer (DER)，有效地缓解了 CO 和 RO。'),('2505.22487v1','Effective Context in Neural Speech Models','Modern neural speech models benefit from having longer context, and many\napproaches have been proposed to increase the maximum context a model can use.\nHowever, few have attempted to measure how much context these models actually\nuse, i.e., the effective context. Here, we propose two approaches to measuring\nthe effective context, and use them to analyze different speech Transformers.\nFor supervised models, we find that the effective context correlates well with\nthe nature of the task, with fundamental frequency tracking, phone\nclassification, and word classification requiring increasing amounts of\neffective context. For self-supervised models, we find that effective context\nincreases mainly in the early layers, and remains relatively short -- similar\nto the supervised phone model. Given that these models do not use a long\ncontext during prediction, we show that HuBERT can be run in streaming mode\nwithout modification to the architecture and without further fine-tuning.','Yen Meng, Sharon Goldwater, Hao Tang','2025-05-28','cs.SD','语音处理','http://arxiv.org/pdf/2505.22487v1','本文提出了两种衡量神经语音模型有效上下文的方法，并用它们来分析不同的语音Transformer模型。研究发现，受监督模型的有效上下文与任务性质相关，而自监督模型的有效上下文主要在早期层增加，保持相对较短。'),('2505.22491v1','On the Surprising Effectiveness of Large Learning Rates under Standard Width Scaling','The dominant paradigm for training large-scale vision and language models is\nHe initialization and a single global learning rate (\\textit{standard\nparameterization}, SP). Despite its practical success, standard parametrization\nremains poorly understood from a theoretical perspective: Existing\ninfinite-width theory would predict instability under large learning rates and\nvanishing feature learning under stable learning rates. However, empirically\noptimal learning rates consistently decay much slower than theoretically\npredicted. By carefully studying neural network training dynamics, we\ndemonstrate that this discrepancy is not fully explained by finite-width\nphenomena such as catapult effects or a lack of alignment between weights and\nincoming activations. We instead show that the apparent contradiction can be\nfundamentally resolved by taking the loss function into account: In contrast to\nMean Squared Error (MSE) loss, we prove that under cross-entropy (CE) loss, an\nintermediate \\textit{controlled divergence} regime emerges, where logits\ndiverge but loss, gradients, and activations remain stable. Stable training\nunder large learning rates enables persistent feature evolution at scale in all\nhidden layers, which is crucial for the practical success of SP. In experiments\nacross optimizers (SGD, Adam), architectures (MLPs, GPT) and data modalities\n(vision, language), we validate that neural networks operate in this controlled\ndivergence regime under CE loss but not under MSE loss. Our empirical evidence\nsuggests that width-scaling considerations are surprisingly useful for\npredicting empirically optimal learning rate exponents. Finally, our analysis\nclarifies the effectiveness and limitations of recently proposed layerwise\nlearning rate scalings for standard initialization.','Moritz Haas, Sebastian Bordt, Ulrike von Luxburg, Leena Chennuru Vankadara','2025-05-28','cs.LG','图像识别、自然语言处理','http://arxiv.org/pdf/2505.22491v1','该论文通过研究神经网络训练动态，发现在交叉熵损失下存在一种中间的“受控发散”区域，使得在大学习率下稳定训练，从而实现了在所有隐藏层中规模化的特征演化，这对于标准参数化的实际成功至关重要。'),('2505.22492v1','Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation','This paper studies off-policy evaluation (OPE) in reinforcement learning with\na focus on behavior policy estimation for importance sampling. Prior work has\nshown empirically that estimating a history-dependent behavior policy can lead\nto lower mean squared error (MSE) even when the true behavior policy is\nMarkovian. However, the question of why the use of history should lower MSE\nremains open. In this paper, we theoretically demystify this paradox by\nderiving a bias-variance decomposition of the MSE of ordinary importance\nsampling (IS) estimators, demonstrating that history-dependent behavior policy\nestimation decreases their asymptotic variances while increasing their\nfinite-sample biases. Additionally, as the estimated behavior policy conditions\non a longer history, we show a consistent decrease in variance. We extend these\nfindings to a range of other OPE estimators, including the sequential IS\nestimator, the doubly robust estimator and the marginalized IS estimator, with\nthe behavior policy estimated either parametrically or non-parametrically.','Hongyi Zhou, Josiah P. Hanna, Jin Zhu, Ying Yang, Chengchun Shi','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22492v1','本文研究了强化学习中的离策略评估，重点关注重要性采样的行为策略估计。通过理论推导，证明了历史相关的行为策略估计可以降低重要性采样估计器的渐近方差，同时增加有限样本偏差。'),('2505.22494v1','ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods','Designing protein sequences of both high fitness and novelty is a challenging\ntask in data-efficient protein engineering. Exploration beyond wild-type\nneighborhoods often leads to biologically implausible sequences or relies on\nsurrogate models that lose fidelity in novel regions. Here, we propose\nProSpero, an active learning framework in which a frozen pre-trained generative\nmodel is guided by a surrogate updated from oracle feedback. By integrating\nfitness-relevant residue selection with biologically-constrained Sequential\nMonte Carlo sampling, our approach enables exploration beyond wild-type\nneighborhoods while preserving biological plausibility. We show that our\nframework remains effective even when the surrogate is misspecified. ProSpero\nconsistently outperforms or matches existing methods across diverse protein\nengineering tasks, retrieving sequences of both high fitness and novelty.','Michal Kmicikiewicz, Vincent Fortuin, Ewa Szczurek','2025-05-28','cs.LG','蛋白质工程','http://arxiv.org/pdf/2505.22494v1','该论文提出了一种名为ProSpero的主动学习框架，通过整合与生物相关的残基选择和生物约束的顺序蒙特卡洛采样，实现了在超越野生型邻域的探索同时保持生物合理性。研究表明，即使代理模型被错误指定，ProSpero仍然有效，并在各种蛋白质工程任务中始终优于或与现有方法相匹配，检索到高适应性和新颖性的序列。'),('2505.22501v1','EvolveSearch: An Iterative Self-Evolving Search Agent','The rapid advancement of large language models (LLMs) has transformed the\nlandscape of agentic information seeking capabilities through the integration\nof tools such as search engines and web browsers. However, current mainstream\napproaches for enabling LLM web search proficiency face significant challenges:\nsupervised fine-tuning struggles with data production in open-search domains,\nwhile RL converges quickly, limiting their data utilization efficiency. To\naddress these issues, we propose EvolveSearch, a novel iterative self-evolution\nframework that combines SFT and RL to enhance agentic web search capabilities\nwithout any external human-annotated reasoning data. Extensive experiments on\nseven multi-hop question-answering (MHQA) benchmarks demonstrate that\nEvolveSearch consistently improves performance across iterations, ultimately\nachieving an average improvement of 4.7\\% over the current state-of-the-art\nacross seven benchmarks, opening the door to self-evolution agentic\ncapabilities in open web search domains.','Dingchu Zhang, Yida Zhao, Jialong Wu, Baixuan Li, Wenbiao Yin, Liwen Zhang, Yong Jiang, Yufeng Li, Kewei Tu, Pengjun Xie, Fei Huang','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22501v1','该论文提出了一个名为EvolveSearch的新颖迭代自我演进框架，结合了SFT和RL方法，以增强主动式网络搜索能力，无需外部人类注释数据。在七个多跳问答基准测试上进行的广泛实验表明，EvolveSearch在迭代过程中持续提高性能，最终在七个基准测试中取得了平均4.7%的改进，为在开放网络搜索领域实现自我演进主动能力打开了大门。'),('2505.22503v1','From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation','While embodied agents have made significant progress in performing complex\nphysical tasks, real-world applications demand more than pure task execution.\nThe agents must collaborate with unfamiliar agents and human users, whose goals\nare often vague and implicit. In such settings, interpreting ambiguous\ninstructions and uncovering underlying desires is essential for effective\nassistance. Therefore, fast and accurate desire alignment becomes a critical\ncapability for embodied agents. In this work, we first develop a home\nassistance simulation environment HA-Desire that integrates an LLM-driven human\nuser agent exhibiting realistic value-driven goal selection and communication.\nThe ego agent must interact with this proxy user to infer and adapt to the\nuser\\\'s latent desires. To achieve this, we present a novel framework FAMER for\nfast desire alignment, which introduces a desire-based mental reasoning\nmechanism to identify user intent and filter desire-irrelevant actions. We\nfurther design a reflection-based communication module that reduces redundant\ninquiries, and incorporate goal-relevant information extraction with memory\npersistence to improve information reuse and reduce unnecessary exploration.\nExtensive experiments demonstrate that our framework significantly enhances\nboth task execution and communication efficiency, enabling embodied agents to\nquickly adapt to user-specific desires in complex embodied environments.','Yuanfei Wang, Xinju Huang, Fangwei Zhong, Yaodong Yang, Yizhou Wang, Yuanpei Chen, Hao Dong','2025-05-28','cs.RO','强化学习','http://arxiv.org/pdf/2505.22503v1','该论文研究了在复杂的实体环境中，如何通过快速准确的愿望对齐来帮助实体代理与陌生代理和人类用户合作。他们提出了一个新的框架 FAMER，通过愿望驱动的心智推理机制和反思型通信模块来实现快速愿望对齐，从而提高任务执行和沟通效率。'),('2505.22504v1','Geometric GNNs for Charged Particle Tracking at GlueX','Nuclear physics experiments are aimed at uncovering the fundamental building\nblocks of matter. The experiments involve high-energy collisions that produce\ncomplex events with many particle trajectories. Tracking charged particles\nresulting from collisions in the presence of a strong magnetic field is\ncritical to enable the reconstruction of particle trajectories and precise\ndetermination of interactions. It is traditionally achieved through\ncombinatorial approaches that scale worse than linearly as the number of hits\ngrows. Since particle hit data naturally form a 3-dimensional point cloud and\ncan be structured as graphs, Graph Neural Networks (GNNs) emerge as an\nintuitive and effective choice for this task. In this study, we evaluate the\nGNN model for track finding on the data from the GlueX experiment at Jefferson\nLab. We use simulation data to train the model and test on both simulation and\nreal GlueX measurements. We demonstrate that GNN-based track finding\noutperforms the currently used traditional method at GlueX in terms of\nsegment-based efficiency at a fixed purity while providing faster inferences.\nWe show that the GNN model can achieve significant speedup by processing\nmultiple events in batches, which exploits the parallel computation capability\nof Graphical Processing Units (GPUs). Finally, we compare the GNN\nimplementation on GPU and FPGA and describe the trade-off.','Ahmed Hossam Mohammed, Kishansingh Rajput, Simon Taylor, Denis Furletov, Sergey Furletov, Malachi Schram','2025-05-28','cs.LG','图神经网络 (GNN)','http://arxiv.org/pdf/2505.22504v1','该论文研究了在核物理实验中使用图神经网络（GNN）进行轨迹重建的方法。他们在GlueX实验数据上评估了GNN模型，结果表明GNN在轨迹重建方面表现优于传统方法，并具有更快的推断速度。'),('2505.22506v1','Sparsification and Reconstruction from the Perspective of Representation Geometry','Sparse Autoencoders (SAEs) have emerged as a predominant tool in mechanistic\ninterpretability, aiming to identify interpretable monosemantic features.\nHowever, how does sparse encoding organize the representations of activation\nvector from language models? What is the relationship between this\norganizational paradigm and feature disentanglement as well as reconstruction\nperformance? To address these questions, we propose the SAEMA, which validates\nthe stratified structure of the representation by observing the variability of\nthe rank of the symmetric semipositive definite (SSPD) matrix corresponding to\nthe modal tensor unfolded along the latent tensor with the level of noise added\nto the residual stream. To systematically investigate how sparse encoding\nalters representational structures, we define local and global representations,\ndemonstrating that they amplify inter-feature distinctions by merging similar\nsemantic features and introducing additional dimensionality. Furthermore, we\nintervene the global representation from an optimization perspective, proving a\nsignificant causal relationship between their separability and the\nreconstruction performance. This study explains the principles of sparsity from\nthe perspective of representational geometry and demonstrates the impact of\nchanges in representational structure on reconstruction performance.\nParticularly emphasizes the necessity of understanding representations and\nincorporating representational constraints, providing empirical references for\ndeveloping new interpretable tools and improving SAEs. The code is available at\n\\hyperlink{https://github.com/wenjie1835/SAERepGeo}{https://github.com/wenjie1835/SAERepGeo}.','Wenjie Sun, Bingzhe Wu, Zhile Yang, Chengke Wu','2025-05-28','cs.LG','LLM (语言模型)','http://arxiv.org/pdf/2505.22506v1','该论文研究了稀疏自动编码器在语言模型中的表示结构，提出了SAEMA方法来验证表示的层次结构，并探讨了稀疏编码如何改变表示结构以及对重建性能的影响。'),('2505.22509v1','Accelerating Optimization via Differentiable Stopping Time','Optimization is an important module of modern machine learning applications.\nTremendous efforts have been made to accelerate optimization algorithms. A\ncommon formulation is achieving a lower loss at a given time. This enables a\ndifferentiable framework with respect to the algorithm hyperparameters. In\ncontrast, its dual, minimizing the time to reach a target loss, is believed to\nbe non-differentiable, as the time is not differentiable. As a result, it\nusually serves as a conceptual framework or is optimized using zeroth-order\nmethods. To address this limitation, we propose a differentiable stopping time\nand theoretically justify it based on differential equations. An efficient\nalgorithm is designed to backpropagate through it. As a result, the proposed\ndifferentiable stopping time enables a new differentiable formulation for\naccelerating algorithms. We further discuss its applications, such as online\nhyperparameter tuning and learning to optimize. Our proposed methods show\nsuperior performance in comprehensive experiments across various problems,\nwhich confirms their effectiveness.','Zhonglin Xie, Yiman Fong, Haoran Yuan, Zaiwen Wen','2025-05-28','cs.LG','优化算法','http://arxiv.org/pdf/2505.22509v1','该论文提出了一种可微的停止时间概念，通过理论上的差分方程进行了论证，并设计了一个有效的算法来进行反向传播。这种不同iable的停止时间为加速算法提供了一种新的可微的表述方式，进一步讨论了其在在线超参数调整和学习优化等方面的应用，并在综合实验中展示了其优越性能。'),('2505.22517v1','Multi-MLLM Knowledge Distillation for Out-of-Context News Detection','Multimodal out-of-context news is a type of misinformation in which the image\nis used outside of its original context. Many existing works have leveraged\nmultimodal large language models (MLLMs) for detecting out-of-context news.\nHowever, observing the limited zero-shot performance of smaller MLLMs, they\ngenerally require label-rich fine-tuning and/or expensive API calls to GPT\nmodels to improve the performance, which is impractical in low-resource\nscenarios. In contrast, we aim to improve the performance of small MLLMs in a\nmore label-efficient and cost-effective manner. To this end, we first prompt\nmultiple teacher MLLMs to generate both label predictions and corresponding\nrationales, which collectively serve as the teachers\\\' knowledge. We then\nintroduce a two-stage knowledge distillation framework to transfer this\nknowledge to a student MLLM. In Stage 1, we apply LoRA fine-tuning to the\nstudent model using all training data. In Stage 2, we further fine-tune the\nstudent model using both LoRA fine-tuning and DPO on the data points where\nteachers\\\' predictions conflict. This two-stage strategy reduces annotation\ncosts and helps the student model uncover subtle patterns in more challenging\ncases. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance using less than 10% labeled data.','Yimeng Gu, Zhao Tong, Ignacio Castro, Shu Wu, Gareth Tyson','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22517v1','该论文提出了一种在低资源情况下改善小型多模态大语言模型在检测跨语境新闻中的性能的方法。他们通过引入两阶段知识蒸馏框架，将多个教师模型的知识传递给一个学生模型，以降低标注成本并提高性能。'),('2505.22518v1','IGNIS: A Neural Network Framework for Robust Parameter Estimation in Archimedean Copulas','Parameter estimation for Archimedean copulas remains a challenging problem,\nparticularly for the recently developed A1 and A2 families that exhibit complex\ndependency structures. Traditional methods, such as the Method of Moments\n(MoM), Maximum Likelihood Estimation (MLE), and Maximum Pseudo-Likelihood\n(MPL), often struggle due to issues of non-monotonic relationship with\ndependency measures such as Kendall\\\'s tau (as in the case of A1) and numerical\ninstability. In this paper, we present the IGNIS Network, a novel, unified\nneural framework that learns a direct mapping from observable dependency\nmeasures to copula parameters, thereby overcoming the limitations of classical\napproaches. Our approach is trained on simulated data spanning five Archimedean\ncopula families including Clayton, Gumbel, Frank, A1, and A2, ensuring its\ngeneral applicability across the entire family. Extensive simulation studies\ndemonstrate that the IGNIS Network reduces estimation errors compared to MoM,\nwhile inherently enforcing parameter constraints through theory-guided\npost-processing. We further validate the practical utility of our method on\ndiverse real-world datasets, including financial returns (AAPL-MSFT),\nhealthcare metrics (CDC Diabetes indicators), and environmental measurements\n(PM2.5 air quality). Our results underscore the transformative potential of\nneural methods for robust and accurate dependence modeling in modern\napplications.','Agnideep Aich, Ashit Baran Aich, Bruce Wade','2025-05-28','stat.ML','强化学习','http://arxiv.org/pdf/2505.22518v1','本文介绍了IGNIS Network，这是一个新颖的神经网络框架，可以从可观测的依赖度量直接映射到Copula参数，克服了传统方法的局限性。研究表明，IGNIS Network相比MoM减少了估计误差，并通过理论引导的后处理方法自然地实施参数约束。'),('2505.22524v1','Test-Time Alignment of Discrete Diffusion Models with Sequential Monte Carlo','Discrete diffusion models have become highly effective across various\ndomains. However, real-world applications often require the generative process\nto adhere to certain constraints but without task-specific fine-tuning. To this\nend, we propose a training-free method based on Sequential Monte Carlo (SMC) to\nsample from the reward-aligned target distribution at the test time. Our\napproach leverages twisted SMC with an approximate locally optimal proposal,\nobtained via a first-order Taylor expansion of the reward function. To address\nthe challenge of ill-defined gradients in discrete spaces, we incorporate a\nGumbel-Softmax relaxation, enabling efficient gradient-based approximation\nwithin the discrete generative framework. Empirical results on both synthetic\ndatasets and image modelling validate the effectiveness of our approach.','Chinmay Pani, Zijing Ou, Yingzhen Li','2025-05-28','cs.LG','生成模型','http://arxiv.org/pdf/2505.22524v1','该论文提出了一种基于序贯蒙特卡洛方法的训练免费的生成模型，用于在测试时从与奖励对齐的目标分布中进行采样。他们的方法结合了扭曲的SMC和近似局部最优提议，通过奖励函数的一阶泰勒展开来获得。同时，他们还引入了Gumbel-Softmax松弛来解决离散空间中梯度不明确的挑战，从而在离散生成框架内实现了高效的基于梯度的近似。'),('2505.22525v1','Thinking with Generated Images','We present Thinking with Generated Images, a novel paradigm that\nfundamentally transforms how large multimodal models (LMMs) engage with visual\nreasoning by enabling them to natively think across text and vision modalities\nthrough spontaneous generation of intermediate visual thinking steps. Current\nvisual reasoning with LMMs is constrained to either processing fixed\nuser-provided images or reasoning solely through text-based chain-of-thought\n(CoT). Thinking with Generated Images unlocks a new dimension of cognitive\ncapability where models can actively construct intermediate visual thoughts,\ncritique their own visual hypotheses, and refine them as integral components of\ntheir reasoning process. We demonstrate the effectiveness of our approach\nthrough two complementary mechanisms: (1) vision generation with intermediate\nvisual subgoals, where models decompose complex visual tasks into manageable\ncomponents that are generated and integrated progressively, and (2) vision\ngeneration with self-critique, where models generate an initial visual\nhypothesis, analyze its shortcomings through textual reasoning, and produce\nrefined outputs based on their own critiques. Our experiments on vision\ngeneration benchmarks show substantial improvements over baseline approaches,\nwith our models achieving up to 50% (from 38% to 57%) relative improvement in\nhandling complex multi-object scenarios. From biochemists exploring novel\nprotein structures, and architects iterating on spatial designs, to forensic\nanalysts reconstructing crime scenes, and basketball players envisioning\nstrategic plays, our approach enables AI models to engage in the kind of visual\nimagination and iterative refinement that characterizes human creative,\nanalytical, and strategic thinking. We release our open-source suite at\nhttps://github.com/GAIR-NLP/thinking-with-generated-images.','Ethan Chern, Zhulin Hu, Steffi Chern, Siqi Kou, Jiadi Su, Yan Ma, Zhijie Deng, Pengfei Liu','2025-05-28','cs.CV','LLM、视觉推理','http://arxiv.org/pdf/2505.22525v1','该论文提出了一种新的思维范式，通过生成中间视觉思维步骤，使大型多模态模型能够跨文本和视觉模态进行思考，从而提高视觉推理的效果。'),('2505.22527v1','Symplectic Generative Networks (SGNs): A Hamiltonian Framework for Invertible Deep Generative Modeling','We introduce the Symplectic Generative Network (SGN), a deep generative model\nthat leverages Hamiltonian mechanics to construct an invertible,\nvolume-preserving mapping between a latent space and the data space. By\nendowing the latent space with a symplectic structure and modeling data\ngeneration as the time evolution of a Hamiltonian system, SGN achieves exact\nlikelihood evaluation without incurring the computational overhead of Jacobian\ndeterminant calculations. In this work, we provide a rigorous mathematical\nfoundation for SGNs through a comprehensive theoretical framework that\nincludes: (i) complete proofs of invertibility and volume preservation, (ii) a\nformal complexity analysis with theoretical comparisons to Variational\nAutoencoders and Normalizing Flows, (iii) strengthened universal approximation\nresults with quantitative error bounds, (iv) an information-theoretic analysis\nbased on the geometry of statistical manifolds, and (v) an extensive stability\nanalysis with adaptive integration guarantees. These contributions highlight\nthe fundamental advantages of SGNs and establish a solid foundation for future\nempirical investigations and applications to complex, high-dimensional data.','Agnideep Aich, Ashit Aich, Bruce Wade','2025-05-28','stat.ML','生成模型','http://arxiv.org/pdf/2505.22527v1','该论文介绍了Symplectic Generative Network (SGN)，一种利用哈密顿力学构建的深度生成模型，通过在潜在空间和数据空间之间建立可逆、保体积映射来实现精确似然评估。通过赋予潜在空间一个辛结构，并将数据生成建模为哈密顿系统的时间演化，SGN实现了精确似然评估，避免了雅可比行列式计算的计算开销。'),('2505.22531v1','Training RL Agents for Multi-Objective Network Defense Tasks','Open-ended learning (OEL) -- which emphasizes training agents that achieve\nbroad capability over narrow competency -- is emerging as a paradigm to develop\nartificial intelligence (AI) agents to achieve robustness and generalization.\nHowever, despite promising results that demonstrate the benefits of OEL,\napplying OEL to develop autonomous agents for real-world cybersecurity\napplications remains a challenge.\n  We propose a training approach, inspired by OEL, to develop autonomous\nnetwork defenders. Our results demonstrate that like in other domains, OEL\nprinciples can translate into more robust and generalizable agents for cyber\ndefense. To apply OEL to network defense, it is necessary to address several\ntechnical challenges. Most importantly, it is critical to provide a task\nrepresentation approach over a broad universe of tasks that maintains a\nconsistent interface over goals, rewards and action spaces. This way, the\nlearning agent can train with varying network conditions, attacker behaviors,\nand defender goals while being able to build on previously gained knowledge.\n  With our tools and results, we aim to fundamentally impact research that\napplies AI to solve cybersecurity problems. Specifically, as researchers\ndevelop gyms and benchmarks for cyber defense, it is paramount that they\nconsider diverse tasks with consistent representations, such as those we\npropose in our work.','Andres Molina-Markham, Luis Robaina, Sean Steinle, Akash Trivedi, Derek Tsui, Nicholas Potteiger, Lauren Brandt, Ransom Winder, Ahmed Ridley','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22531v1','本文提出了一种受开放式学习（OEL）启发的训练方法，用于开发自主网络防御者，结果表明OEL原则可以转化为更强大和通用的网络防御代理。作者强调了在网络防御领域应用OEL的技术挑战，包括提供广泛任务表示方法以及考虑网络条件、攻击者行为和防御者目标的变化。'),('2505.22533v1','TabularQGAN: A Quantum Generative Model for Tabular Data','In this paper, we introduce a novel quantum generative model for synthesizing\ntabular data. Synthetic data is valuable in scenarios where real-world data is\nscarce or private, it can be used to augment or replace existing datasets.\nReal-world enterprise data is predominantly tabular and heterogeneous, often\ncomprising a mixture of categorical and numerical features, making it highly\nrelevant across various industries such as healthcare, finance, and software.\nWe propose a quantum generative adversarial network architecture with flexible\ndata encoding and a novel quantum circuit ansatz to effectively model tabular\ndata. The proposed approach is tested on the MIMIC III healthcare and Adult\nCensus datasets, with extensive benchmarking against leading classical models,\nCTGAN, and CopulaGAN. Experimental results demonstrate that our quantum model\noutperforms classical models by an average of 8.5% with respect to an overall\nsimilarity score from SDMetrics, while using only 0.072% of the parameters of\nthe classical models. Additionally, we evaluate the generalization capabilities\nof the models using two custom-designed metrics that demonstrate the ability of\nthe proposed quantum model to generate useful and novel samples. To our\nknowledge, this is one of the first demonstrations of a successful quantum\ngenerative model for handling tabular data, indicating that this task could be\nwell-suited to quantum computers.','Pallavi Bhardwaj, Caitlin Jones, Lasse Dierich, Aleksandar Vučković','2025-05-28','cs.LG','生成模型','http://arxiv.org/pdf/2505.22533v1','本文介绍了一种用于合成表格数据的新型量子生成模型。提出的量子生成对抗网络架构具有灵活的数据编码和一种新颖的量子电路ansatz，能够有效地建模表格数据。在MIMIC III医疗保健和成人普查数据集上进行了测试，实验结果表明，我们的量子模型在整体相似度得分方面优于传统模型平均8.5％，同时仅使用传统模型参数的0.072％。'),('2505.22535v1','RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting','Recent deep learning approaches for river discharge forecasting have improved\nthe accuracy and efficiency in flood forecasting, enabling more reliable early\nwarning systems for risk management. Nevertheless, existing deep learning\napproaches in hydrology remain largely confined to local-scale applications and\ndo not leverage the inherent spatial connections of bodies of water. Thus,\nthere is a strong need for new deep learning methodologies that are capable of\nmodeling spatio-temporal relations to improve river discharge and flood\nforecasting for scientific and operational applications. To address this, we\npresent RiverMamba, a novel deep learning model that is pretrained with\nlong-term reanalysis data and that can forecast global river discharge and\nfloods on a $0.05^\\circ$ grid up to 7 days lead time, which is of high\nrelevance in early warning. To achieve this, RiverMamba leverages efficient\nMamba blocks that enable the model to capture global-scale channel network\nrouting and enhance its forecast capability for longer lead times. The forecast\nblocks integrate ECMWF HRES meteorological forecasts, while accounting for\ntheir inaccuracies through spatio-temporal modeling. Our analysis demonstrates\nthat RiverMamba delivers reliable predictions of river discharge, including\nextreme floods across return periods and lead times, surpassing both\noperational AI- and physics-based models.','Mohamad Hakam Shams Eddin, Yikui Zahng, Stefan Kollet, Juergen Gall','2025-05-28','cs.CV','水文学、深度学习','http://arxiv.org/pdf/2505.22535v1','该论文介绍了一种名为RiverMamba的新型深度学习模型，通过预训练长期再分析数据，能够在0.05°网格上预测全球河流流量和洪水，提高了洪水预测的准确性和效率。'),('2505.22538v1','Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks','We address the problem of uncertainty quantification and propose measures of\ntotal, aleatoric, and epistemic uncertainty based on a known decomposition of\n(strictly) proper scoring rules, a specific type of loss function, into a\ndivergence and an entropy component. This leads to a flexible framework for\nuncertainty quantification that can be instantiated with different losses\n(scoring rules), which makes it possible to tailor uncertainty quantification\nto the use case at hand. We show that this flexibility is indeed advantageous.\nIn particular, we analyze the task of selective prediction and show that the\nscoring rule should ideally match the task loss. In addition, we perform\nexperiments on two other common tasks. For out-of-distribution detection, our\nresults confirm that a widely used measure of epistemic uncertainty, mutual\ninformation, performs best. Moreover, in the setting of active learning, our\nmeasure of epistemic uncertainty based on the zero-one-loss consistently\noutperforms other uncertainty measures.','Paul Hofman, Yusuf Sale, Eyke Hüllermeier','2025-05-28','cs.LG','不确定性量化','http://arxiv.org/pdf/2505.22538v1','该论文提出了基于已知的严格适当得分规则分解的总体、aleatoric和认知不确定性的衡量方法，建立了一个灵活的不确定性量化框架，可以根据不同的损失函数进行实例化，从而可以根据具体用例定制不确定性量化。研究结果表明，这种灵活性确实是有优势的。'),('2505.22541v1','A Human-Centric Approach to Explainable AI for Personalized Education','Deep neural networks form the backbone of artificial intelligence research,\nwith potential to transform the human experience in areas ranging from\nautonomous driving to personal assistants, healthcare to education. However,\ntheir integration into the daily routines of real-world classrooms remains\nlimited. It is not yet common for a teacher to assign students individualized\nhomework targeting their specific weaknesses, provide students with instant\nfeedback, or simulate student responses to a new exam question. While these\nmodels excel in predictive performance, this lack of adoption can be attributed\nto a significant weakness: the lack of explainability of model decisions,\nleading to a lack of trust from students, parents, and teachers. This thesis\naims to bring human needs to the forefront of eXplainable AI (XAI) research,\ngrounded in the concrete use case of personalized learning and teaching. We\nframe the contributions along two verticals: technical advances in XAI and\ntheir aligned human studies. We investigate explainability in AI for education,\nrevealing systematic disagreements between post-hoc explainers and identifying\na need for inherently interpretable model architectures. We propose four novel\ntechnical contributions in interpretability with a multimodal modular\narchitecture (MultiModN), an interpretable mixture-of-experts model\n(InterpretCC), adversarial training for explainer stability, and a\ntheory-driven LLM-XAI framework to present explanations to students\n(iLLuMinaTE), which we evaluate in diverse settings with professors, teachers,\nlearning scientists, and university students. By combining empirical\nevaluations of existing explainers with novel architectural designs and human\nstudies, our work lays a foundation for human-centric AI systems that balance\nstate-of-the-art performance with built-in transparency and trust.','Vinitra Swamy','2025-05-28','cs.LG','教育人工智能','http://arxiv.org/pdf/2505.22541v1','该论文旨在解决深度神经网络在教育领域的应用中缺乏可解释性的问题，提出了基于可解释AI的研究，以个性化学习和教学为具体应用场景，通过技术进步和人类研究两个方面的贡献，提出了多模态模块化架构、可解释的专家模型、对抗训练以及理论驱动的LLM-XAI框架等四个新的技术贡献。'),('2505.22543v1','Scaling-up Perceptual Video Quality Assessment','The data scaling law has been shown to significantly enhance the performance\nof large multi-modal models (LMMs) across various downstream tasks. However, in\nthe domain of perceptual video quality assessment (VQA), the potential of\nscaling law remains unprecedented due to the scarcity of labeled resources and\nthe insufficient scale of datasets. To address this, we propose\n\\textbf{OmniVQA}, an efficient framework designed to efficiently build\nhigh-quality, human-in-the-loop VQA multi-modal instruction databases (MIDBs).\nWe then scale up to create \\textbf{OmniVQA-Chat-400K}, the largest MIDB in the\nVQA field concurrently. Our focus is on the technical and aesthetic quality\ndimensions, with abundant in-context instruction data to provide fine-grained\nVQA knowledge. Additionally, we have built the \\textbf{OmniVQA-MOS-20K} dataset\nto enhance the model\\\'s quantitative quality rating capabilities. We then\nintroduce a \\textbf{complementary} training strategy that effectively leverages\nthe knowledge from datasets for quality understanding and quality rating tasks.\nFurthermore, we propose the \\textbf{OmniVQA-FG (fine-grain)-Benchmark} to\nevaluate the fine-grained performance of the models. Our results demonstrate\nthat our models achieve state-of-the-art performance in both quality\nunderstanding and rating tasks.','Ziheng Jia, Zicheng Zhang, Zeyu Zhang, Yingji Liang, Xiaorong Zhu, Chunyi Li, Jinliang Han, Haoning Wu, Bin Wang, Haoran Zhang, Guanyu Zhu, Qiyong Zhao, Xiaohong Liu, Guangtao Zhai, Xiongkuo Min','2025-05-28','cs.CV','多模态学习(LMM)','http://arxiv.org/pdf/2505.22543v1','本论文提出了OmniVQA框架，旨在构建高质量的人机交互VQA多模态指导数据库，并通过扩展规模创建了目前规模最大的VQA数据库。他们专注于技术和美学质量维度，提供丰富的上下文指导数据，以提供细粒度的VQA知识。通过引入补充训练策略，有效地利用数据集的知识，实现了在质量理解和评分任务中的最先进性能。'),('2505.22548v1','Emotion-o1: Adaptive Long Reasoning for Emotion Understanding in LLMs','Emotion understanding includes basic tasks (e.g., sentiment/emotion\nclassification) and advanced tasks (e.g., sarcasm/humor detection). Current\nmethods rely on fixed-length CoT reasoning, failing to adapt to the varying\ncomplexity of emotions. We propose a task-adaptive reasoning framework that\nemploys DeepSeek-R1 to generate variable-length reasoning chains for different\nemotion tasks. By combining fine-tuning with reinforcement learning, we design\na composite reward function that balances four objectives: prediction accuracy,\nadaptive reasoning depth control, structural diversity in reasoning paths, and\nsuppression of repetitive logic. This approach achieves dynamic\ncontext-sensitive inference while enabling LLMs to autonomously develop deep\nreasoning capabilities. Experimental results demonstrate consistent\nimprovements in both Acc and F1 scores across four tasks: emotion, sentiment,\nhumor, and sarcasm. Notably, peak enhancements reached 3.56% F1 (2.76% Acc) for\nbasic tasks and 37.95% F1 (23.14% Acc) for advanced tasks. Our work bridges\nrigid CoT reasoning and emotional complexity through adaptive-depth analysis.','Changhao Song, Yazhou Zhang, Peng Zhang','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22548v1','该论文提出了一种任务自适应推理框架，利用DeepSeek-R1为不同情绪任务生成可变长度的推理链。通过将微调与强化学习相结合，设计了一个平衡四个目标的复合奖励函数，实现了动态的上下文敏感推理，使LLMs能够自主发展深度推理能力。实验结果表明，在情绪、情感、幽默和讽刺四个任务中，Acc和F1分数均有一致的提升。'),('2505.22549v1','DES-LOC: Desynced Low Communication Adaptive Optimizers for Training Foundation Models','Scaling foundation model training with Distributed Data Parallel (DDP)\nmethods is bandwidth-limited. Existing infrequent communication methods like\nLocal SGD were designed to synchronize only model parameters and cannot be\ntrivially applied to adaptive optimizers due to additional optimizer states.\nCurrent approaches extending Local SGD either lack convergence guarantees or\nrequire synchronizing all optimizer states, tripling communication costs. We\npropose Desynced Low Communication Adaptive Optimizers (DES-LOC), a family of\noptimizers assigning independent synchronization periods to parameters and\nmomenta, enabling lower communication costs while preserving convergence.\nThrough extensive experiments on language models of up to 1.7B, we show that\nDES-LOC can communicate 170x less than DDP and 2x less than the previous\nstate-of-the-art Local ADAM. Furthermore, unlike previous heuristic approaches,\nDES-LOC is suited for practical training scenarios prone to system failures.\nDES-LOC offers a scalable, bandwidth-efficient, and fault-tolerant solution for\nfoundation model training.','Alex Iacob, Lorenzo Sani, Mher Safaryan, Paris Giampouras, Samuel Horváth, Andrej Jovanovic, Meghdad Kurmanji, Preslav Aleksandrov, William F. Shen, Xinchi Qiu, Nicholas D. Lane','2025-05-28','cs.LG','优化算法','http://arxiv.org/pdf/2505.22549v1','该论文提出了一种名为DES-LOC的优化器家族，可以为基础模型训练提供可扩展、带宽高效和容错的解决方案。通过将独立的同步周期分配给参数和动量，DES-LOC可以实现更低的通信成本，同时保持收敛性。'),('2505.22552v1','ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM','Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of\nlarge language models (LLMs) is an emerging research challenge in claim\nverification. While KGs provide structured, semantically rich representations\nwell-suited for reasoning, most existing verification methods rely on\nunstructured text corpora, limiting their ability to effectively leverage KGs.\nAdditionally, despite possessing strong reasoning abilities, modern LLMs\nstruggle with multi-step modular pipelines and reasoning over KGs without\nadaptation. To address these challenges, we propose ClaimPKG, an end-to-end\nframework that seamlessly integrates LLM reasoning with structured knowledge\nfrom KGs. Specifically, the main idea of ClaimPKG is to employ a lightweight,\nspecialized LLM to represent the input claim as pseudo-subgraphs, guiding a\ndedicated subgraph retrieval module to identify relevant KG subgraphs. These\nretrieved subgraphs are then processed by a general-purpose LLM to produce the\nfinal verdict and justification. Extensive experiments on the FactKG dataset\ndemonstrate that ClaimPKG achieves state-of-the-art performance, outperforming\nstrong baselines in this research field by 9%-12% accuracy points across\nmultiple categories. Furthermore, ClaimPKG exhibits zero-shot generalizability\nto unstructured datasets such as HoVer and FEVEROUS, effectively combining\nstructured knowledge from KGs with LLM reasoning across various LLM backbones.','Hoang Pham, Thanh-Do Nguyen, Khac-Hoai Nam Bui','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22552v1','该论文提出了一个名为ClaimPKG的框架，旨在将大型语言模型（LLMs）的推理能力与知识图谱（KGs）相结合，以提高声明验证的性能。通过使用轻量级、专门化的LLM表示输入声明，并引导专门的子图检索模块识别相关的KG子图，最终结合通用目的的LLM生成最终的判断和理由。'),('2505.22560v1','Geometric Hyena Networks for Large-scale Equivariant Learning','Processing global geometric context while preserving equivariance is crucial\nwhen modeling biological, chemical, and physical systems. Yet, this is\nchallenging due to the computational demands of equivariance and global context\nat scale. Standard methods such as equivariant self-attention suffer from\nquadratic complexity, while local methods such as distance-based message\npassing sacrifice global information. Inspired by the recent success of\nstate-space and long-convolutional models, we introduce Geometric Hyena, the\nfirst equivariant long-convolutional model for geometric systems. Geometric\nHyena captures global geometric context at sub-quadratic complexity while\nmaintaining equivariance to rotations and translations. Evaluated on all-atom\nproperty prediction of large RNA molecules and full protein molecular dynamics,\nGeometric Hyena outperforms existing equivariant models while requiring\nsignificantly less memory and compute that equivariant self-attention. Notably,\nour model processes the geometric context of 30k tokens 20x faster than the\nequivariant transformer and allows 72x longer context within the same budget.','Artem Moskalev, Mangal Prakash, Junjie Xu, Tianyu Cui, Rui Liao, Tommaso Mansi','2025-05-28','cs.LG','几何系统建模','http://arxiv.org/pdf/2505.22560v1','该论文介绍了一种名为Geometric Hyena的新型等变长卷积模型，用于处理生物、化学和物理系统的全局几何上下文，能够在保持等变性的同时以次二次复杂度捕捉全局几何上下文。在大RNA分子的全原子属性预测和完整蛋白质分子动力学方面，Geometric Hyena优于现有的等变模型，同时需要更少的内存和计算资源。'),('2505.22563v1','Do Large Language Models Think Like the Brain? Sentence-Level Evidence from fMRI and Hierarchical Embeddings','Understanding whether large language models (LLMs) and the human brain\nconverge on similar computational principles remains a fundamental and\nimportant question in cognitive neuroscience and AI. Do the brain-like patterns\nobserved in LLMs emerge simply from scaling, or do they reflect deeper\nalignment with the architecture of human language processing? This study\nfocuses on the sentence-level neural mechanisms of language models,\nsystematically investigating how hierarchical representations in LLMs align\nwith the dynamic neural responses during human sentence comprehension. By\ncomparing hierarchical embeddings from 14 publicly available LLMs with fMRI\ndata collected from participants, who were exposed to a naturalistic narrative\nstory, we constructed sentence-level neural prediction models to precisely\nidentify the model layers most significantly correlated with brain region\nactivations. Results show that improvements in model performance drive the\nevolution of representational architectures toward brain-like hierarchies,\nparticularly achieving stronger functional and anatomical correspondence at\nhigher semantic abstraction levels.','Yu Lei, Xingyang Ge, Yi Zhang, Yiming Yang, Bolei Ma','2025-05-28','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22563v1','该论文研究了大型语言模型（LLMs）和人类大脑是否在语言处理方面存在相似的计算原理，通过比较LLMs的层级表示与人类句子理解期间的神经反应，发现模型性能的提升推动了表示结构向类似大脑的层级演化。'),('2505.22564v1','PRISM: Video Dataset Condensation with Progressive Refinement and Insertion for Sparse Motion','Video dataset condensation has emerged as a critical technique for addressing\nthe computational challenges associated with large-scale video data processing\nin deep learning applications. While significant progress has been made in\nimage dataset condensation, the video domain presents unique challenges due to\nthe complex interplay between spatial content and temporal dynamics. This paper\nintroduces PRISM, Progressive Refinement and Insertion for Sparse Motion, for\nvideo dataset condensation, a novel approach that fundamentally reconsiders how\nvideo data should be condensed. Unlike the previous method that separates\nstatic content from dynamic motion, our method preserves the essential\ninterdependence between these elements. Our approach progressively refines and\ninserts frames to fully accommodate the motion in an action while achieving\nbetter performance but less storage, considering the relation of gradients for\neach frame. Extensive experiments across standard video action recognition\nbenchmarks demonstrate that PRISM outperforms existing disentangled approaches\nwhile maintaining compact representations suitable for resource-constrained\nenvironments.','Jaehyun Choi, Jiwan Hur, Gyojin Han, Jaemyung Yu, Junmo Kim','2025-05-28','cs.CV','视频识别','http://arxiv.org/pdf/2505.22564v1','本文介绍了一种名为 PRISM 的视频数据集精简方法，与以往方法不同的是，该方法保留了静态内容和动态运动之间的重要相互关系，通过逐步优化和插入帧来充分适应动作中的运动，同时在资源受限环境下保持紧凑表示。'),('2505.22566v1','Universal Visuo-Tactile Video Understanding for Embodied Interaction','Tactile perception is essential for embodied agents to understand physical\nattributes of objects that cannot be determined through visual inspection\nalone. While existing approaches have made progress in visual and language\nmodalities for physical understanding, they fail to effectively incorporate\ntactile information that provides crucial haptic feedback for real-world\ninteraction. In this paper, we present VTV-LLM, the first multi-modal large\nlanguage model for universal Visuo-Tactile Video (VTV) understanding that\nbridges the gap between tactile perception and natural language. To address the\nchallenges of cross-sensor and cross-modal integration, we contribute VTV150K,\na comprehensive dataset comprising 150,000 video frames from 100 diverse\nobjects captured across three different tactile sensors (GelSight Mini, DIGIT,\nand Tac3D), annotated with four fundamental tactile attributes (hardness,\nprotrusion, elasticity, and friction). We develop a novel three-stage training\nparadigm that includes VTV enhancement for robust visuo-tactile representation,\nVTV-text alignment for cross-modal correspondence, and text prompt finetuning\nfor natural language generation. Our framework enables sophisticated tactile\nreasoning capabilities including feature assessment, comparative analysis,\nscenario-based decision making and so on. Experimental evaluations demonstrate\nthat VTV-LLM achieves superior performance in tactile video understanding\ntasks, establishing a foundation for more intuitive human-machine interaction\nin tactile domains.','Yifan Xie, Mingyang Li, Shoujie Li, Xingting Li, Guangyu Chen, Fei Ma, Fei Richard Yu, Wenbo Ding','2025-05-28','cs.CV','LLM、视觉感知、自然语言处理','http://arxiv.org/pdf/2505.22566v1','本文介绍了VTV-LLM，这是第一个用于通用视触觉视频（VTV）理解的多模态大型语言模型，弥合了触觉感知和自然语言之间的差距。作者提出了一个包含150,000个视频帧的综合数据集VTV150K，涵盖了来自100个不同对象的视频，通过三种不同的触觉传感器（GelSight Mini、DIGIT和Tac3D）捕获，并注释了四个基本触觉属性（硬度、突出、弹性和摩擦）。他们开发了一个新颖的三阶段训练范式，包括VTV增强、VTV文本对齐和文本提示微调。实验评估表明，VTV-LLM在触觉视频理解任务中表现出优异的性能。'),('2505.22571v1','Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems','This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.','Hoang Pham, Khac-Hoai Nam Bui','2025-05-28','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22571v1','该论文提出了一种统一的检索增强生成系统，利用最近出现的大型语言模型（LLM）代理概念。他们提出了一种可训练的代理框架，称为Agent-UniRAG，用于统一的检索增强LLM系统，以提高RAG系统的效果和可解释性。'),('2505.22572v1','Fusion Steering: Prompt-Specific Activation Control','We present Fusion Steering, an activation steering methodology that improves\nfactual accuracy in large language models (LLMs) for question-answering (QA)\ntasks. This approach introduces flexible steering configurations, including\nfull-layer steering and segmented steering. Unlike traditional methods\nconstrained to single-layer or fixed-layer operations, Fusion Steering employs\ndynamic injection of prompt-specific activation deltas across all transformer\nlayers. These activation deltas are derived from reference completions that\ncombine the ground-truth answer with a model-generated explanation to\nfacilitate semantically enriched, example-specific steering. The injection\nweights are optimized per prompt using Optuna, targeting a joint objective that\nbalances token overlap (factual alignment) and perplexity (fluency proxy).\nEvaluation employs a composite score integrating token overlap and LLM-graded\nquality, encompassing factual accuracy, coherence, and relevance. Empirical\nresults on 260 SimpleQA prompts (selected from 500 where the baseline failed)\nshowcase the efficacy of segmented steering. Using Gemma-2-2B-IT with 8-bit\nquantization, segmented steering achieves an accuracy of 25.4% (outputs scoring\n$\\geq 0.6$), outperforming the baseline at 3.5% and full-layer steering at\n16.2%. Under the stricter SimpleQA rubric, segmented steering boosts fully\ncorrect responses from 0.0% to 13.1%. These findings highlight the strengths of\nsegmented, dynamic intervention strategies and the promise of per-prompt,\nfull-network activation control. Fusion Steering is also amenable to sparse\nrepresentations, such as Neuronpedia or sparse crosscoders, suggesting a\npromising direction for interpretable and scalable activation-level control in\nLLMs.','Waldemar Chang, Alhassan Yasin','2025-05-28','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22572v1','该论文介绍了一种名为Fusion Steering的激活引导方法，用于改善大型语言模型（LLMs）在问答任务中的事实准确性。该方法采用灵活的引导配置，包括全层引导和分段引导，通过在所有变换器层动态注入特定提示的激活增量来实现。'),('2505.22573v1','FNOPE: Simulation-based inference on function spaces with Fourier Neural Operators','Simulation-based inference (SBI) is an established approach for performing\nBayesian inference on scientific simulators. SBI so far works best on\nlow-dimensional parametric models. However, it is difficult to infer\nfunction-valued parameters, which frequently occur in disciplines that model\nspatiotemporal processes such as the climate and earth sciences. Here, we\nintroduce an approach for efficient posterior estimation, using a Fourier\nNeural Operator (FNO) architecture with a flow matching objective. We show that\nour approach, FNOPE, can perform inference of function-valued parameters at a\nfraction of the simulation budget of state of the art methods. In addition,\nFNOPE supports posterior evaluation at arbitrary discretizations of the domain,\nas well as simultaneous estimation of vector-valued parameters. We demonstrate\nthe effectiveness of our approach on several benchmark tasks and a challenging\nspatial inference task from glaciology. FNOPE extends the applicability of SBI\nmethods to new scientific domains by enabling the inference of function-valued\nparameters.','Guy Moss, Leah Sophie Muhle, Reinhard Drews, Jakob H. Macke, Cornelius Schröder','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22573v1','该论文介绍了一种使用傅立叶神经算子（FNO）架构和流匹配目标的方法，名为FNOPE，可以以较低的仿真预算对函数值参数进行后验估计。该方法支持在域的任意离散化处进行后验评估，同时估计矢量值参数。'),('2505.22578v1','Benignity of loss landscape with weight decay requires both large overparametrization and initialization','The optimization of neural networks under weight decay remains poorly\nunderstood from a theoretical standpoint. While weight decay is standard\npractice in modern training procedures, most theoretical analyses focus on\nunregularized settings. In this work, we investigate the loss landscape of the\n$\\ell_2$-regularized training loss for two-layer ReLU networks. We show that\nthe landscape becomes benign -- i.e., free of spurious local minima -- under\nlarge overparametrization, specifically when the network width $m$ satisfies $m\n\\gtrsim \\min(n^d, 2^n)$, where $n$ is the number of data points and $d$ the\ninput dimension. More precisely in this regime, almost all constant activation\nregions contain a global minimum and no spurious local minima. We further show\nthat this level of overparametrization is not only sufficient but also\nnecessary via the example of orthogonal data. Finally, we demonstrate that such\nloss landscape results primarily hold relevance in the large initialization\nregime. In contrast, for small initializations -- corresponding to the feature\nlearning regime -- optimization can still converge to spurious local minima,\ndespite the global benignity of the landscape.','Etienne Boursier, Matthew Bowditch, Matthias Englert, Ranko Lazic','2025-05-28','cs.LG','神经网络/深度学习','http://arxiv.org/pdf/2505.22578v1','本文研究了神经网络在权重衰减下的优化问题，特别是针对两层ReLU网络的$\\ell_2$正则化训练损失的损失景观。他们发现在大规模过参数化时，损失景观变得良性，几乎所有常量激活区域都包含全局最小值，没有虚假局部最小值。'),('2505.22581v1','Tell me Habibi, is it Real or Fake?','Deepfake generation methods are evolving fast, making fake media harder to\ndetect and raising serious societal concerns. Most deepfake detection and\ndataset creation research focuses on monolingual content, often overlooking the\nchallenges of multilingual and code-switched speech, where multiple languages\nare mixed within the same discourse. Code-switching, especially between Arabic\nand English, is common in the Arab world and is widely used in digital\ncommunication. This linguistic mixing poses extra challenges for deepfake\ndetection, as it can confuse models trained mostly on monolingual data. To\naddress this, we introduce \\textbf{ArEnAV}, the first large-scale\nArabic-English audio-visual deepfake dataset featuring intra-utterance\ncode-switching, dialectal variation, and monolingual Arabic content. It\n\\textbf{contains 387k videos and over 765 hours of real and fake videos}. Our\ndataset is generated using a novel pipeline integrating four Text-To-Speech and\ntwo lip-sync models, enabling comprehensive analysis of multilingual multimodal\ndeepfake detection. We benchmark our dataset against existing monolingual and\nmultilingual datasets, state-of-the-art deepfake detection models, and a human\nevaluation, highlighting its potential to advance deepfake research. The\ndataset can be accessed\n\\href{https://huggingface.co/datasets/kartik060702/ArEnAV-Full}{here}.','Kartik Kuckreja, Parul Gupta, Injy Hamed, Thamar Solorio, Muhammad Haris Khan, Abhinav Dhall','2025-05-28','cs.CV','多语言处理、深度伪造检测','http://arxiv.org/pdf/2505.22581v1','该论文介绍了一个大规模的阿拉伯语-英语音视频深度伪造数据集ArEnAV，包含了语言混合、方言变化和单语阿拉伯语内容，通过新颖的生成方法进行创建，用于多语言多模态深度伪造检测研究。'),('2505.22582v1','Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts','Continually expanding new languages for existing large language models (LLMs)\nis a promising yet challenging approach to building powerful multilingual LLMs.\nThe biggest challenge is to make the model continuously learn new languages\nwhile preserving the proficient ability of old languages. To achieve this,\nrecent work utilizes the Mixture-of-Experts (MoE) architecture to expand new\nlanguages by adding new experts and avoid catastrophic forgetting of old\nlanguages by routing corresponding tokens to the original model backbone (old\nexperts). Although intuitive, this kind of method is parameter-costly when\nexpanding new languages and still inevitably impacts the performance of old\nlanguages. To address these limitations, we analyze the language\ncharacteristics of different layers in LLMs and propose a layer-wise expert\nallocation algorithm (LayerMoE) to determine the appropriate number of new\nexperts for each layer. Specifically, we find different layers in LLMs exhibit\ndifferent representation similarities between languages and then utilize the\nsimilarity as the indicator to allocate experts for each layer, i.e., the\nhigher similarity, the fewer experts. Additionally, to further mitigate the\nforgetting of old languages, we add a classifier in front of the router network\non the layers with higher similarity to guide the routing of old language\ntokens. Experimental results show that our method outperforms the previous\nstate-of-the-art baseline with 60% fewer experts in the single-expansion\nsetting and with 33.3% fewer experts in the lifelong-expansion setting,\ndemonstrating the effectiveness of our method.','Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou','2025-05-28','cs.CL','大型语言模型（LLM）','http://arxiv.org/pdf/2505.22582v1','该论文提出了一种新的方法，通过分析大型语言模型中不同层次的语言特征，提出了一种逐层专家分配算法（LayerMoE），以确定每个层次需要的新专家数量，并在具有更高相似性的层次前添加分类器，以指导旧语言标记的路由，以减少对旧语言的影响。'),('2505.22583v1','GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git','Benchmarks for Software Engineering (SE) AI agents, most notably SWE-bench,\nhave catalyzed progress in programming capabilities of AI agents. However, they\noverlook critical developer workflows such as Version Control System (VCS)\noperations. To address this issue, we present GitGoodBench, a novel benchmark\nfor evaluating AI agent performance on VCS tasks. GitGoodBench covers three\ncore Git scenarios extracted from permissive open-source Python, Java, and\nKotlin repositories. Our benchmark provides three datasets: a comprehensive\nevaluation suite (900 samples), a rapid prototyping version (120 samples), and\na training corpus (17,469 samples). We establish baseline performance on the\nprototyping version of our benchmark using GPT-4o equipped with custom tools,\nachieving a 21.11% solve rate overall. We expect GitGoodBench to serve as a\ncrucial stepping stone toward truly comprehensive SE agents that go beyond mere\nprogramming.','Tobias Lindenbauer, Egor Bogomolov, Yaroslav Zharov','2025-05-28','cs.SE','软件工程、人工智能应用','http://arxiv.org/pdf/2505.22583v1','该论文介绍了一个新的基准测试工具 GitGoodBench，用于评估AI代理在版本控制系统任务上的表现。通过使用GPT-4o和自定义工具，在快速原型版本的基准测试中取得了21.11%的解决率。该研究旨在推动软件工程代理的发展，使其不仅仅局限于编程能力。'),('2505.22586v1','Precise In-Parameter Concept Erasure in Large Language Models','Large language models (LLMs) often acquire knowledge during pretraining that\nis undesirable in downstream deployments, e.g., sensitive information or\ncopyrighted content. Existing approaches for removing such knowledge rely on\nfine-tuning, training low-rank adapters or fact-level editing, but these are\neither too coarse, too shallow, or ineffective. In this work, we propose PISCES\n(Precise In-parameter Suppression for Concept EraSure), a novel framework for\nprecisely erasing entire concepts from model parameters by directly editing\ndirections that encode them in parameter space. PISCES uses a disentangler\nmodel to decompose MLP vectors into interpretable features, identifies those\nassociated with a target concept using automated interpretability techniques,\nand removes them from model parameters. Experiments on Gemma 2 and Llama 3.1\nover various concepts show that PISCES achieves modest gains in efficacy over\nleading erasure methods, reducing accuracy on the target concept to as low as\n7.7%, while dramatically improving erasure specificity (by up to 31%) and\nrobustness (by up to 38%). Overall, these results demonstrate that\nfeature-based in-parameter editing enables a more precise and reliable approach\nfor removing conceptual knowledge in language models.','Yoav Gur-Arieh, Clara Suslik, Yihuai Hong, Fazl Barez, Mor Geva','2025-05-28','cs.CL','大型语言模型（LLM）','http://arxiv.org/pdf/2505.22586v1','本文提出了一种名为PISCES的新框架，用于精确擦除大型语言模型中不需要的知识，通过直接编辑参数空间中编码这些知识的方向。实验结果表明，PISCES在准确性、特异性和鲁棒性方面均取得了显著改进。'),('2505.22591v1','Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning','Although large language models demonstrate strong performance across various\ndomains, they still struggle with numerous bad cases in mathematical reasoning.\nPrevious approaches to learning from errors synthesize training data by solely\nextrapolating from isolated bad cases, thereby failing to generalize the\nextensive patterns inherent within these cases. This paper presents\nSelf-Error-Instruct (SEI), a framework that addresses these model weaknesses\nand synthesizes more generalized targeted training data. Specifically, we\nexplore a target model on two mathematical datasets, GSM8K and MATH, to\npinpoint bad cases. Then, we generate error keyphrases for these cases based on\nthe instructor model\\\'s (GPT-4o) analysis and identify error types by clustering\nthese keyphrases. Next, we sample a few bad cases during each generation for\neach identified error type and input them into the instructor model, which\nsynthesizes additional training data using a self-instruct approach. This new\ndata is refined through a one-shot learning process to ensure that only the\nmost effective examples are kept. Finally, we use these curated data to\nfine-tune the target model, iteratively repeating the process to enhance\nperformance. We apply our framework to various models and observe improvements\nin their reasoning abilities across both in-domain and out-of-domain\nmathematics datasets. These results demonstrate the effectiveness of self-error\ninstruction in improving LLMs\\\' mathematical reasoning through error\ngeneralization.','Erxin Yu, Jing Li, Ming Liao, Qi Zhu, Boyang Xue, Minghui Xu, Baojun Wang, Lanqing Hong, Fei Mi, Lifeng Shang','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22591v1','该论文介绍了一种名为Self-Error-Instruct (SEI)的框架，用于改善大型语言模型在数学推理方面的性能。通过识别数学数据集中的错误案例，并利用自我指导方法生成更广义的有针对性的训练数据，最终通过迭代过程提高模型性能。'),('2505.22594v1','GLAMP: An Approximate Message Passing Framework for Transfer Learning with Applications to Lasso-based Estimators','Approximate Message Passing (AMP) algorithms enable precise characterization\nof certain classes of random objects in the high-dimensional limit, and have\nfound widespread applications in fields such as statistics, deep learning,\ngenetics, and communications. However, existing AMP frameworks cannot\nsimultaneously handle matrix-valued iterates and non-separable denoising\nfunctions. This limitation prevents them from precisely characterizing\nestimators that draw information from multiple data sources with distribution\nshifts. In this work, we introduce Generalized Long Approximate Message Passing\n(GLAMP), a novel extension of AMP that addresses this limitation. We rigorously\nprove state evolution for GLAMP. GLAMP significantly broadens the scope of AMP,\nenabling the analysis of transfer learning estimators that were previously out\nof reach. We demonstrate the utility of GLAMP by precisely characterizing the\nrisk of three Lasso-based transfer learning estimators: the Stacked Lasso, the\nModel Averaging Estimator, and the Second Step Estimator. We also demonstrate\nthe remarkable finite sample accuracy of our theory via extensive simulations.','Longlin Wang, Yanke Song, Kuanhao Jiang, Pragya Sur','2025-05-28','math.ST','机器学习','http://arxiv.org/pdf/2505.22594v1','本文介绍了一种名为Generalized Long Approximate Message Passing (GLAMP)的算法，它是Approximate Message Passing (AMP)算法的一种扩展，可以处理矩阵值迭代和非可分离去噪函数，从而能够精确地表征利用多个数据源信息的估计器。'),('2505.22597v1','HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined in HDDL with OpenAI Gym','In recent years, reinforcement learning (RL) methods have been widely tested\nusing tools like OpenAI Gym, though many tasks in these environments could also\nbenefit from hierarchical planning. However, there is a lack of a tool that\nenables seamless integration of hierarchical planning with RL. Hierarchical\nDomain Definition Language (HDDL), used in classical planning, introduces a\nstructured approach well-suited for model-based RL to address this gap. To\nbridge this integration, we introduce HDDLGym, a Python-based tool that\nautomatically generates OpenAI Gym environments from HDDL domains and problems.\nHDDLGym serves as a link between RL and hierarchical planning, supporting\nmulti-agent scenarios and enabling collaborative planning among agents. This\npaper provides an overview of HDDLGym\\\'s design and implementation, highlighting\nthe challenges and design choices involved in integrating HDDL with the Gym\ninterface, and applying RL policies to support hierarchical planning. We also\nprovide detailed instructions and demonstrations for using the HDDLGym\nframework, including how to work with existing HDDL domains and problems from\nInternational Planning Competitions, exemplified by the Transport domain.\nAdditionally, we offer guidance on creating new HDDL domains for multi-agent\nscenarios and demonstrate the practical use of HDDLGym in the Overcooked\ndomain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a\nvaluable tool for studying RL in hierarchical planning, particularly in\nmulti-agent contexts.','Ngoc La, Ruaridh Mon-Williams, Julie A. Shah','2025-05-28','cs.AI','强化学习','http://arxiv.org/pdf/2505.22597v1','该论文介绍了一种名为HDDLGym的工具，通过将HDDL领域与问题转换为OpenAI Gym环境，实现了层次规划与强化学习的无缝集成，支持多智能体场景下的协同规划。'),('2505.22601v1','Machine Unlearning under Overparameterization','Machine unlearning algorithms aim to remove the influence of specific\ntraining samples, ideally recovering the model that would have resulted from\ntraining on the remaining data alone. We study unlearning in the\noverparameterized setting, where many models interpolate the data, and defining\nthe unlearning solution as any loss minimizer over the retained\nset$\\unicode{x2013}$as in prior work in the underparameterized\nsetting$\\unicode{x2013}$is inadequate, since the original model may already\ninterpolate the retained data and satisfy this condition. In this regime, loss\ngradients vanish, rendering prior methods based on gradient perturbations\nineffective, motivating both new unlearning definitions and algorithms. For\nthis setting, we define the unlearning solution as the minimum-complexity\ninterpolator over the retained data and propose a new algorithmic framework\nthat only requires access to model gradients on the retained set at the\noriginal solution. We minimize a regularized objective over perturbations\nconstrained to be orthogonal to these model gradients, a first-order relaxation\nof the interpolation condition. For different model classes, we provide exact\nand approximate unlearning guarantees, and we demonstrate that an\nimplementation of our framework outperforms existing baselines across various\nunlearning experiments.','Jacob L. Block, Aryan Mokhtari, Sanjay Shakkottai','2025-05-28','cs.LG','机器学习/深度学习','http://arxiv.org/pdf/2505.22601v1','该论文研究了在过参数化设置下的机器去学习算法，提出了新的去学习定义和算法框架，通过最小化在保留数据上的正则化目标来实现。他们提供了不同模型类的确切和近似去学习保证，并展示了他们的框架在各种去学习实验中优于现有基线。'),('2505.22602v1','One Rank at a Time: Cascading Error Dynamics in Sequential Learning','Sequential learning -- where complex tasks are broken down into simpler,\nhierarchical components -- has emerged as a paradigm in AI. This paper views\nsequential learning through the lens of low-rank linear regression, focusing\nspecifically on how errors propagate when learning rank-1 subspaces\nsequentially. We present an analysis framework that decomposes the learning\nprocess into a series of rank-1 estimation problems, where each subsequent\nestimation depends on the accuracy of previous steps. Our contribution is a\ncharacterization of the error propagation in this sequential process,\nestablishing bounds on how errors -- e.g., due to limited computational budgets\nand finite precision -- affect the overall model accuracy. We prove that these\nerrors compound in predictable ways, with implications for both algorithmic\ndesign and stability guarantees.','Mahtab Alizadeh Vandchali, Fangshuo, Liao, Anastasios Kyrillidis','2025-05-28','cs.LG','机器学习','http://arxiv.org/pdf/2505.22602v1','本文通过低秩线性回归的视角，研究了顺序学习中错误是如何传播的，将学习过程分解为一系列秩-1估计问题，每个后续估计都依赖于前面步骤的准确性。通过对错误传播的特性进行表征，建立了有关错误如何影响整体模型准确性的界限。这些错误以可预测的方式相互叠加，对算法设计和稳定性保证都有重要影响。'),('2505.22608v1','Effective and Efficient One-pass Compression of Speech Foundation Models Using Sparsity-aware Self-pinching Gates','This paper presents a novel approach for speech foundation models compression\nthat tightly integrates model pruning and parameter update into a single stage.\nHighly compact layer-level tied self-pinching gates each containing only a\nsingle learnable threshold are jointly trained with uncompressed models and\nused in fine-grained neuron level pruning. Experiments conducted on the\nLibriSpeech-100hr corpus suggest that our approach reduces the number of\nparameters of wav2vec2.0-base and HuBERT-large models by 65% and 60%\nrespectively, while incurring no statistically significant word error rate\n(WER) increase on the test-clean dataset. Compared to previously published\nmethods on the same task, our approach not only achieves the lowest WER of\n7.05% on the test-clean dataset under a comparable model compression ratio of\n4.26x, but also operates with at least 25% less model compression time.','Haoning Xu, Zhaoqing Li, Youjun Chen, Huimeng Wang, Guinan Li, Mengzhe Geng, Chengxi Deng, Xunying Liu','2025-05-28','cs.SD','语音处理','http://arxiv.org/pdf/2505.22608v1','该论文提出了一种新颖的语音基础模型压缩方法，将模型修剪和参数更新紧密结合在一个阶段中。通过在未压缩模型中联合训练高度紧凑的层级绑定的自我捏门，并在细粒度神经元级修剪中使用单个可学习阈值，实验表明该方法可以将wav2vec2.0-base和HuBERT-large模型的参数数量分别降低65%和60%，而在测试干净数据集上不会导致统计显著的词错误率（WER）增加。与先前发表的相同任务的方法相比，该方法不仅在相当的模型压缩比（4.26x）下在测试干净数据集上实现了最低的WER为7.05%，而且至少比其他方法少25%的模型压缩时间。'),('2505.22609v1','Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method','In this work, we investigate the performance across multiple classification\nmodels to classify chest X-ray images into four categories of COVID-19,\npneumonia, tuberculosis (TB), and normal cases. We leveraged transfer learning\ntechniques with state-of-the-art pre-trained Convolutional Neural Networks\n(CNNs) models. We fine-tuned these pre-trained architectures on a labeled\nmedical x-ray images. The initial results are promising with high accuracy and\nstrong performance in key classification metrics such as precision, recall, and\nF1 score. We applied Gradient-weighted Class Activation Mapping (Grad-CAM) for\nmodel interpretability to provide visual explanations for classification\ndecisions, improving trust and transparency in clinical applications.','Alanna Hazlett, Naomi Ohashi, Timothy Rodriguez, Sodiq Adewole','2025-05-28','eess.IV','图像识别','http://arxiv.org/pdf/2505.22609v1','本研究探讨了使用多个分类模型对胸部X射线图像进行分类，包括COVID-19、肺炎、结核病（TB）和正常情况。研究采用迁移学习技术与最先进的预训练卷积神经网络（CNNs）模型，对标记的医学X射线图像进行微调。初步结果表现良好，在关键分类指标如精度、召回率和F1分数方面表现出色。研究还应用Gradient-weighted Class Activation Mapping（Grad-CAM）进行模型可解释性分析，提供视觉解释以改善临床应用的信任和透明度。'),('2505.22613v1','RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction','Image recaptioning is widely used to generate training datasets with enhanced\nquality for various multimodal tasks. Existing recaptioning methods typically\nrely on powerful multimodal large language models (MLLMs) to enhance textual\ndescriptions, but often suffer from inaccuracies due to hallucinations and\nincompleteness caused by missing fine-grained details. To address these\nlimitations, we propose RICO, a novel framework that refines captions through\nvisual reconstruction. Specifically, we leverage a text-to-image model to\nreconstruct a caption into a reference image, and prompt an MLLM to identify\ndiscrepancies between the original and reconstructed images to refine the\ncaption. This process is performed iteratively, further progressively promoting\nthe generation of more faithful and comprehensive descriptions. To mitigate the\nadditional computational cost induced by the iterative process, we introduce\nRICO-Flash, which learns to generate captions like RICO using DPO. Extensive\nexperiments demonstrate that our approach significantly improves caption\naccuracy and completeness, outperforms most baselines by approximately 10% on\nboth CapsBench and CompreCap. Code released at\nhttps://github.com/wangyuchi369/RICO.','Yuchi Wang, Yishuo Cai, Shuhuai Ren, Sihan Yang, Linli Yao, Yuanxin Liu, Yuanxing Zhang, Pengfei Wan, Xu Sun','2025-05-28','cs.CV','图像识别','http://arxiv.org/pdf/2505.22613v1','该论文提出了一种通过视觉重建来改进图像描述的新框架 RICO，通过迭代地促进更准确和全面的描述生成。他们还提出了 RICO-Flash 来减少迭代过程带来的额外计算成本。'),('2505.22617v1','The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models','This paper aims to overcome a major obstacle in scaling RL for reasoning with\nLLMs, namely the collapse of policy entropy. Such phenomenon is consistently\nobserved across vast RL runs without entropy intervention, where the policy\nentropy dropped sharply at the early training stage, this diminished\nexploratory ability is always accompanied with the saturation of policy\nperformance. In practice, we establish a transformation equation R=-a*e^H+b\nbetween entropy H and downstream performance R. This empirical law strongly\nindicates that, the policy performance is traded from policy entropy, thus\nbottlenecked by its exhaustion, and the ceiling is fully predictable H=0,\nR=-a+b. Our finding necessitates entropy management for continuous exploration\ntoward scaling compute for RL. To this end, we investigate entropy dynamics\nboth theoretically and empirically. Our derivation highlights that, the change\nin policy entropy is driven by the covariance between action probability and\nthe change in logits, which is proportional to its advantage when using Policy\nGradient-like algorithms. Empirical study shows that, the values of covariance\nterm and entropy differences matched exactly, supporting the theoretical\nconclusion. Moreover, the covariance term stays mostly positive throughout\ntraining, further explaining why policy entropy would decrease monotonically.\nThrough understanding the mechanism behind entropy dynamics, we motivate to\ncontrol entropy by restricting the update of high-covariance tokens.\nSpecifically, we propose two simple yet effective techniques, namely Clip-Cov\nand KL-Cov, which clip and apply KL penalty to tokens with high covariances\nrespectively. Experiments show that these methods encourage exploration, thus\nhelping policy escape entropy collapse and achieve better downstream\nperformance.','Ganqu Cui, Yuchen Zhang, Jiacheng Chen, Lifan Yuan, Zhi Wang, Yuxin Zuo, Haozhan Li, Yuchen Fan, Huayu Chen, Weize Chen, Zhiyuan Liu, Hao Peng, Lei Bai, Wanli Ouyang, Yu Cheng, Bowen Zhou, Ning Ding','2025-05-28','cs.LG','强化学习 (RL)','http://arxiv.org/pdf/2505.22617v1','该论文研究如何克服在大规模RL推理中遇到的策略熵崩溃问题，通过建立策略熵与性能之间的转换方程，探讨策略熵动态变化机制，并提出了Clip-Cov和KL-Cov两种有效的控制策略熵的方法。'),('2505.22618v1','Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding','Diffusion-based large language models (Diffusion LLMs) have shown promise for\nnon-autoregressive text generation with parallel decoding capabilities.\nHowever, the practical inference speed of open-sourced Diffusion LLMs often\nlags behind autoregressive models due to the lack of Key-Value (KV) Cache and\nquality degradation when decoding multiple tokens simultaneously. To bridge\nthis gap, we introduce a novel block-wise approximate KV Cache mechanism\ntailored for bidirectional diffusion models, enabling cache reuse with\nnegligible performance drop. Additionally, we identify the root cause of\ngeneration quality degradation in parallel decoding as the disruption of token\ndependencies under the conditional independence assumption. To address this, we\npropose a confidence-aware parallel decoding strategy that selectively decodes\ntokens exceeding a confidence threshold, mitigating dependency violations and\nmaintaining generation quality. Experimental results on LLaDA and Dream models\nacross multiple LLM benchmarks demonstrate up to \\textbf{27.6$\\times$\nthroughput} improvement with minimal accuracy loss, closing the performance gap\nwith autoregressive models and paving the way for practical deployment of\nDiffusion LLMs.','Chengyue Wu, Hao Zhang, Shuchen Xue, Zhijian Liu, Shizhe Diao, Ligeng Zhu, Ping Luo, Song Han, Enze Xie','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22618v1','该论文介绍了一种新颖的基于扩散的大型语言模型，针对双向扩散模型设计了一种块状近似KV缓存机制，以及提出了一种置信度感知的并行解码策略，实现了高效的非自回归文本生成。'),('2505.22622v1','Principled Out-of-Distribution Generalization via Simplicity','Modern foundation models exhibit remarkable out-of-distribution (OOD)\ngeneralization, solving tasks far beyond the support of their training data.\nHowever, the theoretical principles underpinning this phenomenon remain\nelusive. This paper investigates this problem by examining the compositional\ngeneralization abilities of diffusion models in image generation. Our analysis\nreveals that while neural network architectures are expressive enough to\nrepresent a wide range of models -- including many with undesirable behavior on\nOOD inputs -- the true, generalizable model that aligns with human expectations\ntypically corresponds to the simplest among those consistent with the training\ndata.\n  Motivated by this observation, we develop a theoretical framework for OOD\ngeneralization via simplicity, quantified using a predefined simplicity metric.\nWe analyze two key regimes: (1) the constant-gap setting, where the true model\nis strictly simpler than all spurious alternatives by a fixed gap, and (2) the\nvanishing-gap setting, where the fixed gap is replaced by a smoothness\ncondition ensuring that models close in simplicity to the true model yield\nsimilar predictions. For both regimes, we study the regularized maximum\nlikelihood estimator and establish the first sharp sample complexity guarantees\nfor learning the true, generalizable, simple model.','Jiawei Ge, Amanda Wang, Shange Tang, Chi Jin','2025-05-28','stat.ML','生成模型','http://arxiv.org/pdf/2505.22622v1','本文研究现代基础模型在超出其训练数据支持范围的任务上表现出色的问题，通过研究扩散模型在图像生成中的组合泛化能力来探讨这一现象。作者提出了一个基于简单性的理论框架，通过预定义的简单性度量来量化超出分布泛化。'),('2505.22626v1','SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning','Imitation learning advances robot capabilities by enabling the acquisition of\ndiverse behaviors from human demonstrations. However, large-scale datasets used\nfor policy training often introduce substantial variability in quality, which\ncan negatively impact performance. As a result, automatically curating datasets\nby filtering low-quality samples to improve quality becomes essential. Existing\nrobotic curation approaches rely on costly manual annotations and perform\ncuration at a coarse granularity, such as the dataset or trajectory level,\nfailing to account for the quality of individual state-action pairs. To address\nthis, we introduce SCIZOR, a self-supervised data curation framework that\nfilters out low-quality state-action pairs to improve the performance of\nimitation learning policies. SCIZOR targets two complementary sources of\nlow-quality data: suboptimal data, which hinders learning with undesirable\nactions, and redundant data, which dilutes training with repetitive patterns.\nSCIZOR leverages a self-supervised task progress predictor for suboptimal data\nto remove samples lacking task progression, and a deduplication module\noperating on joint state-action representation for samples with redundant\npatterns. Empirically, we show that SCIZOR enables imitation learning policies\nto achieve higher performance with less data, yielding an average improvement\nof 15.4% across multiple benchmarks. More information is available at:\nhttps://ut-austin-rpl.github.io/SCIZOR/','Yu Zhang, Yuqi Xie, Huihan Liu, Rutav Shah, Michael Wan, Linxi Fan, Yuke Zhu','2025-05-28','cs.RO','强化学习','http://arxiv.org/pdf/2505.22626v1','该论文介绍了一种名为SCIZOR的自监督数据筛选框架，用于过滤低质量的状态-动作对，以提高模仿学习策略的性能。SCIZOR针对两种低质量数据源进行处理：不良数据和冗余数据。通过实验证明，SCIZOR能够使模仿学习策略在多个基准测试中表现更好，平均提高了15.4%。'),('2505.22627v1','Chain-of-Talkers (CoTalk): Fast Human Annotation of Dense Image Captions','While densely annotated image captions significantly facilitate the learning\nof robust vision-language alignment, methodologies for systematically\noptimizing human annotation efforts remain underexplored. We introduce\nChain-of-Talkers (CoTalk), an AI-in-the-loop methodology designed to maximize\nthe number of annotated samples and improve their comprehensiveness under fixed\nbudget constraints (e.g., total human annotation time). The framework is built\nupon two key insights. First, sequential annotation reduces redundant workload\ncompared to conventional parallel annotation, as subsequent annotators only\nneed to annotate the ``residual\\\'\\\' -- the missing visual information that\nprevious annotations have not covered. Second, humans process textual input\nfaster by reading while outputting annotations with much higher throughput via\ntalking; thus a multimodal interface enables optimized efficiency. We evaluate\nour framework from two aspects: intrinsic evaluations that assess the\ncomprehensiveness of semantic units, obtained by parsing detailed captions into\nobject-attribute trees and analyzing their effective connections; extrinsic\nevaluation measures the practical usage of the annotated captions in\nfacilitating vision-language alignment. Experiments with eight participants\nshow our Chain-of-Talkers (CoTalk) improves annotation speed (0.42 vs. 0.30\nunits/sec) and retrieval performance (41.13\\% vs. 40.52\\%) over the parallel\nmethod.','Yijun Shen, Delong Chen, Fan Liu, Xingyu Wang, Chuanyi Zhang, Liang Yao, Yuhui Zheng','2025-05-28','cs.CL','图像识别','http://arxiv.org/pdf/2505.22627v1','该论文介绍了一种名为CoTalk的AI辅助方法，旨在在固定预算约束下最大化标注样本数量并提高其全面性。该方法通过顺序标注减少了冗余工作量，并通过多模态界面优化了效率。实验结果表明，CoTalk提高了标注速度和检索性能。'),('2505.22630v1','Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs','The widespread success of large language models (LLMs) on NLP benchmarks has\nbeen accompanied by concerns that LLMs function primarily as stochastic parrots\nthat reproduce texts similar to what they saw during pre-training, often\nerroneously. But what is the nature of their errors, and do these errors\nexhibit any regularities? In this work, we examine irrelevant context\nhallucinations, in which models integrate misleading contextual cues into their\npredictions. Through behavioral analysis, we show that these errors result from\na structured yet flawed mechanism that we term class-based (mis)generalization,\nin which models combine abstract class cues with features extracted from the\nquery or context to derive answers. Furthermore, mechanistic interpretability\nexperiments on Llama-3, Mistral, and Pythia across 39 factual recall relation\ntypes reveal that this behavior is reflected in the model\\\'s internal\ncomputations: (i) abstract class representations are constructed in lower\nlayers before being refined into specific answers in higher layers, (ii)\nfeature selection is governed by two competing circuits -- one prioritizing\ndirect query-based reasoning, the other incorporating contextual cues -- whose\nrelative influences determine the final output. Our findings provide a more\nnuanced perspective on the stochastic parrot argument: through form-based\ntraining, LLMs can exhibit generalization leveraging abstractions, albeit in\nunreliable ways based on contextual cues -- what we term stochastic chameleons.','Ziling Cheng, Meng Cao, Marc-Antoine Rondeau, Jackie Chi Kit Cheung','2025-05-28','cs.CL','LLM（大型语言模型）、自然语言处理','http://arxiv.org/pdf/2505.22630v1','该论文研究了大型语言模型在自然语言处理基准测试中的成功，以及它们可能存在的错误行为，主要是在预测中集成了误导性的上下文线索。通过行为分析和机械解释实验，揭示了模型在内部计算中存在的结构化但有缺陷的机制，即基于类别的（误）泛化。'),('2505.22633v1','Spatial Knowledge Graph-Guided Multimodal Synthesis','Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced their capabilities; however, their spatial perception\nabilities remain a notable limitation. To address this challenge, multimodal\ndata synthesis offers a promising solution. Yet, ensuring that synthesized data\nadhere to spatial common sense is a non-trivial task. In this work, we\nintroduce SKG2Data, a novel multimodal synthesis approach guided by spatial\nknowledge graphs, grounded in the concept of knowledge-to-data generation.\nSKG2Data automatically constructs a Spatial Knowledge Graph (SKG) to emulate\nhuman-like perception of spatial directions and distances, which is\nsubsequently utilized to guide multimodal data synthesis. Extensive experiments\ndemonstrate that data synthesized from diverse types of spatial knowledge,\nincluding direction and distance, not only enhance the spatial perception and\nreasoning abilities of MLLMs but also exhibit strong generalization\ncapabilities. We hope that the idea of knowledge-based data synthesis can\nadvance the development of spatial intelligence.','Yida Xue, Zhen Bi, Jinnan Yang, Jungang Lou, Huajun Chen, Ningyu Zhang','2025-05-28','cs.CL','LLM（大语言模型）','http://arxiv.org/pdf/2505.22633v1','该论文介绍了一种新颖的多模态数据综合方法SKG2Data，通过空间知识图引导多模态数据合成，以提高多模态大语言模型的空间感知和推理能力，并展现出强大的泛化能力。'),('2505.22635v1','Learning Composable Chains-of-Thought','A common approach for teaching large language models (LLMs) to reason is to\ntrain on chain-of-thought (CoT) traces of in-distribution reasoning problems,\nbut such annotated data is costly to obtain for every problem of interest. We\nwant reasoning models to generalize beyond their training distribution, and\nideally to generalize compositionally: combine atomic reasoning skills to solve\nharder, unseen reasoning tasks. We take a step towards compositional\ngeneralization of reasoning skills when addressing a target compositional task\nthat has no labeled CoT data. We find that simply training models on CoT data\nof atomic tasks leads to limited generalization, but minimally modifying CoT\nformats of constituent atomic tasks to be composable can lead to improvements.\nWe can train \"atomic CoT\" models on the atomic tasks with Composable CoT data\nand combine them with multitask learning or model merging for better zero-shot\nperformance on the target compositional task. Such a combined model can be\nfurther bootstrapped on a small amount of compositional data using rejection\nsampling fine-tuning (RFT). Results on string operations and natural language\nskill compositions show that training LLMs on Composable CoT outperforms\nmultitask learning and continued fine-tuning baselines within a given training\ndata budget.','Fangcong Yin, Zeyu Leo Liu, Liu Leqi, Xi Ye, Greg Durrett','2025-05-28','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22635v1','该论文研究了如何让大型语言模型具有推理能力，通过修改原子任务的CoT数据格式，使得模型能够组合原子推理技能来解决更难的推理任务，并通过多任务学习和模型合并提高了模型在目标组合任务上的零样本性能。'),('2505.22637v1','Understanding (Un)Reliability of Steering Vectors in Language Models','Steering vectors are a lightweight method to control language model behavior\nby adding a learned bias to the activations at inference time. Although\nsteering demonstrates promising performance, recent work shows that it can be\nunreliable or even counterproductive in some cases. This paper studies the\ninfluence of prompt types and the geometry of activation differences on\nsteering reliability. First, we find that all seven prompt types used in our\nexperiments produce a net positive steering effect, but exhibit high variance\nacross samples, and often give an effect opposite of the desired one. No prompt\ntype clearly outperforms the others, and yet the steering vectors resulting\nfrom the different prompt types often differ directionally (as measured by\ncosine similarity). Second, we show that higher cosine similarity between\ntraining set activation differences predicts more effective steering. Finally,\nwe observe that datasets where positive and negative activations are better\nseparated are more steerable. Our results suggest that vector steering is\nunreliable when the target behavior is not represented by a coherent direction.','Joschka Braun, Carsten Eickhoff, David Krueger, Seyed Ali Bahrainian, Dmitrii Krasheninnikov','2025-05-28','cs.LG','LLM (轻量级方法控制语言模型行为)','http://arxiv.org/pdf/2505.22637v1','该论文研究了如何通过在推断时向激活添加学习偏差来控制语言模型行为的轻量级方法。研究发现，不同提示类型和激活差异的几何形状对于操纵的可靠性有影响。结果表明，当目标行为没有明确的方向表示时，向量操纵是不可靠的。'),('2505.22641v1','Spectral Survival Analysis','Survival analysis is widely deployed in a diverse set of fields, including\nhealthcare, business, ecology, etc. The Cox Proportional Hazard (CoxPH) model\nis a semi-parametric model often encountered in the literature. Despite its\npopularity, wide deployment, and numerous variants, scaling CoxPH to large\ndatasets and deep architectures poses a challenge, especially in the\nhigh-dimensional regime. We identify a fundamental connection between rank\nregression and the CoxPH model: this allows us to adapt and extend the\nso-called spectral method for rank regression to survival analysis. Our\napproach is versatile, naturally generalizing to several CoxPH variants,\nincluding deep models. We empirically verify our method\\\'s scalability on\nmultiple real-world high-dimensional datasets; our method outperforms legacy\nmethods w.r.t. predictive performance and efficiency.','Chengzhi Shi, Stratis Ioannidis','2025-05-28','cs.LG','生存分析','http://arxiv.org/pdf/2505.22641v1','该论文提出了一种将排名回归方法应用于生存分析中的方法，以解决Cox Proportional Hazard模型在大规模数据和深度结构中的扩展问题。他们的方法在多个真实高维数据集上验证了可扩展性，并在预测性能和效率方面优于传统方法。'),('2505.22642v1','FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control','Reinforcement learning (RL) has driven significant progress in robotics, but\nits complexity and long training times remain major bottlenecks. In this\nreport, we introduce FastTD3, a simple, fast, and capable RL algorithm that\nsignificantly speeds up training for humanoid robots in popular suites such as\nHumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably\nsimple: we train an off-policy TD3 agent with several modifications -- parallel\nsimulation, large-batch updates, a distributional critic, and carefully tuned\nhyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours\non a single A100 GPU, while remaining stable during training. We also provide a\nlightweight and easy-to-use implementation of FastTD3 to accelerate RL research\nin robotics.','Younggyo Seo, Carmelo Sferrazza, Haoran Geng, Michal Nauman, Zhao-Heng Yin, Pieter Abbeel','2025-05-28','cs.RO','强化学习','http://arxiv.org/pdf/2505.22642v1','该论文介绍了一种名为FastTD3的简单、快速、有效的强化学习算法，可以显著加速人形机器人在HumanoidBench、IsaacLab和MuJoCo Playground等流行套件中的训练速度。他们通过训练一个离策略TD3代理，结合多个修改，如并行仿真、大批量更新、分布式评论家和精心调整的超参数，解决了一系列HumanoidBench任务，在单个A100 GPU上不到3小时内完成训练，并且在训练过程中保持稳定。他们还提供了一个轻量级且易于使用的FastTD3实现，以加速机器人领域的强化学习研究。'),('2505.22645v1','Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese','While the capabilities of Large Language Models (LLMs) have been studied in\nboth Simplified and Traditional Chinese, it is yet unclear whether LLMs exhibit\ndifferential performance when prompted in these two variants of written\nChinese. This understanding is critical, as disparities in the quality of LLM\nresponses can perpetuate representational harms by ignoring the different\ncultural contexts underlying Simplified versus Traditional Chinese, and can\nexacerbate downstream harms in LLM-facilitated decision-making in domains such\nas education or hiring. To investigate potential LLM performance disparities,\nwe design two benchmark tasks that reflect real-world scenarios: regional term\nchoice (prompting the LLM to name a described item which is referred to\ndifferently in Mainland China and Taiwan), and regional name choice (prompting\nthe LLM to choose who to hire from a list of names in both Simplified and\nTraditional Chinese). For both tasks, we audit the performance of 11 leading\ncommercial LLM services and open-sourced models -- spanning those primarily\ntrained on English, Simplified Chinese, or Traditional Chinese. Our analyses\nindicate that biases in LLM responses are dependent on both the task and\nprompting language: while most LLMs disproportionately favored Simplified\nChinese responses in the regional term choice task, they surprisingly favored\nTraditional Chinese names in the regional name choice task. We find that these\ndisparities may arise from differences in training data representation, written\ncharacter preferences, and tokenization of Simplified and Traditional Chinese.\nThese findings highlight the need for further analysis of LLM biases; as such,\nwe provide an open-sourced benchmark dataset to foster reproducible evaluations\nof future LLM behavior across Chinese language variants\n(https://github.com/brucelyu17/SC-TC-Bench).','Hanjia Lyu, Jiebo Luo, Jian Kang, Allison Koenecke','2025-05-28','cs.CL','大型语言模型(LLM)','http://arxiv.org/pdf/2505.22645v1','本文研究了大型语言模型在简体和繁体中文中的表现差异，设计了两个基准任务来评估这种差异，并发现在不同任务和提示语言下，LLM的偏见取决于任务和提示语言。'),('2505.22648v1','WebDancer: Towards Autonomous Information Seeking Agency','Addressing intricate real-world problems necessitates in-depth information\nseeking and multi-step reasoning. Recent progress in agentic systems,\nexemplified by Deep Research, underscores the potential for autonomous\nmulti-step research. In this work, we present a cohesive paradigm for building\nend-to-end agentic information seeking agents from a data-centric and\ntraining-stage perspective. Our approach consists of four key stages: (1)\nbrowsing data construction, (2) trajectories sampling, (3) supervised\nfine-tuning for effective cold start, and (4) reinforcement learning for\nenhanced generalisation. We instantiate this framework in a web agent based on\nthe ReAct, WebDancer. Empirical evaluations on the challenging information\nseeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of\nWebDancer, achieving considerable results and highlighting the efficacy of our\ntraining paradigm. Further analysis of agent training provides valuable\ninsights and actionable, systematic pathways for developing more capable\nagentic models. The codes and demo will be released in\nhttps://github.com/Alibaba-NLP/WebAgent.','Jialong Wu, Baixuan Li, Runnan Fang, Wenbiao Yin, Liwen Zhang, Zhengwei Tao, Dingchu Zhang, Zekun Xi, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou','2025-05-28','cs.CL','自然语言处理','http://arxiv.org/pdf/2505.22648v1','该论文提出了一个建立端到端信息搜索代理的方法，包括数据构建、轨迹采样、监督微调和强化学习等四个关键阶段。他们在具有挑战性的信息搜索基准上进行了实证评估，展示了WebDancer的强大性能，并突出了他们训练范式的有效性。'),('2505.22649v1','Pre-training for Recommendation Unlearning','Modern recommender systems powered by Graph Neural Networks (GNNs) excel at\nmodeling complex user-item interactions, yet increasingly face scenarios\nrequiring selective forgetting of training data. Beyond user requests to remove\nspecific interactions due to privacy concerns or preference changes, regulatory\nframeworks mandate recommender systems\\\' ability to eliminate the influence of\ncertain user data from models. This recommendation unlearning challenge\npresents unique difficulties as removing connections within interaction graphs\ncreates ripple effects throughout the model, potentially impacting\nrecommendations for numerous users. Traditional approaches suffer from\nsignificant drawbacks: fragmentation methods damage graph structure and\ndiminish performance, while influence function techniques make assumptions that\nmay not hold in complex GNNs, particularly with self-supervised or random\narchitectures. To address these limitations, we propose a novel model-agnostic\npre-training paradigm UnlearnRec that prepares systems for efficient unlearning\noperations. Our Influence Encoder takes unlearning requests together with\nexisting model parameters and directly produces updated parameters of unlearned\nmodel with little fine-tuning, avoiding complete retraining while preserving\nmodel performance characteristics. Extensive evaluation on public benchmarks\ndemonstrates that our method delivers exceptional unlearning effectiveness\nwhile providing more than 10x speedup compared to retraining approaches. We\nrelease our method implementation at: https://github.com/HKUDS/UnlearnRec.','Guoxuan Chen, Lianghao Xia, Chao Huang','2025-05-28','cs.IR','推荐系统、图神经网络','http://arxiv.org/pdf/2505.22649v1','该论文提出了一种新颖的模型无关的预训练范式 UnlearnRec，用于解决推荐系统中的推荐遗忘挑战，通过 Influence Encoder 处理取消学习请求，直接生成未学习模型的更新参数，从而在保留模型性能特征的同时避免完全重新训练，提供了比重新训练方法快 10 倍以上的速度提升。'),('2505.22650v1','On Learning Verifiers for Chain-of-Thought Reasoning','Chain-of-Thought reasoning has emerged as a powerful approach for solving\ncomplex mathematical and logical problems. However, it can often veer off track\nthrough incorrect or unsubstantiated inferences. Formal mathematical reasoning,\nwhich can be checked with a formal verifier, is one approach to addressing this\nissue. However, currently LLMs are simply not good enough to solve complex\nproblems in a formal way, and even just formalizing an informal problem\nstatement can be challenging. Motivated by this fact, in this work we consider\nthe problem of learning reliable verifiers for natural language\nChain-of-Thought reasoning. That is, given a problem statement and step-by-step\nsolution in natural language, the aim of the verifier is to output [Yes] if the\nreasoning steps in the solution are all valid, and [No] otherwise. In this work\nwe give a formal PAC-learning framework for studying this problem. We propose\nand analyze several natural verification goals, at different levels of\nstrength, in this framework. We provide sample complexity upper-bounds for\nlearning verifiers satisfying these goals, as well as lower-bound and\nimpossibility results for learning other natural verification objectives\nwithout additional assumptions.','Maria-Florina Balcan, Avrim Blum, Zhiyuan Li, Dravyansh Sharma','2025-05-28','cs.LG','自然语言处理','http://arxiv.org/pdf/2505.22650v1','本文研究了学习可靠的自然语言Chain-of-Thought推理验证器的问题，通过给出一个形式化的PAC-learning框架来研究这个问题，提出并分析了几个自然验证目标，并给出了学习满足这些目标的验证器的样本复杂度上界，以及在没有额外假设的情况下学习其他自然验证目标的下界和不可能性结果。'),('2505.22651v1','Sherlock: Self-Correcting Reasoning in Vision-Language Models','Reasoning Vision-Language Models (VLMs) have shown promising performance on\ncomplex multimodal tasks. However, they still face significant challenges: they\nare highly sensitive to reasoning errors, require large volumes of annotated\ndata or accurate verifiers, and struggle to generalize beyond specific domains.\nTo address these limitations, we explore self-correction as a strategy to\nenhance reasoning VLMs. We first conduct an in-depth analysis of reasoning\nVLMs\\\' self-correction abilities and identify key gaps. Based on our findings,\nwe introduce Sherlock, a self-correction and self-improvement training\nframework. Sherlock introduces a trajectory-level self-correction objective, a\npreference data construction method based on visual perturbation, and a dynamic\n$\\beta$ for preference tuning. Once the model acquires self-correction\ncapabilities using only 20k randomly sampled annotated data, it continues to\nself-improve without external supervision. Built on the Llama3.2-Vision-11B\nmodel, Sherlock achieves remarkable results across eight benchmarks, reaching\nan average accuracy of 64.1 with direct generation and 65.4 after\nself-correction. It outperforms LLaVA-CoT (63.2), Mulberry (63.9), and\nLlamaV-o1 (63.4) while using less than 20% of the annotated data.','Yi Ding, Ruqi Zhang','2025-05-28','cs.CV','LLM (Reasoning Vision-Language Models)','http://arxiv.org/pdf/2505.22651v1','该论文研究了如何通过自我纠正来增强推理视觉语言模型的性能，提出了Sherlock框架，并在多个基准测试中取得了显著的结果。'),('2505.22653v1','The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in Learning to Reason','Recent studies on post-training large language models (LLMs) for reasoning\nthrough reinforcement learning (RL) typically focus on tasks that can be\naccurately verified and rewarded, such as solving math problems. In contrast,\nour research investigates the impact of reward noise, a more practical\nconsideration for real-world scenarios involving the post-training of LLMs\nusing reward models. We found that LLMs demonstrate strong robustness to\nsubstantial reward noise. For example, manually flipping 40% of the reward\nfunction\\\'s outputs in math tasks still allows a Qwen-2.5-7B model to achieve\nrapid convergence, improving its performance on math tasks from 5% to 72%,\ncompared to the 75% accuracy achieved by a model trained with noiseless\nrewards. Surprisingly, by only rewarding the appearance of key reasoning\nphrases (namely reasoning pattern reward, RPR), such as ``first, I need\nto\\\'\\\'-without verifying the correctness of answers, the model achieved peak\ndownstream performance (over 70% accuracy for Qwen-2.5-7B) comparable to models\ntrained with strict correctness verification and accurate rewards. Recognizing\nthe importance of the reasoning process over the final results, we combined RPR\nwith noisy reward models. RPR helped calibrate the noisy reward models,\nmitigating potential false negatives and enhancing the LLM\\\'s performance on\nopen-ended tasks. These findings suggest the importance of improving models\\\'\nfoundational abilities during the pre-training phase while providing insights\nfor advancing post-training techniques. Our code and scripts are available at\nhttps://github.com/trestad/Noisy-Rewards-in-Learning-to-Reason.','Ang Lv, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Rui Yan','2025-05-28','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22653v1','该论文研究了在后训练大型语言模型（LLMs）时使用奖励噪声的影响，发现LLMs对大量奖励噪声表现出强大的稳健性，并通过奖励关键推理短语来提高模型性能。'),('2505.22655v1','Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents','Large-language models (LLMs) and chatbot agents are known to provide wrong\noutputs at times, and it was recently found that this can never be fully\nprevented. Hence, uncertainty quantification plays a crucial role, aiming to\nquantify the level of ambiguity in either one overall number or two numbers for\naleatoric and epistemic uncertainty. This position paper argues that this\ntraditional dichotomy of uncertainties is too limited for the open and\ninteractive setup that LLM agents operate in when communicating with a user,\nand that we need to research avenues that enrich uncertainties in this novel\nscenario. We review the literature and find that popular definitions of\naleatoric and epistemic uncertainties directly contradict each other and lose\ntheir meaning in interactive LLM agent settings. Hence, we propose three novel\nresearch directions that focus on uncertainties in such human-computer\ninteractions: Underspecification uncertainties, for when users do not provide\nall information or define the exact task at the first go, interactive learning,\nto ask follow-up questions and reduce the uncertainty about the current\ncontext, and output uncertainties, to utilize the rich language and speech\nspace to express uncertainties as more than mere numbers. We expect that these\nnew ways of dealing with and communicating uncertainties will lead to LLM agent\ninteractions that are more transparent, trustworthy, and intuitive.','Michael Kirchhof, Gjergji Kasneci, Enkelejda Kasneci','2025-05-28','cs.LG','LLM、自然语言处理','http://arxiv.org/pdf/2505.22655v1','该论文讨论了大型语言模型(LLMs)和聊天机器人在交互过程中提供错误输出的问题，认为传统的不确定性分类方法对于这种开放和交互式环境过于有限，提出了三个新的研究方向来丰富这种情境下的不确定性处理方式。'),('2505.22657v1','3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model','Humans excel at performing complex tasks by leveraging long-term memory\nacross temporal and spatial experiences. In contrast, current Large Language\nModels (LLMs) struggle to effectively plan and act in dynamic, multi-room 3D\nenvironments. We posit that part of this limitation is due to the lack of\nproper 3D spatial-temporal memory modeling in LLMs. To address this, we first\nintroduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000\ntrajectories and 2,892 embodied tasks, question-answering and captioning,\ndesigned to evaluate an agent\\\'s ability to reason over long-term memory in 3D\nenvironments. Second, we propose 3DLLM-Mem, a novel dynamic memory management\nand fusion model for embodied spatial-temporal reasoning and actions in LLMs.\nOur model uses working memory tokens, which represents current observations, as\nqueries to selectively attend to and fuse the most useful spatial and temporal\nfeatures from episodic memory, which stores past observations and interactions.\nOur approach allows the agent to focus on task-relevant information while\nmaintaining memory efficiency in complex, long-horizon environments.\nExperimental results demonstrate that 3DLLM-Mem achieves state-of-the-art\nperformance across various tasks, outperforming the strongest baselines by\n16.5% in success rate on 3DMem-Bench\\\'s most challenging in-the-wild embodied\ntasks.','Wenbo Hu, Yining Hong, Yanjun Wang, Leison Gao, Zibu Wei, Xingcheng Yao, Nanyun Peng, Yonatan Bitton, Idan Szpektor, Kai-Wei Chang','2025-05-28','cs.CV','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22657v1','该论文提出了一个新的动态记忆管理和融合模型，用于在LLMs中进行空间-时间推理和行动，以解决在动态、多房间3D环境中规划和行动的挑战。他们引入了一个全面的基准测试3DMem-Bench，证明了他们的模型在各种任务上取得了最先进的性能。'),('2505.22660v1','Maximizing Confidence Alone Improves Reasoning','Reinforcement learning (RL) has enabled machine learning models to achieve\nsignificant advances in many fields. Most recently, RL has empowered frontier\nlanguage models to solve challenging math, science, and coding problems.\nHowever, central to any RL algorithm is the reward function, and reward\nengineering is a notoriously difficult problem in any domain. In this paper, we\npropose RENT: Reinforcement Learning via Entropy Minimization -- a fully\nunsupervised RL method that requires no external reward or ground-truth\nanswers, and instead uses the model\\\'s entropy of its underlying distribution as\nan intrinsic reward. We find that by reinforcing the chains of thought that\nyield high model confidence on its generated answers, the model improves its\nreasoning ability. In our experiments, we showcase these improvements on an\nextensive suite of commonly-used reasoning benchmarks, including GSM8K,\nMATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen and\nMistral families. The generality of our unsupervised learning method lends\nitself to applicability in a wide range of domains where external supervision\nis limited or unavailable.','Mihir Prabhudesai, Lili Chen, Alex Ippoliti, Katerina Fragkiadaki, Hao Liu, Deepak Pathak','2025-05-28','cs.LG','强化学习','http://arxiv.org/pdf/2505.22660v1','本文提出了一种名为RENT的全无监督强化学习方法，通过最小化模型分布的熵作为内在奖励，而无需外部奖励或真实答案，以改进模型的推理能力。实验结果表明，在多个常用推理基准测试中，包括GSM8K、MATH500、AMC、AIME和GPQA等，以及不同规模的模型，该方法取得了显著的改进。'),('2505.22661v1','GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning','The evaluation of large language models (LLMs) has traditionally relied on\nstatic benchmarks, a paradigm that poses two major limitations: (1) predefined\ntest sets lack adaptability to diverse application domains, and (2)\nstandardized evaluation protocols often fail to capture fine-grained\nassessments of domain-specific knowledge and contextual reasoning abilities. To\novercome these challenges, we propose GuessArena, an adaptive evaluation\nframework grounded in adversarial game-based interactions. Inspired by the\ninteractive structure of the Guess Who I Am? game, our framework seamlessly\nintegrates dynamic domain knowledge modeling with progressive reasoning\nassessment to improve evaluation fidelity. Empirical studies across five\nvertical domains-finance, healthcare, manufacturing, information technology,\nand education-demonstrate that GuessArena effectively distinguishes LLMs in\nterms of domain knowledge coverage and reasoning chain completeness. Compared\nto conventional benchmarks, our method provides substantial advantages in\ninterpretability, scalability, and scenario adaptability.','Qingchen Yu, Zifan Zheng, Ding Chen, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li','2025-05-28','cs.CL','LLM (Large Language Models)','http://arxiv.org/pdf/2505.22661v1','该论文提出了一个名为GuessArena的自适应评估框架，通过对抗游戏交互来评估大型语言模型的领域知识覆盖和推理链完整性。实证研究表明，GuessArena在解释性、可扩展性和场景适应性方面相比传统基准具有显著优势。'),('2505.22662v1','AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models','The reasoning-capable large language models (LLMs) demonstrate strong\nperformance on complex reasoning tasks but often suffer from overthinking,\ngenerating unnecessarily long chain-of-thought (CoT) reasoning paths for easy\nreasoning questions, thereby increasing inference cost and latency. Recent\napproaches attempt to address this challenge by manually deciding when to apply\nlong or short reasoning. However, they lack the flexibility to adapt CoT length\ndynamically based on question complexity. In this paper, we propose Auto\nLong-Short Reasoning (AutoL2S), a dynamic and model-agnostic framework that\nenables LLMs to dynamically compress their generated reasoning path based on\nthe complexity of the reasoning question. AutoL2S enables a learned paradigm,\nin which LLMs themselves can decide when longer reasoning is necessary and when\nshorter reasoning suffices, by training on data annotated with our proposed\nmethod, which includes both long and short CoT paths and a special <EASY>\ntoken. We then use <EASY> token to indicate when the model can skip generating\nlengthy CoT reasoning. This proposed annotation strategy can enhance the LLMs\\\'\nability to generate shorter CoT reasoning paths with improved quality after\ntraining. Extensive evaluation results show that AutoL2S reduces the length of\nreasoning generation by up to 57% without compromising performance,\ndemonstrating the effectiveness of AutoL2S for scalable and efficient LLM\nreasoning.','Feng Luo, Yu-Neng Chuang, Guanchu Wang, Hoang Anh Duy Le, Shaochen Zhong, Hongyi Liu, Jiayi Yuan, Yang Sui, Vladimir Braverman, Vipin Chaudhary, Xia Hu','2025-05-28','cs.CL','LLM (大型语言模型)','http://arxiv.org/pdf/2505.22662v1','本文提出了一种名为Auto Long-Short Reasoning (AutoL2S) 的动态和模型无关的框架，使得大型语言模型能够根据推理问题的复杂性动态压缩生成的推理路径，从而减少推理生成的长度，提高效率。通过在经过我们提出的方法注释的数据上进行训练，使得语言模型自己能够决定何时需要更长的推理和何时足够短的推理。实验结果表明，AutoL2S 可以将推理生成的长度减少高达57%，同时不影响性能。');
/*!40000 ALTER TABLE `ai_processed_papers` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `arxiv_papers`
--

DROP TABLE IF EXISTS `arxiv_papers`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `arxiv_papers` (
  `paper_id` varchar(50) COLLATE utf8mb4_unicode_ci NOT NULL,
  `title` text COLLATE utf8mb4_unicode_ci,
  `abstract` text COLLATE utf8mb4_unicode_ci,
  `authors` text COLLATE utf8mb4_unicode_ci,
  `published` date DEFAULT NULL,
  `category` varchar(20) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `pdf_url` text COLLATE utf8mb4_unicode_ci,
  PRIMARY KEY (`paper_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `arxiv_papers`
--

LOCK TABLES `arxiv_papers` WRITE;
/*!40000 ALTER TABLE `arxiv_papers` DISABLE KEYS */;
INSERT INTO `arxiv_papers` VALUES ('2505.20015v1','On the class of coding optimality of human languages and the origins of Zipf\\\'s law','Here we present a new class of optimality for coding systems. Members of that\nclass are separated linearly from optimal coding and thus exhibit Zipf\\\'s law,\nnamely a power-law distribution of frequency ranks. Whithin that class, Zipf\\\'s\nlaw, the size-rank law and the size-probability law form a group-like\nstructure. We identify human languages that are members of the class. All\nlanguages showing sufficient agreement with Zipf\\\'s law are potential members of\nthe class. In contrast, there are communication systems in other species that\ncannot be members of that class for exhibiting an exponential distribution\ninstead but dolphins and humpback whales might. We provide a new insight into\nplots of frequency versus rank in double logarithmic scale. For any system, a\nstraight line in that scale indicates that the lengths of optimal codes under\nnon-singular coding and under uniquely decodable encoding are separated by a\nlinear function whose slope is the exponent of Zipf\\\'s law. For systems under\ncompression and constrained to be uniquely decodable, such a straight line may\nindicate that the system is coding close to optimality. Our findings provide\nsupport for the hypothesis that Zipf\\\'s law originates from compression.','Ramon Ferrer-i-Cancho','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20015v1'),('2505.20016v1','TTPA: Token-level Tool-use Preference Alignment Training Framework with Fine-grained Evaluation','Existing tool-learning methods usually rely on supervised fine-tuning, they\noften overlook fine-grained optimization of internal tool call details, leading\nto limitations in preference alignment and error discrimination. To overcome\nthese challenges, we propose Token-level Tool-use Preference Alignment Training\nFramework (TTPA), a training paradigm for constructing token-level tool-use\npreference datasets that align LLMs with fine-grained preferences using a novel\nerror-oriented scoring mechanism. TTPA first introduces reversed dataset\nconstruction, a method for creating high-quality, multi-turn tool-use datasets\nby reversing the generation flow. Additionally, we propose Token-level\nPreference Sampling (TPS) to capture fine-grained preferences by modeling\ntoken-level differences during generation. To address biases in scoring, we\nintroduce the Error-oriented Scoring Mechanism (ESM), which quantifies\ntool-call errors and can be used as a training signal. Extensive experiments on\nthree diverse benchmark datasets demonstrate that TTPA significantly improves\ntool-using performance while showing strong generalization ability across\nmodels and datasets.','Chengrui Huang, Shen Gao, Zhengliang Shi, Dongsheng Wang, Shuo Shang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20016v1'),('2505.20017v2','Linear Bandits with Non-i.i.d. Noise','We study the linear stochastic bandit problem, relaxing the standard i.i.d.\nassumption on the observation noise. As an alternative to this restrictive\nassumption, we allow the noise terms across rounds to be sub-Gaussian but\ninterdependent, with dependencies that decay over time. To address this\nsetting, we develop new confidence sequences using a recently introduced\nreduction scheme to sequential probability assignment, and use these to derive\na bandit algorithm based on the principle of optimism in the face of\nuncertainty. We provide regret bounds for the resulting algorithm, expressed in\nterms of the decay rate of the strength of dependence between observations.\nAmong other results, we show that our bounds recover the standard rates up to a\nfactor of the mixing time for geometrically mixing observation noise.','Baptiste Abélès, Eugenio Clerico, Hamish Flynn, Gergely Neu','2025-05-26','stat.ML','http://arxiv.org/pdf/2505.20017v2'),('2505.20020v1','Ontology- and LLM-based Data Harmonization for Federated Learning in Healthcare','The rise of electronic health records (EHRs) has unlocked new opportunities\nfor medical research, but privacy regulations and data heterogeneity remain key\nbarriers to large-scale machine learning. Federated learning (FL) enables\ncollaborative modeling without sharing raw data, yet faces challenges in\nharmonizing diverse clinical datasets. This paper presents a two-step data\nalignment strategy integrating ontologies and large language models (LLMs) to\nsupport secure, privacy-preserving FL in healthcare, demonstrating its\neffectiveness in a real-world project involving semantic mapping of EHR data.','Natallia Kokash, Lei Wang, Thomas H. Gillespie, Adam Belloum, Paola Grosso, Sara Quinney, Lang Li, Bernard de Bono','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20020v1'),('2505.20021v1','Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models','Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal\ncomprehension and reasoning capabilities, yet they often struggle with\ntrivially simple visual tasks. In this work, we focus on the domain of basic 2D\nEuclidean geometry and systematically categorize the fundamental, indivisible\nvisual perception skills, which we refer to as atomic visual skills. We then\nintroduce the Atomic Visual Skills Dataset (AVSD) for evaluating VLMs on the\natomic visual skills. Using AVSD, we benchmark state-of-the-art VLMs and find\nthat they struggle with these tasks, despite being trivial for adult humans.\nOur findings highlight the need for purpose-built datasets to train and\nevaluate VLMs on atomic, rather than composite, visual perception tasks.','Hyunsik Chae, Seungwoo Yoon, Jaden Park, Chloe Yewon Chun, Yongin Cho, Mu Cai, Yong Jae Lee, Ernest K. Ryu','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20021v1'),('2505.20023v1','Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking','Autonomous agents, which perceive environments and take actions to achieve\ngoals, have become increasingly feasible with the advancements in large\nlanguage models (LLMs). However, current powerful agents often depend on\nsophisticated prompt engineering combined with closed-source LLMs like GPT-4.\nAlthough training open-source LLMs using expert trajectories from teacher\nmodels has yielded some improvements in agent capabilities, this approach still\nfaces limitations such as performance plateauing and error propagation. To\nmitigate these challenges, we propose STeP, a novel method for improving\nLLM-based agent training. We synthesize self-reflected trajectories that\ninclude reflections and corrections of error steps, which enhance the\neffectiveness of LLM agents in learning from teacher models, enabling them to\nbecome agents capable of self-reflecting and correcting. We also introduce\npartial masking strategy that prevents the LLM from internalizing incorrect or\nsuboptimal steps. Experiments demonstrate that our method improves agent\nperformance across three representative tasks: ALFWorld, WebShop, and SciWorld.\nFor the open-source model LLaMA2-7B-Chat, when trained using self-reflected\ntrajectories constructed with Qwen1.5-110B-Chat as the teacher model, it\nachieves comprehensive improvements with less training data compared to agents\ntrained exclusively on expert trajectories.','Yihan Chen, Benfeng Xu, Xiaorui Wang, Yongdong Zhang, Zhendong Mao','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20023v1'),('2505.20024v1','ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving','Due to the powerful vision-language reasoning and generalization abilities,\nmultimodal large language models (MLLMs) have garnered significant attention in\nthe field of end-to-end (E2E) autonomous driving. However, their application to\nclosed-loop systems remains underexplored, and current MLLM-based methods have\nnot shown clear superiority to mainstream E2E imitation learning approaches. In\nthis work, we propose ReasonPlan, a novel MLLM fine-tuning framework designed\nfor closed-loop driving through holistic reasoning with a self-supervised Next\nScene Prediction task and supervised Decision Chain-of-Thought process. This\ndual mechanism encourages the model to align visual representations with\nactionable driving context, while promoting interpretable and causally grounded\ndecision making. We curate a planning-oriented decision reasoning dataset,\nnamely PDR, comprising 210k diverse and high-quality samples. Our method\noutperforms the mainstream E2E imitation learning method by a large margin of\n19% L2 and 16.1 driving score on Bench2Drive benchmark. Furthermore, ReasonPlan\ndemonstrates strong zero-shot generalization on unseen DOS benchmark,\nhighlighting its adaptability in handling zero-shot corner cases. Code and\ndataset will be found in https://github.com/Liuxueyi/ReasonPlan.','Xueyi Liu, Zuodong Zhong, Yuxin Guo, Yun-Fu Liu, Zhiguo Su, Qichao Zhang, Junli Wang, Yinfeng Gao, Yupeng Zheng, Qiao Lin, Huiyong Chen, Dongbin Zhao','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20024v1'),('2505.20026v1','Gradient Inversion Transcript: Leveraging Robust Generative Priors to Reconstruct Training Data from Gradient Leakage','We propose Gradient Inversion Transcript (GIT), a novel generative approach\nfor reconstructing training data from leaked gradients. GIT employs a\ngenerative attack model, whose architecture is tailored to align with the\nstructure of the leaked model based on theoretical analysis. Once trained\noffline, GIT can be deployed efficiently and only relies on the leaked\ngradients to reconstruct the input data, rendering it applicable under various\ndistributed learning environments. When used as a prior for other iterative\noptimization-based methods, GIT not only accelerates convergence but also\nenhances the overall reconstruction quality. GIT consistently outperforms\nexisting methods across multiple datasets and demonstrates strong robustness\nunder challenging conditions, including inaccurate gradients, data distribution\nshifts and discrepancies in model parameters.','Xinping Chen, Chen Liu','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20026v1'),('2505.20027v1','Multi-modal brain encoding models for multi-modal stimuli','Despite participants engaging in unimodal stimuli, such as watching images or\nsilent videos, recent work has demonstrated that multi-modal Transformer models\ncan predict visual brain activity impressively well, even with incongruent\nmodality representations. This raises the question of how accurately these\nmulti-modal models can predict brain activity when participants are engaged in\nmulti-modal stimuli. As these models grow increasingly popular, their use in\nstudying neural activity provides insights into how our brains respond to such\nmulti-modal naturalistic stimuli, i.e., where it separates and integrates\ninformation across modalities through a hierarchy of early sensory regions to\nhigher cognition. We investigate this question by using multiple unimodal and\ntwo types of multi-modal models-cross-modal and jointly pretrained-to determine\nwhich type of model is more relevant to fMRI brain activity when participants\nare engaged in watching movies. We observe that both types of multi-modal\nmodels show improved alignment in several language and visual regions. This\nstudy also helps in identifying which brain regions process unimodal versus\nmulti-modal information. We further investigate the contribution of each\nmodality to multi-modal alignment by carefully removing unimodal features one\nby one from multi-modal representations, and find that there is additional\ninformation beyond the unimodal embeddings that is processed in the visual and\nlanguage regions. Based on this investigation, we find that while for\ncross-modal models, their brain alignment is partially attributed to the video\nmodality; for jointly pretrained models, it is partially attributed to both the\nvideo and audio modalities. This serves as a strong motivation for the\nneuroscience community to investigate the interpretability of these models for\ndeepening our understanding of multi-modal information processing in brain.','Subba Reddy Oota, Khushbu Pahwa, Mounika Marreddy, Maneesh Singh, Manish Gupta, Bapi S. Raju','2025-05-26','q-bio.NC','http://arxiv.org/pdf/2505.20027v1'),('2505.20029v1','Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)','Transformer-based language models, though not explicitly trained to mimic\nbrain recordings, have demonstrated surprising alignment with brain activity.\nProgress in these models-through increased size, instruction-tuning, and\nmultimodality-has led to better representational alignment with neural data.\nRecently, a new class of instruction-tuned multimodal LLMs (MLLMs) have\nemerged, showing remarkable zero-shot capabilities in open-ended multimodal\nvision tasks. However, it is unknown whether MLLMs, when prompted with natural\ninstructions, lead to better brain alignment and effectively capture\ninstruction-specific representations. To address this, we first investigate\nbrain alignment, i.e., measuring the degree of predictivity of neural visual\nactivity using text output response embeddings from MLLMs as participants\nengage in watching natural scenes. Experiments with 10 different instructions\nshow that MLLMs exhibit significantly better brain alignment than vision-only\nmodels and perform comparably to non-instruction-tuned multimodal models like\nCLIP. We also find that while these MLLMs are effective at generating\nhigh-quality responses suitable to the task-specific instructions, not all\ninstructions are relevant for brain alignment. Further, by varying\ninstructions, we make the MLLMs encode instruction-specific visual concepts\nrelated to the input image. This analysis shows that MLLMs effectively capture\ncount-related and recognition-related concepts, demonstrating strong alignment\nwith brain activity. Notably, the majority of the explained variance of the\nbrain encoding models is shared between MLLM embeddings of image captioning and\nother instructions. These results suggest that enhancing MLLMs\\\' ability to\ncapture task-specific information could lead to better differentiation between\nvarious types of instructions, and thereby improving their precision in\npredicting brain responses.','Subba Reddy Oota, Akshett Jindal, Ishani Mondal, Khushbu Pahwa, Satya Sai Srinath Namburi, Manish Shrivastava, Maneesh Singh, Bapi S. Raju, Manish Gupta','2025-05-26','q-bio.NC','http://arxiv.org/pdf/2505.20029v1'),('2505.20030v1','Multiple Descents in Deep Learning as a Sequence of Order-Chaos Transitions','We observe a novel \\\'multiple-descent\\\' phenomenon during the training process\nof LSTM, in which the test loss goes through long cycles of up and down trend\nmultiple times after the model is overtrained. By carrying out asymptotic\nstability analysis of the models, we found that the cycles in test loss are\nclosely associated with the phase transition process between order and chaos,\nand the local optimal epochs are consistently at the critical transition point\nbetween the two phases. More importantly, the global optimal epoch occurs at\nthe first transition from order to chaos, where the \\\'width\\\' of the \\\'edge of\nchaos\\\' is the widest, allowing the best exploration of better weight\nconfigurations for learning.','Wenbo Wei, Nicholas Chong Jia Le, Choy Heng Lai, Ling Feng','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20030v1'),('2505.20032v1','ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers','Tactile sensing provides local essential information that is complementary to\nvisual perception, such as texture, compliance, and force. Despite recent\nadvances in visuotactile representation learning, challenges remain in fusing\nthese modalities and generalizing across tasks and environments without heavy\nreliance on pre-trained vision-language models. Moreover, existing methods do\nnot study positional encodings, thereby overlooking the multi-scale spatial\nreasoning needed to capture fine-grained visuotactile correlations. We\nintroduce ViTaPEs, a transformer-based framework that robustly integrates\nvisual and tactile input data to learn task-agnostic representations for\nvisuotactile perception. Our approach exploits a novel multi-scale positional\nencoding scheme to capture intra-modal structures, while simultaneously\nmodeling cross-modal cues. Unlike prior work, we provide provable guarantees in\nvisuotactile fusion, showing that our encodings are injective,\nrigid-motion-equivariant, and information-preserving, validating these\nproperties empirically. Experiments on multiple large-scale real-world datasets\nshow that ViTaPEs not only surpasses state-of-the-art baselines across various\nrecognition tasks but also demonstrates zero-shot generalization to unseen,\nout-of-domain scenarios. We further demonstrate the transfer-learning strength\nof ViTaPEs in a robotic grasping task, where it outperforms state-of-the-art\nbaselines in predicting grasp success. Project page:\nhttps://sites.google.com/view/vitapes','Fotios Lygerakis, Ozan Özdenizci, Elmar Rückert','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20032v1'),('2505.20033v2','EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition','Effective human-AI interaction relies on AI\\\'s ability to accurately perceive\nand interpret human emotions. Current benchmarks for vision and vision-language\nmodels are severely limited, offering a narrow emotional spectrum that\noverlooks nuanced states (e.g., bitterness, intoxication) and fails to\ndistinguish subtle differences between related feelings (e.g., shame vs.\nembarrassment). Existing datasets also often use uncontrolled imagery with\noccluded faces and lack demographic diversity, risking significant bias. To\naddress these critical gaps, we introduce EmoNet Face, a comprehensive\nbenchmark suite. EmoNet Face features: (1) A novel 40-category emotion\ntaxonomy, meticulously derived from foundational research to capture finer\ndetails of human emotional experiences. (2) Three large-scale, AI-generated\ndatasets (EmoNet HQ, Binary, and Big) with explicit, full-face expressions and\ncontrolled demographic balance across ethnicity, age, and gender. (3) Rigorous,\nmulti-expert annotations for training and high-fidelity evaluation. (4) We\nbuilt EmpathicInsight-Face, a model achieving human-expert-level performance on\nour benchmark. The publicly released EmoNet Face suite - taxonomy, datasets,\nand model - provides a robust foundation for developing and evaluating AI\nsystems with a deeper understanding of human emotions.','Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Felix Friedrich, Maurice Kraus, Krishna Kalyan, Kourosh Nadi, Huu Nguyen, Kristian Kersting, Sören Auer','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20033v2'),('2505.20034v1','Graph Wave Networks','Dynamics modeling has been introduced as a novel paradigm in message passing\n(MP) of graph neural networks (GNNs). Existing methods consider MP between\nnodes as a heat diffusion process, and leverage heat equation to model the\ntemporal evolution of nodes in the embedding space. However, heat equation can\nhardly depict the wave nature of graph signals in graph signal processing.\nBesides, heat equation is essentially a partial differential equation (PDE)\ninvolving a first partial derivative of time, whose numerical solution usually\nhas low stability, and leads to inefficient model training. In this paper, we\nwould like to depict more wave details in MP, since graph signals are\nessentially wave signals that can be seen as a superposition of a series of\nwaves in the form of eigenvector. This motivates us to consider MP as a wave\npropagation process to capture the temporal evolution of wave signals in the\nspace. Based on wave equation in physics, we innovatively develop a graph wave\nequation to leverage the wave propagation on graphs. In details, we demonstrate\nthat the graph wave equation can be connected to traditional spectral GNNs,\nfacilitating the design of graph wave networks based on various Laplacians and\nenhancing the performance of the spectral GNNs. Besides, the graph wave\nequation is particularly a PDE involving a second partial derivative of time,\nwhich has stronger stability on graphs than the heat equation that involves a\nfirst partial derivative of time. Additionally, we theoretically prove that the\nnumerical solution derived from the graph wave equation are constantly stable,\nenabling to significantly enhance model efficiency while ensuring its\nperformance. Extensive experiments show that GWNs achieve SOTA and efficient\nperformance on benchmark datasets, and exhibit outstanding performance in\naddressing challenging graph problems, such as over-smoothing and heterophily.','Juwei Yue, Haikuo Li, Jiawei Sheng, Yihan Guo, Xinghua Zhang, Chuan Zhou, Tingwen Liu, Li Guo','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20034v1'),('2505.20036v1','Beyond Simple Concatenation: Fairly Assessing PLM Architectures for Multi-Chain Protein-Protein Interactions Prediction','Protein-protein interactions (PPIs) are fundamental to numerous cellular\nprocesses, and their characterization is vital for understanding disease\nmechanisms and guiding drug discovery. While protein language models (PLMs)\nhave demonstrated remarkable success in predicting protein structure and\nfunction, their application to sequence-based PPI binding affinity prediction\nremains relatively underexplored. This gap is often attributed to the scarcity\nof high-quality, rigorously refined datasets and the reliance on simple\nstrategies for concatenating protein representations. In this work, we address\nthese limitations. First, we introduce a meticulously curated version of the\nPPB-Affinity dataset of a total of 8,207 unique protein-protein interaction\nentries, by resolving annotation inconsistencies and duplicate entries for\nmulti-chain protein interactions. This dataset incorporates a stringent, less\nthan or equal to 30%, sequence identity threshold to ensure robust splitting\ninto training, validation, and test sets, minimizing data leakage. Second, we\npropose and systematically evaluate four architectures for adapting PLMs to PPI\nbinding affinity prediction: embeddings concatenation (EC), sequences\nconcatenation (SC), hierarchical pooling (HP), and pooled attention addition\n(PAD). These architectures were assessed using two training methods: full\nfine-tuning and a lightweight approach employing ConvBERT heads over frozen PLM\nfeatures. Our comprehensive experiments across multiple leading PLMs (ProtT5,\nESM2, Ankh, Ankh2, and ESM3) demonstrated that the HP and PAD architectures\nconsistently outperform conventional concatenation methods, achieving up to 12%\nincrease in terms of Spearman correlation. These results highlight the\nnecessity of sophisticated architectural designs to fully exploit the\ncapabilities of PLMs for nuanced PPI binding affinity prediction.','Hazem Alsamkary, Mohamed Elshaffei, Mohamed Soudy, Sara Ossman, Abdallah Amr, Nehal Adel Abdelsalam, Mohamed Elkerdawy, Ahmed Elnaggar','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20036v1'),('2505.20045v1','Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs','Large language models (LLMs) exhibit impressive fluency, but often produce\ncritical errors known as \"hallucinations\". Uncertainty quantification (UQ)\nmethods are a promising tool for coping with this fundamental shortcoming. Yet,\nexisting UQ methods face challenges such as high computational overhead or\nreliance on supervised learning. Here, we aim to bridge this gap. In\nparticular, we propose RAUQ (Recurrent Attention-based Uncertainty\nQuantification), an unsupervised approach that leverages intrinsic attention\npatterns in transformers to detect hallucinations efficiently. By analyzing\nattention weights, we identified a peculiar pattern: drops in attention to\npreceding tokens are systematically observed during incorrect generations for\ncertain \"uncertainty-aware\" heads. RAUQ automatically selects such heads,\nrecurrently aggregates their attention weights and token-level confidences, and\ncomputes sequence-level uncertainty scores in a single forward pass.\nExperiments across 4 LLMs and 12 question answering, summarization, and\ntranslation tasks demonstrate that RAUQ yields excellent results, outperforming\nstate-of-the-art UQ methods using minimal computational overhead (<1% latency).\nMoreover, it requires no task-specific labels and no careful hyperparameter\ntuning, offering plug-and-play real-time hallucination detection in white-box\nLLMs.','Artem Vazhentsev, Lyudmila Rvanova, Gleb Kuzmin, Ekaterina Fadeeva, Ivan Lazichny, Alexander Panchenko, Maxim Panov, Timothy Baldwin, Mrinmaya Sachan, Preslav Nakov, Artem Shelmanov','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20045v1'),('2505.20046v1','REARANK: Reasoning Re-ranking Agent via Reinforcement Learning','We present REARANK, a large language model (LLM)-based listwise reasoning\nreranking agent. REARANK explicitly reasons before reranking, significantly\nimproving both performance and interpretability. Leveraging reinforcement\nlearning and data augmentation, REARANK achieves substantial improvements over\nbaseline models across popular information retrieval benchmarks, notably\nrequiring only 179 annotated samples. Built on top of Qwen2.5-7B, our\nREARANK-7B demonstrates performance comparable to GPT-4 on both in-domain and\nout-of-domain benchmarks and even surpasses GPT-4 on reasoning-intensive BRIGHT\nbenchmarks. These results underscore the effectiveness of our approach and\nhighlight how reinforcement learning can enhance LLM reasoning capabilities in\nreranking.','Le Zhang, Bo Wang, Xipeng Qiu, Siva Reddy, Aishwarya Agrawal','2025-05-26','cs.IR','http://arxiv.org/pdf/2505.20046v1'),('2505.20047v1','Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks','Large language models (LLMs) show remarkable promise for democratizing\nautomated reasoning by generating formal specifications. However, a fundamental\ntension exists: LLMs are probabilistic, while formal verification demands\ndeterministic guarantees. This paper addresses this epistemological gap by\ncomprehensively investigating failure modes and uncertainty quantification (UQ)\nin LLM-generated formal artifacts. Our systematic evaluation of five frontier\nLLMs reveals Satisfiability Modulo Theories (SMT) based autoformalization\\\'s\ndomain-specific impact on accuracy (from +34.8% on logical tasks to -44.5% on\nfactual ones), with known UQ techniques like the entropy of token probabilities\nfailing to identify these errors. We introduce a probabilistic context-free\ngrammar (PCFG) framework to model LLM outputs, yielding a refined uncertainty\ntaxonomy. We find uncertainty signals are task-dependent (e.g., grammar entropy\nfor logic, AUROC>0.93). Finally, a lightweight fusion of these signals enables\nselective verification, drastically reducing errors (14-100%) with minimal\nabstention, transforming LLM-driven formalization into a reliable engineering\ndiscipline.','Debargha Ganguly, Vikash Singh, Sreehari Sankar, Biyao Zhang, Xuecen Zhang, Srinivasan Iyengar, Xiaotian Han, Amit Sharma, Shivkumar Kalyanaraman, Vipin Chaudhary','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20047v1'),('2505.20048v1','Synthetic Time Series Forecasting with Transformer Architectures: Extensive Simulation Benchmarks','Time series forecasting plays a critical role in domains such as energy,\nfinance, and healthcare, where accurate predictions inform decision-making\nunder uncertainty. Although Transformer-based models have demonstrated success\nin sequential modeling, their adoption for time series remains limited by\nchallenges such as noise sensitivity, long-range dependencies, and a lack of\ninductive bias for temporal structure. In this work, we present a unified and\nprincipled framework for benchmarking three prominent Transformer forecasting\narchitectures-Autoformer, Informer, and Patchtst-each evaluated through three\narchitectural variants: Minimal, Standard, and Full, representing increasing\nlevels of complexity and modeling capacity.\n  We conduct over 1500 controlled experiments on a suite of ten synthetic\nsignals, spanning five patch lengths and five forecast horizons under both\nclean and noisy conditions. Our analysis reveals consistent patterns across\nmodel families.\n  To advance this landscape further, we introduce the Koopman-enhanced\nTransformer framework, Deep Koopformer, which integrates operator-theoretic\nlatent state modeling to improve stability and interpretability. We demonstrate\nits efficacy on nonlinear and chaotic dynamical systems. Our results highlight\nKoopman based Transformer as a promising hybrid approach for robust,\ninterpretable, and theoretically grounded time series forecasting in noisy and\ncomplex real-world conditions.','Ali Forootani, Mohammad Khosravi','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20048v1'),('2505.20050v1','MVP: Multi-source Voice Pathology detection','Voice disorders significantly impact patient quality of life, yet\nnon-invasive automated diagnosis remains under-explored due to both the\nscarcity of pathological voice data, and the variability in recording sources.\nThis work introduces MVP (Multi-source Voice Pathology detection), a novel\napproach that leverages transformers operating directly on raw voice signals.\nWe explore three fusion strategies to combine sentence reading and sustained\nvowel recordings: waveform concatenation, intermediate feature fusion, and\ndecision-level combination. Empirical validation across the German, Portuguese,\nand Italian languages shows that intermediate feature fusion using transformers\nbest captures the complementary characteristics of both recording types. Our\napproach achieves up to +13% AUC improvement over single-source methods.','Alkis Koudounas, Moreno La Quatra, Gabriele Ciravegna, Marco Fantini, Erika Crosetti, Giovanni Succo, Tania Cerquitelli, Sabato Marco Siniscalchi, Elena Baralis','2025-05-26','eess.AS','http://arxiv.org/pdf/2505.20050v1'),('2505.20051v1','Catoni-Style Change Point Detection for Regret Minimization in Non-Stationary Heavy-Tailed Bandits','Regret minimization in stochastic non-stationary bandits gained popularity\nover the last decade, as it can model a broad class of real-world problems,\nfrom advertising to recommendation systems. Existing literature relies on\nvarious assumptions about the reward-generating process, such as Bernoulli or\nsubgaussian rewards. However, in settings such as finance and\ntelecommunications, heavy-tailed distributions naturally arise. In this work,\nwe tackle the heavy-tailed piecewise-stationary bandit problem. Heavy-tailed\nbandits, introduced by Bubeck et al., 2013, operate on the minimal assumption\nthat the finite absolute centered moments of maximum order $1+\\epsilon$ are\nuniformly bounded by a constant $v<+\\infty$, for some $\\epsilon \\in (0,1]$. We\nfocus on the most popular non-stationary bandit setting, i.e., the\npiecewise-stationary setting, in which the mean of reward-generating\ndistributions may change at unknown time steps. We provide a novel Catoni-style\nchange-point detection strategy tailored for heavy-tailed distributions that\nrelies on recent advancements in the theory of sequential estimation, which is\nof independent interest. We introduce Robust-CPD-UCB, which combines this\nchange-point detection strategy with optimistic algorithms for bandits,\nproviding its regret upper bound and an impossibility result on the minimum\nattainable regret for any policy. Finally, we validate our approach through\nnumerical experiments on synthetic and real-world datasets.','Gianmarco Genalti, Sujay Bhatt, Nicola Gatti, Alberto Maria Metelli','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20051v1'),('2505.20052v1','Ankh3: Multi-Task Pretraining with Sequence Denoising and Completion Enhances Protein Representations','Protein language models (PLMs) have emerged as powerful tools to detect\ncomplex patterns of protein sequences. However, the capability of PLMs to fully\ncapture information on protein sequences might be limited by focusing on single\npre-training tasks. Although adding data modalities or supervised objectives\ncan improve the performance of PLMs, pre-training often remains focused on\ndenoising corrupted sequences. To push the boundaries of PLMs, our research\ninvestigated a multi-task pre-training strategy. We developed Ankh3, a model\njointly optimized on two objectives: masked language modeling with multiple\nmasking probabilities and protein sequence completion relying only on protein\nsequences as input. This multi-task pre-training demonstrated that PLMs can\nlearn richer and more generalizable representations solely from protein\nsequences. The results demonstrated improved performance in downstream tasks,\nsuch as secondary structure prediction, fluorescence, GB1 fitness, and contact\nprediction. The integration of multiple tasks gave the model a more\ncomprehensive understanding of protein properties, leading to more robust and\naccurate predictions.','Hazem Alsamkary, Mohamed Elshaffei, Mohamed Elkerdawy, Ahmed Elnaggar','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20052v1'),('2505.20053v1','Multimodal LLM-Guided Semantic Correction in Text-to-Image Diffusion','Diffusion models have become the mainstream architecture for text-to-image\ngeneration, achieving remarkable progress in visual quality and prompt\ncontrollability. However, current inference pipelines generally lack\ninterpretable semantic supervision and correction mechanisms throughout the\ndenoising process. Most existing approaches rely solely on post-hoc scoring of\nthe final image, prompt filtering, or heuristic resampling strategies-making\nthem ineffective in providing actionable guidance for correcting the generative\ntrajectory. As a result, models often suffer from object confusion, spatial\nerrors, inaccurate counts, and missing semantic elements, severely compromising\nprompt-image alignment and image quality. To tackle these challenges, we\npropose MLLM Semantic-Corrected Ping-Pong-Ahead Diffusion (PPAD), a novel\nframework that, for the first time, introduces a Multimodal Large Language\nModel (MLLM) as a semantic observer during inference. PPAD performs real-time\nanalysis on intermediate generations, identifies latent semantic\ninconsistencies, and translates feedback into controllable signals that\nactively guide the remaining denoising steps. The framework supports both\ninference-only and training-enhanced settings, and performs semantic correction\nat only extremely few diffusion steps, offering strong generality and\nscalability. Extensive experiments demonstrate PPAD\\\'s significant improvements.','Zheqi Lv, Junhao Chen, Qi Tian, Keting Yin, Shengyu Zhang, Fei Wu','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20053v1'),('2505.20063v1','SAEs Are Good for Steering -- If You Select the Right Features','Sparse Autoencoders (SAEs) have been proposed as an unsupervised approach to\nlearn a decomposition of a model\\\'s latent space. This enables useful\napplications such as steering - influencing the output of a model towards a\ndesired concept - without requiring labeled data. Current methods identify SAE\nfeatures to steer by analyzing the input tokens that activate them. However,\nrecent work has highlighted that activations alone do not fully describe the\neffect of a feature on the model\\\'s output. In this work, we draw a distinction\nbetween two types of features: input features, which mainly capture patterns in\nthe model\\\'s input, and output features, which have a human-understandable\neffect on the model\\\'s output. We propose input and output scores to\ncharacterize and locate these types of features, and show that high values for\nboth scores rarely co-occur in the same features. These findings have practical\nimplications: after filtering out features with low output scores, we obtain\n2-3x improvements when steering with SAEs, making them competitive with\nsupervised methods.','Dana Arad, Aaron Mueller, Yonatan Belinkov','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20063v1'),('2505.20065v1','SafeDPO: A Simple Approach to Direct Preference Optimization with Enhanced Safety','As Large Language Models (LLMs) continue to advance and find applications\nacross a growing number of fields, ensuring the safety of LLMs has become\nincreasingly critical. To address safety concerns, recent studies have proposed\nintegrating safety constraints into Reinforcement Learning from Human Feedback\n(RLHF). However, these approaches tend to be complex, as they encompass\ncomplicated procedures in RLHF along with additional steps required by the\nsafety constraints. Inspired by Direct Preference Optimization (DPO), we\nintroduce a new algorithm called SafeDPO, which is designed to directly\noptimize the safety alignment objective in a single stage of policy learning,\nwithout requiring relaxation. SafeDPO introduces only one additional\nhyperparameter to further enhance safety and requires only minor modifications\nto standard DPO. As a result, it eliminates the need to fit separate reward and\ncost models or to sample from the language model during fine-tuning, while\nstill enhancing the safety of LLMs. Finally, we demonstrate that SafeDPO\nachieves competitive performance compared to state-of-the-art safety alignment\nalgorithms, both in terms of aligning with human preferences and improving\nsafety.','Geon-Hyeong Kim, Youngsoo Jang, Yu Jin Kim, Byoungjip Kim, Honglak Lee, Kyunghoon Bae, Moontae Lee','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20065v1'),('2505.20066v1','Automated data curation for self-supervised learning in underwater acoustic analysis','The sustainability of the ocean ecosystem is threatened by increased levels\nof sound pollution, making monitoring crucial to understand its variability and\nimpact. Passive acoustic monitoring (PAM) systems collect a large amount of\nunderwater sound recordings, but the large volume of data makes manual analysis\nimpossible, creating the need for automation. Although machine learning offers\na potential solution, most underwater acoustic recordings are unlabeled.\nSelf-supervised learning models have demonstrated success in learning from\nlarge-scale unlabeled data in various domains like computer vision, Natural\nLanguage Processing, and audio. However, these models require large, diverse,\nand balanced datasets for training in order to generalize well. To address\nthis, a fully automated self-supervised data curation pipeline is proposed to\ncreate a diverse and balanced dataset from raw PAM data. It integrates\nAutomatic Identification System (AIS) data with recordings from various\nhydrophones in the U.S. waters. Using hierarchical k-means clustering, the raw\naudio data is sampled and then combined with AIS samples to create a balanced\nand diverse dataset. The resulting curated dataset enables the development of\nself-supervised learning models, facilitating various tasks such as monitoring\nmarine mammals and assessing sound pollution.','Hilde I Hummel, Sandjai Bhulai, Burooj Ghani, Rob van der Mei','2025-05-26','cs.SD','http://arxiv.org/pdf/2505.20066v1'),('2505.20067v1','Community Moderation and the New Epistemology of Fact Checking on Social Media','Social media platforms have traditionally relied on internal moderation teams\nand partnerships with independent fact-checking organizations to identify and\nflag misleading content. Recently, however, platforms including X (formerly\nTwitter) and Meta have shifted towards community-driven content moderation by\nlaunching their own versions of crowd-sourced fact-checking -- Community Notes.\nIf effectively scaled and governed, such crowd-checking initiatives have the\npotential to combat misinformation with increased scale and speed as\nsuccessfully as community-driven efforts once did with spam. Nevertheless,\ngeneral content moderation, especially for misinformation, is inherently more\ncomplex. Public perceptions of truth are often shaped by personal biases,\npolitical leanings, and cultural contexts, complicating consensus on what\nconstitutes misleading content. This suggests that community efforts, while\nvaluable, cannot replace the indispensable role of professional fact-checkers.\nHere we systemically examine the current approaches to misinformation detection\nacross major platforms, explore the emerging role of community-driven\nmoderation, and critically evaluate both the promises and challenges of\ncrowd-checking at scale.','Isabelle Augenstein, Michiel Bakker, Tanmoy Chakraborty, David Corney, Emilio Ferrara, Iryna Gurevych, Scott Hale, Eduard Hovy, Heng Ji, Irene Larraz, Filippo Menczer, Preslav Nakov, Paolo Papotti, Dhruv Sahnan, Greta Warren, Giovanni Zagni','2025-05-26','cs.SI','http://arxiv.org/pdf/2505.20067v1'),('2505.20068v1','On the Same Page: Dimensions of Perceived Shared Understanding in Human-AI Interaction','Shared understanding plays a key role in the effective communication in and\nperformance of human-human interactions. With the increasingly common\nintegration of AI into human contexts, the future of personal and workplace\ninteractions will likely see human-AI interaction (HAII) in which the\nperception of shared understanding is important. Existing literature has\naddressed the processes and effects of PSU in human-human interactions, but the\nconstrual remains underexplored in HAII. To better understand PSU in HAII, we\nconducted an online survey to collect user reflections on interactions with a\nlarge language model when it sunderstanding of a situation was thought to be\nsimilar to or different from the participant\\\'s. Through inductive thematic\nanalysis, we identified eight dimensions comprising PSU in human-AI\ninteractions: Fluency, aligned operation, fluidity, outcome satisfaction,\ncontextual awareness, lack of humanlike abilities, computational limits, and\nsuspicion.','Qingyu Liang, Jaime Banks','2025-05-26','cs.HC','http://arxiv.org/pdf/2505.20068v1'),('2505.20072v2','Incentivizing Strong Reasoning from Weak Supervision','Large language models (LLMs) have demonstrated impressive performance on\nreasoning-intensive tasks, but enhancing their reasoning abilities typically\nrelies on either reinforcement learning (RL) with verifiable signals or\nsupervised fine-tuning (SFT) with high-quality long chain-of-thought (CoT)\ndemonstrations, both of which are expensive. In this paper, we study a novel\nproblem of incentivizing the reasoning capacity of LLMs without expensive\nhigh-quality demonstrations and reinforcement learning. We investigate whether\nthe reasoning capabilities of LLMs can be effectively incentivized via\nsupervision from significantly weaker models. We further analyze when and why\nsuch weak supervision succeeds in eliciting reasoning abilities in stronger\nmodels. Our findings show that supervision from significantly weaker reasoners\ncan substantially improve student reasoning performance, recovering close to\n94% of the gains of expensive RL at a fraction of the cost. Experiments across\ndiverse benchmarks and model architectures demonstrate that weak reasoners can\neffectively incentivize reasoning in stronger student models, consistently\nimproving performance across a wide range of reasoning tasks. Our results\nsuggest that this simple weak-to-strong paradigm is a promising and\ngeneralizable alternative to costly methods for incentivizing strong reasoning\ncapabilities at inference-time in LLMs. The code is publicly available at\nhttps://github.com/yuanyige/w2sr.','Yige Yuan, Teng Xiao, Shuchang Tao, Xue Wang, Jinyang Gao, Bolin Ding, Bingbing Xu','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20072v2'),('2505.20074v1','An Out-Of-Distribution Membership Inference Attack Approach for Cross-Domain Graph Attacks','Graph Neural Network-based methods face privacy leakage risks due to the\nintroduction of topological structures about the targets, which allows\nattackers to bypass the target\\\'s prior knowledge of the sensitive attributes\nand realize membership inference attacks (MIA) by observing and analyzing the\ntopology distribution. As privacy concerns grow, the assumption of MIA, which\npresumes that attackers can obtain an auxiliary dataset with the same\ndistribution, is increasingly deviating from reality. In this paper, we\ncategorize the distribution diversity issue in real-world MIA scenarios as an\nOut-Of-Distribution (OOD) problem, and propose a novel Graph OOD Membership\nInference Attack (GOOD-MIA) to achieve cross-domain graph attacks.\nSpecifically, we construct shadow subgraphs with distributions from different\ndomains to model the diversity of real-world data. We then explore the stable\nnode representations that remain unchanged under external influences and\nconsider eliminating redundant information from confounding environments and\nextracting task-relevant key information to more clearly distinguish between\nthe characteristics of training data and unseen data. This OOD-based design\nmakes cross-domain graph attacks possible. Finally, we perform risk\nextrapolation to optimize the attack\\\'s domain adaptability during attack\ninference to generalize the attack to other domains. Experimental results\ndemonstrate that GOOD-MIA achieves superior attack performance in datasets\ndesigned for multiple domains.','Jinyan Wang, Liu Yang, Yuecen Wei, Jiaxuan Si, Chenhao Guo, Qingyun Sun, Xianxian Li, Xingcheng Fu','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20074v1'),('2505.20075v1','Curriculum-RLAIF: Curriculum Alignment with Reinforcement Learning from AI Feedback','Reward models trained with conventional Reinforcement Learning from AI\nFeedback (RLAIF) methods suffer from limited generalizability, which hinders\nthe alignment performance of the policy model during reinforcement learning\n(RL). This challenge stems from various issues, including distribution shift,\npreference label noise, and mismatches between overly challenging samples and\nmodel capacity. In this paper, we attempt to enhance the generalizability of\nreward models through a data-centric approach, driven by the insight that these\nissues are inherently intertwined from the perspective of data difficulty. To\naddress this, we propose a novel framework, $\\textit{Curriculum-RLAIF}$, which\nconstructs preference pairs with varying difficulty levels and produces a\ncurriculum that progressively incorporates preference pairs of increasing\ndifficulty for reward model training. Our experimental results suggest that\nreward models trained with Curriculum-RLAIF achieve improved generalizability,\nsignificantly increasing the alignment performance of the policy model by a\nlarge margin without incurring additional inference costs compared to various\nnon-curriculum baselines. Detailed analysis and comparisons with alternative\napproaches, including data selection via external pretrained reward models or\ninternal self-selection mechanisms, as well as other curriculum strategies,\nfurther demonstrate the superiority of our approach in terms of simplicity,\nefficiency, and effectiveness.','Mengdi Li, Jiaye Lin, Xufeng Zhao, Wenhao Lu, Peilin Zhao, Stefan Wermter, Di Wang','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20075v1'),('2505.20076v1','Grokking ExPLAIND: Unifying Model, Data, and Training Attribution to Study Model Behavior','Post-hoc interpretability methods typically attribute a model\\\'s behavior to\nits components, data, or training trajectory in isolation. This leads to\nexplanations that lack a unified view and may miss key interactions. While\ncombining existing methods or applying them at different training stages offers\nbroader insights, these approaches usually lack theoretical support. In this\nwork, we present ExPLAIND, a unified framework that integrates all three\nperspectives. First, we generalize recent work on gradient path kernels, which\nreformulate models trained by gradient descent as a kernel machine, to more\nrealistic training settings. Empirically, we find that both a CNN and a\nTransformer model are replicated accurately by this reformulation. Second, we\nderive novel parameter- and step-wise influence scores from the kernel feature\nmaps. We show their effectiveness in parameter pruning that is comparable to\nexisting methods, reinforcing their value for model component attribution.\nFinally, jointly interpreting model components and data over the training\nprocess, we leverage ExPLAIND to analyze a Transformer that exhibits Grokking.\nAmong other things, our findings support previously proposed stages of\nGrokking, while refining the final phase as one of alignment of input\nembeddings and final layers around a representation pipeline learned after the\nmemorization phase. Overall, ExPLAIND provides a theoretically grounded,\nunified framework to interpret model behavior and training dynamics.','Florian Eichin, Yupei Du, Philipp Mondorf, Barbara Plank, Michael A. Hedderich','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20076v1'),('2505.20079v1','A fast sound power prediction tool for genset noise using machine learning','This paper investigates the application of machine learning regression\nalgorithms Kernel Ridge Regression (KRR), Huber Regressor (HR), and Gaussian\nProcess Regression (GPR) for predicting sound power levels of gensets, offering\nsignificant value for marketing and sales teams during the early bidding\nprocess. When engine sizes and genset enclosure dimensions are tentative, and\nmeasured noise data is unavailable, these algorithms enable reliable noise\nlevel estimation for unbuilt gensets. The study utilizes high fidelity datasets\nfrom over 100 experiments conducted at Cummins Acoustics Technology Center\n(ATC) in a hemi-anechoic chamber, adhering to ISO 3744 standards. By using\nreadily available information from the bidding and initial design stages, KRR\npredicts sound power with an average accuracy of within 5 dBA. While HR and GPR\nshow slightly higher prediction errors, all models effectively capture the\noverall noise trends across various genset configurations. These findings\npresent a promising method for early-stage noise estimation in genset design.','Saurabh Pargal, Abhijit A. Sane','2025-05-26','physics.app-ph','http://arxiv.org/pdf/2505.20079v1'),('2505.20081v2','Inference-time Alignment in Continuous Space','Aligning large language models with human feedback at inference time has\nreceived increasing attention due to its flexibility. Existing methods rely on\ngenerating multiple responses from the base policy for search using a reward\nmodel, which can be considered as searching in a discrete response space.\nHowever, these methods struggle to explore informative candidates when the base\npolicy is weak or the candidate set is small, resulting in limited\neffectiveness. In this paper, to address this problem, we propose Simple Energy\nAdaptation ($\\textbf{SEA}$), a simple yet effective algorithm for\ninference-time alignment. In contrast to expensive search over the discrete\nspace, SEA directly adapts original responses from the base policy toward the\noptimal one via gradient-based sampling in continuous latent space.\nSpecifically, SEA formulates inference as an iterative optimization procedure\non an energy function over actions in the continuous space defined by the\noptimal policy, enabling simple and effective alignment. For instance, despite\nits simplicity, SEA outperforms the second-best baseline with a relative\nimprovement of up to $ \\textbf{77.51%}$ on AdvBench and $\\textbf{16.36%}$ on\nMATH. Our code is publicly available at https://github.com/yuanyige/sea','Yige Yuan, Teng Xiao, Li Yunfan, Bingbing Xu, Shuchang Tao, Yunqi Qiu, Huawei Shen, Xueqi Cheng','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20081v2'),('2505.20085v1','Explanation User Interfaces: A Systematic Literature Review','Artificial Intelligence (AI) is one of the major technological advancements\nof this century, bearing incredible potential for users through AI-powered\napplications and tools in numerous domains. Being often black-box (i.e., its\ndecision-making process is unintelligible), developers typically resort to\neXplainable Artificial Intelligence (XAI) techniques to interpret the behaviour\nof AI models to produce systems that are transparent, fair, reliable, and\ntrustworthy. However, presenting explanations to the user is not trivial and is\noften left as a secondary aspect of the system\\\'s design process, leading to AI\nsystems that are not useful to end-users. This paper presents a Systematic\nLiterature Review on Explanation User Interfaces (XUIs) to gain a deeper\nunderstanding of the solutions and design guidelines employed in the academic\nliterature to effectively present explanations to users. To improve the\ncontribution and real-world impact of this survey, we also present a framework\nfor Human-cEnteRed developMent of Explainable user interfaceS (HERMES) to guide\npractitioners and academics in the design and evaluation of XUIs.','Eleonora Cappuccio, Andrea Esposito, Francesco Greco, Giuseppe Desolda, Rosa Lanzilotti, Salvatore Rinzivillo','2025-05-26','cs.HC','http://arxiv.org/pdf/2505.20085v1'),('2505.20087v1','Safety Through Reasoning: An Empirical Study of Reasoning Guardrail Models','Reasoning-based language models have demonstrated strong performance across\nvarious domains, with the most notable gains seen in mathematical and coding\ntasks. Recent research has shown that reasoning also offers significant\nbenefits for LLM safety and guardrail applications. In this work, we conduct a\ncomprehensive analysis of training reasoning-based guardrail models for content\nmoderation, with an emphasis on generalization to custom safety policies at\ninference time. Our study focuses on two key dimensions: data efficiency and\ninference efficiency. On the data front, we find that reasoning-based models\nexhibit strong sample efficiency, achieving competitive performance with\nsignificantly fewer training examples than their non-reasoning counterparts.\nThis unlocks the potential to repurpose the remaining data for mining\nhigh-value, difficult samples that further enhance model performance. On the\ninference side, we evaluate practical trade-offs by introducing reasoning\nbudgets, examining the impact of reasoning length on latency and accuracy, and\nexploring dual-mode training to allow runtime control over reasoning behavior.\nOur findings will provide practical insights for researchers and developers to\neffectively and efficiently train and deploy reasoning-based guardrails models\nin real-world systems.','Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20087v1'),('2505.20088v1','Multi-Domain Explainability of Preferences','Preference mechanisms, such as human preference, LLM-as-a-Judge (LaaJ), and\nreward models, are central to aligning and evaluating large language models\n(LLMs). Yet, the underlying concepts that drive these preferences remain poorly\nunderstood. In this work, we propose a fully automated end-to-end method for\ngenerating local and global concept-based explanations of preferences across\nmultiple domains. Our method employs an LLM to discover concepts that\ndifferentiate between chosen and rejected responses and represent them with\nconcept-based vectors. To model the relationships between concepts and\npreferences, we propose a white-box Hierarchical Multi-Domain Regression model\nthat captures both domain-general and domain-specific effects. To evaluate our\nmethod, we curate a dataset spanning eight challenging and diverse domains and\nexplain twelve mechanisms. Our method achieves strong preference prediction\nperformance, outperforming baselines while also being explainable.\nAdditionally, we assess explanations in two novel application-driven settings.\nFirst, guiding LLM outputs with concepts from LaaJ explanations yields\nresponses that those judges consistently prefer. Second, prompting LaaJs with\nconcepts explaining humans improves their preference predictions. Together, our\nwork provides a new paradigm for explainability in the era of LLMs.','Nitay Calderon, Liat Ein-Dor, Roi Reichart','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20088v1'),('2505.20089v2','Homophily Enhanced Graph Domain Adaptation','Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs\nto unlabeled target graphs, addressing the challenge of label scarcity. In this\npaper, we highlight the significance of graph homophily, a pivotal factor for\ngraph domain alignment, which, however, has long been overlooked in existing\napproaches. Specifically, our analysis first reveals that homophily\ndiscrepancies exist in benchmarks. Moreover, we also show that homophily\ndiscrepancies degrade GDA performance from both empirical and theoretical\naspects, which further underscores the importance of homophily alignment in\nGDA. Inspired by this finding, we propose a novel homophily alignment algorithm\nthat employs mixed filters to smooth graph signals, thereby effectively\ncapturing and mitigating homophily discrepancies between graphs. Experimental\nresults on a variety of benchmarks verify the effectiveness of our method.','Ruiyi Fang, Bingheng Li, Jingyu Zhao, Ruizhi Pu, Qiuhao Zeng, Gezheng Xu, Charles Ling, Boyu Wang','2025-05-26','cs.SI','http://arxiv.org/pdf/2505.20089v2'),('2505.20094v1','SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale','Can a scientific simulation system be physically consistent, interpretable by\ndesign, and scalable across regimes--all at once? Despite decades of progress,\nthis trifecta remains elusive. Classical methods like Kinetic Monte Carlo\nensure thermodynamic accuracy but scale poorly; learning-based methods offer\nefficiency but often sacrifice physical consistency and interpretability. We\npresent SwarmThinkers, a reinforcement learning framework that recasts\natomic-scale simulation as a physically grounded swarm intelligence system.\nEach diffusing particle is modeled as a local decision-making agent that\nselects transitions via a shared policy network trained under thermodynamic\nconstraints. A reweighting mechanism fuses learned preferences with transition\nrates, preserving statistical fidelity while enabling interpretable, step-wise\ndecision making. Training follows a centralized-training,\ndecentralized-execution paradigm, allowing the policy to generalize across\nsystem sizes, concentrations, and temperatures without retraining. On a\nbenchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers\nis the first system to achieve full-scale, physically consistent simulation on\na single A100 GPU, previously attainable only via OpenKMC on a supercomputer.\nIt delivers up to 4963x (3185x on average) faster computation with 485x lower\nmemory usage. By treating particles as decision-makers, not passive samplers,\nSwarmThinkers marks a paradigm shift in scientific simulation--one that unifies\nphysical consistency, interpretability, and scalability through agent-driven\nintelligence.','Qi Li, Kun Li, Haozhi Han, Honghui Shang, Xinfu He, Yunquan Zhang, Hong An, Ting Cao, Mao Yang','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20094v1'),('2505.20095v1','Spurious Privacy Leakage in Neural Networks','Neural networks are vulnerable to privacy attacks aimed at stealing sensitive\ndata. The risks can be amplified in a real-world scenario, particularly when\nmodels are trained on limited and biased data. In this work, we investigate the\nimpact of spurious correlation bias on privacy vulnerability. We introduce\n\\emph{spurious privacy leakage}, a phenomenon where spurious groups are\nsignificantly more vulnerable to privacy attacks than non-spurious groups. We\nfurther show that group privacy disparity increases in tasks with simpler\nobjectives (e.g. fewer classes) due to the persistence of spurious features.\nSurprisingly, we find that reducing spurious correlation using spurious robust\nmethods does not mitigate spurious privacy leakage. This leads us to introduce\na perspective on privacy disparity based on memorization, where mitigating\nspurious correlation does not mitigate the memorization of spurious data, and\ntherefore, neither the privacy level. Lastly, we compare the privacy of\ndifferent model architectures trained with spurious data, demonstrating that,\ncontrary to prior works, architectural choice can affect privacy outcomes.','Chenxiang Zhang, Jun Pang, Sjouke Mauw','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20095v1'),('2505.20096v1','MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning','We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\n(RAG) that addresses the inherent ambiguities and reasoning challenges in\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely on\neither end-to-end fine-tuning or isolated component enhancements, MA-RAG\norchestrates a collaborative set of specialized AI agents: Planner, Step\nDefiner, Extractor, and QA Agents, to tackle each stage of the RAG pipeline\nwith task-aware reasoning. Ambiguities may arise from underspecified queries,\nsparse or indirect evidence in retrieved documents, or the need to integrate\ninformation scattered across multiple sources. MA-RAG mitigates these\nchallenges by decomposing the problem into subtasks, such as query\ndisambiguation, evidence extraction, and answer synthesis, and dispatching them\nto dedicated agents equipped with chain-of-thought prompting. These agents\ncommunicate intermediate reasoning and progressively refine the retrieval and\nsynthesis process. Our design allows fine-grained control over information flow\nwithout any model fine-tuning. Crucially, agents are invoked on demand,\nenabling a dynamic and efficient workflow that avoids unnecessary computation.\nThis modular and reasoning-driven architecture enables MA-RAG to deliver\nrobust, interpretable results. Experiments on multi-hop and ambiguous QA\nbenchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free\nbaselines and rivals fine-tuned systems, validating the effectiveness of\ncollaborative agent-based reasoning in RAG.','Thang Nguyen, Peter Chin, Yu-Wing Tai','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20096v1'),('2505.20097v1','S2LPP: Small-to-Large Prompt Prediction across LLMs','The performance of pre-trained Large Language Models (LLMs) is often\nsensitive to nuances in prompt templates, requiring careful prompt engineering,\nadding costs in terms of computing and human effort. In this study, we present\nexperiments encompassing multiple LLMs variants of varying sizes aimed at\nprobing their preference with different prompts. Through experiments on\nQuestion Answering, we show prompt preference consistency across LLMs of\ndifferent sizes. We also show that this consistency extends to other tasks,\nsuch as Natural Language Inference. Utilizing this consistency, we propose a\nmethod to use a smaller model to select effective prompt templates for a larger\nmodel. We show that our method substantially reduces the cost of prompt\nengineering while consistently matching performance with optimal prompts among\ncandidates. More importantly, our experiment shows the efficacy of our strategy\nacross fourteen LLMs and its applicability to a broad range of NLP tasks,\nhighlighting its robustness','Liang Cheng, Tianyi LI, Zhaowei Wang, Mark Steedman','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20097v1'),('2505.20098v2','Transformers in Protein: A Survey','As protein informatics advances rapidly, the demand for enhanced predictive\naccuracy, structural analysis, and functional understanding has intensified.\nTransformer models, as powerful deep learning architectures, have demonstrated\nunprecedented potential in addressing diverse challenges across protein\nresearch. However, a comprehensive review of Transformer applications in this\nfield remains lacking. This paper bridges this gap by surveying over 100\nstudies, offering an in-depth analysis of practical implementations and\nresearch progress of Transformers in protein-related tasks. Our review\nsystematically covers critical domains, including protein structure prediction,\nfunction prediction, protein-protein interaction analysis, functional\nannotation, and drug discovery/target identification. To contextualize these\nadvancements across various protein domains, we adopt a domain-oriented\nclassification system. We first introduce foundational concepts: the\nTransformer architecture and attention mechanisms, categorize Transformer\nvariants tailored for protein science, and summarize essential protein\nknowledge. For each research domain, we outline its objectives and background,\ncritically evaluate prior methods and their limitations, and highlight\ntransformative contributions enabled by Transformer models. We also curate and\nsummarize pivotal datasets and open-source code resources to facilitate\nreproducibility and benchmarking. Finally, we discuss persistent challenges in\napplying Transformers to protein informatics and propose future research\ndirections. This review aims to provide a consolidated foundation for the\nsynergistic integration of Transformer and protein informatics, fostering\nfurther innovation and expanded applications in the field.','Xiaowen Ling, Zhiqiang Li, Yanbin Wang, Zhuhong You','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20098v2'),('2505.20099v1','Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities','Large language models (LLMs) have demonstrated remarkable performance on\nquestion-answering (QA) tasks because of their superior capabilities in natural\nlanguage understanding and generation. However, LLM-based QA struggles with\ncomplex QA tasks due to poor reasoning capacity, outdated knowledge, and\nhallucinations. Several recent works synthesize LLMs and knowledge graphs (KGs)\nfor QA to address the above challenges. In this survey, we propose a new\nstructured taxonomy that categorizes the methodology of synthesizing LLMs and\nKGs for QA according to the categories of QA and the KG\\\'s role when integrating\nwith LLMs. We systematically survey state-of-the-art advances in synthesizing\nLLMs and KGs for QA and compare and analyze these approaches in terms of\nstrength, limitations, and KG requirements. We then align the approaches with\nQA and discuss how these approaches address the main challenges of different\ncomplex QA. Finally, we summarize the advancements, evaluation metrics, and\nbenchmark datasets and highlight open challenges and opportunities.','Chuangtao Ma, Yongrui Chen, Tianxing Wu, Arijit Khan, Haofen Wang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20099v1'),('2505.20100v1','AdaTP: Attention-Debiased Token Pruning for Video Large Language Models','Video Large Language Models (Video LLMs) have achieved remarkable results in\nvideo understanding tasks. However, they often suffer from heavy computational\noverhead due to the large number of visual tokens generated from multiple video\nframes. Existing visual token compression methods often rely on attention\nscores from language models as guidance. However, these scores exhibit inherent\nbiases: global bias reflects a tendency to focus on the two ends of the visual\ntoken sequence, while local bias leads to an over-concentration on the same\nspatial positions across different frames. To address the issue of attention\nbias, we propose $\\textbf{A}$ttention-$\\textbf{D}$ebi$\\textbf{a}$sed\n$\\textbf{T}$oken $\\textbf{P}$runing for Video Large Language Models\n($\\textbf{AdaTP}$), a novel token pruning pipeline for Video LLMs. AdaTP\nintegrates two dedicated debiasing modules into the pipeline, targeting global\nattention bias and local attention bias, respectively. Without the need for\nadditional training, our method significantly reduces the computational\noverhead of Video LLMs while retaining the performance of vanilla models.\nExtensive evaluation shows that AdaTP achieves state-of-the-art performance in\nvarious commonly used video understanding benchmarks. In particular, on\nLLaVA-OneVision-7B, AdaTP maintains performance without degradation while using\nonly up to $27.3\\%$ FLOPs compared to the vanilla model. Our code will be\nreleased soon.','Fengyuan Sun, Leqi Shen, Hui Chen, Sicheng Zhao, Jungong Han, Guiguang Ding','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20100v1'),('2505.20101v2','Adaptive Deep Reasoning: Triggering Deep Thinking When Needed','Large language models (LLMs) have shown impressive capabilities in handling\ncomplex tasks through long-chain reasoning. However, the extensive reasoning\nsteps involved can significantly increase computational costs, posing\nchallenges for real-world deployment. Recent efforts have focused on optimizing\nreasoning efficiency by shortening the Chain-of-Thought (CoT) reasoning\nprocesses through various approaches, such as length-aware prompt engineering,\nsupervised fine-tuning on CoT data with variable lengths, and reinforcement\nlearning with length penalties. Although these methods effectively reduce\nreasoning length, they still necessitate an initial reasoning phase. More\nrecent approaches have attempted to integrate long-chain and short-chain\nreasoning abilities into a single model, yet they still rely on manual control\nto toggle between short and long CoT. In this work, we propose a novel approach\nthat autonomously switches between short and long reasoning chains based on\nproblem complexity. Our method begins with supervised fine-tuning of the base\nmodel to equip both long-chain and short-chain reasoning abilities. We then\nemploy reinforcement learning to further balance short and long CoT generation\nwhile maintaining accuracy through two key strategies: first, integrating\nreinforcement learning with a long-short adaptive group-wise reward strategy to\nassess prompt complexity and provide corresponding rewards; second,\nimplementing a logit-based reasoning mode switching loss to optimize the\nmodel\\\'s initial token choice, thereby guiding the selection of the reasoning\ntype. Evaluations on mathematical datasets demonstrate that our model can\ndynamically switch between long-chain and short-chain reasoning modes without\nsubstantially sacrificing performance. This advancement enhances the\npracticality of reasoning in large language models for real-world applications.','Yunhao Wang, Yuhao Zhang, Tinghao Yu, Can Xu, Feng Zhang, Fengzong Lian','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20101v2'),('2505.20103v2','SCIRGC: Multi-Granularity Citation Recommendation and Citation Sentence Preference Alignment','Citations are crucial in scientific research articles as they highlight the\nconnection between the current study and prior work. However, this process is\noften time-consuming for researchers. In this study, we propose the SciRGC\nframework, which aims to automatically recommend citation articles and generate\ncitation sentences for citation locations within articles. The framework\naddresses two key challenges in academic citation generation: 1) how to\naccurately identify the author\\\'s citation intent and find relevant citation\npapers, and 2) how to generate high-quality citation sentences that align with\nhuman preferences. We enhance citation recommendation accuracy in the citation\narticle recommendation module by incorporating citation networks and sentiment\nintent, and generate reasoning-based citation sentences in the citation\nsentence generation module by using the original article abstract, local\ncontext, citation intent, and recommended articles as inputs. Additionally, we\npropose a new evaluation metric to fairly assess the quality of generated\ncitation sentences. Through comparisons with baseline models and ablation\nexperiments, the SciRGC framework not only improves the accuracy and relevance\nof citation recommendations but also ensures the appropriateness of the\ngenerated citation sentences in context, providing a valuable tool for\ninterdisciplinary researchers.','Xiangyu Li, Jingqiang Chen','2025-05-26','cs.DL','http://arxiv.org/pdf/2505.20103v2'),('2505.20107v1','Refining Few-Step Text-to-Multiview Diffusion via Reinforcement Learning','Text-to-multiview (T2MV) generation, which produces coherent multiview images\nfrom a single text prompt, remains computationally intensive, while accelerated\nT2MV methods using few-step diffusion models often sacrifice image fidelity and\nview consistency. To address this, we propose a novel reinforcement learning\n(RL) finetuning framework tailored for few-step T2MV diffusion models to\njointly optimize per-view fidelity and cross-view consistency. Specifically, we\nfirst reformulate T2MV denoising across all views as a single unified Markov\ndecision process, enabling multiview-aware policy optimization driven by a\njoint-view reward objective. Next, we introduce ZMV-Sampling, a test-time T2MV\nsampling technique that adds an inversion-denoising pass to reinforce both\nviewpoint and text conditioning, resulting in improved T2MV generation at the\ncost of inference time. To internalize its performance gains into the base\nsampling policy, we develop MV-ZigAL, a novel policy optimization strategy that\nuses reward advantages of ZMV-Sampling over standard sampling as learning\nsignals for policy updates. Finally, noting that the joint-view reward\nobjective under-optimizes per-view fidelity but naively optimizing single-view\nmetrics neglects cross-view alignment, we reframe RL finetuning for T2MV\ndiffusion models as a constrained optimization problem that maximizes per-view\nfidelity subject to an explicit joint-view constraint, thereby enabling more\nefficient and balanced policy updates. By integrating this constrained\noptimization paradigm with MV-ZigAL, we establish our complete RL finetuning\nframework, referred to as MVC-ZigAL, which effectively refines the few-step\nT2MV diffusion baseline in both fidelity and consistency while preserving its\nfew-step efficiency.','Ziyi Zhang, Li Shen, Deheng Ye, Yong Luo, Huangxuan Zhao, Lefei Zhang','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20107v1'),('2505.20109v1','Language-Agnostic Suicidal Risk Detection Using Large Language Models','Suicidal risk detection in adolescents is a critical challenge, yet existing\nmethods rely on language-specific models, limiting scalability and\ngeneralization. This study introduces a novel language-agnostic framework for\nsuicidal risk assessment with large language models (LLMs). We generate Chinese\ntranscripts from speech using an ASR model and then employ LLMs with\nprompt-based queries to extract suicidal risk-related features from these\ntranscripts. The extracted features are retained in both Chinese and English to\nenable cross-linguistic analysis and then used to fine-tune corresponding\npretrained language models independently. Experimental results show that our\nmethod achieves performance comparable to direct fine-tuning with ASR results\nor to models trained solely on Chinese suicidal risk-related features,\ndemonstrating its potential to overcome language constraints and improve the\nrobustness of suicidal risk assessment.','June-Woo Kim, Wonkyo Oh, Haram Yoon, Sung-Hoon Yoon, Dae-Jin Kim, Dong-Ho Lee, Sang-Yeol Lee, Chan-Mo Yang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20109v1'),('2505.20110v1','Proxy-Free GFlowNet','Generative Flow Networks (GFlowNets) are a promising class of generative\nmodels designed to sample diverse, high-reward structures by modeling\ndistributions over compositional objects. In many real-world applications,\nobtaining the reward function for such objects is expensive, time-consuming, or\nrequires human input, making it necessary to train GFlowNets from historical\ndatasets. Most existing methods adopt a model-based approach, learning a proxy\nmodel from the dataset to approximate the reward function. However, this\nstrategy inherently ties the quality of the learned policy to the accuracy of\nthe proxy, introducing additional complexity and uncertainty into the training\nprocess. To overcome these limitations, we propose \\textbf{Trajectory-Distilled\nGFlowNet (TD-GFN)}, a \\emph{proxy-free} training framework that eliminates the\nneed for out-of-dataset reward queries. Our method is motivated by the key\nobservation that different edges in the associated directed acyclic graph (DAG)\ncontribute unequally to effective policy learning. TD-GFN leverages inverse\nreinforcement learning to estimate edge-level rewards from the offline dataset,\nwhich are then used to ingeniously prune the DAG and guide backward trajectory\nsampling during training. This approach directs the policy toward high-reward\nregions while reducing the complexity of model fitting. Empirical results\nacross multiple tasks show that TD-GFN trains both efficiently and reliably,\nsignificantly outperforming existing baselines in convergence speed and sample\nquality.','Ruishuo Chen, Xun Wang, Rui Hu, Zhuoran Li, Longbo Huang','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20110v1'),('2505.20112v1','ResSVD: Residual Compensated SVD for Large Language Model Compression','Large language models (LLMs) have demonstrated impressive capabilities in a\nwide range of downstream natural language processing tasks. Nevertheless, their\nconsiderable sizes and memory demands hinder practical deployment, underscoring\nthe importance of developing efficient compression strategies. Singular value\ndecomposition (SVD) decomposes a matrix into orthogonal components, enabling\nefficient low-rank approximation. This is particularly suitable for LLM\ncompression, where weight matrices often exhibit significant redundancy.\nHowever, current SVD-based methods neglect the residual matrix from truncation,\nresulting in significant truncation loss. Additionally, compressing all layers\nof the model results in severe performance degradation. To overcome these\nlimitations, we propose ResSVD, a new post-training SVD-based LLM compression\nmethod. Specifically, we leverage the residual matrix generated during the\ntruncation process to reduce truncation loss. Moreover, under a fixed overall\ncompression ratio, we selectively compress the last few layers of the model,\nwhich mitigates error propagation and significantly improves the performance of\ncompressed models.Comprehensive evaluations of ResSVD on diverse LLM families\nand multiple benchmark datasets indicate that ResSVD consistently achieves\nsuperior performance over existing counterpart methods, demonstrating its\npractical effectiveness.','Haolei Bai, Siyong Jian, Tuo Liang, Yu Yin, Huan Wang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20112v1'),('2505.20113v1','Named Entity Recognition in Historical Italian: The Case of Giacomo Leopardi\\\'s Zibaldone','The increased digitization of world\\\'s textual heritage poses significant\nchallenges for both computer science and literary studies. Overall, there is an\nurgent need of computational techniques able to adapt to the challenges of\nhistorical texts, such as orthographic and spelling variations, fragmentary\nstructure and digitization errors. The rise of large language models (LLMs) has\nrevolutionized natural language processing, suggesting promising applications\nfor Named Entity Recognition (NER) on historical documents. In spite of this,\nno thorough evaluation has been proposed for Italian texts. This research tries\nto fill the gap by proposing a new challenging dataset for entity extraction\nbased on a corpus of 19th century scholarly notes, i.e. Giacomo Leopardi\\\'s\nZibaldone (1898), containing 2,899 references to people, locations and literary\nworks. This dataset was used to carry out reproducible experiments with both\ndomain-specific BERT-based models and state-of-the-art LLMs such as LLaMa3.1.\nResults show that instruction-tuned models encounter multiple difficulties\nhandling historical humanistic texts, while fine-tuned NER models offer more\nrobust performance even with challenging entity types such as bibliographic\nreferences.','Cristian Santini, Laura Melosi, Emanuele Frontoni','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20113v1'),('2505.20118v2','TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent','As large language models (LLMs) become integrated into sensitive workflows,\nconcerns grow over their potential to leak confidential information. We propose\nTrojanStego, a novel threat model in which an adversary fine-tunes an LLM to\nembed sensitive context information into natural-looking outputs via linguistic\nsteganography, without requiring explicit control over inference inputs. We\nintroduce a taxonomy outlining risk factors for compromised LLMs, and use it to\nevaluate the risk profile of the threat. To implement TrojanStego, we propose a\npractical encoding scheme based on vocabulary partitioning learnable by LLMs\nvia fine-tuning. Experimental results show that compromised models reliably\ntransmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over\n97% accuracy using majority voting across three generations. Further, they\nmaintain high utility, can evade human detection, and preserve coherence. These\nresults highlight a new class of LLM data exfiltration attacks that are\npassive, covert, practical, and dangerous.','Dominik Meier, Jan Philip Wahle, Paul Röttger, Terry Ruas, Bela Gipp','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20118v2'),('2505.20119v1','Spatiotemporal Causal Decoupling Model for Air Quality Forecasting','Due to the profound impact of air pollution on human health, livelihoods, and\neconomic development, air quality forecasting is of paramount significance.\nInitially, we employ the causal graph method to scrutinize the constraints of\nexisting research in comprehensively modeling the causal relationships between\nthe air quality index (AQI) and meteorological features. In order to enhance\nprediction accuracy, we introduce a novel air quality forecasting model,\nAirCade, which incorporates a causal decoupling approach. AirCade leverages a\nspatiotemporal module in conjunction with knowledge embedding techniques to\ncapture the internal dynamics of AQI. Subsequently, a causal decoupling module\nis proposed to disentangle synchronous causality from past AQI and\nmeteorological features, followed by the dissemination of acquired knowledge to\nfuture time steps to enhance performance. Additionally, we introduce a causal\nintervention mechanism to explicitly represent the uncertainty of future\nmeteorological features, thereby bolstering the model\\\'s robustness. Our\nevaluation of AirCade on an open-source air quality dataset demonstrates over\n20\\% relative improvement over state-of-the-art models.','Jiaming Ma, Guanjun Wang, Sheng Huang, Kuo Yang, Binwu Wang, Pengkun Wang, Yang Wang','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20119v1'),('2505.20120v1','Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets','Current labor markets are strongly affected by the economic forces of adverse\nselection, moral hazard, and reputation, each of which arises due to\n$\\textit{incomplete information}$. These economic forces will still be\ninfluential after AI agents are introduced, and thus, agents must use\nmetacognitive and strategic reasoning to perform effectively. Metacognition is\na form of $\\textit{internal reasoning}$ that includes the capabilities for\nself-assessment, task understanding, and evaluation of strategies. Strategic\nreasoning is $\\textit{external reasoning}$ that covers holding beliefs about\nother participants in the labor market (e.g., competitors, colleagues), making\nstrategic decisions, and learning about others over time. Both types of\nreasoning are required by agents as they decide among the many\n$\\textit{actions}$ they can take in labor markets, both within and outside\ntheir jobs. We discuss current research into metacognitive and strategic\nreasoning and the areas requiring further development.','Simpson Zhang, Tennison Liu, Mihaela van der Schaar','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20120v1'),('2505.20123v1','Understanding Generalization in Diffusion Models via Probability Flow Distance','Diffusion models have emerged as a powerful class of generative models,\ncapable of producing high-quality samples that generalize beyond the training\ndata. However, evaluating this generalization remains challenging: theoretical\nmetrics are often impractical for high-dimensional data, while no practical\nmetrics rigorously measure generalization. In this work, we bridge this gap by\nintroducing probability flow distance ($\\texttt{PFD}$), a theoretically\ngrounded and computationally efficient metric to measure distributional\ngeneralization. Specifically, $\\texttt{PFD}$ quantifies the distance between\ndistributions by comparing their noise-to-data mappings induced by the\nprobability flow ODE. Moreover, by using $\\texttt{PFD}$ under a teacher-student\nevaluation protocol, we empirically uncover several key generalization\nbehaviors in diffusion models, including: (1) scaling behavior from\nmemorization to generalization, (2) early learning and double descent training\ndynamics, and (3) bias-variance decomposition. Beyond these insights, our work\nlays a foundation for future empirical and theoretical studies on\ngeneralization in diffusion models.','Huijie Zhang, Zijian Huang, Siyi Chen, Jinfan Zhou, Zekai Zhang, Peng Wang, Qing Qu','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20123v1'),('2505.20127v1','Agentic AI Process Observability: Discovering Behavioral Variability','AI agents that leverage Large Language Models (LLMs) are increasingly\nbecoming core building blocks of modern software systems. A wide range of\nframeworks is now available to support the specification of such applications.\nThese frameworks enable the definition of agent setups using natural language\nprompting, which specifies the roles, goals, and tools assigned to the various\nagents involved. Within such setups, agent behavior is non-deterministic for\nany given input, highlighting the critical need for robust debugging and\nobservability tools. In this work, we explore the use of process and causal\ndiscovery applied to agent execution trajectories as a means of enhancing\ndeveloper observability. This approach aids in monitoring and understanding the\nemergent variability in agent behavior. Additionally, we complement this with\nLLM-based static analysis techniques to distinguish between intended and\nunintended behavioral variability. We argue that such instrumentation is\nessential for giving developers greater control over evolving specifications\nand for identifying aspects of functionality that may require more precise and\nexplicit definitions.','Fabiana Fournier, Lior Limonad, Yuval David','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20127v1'),('2505.20128v1','Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers','Large language models (LLMs) have been widely integrated into information\nretrieval to advance traditional techniques. However, effectively enabling LLMs\nto seek accurate knowledge in complex tasks remains a challenge due to the\ncomplexity of multi-hop queries as well as the irrelevant retrieved content. To\naddress these limitations, we propose EXSEARCH, an agentic search framework,\nwhere the LLM learns to retrieve useful information as the reasoning unfolds\nthrough a self-incentivized process. At each step, the LLM decides what to\nretrieve (thinking), triggers an external retriever (search), and extracts\nfine-grained evidence (recording) to support next-step reasoning. To enable LLM\nwith this capability, EXSEARCH adopts a Generalized Expectation-Maximization\nalgorithm. In the E-step, the LLM generates multiple search trajectories and\nassigns an importance weight to each; the M-step trains the LLM on them with a\nre-weighted loss function. This creates a self-incentivized loop, where the LLM\niteratively learns from its own generated data, progressively improving itself\nfor search. We further theoretically analyze this training process,\nestablishing convergence guarantees. Extensive experiments on four\nknowledge-intensive benchmarks show that EXSEARCH substantially outperforms\nbaselines, e.g., +7.8% improvement on exact match score. Motivated by these\npromising results, we introduce EXSEARCH-Zoo, an extension that extends our\nmethod to broader scenarios, to facilitate future work.','Zhengliang Shi, Lingyong Yan, Dawei Yin, Suzan Verberne, Maarten de Rijke, Zhaochun Ren','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20128v1'),('2505.20130v1','Balancing Interference and Correlation in Spatial Experimental Designs: A Causal Graph Cut Approach','This paper focuses on the design of spatial experiments to optimize the\namount of information derived from the experimental data and enhance the\naccuracy of the resulting causal effect estimator. We propose a surrogate\nfunction for the mean squared error (MSE) of the estimator, which facilitates\nthe use of classical graph cut algorithms to learn the optimal design. Our\nproposal offers three key advances: (1) it accommodates moderate to large\nspatial interference effects; (2) it adapts to different spatial covariance\nfunctions; (3) it is computationally efficient. Theoretical results and\nnumerical experiments based on synthetic environments and a dispatch simulator\nthat models a city-scale ridesharing market, further validate the effectiveness\nof our design. A python implementation of our method is available at\nhttps://github.com/Mamba413/CausalGraphCut.','Zhu Jin, Li Jingyi, Zhou Hongyi, Lin Yinan, Lin Zhenhua, Shi Chengchun','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20130v1'),('2505.20131v1','MolEditRL: Structure-Preserving Molecular Editing via Discrete Diffusion and Reinforcement Learning','Molecular editing aims to modify a given molecule to optimize desired\nchemical properties while preserving structural similarity. However, current\napproaches typically rely on string-based or continuous representations, which\nfail to adequately capture the discrete, graph-structured nature of molecules,\nresulting in limited structural fidelity and poor controllability. In this\npaper, we propose MolEditRL, a molecular editing framework that explicitly\nintegrates structural constraints with precise property optimization.\nSpecifically, MolEditRL consists of two stages: (1) a discrete graph diffusion\nmodel pretrained to reconstruct target molecules conditioned on source\nstructures and natural language instructions; (2) an editing-aware\nreinforcement learning fine-tuning stage that further enhances property\nalignment and structural preservation by explicitly optimizing editing\ndecisions under graph constraints. For comprehensive evaluation, we construct\nMolEdit-Instruct, the largest and most property-rich molecular editing dataset,\ncomprising 3 million diverse examples spanning single- and multi-property tasks\nacross 10 chemical attributes. Experimental results demonstrate that MolEditRL\nsignificantly outperforms state-of-the-art methods in both property\noptimization accuracy and structural fidelity, achieving a 74\\% improvement in\nediting success rate while using 98\\% fewer parameters.','Yuanxin Zhuang, Dazhong Shen, Ying Sun','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20131v1'),('2505.20132v1','Tensorization is a powerful but underexplored tool for compression and interpretability of neural networks','Tensorizing a neural network involves reshaping some or all of its dense\nweight matrices into higher-order tensors and approximating them using low-rank\ntensor network decompositions. This technique has shown promise as a model\ncompression strategy for large-scale neural networks. However, despite\nencouraging empirical results, tensorized neural networks (TNNs) remain\nunderutilized in mainstream deep learning. In this position paper, we offer a\nperspective on both the potential and current limitations of TNNs. We argue\nthat TNNs represent a powerful yet underexplored framework for deep\nlearning--one that deserves greater attention from both engineering and\ntheoretical communities. Beyond compression, we highlight the value of TNNs as\na flexible class of architectures with distinctive scaling properties and\nincreased interpretability. A central feature of TNNs is the presence of bond\nindices, which introduce new latent spaces not found in conventional networks.\nThese internal representations may provide deeper insight into the evolution of\nfeatures across layers, potentially advancing the goals of mechanistic\ninterpretability. We conclude by outlining several key research directions\naimed at overcoming the practical barriers to scaling and adopting TNNs in\nmodern deep learning workflows.','Safa Hamreras, Sukhbinder Singh, Román Orús','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20132v1'),('2505.20133v1','AweDist: Attention-aware Embedding Distillation for New Input Token Embeddings','Current language models rely on static vocabularies determined at pretraining\ntime, which can lead to decreased performance and increased computational cost\nfor domains underrepresented in the original vocabulary. New tokens can be\nadded to solve this problem, when coupled with a good initialization for their\nnew embeddings. However, existing embedding initialization methods either\nrequire expensive further training or pretraining of additional modules. In\nthis paper, we propose AweDist and show that by distilling representations\nobtained using the original tokenization, we can quickly learn high-quality\ninput embeddings for new tokens. Experimental results with a wide range of\nopen-weight models show that AweDist is able to outperform even strong\nbaselines.','Konstantin Dobler, Desmond Elliott, Gerard de Melo','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20133v1'),('2505.20135v2','Data-Distill-Net: A Data Distillation Approach Tailored for Reply-based Continual Learning','Replay-based continual learning (CL) methods assume that models trained on a\nsmall subset can also effectively minimize the empirical risk of the complete\ndataset. These methods maintain a memory buffer that stores a sampled subset of\ndata from previous tasks to consolidate past knowledge. However, this\nassumption is not guaranteed in practice due to the limited capacity of the\nmemory buffer and the heuristic criteria used for buffer data selection. To\naddress this issue, we propose a new dataset distillation framework tailored\nfor CL, which maintains a learnable memory buffer to distill the global\ninformation from the current task data and accumulated knowledge preserved in\nthe previous memory buffer. Moreover, to avoid the computational overhead and\noverfitting risks associated with parameterizing the entire buffer during\ndistillation, we introduce a lightweight distillation module that can achieve\nglobal information distillation solely by generating learnable soft labels for\nthe memory buffer data. Extensive experiments show that, our method can achieve\ncompetitive results and effectively mitigates forgetting across various\ndatasets. The source code will be publicly available.','Wenyang Liao, Quanziang Wang, Yichen Wu, Renzhen Wang, Deyu Meng','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20135v2'),('2505.20137v1','Error Optimization: Overcoming Exponential Signal Decay in Deep Predictive Coding Networks','Predictive Coding (PC) offers a biologically plausible alternative to\nbackpropagation for neural network training, yet struggles with deeper\narchitectures. This paper identifies the root cause: an inherent signal decay\nproblem where gradients attenuate exponentially with depth, becoming\ncomputationally negligible due to numerical precision constraints. To address\nthis fundamental limitation, we introduce Error Optimization (EO), a novel\nreparameterization that preserves PC\\\'s theoretical properties while eliminating\nsignal decay. By optimizing over prediction errors rather than states, EO\nenables signals to reach all layers simultaneously and without attenuation,\nconverging orders of magnitude faster than standard PC. Experiments across\nmultiple architectures and datasets demonstrate that EO matches\nbackpropagation\\\'s performance even for deeper models where conventional PC\nstruggles. Besides practical improvements, our work provides theoretical\ninsight into PC dynamics and establishes a foundation for scaling\nbiologically-inspired learning to deeper architectures on digital hardware and\nbeyond.','Cédric Goemaere, Gaspard Oliviers, Rafal Bogacz, Thomas Demeester','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20137v1'),('2505.20139v1','StructEval: Benchmarking LLMs\\\' Capabilities to Generate Structural Outputs','As Large Language Models (LLMs) become integral to software development\nworkflows, their ability to generate structured outputs has become critically\nimportant. We introduce StructEval, a comprehensive benchmark for evaluating\nLLMs\\\' capabilities in producing both non-renderable (JSON, YAML, CSV) and\nrenderable (HTML, React, SVG) structured formats. Unlike prior benchmarks,\nStructEval systematically evaluates structural fidelity across diverse formats\nthrough two paradigms: 1) generation tasks, producing structured output from\nnatural language prompts, and 2) conversion tasks, translating between\nstructured formats. Our benchmark encompasses 18 formats and 44 types of task,\nwith novel metrics for format adherence and structural correctness. Results\nreveal significant performance gaps, even state-of-the-art models like o1-mini\nachieve only 75.58 average score, with open-source alternatives lagging\napproximately 10 points behind. We find generation tasks more challenging than\nconversion tasks, and producing correct visual content more difficult than\ngenerating text-only structures.','Jialin Yang, Dongfu Jiang, Lipeng He, Sherman Siu, Yuxuan Zhang, Disen Liao, Zhuofeng Li, Huaye Zeng, Yiming Jia, Haozhe Wang, Benjamin Schneider, Chi Ruan, Wentao Ma, Zhiheng Lyu, Yifei Wang, Yi Lu, Quy Duc Do, Ziyan Jiang, Ping Nie, Wenhu Chen','2025-05-26','cs.SE','http://arxiv.org/pdf/2505.20139v1'),('2505.20142v1','Model Stitching by Functional Latent Alignment','Evaluating functional similarity involves quantifying the degree to which\nindependently trained neural networks learn functionally similar\nrepresentations. Reliably inferring the functional similarity of these networks\nremains an open problem with far-reaching implications for AI. Model stitching\nhas emerged as a promising paradigm, where an optimal affine transformation\naligns two models to solve a task, with the stitched model serving as a proxy\nfor functional similarity. In this work, we draw inspiration from the knowledge\ndistillation literature and propose Functional Latent Alignment (FuLA) as a\nnovel optimality condition for model stitching. We revisit previously explored\nfunctional similarity testbeds and introduce a new one, based on which FuLA\nemerges as an overall more reliable method of functional similarity.\nSpecifically, our experiments in (a) adversarial training, (b) shortcut\ntraining and, (c) cross-layer stitching, reveal that FuLA is less prone to\nartifacts tied to training on task cues while achieving non-trivial alignments\nthat are missed by stitch-level matching.','Ioannis Athanasiadis, Anmar Karmush, Michael Felsberg','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20142v1'),('2505.20144v1','SeMe: Training-Free Language Model Merging via Semantic Alignment','Despite the remarkable capabilities of Language Models (LMs) across diverse\ntasks, no single model consistently outperforms others, necessitating efficient\nmethods to combine their strengths without expensive retraining. Existing model\nmerging techniques, such as parameter averaging and task-guided fusion, often\nrely on data-dependent computations or fail to preserve internal knowledge,\nlimiting their robustness and scalability. We introduce SeMe (Semantic-based\nMerging), a novel, data-free, and training-free approach that leverages latent\nsemantic alignment to merge LMs at a fine-grained, layer-wise level. Unlike\nprior work, SeMe not only preserves model behaviors but also explicitly\nstabilizes internal knowledge, addressing a critical gap in LM fusion. Through\nextensive experiments across diverse architectures and tasks, we demonstrate\nthat SeMe outperforms existing methods in both performance and efficiency while\neliminating reliance on external data. Our work establishes a new paradigm for\nknowledge-aware model merging and provides insights into the semantic structure\nof LMs, paving the way for more scalable and interpretable model composition.','Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20144v1'),('2505.20148v2','MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents','Spatial Planning is a crucial part in the field of spatial intelligence,\nwhich requires the understanding and planning about object arrangements in\nspace perspective. AI agents with the spatial planning ability can better adapt\nto various real-world applications, including robotic manipulation, automatic\nassembly, urban planning etc. Recent works have attempted to construct\nbenchmarks for evaluating the spatial intelligence of Multimodal Large Language\nModels (MLLMs). Nevertheless, these benchmarks primarily focus on spatial\nreasoning based on typical Visual Question-Answering (VQA) forms, which suffers\nfrom the gap between abstract spatial understanding and concrete task\nexecution. In this work, we take a step further to build a comprehensive\nbenchmark called MineAnyBuild, aiming to evaluate the spatial planning ability\nof open-world AI agents in the Minecraft game. Specifically, MineAnyBuild\nrequires an agent to generate executable architecture building plans based on\nthe given multi-modal human instructions. It involves 4,000 curated spatial\nplanning tasks and also provides a paradigm for infinitely expandable data\ncollection by utilizing rich player-generated content. MineAnyBuild evaluates\nspatial planning through four core supporting dimensions: spatial\nunderstanding, spatial reasoning, creativity, and spatial commonsense. Based on\nMineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based\nagents, revealing the severe limitations but enormous potential in their\nspatial planning abilities. We believe our MineAnyBuild will open new avenues\nfor the evaluation of spatial intelligence and help promote further development\nfor open-world AI agents capable of spatial planning.','Ziming Wei, Bingqian Lin, Zijian Jiao, Yunshuang Nie, Liang Ma, Yuecheng Liu, Yuzheng Zhuang, Xiaodan Liang','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20148v2'),('2505.20149v1','Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases','This paper focuses on using few-shot learning to improve the accuracy of\nclassifying OCT diagnosis images with major and rare classes. We used the\nGAN-based augmentation strategy as a baseline and introduced several novel\nmethods to further enhance our model. The proposed strategy contains U-GAT-IT\nfor improving the generative part and uses the data balance technique to narrow\ndown the skew of accuracy between all categories. The best model obtained was\nbuilt with CBAM attention mechanism and fine-tuned InceptionV3, and achieved an\noverall accuracy of 97.85%, representing a significant improvement over the\noriginal baseline.','Cheng-Yu Tai, Ching-Wen Chen, Chi-Chin Wu, Bo-Chen Chiu, Cheng-Hung, Lin, Cheng-Kai Lu, Jia-Kang Wang, Tzu-Lun Huang','2025-05-26','eess.IV','http://arxiv.org/pdf/2505.20149v1'),('2505.20150v1','On the (Non) Injectivity of Piecewise Linear Janossy Pooling','Multiset functions, which are functions that map multisets to vectors, are a\nfundamental tool in the construction of neural networks for multisets and\ngraphs. To guarantee that the vector representation of the multiset is\nfaithful, it is often desirable to have multiset mappings that are both\ninjective and bi-Lipschitz. Currently, there are several constructions of\nmultiset functions achieving both these guarantees, leading to improved\nperformance in some tasks but often also to higher compute time than standard\nconstructions. Accordingly, it is natural to inquire whether simpler multiset\nfunctions achieving the same guarantees are available. In this paper, we make a\nlarge step towards giving a negative answer to this question. We consider the\nfamily of k-ary Janossy pooling, which includes many of the most popular\nmultiset models, and prove that no piecewise linear Janossy pooling function\ncan be injective. On the positive side, we show that when restricted to\nmultisets without multiplicities, even simple deep-sets models suffice for\ninjectivity and bi-Lipschitzness.','Ilai Reshef, Nadav Dym','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20150v1'),('2505.20152v1','Hard Negative Contrastive Learning for Fine-Grained Geometric Understanding in Large Multimodal Models','Benefiting from contrastively trained visual encoders on large-scale natural\nscene images, Large Multimodal Models (LMMs) have achieved remarkable\nperformance across various visual perception tasks. However, the inherent\nlimitations of contrastive learning upon summarized descriptions fundamentally\nrestrict the capabilities of models in meticulous reasoning, particularly in\ncrucial scenarios of geometric problem-solving. To enhance geometric\nunderstanding, we propose a novel hard negative contrastive learning framework\nfor the vision encoder, which combines image-based contrastive learning using\ngeneration-based hard negatives created by perturbing diagram generation code,\nand text-based contrastive learning using rule-based negatives derived from\nmodified geometric descriptions and retrieval-based negatives selected based on\ncaption similarity. We train CLIP using our strong negative learning method,\nnamely MMCLIP (Multimodal Math CLIP), and subsequently train an LMM for\ngeometric problem-solving. Experiments show that our trained model, MMGeoLM,\nsignificantly outperforms other open-source models on three geometric reasoning\nbenchmarks. Even with a size of 7B, it can rival powerful closed-source models\nlike GPT-4o. We further study the impact of different negative sample\nconstruction methods and the number of negative samples on the geometric\nreasoning performance of LMM, yielding fruitful conclusions. The code and\ndataset are available at https://github.com/THU-KEG/MMGeoLM.','Kai Sun, Yushi Bai, Zhen Yang, Jiajie Zhang, Ji Qi, Lei Hou, Juanzi Li','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20152v1'),('2505.20154v1','UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter-Efficient Fine-Tuning of Large Models','This paper introduces Uniform Orthogonal Reinitialization Adaptation (UORA),\na novel parameter-efficient fine-tuning (PEFT) approach for Large Language\nModels (LLMs). UORA achieves state-of-the-art performance and parameter\nefficiency by leveraging a low-rank approximation method to reduce the number\nof trainable parameters. Unlike existing methods such as LoRA and VeRA, UORA\nemploys an interpolation-based reparametrization mechanism that selectively\nreinitializes rows and columns in frozen projection matrices, guided by the\nvector magnitude heuristic. This results in substantially fewer trainable\nparameters compared to LoRA and outperforms VeRA in computation and storage\nefficiency. Comprehensive experiments across various benchmarks demonstrate\nUORA\\\'s superiority in achieving competitive fine-tuning performance with\nnegligible computational overhead. We demonstrate its performance on GLUE and\nE2E benchmarks and its effectiveness in instruction-tuning large language\nmodels and image classification models. Our contributions establish a new\nparadigm for scalable and resource-efficient fine-tuning of LLMs.','Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20154v1'),('2505.20155v1','Pangu Light: Weight Re-Initialization for Pruning and Accelerating LLMs','Large Language Models (LLMs) deliver state-of-the-art capabilities across\nnumerous tasks, but their immense size and inference costs pose significant\ncomputational challenges for practical deployment. While structured pruning\noffers a promising avenue for model compression, existing methods often\nstruggle with the detrimental effects of aggressive, simultaneous width and\ndepth reductions, leading to substantial performance degradation. This paper\nargues that a critical, often overlooked, aspect in making such aggressive\njoint pruning viable is the strategic re-initialization and adjustment of\nremaining weights to improve the model post-pruning training accuracies. We\nintroduce Pangu Light, a framework for LLM acceleration centered around\nstructured pruning coupled with novel weight re-initialization techniques\ndesigned to address this ``missing piece\\\'\\\'. Our framework systematically\ntargets multiple axes, including model width, depth, attention heads, and\nRMSNorm, with its effectiveness rooted in novel re-initialization methods like\nCross-Layer Attention Pruning (CLAP) and Stabilized LayerNorm Pruning (SLNP)\nthat mitigate performance drops by providing the network a better training\nstarting point. Further enhancing efficiency, Pangu Light incorporates\nspecialized optimizations such as absorbing Post-RMSNorm computations and\ntailors its strategies to Ascend NPU characteristics. The Pangu Light models\nconsistently exhibit a superior accuracy-efficiency trade-off, outperforming\nprominent baseline pruning methods like Nemotron and established LLMs like\nQwen3 series. For instance, on Ascend NPUs, Pangu Light-32B\\\'s 81.6 average\nscore and 2585 tokens/s throughput exceed Qwen3-32B\\\'s 80.9 average score and\n2225 tokens/s.','Hanting Chen, Jiarui Qin, Jialong Guo, Tao Yuan, Yichun Yin, Huiling Zhen, Yasheng Wang, Jinpeng Li, Xiaojun Meng, Meng Zhang, Rongju Ruan, Zheyuan Bai, Yehui Tang, Can Chen, Xinghao Chen, Fisher Yu, Ruiming Tang, Yunhe Wang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20155v1'),('2505.20161v1','Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning','Effective generalization in language models depends critically on the\ndiversity of their training data. Yet existing diversity metrics often fall\nshort of this goal, relying on surface-level heuristics that are decoupled from\nmodel behavior. This motivates us to ask: What kind of diversity in training\ndata actually drives generalization in language models -- and how can we\nmeasure and amplify it? Through large-scale empirical analyses spanning over\n300 training runs, carefully controlled for data scale and quality, we show\nthat data diversity can be a strong predictor of generalization in LLM\nreasoning -- as measured by average model performance on unseen\nout-of-distribution benchmarks. We introduce G-Vendi, a metric that quantifies\ndiversity via the entropy of model-induced gradients. Despite using a small\noff-the-shelf proxy model for gradients, G-Vendi consistently outperforms\nalternative measures, achieving strong correlation (Spearman\\\'s $\\rho \\approx\n0.9$) with out-of-distribution (OOD) performance on both natural language\ninference (NLI) and math reasoning tasks. Building on this insight, we present\nPrismatic Synthesis, a framework for generating diverse synthetic data by\ntargeting underrepresented regions in gradient space. Experimental results show\nthat Prismatic Synthesis consistently improves model performance as we scale\nsynthetic data -- not just on in-distribution test but across unseen,\nout-of-distribution benchmarks -- significantly outperforming state-of-the-art\nmodels that rely on 20 times larger data generator than ours. For example,\nPrismMath-7B, our model distilled from a 32B LLM, outperforms\nR1-Distill-Qwen-7B -- the same base model trained on proprietary data generated\nby 671B R1 -- on 6 out of 7 challenging benchmarks.','Jaehun Jung, Seungju Han, Ximing Lu, Skyler Hallinan, David Acuna, Shrimai Prabhumoye, Mostafa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Yejin Choi','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20161v1'),('2505.20162v1','Capability-Based Scaling Laws for LLM Red-Teaming','As large language models grow in capability and agency, identifying\nvulnerabilities through red-teaming becomes vital for safe deployment. However,\ntraditional prompt-engineering approaches may prove ineffective once\nred-teaming turns into a weak-to-strong problem, where target models surpass\nred-teamers in capabilities. To study this shift, we frame red-teaming through\nthe lens of the capability gap between attacker and target. We evaluate more\nthan 500 attacker-target pairs using LLM-based jailbreak attacks that mimic\nhuman red-teamers across diverse families, sizes, and capability levels. Three\nstrong trends emerge: (i) more capable models are better attackers, (ii) attack\nsuccess drops sharply once the target\\\'s capability exceeds the attacker\\\'s, and\n(iii) attack success rates correlate with high performance on social science\nsplits of the MMLU-Pro benchmark. From these trends, we derive a jailbreaking\nscaling law that predicts attack success for a fixed target based on\nattacker-target capability gap. These findings suggest that fixed-capability\nattackers (e.g., humans) may become ineffective against future models,\nincreasingly capable open-source models amplify risks for existing systems, and\nmodel providers must accurately measure and control models\\\' persuasive and\nmanipulative abilities to limit their effectiveness as attackers.','Alexander Panfilov, Paul Kassianik, Maksym Andriushchenko, Jonas Geiping','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20162v1'),('2505.20163v1','Exploring Generative Error Correction for Dysarthric Speech Recognition','Despite the remarkable progress in end-to-end Automatic Speech Recognition\n(ASR) engines, accurately transcribing dysarthric speech remains a major\nchallenge. In this work, we proposed a two-stage framework for the Speech\nAccessibility Project Challenge at INTERSPEECH 2025, which combines\ncutting-edge speech recognition models with LLM-based generative error\ncorrection (GER). We assess different configurations of model scales and\ntraining strategies, incorporating specific hypothesis selection to improve\ntranscription accuracy. Experiments on the Speech Accessibility Project dataset\ndemonstrate the strength of our approach on structured and spontaneous speech,\nwhile highlighting challenges in single-word recognition. Through comprehensive\nanalysis, we provide insights into the complementary roles of acoustic and\nlinguistic modeling in dysarthric speech recognition','Moreno La Quatra, Alkis Koudounas, Valerio Mario Salerno, Sabato Marco Siniscalchi','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20163v1'),('2505.20164v1','Visual Abstract Thinking Empowers Multimodal Reasoning','Images usually convey richer detail than text, but often include redundant\ninformation which potentially downgrades multimodal reasoning performance. When\nfaced with lengthy or complex messages, humans tend to employ abstract thinking\nto convert them into simple and concise abstracts. Inspired by this cognitive\nstrategy, we introduce Visual Abstract Thinking (VAT), a novel thinking\nparadigm that prompts Multimodal Large Language Models (MLLMs) with visual\nabstract instead of explicit verbal thoughts or elaborate guidance, permitting\na more concentrated visual reasoning mechanism. Explicit thinking, such as\nChain-of-thought (CoT) or tool-augmented approaches, increases the complexity\nof reasoning process via inserting verbose intermediate steps, external\nknowledge or visual information. In contrast, VAT reduces redundant visual\ninformation and encourages models to focus their reasoning on more essential\nvisual elements. Experimental results show that VAT consistently empowers\ndifferent models, and achieves an average gain of 17% over GPT-4o baseline by\nemploying diverse types of visual abstracts, demonstrating that VAT can enhance\nvisual reasoning abilities for MLLMs regarding conceptual, structural and\nrelational reasoning tasks. VAT is also compatible with CoT in\nknowledge-intensive multimodal reasoning tasks. These findings highlight the\neffectiveness of visual reasoning via abstract thinking and encourage further\nexploration of more diverse reasoning paradigms from the perspective of human\ncognition.','Dairu Liu, Ziyue Wang, Minyuan Ruan, Fuwen Luo, Chi Chen, Peng Li, Yang Liu','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20164v1'),('2505.20166v1','From Alignment to Advancement: Bootstrapping Audio-Language Alignment with Synthetic Data','Audio-aware large language models (ALLMs) have recently made great strides in\nunderstanding and processing audio inputs. These models are typically adapted\nfrom text-based large language models (LLMs) through additional training on\naudio-related tasks. However, this adaptation process presents two major\nlimitations. First, ALLMs often suffer from catastrophic forgetting, where\nimportant textual capabilities such as instruction-following are lost after\ntraining on audio data. In some cases, models may even hallucinate sounds that\nare not present in the input audio, raising concerns about their reliability.\nSecond, achieving cross-modal alignment between audio and language typically\nrelies on large collections of task-specific question-answer pairs for\ninstruction tuning, making the process resource-intensive. To address these\nissues, we leverage the backbone LLMs from ALLMs to synthesize general-purpose\ncaption-style alignment data. We refer to this process as bootstrapping\naudio-language alignment via synthetic data generation from backbone LLMs\n(BALSa). Building on BALSa, we introduce LISTEN (Learning to Identify Sounds\nThrough Extended Negative Samples), a contrastive-like training method designed\nto improve ALLMs\\\' ability to distinguish between present and absent sounds. We\nfurther extend BALSa to multi-audio scenarios, where the model either explains\nthe differences between audio inputs or produces a unified caption that\ndescribes them all, thereby enhancing audio-language alignment. Experimental\nresults indicate that our method effectively mitigates audio hallucinations\nwhile reliably maintaining strong performance in audio understanding,\nreasoning, and instruction-following skills. Moreover, incorporating\nmulti-audio training further enhances the model\\\'s comprehension and reasoning\ncapabilities. Overall, BALSa offers an efficient and scalable approach to the\ndevelopment of ALLMs.','Chun-Yi Kuan, Hung-yi Lee','2025-05-26','eess.AS','http://arxiv.org/pdf/2505.20166v1'),('2505.20170v1','Program of Equations Thoughts to Solve Algebra Word Problems','Solving algebraic word problems (AWPs) has recently emerged as an important\nnatural language processing task. Recently, large language models (LLMs) have\ndemonstrated powerful mathematical capabilities, and the Chain-of-Thought\ntechnique, which guides LLMs through step-by-step reasoning, has yielded\nimpressive results. However, this reasoning ability is limited by the\ncomputational weaknesses of LLMs themselves, where calculation errors can\naccumulate, leading to incorrect final answers. To address this, we propose\nProgram of Equations Thoughts (POET), which transforms the task of generating\nstep-by-step reasoning answers into a two-stage task of predicting equations\nand generating code, offloading complex computations to a Python interpreter to\navoid calculation errors in LLMs. Furthermore, we propose Zero-shot POET, which\nutilizes a manually designed template to enable LLMs to directly generate\nPython code for one-step solving. Our method achieves accuracies of 95.3% and\n98.0% on the PEN and ALG514 datasets, respectively, setting a new\nstate-of-the-art (SOTA). Zero-shot POET also achieves the SOTA result of 95.5%\non the DRAW-1K dataset.','Yunze Lin','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20170v1'),('2505.20172v1','A Theoretical Framework for Grokking: Interpolation followed by Riemannian Norm Minimisation','We study the dynamics of gradient flow with small weight decay on general\ntraining losses $F: \\mathbb{R}^d \\to \\mathbb{R}$. Under mild regularity\nassumptions and assuming convergence of the unregularised gradient flow, we\nshow that the trajectory with weight decay $\\lambda$ exhibits a two-phase\nbehaviour as $\\lambda \\to 0$. During the initial fast phase, the trajectory\nfollows the unregularised gradient flow and converges to a manifold of critical\npoints of $F$. Then, at time of order $1/\\lambda$, the trajectory enters a slow\ndrift phase and follows a Riemannian gradient flow minimising the $\\ell_2$-norm\nof the parameters. This purely optimisation-based phenomenon offers a natural\nexplanation for the \\textit{grokking} effect observed in deep learning, where\nthe training loss rapidly reaches zero while the test loss plateaus for an\nextended period before suddenly improving. We argue that this generalisation\njump can be attributed to the slow norm reduction induced by weight decay, as\nexplained by our analysis. We validate this mechanism empirically on several\nsynthetic regression tasks.','Etienne Boursier, Scott Pesme, Radu-Alexandru Dragomir','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20172v1'),('2505.20176v1','\"KAN you hear me?\" Exploring Kolmogorov-Arnold Networks for Spoken Language Understanding','Kolmogorov-Arnold Networks (KANs) have recently emerged as a promising\nalternative to traditional neural architectures, yet their application to\nspeech processing remains under explored. This work presents the first\ninvestigation of KANs for Spoken Language Understanding (SLU) tasks. We\nexperiment with 2D-CNN models on two datasets, integrating KAN layers in five\ndifferent configurations within the dense block. The best-performing setup,\nwhich places a KAN layer between two linear layers, is directly applied to\ntransformer-based models and evaluated on five SLU datasets with increasing\ncomplexity. Our results show that KAN layers can effectively replace the linear\nlayers, achieving comparable or superior performance in most cases. Finally, we\nprovide insights into how KAN and linear layers on top of transformers\ndifferently attend to input regions of the raw waveforms.','Alkis Koudounas, Moreno La Quatra, Eliana Pastor, Sabato Marco Siniscalchi, Elena Baralis','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20176v1'),('2505.20177v1','The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination','Inspired by recent work on learning with distribution shift, we give a\ngeneral outlier removal algorithm called iterative polynomial filtering and\nshow a number of striking applications for supervised learning with\ncontamination: (1) We show that any function class that can be approximated by\nlow-degree polynomials with respect to a hypercontractive distribution can be\nefficiently learned under bounded contamination (also known as nasty noise).\nThis is a surprising resolution to a longstanding gap between the complexity of\nagnostic learning and learning with contamination, as it was widely believed\nthat low-degree approximators only implied tolerance to label noise. (2) For\nany function class that admits the (stronger) notion of sandwiching\napproximators, we obtain near-optimal learning guarantees even with respect to\nheavy additive contamination, where far more than $1/2$ of the training set may\nbe added adversarially. Prior related work held only for regression and in a\nlist-decodable setting. (3) We obtain the first efficient algorithms for\ntolerant testable learning of functions of halfspaces with respect to any fixed\nlog-concave distribution. Even the non-tolerant case for a single halfspace in\nthis setting had remained open. These results significantly advance our\nunderstanding of efficient supervised learning under contamination, a setting\nthat has been much less studied than its unsupervised counterpart.','Adam R. Klivans, Konstantinos Stavropoulos, Kevin Tian, Arsen Vasilyan','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20177v1'),('2505.20178v1','No Free Lunch: Non-Asymptotic Analysis of Prediction-Powered Inference','Prediction-Powered Inference (PPI) is a popular strategy for combining\ngold-standard and possibly noisy pseudo-labels to perform statistical\nestimation. Prior work has shown an asymptotic \"free lunch\" for PPI++, an\nadaptive form of PPI, showing that the *asymptotic* variance of PPI++ is always\nless than or equal to the variance obtained from using gold-standard labels\nalone. Notably, this result holds *regardless of the quality of the\npseudo-labels*. In this work, we demystify this result by conducting an exact\nfinite-sample analysis of the estimation error of PPI++ on the mean estimation\nproblem. We give a \"no free lunch\" result, characterizing the settings (and\nsample sizes) where PPI++ has provably worse estimation error than using\ngold-standard labels alone. Specifically, PPI++ will outperform if and only if\nthe correlation between pseudo- and gold-standard is above a certain level that\ndepends on the number of labeled samples ($n$). In some cases our results\nsimplify considerably: For Gaussian data, the correlation must be at least\n$1/\\sqrt{n - 2}$ in order to see improvement, and a similar result holds for\nbinary labels. In experiments, we illustrate that our theoretical findings hold\non real-world datasets, and give insights into trade-offs between single-sample\nand sample-splitting variants of PPI++.','Pranav Mani, Peng Xu, Zachary C. Lipton, Michael Oberst','2025-05-26','stat.ML','http://arxiv.org/pdf/2505.20178v1'),('2505.20182v1','An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation','We study cost-efficient collaboration between strong and weak language models\nfor repository-level code generation, where the weak model handles simpler\ntasks at lower cost, and the most challenging tasks are delegated to the strong\nmodel. While many works propose architectures for this task, few analyze\nperformance relative to cost. We evaluate a broad spectrum of collaboration\nstrategies: context-based, pipeline-based, and dynamic, on GitHub issue\nresolution. Our most effective collaborative strategy achieves equivalent\nperformance to the strong model while reducing the cost by 40%. Based on our\nfindings, we offer actionable guidelines for choosing collaboration strategies\nunder varying budget and performance constraints. Our results show that\nstrong-weak collaboration substantially boosts the weak model\\\'s performance at\na fraction of the cost, pipeline and context-based methods being most\nefficient. We release the code for our work at\nhttps://github.com/shubhamrgandhi/codegen-strong-weak-collab.','Shubham Gandhi, Atharva Naik, Yiqing Xie, Carolyn Rose','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20182v1'),('2505.20184v1','THiNK: Can Large Language Models Think-aloud?','Assessing higher-order thinking skills in large language models (LLMs)\nremains a fundamental challenge, especially in tasks that go beyond\nsurface-level accuracy. In this work, we propose THiNK (Testing Higher-order\nNotion of Knowledge), a multi-agent, feedback-driven evaluation framework\ngrounded in Bloom\\\'s Taxonomy. THiNK frames reasoning assessment as an iterative\ntask of problem generation, critique, and revision, encouraging LLMs to\nthink-aloud through step-by-step reflection and refinement. This enables a\nsystematic evaluation of both lower-order (e.g., remember, understand) and\nhigher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven\nstate-of-the-art LLMs and perform a detailed cognitive analysis of their\noutputs. Results reveal that while models reliably perform lower-order\ncategories well, they struggle with applying knowledge in realistic contexts\nand exhibit limited abstraction. Structured feedback loops significantly\nimprove reasoning performance, particularly in higher-order thinking.\nQualitative evaluations further confirm that THiNK-guided outputs better align\nwith domain logic and problem structure. The code of our framework provides a\nscalable methodology for probing and enhancing LLM reasoning, offering new\ndirections for evaluation grounded in learning science, which is available at\nour GitHub repository.','Yongan Yu, Mengqian Wu, Yiran Lin, Nikki G. Lobczowski','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20184v1'),('2505.20188v1','Research on feature fusion and multimodal patent text based on graph attention network','Aiming at the problems of cross-modal feature fusion, low efficiency of long\ntext modeling and lack of hierarchical semantic coherence in patent text\nsemantic mining, this study proposes HGM-Net, a deep learning framework that\nintegrates Hierarchical Comparative Learning (HCL), Multi-modal Graph Attention\nNetwork (M-GAT) and Multi-Granularity Sparse Attention (MSA), which builds a\ndynamic mask, contrast and cross-structural similarity constraints on the word,\nsentence and paragraph hierarchies through HCL. Contrast and cross-structural\nsimilarity constraints are constructed at the word and paragraph levels by HCL\nto strengthen the local semantic and global thematic consistency of patent\ntext; M-GAT models patent classification codes, citation relations and text\nsemantics as heterogeneous graph structures, and achieves dynamic fusion of\nmulti-source features by cross-modal gated attention; MSA adopts a hierarchical\nsparsity strategy to optimize the computational efficiency of long text\nmodeling at word, phrase, sentence and paragraph granularity. Experiments show\nthat the framework demonstrates significant advantages over existing deep\nlearning methods in tasks such as patent classification and similarity\nmatching, and provides a solution with both theoretical innovation and\npractical value for solving the problems of patent examination efficiency\nimprovement and technology relevance mining.','Zhenzhen Song, Ziwei Liu, Hongji Li','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20188v1'),('2505.20189v1','Private Geometric Median in Nearly-Linear Time','Estimating the geometric median of a dataset is a robust counterpart to mean\nestimation, and is a fundamental problem in computational geometry. Recently,\n[HSU24] gave an $(\\varepsilon, \\delta)$-differentially private algorithm\nobtaining an $\\alpha$-multiplicative approximation to the geometric median\nobjective, $\\frac 1 n \\sum_{i \\in [n]} \\|\\cdot - \\mathbf{x}_i\\|$, given a\ndataset $\\mathcal{D} := \\{\\mathbf{x}_i\\}_{i \\in [n]} \\subset \\mathbb{R}^d$.\nTheir algorithm requires $n \\gtrsim \\sqrt d \\cdot \\frac 1 {\\alpha\\varepsilon}$\nsamples, which they prove is information-theoretically optimal. This result is\nsurprising because its error scales with the \\emph{effective radius} of\n$\\mathcal{D}$ (i.e., of a ball capturing most points), rather than the\nworst-case radius. We give an improved algorithm that obtains the same\napproximation quality, also using $n \\gtrsim \\sqrt d \\cdot \\frac 1\n{\\alpha\\epsilon}$ samples, but in time $\\widetilde{O}(nd + \\frac d\n{\\alpha^2})$. Our runtime is nearly-linear, plus the cost of the cheapest\nnon-private first-order method due to [CLM+16]. To achieve our results, we use\nsubsampling and geometric aggregation tools inspired by FriendlyCore [TCK+22]\nto speed up the \"warm start\" component of the [HSU24] algorithm, combined with\na careful custom analysis of DP-SGD\\\'s sensitivity for the geometric median\nobjective.','Syamantak Kumar, Daogao Liu, Kevin Tian, Chutong Yang','2025-05-26','cs.DS','http://arxiv.org/pdf/2505.20189v1'),('2505.20190v1','Leveraging Descriptions of Emotional Preferences in Recommender Systems','The affective attitude of liking a recommended item reflects just one\ncategory in a wide spectrum of affective phenomena that also includes emotions\nsuch as entranced or intrigued, moods such as cheerful or buoyant, as well as\nmore fine-grained affective states, such as \"pleasantly surprised by the\nconclusion\". In this paper, we introduce a novel recommendation task that can\nleverage a virtually unbounded range of affective states sought explicitly by\nthe user in order to identify items that, upon consumption, are likely to\ninduce those affective states. Correspondingly, we create a large dataset of\nuser preferences containing expressions of fine-grained affective states that\nare mined from book reviews, and propose a Transformer-based architecture that\nleverages such affective expressions as input. We then use the resulting\ndataset of affective states preferences, together with the linked users and\ntheir histories of book readings, ratings, and reviews, to train and evaluate\nmultiple recommendation models on the task of matching recommended items with\naffective preferences. Experiments show that the best results are obtained by\nmodels that can utilize textual descriptions of items and user affective\npreferences.','Tonmoy Hasan, Razvan Bunescu','2025-05-26','cs.IR','http://arxiv.org/pdf/2505.20190v1'),('2505.20192v1','FunReason: Enhancing Large Language Models\\\' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement','The integration of large language models (LLMs) with function calling has\nemerged as a crucial capability for enhancing their practical utility in\nreal-world applications. However, effectively combining reasoning processes\nwith accurate function execution remains a significant challenge. Traditional\ntraining approaches often struggle to balance the detailed reasoning steps with\nthe precision of function calls, leading to suboptimal performance. To address\nthese limitations, we introduce FunReason, a novel framework that enhances\nLLMs\\\' function calling capabilities through an automated data refinement\nstrategy and a Self-Refinement Multiscale Loss (SRML) approach. FunReason\nleverages LLMs\\\' natural reasoning abilities to generate high-quality training\nexamples, focusing on query parseability, reasoning coherence, and function\ncall precision. The SRML approach dynamically balances the contribution of\nreasoning processes and function call accuracy during training, addressing the\ninherent trade-off between these two critical aspects. FunReason achieves\nperformance comparable to GPT-4o while effectively mitigating catastrophic\nforgetting during fine-tuning. FunReason provides a comprehensive solution for\nenhancing LLMs\\\' function calling capabilities by introducing a balanced\ntraining methodology and a data refinement pipeline. For code and dataset,\nplease refer to our repository at GitHub\nhttps://github.com/BingguangHao/FunReason','Bingguang Hao, Maolin Wang, Zengzhuang Xu, Cunyin Peng, Yicheng Chen, Xiangyu Zhao, Jinjie Gu, Chenyi Zhuang','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20192v1'),('2505.20195v2','Monocle: Hybrid Local-Global In-Context Evaluation for Long-Text Generation with Uncertainty-Based Active Learning','Assessing the quality of long-form, model-generated text is challenging, even\nwith advanced LLM-as-a-Judge methods, due to performance degradation as input\nlength increases. To address this issue, we propose a divide-and-conquer\napproach, which breaks down the comprehensive evaluation task into a series of\nlocalized scoring tasks, followed by a final global assessment. This strategy\nallows for more granular and manageable evaluations, ensuring that each segment\nof the text is assessed in isolation for both coherence and quality, while also\naccounting for the overall structure and consistency of the entire piece.\nMoreover, we introduce a hybrid in-context learning approach that leverages\nhuman annotations to enhance the performance of both local and global\nevaluations. By incorporating human-generated feedback directly into the\nevaluation process, this method allows the model to better align with human\njudgment. Finally, we develop an uncertainty-based active learning algorithm\nthat efficiently selects data samples for human annotation, thereby reducing\nannotation costs in practical scenarios. Experimental results show that the\nproposed evaluation framework outperforms several representative baselines,\nhighlighting the effectiveness of our approach.','Xiaorong Wang, Ting Yang, Zhu Zhang, Shuo Wang, Zihan Zhou, Liner Yang, Zhiyuan Liu, Maosong Sun','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20195v2'),('2505.20196v1','Temporal Sampling for Forgotten Reasoning in LLMs','Fine-tuning large language models (LLMs) is intended to improve their\nreasoning capabilities, yet we uncover a counterintuitive effect: models often\nforget how to solve problems they previously answered correctly during\ntraining. We term this phenomenon temporal forgetting and show that it is\nwidespread across model sizes, fine-tuning methods (both Reinforcement Learning\nand Supervised Fine-Tuning), and multiple reasoning benchmarks. To address this\ngap, we introduce Temporal Sampling, a simple decoding strategy that draws\noutputs from multiple checkpoints along the training trajectory. This approach\nrecovers forgotten solutions without retraining or ensembling, and leads to\nsubstantial improvements in reasoning performance, gains from 4 to 19 points in\nPass@k and consistent gains in Majority@k across several benchmarks. We further\nextend our method to LoRA-adapted models, demonstrating that storing only\nadapter weights across checkpoints achieves similar benefits with minimal\nstorage cost. By leveraging the temporal diversity inherent in training,\nTemporal Sampling offers a practical, compute-efficient way to surface hidden\nreasoning ability and rethink how we evaluate LLMs.','Yuetai Li, Zhangchen Xu, Fengqing Jiang, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Xiang Yue, Radha Poovendran','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20196v1'),('2505.20199v1','Adaptive Classifier-Free Guidance via Dynamic Low-Confidence Masking','Classifier-Free Guidance (CFG) significantly enhances controllability in\ngenerative models by interpolating conditional and unconditional predictions.\nHowever, standard CFG often employs a static unconditional input, which can be\nsuboptimal for iterative generation processes where model uncertainty varies\ndynamically. We introduce Adaptive Classifier-Free Guidance (A-CFG), a novel\nmethod that tailors the unconditional input by leveraging the model\\\'s\ninstantaneous predictive confidence. At each step of an iterative (masked)\ndiffusion language model, A-CFG identifies tokens in the currently generated\nsequence for which the model exhibits low confidence. These tokens are\ntemporarily re-masked to create a dynamic, localized unconditional input. This\nfocuses CFG\\\'s corrective influence precisely on areas of ambiguity, leading to\nmore effective guidance. We integrate A-CFG into a state-of-the-art masked\ndiffusion language model and demonstrate its efficacy. Experiments on diverse\nlanguage generation benchmarks show that A-CFG yields substantial improvements\nover standard CFG, achieving, for instance, a 3.9 point gain on GPQA. Our work\nhighlights the benefit of dynamically adapting guidance mechanisms to model\nuncertainty in iterative generation.','Pengxiang Li, Shilin Yan, Joey Tsai, Renrui Zhang, Ruichuan An, Ziyu Guo, Xiaowei Gao','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20199v1'),('2505.20201v2','Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations','Limited access to mental healthcare, extended wait times, and increasing\ncapabilities of Large Language Models (LLMs) has led individuals to turn to\nLLMs for fulfilling their mental health needs. However, examining the\nmulti-turn mental health conversation capabilities of LLMs remains\nunder-explored. Existing evaluation frameworks typically focus on diagnostic\naccuracy and win-rates and often overlook alignment with patient-specific\ngoals, values, and personalities required for meaningful conversations. To\naddress this, we introduce MedAgent, a novel framework for synthetically\ngenerating realistic, multi-turn mental health sensemaking conversations and\nuse it to create the Mental Health Sensemaking Dialogue (MHSD) dataset,\ncomprising over 2,200 patient-LLM conversations. Additionally, we present\nMultiSenseEval, a holistic framework to evaluate the multi-turn conversation\nabilities of LLMs in healthcare settings using human-centric criteria. Our\nfindings reveal that frontier reasoning models yield below-par performance for\npatient-centric communication and struggle at advanced diagnostic capabilities\nwith average score of 31%. Additionally, we observed variation in model\nperformance based on patient\\\'s persona and performance drop with increasing\nturns in the conversation. Our work provides a comprehensive synthetic data\ngeneration framework, a dataset and evaluation framework for assessing LLMs in\nmulti-turn mental health conversations.','Mohit Chandra, Siddharth Sriraman, Harneet Singh Khanuja, Yiqiao Jin, Munmun De Choudhury','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20201v2'),('2505.20203v1','Shutdownable Agents through POST-Agency','Many fear that future artificial agents will resist shutdown. I present an\nidea - the POST-Agents Proposal - for ensuring that doesn\\\'t happen. I propose\nthat we train agents to satisfy Preferences Only Between Same-Length\nTrajectories (POST). I then prove that POST - together with other conditions -\nimplies Neutrality+: the agent maximizes expected utility, ignoring the\nprobability distribution over trajectory-lengths. I argue that Neutrality+\nkeeps agents shutdownable and allows them to be useful.','Elliott Thornley','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20203v1'),('2505.20206v1','Evaluating Large Language Models for Code Review','Context: Code reviews are crucial for software quality. Recent AI advances\nhave allowed large language models (LLMs) to review and fix code; now, there\nare tools that perform these reviews. However, their reliability and accuracy\nhave not yet been systematically evaluated. Objective: This study compares\ndifferent LLMs\\\' performance in detecting code correctness and suggesting\nimprovements. Method: We tested GPT4o and Gemini 2.0 Flash on 492 AI generated\ncode blocks of varying correctness, along with 164 canonical code blocks from\nthe HumanEval benchmark. To simulate the code review task objectively, we\nexpected LLMs to assess code correctness and improve the code if needed. We ran\nexperiments with different configurations and reported on the results. Results:\nWith problem descriptions, GPT4o and Gemini 2.0 Flash correctly classified code\ncorrectness 68.50% and 63.89% of the time, respectively, and corrected the code\n67.83% and 54.26% of the time for the 492 code blocks of varying correctness.\nWithout problem descriptions, performance declined. The results for the 164\ncanonical code blocks differed, suggesting that performance depends on the type\nof code. Conclusion: LLM code reviews can help suggest improvements and assess\ncorrectness, but there is a risk of faulty outputs. We propose a process that\ninvolves humans, called the \"Human in the loop LLM Code Review\" to promote\nknowledge sharing while mitigating the risk of faulty outputs.','Umut Cihan, Arda İçöz, Vahid Haratian, Eray Tüzün','2025-05-26','cs.SE','http://arxiv.org/pdf/2505.20206v1'),('2505.20209v1','How to Improve the Robustness of Closed-Source Models on NLI','Closed-source Large Language Models (LLMs) have become increasingly popular,\nwith impressive performance across a wide range of natural language tasks.\nThese models can be fine-tuned to further improve performance, but this often\nresults in the models learning from dataset-specific heuristics that reduce\ntheir robustness on out-of-distribution (OOD) data. Existing methods to improve\nrobustness either perform poorly, or are non-applicable to closed-source models\nbecause they assume access to model internals, or the ability to change the\nmodel\\\'s training procedure. In this work, we investigate strategies to improve\nthe robustness of closed-source LLMs through data-centric methods that do not\nrequire access to model internals. We find that the optimal strategy depends on\nthe complexity of the OOD data. For highly complex OOD datasets, upsampling\nmore challenging training examples can improve robustness by up to 1.5%. For\nless complex OOD datasets, replacing a portion of the training set with\nLLM-generated examples can improve robustness by 3.7%. More broadly, we find\nthat large-scale closed-source autoregressive LLMs are substantially more\nrobust than commonly used encoder models, and are a more appropriate choice of\nbaseline going forward.','Joe Stacey, Lisa Alazraki, Aran Ubhi, Beyza Ermis, Aaron Mueller, Marek Rei','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20209v1'),('2505.20211v1','Parameter-Efficient Fine-Tuning with Column Space Projection','Fine-tuning large language models (LLMs) with minimal computational overhead\nis essential for efficiently adapting them to downstream tasks under resource\nconstraints. Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank\nAdaptation (LoRA), facilitate this by updating only a small subset of\nparameters. However, recent studies show that LoRA diverges from full\nfine-tuning (Full FT) in its learning behavior, particularly in terms of\nspectral properties. Motivated by these findings, we propose PiCa, the first\ntheoretically grounded PEFT method based on the spectral properties of\nfine-tuned weights. PiCa projects gradients onto the low-rank column subspace\nof pre-trained weights and exhibits learning patterns more closely aligned with\nFull FT. Furthermore, we show that combining PiCa with weight sharing\ndrastically reduces the number of trainable parameters without compromising\nperformance, enabling to achieve superior performance than LoRA using 13x fewer\ntrainable parameters. Extensive experiments demonstrate PiCa achieves the\nstate-of-the-art performance compared to existing PEFT methods.','Junseo Hwang, Wonguk Cho, Taesup Kim','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20211v1'),('2505.20214v1','The Mirage of Multimodality: Where Truth is Tested and Honesty Unravels','Reasoning models have recently attracted significant attention, especially\nfor tasks that involve complex inference. Their strengths exemplify the System\nII paradigm (slow, structured thinking), contrasting with the System I (rapid,\nheuristic-driven). Yet, does slower reasoning necessarily lead to greater\ntruthfulness? Our findings suggest otherwise. In this study, we present the\nfirst systematic investigation of distortions associated with System I and\nSystem II reasoning in multimodal contexts. We demonstrate that slower\nreasoning models, when presented with incomplete or misleading visual inputs,\nare more likely to fabricate plausible yet false details to support flawed\nreasoning -- a phenomenon we term the \"Mirage of Multimodality\". To examine\nthis, we constructed a 5,000-sample hierarchical prompt dataset annotated by 50\nhuman participants. These prompts gradually increase in complexity, revealing a\nconsistent pattern: slower reasoning models tend to employ depth-first thinking\n(delving deeper into incorrect premises), whereas faster chat models favor\nbreadth-first inference, exhibiting greater caution under uncertainty. Our\nresults highlight a critical vulnerability of slower reasoning models: although\nhighly effective in structured domains such as mathematics, it becomes brittle\nwhen confronted with ambiguous multimodal inputs.','Jiaming Ji, Sitong Fang, Wenjing Cao, Jiahao Li, Xuyao Wang, Juntao Dai, Chi-Min Chan, Sirui Han, Yike Guo, Yaodong Yang','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20214v1'),('2505.20215v1','Dependency Parsing is More Parameter-Efficient with Normalization','Dependency parsing is the task of inferring natural language structure, often\napproached by modeling word interactions via attention through biaffine\nscoring. This mechanism works like self-attention in Transformers, where scores\nare calculated for every pair of words in a sentence. However, unlike\nTransformer attention, biaffine scoring does not use normalization prior to\ntaking the softmax of the scores. In this paper, we provide theoretical\nevidence and empirical results revealing that a lack of normalization\nnecessarily results in overparameterized parser models, where the extra\nparameters compensate for the sharp softmax outputs produced by high variance\ninputs to the biaffine scoring function. We argue that biaffine scoring can be\nmade substantially more efficient by performing score normalization. We conduct\nexperiments on six datasets for semantic and syntactic dependency parsing using\na one-hop parser. We train N-layer stacked BiLSTMs and evaluate the parser\\\'s\nperformance with and without normalizing biaffine scores. Normalizing allows us\nto beat the state of the art on two datasets, with fewer samples and trainable\nparameters. Code: https://anonymous.4open.science/r/EfficientSDP-70C1','Paolo Gajo, Domenic Rosati, Hassan Sajjad, Alberto Barrón-Cedeño','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20215v1'),('2505.20218v1','Fine-grained List-wise Alignment for Generative Medication Recommendation','Accurate and safe medication recommendations are critical for effective\nclinical decision-making, especially in multimorbidity cases. However, existing\nsystems rely on point-wise prediction paradigms that overlook synergistic drug\neffects and potential adverse drug-drug interactions (DDIs). We propose FLAME,\na fine-grained list-wise alignment framework for large language models (LLMs),\nenabling drug-by-drug generation of drug lists. FLAME formulates recommendation\nas a sequential decision process, where each step adds or removes a single\ndrug. To provide fine-grained learning signals, we devise step-wise Group\nRelative Policy Optimization (GRPO) with potential-based reward shaping, which\nexplicitly models DDIs and optimizes the contribution of each drug to the\noverall prescription. Furthermore, FLAME enhances patient modeling by\nintegrating structured clinical knowledge and collaborative information into\nthe representation space of LLMs. Experiments on benchmark datasets demonstrate\nthat FLAME achieves state-of-the-art performance, delivering superior accuracy,\ncontrollable safety-accuracy trade-offs, and strong generalization across\ndiverse clinical scenarios. Our code is available at\nhttps://github.com/cxfann/Flame.','Chenxiao Fan, Chongming Gao, Wentao Shi, Yaxin Gong, Zihao Zhao, Fuli Feng','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20218v1'),('2505.20219v1','New Perspectives on the Polyak Stepsize: Surrogate Functions and Negative Results','The Polyak stepsize has been proven to be a fundamental stepsize in convex\noptimization, giving near optimal gradient descent rates across a wide range of\nassumptions. The universality of the Polyak stepsize has also inspired many\nstochastic variants, with theoretical guarantees and strong empirical\nperformance. Despite the many theoretical results, our understanding of the\nconvergence properties and shortcomings of the Polyak stepsize or its variants\nis both incomplete and fractured across different analyses. We propose a new,\nunified, and simple perspective for the Polyak stepsize and its variants as\ngradient descent on a surrogate loss. We show that each variant is equivalent\nto minimize a surrogate function with stepsizes that adapt to a guaranteed\nlocal curvature. Our general surrogate loss perspective is then used to provide\na unified analysis of existing variants across different assumptions. Moreover,\nwe show a number of negative results proving that the non-convergence results\nin some of the upper bounds is indeed real.','Francesco Orabona, Ryan D\'Orazio','2025-05-26','math.OC','http://arxiv.org/pdf/2505.20219v1'),('2505.20221v1','Gradient Flow Matching for Learning Update Dynamics in Neural Network Training','Training deep neural networks remains computationally intensive due to the\nitera2 tive nature of gradient-based optimization. We propose Gradient Flow\nMatching (GFM), a continuous-time modeling framework that treats neural network\ntraining as a dynamical system governed by learned optimizer-aware vector\nfields. By leveraging conditional flow matching, GFM captures the underlying\nupdate rules of optimizers such as SGD, Adam, and RMSprop, enabling smooth\nextrapolation of weight trajectories toward convergence. Unlike black-box\nsequence models, GFM incorporates structural knowledge of gradient-based\nupdates into the learning objective, facilitating accurate forecasting of final\nweights from partial training sequences. Empirically, GFM achieves forecasting\naccuracy that is competitive with Transformer-based models and significantly\noutperforms LSTM and other classical baselines. Furthermore, GFM generalizes\nacross neural architectures and initializations, providing a unified framework\nfor studying optimization dynamics and accelerating convergence prediction.','Xiao Shou, Yanna Ding, Jianxi Gao','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20221v1'),('2505.20223v1','Chain-of-Thought for Autonomous Driving: A Comprehensive Survey and Future Prospects','The rapid evolution of large language models in natural language processing\nhas substantially elevated their semantic understanding and logical reasoning\ncapabilities. Such proficiencies have been leveraged in autonomous driving\nsystems, contributing to significant improvements in system performance. Models\nsuch as OpenAI o1 and DeepSeek-R1, leverage Chain-of-Thought (CoT) reasoning,\nan advanced cognitive method that simulates human thinking processes,\ndemonstrating remarkable reasoning capabilities in complex tasks. By\nstructuring complex driving scenarios within a systematic reasoning framework,\nthis approach has emerged as a prominent research focus in autonomous driving,\nsubstantially improving the system\\\'s ability to handle challenging cases. This\npaper investigates how CoT methods improve the reasoning abilities of\nautonomous driving models. Based on a comprehensive literature review, we\npresent a systematic analysis of the motivations, methodologies, challenges,\nand future research directions of CoT in autonomous driving. Furthermore, we\npropose the insight of combining CoT with self-learning to facilitate\nself-evolution in driving systems. To ensure the relevance and timeliness of\nthis study, we have compiled a dynamic repository of literature and open-source\nprojects, diligently updated to incorporate forefront developments. The\nrepository is publicly available at\nhttps://github.com/cuiyx1720/Awesome-CoT4AD.','Yixin Cui, Haotian Lin, Shuo Yang, Yixiao Wang, Yanjun Huang, Hong Chen','2025-05-26','cs.RO','http://arxiv.org/pdf/2505.20223v1'),('2505.20225v1','FLAME-MoE: A Transparent End-to-End Research Platform for Mixture-of-Experts Language Models','Recent large language models such as Gemini-1.5, DeepSeek-V3, and Llama-4\nincreasingly adopt Mixture-of-Experts (MoE) architectures, which offer strong\nefficiency-performance trade-offs by activating only a fraction of the model\nper token. Yet academic researchers still lack a fully open, end-to-end MoE\nplatform for investigating scaling, routing, and expert behavior. We release\nFLAME-MoE, a completely open-source research suite composed of seven\ndecoder-only models, ranging from 38M to 1.7B active parameters, whose\narchitecture--64 experts with top-8 gating and 2 shared experts--closely\nreflects modern production LLMs. All training data pipelines, scripts, logs,\nand checkpoints are publicly available to enable reproducible experimentation.\nAcross six evaluation tasks, FLAME-MoE improves average accuracy by up to 3.4\npoints over dense baselines trained with identical FLOPs. Leveraging full\ntraining trace transparency, we present initial analyses showing that (i)\nexperts increasingly specialize on distinct token subsets, (ii) co-activation\nmatrices remain sparse, reflecting diverse expert usage, and (iii) routing\nbehavior stabilizes early in training. All code, training logs, and model\ncheckpoints are available at https://github.com/cmu-flame/FLAME-MoE.','Hao Kang, Zichun Yu, Chenyan Xiong','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20225v1'),('2505.20229v1','From What to How: Attributing CLIP\\\'s Latent Components Reveals Unexpected Semantic Reliance','Transformer-based CLIP models are widely used for text-image probing and\nfeature extraction, making it relevant to understand the internal mechanisms\nbehind their predictions. While recent works show that Sparse Autoencoders\n(SAEs) yield interpretable latent components, they focus on what these encode\nand miss how they drive predictions. We introduce a scalable framework that\nreveals what latent components activate for, how they align with expected\nsemantics, and how important they are to predictions. To achieve this, we adapt\nattribution patching for instance-wise component attributions in CLIP and\nhighlight key faithfulness limitations of the widely used Logit Lens technique.\nBy combining attributions with semantic alignment scores, we can automatically\nuncover reliance on components that encode semantically unexpected or spurious\nconcepts. Applied across multiple CLIP variants, our method uncovers hundreds\nof surprising components linked to polysemous words, compound nouns, visual\ntypography and dataset artifacts. While text embeddings remain prone to\nsemantic ambiguity, they are more robust to spurious correlations compared to\nlinear classifiers trained on image embeddings. A case study on skin lesion\ndetection highlights how such classifiers can amplify hidden shortcuts,\nunderscoring the need for holistic, mechanistic interpretability. We provide\ncode at https://github.com/maxdreyer/attributing-clip.','Maximilian Dreyer, Lorenz Hufe, Jim Berend, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20229v1'),('2505.20231v1','Bridging the Long-Term Gap: A Memory-Active Policy for Multi-Session Task-Oriented Dialogue','Existing Task-Oriented Dialogue (TOD) systems primarily focus on\nsingle-session dialogues, limiting their effectiveness in long-term memory\naugmentation. To address this challenge, we introduce a MS-TOD dataset, the\nfirst multi-session TOD dataset designed to retain long-term memory across\nsessions, enabling fewer turns and more efficient task completion. This defines\na new benchmark task for evaluating long-term memory in multi-session TOD.\nBased on this new dataset, we propose a Memory-Active Policy (MAP) that\nimproves multi-session dialogue efficiency through a two-stage approach. 1)\nMemory-Guided Dialogue Planning retrieves intent-aligned history, identifies\nkey QA units via a memory judger, refines them by removing redundant questions,\nand generates responses based on the reconstructed memory. 2) Proactive\nResponse Strategy detects and correct errors or omissions, ensuring efficient\nand accurate task completion. We evaluate MAP on MS-TOD dataset, focusing on\nresponse quality and effectiveness of the proactive strategy. Experiments on\nMS-TOD demonstrate that MAP significantly improves task success and turn\nefficiency in multi-session scenarios, while maintaining competitive\nperformance on conventional single-session tasks.','Yiming Du, Bingbing Wang, Yang He, Bin Liang, Baojun Wang, Zhongyang Li, Lin Gui, Jeff Z. Pan, Ruifeng Xu, Kam-Fai Wong','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20231v1'),('2505.20232v1','Multimodal Federated Learning With Missing Modalities through Feature Imputation Network','Multimodal federated learning holds immense potential for collaboratively\ntraining models from multiple sources without sharing raw data, addressing both\ndata scarcity and privacy concerns, two key challenges in healthcare. A major\nchallenge in training multimodal federated models in healthcare is the presence\nof missing modalities due to multiple reasons, including variations in clinical\npractice, cost and accessibility constraints, retrospective data collection,\nprivacy concerns, and occasional technical or human errors. Previous methods\ntypically rely on publicly available real datasets or synthetic data to\ncompensate for missing modalities. However, obtaining real datasets for every\ndisease is impractical, and training generative models to synthesize missing\nmodalities is computationally expensive and prone to errors due to the high\ndimensionality of medical data. In this paper, we propose a novel, lightweight,\nlow-dimensional feature translator to reconstruct bottleneck features of the\nmissing modalities. Our experiments on three different datasets (MIMIC-CXR, NIH\nOpen-I, and CheXpert), in both homogeneous and heterogeneous settings\nconsistently improve the performance of competitive baselines. The code and\nimplementation details are available at:\nhttps://github.com/bhattarailab/FedFeatGen','Pranav Poudel, Aavash Chhetri, Prashnna Gyawali, Georgios Leontidis, Binod Bhattarai','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20232v1'),('2505.20235v1','Variational Deep Learning via Implicit Regularization','Modern deep learning models generalize remarkably well in-distribution,\ndespite being overparametrized and trained with little to no explicit\nregularization. Instead, current theory credits implicit regularization imposed\nby the choice of architecture, hyperparameters and optimization procedure.\nHowever, deploying deep learning models out-of-distribution, in sequential\ndecision-making tasks, or in safety-critical domains, necessitates reliable\nuncertainty quantification, not just a point estimate. The machinery of modern\napproximate inference -- Bayesian deep learning -- should answer the need for\nuncertainty quantification, but its effectiveness has been challenged by our\ninability to define useful explicit inductive biases through priors, as well as\nthe associated computational burden. Instead, in this work we demonstrate, both\ntheoretically and empirically, how to regularize a variational deep network\nimplicitly via the optimization procedure, just as for standard deep learning.\nWe fully characterize the inductive bias of (stochastic) gradient descent in\nthe case of an overparametrized linear model as generalized variational\ninference and demonstrate the importance of the choice of parametrization.\nFinally, we show empirically that our approach achieves strong in- and\nout-of-distribution performance without tuning of additional hyperparameters\nand with minimal time and memory overhead over standard deep learning.','Jonathan Wenger, Beau Coker, Juraj Marusic, John P. Cunningham','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20235v1'),('2505.20237v1','Efficient Speech Translation through Model Compression and Knowledge Distillation','Efficient deployment of large audio-language models for speech translation\nremains challenging due to their significant computational requirements. In\nthis paper, we address this challenge through our system submissions to the\n\"Model Compression\" track at the International Conference on Spoken Language\nTranslation (IWSLT 2025). We experiment with a combination of approaches\nincluding iterative layer pruning based on layer importance evaluation,\nlow-rank adaptation with 4-bit quantization (QLoRA), and knowledge\ndistillation. In our experiments, we use Qwen2-Audio-7B-Instruct for speech\ntranslation into German and Chinese. Our pruned (student) models achieve up to\na 50% reduction in both model parameters and storage footprint, while retaining\n97-100% of the translation quality of the in-domain (teacher) models.','Yasmin Moslem','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20237v1'),('2505.20241v1','DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning','Reasoning has substantially improved the performance of large language models\n(LLMs) on complicated tasks. Central to the current reasoning studies, Process\nReward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning\nsteps and guide the reasoning process. However, extending PRMs to multimodal\nlarge language models (MLLMs) introduces challenges. Since multimodal reasoning\ncovers a wider range of tasks compared to text-only scenarios, the resulting\ndistribution shift from the training to testing sets is more severe, leading to\ngreater generalization difficulty. Training a reliable multimodal PRM,\ntherefore, demands large and diverse datasets to ensure sufficient coverage.\nHowever, current multimodal reasoning datasets suffer from a marked quality\nimbalance, which degrades PRM performance and highlights the need for an\neffective data selection strategy. To address the issues, we introduce\nDreamPRM, a domain-reweighted training framework for multimodal PRMs which\nemploys bi-level optimization. In the lower-level optimization, DreamPRM\nperforms fine-tuning on multiple datasets with domain weights, allowing the PRM\nto prioritize high-quality reasoning signals and alleviating the impact of\ndataset quality imbalance. In the upper-level optimization, the PRM is\nevaluated on a separate meta-learning dataset; this feedback updates the domain\nweights through an aggregation loss function, thereby improving the\ngeneralization capability of trained PRM. Extensive experiments on multiple\nmultimodal reasoning benchmarks covering both mathematical and general\nreasoning show that test-time scaling with DreamPRM consistently improves the\nperformance of state-of-the-art MLLMs. Further comparisons reveal that\nDreamPRM\\\'s domain-reweighting strategy surpasses other data selection methods\nand yields higher accuracy gains than existing test-time scaling approaches.','Qi Cao, Ruiyi Wang, Ruiyi Zhang, Sai Ashish Somayajula, Pengtao Xie','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20241v1'),('2505.20242v1','RedAHD: Reduction-Based End-to-End Automatic Heuristic Design with Large Language Models','Solving NP-hard combinatorial optimization problems (COPs) (e.g., traveling\nsalesman problems (TSPs) and capacitated vehicle routing problems (CVRPs)) in\npractice traditionally involves handcrafting heuristics or specifying a search\nspace for finding effective heuristics. The main challenges from these\napproaches, however, are the sheer amount of domain knowledge and\nimplementation efforts required from human experts. Recently, significant\nprogress has been made to address these challenges, particularly by using large\nlanguage models (LLMs) to design heuristics within some predetermined\ngeneralized algorithmic framework (GAF, e.g., ant colony optimization and\nguided local search) for building key functions/components (e.g., a priori\ninformation on how promising it is to include each edge in a solution for TSP\nand CVRP). Although existing methods leveraging this idea have shown to yield\nimpressive optimization performance, they are not fully end-to-end and still\nrequire considerable manual interventions. In this paper, we propose a novel\nend-to-end framework, named RedAHD, that enables these LLM-based heuristic\ndesign methods to operate without the need of GAFs. More specifically, RedAHD\nemploys LLMs to automate the process of reduction, i.e., transforming the COP\nat hand into similar COPs that are better-understood, from which LLM-based\nheuristic design methods can design effective heuristics for directly solving\nthe transformed COPs and, in turn, indirectly solving the original COP. Our\nexperimental results, evaluated on six COPs, show that RedAHD is capable of\ndesigning heuristics with competitive or improved results over the\nstate-of-the-art methods with minimal human involvement.','Nguyen Thach, Aida Riahifar, Nathan Huynh, Hau Chan','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20242v1'),('2505.20243v1','It\\\'s High Time: A Survey of Temporal Information Retrieval and Question Answering','Time plays a critical role in how information is generated, retrieved, and\ninterpreted. In this survey, we provide a comprehensive overview of Temporal\nInformation Retrieval and Temporal Question Answering, two research areas aimed\nat handling and understanding time-sensitive information. As the amount of\ntime-stamped content from sources like news articles, web archives, and\nknowledge bases increases, systems must address challenges such as detecting\ntemporal intent, normalizing time expressions, ordering events, and reasoning\nover evolving or ambiguous facts. These challenges are critical across many\ndynamic and time-sensitive domains, from news and encyclopedias to science,\nhistory, and social media. We review both traditional approaches and modern\nneural methods, including those that use transformer models and Large Language\nModels (LLMs). We also review recent advances in temporal language modeling,\nmulti-hop reasoning, and retrieval-augmented generation (RAG), alongside\nbenchmark datasets and evaluation strategies that test temporal robustness,\nrecency awareness, and generalization.','Bhawna Piryani, Abdelrahman Abdullah, Jamshid Mozafari, Avishek Anand, Adam Jatowt','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20243v1'),('2505.20245v1','KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing','Recent advances in retrieval-augmented generation (RAG) furnish large\nlanguage models (LLMs) with iterative retrievals of relevant information to\nhandle complex multi-hop questions. These methods typically alternate between\nLLM reasoning and retrieval to accumulate external information into the LLM\\\'s\ncontext. However, the ever-growing context inherently imposes an increasing\nburden on the LLM to perceive connections among critical information pieces,\nwith futile reasoning steps further exacerbating this overload issue. In this\npaper, we present KnowTrace, an elegant RAG framework to (1) mitigate the\ncontext overload and (2) bootstrap higher-quality multi-step reasoning. Instead\nof simply piling the retrieved contents, KnowTrace autonomously traces out\ndesired knowledge triplets to organize a specific knowledge graph relevant to\nthe input question. Such a structured workflow not only empowers the LLM with\nan intelligible context for inference, but also naturally inspires a reflective\nmechanism of knowledge backtracing to identify contributive LLM generations as\nprocess supervision data for self-bootstrapping. Extensive experiments show\nthat KnowTrace consistently surpasses existing methods across three multi-hop\nquestion answering benchmarks, and the bootstrapped version further amplifies\nthe gains.','Rui Li, Quanyu Dai, Zeyu Zhang, Xu Chen, Zhenhua Dong, Ji-Rong Wen','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20245v1'),('2505.20246v1','On Path to Multimodal Historical Reasoning: HistBench and HistAgent','Recent advances in large language models (LLMs) have led to remarkable\nprogress across domains, yet their capabilities in the humanities, particularly\nhistory, remain underexplored. Historical reasoning poses unique challenges for\nAI, involving multimodal source interpretation, temporal inference, and\ncross-linguistic analysis. While general-purpose agents perform well on many\nexisting benchmarks, they lack the domain-specific expertise required to engage\nwith historical materials and questions. To address this gap, we introduce\nHistBench, a new benchmark of 414 high-quality questions designed to evaluate\nAI\\\'s capacity for historical reasoning and authored by more than 40 expert\ncontributors. The tasks span a wide range of historical problems-from factual\nretrieval based on primary sources to interpretive analysis of manuscripts and\nimages, to interdisciplinary challenges involving archaeology, linguistics, or\ncultural history. Furthermore, the benchmark dataset spans 29 ancient and\nmodern languages and covers a wide range of historical periods and world\nregions. Finding the poor performance of LLMs and other agents on HistBench, we\nfurther present HistAgent, a history-specific agent equipped with carefully\ndesigned tools for OCR, translation, archival search, and image understanding\nin History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of\n27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online\nsearch and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%)\nand Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These\nresults highlight the limitations of existing LLMs and generalist agents and\ndemonstrate the advantages of HistAgent for historical reasoning.','Jiahao Qiu, Fulian Xiao, Yimin Wang, Yuchen Mao, Yijia Chen, Xinzhe Juan, Siran Wang, Xuan Qi, Tongcheng Zhang, Zixin Yao, Jiacheng Guo, Yifu Lu, Charles Argon, Jundi Cui, Daixin Chen, Junran Zhou, Shuyao Zhou, Zhanpeng Zhou, Ling Yang, Shilong Liu, Hongru Wang, Kaixuan Huang, Xun Jiang, Yuming Cao, Yue Chen, Yunfei Chen, Zhengyi Chen, Ruowei Dai, Mengqiu Deng, Jiye Fu, Yunting Gu, Zijie Guan, Zirui Huang, Xiaoyan Ji, Yumeng Jiang, Delong Kong, Haolong Li, Jiaqi Li, Ruipeng Li, Tianze Li, Zhuoran Li, Haixia Lian, Mengyue Lin, Xudong Liu, Jiayi Lu, Jinghan Lu, Wanyu Luo, Ziyue Luo, Zihao Pu, Zhi Qiao, Ruihuan Ren, Liang Wan, Ruixiang Wang, Tianhui Wang, Yang Wang, Zeyu Wang, Zihua Wang, Yujia Wu, Zhaoyi Wu, Hao Xin, Weiao Xing, Ruojun Xiong, Weijie Xu, Yao Shu, Xiao Yao, Xiaorui Yang, Yuchen Yang, Nan Yi, Jiadong Yu, Yangyuxuan Yu, Huiting Zeng, Danni Zhang, Yunjie Zhang, Zhaoyu Zhang, Zhiheng Zhang, Xiaofeng Zheng, Peirong Zhou, Linyan Zhong, Xiaoyin Zong, Ying Zhao, Zhenxin Chen, Lin Ding, Xiaoyu Gao, Bingbing Gong, Yichao Li, Yang Liao, Guang Ma, Tianyuan Ma, Xinrui Sun, Tianyi Wang, Han Xia, Ruobing Xian, Gen Ye, Tengfei Yu, Wentao Zhang, Yuxi Wang, Xi Gao, Mengdi Wang','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20246v1'),('2505.20249v1','WXImpactBench: A Disruptive Weather Impact Understanding Benchmark for Evaluating Large Language Models','Climate change adaptation requires the understanding of disruptive weather\nimpacts on society, where large language models (LLMs) might be applicable.\nHowever, their effectiveness is under-explored due to the difficulty of\nhigh-quality corpus collection and the lack of available benchmarks. The\nclimate-related events stored in regional newspapers record how communities\nadapted and recovered from disasters. However, the processing of the original\ncorpus is non-trivial. In this study, we first develop a disruptive weather\nimpact dataset with a four-stage well-crafted construction pipeline. Then, we\npropose WXImpactBench, the first benchmark for evaluating the capacity of LLMs\non disruptive weather impacts. The benchmark involves two evaluation tasks,\nmulti-label classification and ranking-based question answering. Extensive\nexperiments on evaluating a set of LLMs provide first-hand analysis of the\nchallenges in developing disruptive weather impact understanding and climate\nchange adaptation systems. The constructed dataset and the code for the\nevaluation framework are available to help society protect against\nvulnerabilities from disasters.','Yongan Yu, Qingchen Hu, Xianda Du, Jiayin Wang, Fengran Mo, Renee Sieber','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20249v1'),('2505.20250v1','Efficient Optimization Accelerator Framework for Multistate Ising Problems','Ising Machines are a prominent class of hardware architectures that aim to\nsolve NP-hard combinatorial optimization problems. These machines consist of a\nnetwork of interacting binary spins/neurons that evolve to represent the\noptimum ground state energy solution. Generally, combinatorial problems are\ntransformed into quadratic unconstrained binary optimization (QUBO) form to\nharness the computational efficiency of these Ising machines. However, this\ntransformation, especially for multi-state problems, often leads to a more\ncomplex exploration landscape than the original problem, thus severely\nimpacting the solution quality. To address this challenge, we model the spin\ninteractions as a generalized boolean logic function to significantly reduce\nthe exploration space. We benchmark the graph coloring problem from the class\nof multi-state NP-hard optimization using probabilistic Ising solvers to\nillustrate the effectiveness of our framework. The proposed methodology\nachieves similar accuracy compared to state-of-the-art heuristics and machine\nlearning algorithms, and demonstrates significant improvement over the existing\nIsing methods. Additionally, we demonstrate that combining parallel tempering\nwith our existing framework further reduces the coloring error by up to 50%\ncompared to the conventionally used Gibbs sampling algorithm. We also design a\n1024-neuron all-to-all connected probabilistic Ising accelerator that shows up\nto 10000x performance acceleration compared to heuristics while reducing the\nnumber of required physical neurons by 1.5-4x compared to conventional Ising\nmachines. Indeed, this accelerator solution demonstrates improvement across all\nmetrics over the current methods, i.e., energy, performance, area, and solution\nquality. Thus, this work expands the potential of existing Ising hardware to\nsolve a broad class of these multistate optimization problems.','Chirag Garg, Sayeef Salahuddin','2025-05-26','cs.AR','http://arxiv.org/pdf/2505.20250v1'),('2505.20251v1','Learning Extrapolative Sequence Transformations from Markov Chains','Most successful applications of deep learning involve similar training and\ntest conditions. However, tasks such as biological sequence design involve\nsearching for sequences that improve desirable properties beyond previously\nknown values, which requires novel hypotheses that \\emph{extrapolate} beyond\ntraining data. In these settings, extrapolation may be achieved by using random\nsearch methods such as Markov chain Monte Carlo (MCMC), which, given an initial\nstate, sample local transformations to approximate a target density that\nrewards states with the desired properties. However, even with a well-designed\nproposal, MCMC may struggle to explore large structured state spaces\nefficiently. Rather than relying on stochastic search, it would be desirable to\nhave a model that greedily optimizes the properties of interest, successfully\nextrapolating in as few steps as possible. We propose to learn such a model\nfrom the Markov chains resulting from MCMC search. Specifically, our approach\nuses selected states from Markov chains as a source of training data for an\nautoregressive model, which is then able to efficiently generate novel\nsequences that extrapolate along the sequence-level properties of interest. The\nproposed approach is validated on three problems: protein sequence design, text\nsentiment control, and text anonymization. We find that the autoregressive\nmodel can extrapolate as well or better than MCMC, but with the additional\nbenefits of scalability and significantly higher sample efficiency.','Sophia Hager, Aleem Khan, Andrew Wang, Nicholas Andrews','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20251v1'),('2505.20254v1','Position: Mechanistic Interpretability Should Prioritize Feature Consistency in SAEs','Sparse Autoencoders (SAEs) are a prominent tool in mechanistic\ninterpretability (MI) for decomposing neural network activations into\ninterpretable features. However, the aspiration to identify a canonical set of\nfeatures is challenged by the observed inconsistency of learned SAE features\nacross different training runs, undermining the reliability and efficiency of\nMI research. This position paper argues that mechanistic interpretability\nshould prioritize feature consistency in SAEs -- the reliable convergence to\nequivalent feature sets across independent runs. We propose using the Pairwise\nDictionary Mean Correlation Coefficient (PW-MCC) as a practical metric to\noperationalize consistency and demonstrate that high levels are achievable\n(0.80 for TopK SAEs on LLM activations) with appropriate architectural choices.\nOur contributions include detailing the benefits of prioritizing consistency;\nproviding theoretical grounding and synthetic validation using a model\norganism, which verifies PW-MCC as a reliable proxy for ground-truth recovery;\nand extending these findings to real-world LLM data, where high feature\nconsistency strongly correlates with the semantic similarity of learned feature\nexplanations. We call for a community-wide shift towards systematically\nmeasuring feature consistency to foster robust cumulative progress in MI.','Xiangchen Song, Aashiq Muhamed, Yujia Zheng, Lingjing Kong, Zeyu Tang, Mona T. Diab, Virginia Smith, Kun Zhang','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20254v1'),('2505.20258v1','ARM: Adaptive Reasoning Model','While large reasoning models demonstrate strong performance on complex tasks,\nthey lack the ability to adjust reasoning token usage based on task difficulty.\nThis often leads to the \"overthinking\" problem -- excessive and unnecessary\nreasoning -- which, although potentially mitigated by human intervention to\ncontrol the token budget, still fundamentally contradicts the goal of achieving\nfully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a\nreasoning model capable of adaptively selecting appropriate reasoning formats\nbased on the task at hand. These formats include three efficient ones -- Direct\nAnswer, Short CoT, and Code -- as well as a more elaborate format, Long CoT. To\ntrain ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy\nOptimization (GRPO), which addresses the format collapse issue in traditional\nGRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by\nan average of 30%, and up to 70%, while maintaining performance comparable to\nthe model that relies solely on Long CoT. Furthermore, not only does it improve\ninference efficiency through reduced token generation, but it also brings a 2x\nspeedup in training. In addition to the default Adaptive Mode, ARM supports two\nadditional reasoning modes: 1) Instruction-Guided Mode, which allows users to\nexplicitly specify the reasoning format via special tokens -- ideal when the\nappropriate format is known for a batch of tasks. 2) Consensus-Guided Mode,\nwhich aggregates the outputs of the three efficient formats and resorts to Long\nCoT in case of disagreement, prioritizing performance with higher token usage.','Siye Wu, Jian Xie, Yikai Zhang, Aili Chen, Kai Zhang, Yu Su, Yanghua Xiao','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20258v1'),('2505.20259v1','Lifelong Safety Alignment for Language Models','LLMs have made impressive progress, but their growing capabilities also\nexpose them to highly flexible jailbreaking attacks designed to bypass safety\nalignment. While many existing defenses focus on known types of attacks, it is\nmore critical to prepare LLMs for unseen attacks that may arise during\ndeployment. To address this, we propose a lifelong safety alignment framework\nthat enables LLMs to continuously adapt to new and evolving jailbreaking\nstrategies. Our framework introduces a competitive setup between two\ncomponents: a Meta-Attacker, trained to actively discover novel jailbreaking\nstrategies, and a Defender, trained to resist them. To effectively warm up the\nMeta-Attacker, we first leverage the GPT-4o API to extract key insights from a\nlarge collection of jailbreak-related research papers. Through iterative\ntraining, the first iteration Meta-Attacker achieves a 73% attack success rate\n(ASR) on RR and a 57% transfer ASR on LAT using only single-turn attacks.\nMeanwhile, the Defender progressively improves its robustness and ultimately\nreduces the Meta-Attacker\\\'s success rate to just 7%, enabling safer and more\nreliable deployment of LLMs in open-ended environments. The code is available\nat https://github.com/sail-sg/LifelongSafetyAlignment.','Haoyu Wang, Zeyu Qin, Yifei Zhao, Chao Du, Min Lin, Xueqian Wang, Tianyu Pang','2025-05-26','cs.CR','http://arxiv.org/pdf/2505.20259v1'),('2505.20264v1','We Need to Measure Data Diversity in NLP -- Better and Broader','Although diversity in NLP datasets has received growing attention, the\nquestion of how to measure it remains largely underexplored. This opinion paper\nexamines the conceptual and methodological challenges of measuring data\ndiversity and argues that interdisciplinary perspectives are essential for\ndeveloping more fine-grained and valid measures.','Dong Nguyen, Esther Ploeger','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20264v1'),('2505.20266v1','syftr: Pareto-Optimal Generative AI','Retrieval-Augmented Generation (RAG) pipelines are central to applying large\nlanguage models (LLMs) to proprietary or dynamic data. However, building\neffective RAG flows is complex, requiring careful selection among vector\ndatabases, embedding models, text splitters, retrievers, and synthesizing LLMs.\nThe challenge deepens with the rise of agentic paradigms. Modules like\nverifiers, rewriters, and rerankers-each with intricate hyperparameter\ndependencies have to be carefully tuned. Balancing tradeoffs between latency,\naccuracy, and cost becomes increasingly difficult in performance-sensitive\napplications.\n  We introduce syftr, a framework that performs efficient multi-objective\nsearch over a broad space of agentic and non-agentic RAG configurations. Using\nBayesian Optimization, syftr discovers Pareto-optimal flows that jointly\noptimize task accuracy and cost. A novel early-stopping mechanism further\nimproves efficiency by pruning clearly suboptimal candidates. Across multiple\nRAG benchmarks, syftr finds flows which are on average approximately 9 times\ncheaper while preserving most of the accuracy of the most accurate flows on the\nPareto-frontier. Furthermore, syftr\\\'s ability to design and optimize allows\nintegrating new modules, making it even easier and faster to realize\nhigh-performing generative AI pipelines.','Alexander Conway, Debadeepta Dey, Stefan Hackmann, Matthew Hausknecht, Michael Schmidt, Mark Steadman, Nick Volynets','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20266v1'),('2505.20268v1','Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits','Reinforcement learning with outcome-based feedback faces a fundamental\nchallenge: when rewards are only observed at trajectory endpoints, how do we\nassign credit to the right actions? This paper provides the first comprehensive\nanalysis of this problem in online RL with general function approximation. We\ndevelop a provably sample-efficient algorithm achieving $\\widetilde{O}({C_{\\rm\ncov} H^3}/{\\epsilon^2})$ sample complexity, where $C_{\\rm cov}$ is the\ncoverability coefficient of the underlying MDP. By leveraging general function\napproximation, our approach works effectively in large or infinite state spaces\nwhere tabular methods fail, requiring only that value functions and reward\nfunctions can be represented by appropriate function classes. Our results also\ncharacterize when outcome-based feedback is statistically separated from\nper-step rewards, revealing an unavoidable exponential separation for certain\nMDPs. For deterministic MDPs, we show how to eliminate the completeness\nassumption, dramatically simplifying the algorithm. We further extend our\napproach to preference-based feedback settings, proving that equivalent\nstatistical efficiency can be achieved even under more limited information.\nTogether, these results constitute a theoretical foundation for understanding\nthe statistical properties of outcome-based reinforcement learning.','Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20268v1'),('2505.20269v1','Comparing Neural Network Encodings for Logic-based Explainability','Providing explanations for the outputs of artificial neural networks (ANNs)\nis crucial in many contexts, such as critical systems, data protection laws and\nhandling adversarial examples. Logic-based methods can offer explanations with\ncorrectness guarantees, but face scalability challenges. Due to these issues,\nit is necessary to compare different encodings of ANNs into logical\nconstraints, which are used in logic-based explainability. This work compares\ntwo encodings of ANNs: one has been used in the literature to provide\nexplanations, while the other will be adapted for our context of\nexplainability. Additionally, the second encoding uses fewer variables and\nconstraints, thus, potentially enhancing efficiency. Experiments showed similar\nrunning times for computing explanations, but the adapted encoding performed up\nto 18\\% better in building logical constraints and up to 16\\% better in overall\ntime.','Levi Cordeiro Carvalho, Saulo A. F. Oliveira, Thiago Alves Rocha','2025-05-26','cs.LO','http://arxiv.org/pdf/2505.20269v1'),('2505.20271v1','In-Context Brush: Zero-shot Customized Subject Insertion with Context-Aware Latent Space Manipulation','Recent advances in diffusion models have enhanced multimodal-guided visual\ngeneration, enabling customized subject insertion that seamlessly \"brushes\"\nuser-specified objects into a given image guided by textual prompts. However,\nexisting methods often struggle to insert customized subjects with high\nfidelity and align results with the user\\\'s intent through textual prompts. In\nthis work, we propose \"In-Context Brush\", a zero-shot framework for customized\nsubject insertion by reformulating the task within the paradigm of in-context\nlearning. Without loss of generality, we formulate the object image and the\ntextual prompts as cross-modal demonstrations, and the target image with the\nmasked region as the query. The goal is to inpaint the target image with the\nsubject aligning textual prompts without model tuning. Building upon a\npretrained MMDiT-based inpainting network, we perform test-time enhancement via\ndual-level latent space manipulation: intra-head \"latent feature shifting\"\nwithin each attention head that dynamically shifts attention outputs to reflect\nthe desired subject semantics and inter-head \"attention reweighting\" across\ndifferent heads that amplifies prompt controllability through differential\nattention prioritization. Extensive experiments and applications demonstrate\nthat our approach achieves superior identity preservation, text alignment, and\nimage quality compared to existing state-of-the-art methods, without requiring\ndedicated training or additional data collection.','Yu Xu, Fan Tang, You Wu, Lin Gao, Oliver Deussen, Hongbin Yan, Jintao Li, Juan Cao, Tong-Yee Lee','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20271v1'),('2505.20273v1','Ten Principles of AI Agent Economics','The rapid rise of AI-based autonomous agents is transforming human society\nand economic systems, as these entities increasingly exhibit human-like or\nsuperhuman intelligence. From excelling at complex games like Go to tackling\ndiverse general-purpose tasks with large language and multimodal models, AI\nagents are evolving from specialized tools into dynamic participants in social\nand economic ecosystems. Their autonomy and decision-making capabilities are\npoised to impact industries, professions, and human lives profoundly, raising\ncritical questions about their integration into economic activities, potential\nethical concerns, and the balance between their utility and safety.\n  To address these challenges, this paper presents ten principles of AI agent\neconomics, offering a framework to understand how AI agents make decisions,\ninfluence social interactions, and participate in the broader economy. Drawing\non economics, decision theory, and ethics, we explore fundamental questions,\nsuch as whether AI agents might evolve from tools into independent entities,\ntheir impact on labor markets, and the ethical safeguards needed to align them\nwith human values. These principles build on existing economic theories while\naccounting for the unique traits of AI agents, providing a roadmap for their\nresponsible integration into human systems.\n  Beyond theoretical insights, this paper highlights the urgency of future\nresearch into AI trustworthiness, ethical guidelines, and regulatory oversight.\nAs we enter a transformative era, this work serves as both a guide and a call\nto action, ensuring AI agents contribute positively to human progress while\naddressing risks tied to their unprecedented capabilities.','Ke Yang, ChengXiang Zhai','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20273v1'),('2505.20274v1','Probabilistic Kernel Function for Fast Angle Testing','In this paper, we study the angle testing problem in high-dimensional\nEuclidean spaces and propose two projection-based probabilistic kernel\nfunctions, one designed for angle comparison and the other for angle\nthresholding. Unlike existing approaches that rely on random projection vectors\ndrawn from Gaussian distributions, our approach leverages reference angles and\nemploys a deterministic structure for the projection vectors. Notably, our\nkernel functions do not require asymptotic assumptions, such as the number of\nprojection vectors tending to infinity, and can be both theoretically and\nexperimentally shown to outperform Gaussian-distribution-based kernel\nfunctions. We further apply the proposed kernel function to Approximate Nearest\nNeighbor Search (ANNS) and demonstrate that our approach achieves a 2.5X ~ 3X\nhigher query-per-second (QPS) throughput compared to the state-of-the-art\ngraph-based search algorithm HNSW.','Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20274v1'),('2505.20276v2','Does quantization affect models\\\' performance on long-context tasks?','Large language models (LLMs) now support context windows exceeding 128K\ntokens, but this comes with significant memory requirements and high inference\nlatency. Quantization can mitigate these costs, but may degrade performance. In\nthis work, we present the first systematic evaluation of quantized LLMs on\ntasks with long-inputs (>64K tokens) and long-form outputs. Our evaluation\nspans 9.7K test examples, five quantization methods (FP8, GPTQ-int8, AWQ-int4,\nGPTQ-int4, BNB-nf4), and five models (Llama-3.1 8B and 70B; Qwen-2.5 7B, 32B,\nand 72B). We find that, on average, 8-bit quantization preserves accuracy\n(~0.8% drop), whereas 4-bit methods lead to substantial losses, especially for\ntasks involving long context inputs (drops of up to 59%). This degradation\ntends to worsen when the input is in a language other than English. Crucially,\nthe effects of quantization depend heavily on the quantization method, model,\nand task. For instance, while Qwen-2.5 72B remains robust under BNB-nf4,\nLlama-3.1 70B experiences a 32% performance drop on the same task. These\nfindings highlight the importance of a careful, task-specific evaluation before\ndeploying quantized LLMs, particularly in long-context scenarios and with\nlanguages other than English.','Anmol Mekala, Anirudh Atmakuru, Yixiao Song, Marzena Karpinska, Mohit Iyyer','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20276v2'),('2505.20277v1','OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction','Role-Playing Agents (RPAs), benefiting from large language models, is an\nemerging interactive AI system that simulates roles or characters with diverse\npersonalities. However, existing methods primarily focus on mimicking dialogues\namong roles in textual form, neglecting the role\\\'s voice traits (e.g., voice\nstyle and emotions) as playing a crucial effect in interaction, which tends to\nbe more immersive experiences in realistic scenarios. Towards this goal, we\npropose OmniCharacter, a first seamless speech-language personality interaction\nmodel to achieve immersive RPAs with low latency. Specifically, OmniCharacter\nenables agents to consistently exhibit role-specific personality traits and\nvocal traits throughout the interaction, enabling a mixture of speech and\nlanguage responses. To align the model with speech-language scenarios, we\nconstruct a dataset named OmniCharacter-10K, which involves more distinctive\ncharacters (20), richly contextualized multi-round dialogue (10K), and dynamic\nspeech response (135K). Experimental results showcase that our method yields\nbetter responses in terms of both content and style compared to existing RPAs\nand mainstream speech-language models, with a response latency as low as 289ms.\nCode and dataset are available at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/OmniCharacter.','Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, Qiang Qu, Feiteng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20277v1'),('2505.20278v1','The Coverage Principle: A Framework for Understanding Compositional Generalization','Large language models excel at pattern matching, yet often fall short in\nsystematic compositional generalization. We propose the coverage principle: a\ndata-centric framework showing that models relying primarily on pattern\nmatching for compositional tasks cannot reliably generalize beyond substituting\nfragments that yield identical results when used in the same contexts. We\ndemonstrate that this framework has a strong predictive power for the\ngeneralization capabilities of Transformers. First, we derive and empirically\nconfirm that the training data required for two-hop generalization grows at\nleast quadratically with the token set size, and the training data efficiency\ndoes not improve with 20x parameter scaling. Second, for compositional tasks\nwith path ambiguity where one variable affects the output through multiple\ncomputational paths, we show that Transformers learn context-dependent state\nrepresentations that undermine both performance and interoperability. Third,\nChain-of-Thought supervision improves training data efficiency for multi-hop\ntasks but still struggles with path ambiguity. Finally, we outline a\n\\emph{mechanism-based} taxonomy that distinguishes three ways neural networks\ncan generalize: structure-based (bounded by coverage), property-based\n(leveraging algebraic invariances), and shared-operator (through function\nreuse). This conceptual lens contextualizes our results and highlights where\nnew architectural ideas are needed to achieve systematic compositionally.\nOverall, the coverage principle provides a unified lens for understanding\ncompositional reasoning, and underscores the need for fundamental architectural\nor training innovations to achieve truly systematic compositionality.','Hoyeon Chang, Jinho Park, Hanseul Cho, Sohee Yang, Miyoung Ko, Hyeonbin Hwang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20278v1'),('2505.20279v1','VLM-3R: Vision-Language Models Augmented with Instruction-Aligned 3D Reconstruction','The rapid advancement of Large Multimodal Models (LMMs) for 2D images and\nvideos has motivated extending these models to understand 3D scenes, aiming for\nhuman-like visual-spatial intelligence. Nevertheless, achieving deep spatial\nunderstanding comparable to human capabilities poses significant challenges in\nmodel encoding and data acquisition. Existing methods frequently depend on\nexternal depth sensors for geometry capture or utilize off-the-shelf algorithms\nfor pre-constructing 3D maps, thereby limiting their scalability, especially\nwith prevalent monocular video inputs and for time-sensitive applications. In\nthis work, we introduce VLM-3R, a unified framework for Vision-Language Models\n(VLMs) that incorporates 3D Reconstructive instruction tuning. VLM-3R processes\nmonocular video frames by employing a geometry encoder to derive implicit 3D\ntokens that represent spatial understanding. Leveraging our Spatial-Visual-View\nFusion and over 200K curated 3D reconstructive instruction tuning\nquestion-answer (QA) pairs, VLM-3R effectively aligns real-world spatial\ncontext with language instructions. This enables monocular 3D spatial\nassistance and embodied reasoning. To facilitate the evaluation of temporal\nreasoning, we introduce the Vision-Spatial-Temporal Intelligence benchmark,\nfeaturing over 138.6K QA pairs across five distinct tasks focused on evolving\nspatial relationships. Extensive experiments demonstrate that our model,\nVLM-3R, not only facilitates robust visual-spatial reasoning but also enables\nthe understanding of temporal 3D context changes, excelling in both accuracy\nand scalability.','Zhiwen Fan, Jian Zhang, Renjie Li, Junge Zhang, Runjin Chen, Hezhen Hu, Kevin Wang, Huaizhi Qu, Dilin Wang, Zhicheng Yan, Hongyu Xu, Justin Theiss, Tianlong Chen, Jiachen Li, Zhengzhong Tu, Zhangyang Wang, Rakesh Ranjan','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20279v1'),('2505.20280v1','Lorentz Local Canonicalization: How to Make Any Network Lorentz-Equivariant','Lorentz-equivariant neural networks are becoming the leading architectures\nfor high-energy physics. Current implementations rely on specialized layers,\nlimiting architectural choices. We introduce Lorentz Local Canonicalization\n(LLoCa), a general framework that renders any backbone network exactly\nLorentz-equivariant. Using equivariantly predicted local reference frames, we\nconstruct LLoCa-transformers and graph networks. We adapt a recent approach to\ngeometric message passing to the non-compact Lorentz group, allowing\npropagation of space-time tensorial features. Data augmentation emerges from\nLLoCa as a special choice of reference frame. Our models surpass\nstate-of-the-art accuracy on relevant particle physics tasks, while being\n$4\\times$ faster and using $5$-$100\\times$ fewer FLOPs.','Jonas Spinner, Luigi Favaro, Peter Lippmann, Sebastian Pitz, Gerrit Gerhartz, Tilman Plehn, Fred A. Hamprecht','2025-05-26','stat.ML','http://arxiv.org/pdf/2505.20280v1'),('2505.20282v2','One-shot Entropy Minimization','We trained 13,440 large language models and found that entropy minimization\nrequires only a single unlabeled data and 10 steps optimization to achieve\nperformance improvements comparable to or even greater than those obtained\nusing thousands of data and carefully designed rewards in rule-based\nreinforcement learning. This striking result may prompt a rethinking of\npost-training paradigms for large language models. Our code is avaliable at\nhttps://github.com/zitian-gao/one-shot-em.','Zitian Gao, Lynx Chen, Joey Zhou, Bryan Dai','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20282v2'),('2505.20285v2','MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability','Retrieval-Augmented Language Models (RALMs) represent a classic paradigm\nwhere models enhance generative capabilities using external knowledge retrieved\nvia a specialized module. Recent advancements in Agent techniques enable Large\nLanguage Models (LLMs) to autonomously utilize tools for retrieval, planning,\nand reasoning. While existing training-based methods show promise, their\nagentic abilities are limited by inherent characteristics of the task-specific\ndata used during training. To further enhance the universal search capability\nof agents, we propose a novel pre-training framework, MaskSearch. In the\npre-training stage, we introduce the Retrieval Augmented Mask Prediction (RAMP)\ntask, where the model learns to leverage search tools to fill masked spans on a\nlarge number of pre-training data, thus acquiring universal retrieval and\nreasoning capabilities for LLMs. After that, the model is trained on downstream\ntasks to achieve further improvement. We apply both Supervised Fine-tuning\n(SFT) and Reinforcement Learning (RL) for training. For SFT, we combine\nagent-based and distillation-based methods to generate training data, starting\nwith a multi-agent system consisting of a planner, rewriter, observer, and\nfollowed by a self-evolving teacher model. While for RL, we employ DAPO as the\ntraining framework and adopt a hybrid reward system consisting of answer\nrewards and format rewards. Additionally, we introduce a curriculum learning\napproach that allows the model to learn progressively from easier to more\nchallenging instances based on the number of masked spans. We evaluate the\neffectiveness of our framework in the scenario of open-domain multi-hop\nquestion answering. Through extensive experiments, we demonstrate that\nMaskSearch significantly enhances the performance of LLM-based search agents on\nboth in-domain and out-of-domain downstream tasks.','Weiqi Wu, Xin Guan, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Jiuxin Cao, Hai Zhao, Jingren Zhou','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20285v2'),('2505.20286v1','Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution','Recent advances in large language models (LLMs) have enabled agents to\nautonomously perform complex, open-ended tasks. However, many existing\nframeworks depend heavily on manually predefined tools and workflows, which\nhinder their adaptability, scalability, and generalization across domains. In\nthis work, we introduce Alita--a generalist agent designed with the principle\nof \"Simplicity is the ultimate sophistication,\" enabling scalable agentic\nreasoning through minimal predefinition and maximal self-evolution. For minimal\npredefinition, Alita is equipped with only one component for direct\nproblem-solving, making it much simpler and neater than previous approaches\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean\ndesign enhances its potential to generalize to challenging questions, without\nbeing limited by tools. For Maximal self-evolution, we enable the creativity of\nAlita by providing a suite of general-purpose components to autonomously\nconstruct, refine, and reuse external capabilities by generating task-related\nmodel context protocols (MCPs) from open source, which contributes to scalable\nagentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3\naccuracy, which is top-ranking among general-purpose agents, on the GAIA\nbenchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on\nMathvista and PathVQA, outperforming many agent systems with far greater\ncomplexity. More details will be updated at\n$\\href{https://github.com/CharlesQ9/Alita}{https://github.com/CharlesQ9/Alita}$.','Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, Xing Zhou, Dongrui Liu, Ling Yang, Yue Wu, Kaixuan Huang, Shilong Liu, Hongru Wang, Mengdi Wang','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20286v1'),('2505.20290v1','EgoZero: Robot Learning from Smart Glasses','Despite recent progress in general purpose robotics, robot policies still lag\nfar behind basic human capabilities in the real world. Humans interact\nconstantly with the physical world, yet this rich data resource remains largely\nuntapped in robot learning. We propose EgoZero, a minimal system that learns\nrobust manipulation policies from human demonstrations captured with Project\nAria smart glasses, $\\textbf{and zero robot data}$. EgoZero enables: (1)\nextraction of complete, robot-executable actions from in-the-wild, egocentric,\nhuman demonstrations, (2) compression of human visual observations into\nmorphology-agnostic state representations, and (3) closed-loop policy learning\nthat generalizes morphologically, spatially, and semantically. We deploy\nEgoZero policies on a gripper Franka Panda robot and demonstrate zero-shot\ntransfer with 70% success rate over 7 manipulation tasks and only 20 minutes of\ndata collection per task. Our results suggest that in-the-wild human data can\nserve as a scalable foundation for real-world robot learning - paving the way\ntoward a future of abundant, diverse, and naturalistic training data for\nrobots. Code and videos are available at https://egozero-robot.github.io.','Vincent Liu, Ademi Adeniji, Haotian Zhan, Raunaq Bhirangi, Pieter Abbeel, Lerrel Pinto','2025-05-26','cs.RO','http://arxiv.org/pdf/2505.20290v1'),('2505.20291v1','Visualized Text-to-Image Retrieval','We propose Visualize-then-Retrieve (VisRet), a new paradigm for Text-to-Image\n(T2I) retrieval that mitigates the limitations of cross-modal similarity\nalignment of existing multi-modal embeddings. VisRet first projects textual\nqueries into the image modality via T2I generation. Then, it performs retrieval\nwithin the image modality to bypass the weaknesses of cross-modal retrievers in\nrecognizing subtle visual-spatial features. Experiments on three\nknowledge-intensive T2I retrieval benchmarks, including a newly introduced\nmulti-entity benchmark, demonstrate that VisRet consistently improves T2I\nretrieval by 24.5% to 32.7% NDCG@10 across different embedding models. VisRet\nalso significantly benefits downstream visual question answering accuracy when\nused in retrieval-augmented generation pipelines. The method is plug-and-play\nand compatible with off-the-shelf retrievers, making it an effective module for\nknowledge-intensive multi-modal systems. Our code and the new benchmark are\npublicly available at https://github.com/xiaowu0162/Visualize-then-Retrieve.','Di Wu, Yixin Wan, Kai-Wei Chang','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20291v1'),('2505.20292v3','OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation','Subject-to-Video (S2V) generation aims to create videos that faithfully\nincorporate reference content, providing enhanced flexibility in the production\nof videos. To establish the infrastructure for S2V generation, we propose\nOpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, and\n(ii) OpenS2V-5M, a million-scale dataset. In contrast to existing S2V\nbenchmarks inherited from VBench that focus on global and coarse-grained\nassessment of generated videos, OpenS2V-Eval focuses on the model\\\'s ability to\ngenerate subject-consistent videos with natural subject appearance and identity\nfidelity. For these purposes, OpenS2V-Eval introduces 180 prompts from seven\nmajor categories of S2V, which incorporate both real and synthetic test data.\nFurthermore, to accurately align human preferences with S2V benchmarks, we\npropose three automatic metrics, NexusScore, NaturalScore and GmeScore, to\nseparately quantify subject consistency, naturalness, and text relevance in\ngenerated videos. Building on this, we conduct a comprehensive evaluation of 16\nrepresentative S2V models, highlighting their strengths and weaknesses across\ndifferent content. Moreover, we create the first open-source large-scale S2V\ngeneration dataset OpenS2V-5M, which consists of five million high-quality 720P\nsubject-text-video triples. Specifically, we ensure subject-information\ndiversity in our dataset by (1) segmenting subjects and building pairing\ninformation via cross-video associations and (2) prompting GPT-Image-1 on raw\nframes to synthesize multi-view representations. Through OpenS2V-Nexus, we\ndeliver a robust infrastructure to accelerate future S2V generation research.','Shenghai Yuan, Xianyi He, Yufan Deng, Yang Ye, Jinfa Huang, Bin Lin, Jiebo Luo, Li Yuan','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20292v3'),('2505.20293v1','Enhancing the Comprehensibility of Text Explanations via Unsupervised Concept Discovery','Concept-based explainable approaches have emerged as a promising method in\nexplainable AI because they can interpret models in a way that aligns with\nhuman reasoning. However, their adaption in the text domain remains limited.\nMost existing methods rely on predefined concept annotations and cannot\ndiscover unseen concepts, while other methods that extract concepts without\nsupervision often produce explanations that are not intuitively comprehensible\nto humans, potentially diminishing user trust. These methods fall short of\ndiscovering comprehensible concepts automatically. To address this issue, we\npropose \\textbf{ECO-Concept}, an intrinsically interpretable framework to\ndiscover comprehensible concepts with no concept annotations. ECO-Concept first\nutilizes an object-centric architecture to extract semantic concepts\nautomatically. Then the comprehensibility of the extracted concepts is\nevaluated by large language models. Finally, the evaluation result guides the\nsubsequent model fine-tuning to obtain more understandable explanations.\nExperiments show that our method achieves superior performance across diverse\ntasks. Further concept evaluations validate that the concepts learned by\nECO-Concept surpassed current counterparts in comprehensibility.','Yifan Sun, Danding Wang, Qiang Sheng, Juan Cao, Jintao Li','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20293v1'),('2505.20294v1','GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes','Generalizable active mapping in complex unknown environments remains a\ncritical challenge for mobile robots. Existing methods, constrained by\ninsufficient training data and conservative exploration strategies, exhibit\nlimited generalizability across scenes with diverse layouts and complex\nconnectivity. To enable scalable training and reliable evaluation, we introduce\nGLEAM-Bench, the first large-scale benchmark designed for generalizable active\nmapping with 1,152 diverse 3D scenes from synthetic and real-scan datasets.\nBuilding upon this foundation, we propose GLEAM, a unified generalizable\nexploration policy for active mapping. Its superior generalizability comes\nmainly from our semantic representations, long-term navigable goals, and\nrandomized strategies. It significantly outperforms state-of-the-art methods,\nachieving 66.50% coverage (+9.49%) with efficient trajectories and improved\nmapping accuracy on 128 unseen complex scenes. Project page:\nhttps://xiao-chen.tech/gleam/.','Xiao Chen, Tai Wang, Quanyi Li, Tao Huang, Jiangmiao Pang, Tianfan Xue','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20294v1'),('2505.20295v1','Self-reflective Uncertainties: Do LLMs Know Their Internal Answer Distribution?','To reveal when a large language model (LLM) is uncertain about a response,\nuncertainty quantification commonly produces percentage numbers along with the\noutput. But is this all we can do? We argue that in the output space of LLMs,\nthe space of strings, exist strings expressive enough to summarize the\ndistribution over output strings the LLM deems possible. We lay a foundation\nfor this new avenue of uncertainty explication and present SelfReflect, a\ntheoretically-motivated metric to assess how faithfully a string summarizes an\nLLM\\\'s internal answer distribution. We show that SelfReflect is able to\ndiscriminate even subtle differences of candidate summary strings and that it\naligns with human judgement, outperforming alternative metrics such as LLM\njudges and embedding comparisons. With SelfReflect, we investigate a number of\nself-summarization methods and find that even state-of-the-art reasoning models\nstruggle to explicate their internal uncertainty. But we find that faithful\nsummarizations can be generated by sampling and summarizing. Our metric enables\nfuture works towards this universal form of LLM uncertainties.','Michael Kirchhof, Luca Füger, Adam Goliński, Eeshan Gunesh Dhekane, Arno Blaas, Sinead Williamson','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20295v1'),('2505.20296v1','Reasoning LLMs are Wandering Solution Explorers','Large Language Models (LLMs) have demonstrated impressive reasoning abilities\nthrough test-time computation (TTC) techniques such as chain-of-thought\nprompting and tree-based reasoning. However, we argue that current reasoning\nLLMs (RLLMs) lack the ability to systematically explore the solution space.\nThis paper formalizes what constitutes systematic problem solving and\nidentifies common failure modes that reveal reasoning LLMs to be wanderers\nrather than systematic explorers. Through qualitative and quantitative analysis\nacross multiple state-of-the-art LLMs, we uncover persistent issues: invalid\nreasoning steps, redundant explorations, hallucinated or unfaithful\nconclusions, and so on. Our findings suggest that current models\\\' performance\ncan appear to be competent on simple tasks yet degrade sharply as complexity\nincreases. Based on the findings, we advocate for new metrics and tools that\nevaluate not just final outputs but the structure of the reasoning process\nitself.','Jiahao Lu, Ziwei Xu, Mohan Kankanhalli','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20296v1'),('2505.20297v1','DiSA: Diffusion Step Annealing in Autoregressive Image Generation','An increasing number of autoregressive models, such as MAR, FlowAR, xAR, and\nHarmon adopt diffusion sampling to improve the quality of image generation.\nHowever, this strategy leads to low inference efficiency, because it usually\ntakes 50 to 100 steps for diffusion to sample a token. This paper explores how\nto effectively address this issue. Our key motivation is that as more tokens\nare generated during the autoregressive process, subsequent tokens follow more\nconstrained distributions and are easier to sample. To intuitively explain, if\na model has generated part of a dog, the remaining tokens must complete the dog\nand thus are more constrained. Empirical evidence supports our motivation: at\nlater generation stages, the next tokens can be well predicted by a multilayer\nperceptron, exhibit low variance, and follow closer-to-straight-line denoising\npaths from noise to tokens. Based on our finding, we introduce diffusion step\nannealing (DiSA), a training-free method which gradually uses fewer diffusion\nsteps as more tokens are generated, e.g., using 50 steps at the beginning and\ngradually decreasing to 5 steps at later stages. Because DiSA is derived from\nour finding specific to diffusion in autoregressive models, it is complementary\nto existing acceleration methods designed for diffusion alone. DiSA can be\nimplemented in only a few lines of code on existing models, and albeit simple,\nachieves $5-10\\times$ faster inference for MAR and Harmon and $1.4-2.5\\times$\nfor FlowAR and xAR, while maintaining the generation quality.','Qinyu Zhao, Jaskirat Singh, Ming Xu, Akshay Asthana, Stephen Gould, Liang Zheng','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20297v1'),('2505.20298v1','MangaVQA and MangaLMM: A Benchmark and Specialized Model for Multimodal Manga Understanding','Manga, or Japanese comics, is a richly multimodal narrative form that blends\nimages and text in complex ways. Teaching large multimodal models (LMMs) to\nunderstand such narratives at a human-like level could help manga creators\nreflect on and refine their stories. To this end, we introduce two benchmarks\nfor multimodal manga understanding: MangaOCR, which targets in-page text\nrecognition, and MangaVQA, a novel benchmark designed to evaluate contextual\nunderstanding through visual question answering. MangaVQA consists of 526\nhigh-quality, manually constructed question-answer pairs, enabling reliable\nevaluation across diverse narrative and visual scenarios. Building on these\nbenchmarks, we develop MangaLMM, a manga-specialized model finetuned from the\nopen-source LMM Qwen2.5-VL to jointly handle both tasks. Through extensive\nexperiments, including comparisons with proprietary models such as GPT-4o and\nGemini 2.5, we assess how well LMMs understand manga. Our benchmark and model\nprovide a comprehensive foundation for evaluating and advancing LMMs in the\nrichly narrative domain of manga.','Jeonghun Baek, Kazuki Egashira, Shota Onohara, Atsuyuki Miyai, Yuki Imajuku, Hikaru Ikuta, Kiyoharu Aizawa','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20298v1'),('2505.20377v1','Algorithmic Control Improves Residential Building Energy and EV Management when PV Capacity is High but Battery Capacity is Low','Efficient energy management in prosumer households is key to alleviating grid\nstress in an energy transition marked by electric vehicles (EV), renewable\nenergies and battery storage. However, it is unclear how households optimize\nprosumer EV charging. Here we study real-world data from 90 households on\nfixed-rate electricity tariffs in German-speaking countries to investigate the\npotential of Deep Reinforcement Learning (DRL) and other control approaches\n(Rule-Based, Model Predictive Control) to manage the dynamic and uncertain\nenvironment of Home Energy Management (HEM) and optimize household charging\npatterns. The DRL agent efficiently aligns charging of EV and battery storage\nwith photovoltaic (PV) surplus. We find that frequent EV charging transactions,\nearly EV connections and PV surplus increase optimization potential. A detailed\nanalysis of nine households (1 hour resolution, 1 year) demonstrates that high\nbattery capacity facilitates self optimization; in this case further\nalgorithmic control shows little value. In cases with relatively low battery\ncapacity, algorithmic control with DRL improves energy management and cost\nsavings by a relevant margin. This result is further corroborated by our\nsimulation of a synthetic household. We conclude that prosumer households with\noptimization potential would profit from DRL, thus benefiting also the full\nelectricity system and its decarbonization.','Lennart Ullner, Alona Zharova, Felix Creutzig','2025-05-26','eess.SY','http://arxiv.org/pdf/2505.20377v1'),('2505.20380v1','GRAPE: Optimize Data Mixture for Group Robust Multi-target Adaptive Pretraining','The performance of large language models (LLMs) across diverse downstream\napplications is fundamentally governed by the quality and composition of their\npretraining corpora. Existing domain reweighting algorithms primarily optimize\ndata mixtures for a single target task, thereby resulting in models that\noverfit to specialized objectives while exhibiting substantial performance\ndegradation on other benchmarks. This paper introduces Group Robust\nMulti-target Adaptive PrEtraining (GRAPE), a novel multi-source-multi-target\ndomain reweighting framework designed to calibrate pretraining data mixtures\nfor robust performance across multiple target tasks simultaneously. GRAPE\ndynamically adjusts sampling weights across source domains (domain weights)\nwhile concurrently modulating task weights that quantify the relative\nimportance of each individual target task. This adaptive process prioritizes\ntasks based on their learning difficulty throughout training. We formulate this\ninterleaved reweighting mechanism as a minimax optimization problem: The inner\nmaximization adjusts task weights leveraging group\ndistributed-robust-optimization (DRO), where those tasks demonstrating the\nleast improvement under the current data mixture are prioritized with higher\nweights; The outer minimization then optimizes domain weights to maximize loss\nreduction on the prioritized tasks. Experiments on ClimbLab and SlimPajama\ndatasets demonstrate that GRAPE consistently outperforms baseline methods in\nterms of reasoning performance across 6 benchmarks. Furthermore, when applied\nto multilingual targets, GRAPE effectively identifies optimal training mixtures\nfrom mainstream languages, achieving superior language modeling capabilities\nacross 8 low-resource target languages.','Simin Fan, Maria Ios Glarou, Martin Jaggi','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20380v1'),('2505.20405v1','What Changed? Detecting and Evaluating Instruction-Guided Image Edits with Multimodal Large Language Models','Instruction-based image editing models offer increased personalization\nopportunities in generative tasks. However, properly evaluating their results\nis challenging, and most of the existing metrics lag in terms of alignment with\nhuman judgment and explainability. To tackle these issues, we introduce DICE\n(DIfference Coherence Estimator), a model designed to detect localized\ndifferences between the original and the edited image and to assess their\nrelevance to the given modification request. DICE consists of two key\ncomponents: a difference detector and a coherence estimator, both built on an\nautoregressive Multimodal Large Language Model (MLLM) and trained using a\nstrategy that leverages self-supervision, distillation from inpainting\nnetworks, and full supervision. Through extensive experiments, we evaluate each\nstage of our pipeline, comparing different MLLMs within the proposed framework.\nWe demonstrate that DICE effectively identifies coherent edits, effectively\nevaluating images generated by different editing models with a strong\ncorrelation with human judgment. We publicly release our source code, models,\nand data.','Lorenzo Baraldi, Davide Bucciarelli, Federico Betti, Marcella Cornia, Lorenzo Baraldi, Nicu Sebe, Rita Cucchiara','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20405v1'),('2505.20411v1','SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents','LLM-based agents have shown promising capabilities in a growing range of\nsoftware engineering (SWE) tasks. However, advancing this field faces two\ncritical challenges. First, high-quality training data is scarce, especially\ndata that reflects real-world SWE scenarios, where agents must interact with\ndevelopment environments, execute code and adapt behavior based on the outcomes\nof their actions. Existing datasets are either limited to one-shot code\ngeneration or comprise small, manually curated collections of interactive\ntasks, lacking both scale and diversity. Second, the lack of fresh interactive\nSWE tasks affects evaluation of rapidly improving models, as static benchmarks\nquickly become outdated due to contamination issues. To address these\nlimitations, we introduce a novel, automated, and scalable pipeline to\ncontinuously extract real-world interactive SWE tasks from diverse GitHub\nrepositories. Using this pipeline, we construct SWE-rebench, a public dataset\ncomprising over 21,000 interactive Python-based SWE tasks, suitable for\nreinforcement learning of SWE agents at scale. Additionally, we use continuous\nsupply of fresh tasks collected using SWE-rebench methodology to build a\ncontamination-free benchmark for agentic software engineering. We compare\nresults of various LLMs on this benchmark to results on SWE-bench Verified and\nshow that performance of some language models might be inflated due to\ncontamination issues.','Ibragim Badertdinov, Alexander Golubev, Maksim Nekrashevich, Anton Shevtsov, Simon Karasik, Andrei Andriushchenko, Maria Trofimova, Daria Litvintseva, Boris Yangel','2025-05-26','cs.SE','http://arxiv.org/pdf/2505.20411v1'),('2505.20414v1','RetroMotion: Retrocausal Motion Forecasting Models are Instructable','Motion forecasts of road users (i.e., agents) vary in complexity as a\nfunction of scene constraints and interactive behavior. We address this with a\nmulti-task learning method for motion forecasting that includes a retrocausal\nflow of information. The corresponding tasks are to forecast (1) marginal\ntrajectory distributions for all modeled agents and (2) joint trajectory\ndistributions for interacting agents. Using a transformer model, we generate\nthe joint distributions by re-encoding marginal distributions followed by\npairwise modeling. This incorporates a retrocausal flow of information from\nlater points in marginal trajectories to earlier points in joint trajectories.\nPer trajectory point, we model positional uncertainty using compressed\nexponential power distributions. Notably, our method achieves state-of-the-art\nresults in the Waymo Interaction Prediction dataset and generalizes well to the\nArgoverse 2 dataset. Additionally, our method provides an interface for issuing\ninstructions through trajectory modifications. Our experiments show that\nregular training of motion forecasting leads to the ability to follow\ngoal-based instructions and to adapt basic directional instructions to the\nscene context. Code: https://github.com/kit-mrt/future-motion','Royden Wagner, Omer Sahin Tas, Felix Hauser, Marlon Steiner, Dominik Strutz, Abhishek Vivekanandan, Carlos Fernandez, Christoph Stiller','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20414v1'),('2505.20415v1','Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision','Large language models (LLMs) have shown promising performance in mathematical\nand logical reasoning benchmarks. However, recent studies have pointed to\nmemorization, rather than generalization, as one of the leading causes for such\nperformance. LLMs, in fact, are susceptible to content variations,\ndemonstrating a lack of robust symbolic abstractions supporting their reasoning\nprocess. To improve reliability, many attempts have been made to combine LLMs\nwith symbolic methods. Nevertheless, existing approaches fail to effectively\nleverage symbolic representations due to the challenges involved in developing\nreliable and scalable verification mechanisms. In this paper, we propose to\novercome such limitations by generating symbolic reasoning trajectories and\nselect the high-quality ones using a process reward model automatically tuned\nbased on Monte Carlo estimation. The trajectories are then employed via\nfine-tuning methods to improve logical reasoning and generalization. Our\nresults on logical reasoning benchmarks such as FOLIO and LogicAsker show the\neffectiveness of the proposed method with large gains on frontier and\nopen-weight models. Moreover, additional experiments on claim verification\nreveal that fine-tuning on the generated symbolic reasoning trajectories\nenhances out-of-domain generalizability, suggesting the potential impact of\nsymbolically-guided process supervision in alleviating the effect of\nmemorization on LLM reasoning.','Xingwei Tan, Marco Valentino, Mahmud Akhter, Maria Liakata, Nikolaos Aletras','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20415v1'),('2505.20416v1','GraphGen: Enhancing Supervised Fine-Tuning for LLMs with Knowledge-Driven Synthetic Data Generation','Fine-tuning for large language models (LLMs) typically requires substantial\namounts of high-quality supervised data, which is both costly and\nlabor-intensive to acquire. While synthetic data generation has emerged as a\npromising solution, existing approaches frequently suffer from factual\ninaccuracies, insufficient long-tail coverage, simplistic knowledge structures,\nand homogenized outputs. To address these challenges, we introduce GraphGen, a\nknowledge graph-guided framework designed for three key question-answering (QA)\nscenarios: atomic QA, aggregated QA, and multi-hop QA. It begins by\nconstructing a fine-grained knowledge graph from the source text. It then\nidentifies knowledge gaps in LLMs using the expected calibration error metric,\nprioritizing the generation of QA pairs that target high-value, long-tail\nknowledge. Furthermore, GraphGen incorporates multi-hop neighborhood sampling\nto capture complex relational information and employs style-controlled\ngeneration to diversify the resulting QA data. Experimental results on\nknowledge-intensive tasks under closed-book settings demonstrate that GraphGen\noutperforms conventional synthetic data methods, offering a more reliable and\ncomprehensive solution to the data scarcity challenge in supervised\nfine-tuning. The code and data are publicly available at\nhttps://github.com/open-sciencelab/GraphGen.','Zihong Chen, Wanli Jiang, Jinzhe Li, Zhonghang Yuan, Huanjun Kong, Wanli Ouyang, Nanqing Dong','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20416v1'),('2505.20417v1','SCAR: Shapley Credit Assignment for More Efficient RLHF','Reinforcement Learning from Human Feedback (RLHF) is a widely used technique\nfor aligning Large Language Models (LLMs) with human preferences, yet it often\nsuffers from sparse reward signals, making effective credit assignment\nchallenging. In typical setups, the reward model provides a single scalar score\nfor an entire generated sequence, offering little insight into which token or\nspan-level decisions were responsible for the outcome. To address this, we\npropose Shapley Credit Assignment Rewards (SCAR), a novel method that leverages\nShapley values in cooperative game theory. SCAR distributes the total\nsequence-level reward among constituent tokens or text spans based on their\nprincipled marginal contributions. This creates dense reward signals,\ncrucially, without necessitating the training of auxiliary critique models or\nrecourse to fine-grained human annotations at intermediate generation stages.\nUnlike prior dense reward methods, SCAR offers a game-theoretic foundation for\nfair credit attribution. Theoretically, we demonstrate that SCAR preserves the\noriginal optimal policy, and empirically, across diverse tasks including\nsentiment control, text summarization, and instruction tuning, we show that\nSCAR converges significantly faster and achieves higher final reward scores\ncompared to standard RLHF and attention-based dense reward baselines. Our\nfindings suggest that SCAR provides a more effective and theoretically sound\nmethod for credit assignment in RLHF, leading to more efficient alignment of\nLLMs.','Meng Cao, Shuyuan Zhang, Xiao-Wen Chang, Doina Precup','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20417v1'),('2505.20422v1','SEMMA: A Semantic Aware Knowledge Graph Foundation Model','Knowledge Graph Foundation Models (KGFMs) have shown promise in enabling\nzero-shot reasoning over unseen graphs by learning transferable patterns.\nHowever, most existing KGFMs rely solely on graph structure, overlooking the\nrich semantic signals encoded in textual attributes. We introduce SEMMA, a\ndual-module KGFM that systematically integrates transferable textual semantics\nalongside structure. SEMMA leverages Large Language Models (LLMs) to enrich\nrelation identifiers, generating semantic embeddings that subsequently form a\ntextual relation graph, which is fused with the structural component. Across 54\ndiverse KGs, SEMMA outperforms purely structural baselines like ULTRA in fully\ninductive link prediction. Crucially, we show that in more challenging\ngeneralization settings, where the test-time relation vocabulary is entirely\nunseen, structural methods collapse while SEMMA is 2x more effective. Our\nfindings demonstrate that textual semantics are critical for generalization in\nsettings where structure alone fails, highlighting the need for foundation\nmodels that unify structural and linguistic signals in knowledge reasoning.','Arvindh Arun, Sumit Kumar, Mojtaba Nayyeri, Bo Xiong, Ponnurangam Kumaraguru, Antonio Vergari, Steffen Staab','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20422v1'),('2505.20423v1','Vision-Based Risk Aware Emergency Landing for UAVs in Complex Urban Environments','Landing safely in crowded urban environments remains an essential yet\nchallenging endeavor for Unmanned Aerial Vehicles (UAVs), especially in\nemergency situations. In this work, we propose a risk-aware approach that\nharnesses semantic segmentation to continuously evaluate potential hazards in\nthe drone\\\'s field of view. By using a specialized deep neural network to assign\npixel-level risk values and applying an algorithm based on risk maps, our\nmethod adaptively identifies a stable Safe Landing Zone (SLZ) despite moving\ncritical obstacles such as vehicles, people, etc., and other visual challenges\nlike shifting illumination. A control system then guides the UAV toward this\nlow-risk region, employing altitude-dependent safety thresholds and temporal\nlanding point stabilization to ensure robust descent trajectories. Experimental\nvalidation in diverse urban environments demonstrates the effectiveness of our\napproach, achieving over 90% landing success rates in very challenging real\nscenarios, showing significant improvements in various risk metrics. Our\nfindings suggest that risk-oriented vision methods can effectively help reduce\nthe risk of accidents in emergency landing situations, particularly in complex,\nunstructured, urban scenarios, densely populated with moving risky obstacles,\nwhile potentiating the true capabilities of UAVs in complex urban operations.','Julio de la Torre-Vanegas, Miguel Soriano-Garcia, Israel Becerra, Diego Mercado-Ravell','2025-05-26','cs.RO','http://arxiv.org/pdf/2505.20423v1'),('2505.20424v1','Robot Operation of Home Appliances by Reading User Manuals','Operating home appliances, among the most common tools in every household, is\na critical capability for assistive home robots. This paper presents ApBot, a\nrobot system that operates novel household appliances by \"reading\" their user\nmanuals. ApBot faces multiple challenges: (i) infer goal-conditioned partial\npolicies from their unstructured, textual descriptions in a user manual\ndocument, (ii) ground the policies to the appliance in the physical world, and\n(iii) execute the policies reliably over potentially many steps, despite\ncompounding errors. To tackle these challenges, ApBot constructs a structured,\nsymbolic model of an appliance from its manual, with the help of a large\nvision-language model (VLM). It grounds the symbolic actions visually to\ncontrol panel elements. Finally, ApBot closes the loop by updating the model\nbased on visual feedback. Our experiments show that across a wide range of\nsimulated and real-world appliances, ApBot achieves consistent and\nstatistically significant improvements in task success rate, compared with\nstate-of-the-art large VLMs used directly as control policies. These results\nsuggest that a structured internal representations plays an important role in\nrobust robot operation of home appliances, especially, complex ones.','Jian Zhang, Hanbo Zhang, Anxing Xiao, David Hsu','2025-05-26','cs.RO','http://arxiv.org/pdf/2505.20424v1'),('2505.20428v1','The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project','This paper presents UD-NewsCrawl, the largest Tagalog treebank to date,\ncontaining 15.6k trees manually annotated according to the Universal\nDependencies framework. We detail our treebank development process, including\ndata collection, pre-processing, manual annotation, and quality assurance\nprocedures. We provide baseline evaluations using multiple transformer-based\nmodels to assess the performance of state-of-the-art dependency parsers on\nTagalog. We also highlight challenges in the syntactic analysis of Tagalog\ngiven its distinctive grammatical properties, and discuss its implications for\nthe annotation of this treebank. We anticipate that UD-NewsCrawl and our\nbaseline model implementations will serve as valuable resources for advancing\ncomputational linguistics research in underrepresented languages like Tagalog.','Angelina A. Aquino, Lester James V. Miranda, Elsie Marie T. Or','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20428v1'),('2505.20429v2','PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy','This paper introduces PreP-OCR, a two-stage pipeline that combines document\nimage restoration with semantic-aware post-OCR correction to enhance both\nvisual clarity and textual consistency, thereby improving text extraction from\ndegraded historical documents. First, we synthesize document-image pairs from\nplaintext, rendering them with diverse fonts and layouts and then applying a\nrandomly ordered set of degradation operations. An image restoration model is\ntrained on this synthetic data, using multi-directional patch extraction and\nfusion to process large images. Second, a ByT5 post-OCR model, fine-tuned on\nsynthetic historical text pairs, addresses remaining OCR errors. Detailed\nexperiments on 13,831 pages of real historical documents in English, French,\nand Spanish show that the PreP-OCR pipeline reduces character error rates by\n63.9-70.3% compared to OCR on raw images. Our pipeline demonstrates the\npotential of integrating image restoration with linguistic error correction for\ndigitizing historical archives.','Shuhao Guan, Moule Lin, Cheng Xu, Xinyi Liu, Jinman Zhao, Jiexin Fan, Qi Xu, Derek Greene','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20429v2'),('2505.20433v1','Kernel Quantile Embeddings and Associated Probability Metrics','Embedding probability distributions into reproducing kernel Hilbert spaces\n(RKHS) has enabled powerful nonparametric methods such as the maximum mean\ndiscrepancy (MMD), a statistical distance with strong theoretical and\ncomputational properties. At its core, the MMD relies on kernel mean embeddings\nto represent distributions as mean functions in RKHS. However, it remains\nunclear if the mean function is the only meaningful RKHS representation.\nInspired by generalised quantiles, we introduce the notion of kernel quantile\nembeddings (KQEs). We then use KQEs to construct a family of distances that:\n(i) are probability metrics under weaker kernel conditions than MMD; (ii)\nrecover a kernelised form of the sliced Wasserstein distance; and (iii) can be\nefficiently estimated with near-linear cost. Through hypothesis testing, we\nshow that these distances offer a competitive alternative to MMD and its fast\napproximations.','Masha Naslidnyk, Siu Lun Chau, François-Xavier Briol, Krikamol Muandet','2025-05-26','stat.ML','http://arxiv.org/pdf/2505.20433v1'),('2505.20435v1','Holes in Latent Space: Topological Signatures Under Adversarial Influence','Understanding how adversarial conditions affect language models requires\ntechniques that capture both global structure and local detail within\nhigh-dimensional activation spaces. We propose persistent homology (PH), a tool\nfrom topological data analysis, to systematically characterize multiscale\nlatent space dynamics in LLMs under two distinct attack modes -- backdoor\nfine-tuning and indirect prompt injection. By analyzing six state-of-the-art\nLLMs, we show that adversarial conditions consistently compress latent\ntopologies, reducing structural diversity at smaller scales while amplifying\ndominant features at coarser ones. These topological signatures are\nstatistically robust across layers, architectures, model sizes, and align with\nthe emergence of adversarial effects deeper in the network. To capture\nfiner-grained mechanisms underlying these shifts, we introduce a neuron-level\nPH framework that quantifies how information flows and transforms within and\nacross layers. Together, our findings demonstrate that PH offers a principled\nand unifying approach to interpreting representational dynamics in LLMs,\nparticularly under distributional shift.','Aideen Fay, Inés García-Redondo, Qiquan Wang, Haim Dubossarsky, Anthea Monod','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20435v1'),('2505.20438v1','HAMburger: Accelerating LLM Inference via Token Smashing','The growing demand for efficient Large Language Model (LLM) inference\nrequires a holistic optimization on algorithms, systems, and hardware. However,\nvery few works have fundamentally changed the generation pattern: each token\nneeds one forward pass and one KV cache. This can be sub-optimal because we\nfound that LLMs are extremely capable of self-identifying the exact dose of\ninformation that a single KV cache can store, and many tokens can be generated\nconfidently without global context. Based on this insight, we introduce\nHAMburger, a Hierarchically Auto-regressive Model that redefines resource\nallocation in LLMs by moving beyond uniform computation and storage per token\nduring inference. Stacking a compositional embedder and a micro-step decoder in\nbetween a base LLM, HAMburger smashes multiple tokens into a single KV and\ngenerates several tokens per step. Additionally, HAMburger functions as a\nspeculative decoding framework where it can blindly trust self-drafted tokens.\nAs a result, HAMburger shifts the growth of KV cache and forward FLOPs from\nlinear to sub-linear with respect to output length, and adjusts its inference\nspeed based on query perplexity and output structure. Extensive evaluations\nshow that HAMburger reduces the KV cache computation by up to 2$\\times$ and\nachieves up to 2$\\times$ TPS, while maintaining quality in both short- and\nlong-context tasks. Our method explores an extremely challenging inference\nregime that requires both computation- and memory-efficiency with a\nhardware-agnostic design.','Jingyu Liu, Ce Zhang','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20438v1'),('2505.20444v1','HoPE: Hybrid of Position Embedding for Length Generalization in Vision-Language Models','Vision-Language Models (VLMs) have made significant progress in multimodal\ntasks. However, their performance often deteriorates in long-context scenarios,\nparticularly long videos. While Rotary Position Embedding (RoPE) has been\nwidely adopted for length generalization in Large Language Models (LLMs),\nextending vanilla RoPE to capture the intricate spatial-temporal dependencies\nin videos remains an unsolved challenge. Existing methods typically allocate\ndifferent frequencies within RoPE to encode 3D positional information. However,\nthese allocation strategies mainly rely on heuristics, lacking in-depth\ntheoretical analysis. In this paper, we first study how different allocation\nstrategies impact the long-context capabilities of VLMs. Our analysis reveals\nthat current multimodal RoPEs fail to reliably capture semantic similarities\nover extended contexts. To address this issue, we propose HoPE, a Hybrid of\nPosition Embedding designed to improve the long-context capabilities of VLMs.\nHoPE introduces a hybrid frequency allocation strategy for reliable semantic\nmodeling over arbitrarily long context, and a dynamic temporal scaling\nmechanism to facilitate robust learning and flexible inference across diverse\ncontext lengths. Extensive experiments across four video benchmarks on long\nvideo understanding and retrieval tasks demonstrate that HoPE consistently\noutperforms existing methods, confirming its effectiveness. Code is available\nat https://github.com/hrlics/HoPE.','Haoran Li, Yingjie Qin, Baoyuan Ou, Lai Xu, Ruiwen Xu','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20444v1'),('2505.20445v2','In-context Language Learning for Endangered Languages in Speech Recognition','With approximately 7,000 languages spoken worldwide, current large language\nmodels (LLMs) support only a small subset. Prior research indicates LLMs can\nlearn new languages for certain tasks without supervised data. We extend this\ninvestigation to speech recognition, investigating whether LLMs can learn\nunseen, low-resource languages through in-context learning (ICL). With\nexperiments on four diverse endangered languages that LLMs have not been\ntrained on, we find that providing more relevant text samples enhances\nperformance in both language modelling and Automatic Speech Recognition (ASR)\ntasks. Furthermore, we show that the probability-based approach outperforms the\ntraditional instruction-based approach in language learning. Lastly, we show\nICL enables LLMs to achieve ASR performance that is comparable to or even\nsurpasses dedicated language models trained specifically for these languages,\nwhile preserving the original capabilities of the LLMs.','Zhaolin Li, Jan Niehues','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20445v2'),('2505.20446v1','Time Series Generation Under Data Scarcity: A Unified Generative Modeling Approach','Generative modeling of time series is a central challenge in time series\nanalysis, particularly under data-scarce conditions. Despite recent advances in\ngenerative modeling, a comprehensive understanding of how state-of-the-art\ngenerative models perform under limited supervision remains lacking. In this\nwork, we conduct the first large-scale study evaluating leading generative\nmodels in data-scarce settings, revealing a substantial performance gap between\nfull-data and data-scarce regimes. To close this gap, we propose a unified\ndiffusion-based generative framework that can synthesize high-fidelity time\nseries across diverse domains using just a few examples. Our model is\npre-trained on a large, heterogeneous collection of time series datasets,\nenabling it to learn generalizable temporal representations. It further\nincorporates architectural innovations such as dynamic convolutional layers for\nflexible channel adaptation and dataset token conditioning for domain-aware\ngeneration. Without requiring abundant supervision, our unified model achieves\nstate-of-the-art performance in few-shot settings-outperforming domain-specific\nbaselines across a wide range of subset sizes. Remarkably, it also surpasses\nall baselines even when tested on full datasets benchmarks, highlighting the\nstrength of pre-training and cross-domain generalization. We hope this work\nencourages the community to revisit few-shot generative modeling as a key\nproblem in time series research and pursue unified solutions that scale\nefficiently across domains. Code is available at\nhttps://github.com/azencot-group/ImagenFew.','Tal Gonen, Itai Pemper, Ilan Naiman, Nimrod Berman, Omri Azencot','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20446v1'),('2505.20451v1','Amulet: Putting Complex Multi-Turn Conversations on the Stand with LLM Juries','Today, large language models are widely used as judges to evaluate responses\nfrom other language models. Hence, it is imperative to benchmark and improve\nthese LLM-judges on real-world language model usage: a typical human-assistant\nconversation is lengthy, and shows significant diversity in topics, intents,\nand requirements across turns, e.g. social interactions, task requests,\nfeedback. We present Amulet, a framework that leverages pertinent linguistic\nconcepts of dialog-acts and maxims to improve the accuracy of LLM-judges on\npreference data with complex, multi-turn conversational context. Amulet\npresents valuable insights about (a) the communicative structures and intents\npresent in the conversation (dialog acts), and (b) the satisfaction of\nconversational principles (maxims) by the preference responses, and uses them\nto make judgments. On four challenging datasets, Amulet shows that (a) humans\nfrequently (60 to 70 percent of the time) change their intents from one turn of\nthe conversation to the next, and (b) in 75 percent of instances, the\npreference responses can be differentiated via dialog acts and/or maxims,\nreiterating the latter\\\'s significance in judging such data. Amulet can be used\neither as a judge by applying the framework to a single LLM, or integrated into\na jury with different LLM judges; our judges and juries show strong\nimprovements on relevant baselines for all four datasets.','Sahana Ramnath, Anurag Mudgil, Brihi Joshi, Skyler Hallinan, Xiang Ren','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20451v1'),('2505.20452v1','Active Learning for Multiple Change Point Detection in Non-stationary Time Series with Deep Gaussian Processes','Multiple change point (MCP) detection in non-stationary time series is\nchallenging due to the variety of underlying patterns. To address these\nchallenges, we propose a novel algorithm that integrates Active Learning (AL)\nwith Deep Gaussian Processes (DGPs) for robust MCP detection. Our method\nleverages spectral analysis to identify potential changes and employs AL to\nstrategically select new sampling points for improved efficiency. By\nincorporating the modeling flexibility of DGPs with the change-identification\ncapabilities of spectral methods, our approach adapts to diverse spectral\nchange behaviors and effectively localizes multiple change points. Experiments\non both simulated and real-world data demonstrate that our method outperforms\nexisting techniques in terms of detection accuracy and sampling efficiency for\nnon-stationary time series.','Hao Zhao, Rong Pan','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20452v1'),('2505.20454v1','BlastOFormer: Attention and Neural Operator Deep Learning Methods for Explosive Blast Prediction','Accurate prediction of blast pressure fields is essential for applications in\nstructural safety, defense planning, and hazard mitigation. Traditional methods\nsuch as empirical models and computational fluid dynamics (CFD) simulations\noffer limited trade offs between speed and accuracy; empirical models fail to\ncapture complex interactions in cluttered environments, while CFD simulations\nare computationally expensive and time consuming. In this work, we introduce\nBlastOFormer, a novel Transformer based surrogate model for full field maximum\npressure prediction from arbitrary obstacle and charge configurations.\nBlastOFormer leverages a signed distance function (SDF) encoding and a grid to\ngrid attention based architecture inspired by OFormer and Vision Transformer\n(ViT) frameworks. Trained on a dataset generated using the open source\nblastFoam CFD solver, our model outperforms convolutional neural networks\n(CNNs) and Fourier Neural Operators (FNOs) across both log transformed and\nunscaled domains. Quantitatively, BlastOFormer achieves the highest R2 score\n(0.9516) and lowest error metrics, while requiring only 6.4 milliseconds for\ninference, more than 600,000 times faster than CFD simulations. Qualitative\nvisualizations and error analyses further confirm BlastOFormer\\\'s superior\nspatial coherence and generalization capabilities. These results highlight its\npotential as a real time alternative to conventional CFD approaches for blast\npressure estimation in complex environments.','Reid Graves, Anthony Zhou, Amir Barati Farimani','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20454v1'),('2505.20456v1','Federated Learning-Distillation Alternation for Resource-Constrained IoT','Federated learning (FL) faces significant challenges in Internet of Things\n(IoT) networks due to device limitations in energy and communication resources,\nespecially when considering the large size of FL models. From an energy\nperspective, the challenge is aggravated if devices rely on energy harvesting\n(EH), as energy availability can vary significantly over time, influencing the\naverage number of participating users in each iteration. Additionally, the\ntransmission of large model updates is more susceptible to interference from\nuncorrelated background traffic in shared wireless environments. As an\nalternative, federated distillation (FD) reduces communication overhead and\nenergy consumption by transmitting local model outputs, which are typically\nmuch smaller than the entire model used in FL. However, this comes at the cost\nof reduced model accuracy. Therefore, in this paper, we propose FL-distillation\nalternation (FLDA). In FLDA, devices alternate between FD and FL phases,\nbalancing model information with lower communication overhead and energy\nconsumption per iteration. We consider a multichannel slotted-ALOHA EH-IoT\nnetwork subject to background traffic/interference. In such a scenario, FLDA\ndemonstrates higher model accuracy than both FL and FD, and achieves faster\nconvergence than FL. Moreover, FLDA achieves target accuracies saving up to 98%\nin energy consumption, while also being less sensitive to interference, both\nrelative to FL.','Rafael Valente da Silva, Onel L. Alcaraz López, Richard Demo Souza','2025-05-26','eess.SP','http://arxiv.org/pdf/2505.20456v1'),('2505.20464v1','The Impact of a Chatbot\\\'s Ephemerality-Framing on Self-Disclosure Perceptions','Self-disclosure, the sharing of one\\\'s thoughts and feelings, is affected by\nthe perceived relationship between individuals. While chatbots are increasingly\nused for self-disclosure, the impact of a chatbot\\\'s framing on users\\\'\nself-disclosure remains under-explored. We investigated how a chatbot\\\'s\ndescription of its relationship with users, particularly in terms of\nephemerality, affects self-disclosure. Specifically, we compared a Familiar\nchatbot, presenting itself as a companion remembering past interactions, with a\nStranger chatbot, presenting itself as a new, unacquainted entity in each\nconversation. In a mixed factorial design, participants engaged with either the\nFamiliar or Stranger chatbot in two sessions across two days, with one\nconversation focusing on Emotional- and another Factual-disclosure. When\nEmotional-disclosure was sought in the first chatting session,\nStranger-condition participants felt more comfortable self-disclosing. However,\nwhen Factual-disclosure was sought first, these differences were replaced by\nmore enjoyment among Familiar-condition participants. Qualitative findings\nshowed Stranger afforded anonymity and reduced judgement, whereas Familiar\nsometimes felt intrusive unless rapport was built via low-risk\nFactual-disclosure.','Samuel Rhys Cox, Rune Møberg Jacobsen, Niels van Berkel','2025-05-26','cs.HC','http://arxiv.org/pdf/2505.20464v1'),('2505.20465v1','Learning with Expected Signatures: Theory and Applications','The expected signature maps a collection of data streams to a lower\ndimensional representation, with a remarkable property: the resulting feature\ntensor can fully characterize the data generating distribution. This\n\"model-free\" embedding has been successfully leveraged to build multiple\ndomain-agnostic machine learning (ML) algorithms for time series and sequential\ndata. The convergence results proved in this paper bridge the gap between the\nexpected signature\\\'s empirical discrete-time estimator and its theoretical\ncontinuous-time value, allowing for a more complete probabilistic\ninterpretation of expected signature-based ML methods. Moreover, when the data\ngenerating process is a martingale, we suggest a simple modification of the\nexpected signature estimator with significantly lower mean squared error and\nempirically demonstrate how it can be effectively applied to improve predictive\nperformance.','Lorenzo Lucchese, Mikko S. Pakkanen, Almut E. D. Veraart','2025-05-26','stat.ML','http://arxiv.org/pdf/2505.20465v1'),('2505.20466v1','Reconceptualizing Smart Microscopy: From Data Collection to Knowledge Creation by Multi-Agent Integration','Smart microscopy represents a paradigm shift in biological imaging, moving\nfrom passive observation tools to active collaborators in scientific inquiry.\nEnabled by advances in automation, computational power, and artificial\nintelligence, these systems are now capable of adaptive decision-making and\nreal-time experimental control. Here, we introduce a theoretical framework that\nreconceptualizes smart microscopy as a partner in scientific investigation.\nCentral to our framework is the concept of the \\\'epistemic-empirical divide\\\' in\ncellular investigation-the gap between what is observable (empirical domain)\nand what must be understood (epistemic domain). We propose six core design\nprinciples: epistemic-empirical awareness, hierarchical context integration, an\nevolution from detection to perception, adaptive measurement frameworks,\nnarrative synthesis capabilities, and cross-contextual reasoning. Together,\nthese principles guide a multi-agent architecture designed to align empirical\nobservation with the goals of scientific understanding. Our framework provides\na roadmap for building microscopy systems that go beyond automation to actively\nsupport hypothesis generation, insight discovery, and theory development,\nredefining the role of scientific instruments in the process of knowledge\ncreation.','P. S. Kesavan, Pontus Nordenfelt','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20466v1'),('2505.20469v1','CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting','Recent advances in 3D reconstruction techniques and vision-language models\nhave fueled significant progress in 3D semantic understanding, a capability\ncritical to robotics, autonomous driving, and virtual/augmented reality.\nHowever, methods that rely on 2D priors are prone to a critical challenge:\ncross-view semantic inconsistencies induced by occlusion, image blur, and\nview-dependent variations. These inconsistencies, when propagated via\nprojection supervision, deteriorate the quality of 3D Gaussian semantic fields\nand introduce artifacts in the rendered outputs. To mitigate this limitation,\nwe propose CCL-LGS, a novel framework that enforces view-consistent semantic\nsupervision by integrating multi-view semantic cues. Specifically, our approach\nfirst employs a zero-shot tracker to align a set of SAM-generated 2D masks and\nreliably identify their corresponding categories. Next, we utilize CLIP to\nextract robust semantic encodings across views. Finally, our Contrastive\nCodebook Learning (CCL) module distills discriminative semantic features by\nenforcing intra-class compactness and inter-class distinctiveness. In contrast\nto previous methods that directly apply CLIP to imperfect masks, our framework\nexplicitly resolves semantic conflicts while preserving category\ndiscriminability. Extensive experiments demonstrate that CCL-LGS outperforms\nprevious state-of-the-art methods. Our project page is available at\nhttps://epsilontl.github.io/CCL-LGS/.','Lei Tian, Xiaomin Li, Liqian Ma, Hefei Huang, Zirui Zheng, Hao Yin, Taiqing Li, Huchuan Lu, Xu Jia','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20469v1'),('2505.20471v1','WeatherEdit: Controllable Weather Editing with 4D Gaussian Field','In this work, we present WeatherEdit, a novel weather editing pipeline for\ngenerating realistic weather effects with controllable types and severity in 3D\nscenes. Our approach is structured into two key components: weather background\nediting and weather particle construction. For weather background editing, we\nintroduce an all-in-one adapter that integrates multiple weather styles into a\nsingle pretrained diffusion model, enabling the generation of diverse weather\neffects in 2D image backgrounds. During inference, we design a Temporal-View\n(TV-) attention mechanism that follows a specific order to aggregate temporal\nand spatial information, ensuring consistent editing across multi-frame and\nmulti-view images. To construct the weather particles, we first reconstruct a\n3D scene using the edited images and then introduce a dynamic 4D Gaussian field\nto generate snowflakes, raindrops and fog in the scene. The attributes and\ndynamics of these particles are precisely controlled through physical-based\nmodelling and simulation, ensuring realistic weather representation and\nflexible severity adjustments. Finally, we integrate the 4D Gaussian field with\nthe 3D scene to render consistent and highly realistic weather effects.\nExperiments on multiple driving datasets demonstrate that WeatherEdit can\ngenerate diverse weather effects with controllable condition severity,\nhighlighting its potential for autonomous driving simulation in adverse\nweather. See project page: https://jumponthemoon.github.io/w-edit','Chenghao Qian, Wenjing Li, Yuhu Guo, Gustav Markkula','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20471v1'),('2505.20473v1','Stochastic Preconditioning for Neural Field Optimization','Neural fields are a highly effective representation across visual computing.\nThis work observes that fitting these fields is greatly improved by\nincorporating spatial stochasticity during training, and that this simple\ntechnique can replace or even outperform custom-designed hierarchies and\nfrequency space constructions. The approach is formalized as implicitly\noperating on a blurred version of the field, evaluated in-expectation by\nsampling with Gaussian-distributed offsets. Querying the blurred field during\noptimization greatly improves convergence and robustness, akin to the role of\npreconditioners in numerical linear algebra. This implicit, sampling-based\nperspective fits naturally into the neural field paradigm, comes at no\nadditional cost, and is extremely simple to implement. We describe the basic\ntheory of this technique, including details such as handling boundary\nconditions, and extending to a spatially-varying blur. Experiments demonstrate\nthis approach on representations including coordinate MLPs, neural hashgrids,\ntriplanes, and more, across tasks including surface reconstruction and radiance\nfields. In settings where custom-designed hierarchies have already been\ndeveloped, stochastic preconditioning nearly matches or improves their\nperformance with a simple and unified approach; in settings without existing\nhierarchies it provides an immediate boost to quality and robustness.','Selena Ling, Merlin Nimier-David, Alec Jacobson, Nicholas Sharp','2025-05-26','cs.GR','http://arxiv.org/pdf/2505.20473v1'),('2505.20480v1','BrainStratify: Coarse-to-Fine Disentanglement of Intracranial Neural Dynamics','Decoding speech directly from neural activity is a central goal in\nbrain-computer interface (BCI) research. In recent years, exciting advances\nhave been made through the growing use of intracranial field potential\nrecordings, such as stereo-ElectroEncephaloGraphy (sEEG) and\nElectroCorticoGraphy (ECoG). These neural signals capture rich population-level\nactivity but present key challenges: (i) task-relevant neural signals are\nsparsely distributed across sEEG electrodes, and (ii) they are often entangled\nwith task-irrelevant neural signals in both sEEG and ECoG. To address these\nchallenges, we introduce a unified Coarse-to-Fine neural disentanglement\nframework, BrainStratify, which includes (i) identifying functional groups\nthrough spatial-context-guided temporal-spatial modeling, and (ii)\ndisentangling distinct neural dynamics within the target functional group using\nDecoupled Product Quantization (DPQ). We evaluate BrainStratify on two\nopen-source sEEG datasets and one (epidural) ECoG dataset, spanning tasks like\nvocal production and speech perception. Extensive experiments show that\nBrainStratify, as a unified framework for decoding speech from intracranial\nneural signals, significantly outperforms previous decoding methods. Overall,\nby combining data-driven stratification with neuroscience-inspired modularity,\nBrainStratify offers a robust and interpretable solution for speech decoding\nfrom intracranial recordings.','Hui Zheng, Hai-Teng Wang, Yi-Tao Jing, Pei-Yang Lin, Han-Qing Zhao, Wei Chen, Peng-Hu Wei, Yong-Zhi Shan, Guo-Guang Zhao, Yun-Zhe Liu','2025-05-26','eess.SP','http://arxiv.org/pdf/2505.20480v1'),('2505.20481v1','CardioPatternFormer: Pattern-Guided Attention for Interpretable ECG Classification with Transformer Architecture','Accurate ECG interpretation is vital, yet complex cardiac data and\n\"black-box\" AI models limit clinical utility. Inspired by Transformer\narchitectures\\\' success in NLP for understanding sequential data, we frame ECG\nas the heart\\\'s unique \"language\" of temporal patterns. We present\nCardioPatternFormer, a novel Transformer-based model for interpretable ECG\nclassification. It employs a sophisticated attention mechanism to precisely\nidentify and classify diverse cardiac patterns, excelling at discerning subtle\nanomalies and distinguishing multiple co-occurring conditions. This\npattern-guided attention provides clear insights by highlighting influential\nsignal regions, effectively allowing the \"heart to talk\" through transparent\ninterpretations. CardioPatternFormer demonstrates robust performance on\nchallenging ECGs, including complex multi-pathology cases. Its interpretability\nvia attention maps enables clinicians to understand the model\\\'s rationale,\nfostering trust and aiding informed diagnostic decisions. This work offers a\npowerful, transparent solution for advanced ECG analysis, paving the way for\nmore reliable and clinically actionable AI in cardiology.','Berat Kutay Uğraş, Ömer Nezih Gerek, İbrahim Talha Saygı','2025-05-26','eess.SP','http://arxiv.org/pdf/2505.20481v1'),('2505.20482v1','Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Understanding','Understanding online conversations has attracted research attention with the\ngrowth of social networks and online discussion forums. Content analysis of\nposts and replies in online conversations is difficult because each individual\nutterance is usually short and may implicitly refer to other posts within the\nsame conversation. Thus, understanding individual posts requires capturing the\nconversational context and dependencies between different parts of a\nconversation tree and then encoding the context dependencies between posts and\ncomments/replies into the language model.\n  To this end, we propose a general-purpose mechanism to discover appropriate\nconversational context for various aspects about an online post in a\nconversation, such as whether it is informative, insightful, interesting or\nfunny. Specifically, we design two families of Conversation Kernels, which\nexplore different parts of the neighborhood of a post in the tree representing\nthe conversation and through this, build relevant conversational context that\nis appropriate for each task being considered. We apply our developed method to\nconversations crawled from slashdot.org, which allows users to apply highly\ndifferent labels to posts, such as \\\'insightful\\\', \\\'funny\\\', etc., and therefore\nprovides an ideal experimental platform to study whether a framework such as\nConversation Kernels is general-purpose and flexible enough to be adapted to\ndisparately different conversation understanding tasks.','Vibhor Agarwal, Arjoo Gupta, Suparna De, Nishanth Sastry','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20482v1'),('2505.20485v1','Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data','The inevitable presence of data heterogeneity has made federated learning\nvery challenging. There are numerous methods to deal with this issue, such as\nlocal regularization, better model fusion techniques, and data sharing. Though\neffective, they lack a deep understanding of how data heterogeneity can affect\nthe global decision boundary. In this paper, we bridge this gap by performing\nan experimental analysis of the learned decision boundary using a toy example.\nOur observations are surprising: (1) we find that the existing methods suffer\nfrom forgetting and clients forget the global decision boundary and only learn\nthe perfect local one, and (2) this happens regardless of the initial weights,\nand clients forget the global decision boundary even starting from pre-trained\noptimal weights. In this paper, we present FedProj, a federated learning\nframework that robustly learns the global decision boundary and avoids its\nforgetting during local training. To achieve better ensemble knowledge fusion,\nwe design a novel server-side ensemble knowledge transfer loss to further\ncalibrate the learned global decision boundary. To alleviate the issue of\nlearned global decision boundary forgetting, we further propose leveraging an\nepisodic memory of average ensemble logits on a public unlabeled dataset to\nregulate the gradient updates at each step of local training. Experimental\nresults demonstrate that FedProj outperforms state-of-the-art methods by a\nlarge margin.','Abhijit Chunduru, Majid Morafah, Mahdi Morafah, Vishnu Pandi Chellapandi, Ang Li','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20485v1'),('2505.20487v1','InFact: Informativeness Alignment for Improved LLM Factuality','Factual completeness is a general term that captures how detailed and\ninformative a factually correct text is. For instance, the factual sentence\n``Barack Obama was born in the United States\\\'\\\' is factually correct, though\nless informative than the factual sentence ``Barack Obama was born in Honolulu,\nHawaii, United States\\\'\\\'. Despite the known fact that LLMs tend to hallucinate\nand generate factually incorrect text, they might also tend to choose to\ngenerate factual text that is indeed factually correct and yet less informative\nthan other, more informative choices. In this work, we tackle this problem by\nproposing an informativeness alignment mechanism. This mechanism takes\nadvantage of recent factual benchmarks to propose an informativeness alignment\nobjective. This objective prioritizes answers that are both correct and\ninformative. A key finding of our work is that when training a model to\nmaximize this objective or optimize its preference, we can improve not just\ninformativeness but also factuality.','Roi Cohen, Russa Biswas, Gerard de Melo','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20487v1'),('2505.20496v1','Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages','Conventional transformer models typically compress the information from all\ntokens in a sequence into a single \\texttt{[CLS]} token to represent global\ncontext-- an approach that can lead to information loss in tasks requiring\nlocalized or hierarchical cues. In this work, we introduce \\textit{Inceptive\nTransformer}, a modular and lightweight architecture that enriches\ntransformer-based token representations by integrating a multi-scale feature\nextraction module inspired by inception networks. Our model is designed to\nbalance local and global dependencies by dynamically weighting tokens based on\ntheir relevance to a particular task. Evaluation across a diverse range of\ntasks including emotion recognition (both English and Bangla), irony detection,\ndisease identification, and anti-COVID vaccine tweets classification shows that\nour models consistently outperform the baselines by 1\\% to 14\\% while\nmaintaining efficiency. These findings highlight the versatility and\ncross-lingual applicability of our method for enriching transformer-based\nrepresentations across diverse domains.','Asif Shahriar, Rifat Shahriyar, M Saifur Rahman','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20496v1'),('2505.20498v2','ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image','Vision-based tactile sensing has been widely used in perception,\nreconstruction, and robotic manipulation. However, collecting large-scale\ntactile data remains costly due to the localized nature of sensor-object\ninteractions and inconsistencies across sensor instances. Existing approaches\nto scaling tactile data, such as simulation and free-form tactile generation,\noften suffer from unrealistic output and poor transferability to downstream\ntasks. To address this, we propose ControlTac, a two-stage controllable\nframework that generates realistic tactile images conditioned on a single\nreference tactile image, contact force, and contact position. With those\nphysical priors as control input, ControlTac generates physically plausible and\nvaried tactile images that can be used for effective data augmentation. Through\nexperiments on three downstream tasks, we demonstrate that ControlTac can\neffectively augment tactile datasets and lead to consistent gains. Our three\nreal-world experiments further validate the practical utility of our approach.\nProject page: https://dongyuluo.github.io/controltac.','Dongyu Luo, Kelin Yu, Amir-Hossein Shahidzadeh, Cornelia Fermüller, Yiannis Aloimonos, Ruohan Gao','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20498v2'),('2505.20500v1','Beyond Keywords: Evaluating Large Language Model Classification of Nuanced Ableism','Large language models (LLMs) are increasingly used in decision-making tasks\nlike r\\\\\'esum\\\\\'e screening and content moderation, giving them the power to\namplify or suppress certain perspectives. While previous research has\nidentified disability-related biases in LLMs, little is known about how they\nconceptualize ableism or detect it in text. We evaluate the ability of four\nLLMs to identify nuanced ableism directed at autistic individuals. We examine\nthe gap between their understanding of relevant terminology and their\neffectiveness in recognizing ableist content in context. Our results reveal\nthat LLMs can identify autism-related language but often miss harmful or\noffensive connotations. Further, we conduct a qualitative comparison of human\nand LLM explanations. We find that LLMs tend to rely on surface-level keyword\nmatching, leading to context misinterpretations, in contrast to human\nannotators who consider context, speaker identity, and potential impact. On the\nother hand, both LLMs and humans agree on the annotation scheme, suggesting\nthat a binary classification is adequate for evaluating LLM performance, which\nis consistent with findings from prior studies involving human annotators.','Naba Rizvi, Harper Strickland, Saleha Ahmedi, Aekta Kallepalli, Isha Khirwadkar, William Wu, Imani N. S. Munyaka, Nedjma Ousidhoum','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20500v1'),('2505.20501v1','Gatsby Without the \\\'E\\\': Crafting Lipograms with LLMs','Lipograms are a unique form of constrained writing where all occurrences of a\nparticular letter are excluded from the text, typified by the novel Gadsby,\nwhich daringly avoids all usage of the letter \\\'e\\\'. In this study, we explore\nthe power of modern large language models (LLMs) by transforming the novel F.\nScott Fitzgerald\\\'s The Great Gatsby into a fully \\\'e\\\'-less text. We experimented\nwith a range of techniques, from baseline methods like synonym replacement to\nsophisticated generative models enhanced with beam search and named entity\nanalysis. We show that excluding up to 3.6% of the most common letters (up to\nthe letter \\\'u\\\') had minimal impact on the text\\\'s meaning, although translation\nfidelity rapidly and predictably decays with stronger lipogram constraints. Our\nwork highlights the surprising flexibility of English under strict constraints,\nrevealing just how adaptable and creative language can be.','Rohan Balasubramanian, Nitish Gokulakrishnan, Syeda Jannatus Saba, Steven Skiena','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20501v1'),('2505.20503v1','Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review','Rapid advancements in foundation models, including Large Language Models,\nVision-Language Models, Multimodal Large Language Models, and\nVision-Language-Action Models have opened new avenues for embodied AI in mobile\nservice robotics. By combining foundation models with the principles of\nembodied AI, where intelligent systems perceive, reason, and act through\nphysical interactions, robots can improve understanding, adapt to, and execute\ncomplex tasks in dynamic real-world environments. However, embodied AI in\nmobile service robots continues to face key challenges, including multimodal\nsensor fusion, real-time decision-making under uncertainty, task\ngeneralization, and effective human-robot interactions (HRI). In this paper, we\npresent the first systematic review of the integration of foundation models in\nmobile service robotics, identifying key open challenges in embodied AI and\nexamining how foundation models can address them. Namely, we explore the role\nof such models in enabling real-time sensor fusion, language-conditioned\ncontrol, and adaptive task execution. Furthermore, we discuss real-world\napplications in the domestic assistance, healthcare, and service automation\nsectors, demonstrating the transformative impact of foundation models on\nservice robotics. We also include potential future research directions,\nemphasizing the need for predictive scaling laws, autonomous long-term\nadaptation, and cross-embodiment generalization to enable scalable, efficient,\nand robust deployment of foundation models in human-centric robotic systems.','Matthew Lisondra, Beno Benhabib, Goldie Nejat','2025-05-26','cs.RO','http://arxiv.org/pdf/2505.20503v1'),('2505.20505v1','Large Language Models for IT Automation Tasks: Are We There Yet?','LLMs show promise in code generation, yet their effectiveness for IT\nautomation tasks, particularly for tools like Ansible, remains understudied.\nExisting benchmarks rely primarily on synthetic tasks that fail to capture the\nneeds of practitioners who use IT automation tools, such as Ansible. We present\nITAB (IT Automation Task Benchmark), a benchmark of 126 diverse tasks (e.g.,\nconfiguring servers, managing files) where each task accounts for state\nreconciliation: a property unique to IT automation tools. ITAB evaluates LLMs\\\'\nability to generate functional Ansible automation scripts via dynamic execution\nin controlled environments. We evaluate 14 open-source LLMs, none of which\naccomplish pass@10 at a rate beyond 12%. To explain these low scores, we\nanalyze 1,411 execution failures across the evaluated LLMs and identify two\nmain categories of prevalent semantic errors: failures in state reconciliation\nrelated reasoning (44.87% combined from variable (11.43%), host (11.84%),\npath(11.63%), and template (9.97%) issues) and deficiencies in module-specific\nexecution knowledge (24.37% combined from Attribute and parameter (14.44%) and\nmodule (9.93%) errors). Our findings reveal key limitations in open-source\nLLMs\\\' ability to track state changes and apply specialized module knowledge,\nindicating that reliable IT automation will require major advances in state\nreasoning and domain-specific execution understanding.','Md Mahadi Hassan, John Salvador, Akond Rahman, Santu Karmaker','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20505v1'),('2505.20506v1','ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis','We introduce ArVoice, a multi-speaker Modern Standard Arabic (MSA) speech\ncorpus with diacritized transcriptions, intended for multi-speaker speech\nsynthesis, and can be useful for other tasks such as speech-based diacritic\nrestoration, voice conversion, and deepfake detection. ArVoice comprises: (1) a\nnew professionally recorded set from six voice talents with diverse\ndemographics, (2) a modified subset of the Arabic Speech Corpus; and (3)\nhigh-quality synthetic speech from two commercial systems. The complete corpus\nconsists of a total of 83.52 hours of speech across 11 voices; around 10 hours\nconsist of human voices from 7 speakers. We train three open-source TTS and two\nvoice conversion systems to illustrate the use cases of the dataset. The corpus\nis available for research use.','Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20506v1'),('2505.20507v1','Electrolyzers-HSI: Close-Range Multi-Scene Hyperspectral Imaging Benchmark Dataset','The global challenge of sustainable recycling demands automated, fast, and\naccurate, state-of-the-art (SOTA) material detection systems that act as a\nbedrock for a circular economy. Democratizing access to these cutting-edge\nsolutions that enable real-time waste analysis is essential for scaling up\nrecycling efforts and fostering the Green Deal. In response, we introduce\n\\textbf{Electrolyzers-HSI}, a novel multimodal benchmark dataset designed to\naccelerate the recovery of critical raw materials through accurate electrolyzer\nmaterials classification. The dataset comprises 55 co-registered\nhigh-resolution RGB images and hyperspectral imaging (HSI) data cubes spanning\nthe 400--2500 nm spectral range, yielding over 4.2 million pixel vectors and\n424,169 labeled ones. This enables non-invasive spectral analysis of shredded\nelectrolyzer samples, supporting quantitative and qualitative material\nclassification and spectral properties investigation. We evaluate a suite of\nbaseline machine learning (ML) methods alongside SOTA transformer-based deep\nlearning (DL) architectures, including Vision Transformer, SpectralFormer, and\nthe Multimodal Fusion Transformer, to investigate architectural bottlenecks for\nfurther efficiency optimisation when deploying transformers in material\nidentification. We implement zero-shot detection techniques and majority voting\nacross pixel-level predictions to establish object-level classification\nrobustness. In adherence to the FAIR data principles, the electrolyzers-HSI\ndataset and accompanying codebase are openly available at\nhttps://github.com/hifexplo/Electrolyzers-HSI and\nhttps://rodare.hzdr.de/record/3668, supporting reproducible research and\nfacilitating the broader adoption of smart and sustainable e-waste recycling\nsolutions.','Elias Arbash, Ahmed Jamal Afifi, Ymane Belahsen, Margret Fuchs, Pedram Ghamisi, Paul Scheunders, Richard Gloaguen','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20507v1'),('2505.20511v1','Multimodal Emotion Recognition in Conversations: A Survey of Methods, Trends, Challenges and Prospects','While text-based emotion recognition methods have achieved notable success,\nreal-world dialogue systems often demand a more nuanced emotional understanding\nthan any single modality can offer. Multimodal Emotion Recognition in\nConversations (MERC) has thus emerged as a crucial direction for enhancing the\nnaturalness and emotional understanding of human-computer interaction. Its goal\nis to accurately recognize emotions by integrating information from various\nmodalities such as text, speech, and visual signals.\n  This survey offers a systematic overview of MERC, including its motivations,\ncore tasks, representative methods, and evaluation strategies. We further\nexamine recent trends, highlight key challenges, and outline future directions.\nAs interest in emotionally intelligent systems grows, this survey provides\ntimely guidance for advancing MERC research.','Chengyan Wu, Yiqiang Cai, Yang Liu, Pengxu Zhu, Yun Xue, Ziwei Gong, Julia Hirschberg, Bolei Ma','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20511v1'),('2505.20515v1','Semi-Explicit Neural DAEs: Learning Long-Horizon Dynamical Systems with Algebraic Constraints','Despite the promise of scientific machine learning (SciML) in combining\ndata-driven techniques with mechanistic modeling, existing approaches for\nincorporating hard constraints in neural differential equations (NDEs) face\nsignificant limitations. Scalability issues and poor numerical properties\nprevent these neural models from being used for modeling physical systems with\ncomplicated conservation laws. We propose Manifold-Projected Neural ODEs\n(PNODEs), a method that explicitly enforces algebraic constraints by projecting\neach ODE step onto the constraint manifold. This framework arises naturally\nfrom semi-explicit differential-algebraic equations (DAEs), and includes both a\nrobust iterative variant and a fast approximation requiring a single Jacobian\nfactorization. We further demonstrate that prior works on relaxation methods\nare special cases of our approach. PNODEs consistently outperform baselines\nacross six benchmark problems achieving a mean constraint violation error below\n$10^{-10}$. Additionally, PNODEs consistently achieve lower runtime compared to\nother methods for a given level of error tolerance. These results show that\nconstraint projection offers a simple strategy for learning physically\nconsistent long-horizon dynamics.','Avik Pal, Alan Edelman, Christopher Rackauckas','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20515v1'),('2505.20521v1','Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting','This paper presents Project Riley, a novel multimodal and multi-model\nconversational AI architecture oriented towards the simulation of reasoning\ninfluenced by emotional states. Drawing inspiration from Pixar\\\'s Inside Out,\nthe system comprises five distinct emotional agents - Joy, Sadness, Fear,\nAnger, and Disgust - that engage in structured multi-round dialogues to\ngenerate, criticise, and iteratively refine responses. A final reasoning\nmechanism synthesises the contributions of these agents into a coherent output\nthat either reflects the dominant emotion or integrates multiple perspectives.\nThe architecture incorporates both textual and visual large language models\n(LLMs), alongside advanced reasoning and self-refinement processes. A\nfunctional prototype was deployed locally in an offline environment, optimised\nfor emotional expressiveness and computational efficiency. From this initial\nprototype, another one emerged, called Armando, which was developed for use in\nemergency contexts, delivering emotionally calibrated and factually accurate\ninformation through the integration of Retrieval-Augmented Generation (RAG) and\ncumulative context tracking. The Project Riley prototype was evaluated through\nuser testing, in which participants interacted with the chatbot and completed a\nstructured questionnaire assessing three dimensions: Emotional Appropriateness,\nClarity and Utility, and Naturalness and Human-likeness. The results indicate\nstrong performance in structured scenarios, particularly with respect to\nemotional alignment and communicative clarity.','Ana Rita Ortigoso, Gabriel Vieira, Daniel Fuentes, Luis Frazão, Nuno Costa, António Pereira','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20521v1'),('2505.20522v1','Scaling over Scaling: Exploring Test-Time Scaling Pareto in Large Reasoning Models','Large reasoning models (LRMs) have exhibited the capacity of enhancing\nreasoning performance via internal test-time scaling. Building upon this, a\npromising direction is to further scale test-time compute to unlock even\ngreater reasoning capabilities. However, as we push these scaling boundaries,\nsystematically understanding the practical limits and achieving optimal\nresource allocation becomes a critical challenge. In this paper, we investigate\nthe scaling Pareto of test-time scaling and introduce the Test-Time Scaling\nPerformance Model (TTSPM). We theoretically analyze two fundamental paradigms\nfor such extended scaling, parallel scaling and sequential scaling, from a\nprobabilistic modeling perspective. Our primary contribution is the derivation\nof the saturation point on the scaling budget for both strategies, identifying\nthresholds beyond which additional computation yields diminishing returns.\nRemarkably, despite their distinct mechanisms, both paradigms converge to a\nunified mathematical structure in their upper bounds. We empirically validate\nour theoretical findings on challenging reasoning benchmarks, including AIME,\nMATH-500, and GPQA, demonstrating the practical utility of these bounds for\ntest-time resource allocation. We hope that this work provides insights into\nthe cost-benefit trade-offs of test-time scaling, guiding the development of\nmore resource-efficient inference strategies for large reasoning models.','Jian Wang, Boyan Zhu, Chak Tou Leong, Yongqi Li, Wenjie Li','2025-05-26','cs.AI','http://arxiv.org/pdf/2505.20522v1'),('2505.20524v1','Towards Fully FP8 GEMM LLM Training at Scale','Despite the significant potential of FP8 data formats for large language\nmodel (LLM) pre-training, their adoption has been limited due to challenges in\nmaintaining stability at scale. Existing approaches often rely on suboptimal\nfine-grained FP8 kernels or fall back to higher-precision matrix\nmultiplications (GEMMs) in sensitive components, such as attention projections,\ncompromising potential throughput gains. We introduce a new class of LLM\narchitectures that, for the first time, support FP8 computation for all GEMMs\nwithin transformer blocks during both forward and backward passes. This enables\nunprecedented throughput gains, particularly at scale, while matching the\ndownstream performance of standard BF16 training. Our architecture design\nreduces large outlier activations, promoting stable long-term FP8 training. In\naddition, we identify key metrics to monitor low-precision training and predict\npotential future divergences.','Alejandro Hernández-Cano, Dhia Garbaya, Imanol Schlag, Martin Jaggi','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20524v1'),('2505.20529v1','Training Articulatory Inversion Models for Inter-Speaker Consistency','Acoustic-to-Articulatory Inversion (AAI) attempts to model the inverse\nmapping from speech to articulation. Exact articulatory prediction from speech\nalone may be impossible, as speakers can choose different forms of articulation\nseemingly without reference to their vocal tract structure. However, once a\nspeaker has selected an articulatory form, their productions vary minimally.\nRecent works in AAI have proposed adapting Self-Supervised Learning (SSL)\nmodels to single-speaker datasets, claiming that these single-speaker models\nprovide a universal articulatory template. In this paper, we investigate\nwhether SSL-adapted models trained on single and multi-speaker data produce\narticulatory targets which are consistent across speaker identities for English\nand Russian. We do this through the use of a novel evaluation method which\nextracts articulatory targets using minimal pair sets. We also present a\ntraining method which can improve inter-speaker consistency using only speech\ndata.','Charles McGhee, Mark J. F. Gales, Kate M. Knill','2025-05-26','cs.SD','http://arxiv.org/pdf/2505.20529v1'),('2505.20532v1','One-shot Robust Federated Learning of Independent Component Analysis','This paper investigates a general robust one-shot aggregation framework for\ndistributed and federated Independent Component Analysis (ICA) problem. We\npropose a geometric median-based aggregation algorithm that leverages $k$-means\nclustering to resolve the permutation ambiguity in local client estimations.\nOur method first performs k-means to partition client-provided estimators into\nclusters and then aggregates estimators within each cluster using the geometric\nmedian. This approach provably remains effective even in highly heterogeneous\nscenarios where at most half of the clients can observe only a minimal number\nof samples. The key theoretical contribution lies in the combined analysis of\nthe geometric median\\\'s error bound-aided by sample quantiles-and the maximum\nmisclustering rates of the aforementioned solution of $k$-means. The\neffectiveness of the proposed approach is further supported by simulation\nstudies conducted under various heterogeneous settings.','Dian Jin, Xin Bing, Yuqian Zhang','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20532v1'),('2505.20535v1','Rotary Masked Autoencoders are Versatile Learners','Applying Transformers to irregular time-series typically requires\nspecializations to their baseline architecture, which can result in additional\ncomputational overhead and increased method complexity. We present the Rotary\nMasked Autoencoder (RoMAE), which utilizes the popular Rotary Positional\nEmbedding (RoPE) method for continuous positions. RoMAE is an extension to the\nMasked Autoencoder (MAE) that enables representation learning with\nmultidimensional continuous positional information while avoiding any\ntime-series-specific architectural specializations. We showcase RoMAE\\\'s\nperformance on a variety of modalities including irregular and multivariate\ntime-series, images, and audio, demonstrating that RoMAE surpasses specialized\ntime-series architectures on difficult datasets such as the DESC ELAsTiCC\nChallenge while maintaining MAE\\\'s usual performance across other modalities. In\naddition, we investigate RoMAE\\\'s ability to reconstruct the embedded continuous\npositions, demonstrating that including learned embeddings in the input\nsequence breaks RoPE\\\'s relative position property.','Uros Zivanovic, Serafina Di Gioia, Andre Scaffidi, Martín de los Rios, Gabriella Contardo, Roberto Trotta','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20535v1'),('2505.20536v1','Covariate-Adjusted Deep Causal Learning for Heterogeneous Panel Data Models','This paper studies the task of estimating heterogeneous treatment effects in\ncausal panel data models, in the presence of covariate effects. We propose a\nnovel Covariate-Adjusted Deep Causal Learning (CoDEAL) for panel data models,\nthat employs flexible model structures and powerful neural network\narchitectures to cohesively deal with the underlying heterogeneity and\nnonlinearity of both panel units and covariate effects. The proposed CoDEAL\nintegrates nonlinear covariate effect components (parameterized by a\nfeed-forward neural network) with nonlinear factor structures (modeled by a\nmulti-output autoencoder) to form a heterogeneous causal panel model. The\nnonlinear covariate component offers a flexible framework for capturing the\ncomplex influences of covariates on outcomes. The nonlinear factor analysis\nenables CoDEAL to effectively capture both cross-sectional and temporal\ndependencies inherent in the data panel. This latent structural information is\nsubsequently integrated into a customized matrix completion algorithm, thereby\nfacilitating more accurate imputation of missing counterfactual outcomes.\nMoreover, the use of a multi-output autoencoder explicitly accounts for\nheterogeneity across units and enhances the model interpretability of the\nlatent factors. We establish theoretical guarantees on the convergence of the\nestimated counterfactuals, and demonstrate the compelling performance of the\nproposed method using extensive simulation studies and a real data application.','Guanhao Zhou, Yuefeng Han, Xiufan Yu','2025-05-26','stat.ML','http://arxiv.org/pdf/2505.20536v1'),('2505.20538v2','AstroVisBench: A Code Benchmark for Scientific Computing and Visualization in Astronomy','Large Language Models (LLMs) are being explored for applications in\nscientific research, including their capabilities to synthesize literature,\nanswer research questions, generate research ideas, and even conduct\ncomputational experiments. Ultimately, our goal is for these to help scientists\nderive novel scientific insights. In many areas of science, such insights often\narise from processing and visualizing data to understand its patterns. However,\nevaluating whether an LLM-mediated scientific workflow produces outputs\nconveying the correct scientific insights is challenging to evaluate and has\nnot been addressed in past work. We introduce AstroVisBench, the first\nbenchmark for both scientific computing and visualization in the astronomy\ndomain. AstroVisBench judges a language model\\\'s ability to both (1) create\nastronomy-specific workflows to process and analyze data and (2) visualize the\nresults of these workflows through complex plots. Our evaluation of\nvisualizations uses a novel LLM-as-a-judge workflow, which is validated against\nannotation by five professional astronomers. Using AstroVisBench we present an\nevaluation of state-of-the-art language models, showing a significant gap in\ntheir ability to engage in astronomy research as useful assistants. This\nevaluation provides a strong end-to-end evaluation for AI scientists that\noffers a path forward for the development of visualization-based workflows,\nwhich are central to a broad range of domains from physics to biology.','Sebastian Antony Joseph, Syed Murtaza Husain, Stella S. R. Offner, Stéphanie Juneau, Paul Torrey, Adam S. Bolton, Juan P. Farias, Niall Gaffney, Greg Durrett, Junyi Jessy Li','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20538v2'),('2505.20546v2','Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline','Multilingual large language models (LLMs) often exhibit factual\ninconsistencies across languages, with significantly better performance in\nfactual recall tasks in English than in other languages. The causes of these\nfailures, however, remain poorly understood. Using mechanistic analysis\ntechniques, we uncover the underlying pipeline that LLMs employ, which involves\nusing the English-centric factual recall mechanism to process multilingual\nqueries and then translating English answers back into the target language. We\nidentify two primary sources of error: insufficient engagement of the reliable\nEnglish-centric mechanism for factual recall, and incorrect translation from\nEnglish back into the target language for the final answer. To address these\nvulnerabilities, we introduce two vector interventions, both independent of\nlanguages and datasets, to redirect the model toward better internal paths for\nhigher factual consistency. Our interventions combined increase the recall\naccuracy by over 35 percent for the lowest-performing language. Our findings\ndemonstrate how mechanistic insights can be used to unlock latent multilingual\ncapabilities in LLMs.','Meng Lu, Ruochen Zhang, Carsten Eickhoff, Ellie Pavlick','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20546v2'),('2505.20553v1','A ZeNN architecture to avoid the Gaussian trap','We propose a new simple architecture, Zeta Neural Networks (ZeNNs), in order\nto overcome several shortcomings of standard multi-layer perceptrons (MLPs).\nNamely, in the large width limit, MLPs are non-parametric, they do not have a\nwell-defined pointwise limit, they lose non-Gaussian attributes and become\nunable to perform feature learning; moreover, finite width MLPs perform poorly\nin learning high frequencies. The new ZeNN architecture is inspired by three\nsimple principles from harmonic analysis:\n  i) Enumerate the perceptons and introduce a non-learnable weight to enforce\nconvergence;\n  ii) Introduce a scaling (or frequency) factor;\n  iii) Choose activation functions that lead to near orthogonal systems.\n  We will show that these ideas allow us to fix the referred shortcomings of\nMLPs. In fact, in the infinite width limit, ZeNNs converge pointwise, they\nexhibit a rich asymptotic structure beyond Gaussianity, and perform feature\nlearning. Moreover, when appropriate activation functions are chosen, (finite\nwidth) ZeNNs excel at learning high-frequency features of functions with low\ndimensional domains.','Luís Carvalho, João L. Costa, José Mourão, Gonçalo Oliveira','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20553v1'),('2505.20556v1','Learning a Pessimistic Reward Model in RLHF','This work proposes `PET\\\', a novel pessimistic reward fine-tuning method, to\nlearn a pessimistic reward model robust against reward hacking in offline\nreinforcement learning from human feedback (RLHF). Traditional reward modeling\ntechniques in RLHF train an imperfect reward model, on which a KL\nregularization plays a pivotal role in mitigating reward hacking when\noptimizing a policy. Such an intuition-based method still suffers from reward\nhacking, and the policies with large KL divergence from the dataset\ndistribution are excluded during learning. In contrast, we show that when\noptimizing a policy on a pessimistic reward model fine-tuned through PET,\nreward hacking can be prevented without relying on any regularization. We test\nour methods on the standard TL;DR summarization dataset. We find that one can\nlearn a high-quality policy on our pessimistic reward without using any\nregularization. Such a policy has a high KL divergence from the dataset\ndistribution while having high performance in practice. In summary, our work\nshows the feasibility of learning a pessimistic reward model against reward\nhacking. The agent can greedily search for the policy with a high pessimistic\nreward without suffering from reward hacking.','Yinglun Xu, Hangoo Kang, Tarun Suresh, Yuxuan Wan, Gagandeep Singh','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20556v1'),('2505.20561v1','Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning','Large Language Models (LLMs) trained via Reinforcement Learning (RL) have\nexhibited strong reasoning capabilities and emergent reflective behaviors, such\nas backtracking and error correction. However, conventional Markovian RL\nconfines exploration to the training phase to learn an optimal deterministic\npolicy and depends on the history contexts only through the current state.\nTherefore, it remains unclear whether reflective reasoning will emerge during\nMarkovian RL training, or why they are beneficial at test time. To remedy this,\nwe recast reflective exploration within the Bayes-Adaptive RL framework, which\nexplicitly optimizes the expected return under a posterior distribution over\nMarkov decision processes. This Bayesian formulation inherently incentivizes\nboth reward-maximizing exploitation and information-gathering exploration via\nbelief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and\nswitch strategies based on the observed outcomes, offering principled guidance\non when and how the model should reflectively explore. Empirical results on\nboth synthetic and mathematical reasoning tasks demonstrate that BARL\noutperforms standard Markovian RL approaches at test time, achieving superior\ntoken efficiency with improved exploration effectiveness. Our code is available\nat https://github.com/shenao-zhang/BARL.','Shenao Zhang, Yaqing Wang, Yinxiao Liu, Tianqi Liu, Peter Grabowski, Eugene Ie, Zhaoran Wang, Yunxuan Li','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20561v1'),('2505.20563v1','Bi-Level Unsupervised Feature Selection','Unsupervised feature selection (UFS) is an important task in data\nengineering. However, most UFS methods construct models from a single\nperspective and often fail to simultaneously evaluate feature importance and\npreserve their inherent data structure, thus limiting their performance. To\naddress this challenge, we propose a novel bi-level unsupervised feature\nselection (BLUFS) method, including a clustering level and a feature level.\nSpecifically, at the clustering level, spectral clustering is used to generate\npseudo-labels for representing the data structure, while a continuous linear\nregression model is developed to learn the projection matrix. At the feature\nlevel, the $\\ell_{2,0}$-norm constraint is imposed on the projection matrix for\nmore effectively selecting features. To the best of our knowledge, this is the\nfirst work to combine a bi-level framework with the $\\ell_{2,0}$-norm. To solve\nthe proposed bi-level model, we design an efficient proximal alternating\nminimization (PAM) algorithm, whose subproblems either have explicit solutions\nor can be computed by fast solvers. Furthermore, we establish the convergence\nresult and computational complexity. Finally, extensive experiments on two\nsynthetic datasets and eight real datasets demonstrate the superiority of BLUFS\nin clustering and classification tasks.','Jingjing Liu, Xiansen Ju, Xianchao Xiu, Wanquan Liu','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20563v1'),('2505.20564v1','The NaijaVoices Dataset: Cultivating Large-Scale, High-Quality, Culturally-Rich Speech Data for African Languages','The development of high-performing, robust, and reliable speech technologies\ndepends on large, high-quality datasets. However, African languages --\nincluding our focus, Igbo, Hausa, and Yoruba -- remain under-represented due to\ninsufficient data. Popular voice-enabled technologies do not support any of the\n2000+ African languages, limiting accessibility for circa one billion people.\nWhile previous dataset efforts exist for the target languages, they lack the\nscale and diversity needed for robust speech models. To bridge this gap, we\nintroduce the NaijaVoices dataset, a 1,800-hour speech-text dataset with 5,000+\nspeakers. We outline our unique data collection approach, analyze its acoustic\ndiversity, and demonstrate its impact through finetuning experiments on\nautomatic speech recognition, averagely achieving 75.86% (Whisper), 52.06%\n(MMS), and 42.33% (XLSR) WER improvements. These results highlight NaijaVoices\\\'\npotential to advance multilingual speech processing for African languages.','Chris Emezue, The NaijaVoices Community, Busayo Awobade, Abraham Owodunni, Handel Emezue, Gloria Monica Tobechukwu Emezue, Nefertiti Nneoma Emezue, Sewade Ogun, Bunmi Akinremi, David Ifeoluwa Adelani, Chris Pal','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20564v1'),('2505.20569v1','Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models','Despite significant advancements in Large Vision-Language Models, Object\nHallucination (OH) remains a persistent challenge. Building upon prior studies\non contrastive decoding that address this issue without requiring additional\nmodel training, we introduce RVCD (Retrieval Visual Contrastive Decoding), an\nadvanced method to suppress OH. RVCD leverages both negative and positive\nimages at the logit level, explicitly referencing AI-generated images designed\nto represent a single concept. Our approach demonstrates substantial\nimprovements over existing decoding-based methods.','Jihoon Lee, Min Song','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.20569v1'),('2505.20571v1','Emotion Classification In-Context in Spanish','Classifying customer feedback into distinct emotion categories is essential\nfor understanding sentiment and improving customer experience. In this paper,\nwe classify customer feedback in Spanish into three emotion\ncategories--positive, neutral, and negative--using advanced NLP and ML\ntechniques. Traditional methods translate feedback from widely spoken languages\nto less common ones, resulting in a loss of semantic integrity and contextual\nnuances inherent to the original language. To address this limitation, we\npropose a hybrid approach that combines TF-IDF with BERT embeddings,\neffectively transforming Spanish text into rich numerical representations that\npreserve the semantic depth of the original language by using a Custom Stacking\nEnsemble (CSE) approach. To evaluate emotion classification, we utilize a range\nof models, including Logistic Regression, KNN, Bagging classifier with LGBM,\nand AdaBoost. The CSE model combines these classifiers as base models and uses\na one-vs-all Logistic Regression as the meta-model. Our experimental results\ndemonstrate that CSE significantly outperforms the individual and BERT model,\nachieving a test accuracy of 93.3% on the native Spanish dataset--higher than\nthe accuracy obtained from the translated version. These findings underscore\nthe challenges of emotion classification in Spanish and highlight the\nadvantages of combining vectorization techniques like TF-IDF with BERT for\nimproved accuracy. Our results provide valuable insights for businesses seeking\nto leverage emotion classification to enhance customer feedback analysis and\nservice improvements.','Bipul Thapa, Gabriel Cofre','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20571v1'),('2505.20573v1','Collision- and Reachability-Aware Multi-Robot Control with Grounded LLM Planners','Large language models (LLMs) have demonstrated strong performance in various\nrobot control tasks. However, their deployment in real-world applications\nremains constrained. Even state-ofthe-art LLMs, such as GPT-o4mini, frequently\nproduce invalid action plans that violate physical constraints, such as\ndirecting a robot to an unreachable location or causing collisions between\nrobots. This issue primarily arises from a lack of awareness of these physical\nconstraints during the reasoning process. To address this issue, we propose a\nnovel framework that integrates reinforcement learning with verifiable rewards\n(RLVR) to incentivize knowledge of physical constraints into LLMs to induce\nconstraints-aware reasoning during plan generation. In this approach, only\nvalid action plans that successfully complete a control task receive positive\nrewards. We applied our method to two small-scale LLMs: a non-reasoning\nQwen2.5-3B-Instruct and a reasoning Qwen3-4B. The experiment results\ndemonstrate that constraint-aware small LLMs largely outperform large-scale\nmodels without constraints, grounded on both the BoxNet task and a newly\ndeveloped BoxNet3D environment built using MuJoCo. This work highlights the\neffectiveness of grounding even small LLMs with physical constraints to enable\nscalable and efficient multi-robot control in complex, physically constrained\nenvironments.','Jiabao Ji, Yongchao Chen, Yang Zhang, Ramana Rao Kompella, Chuchu Fan, Gaowen Liu, Shiyu Chang','2025-05-26','cs.RO','http://arxiv.org/pdf/2505.20573v1'),('2505.20578v1','Ctrl-DNA: Controllable Cell-Type-Specific Regulatory DNA Design via Constrained RL','Designing regulatory DNA sequences that achieve precise cell-type-specific\ngene expression is crucial for advancements in synthetic biology, gene therapy\nand precision medicine. Although transformer-based language models (LMs) can\neffectively capture patterns in regulatory DNA, their generative approaches\noften struggle to produce novel sequences with reliable cell-specific activity.\nHere, we introduce Ctrl-DNA, a novel constrained reinforcement learning (RL)\nframework tailored for designing regulatory DNA sequences with controllable\ncell-type specificity. By formulating regulatory sequence design as a\nbiologically informed constrained optimization problem, we apply RL to\nautoregressive genomic LMs, enabling the models to iteratively refine sequences\nthat maximize regulatory activity in targeted cell types while constraining\noff-target effects. Our evaluation on human promoters and enhancers\ndemonstrates that Ctrl-DNA consistently outperforms existing generative and\nRL-based approaches, generating high-fitness regulatory sequences and achieving\nstate-of-the-art cell-type specificity. Moreover, Ctrl-DNA-generated sequences\ncapture key cell-type-specific transcription factor binding sites (TFBS), short\nDNA motifs recognized by regulatory proteins that control gene expression,\ndemonstrating the biological plausibility of the generated sequences.','Xingyu Chen, Shihao Ma, Runsheng Lin, Jiecong Lin, Bo Wang','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20578v1'),('2505.20579v1','The challenge of hidden gifts in multi-agent reinforcement learning','Sometimes we benefit from actions that others have taken even when we are\nunaware that they took those actions. For example, if your neighbor chooses not\nto take a parking spot in front of your house when you are not there, you can\nbenefit, even without being aware that they took this action. These \"hidden\ngifts\" represent an interesting challenge for multi-agent reinforcement\nlearning (MARL), since assigning credit when the beneficial actions of others\nare hidden is non-trivial. Here, we study the impact of hidden gifts with a\nvery simple MARL task. In this task, agents in a grid-world environment have\nindividual doors to unlock in order to obtain individual rewards. As well, if\nall the agents unlock their door the group receives a larger collective reward.\nHowever, there is only one key for all of the doors, such that the collective\nreward can only be obtained when the agents drop the key for others after they\nuse it. Notably, there is nothing to indicate to an agent that the other agents\nhave dropped the key, thus the act of dropping the key for others is a \"hidden\ngift\". We show that several different state-of-the-art RL algorithms, including\nMARL algorithms, fail to learn how to obtain the collective reward in this\nsimple task. Interestingly, we find that independent model-free policy gradient\nagents can solve the task when we provide them with information about their own\naction history, but MARL agents still cannot solve the task with action\nhistory. Finally, we derive a correction term for these independent agents,\ninspired by learning aware approaches, which reduces the variance in learning\nand helps them to converge to collective success more reliably. These results\nshow that credit assignment in multi-agent settings can be particularly\nchallenging in the presence of \"hidden gifts\", and demonstrate that learning\nawareness in independent agents can benefit these settings.','Dane Malenfant, Blake A. Richards','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20579v1'),('2505.20583v1','Balancing Performance and Costs in Best Arm Identification','We consider the problem of identifying the best arm in a multi-armed bandit\nmodel. Despite a wealth of literature in the traditional fixed budget and fixed\nconfidence regimes of the best arm identification problem, it still remains a\nmystery to most practitioners as to how to choose an approach and corresponding\nbudget or confidence parameter. We propose a new formalism to avoid this\ndilemma altogether by minimizing a risk functional which explicitly balances\nthe performance of the recommended arm and the cost incurred by learning this\narm. In this framework, a cost is incurred for each observation during the\nsampling phase, and upon recommending an arm, a performance penalty is incurred\nfor identifying a suboptimal arm. The learner\\\'s goal is to minimize the sum of\nthe penalty and cost. This new regime mirrors the priorities of many\npractitioners, e.g. maximizing profit in an A/B testing framework, better than\nclassical fixed budget or confidence settings. We derive theoretical lower\nbounds for the risk of each of two choices for the performance penalty, the\nprobability of misidentification and the simple regret, and propose an\nalgorithm called DBCARE to match these lower bounds up to polylog factors on\nnearly all problem instances. We then demonstrate the performance of DBCARE on\na number of simulated models, comparing to fixed budget and confidence\nalgorithms to show the shortfalls of existing BAI paradigms on this problem.','Michael O. Harding, Kirthevasan Kandasamy','2025-05-26','stat.ML','http://arxiv.org/pdf/2505.20583v1'),('2505.20589v1','Prot2Token: A Unified Framework for Protein Modeling via Next-Token Prediction','The diverse nature of protein prediction tasks has traditionally necessitated\nspecialized models, hindering the development of broadly applicable and\ncomputationally efficient Protein Language Models (PLMs). In this work, we\nintroduce Prot2Token, a unified framework that overcomes these challenges by\nconverting a wide spectrum of protein-related predictions, from sequence-level\nproperties and residue-specific attributes to complex inter-protein\ninteractions, into a standardized next-token prediction format. At its core,\nProt2Token employs an autoregressive decoder, conditioned on embeddings from\npre-trained protein encoders and guided by learnable task tokens, to perform\ndiverse predictions. This architecture uniquely facilitates multi-task\nlearning, enabling a single model to master numerous tasks with improved\nefficiency. We present extensive experimental validation across a variety of\nbenchmarks, demonstrating Prot2Tokens strong predictive power in different\ntypes of protein-prediction tasks. Key results include significant speedups\n(e.g., near 1000x over AlphaFold2 with MSA) and performance often matching or\nexceeding specialized approaches. Beyond that, we introduce an auxiliary\nself-supervised decoder pre-training approach to improve spatially sensitive\ntask performance. Prot2Token thus offers a significant step towards a\nversatile, high-throughput paradigm for protein modeling, promising to\naccelerate biological discovery and the development of novel therapeutics. The\ncode is available at https://github.com/mahdip72/prot2token .','Mahdi Pourmirzaei, Farzaneh Esmaili, Salhuldin Alqarghuli, Mohammadreza Pourmirzaei, Ye Han, Kai Chen, Mohsen Rezaei, Duolin Wang, Dong Xu','2025-05-26','cs.LG','http://arxiv.org/pdf/2505.20589v1'),('2505.20591v1','Effectiveness of Prompt Optimization in NL2SQL Systems','NL2SQL approaches have greatly benefited from the impressive capabilities of\nlarge language models (LLMs). In particular, bootstrapping an NL2SQL system for\na specific domain can be as simple as instructing an LLM with sufficient\ncontextual information, such as schema details and translation demonstrations.\nHowever, building an accurate system still requires the rigorous task of\nselecting the right context for each query-including identifying relevant\nschema elements, cell values, and suitable exemplars that help the LLM\nunderstand domain-specific nuances. Retrieval-based methods have become the\ngo-to approach for identifying such context. While effective, these methods\nintroduce additional inference-time costs due to the retrieval process.\n  In this paper, we argue that production scenarios demand high-precision,\nhigh-performance NL2SQL systems, rather than simply high-quality SQL\ngeneration, which is the focus of most current NL2SQL approaches. In such\nscenarios, the careful selection of a static set of exemplars-capturing the\nintricacies of the query log, target database, SQL constructs, and execution\nlatencies-plays a more crucial role than exemplar selection based solely on\nsimilarity. The key challenge, however, lies in identifying a representative\nset of exemplars for a given production setting. To this end, we propose a\nprompt optimization framework that not only addresses the high-precision\nrequirement but also optimizes the performance of the generated SQL through\nmulti-objective optimization. Preliminary empirical analysis demonstrates the\neffectiveness of the proposed framework.','Sairam Gurajada, Eser Kandogan, Sajjadur Rahman','2025-05-26','cs.CL','http://arxiv.org/pdf/2505.20591v1'),('2505.20600v1','InstGenIE: Generative Image Editing Made Efficient with Mask-aware Caching and Scheduling','Generative image editing using diffusion models has become a prevalent\napplication in today\\\'s AI cloud services. In production environments, image\nediting typically involves a mask that specifies the regions of an image\ntemplate to be edited. The use of masks provides direct control over the\nediting process and introduces sparsity in the model inference. In this paper,\nwe present InstGenIE, a system that efficiently serves image editing requests.\nThe key insight behind InstGenIE is that image editing only modifies the masked\nregions of image templates while preserving the original content in the\nunmasked areas. Driven by this insight, InstGenIE judiciously skips redundant\ncomputations associated with the unmasked areas by reusing cached intermediate\nactivations from previous inferences. To mitigate the high cache loading\noverhead, InstGenIE employs a bubble-free pipeline scheme that overlaps\ncomputation with cache loading. Additionally, to reduce queuing latency in\nonline serving while improving the GPU utilization, InstGenIE proposes a novel\ncontinuous batching strategy for diffusion model serving, allowing newly\narrived requests to join the running batch in just one step of denoising\ncomputation, without waiting for the entire batch to complete. As heterogeneous\nmasks induce imbalanced loads, InstGenIE also develops a load balancing\nstrategy that takes into account the loads of both computation and cache\nloading. Collectively, InstGenIE outperforms state-of-the-art diffusion serving\nsystems for image editing, achieving up to 3x higher throughput and reducing\naverage request latency by up to 14.7x while ensuring image quality.','Xiaoxiao Jiang, Suyi Li, Lingyun Yang, Tianyu Feng, Zhipeng Di, Weiyi Lu, Guoxuan Zhu, Xiu Lin, Kan Liu, Yinghao Yu, Tao Lan, Guodong Yang, Lin Qu, Liping Zhang, Wei Wang','2025-05-27','cs.DC','http://arxiv.org/pdf/2505.20600v1'),('2505.20606v1','Towards Pretraining Robust ASR Foundation Model with Acoustic-Aware Data Augmentation','Whisper\\\'s robust performance in automatic speech recognition (ASR) is often\nattributed to its massive 680k-hour training set, an impractical scale for most\nresearchers. In this work, we examine how linguistic and acoustic diversity in\ntraining data affect the robustness of the ASR model and reveal that\ntranscription generalization is primarily driven by acoustic variation rather\nthan linguistic richness. We find that targeted acoustic augmentation methods\ncould significantly improve the generalization ability of ASR models, reducing\nword-error rates by up to 19.24 percent on unseen datasets when training on the\n960-hour Librispeech dataset. These findings highlight strategic acoustically\nfocused data augmentation as a promising alternative to massive datasets for\nbuilding robust ASR models, offering a potential solution to future foundation\nASR models when massive human speech data is lacking.','Dancheng Liu, Amir Nassereldine, Chenhui Xu, Jinjun Xiong','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20606v1'),('2505.20609v1','Comparisons between a Large Language Model-based Real-Time Compound Diagnostic Medical AI Interface and Physicians for Common Internal Medicine Cases using Simulated Patients','Objective To develop an LLM based realtime compound diagnostic medical AI\ninterface and performed a clinical trial comparing this interface and\nphysicians for common internal medicine cases based on the United States\nMedical License Exam (USMLE) Step 2 Clinical Skill (CS) style exams. Methods A\nnonrandomized clinical trial was conducted on August 20, 2024. We recruited one\ngeneral physician, two internal medicine residents (2nd and 3rd year), and five\nsimulated patients. The clinical vignettes were adapted from the USMLE Step 2\nCS style exams. We developed 10 representative internal medicine cases based on\nactual patients and included information available on initial diagnostic\nevaluation. Primary outcome was the accuracy of the first differential\ndiagnosis. Repeatability was evaluated based on the proportion of agreement.\nResults The accuracy of the physicians\\\' first differential diagnosis ranged\nfrom 50% to 70%, whereas the realtime compound diagnostic medical AI interface\nachieved an accuracy of 80%. The proportion of agreement for the first\ndifferential diagnosis was 0.7. The accuracy of the first and second\ndifferential diagnoses ranged from 70% to 90% for physicians, whereas the AI\ninterface achieved an accuracy rate of 100%. The average time for the AI\ninterface (557 sec) was 44.6% shorter than that of the physicians (1006 sec).\nThe AI interface ($0.08) also reduced costs by 98.1% compared to the\nphysicians\\\' average ($4.2). Patient satisfaction scores ranged from 4.2 to 4.3\nfor care by physicians and were 3.9 for the AI interface Conclusion An LLM\nbased realtime compound diagnostic medical AI interface demonstrated diagnostic\naccuracy and patient satisfaction comparable to those of a physician, while\nrequiring less time and lower costs. These findings suggest that AI interfaces\nmay have the potential to assist primary care consultations for common internal\nmedicine cases.','Hyungjun Park, Chang-Yun Woo, Seungjo Lim, Seunghwan Lim, Keunho Kwak, Ju Young Jeong, Chong Hyun Suh','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20609v1'),('2505.20612v1','Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models','Vision-language models (VLMs) trained on internet-scale data achieve\nremarkable zero-shot detection performance on common objects like car, truck,\nand pedestrian. However, state-of-the-art models still struggle to generalize\nto out-of-distribution classes, tasks and imaging modalities not typically\nfound in their pre-training. Rather than simply re-training VLMs on more visual\ndata, we argue that one should align VLMs to new concepts with annotation\ninstructions containing a few visual examples and rich textual descriptions. To\nthis end, we introduce Roboflow100-VL, a large-scale collection of 100\nmulti-modal object detection datasets with diverse concepts not commonly found\nin VLM pre-training. We evaluate state-of-the-art models on our benchmark in\nzero-shot, few-shot, semi-supervised, and fully-supervised settings, allowing\nfor comparison across data regimes. Notably, we find that VLMs like\nGroundingDINO and Qwen2.5-VL achieve less than 2% zero-shot accuracy on\nchallenging medical imaging datasets within Roboflow100-VL, demonstrating the\nneed for few-shot concept alignment. Our code and dataset are available at\nhttps://github.com/roboflow/rf100-vl/ and\nhttps://universe.roboflow.com/rf100-vl/','Peter Robicheaux, Matvei Popov, Anish Madan, Isaac Robinson, Joseph Nelson, Deva Ramanan, Neehar Peri','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20612v1'),('2505.20613v1','REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning','Nowadays, formal theorem provers have made monumental progress on high-school\nand competition-level mathematics, but few of them generalize to more advanced\nmathematics. In this paper, we present REAL-Prover, a new open-source stepwise\ntheorem prover for Lean 4 to push this boundary. This prover, based on our\nfine-tuned large language model (REAL-Prover-v1) and integrated with a\nretrieval system (Leansearch-PS), notably boosts performance on solving\ncollege-level mathematics problems. To train REAL-Prover-v1, we developed\nHERALD-AF, a data extraction pipeline that converts natural language math\nproblems into formal statements, and a new open-source Lean 4 interactive\nenvironment (Jixia-interactive) to facilitate synthesis data collection. In our\nexperiments, our prover using only supervised fine-tune achieves competitive\nresults with a 23.7% success rate (Pass@64) on the ProofNet dataset-comparable\nto state-of-the-art (SOTA) models. To further evaluate our approach, we\nintroduce FATE-M, a new benchmark focused on algebraic problems, where our\nprover achieves a SOTA success rate of 56.7% (Pass@64).','Ziju Shen, Naohao Huang, Fanyi Yang, Yutong Wang, Guoxiong Gao, Tianyi Xu, Jiedong Jiang, Wanyi He, Pu Yang, Mengzhou Sun, Haocheng Ju, Peihao Wu, Bryan Dai, Bin Dong','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20613v1'),('2505.20615v1','Intelligent Incident Hypertension Prediction in Obstructive Sleep Apnea','Obstructive sleep apnea (OSA) is a significant risk factor for hypertension,\nprimarily due to intermittent hypoxia and sleep fragmentation. Predicting\nwhether individuals with OSA will develop hypertension within five years\nremains a complex challenge. This study introduces a novel deep learning\napproach that integrates Discrete Cosine Transform (DCT)-based transfer\nlearning to enhance prediction accuracy. We are the first to incorporate all\npolysomnography signals together for hypertension prediction, leveraging their\ncollective information to improve model performance. Features were extracted\nfrom these signals and transformed into a 2D representation to utilize\npre-trained 2D neural networks such as MobileNet, EfficientNet, and ResNet\nvariants. To further improve feature learning, we introduced a DCT layer, which\ntransforms input features into a frequency-based representation, preserving\nessential spectral information, decorrelating features, and enhancing\nrobustness to noise. This frequency-domain approach, coupled with transfer\nlearning, is especially beneficial for limited medical datasets, as it\nleverages rich representations from pre-trained networks to improve\ngeneralization. By strategically placing the DCT layer at deeper truncation\ndepths within EfficientNet, our model achieved a best area under the curve\n(AUC) of 72.88%, demonstrating the effectiveness of frequency-domain feature\nextraction and transfer learning in predicting hypertension risk in OSA\npatients over a five-year period.','Omid Halimi Milani, Ahmet Enis Cetin, Bharati Prasad','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20615v1'),('2505.20621v1','Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning','Similar to other machine learning frameworks, Offline Reinforcement Learning\n(RL) is shown to be vulnerable to poisoning attacks, due to its reliance on\nexternally sourced datasets, a vulnerability that is exacerbated by its\nsequential nature. To mitigate the risks posed by RL poisoning, we extend\ncertified defenses to provide larger guarantees against adversarial\nmanipulation, ensuring robustness for both per-state actions, and the overall\nexpected cumulative reward. Our approach leverages properties of Differential\nPrivacy, in a manner that allows this work to span both continuous and discrete\nspaces, as well as stochastic and deterministic environments -- significantly\nexpanding the scope and applicability of achievable guarantees. Empirical\nevaluations demonstrate that our approach ensures the performance drops to no\nmore than $50\\%$ with up to $7\\%$ of the training data poisoned, significantly\nimproving over the $0.008\\%$ in prior work~\\citep{wu_copa_2022}, while\nproducing certified radii that is $5$ times larger as well. This highlights the\npotential of our framework to enhance safety and reliability in offline RL.','Shijie Liu, Andrew C. Cullen, Paul Montague, Sarah Erfani, Benjamin I. P. Rubinstein','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20621v1'),('2505.20622v1','SeqPO-SiMT: Sequential Policy Optimization for Simultaneous Machine Translation','We present Sequential Policy Optimization for Simultaneous Machine\nTranslation (SeqPO-SiMT), a new policy optimization framework that defines the\nsimultaneous machine translation (SiMT) task as a sequential decision making\nproblem, incorporating a tailored reward to enhance translation quality while\nreducing latency. In contrast to popular Reinforcement Learning from Human\nFeedback (RLHF) methods, such as PPO and DPO, which are typically applied in\nsingle-step tasks, SeqPO-SiMT effectively tackles the multi-step SiMT task.\nThis intuitive framework allows the SiMT LLMs to simulate and refine the SiMT\nprocess using a tailored reward. We conduct experiments on six datasets from\ndiverse domains for En to Zh and Zh to En SiMT tasks, demonstrating that\nSeqPO-SiMT consistently achieves significantly higher translation quality with\nlower latency. In particular, SeqPO-SiMT outperforms the supervised fine-tuning\n(SFT) model by 1.13 points in COMET, while reducing the Average Lagging by 6.17\nin the NEWSTEST2021 En to Zh dataset. While SiMT operates with far less context\nthan offline translation, the SiMT results of SeqPO-SiMT on 7B LLM surprisingly\nrival the offline translation of high-performing LLMs, including\nQwen-2.5-7B-Instruct and LLaMA-3-8B-Instruct.','Ting Xu, Zhichao Huang, Jiankai Sun, Shanbo Cheng, Wai Lam','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20622v1'),('2505.20624v1','POLAR: A Benchmark for Multilingual, Multicultural, and Multi-Event Online Polarization','Online polarization poses a growing challenge for democratic discourse, yet\nmost computational social science research remains monolingual, culturally\nnarrow, or event-specific. We introduce POLAR, a multilingual, multicultural,\nand multievent dataset with over 23k instances in seven languages from diverse\nonline platforms and real-world events. Polarization is annotated along three\naxes: presence, type, and manifestation, using a variety of annotation\nplatforms adapted to each cultural context. We conduct two main experiments:\n(1) we fine-tune six multilingual pretrained language models in both\nmonolingual and cross-lingual setups; and (2) we evaluate a range of open and\nclosed large language models (LLMs) in few-shot and zero-shot scenarios.\nResults show that while most models perform well on binary polarization\ndetection, they achieve substantially lower scores when predicting polarization\ntypes and manifestations. These findings highlight the complex, highly\ncontextual nature of polarization and the need for robust, adaptable approaches\nin NLP and computational social science. All resources will be released to\nsupport further research and effective mitigation of digital polarization\nglobally.','Usman Naseem, Juan Ren, Saba Anwar, Sarah Kohail, Rudy Alexandro Garrido Veliz, Robert Geislinger, Aisha Jabr, Idris Abdulmumin, Laiba Qureshi, Aarushi Ajay Borkar, Maryam Ibrahim Mukhtar, Abinew Ali Ayele, Ibrahim Said Ahmad, Adem Ali, Martin Semmann, Shamsuddeen Hassan Muhammad, Seid Muhie Yimam','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20624v1'),('2505.20625v1','Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration','Processing long contexts has become a critical capability for modern large\nlanguage models (LLMs). Existing works leverage agent-based divide-and-conquer\nmethods for processing long contexts. But these methods face crucial\nlimitations, including prohibitive accumulated latency and amplified\ninformation loss from excessive agent invocations, and the disruption of\ninherent textual dependencies by immoderate partitioning. In this paper, we\npropose a novel multi-agent framework XpandA (Expand-Agent) coupled with\nquestion-driven workflow and dynamic partitioning for robust long-context\nprocessing. XpandA overcomes these limitations through: 1) dynamic partitioning\nof long texts, which adaptively modulates the filling rate of context windows\nfor input sequences of vastly varying lengths; 2) question-guided protocol to\nupdate flat information ensembles within centralized shared memory,\nconstructing consistent inter-agent knowledge across partitions; and 3)\nselectively replaying specific partitions based on the state-tracking of\nquestion-information couples to promote the resolution of inverted-order\nstructures across partitions (e.g., flashbacks). We perform a comprehensive\nevaluation of XpandA on multiple long-context benchmarks with length varying\nfrom 1k to 1M, demonstrating XpandA\\\'s feasibility for processing ultra-long\nsequences and its significant effectiveness in enhancing the long-context\ncapabilities of various LLMs by achieving 20\\% improvements and 1.5x inference\nspeedup over baselines of full-context, RAG and previous agent-based methods.','Sibo Xiao, Zixin Lin, Wenyang Gao, Yue Zhang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20625v1'),('2505.20627v1','Fundamental Limits of Game-Theoretic LLM Alignment: Smith Consistency and Preference Matching','Nash Learning from Human Feedback is a game-theoretic framework for aligning\nlarge language models (LLMs) with human preferences by modeling learning as a\ntwo-player zero-sum game. However, using raw preference as the payoff in the\ngame highly limits the potential of the game-theoretic LLM alignment framework.\nIn this paper, we systematically study using what choices of payoff based on\nthe pairwise human preferences can yield desirable alignment properties. We\nestablish necessary and sufficient conditions for Condorcet consistency,\ndiversity through mixed strategies, and Smith consistency. These results\nprovide a theoretical foundation for the robustness of game-theoretic LLM\nalignment. Further, we show the impossibility of preference matching -- i.e.,\nno smooth and learnable mappings of pairwise preferences can guarantee a unique\nNash equilibrium that matches a target policy, even under standard assumptions\nlike the Bradley-Terry-Luce model. This result highlights the fundamental\nlimitation of game-theoretic LLM alignment.','Zhekun Shi, Kaizhao Liu, Qi Long, Weijie J. Su, Jiancong Xiao','2025-05-27','cs.GT','http://arxiv.org/pdf/2505.20627v1'),('2505.20628v1','Position: Adopt Constraints Over Penalties in Deep Learning','Recent efforts toward developing trustworthy AI systems with accountability\nguarantees have led to a growing reliance on machine learning formulations that\nincorporate external requirements, or constraints. These requirements are often\nenforced through penalization--adding fixed-weight terms to the task loss. We\nargue that this approach is ill-suited, and that tailored constrained\noptimization methods should be adopted instead. In particular, no penalty\ncoefficient may yield a solution that both satisfies the constraints and\nachieves good performance--i.e., one solving the constrained problem. Moreover,\ntuning these coefficients is costly, incurring significant time and\ncomputational overhead. In contrast, tailored constrained methods--such as the\nLagrangian approach, which optimizes the penalization \"coefficients\" (the\nLagrange multipliers) alongside the model--(i) truly solve the constrained\nproblem and add accountability, (ii) eliminate the need for extensive penalty\ntuning, and (iii) integrate seamlessly with modern deep learning pipelines.','Juan Ramirez, Meraj Hashemizadeh, Simon Lacoste-Julien','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20628v1'),('2505.20629v1','Incorporating Flexible Image Conditioning into Text-to-Video Diffusion Models without Training','Text-image-to-video (TI2V) generation is a critical problem for controllable\nvideo generation using both semantic and visual conditions. Most existing\nmethods typically add visual conditions to text-to-video (T2V) foundation\nmodels by finetuning, which is costly in resources and only limited to a few\npredefined conditioning settings. To tackle this issue, we introduce a unified\nformulation for TI2V generation with flexible visual conditioning. Furthermore,\nwe propose an innovative training-free approach, dubbed FlexTI2V, that can\ncondition T2V foundation models on an arbitrary amount of images at arbitrary\npositions. Specifically, we firstly invert the condition images to noisy\nrepresentation in a latent space. Then, in the denoising process of T2V models,\nour method uses a novel random patch swapping strategy to incorporate visual\nfeatures into video representations through local image patches. To balance\ncreativity and fidelity, we use a dynamic control mechanism to adjust the\nstrength of visual conditioning to each video frame. Extensive experiments\nvalidate that our method surpasses previous training-free image conditioning\nmethods by a notable margin. We also show more insights of our method by\ndetailed ablation study and analysis.','Bolin Lai, Sangmin Lee, Xu Cao, Xiang Li, James M. Rehg','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20629v1'),('2505.20630v1','SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis','As Large Language Models (LLMs) evolve in understanding and generating code,\naccurately evaluating their reliability in analyzing source code\nvulnerabilities becomes increasingly vital. While studies have examined LLM\ncapabilities in tasks like vulnerability detection and repair, they often\noverlook the importance of both structure and semantic reasoning crucial for\ntrustworthy vulnerability analysis. To address this gap, we introduce\nSV-TrustEval-C, a benchmark designed to evaluate LLMs\\\' abilities for\nvulnerability analysis of code written in the C programming language through\ntwo key dimensions: structure reasoning - assessing how models identify\nrelationships between code elements under varying data and control flow\ncomplexities; and semantic reasoning - examining their logical consistency in\nscenarios where code is structurally and semantically perturbed. Our results\nshow that current LLMs are far from satisfactory in understanding complex code\nrelationships and that their vulnerability analyses rely more on pattern\nmatching than on robust logical reasoning. These findings underscore the\neffectiveness of the SV-TrustEval-C benchmark and highlight critical areas for\nenhancing the reasoning capabilities and trustworthiness of LLMs in real-world\nvulnerability analysis tasks. Our initial benchmark dataset is publicly\navailable.','Yansong Li, Paula Branco, Alexander M. Hoole, Manish Marwah, Hari Manassery Koduvely, Guy-Vincent Jourdan, Stephan Jou','2025-05-27','cs.SE','http://arxiv.org/pdf/2505.20630v1'),('2505.20633v1','Test-Time Learning for Large Language Models','While Large Language Models (LLMs) have exhibited remarkable emergent\ncapabilities through extensive pre-training, they still face critical\nlimitations in generalizing to specialized domains and handling diverse\nlinguistic variations, known as distribution shifts. In this paper, we propose\na Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically\nadapts LLMs to target domains using only unlabeled test data during testing.\nSpecifically, we first provide empirical evidence and theoretical insights to\nreveal that more accurate predictions from LLMs can be achieved by minimizing\nthe input perplexity of the unlabeled test data. Based on this insight, we\nformulate the Test-Time Learning process of LLMs as input perplexity\nminimization, enabling self-supervised enhancement of LLM performance.\nFurthermore, we observe that high-perplexity samples tend to be more\ninformative for model optimization. Accordingly, we introduce a Sample\nEfficient Learning Strategy that actively selects and emphasizes these\nhigh-perplexity samples for test-time updates. Lastly, to mitigate catastrophic\nforgetting and ensure adaptation stability, we adopt Low-Rank Adaptation (LoRA)\ninstead of full-parameter optimization, which allows lightweight model updates\nwhile preserving more original knowledge from the model. We introduce the\nAdaptEval benchmark for TTL and demonstrate through experiments that TLM\nimproves performance by at least 20% compared to original LLMs on domain\nknowledge adaptation.','Jinwu Hu, Zhitian Zhang, Guohao Chen, Xutao Wen, Chao Shuai, Wei Luo, Bin Xiao, Yuanqing Li, Mingkui Tan','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20633v1'),('2505.20634v1','Explaining Concept Shift with Interpretable Feature Attribution','Regardless the amount of data a machine learning (ML) model is trained on,\nthere will inevitably be data that differs from their training set, lowering\nmodel performance. Concept shift occurs when the distribution of labels\nconditioned on the features changes, making even a well-tuned ML model to have\nlearned a fundamentally incorrect representation. Identifying these shifted\nfeatures provides unique insight into how one dataset differs from another,\nconsidering the difference may be across a scientifically relevant dimension,\nsuch as time, disease status, population, etc. In this paper, we propose\nSGShift, a model for detecting concept shift in tabular data and attributing\nreduced model performance to a sparse set of shifted features. SGShift models\nconcept shift with a Generalized Additive Model (GAM) and performs subsequent\nfeature selection to identify shifted features. We propose further extensions\nof SGShift by incorporating knockoffs to control false discoveries and an\nabsorption term to account for models with poor fit to the data. We conduct\nextensive experiments in synthetic and real data across various ML models and\nfind SGShift can identify shifted features with AUC $>0.9$ and recall $>90\\%$,\noften 2 or 3 times as high as baseline methods.','Ruiqi Lyu, Alistair Turcan, Bryan Wilder','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20634v1'),('2505.20635v1','Plug-and-Play Co-Occurring Face Attention for Robust Audio-Visual Speaker Extraction','Audio-visual speaker extraction isolates a target speaker\\\'s speech from a\nmixture speech signal conditioned on a visual cue, typically using the target\nspeaker\\\'s face recording. However, in real-world scenarios, other co-occurring\nfaces are often present on-screen, providing valuable speaker activity cues in\nthe scene. In this work, we introduce a plug-and-play inter-speaker attention\nmodule to process these flexible numbers of co-occurring faces, allowing for\nmore accurate speaker extraction in complex multi-person environments. We\nintegrate our module into two prominent models: the AV-DPRNN and the\nstate-of-the-art AV-TFGridNet. Extensive experiments on diverse datasets,\nincluding the highly overlapped VoxCeleb2 and sparsely overlapped MISP,\ndemonstrate that our approach consistently outperforms baselines. Furthermore,\ncross-dataset evaluations on LRS2 and LRS3 confirm the robustness and\ngeneralizability of our method.','Zexu Pan, Shengkui Zhao, Tingting Wang, Kun Zhou, Yukun Ma, Chong Zhang, Bin Ma','2025-05-27','eess.AS','http://arxiv.org/pdf/2505.20635v1'),('2505.20637v1','TrustSkin: A Fairness Pipeline for Trustworthy Facial Affect Analysis Across Skin Tone','Understanding how facial affect analysis (FAA) systems perform across\ndifferent demographic groups requires reliable measurement of sensitive\nattributes such as ancestry, often approximated by skin tone, which itself is\nhighly influenced by lighting conditions. This study compares two objective\nskin tone classification methods: the widely used Individual Typology Angle\n(ITA) and a perceptually grounded alternative based on Lightness ($L^*$) and\nHue ($H^*$). Using AffectNet and a MobileNet-based model, we assess fairness\nacross skin tone groups defined by each method. Results reveal a severe\nunderrepresentation of dark skin tones ($\\sim 2 \\%$), alongside fairness\ndisparities in F1-score (up to 0.08) and TPR (up to 0.11) across groups. While\nITA shows limitations due to its sensitivity to lighting, the $H^*$-$L^*$\nmethod yields more consistent subgrouping and enables clearer diagnostics\nthrough metrics such as Equal Opportunity. Grad-CAM analysis further highlights\ndifferences in model attention patterns by skin tone, suggesting variation in\nfeature encoding. To support future mitigation efforts, we also propose a\nmodular fairness-aware pipeline that integrates perceptual skin tone\nestimation, model interpretability, and fairness evaluation. These findings\nemphasize the relevance of skin tone measurement choices in fairness assessment\nand suggest that ITA-based evaluations may overlook disparities affecting\ndarker-skinned individuals.','Ana M. Cabanas, Alma Pedro, Domingo Mery','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20637v1'),('2505.20642v1','CoderAgent: Simulating Student Behavior for Personalized Programming Learning with Large Language Models','Personalized programming tutoring, such as exercise recommendation, can\nenhance learners\\\' efficiency, motivation, and outcomes, which is increasingly\nimportant in modern digital education. However, the lack of sufficient and\nhigh-quality programming data, combined with the mismatch between offline\nevaluation and real-world learning, hinders the practical deployment of such\nsystems. To address this challenge, many approaches attempt to simulate learner\npractice data, yet they often overlook the fine-grained, iterative nature of\nprogramming learning, resulting in a lack of interpretability and granularity.\nTo fill this gap, we propose a LLM-based agent, CoderAgent, to simulate\nstudents\\\' programming processes in a fine-grained manner without relying on\nreal data. Specifically, we equip each human learner with an intelligent agent,\nthe core of which lies in capturing the cognitive states of the human\nprogramming practice process. Inspired by ACT-R, a cognitive architecture\nframework, we design the structure of CoderAgent to align with human cognitive\narchitecture by focusing on the mastery of programming knowledge and the\napplication of coding ability. Recognizing the inherent patterns in\nmulti-layered cognitive reasoning, we introduce the Programming Tree of Thought\n(PTOT), which breaks down the process into four steps: why, how, where, and\nwhat. This approach enables a detailed analysis of iterative problem-solving\nstrategies. Finally, experimental evaluations on real-world datasets\ndemonstrate that CoderAgent provides interpretable insights into learning\ntrajectories and achieves accurate simulations, paving the way for personalized\nprogramming education.','Yi Zhan, Qi Liu, Weibo Gao, Zheng Zhang, Tianfu Wang, Shuanghong Shen, Junyu Lu, Zhenya Huang','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20642v1'),('2505.20643v1','Can Past Experience Accelerate LLM Reasoning?','Allocating more compute to large language models (LLMs) reasoning has\ngenerally been demonstrated to improve their effectiveness, but also results in\nincreased inference time. In contrast, humans can perform tasks faster and\nbetter with increased experience and exposure. Hence, this paper aims to\ninvestigate the question: Can LLMs also become faster at reasoning through\nrecurrent exposure on relevant tasks, and if so, how can it be achieved? To\naddress these questions, we first formalize the problem setting of LLM\nreasoning speedup systematically in the dimensions of task relevancy and\ncompute budget calculation. We then propose SpeedupLLM, a theoretically\nguaranteed framework to implement and benchmark such reasoning speedup\nbehaviour based on adaptive compute allocation and memory mechanisms. We\nfurther conduct comprehensive experiments to benchmark such behaviour across\ndifferent question similarity levels, memory methods, and reasoning methods.\nResults show that LLMs can generally reason faster with past experience,\nachieving up to a 56% reduction in compute cost when equipped with appropriate\nmemory and reasoning methods.','Bo Pan, Liang Zhao','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20643v1'),('2505.20644v1','HCQA-1.5 @ Ego4D EgoSchema Challenge 2025','In this report, we present the method that achieves third place for Ego4D\nEgoSchema Challenge in CVPR 2025. To improve the reliability of answer\nprediction in egocentric video question answering, we propose an effective\nextension to the previously proposed HCQA framework. Our approach introduces a\nmulti-source aggregation strategy to generate diverse predictions, followed by\na confidence-based filtering mechanism that selects high-confidence answers\ndirectly. For low-confidence cases, we incorporate a fine-grained reasoning\nmodule that performs additional visual and contextual analysis to refine the\npredictions. Evaluated on the EgoSchema blind test set, our method achieves 77%\naccuracy on over 5,000 human-curated multiple-choice questions, outperforming\nlast year\\\'s winning solution and the majority of participating teams. Our code\nwill be added at https://github.com/Hyu-Zhang/HCQA.','Haoyu Zhang, Yisen Feng, Qiaohui Chu, Meng Liu, Weili Guan, Yaowei Wang, Liqiang Nie','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20644v1'),('2505.20645v1','STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models','Steerability, or the ability of large language models (LLMs) to adapt outputs\nto align with diverse community-specific norms, perspectives, and communication\nstyles, is critical for real-world applications but remains under-evaluated. We\nintroduce Steer-Bench, a benchmark for assessing population-specific steering\nusing contrasting Reddit communities. Covering 30 contrasting subreddit pairs\nacross 19 domains, Steer-Bench includes over 10,000 instruction-response pairs\nand validated 5,500 multiple-choice question with corresponding silver labels\nto test alignment with diverse community norms. Our evaluation of 13 popular\nLLMs using Steer-Bench reveals that while human experts achieve an accuracy of\n81% with silver labels, the best-performing models reach only around 65%\naccuracy depending on the domain and configuration. Some models lag behind\nhuman-level alignment by over 15 percentage points, highlighting significant\ngaps in community-sensitive steerability. Steer-Bench is a benchmark to\nsystematically assess how effectively LLMs understand community-specific\ninstructions, their resilience to adversarial steering attempts, and their\nability to accurately represent diverse cultural and ideological perspectives.','Kai Chen, Zihao He, Taiwei Shi, Kristina Lerman','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20645v1'),('2505.20646v1','Evaluating Training in Binarized Neural Networks Through the Lens of Algorithmic Information Theory','Understanding and controlling the informational complexity of neural networks\nis a central challenge in machine learning, with implications for\ngeneralization, optimization, and model capacity. While most approaches rely on\nentropy-based loss functions and statistical metrics, these measures often fail\nto capture deeper, causally relevant algorithmic regularities embedded in\nnetwork structure. We propose a shift toward algorithmic information theory,\nusing Binarized Neural Networks (BNNs) as a first proxy. Grounded in\nalgorithmic probability (AP) and the universal distribution it defines, our\napproach characterizes learning dynamics through a formal, causally grounded\nlens. We apply the Block Decomposition Method (BDM) -- a scalable approximation\nof algorithmic complexity based on AP -- and demonstrate that it more closely\ntracks structural changes during training than entropy, consistently exhibiting\nstronger correlations with training loss across varying model sizes and\nrandomized training runs. These results support the view of training as a\nprocess of algorithmic compression, where learning corresponds to the\nprogressive internalization of structured regularities. In doing so, our work\noffers a principled estimate of learning progression and suggests a framework\nfor complexity-aware learning and regularization, grounded in first principles\nfrom information theory, complexity, and computability.','Eduardo Y. Sakabe, Felipe S. Abrahão, Alexandre Simões, Esther Colombini, Paula Costa, Ricardo Gudwin, Hector Zenil','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20646v1'),('2505.20647v1','Moment Expansions of the Energy Distance','The energy distance is used to test distributional equality, and as a loss\nfunction in machine learning. While $D^2(X, Y)=0$ only when $X\\sim Y$, the\nsensitivity to different moments is of practical importance. This work\nconsiders $D^2(X, Y)$ in the case where the distributions are close. In this\nregime, $D^2(X, Y)$ is more sensitive to differences in the means\n$\\bar{X}-\\bar{Y}$, than differences in the covariances $\\Delta$. This is due to\nthe structure of the energy distance and is independent of dimension. The\nsensitivity to on versus off diagonal components of $\\Delta$ is examined when\n$X$ and $Y$ are close to isotropic. Here a dimension dependent averaging occurs\nand, in many cases, off diagonal correlations contribute significantly less.\nNumerical results verify these relationships hold even when distributional\nassumptions are not strictly met.','Ian Langmore','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.20647v1'),('2505.20648v1','Voronoi-grid-based Pareto Front Learning and Its Application to Collaborative Federated Learning','Multi-objective optimization (MOO) exists extensively in machine learning,\nand aims to find a set of Pareto-optimal solutions, called the Pareto front,\ne.g., it is fundamental for multiple avenues of research in federated learning\n(FL). Pareto-Front Learning (PFL) is a powerful method implemented using\nHypernetworks (PHNs) to approximate the Pareto front. This method enables the\nacquisition of a mapping function from a given preference vector to the\nsolutions on the Pareto front. However, most existing PFL approaches still face\ntwo challenges: (a) sampling rays in high-dimensional spaces; (b) failing to\ncover the entire Pareto Front which has a convex shape. Here, we introduce a\nnovel PFL framework, called as PHN-HVVS, which decomposes the design space into\nVoronoi grids and deploys a genetic algorithm (GA) for Voronoi grid\npartitioning within high-dimensional space. We put forward a new loss function,\nwhich effectively contributes to more extensive coverage of the resultant\nPareto front and maximizes the HV Indicator. Experimental results on multiple\nMOO machine learning tasks demonstrate that PHN-HVVS outperforms the baselines\nsignificantly in generating Pareto front. Also, we illustrate that PHN-HVVS\nadvances the methodologies of several recent problems in the FL field. The code\nis available at\nhttps://github.com/buptcmm/phnhvvs}{https://github.com/buptcmm/phnhvvs.','Mengmeng Chen, Xiaohu Wu, Qiqi Liu, Tiantian He, Yew-Soon Ong, Yaochu Jin, Qicheng Lao, Han Yu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20648v1'),('2505.20650v1','FinTagging: An LLM-ready Benchmark for Extracting and Structuring Financial Information','We introduce FinTagging, the first full-scope, table-aware XBRL benchmark\ndesigned to evaluate the structured information extraction and semantic\nalignment capabilities of large language models (LLMs) in the context of\nXBRL-based financial reporting. Unlike prior benchmarks that oversimplify XBRL\ntagging as flat multi-class classification and focus solely on narrative text,\nFinTagging decomposes the XBRL tagging problem into two subtasks: FinNI for\nfinancial entity extraction and FinCL for taxonomy-driven concept alignment. It\nrequires models to jointly extract facts and align them with the full 10k+\nUS-GAAP taxonomy across both unstructured text and structured tables, enabling\nrealistic, fine-grained evaluation. We assess a diverse set of LLMs under\nzero-shot settings, systematically analyzing their performance on both subtasks\nand overall tagging accuracy. Our results reveal that, while LLMs demonstrate\nstrong generalization in information extraction, they struggle with\nfine-grained concept alignment, particularly in disambiguating closely related\ntaxonomy entries. These findings highlight the limitations of existing LLMs in\nfully automating XBRL tagging and underscore the need for improved semantic\nreasoning and schema-aware modeling to meet the demands of accurate financial\ndisclosure. Code is available at our GitHub repository and data is at our\nHugging Face repository.','Yan Wang, Yang Ren, Lingfei Qian, Xueqing Peng, Keyi Wang, Yi Han, Dongji Feng, Xiao-Yang Liu, Jimin Huang, Qianqian Xie','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20650v1'),('2505.20653v1','RoGA: Towards Generalizable Deepfake Detection through Robust Gradient Alignment','Recent advancements in domain generalization for deepfake detection have\nattracted significant attention, with previous methods often incorporating\nadditional modules to prevent overfitting to domain-specific patterns. However,\nsuch regularization can hinder the optimization of the empirical risk\nminimization (ERM) objective, ultimately degrading model performance. In this\npaper, we propose a novel learning objective that aligns generalization\ngradient updates with ERM gradient updates. The key innovation is the\napplication of perturbations to model parameters, aligning the ascending points\nacross domains, which specifically enhances the robustness of deepfake\ndetection models to domain shifts. This approach effectively preserves\ndomain-invariant features while managing domain-specific characteristics,\nwithout introducing additional regularization. Experimental results on multiple\nchallenging deepfake detection datasets demonstrate that our gradient alignment\nstrategy outperforms state-of-the-art domain generalization techniques,\nconfirming the efficacy of our method. The code is available at\nhttps://github.com/Lynn0925/RoGA.','Lingyu Qiu, Ke Jiang, Xiaoyang Tan','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20653v1'),('2505.20654v1','Chinese Cyberbullying Detection: Dataset, Method, and Validation','Existing cyberbullying detection benchmarks were organized by the polarity of\nspeech, such as \"offensive\" and \"non-offensive\", which were essentially hate\nspeech detection. However, in the real world, cyberbullying often attracted\nwidespread social attention through incidents. To address this problem, we\npropose a novel annotation method to construct a cyberbullying dataset that\norganized by incidents. The constructed CHNCI is the first Chinese\ncyberbullying incident detection dataset, which consists of 220,676 comments in\n91 incidents. Specifically, we first combine three cyberbullying detection\nmethods based on explanations generation as an ensemble method to generate the\npseudo labels, and then let human annotators judge these labels. Then we\npropose the evaluation criteria for validating whether it constitutes a\ncyberbullying incident. Experimental results demonstrate that the constructed\ndataset can be a benchmark for the tasks of cyberbullying detection and\nincident prediction. To the best of our knowledge, this is the first study for\nthe Chinese cyberbullying incident detection task.','Yi Zhu, Xin Zou, Xindong Wu','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20654v1'),('2505.20658v1','Enhancing Transformation from Natural Language to Signal Temporal Logic Using LLMs with Diverse External Knowledge','Temporal Logic (TL), especially Signal Temporal Logic (STL), enables precise\nformal specification, making it widely used in cyber-physical systems such as\nautonomous driving and robotics. Automatically transforming NL into STL is an\nattractive approach to overcome the limitations of manual transformation, which\nis time-consuming and error-prone. However, due to the lack of datasets,\nautomatic transformation currently faces significant challenges and has not\nbeen fully explored. In this paper, we propose an NL-STL dataset named\nSTL-Diversity-Enhanced (STL-DivEn), which comprises 16,000 samples enriched\nwith diverse patterns. To develop the dataset, we first manually create a\nsmall-scale seed set of NL-STL pairs. Next, representative examples are\nidentified through clustering and used to guide large language models (LLMs) in\ngenerating additional NL-STL pairs. Finally, diversity and accuracy are ensured\nthrough rigorous rule-based filters and human validation. Furthermore, we\nintroduce the Knowledge-Guided STL Transformation (KGST) framework, a novel\napproach for transforming natural language into STL, involving a\ngenerate-then-refine process based on external knowledge. Statistical analysis\nshows that the STL-DivEn dataset exhibits more diversity than the existing\nNL-STL dataset. Moreover, both metric-based and human evaluations indicate that\nour KGST approach outperforms baseline models in transformation accuracy on\nSTL-DivEn and DeepSTL datasets.','Yue Fang, Zhi Jin, Jie An, Hongshen Chen, Xiaohong Chen, Naijun Zhan','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20658v1'),('2505.20659v1','An Optimisation Framework for Unsupervised Environment Design','For reinforcement learning agents to be deployed in high-risk settings, they\nmust achieve a high level of robustness to unfamiliar scenarios. One method for\nimproving robustness is unsupervised environment design (UED), a suite of\nmethods aiming to maximise an agent\\\'s generalisability across configurations of\nan environment. In this work, we study UED from an optimisation perspective,\nproviding stronger theoretical guarantees for practical settings than prior\nwork. Whereas previous methods relied on guarantees if they reach convergence,\nour framework employs a nonconvex-strongly-concave objective for which we\nprovide a provably convergent algorithm in the zero-sum setting. We empirically\nverify the efficacy of our method, outperforming prior methods in a number of\nenvironments with varying difficulties.','Nathan Monette, Alistair Letcher, Michael Beukman, Matthew T. Jackson, Alexander Rutherford, Alexander D. Goldie, Jakob N. Foerster','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20659v1'),('2505.20660v1','BacktrackAgent: Enhancing GUI Agent with Error Detection and Backtracking Mechanism','Graphical User Interface (GUI) agents have gained substantial attention due\nto their impressive capabilities to complete tasks through multiple\ninteractions within GUI environments. However, existing agents primarily focus\non enhancing the accuracy of individual actions and often lack effective\nmechanisms for detecting and recovering from errors. To address these\nshortcomings, we propose the BacktrackAgent, a robust framework that\nincorporates a backtracking mechanism to improve task completion efficiency.\nBacktrackAgent includes verifier, judger, and reflector components as modules\nfor error detection and recovery, while also applying judgment rewards to\nfurther enhance the agent\\\'s performance. Additionally, we develop a training\ndataset specifically designed for the backtracking mechanism, which considers\nthe outcome pages after action executions. Experimental results show that\nBacktrackAgent has achieved performance improvements in both task success rate\nand step accuracy on Mobile3M and Auto-UI benchmarks. Our data and code will be\nreleased upon acceptance.','Qinzhuo Wu, Pengzhi Gao, Wei Liu, Jian Luan','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20660v1'),('2505.20662v1','AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage','Efficient experiment reproduction is critical to accelerating progress in\nartificial intelligence. However, the inherent complexity of method design and\ntraining procedures presents substantial challenges for automation. Notably,\nreproducing experiments often requires implicit domain-specific knowledge not\nexplicitly documented in the original papers. To address this, we introduce the\npaper lineage algorithm, which identifies and extracts implicit knowledge from\nthe relevant references cited by the target paper. Building on this idea, we\npropose AutoReproduce, a multi-agent framework capable of automatically\nreproducing experiments described in research papers in an end-to-end manner.\nAutoReproduce enhances code executability by generating unit tests alongside\nthe reproduction process. To evaluate the reproduction capability, we construct\nReproduceBench, a benchmark annotated with verified implementations, and\nintroduce novel evaluation metrics to assess both the reproduction and\nexecution fidelity. Experimental results demonstrate that AutoReproduce\noutperforms the existing strong agent baselines on all five evaluation metrics\nby a peak margin of over $70\\%$. In particular, compared to the official\nimplementations, AutoReproduce achieves an average performance gap of $22.1\\%$\non $89.74\\%$ of the executable experiment runs. The code will be available at\nhttps://github.com/AI9Stars/AutoReproduce.','Xuanle Zhao, Zilin Sang, Yuxuan Li, Qi Shi, Shuo Wang, Duzhen Zhang, Xu Han, Zhiyuan Liu, Maosong Sun','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20662v1'),('2505.20663v1','TeroSeek: An AI-Powered Knowledge Base and Retrieval Generation Platform for Terpenoid Research','Terpenoids are a crucial class of natural products that have been studied for\nover 150 years, but their interdisciplinary nature (spanning chemistry,\npharmacology, and biology) complicates knowledge integration. To address this,\nthe authors developed TeroSeek, a curated knowledge base (KB) built from two\ndecades of terpenoid literature, coupled with an AI-powered question-answering\nchatbot and web service. Leveraging a retrieval-augmented generation (RAG)\nframework, TeroSeek provides structured, high-quality information and\noutperforms general-purpose large language models (LLMs) in terpenoid-related\nqueries. It serves as a domain-specific expert tool for multidisciplinary\nresearch and is publicly available at http://teroseek.qmclab.com.','Xu Kang, Siqi Jiang, Kangwei Xu, Jiahao Li, Ruibo Wu','2025-05-27','cs.IR','http://arxiv.org/pdf/2505.20663v1'),('2505.20664v1','Self-Route: Automatic Mode Switching via Capability Estimation for Efficient Reasoning','While reasoning-augmented large language models (RLLMs) significantly enhance\ncomplex task performance through extended reasoning chains, they inevitably\nintroduce substantial unnecessary token consumption, particularly for simpler\nproblems where Short Chain-of-Thought (Short CoT) suffices. This overthinking\nphenomenon leads to inefficient resource usage without proportional accuracy\ngains. To address this issue, we propose Self-Route, a dynamic reasoning\nframework that automatically selects between general and reasoning modes based\non model capability estimation. Our approach introduces a lightweight\npre-inference stage to extract capability-aware embeddings from hidden layer\nrepresentations, enabling real-time evaluation of the model\\\'s ability to solve\nproblems. We further construct Gradient-10K, a model difficulty\nestimation-based dataset with dense complexity sampling, to train the router\nfor precise capability boundary detection. Extensive experiments demonstrate\nthat Self-Route achieves comparable accuracy to reasoning models while reducing\ntoken consumption by 30-55\\% across diverse benchmarks. The proposed framework\ndemonstrates consistent effectiveness across models with different parameter\nscales and reasoning paradigms, highlighting its general applicability and\npractical value.','Yang He, Xiao Ding, Bibo Cai, Yufei Zhang, Kai Xiong, Zhouhao Sun, Bing Qin, Ting Liu','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20664v1'),('2505.20666v1','Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers','We propose a novel framework, Continuous_Time Attention, which infuses\npartial differential equations (PDEs) into the Transformer\\\'s attention\nmechanism to address the challenges of extremely long input sequences. Instead\nof relying solely on a static attention matrix, we allow attention weights to\nevolve over a pseudo_time dimension via diffusion, wave, or reaction_diffusion\ndynamics. This mechanism systematically smooths local noise, enhances\nlong_range dependencies, and stabilizes gradient flow. Theoretically, our\nanalysis shows that PDE_based attention leads to better optimization landscapes\nand polynomial rather than exponential decay of distant interactions.\nEmpirically, we benchmark our method on diverse experiments_demonstrating\nconsistent gains over both standard and specialized long sequence Transformer\nvariants. Our findings highlight the potential of PDE_based formulations to\nenrich attention mechanisms with continuous_time dynamics and global coherence.','Yukun Zhang, Xueqing Zhou','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20666v1'),('2505.20670v1','MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning in Tool Learning','Complex tasks involving tool integration pose significant challenges for\nLarge Language Models (LLMs), leading to the emergence of multi-agent workflows\nas a promising solution. Reflection has emerged as an effective strategy for\ncorrecting erroneous trajectories in agentic workflows. However, existing\napproaches only exploit such capability in the post-action stage, where the\nagent observes the execution outcomes. We argue that, like humans, LLMs can\nalso engage in reflection before action execution: the agent can anticipate\nundesirable outcomes from its own decisions, which not only provides a\nnecessarily complementary perspective to evaluate the decision but also\nprevents the propagation of errors throughout the trajectory. In this paper, we\npropose MIRROR, a framework that consists of both intra-reflection, which\ncritically assesses intended actions before execution, and inter-reflection,\nwhich further adjusts the trajectory based on observations. This design\nsystematically leverages LLM reflection capabilities to eliminate and rectify\nerroneous actions on a more comprehensive scope. Evaluations on both the\nStableToolBench and TravelPlanner benchmarks demonstrate MIRROR\\\'s superior\nperformance, achieving state-of-the-art results compared to existing\napproaches.','Zikang Guo, Benfeng Xu, Xiaorui Wang, Zhendong Mao','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20670v1'),('2505.20671v1','LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation','While reinforcement learning (RL) has achieved notable success in various\ndomains, training effective policies for complex tasks remains challenging.\nAgents often converge to local optima and fail to maximize long-term rewards.\nExisting approaches to mitigate training bottlenecks typically fall into two\ncategories: (i) Automated policy refinement, which identifies critical states\nfrom past trajectories to guide policy updates, but suffers from costly and\nuncertain model training; and (ii) Human-in-the-loop refinement, where human\nfeedback is used to correct agent behavior, but this does not scale well to\nenvironments with large or continuous action spaces. In this work, we design a\nlarge language model-guided policy modulation framework that leverages LLMs to\nimprove RL training without additional model training or human intervention. We\nfirst prompt an LLM to identify critical states from a sub-optimal agent\\\'s\ntrajectories. Based on these states, the LLM then provides action suggestions\nand assigns implicit rewards to guide policy refinement. Experiments across\nstandard RL benchmarks demonstrate that our method outperforms state-of-the-art\nbaselines, highlighting the effectiveness of LLM-based explanations in\naddressing RL training bottlenecks.','Heng Tan, Hua Yan, Yu Yang','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20671v1'),('2505.20672v1','GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning','The Abstraction and Reasoning Corpus (ARC) poses a stringent test of general\nAI capabilities, requiring solvers to infer abstract patterns from only a\nhandful of examples. Despite substantial progress in deep learning,\nstate-of-the-art models still achieve accuracy rates of merely 40-55% on 2024\nARC Competition, indicative of a significant gap between their performance and\nhuman-level reasoning. In this work, we seek to bridge that gap by introducing\nan analogy-inspired ARC dataset, GIFARC. Leveraging large language models\n(LLMs) and vision-language models (VLMs), we synthesize new ARC-style tasks\nfrom a variety of GIF images that include analogies. Each new task is paired\nwith ground-truth analogy, providing an explicit mapping between visual\ntransformations and everyday concepts. By embedding robust human-intuitive\nanalogies into ARC-style tasks, GIFARC guides AI agents to evaluate the task\nanalogically before engaging in brute-force pattern search, thus efficiently\nreducing problem complexity and build a more concise and human-understandable\nsolution. We empirically validate that guiding LLM with analogic approach with\nGIFARC affects task-solving approaches of LLMs to align with analogic approach\nof human.','Woochang Sim, Hyunseok Ryu, Kyungmin Choi, Sungwon Han, Sundong Kim','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20672v1'),('2505.20674v1','Pretraining Language Models to Ponder in Continuous Space','Humans ponder before articulating complex sentence elements, enabling deeper\ncognitive processing through focused effort. In this work, we introduce this\npondering process into language models by repeatedly invoking the forward\nprocess within a single token generation step. During pondering, instead of\ngenerating an actual token sampled from the prediction distribution, the model\nponders by yielding a weighted sum of all token embeddings according to the\npredicted token distribution. The generated embedding is then fed back as input\nfor another forward pass. We show that the model can learn to ponder in this\nway through self-supervised learning, without any human annotations. Our method\nis straightforward and can be seamlessly integrated with various existing\nlanguage models. Experiments across three widely used open-source\narchitectures-GPT-2, Pythia, and LLaMA-and extensive downstream task\nevaluations demonstrate the effectiveness and generality of our method. For\nlanguage modeling tasks, pondering language models achieve performance\ncomparable to vanilla models with twice the number of parameters. On 9\ndownstream benchmarks, our pondering-enhanced Pythia models significantly\noutperform the official Pythia models. Notably, pondering-enhanced Pythia-1B is\ncomparable to TinyLlama-1.1B, which is trained on 10 times more data. The code\nis available at https://github.com/LUMIA-Group/PonderingLM.','Boyi Zeng, Shixiang Song, Siyuan Huang, Yixuan Wang, He Li, Ziwei He, Xinbing Wang, Zhiyu Li, Zhouhan Lin','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20674v1'),('2505.20679v1','SELF-PERCEPT: Introspection Improves Large Language Models\\\' Detection of Multi-Person Mental Manipulation in Conversations','Mental manipulation is a subtle yet pervasive form of abuse in interpersonal\ncommunication, making its detection critical for safeguarding potential\nvictims. However, due to manipulation\\\'s nuanced and context-specific nature,\nidentifying manipulative language in complex, multi-turn, and multi-person\nconversations remains a significant challenge for large language models (LLMs).\nTo address this gap, we introduce the MultiManip dataset, comprising 220\nmulti-turn, multi-person dialogues balanced between manipulative and\nnon-manipulative interactions, all drawn from reality shows that mimic\nreal-world scenarios. For manipulative interactions, it includes 11 distinct\nmanipulations depicting real-life scenarios. We conduct extensive evaluations\nof state-of-the-art LLMs, such as GPT-4o and Llama-3.1-8B, employing various\nprompting strategies. Despite their capabilities, these models often struggle\nto detect manipulation effectively. To overcome this limitation, we propose\nSELF-PERCEPT, a novel, two-stage prompting framework inspired by\nSelf-Perception Theory, demonstrating strong performance in detecting\nmulti-person, multi-turn mental manipulation. Our code and data are publicly\navailable at https://github.com/danushkhanna/self-percept .','Danush Khanna, Pratinav Seth, Sidhaarth Sredharan Murali, Aditya Kumar Guru, Siddharth Shukla, Tanuj Tyagi, Sandeep Chaurasia, Kripabandhu Ghosh','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20679v1'),('2505.20686v1','Accelerating RL for LLM Reasoning with Optimal Advantage Regression','Reinforcement learning (RL) has emerged as a powerful tool for fine-tuning\nlarge language models (LLMs) to improve complex reasoning abilities. However,\nstate-of-the-art policy optimization methods often suffer from high\ncomputational overhead and memory consumption, primarily due to the need for\nmultiple generations per prompt and the reliance on critic networks or\nadvantage estimates of the current policy. In this paper, we propose $A$*-PO, a\nnovel two-stage policy optimization framework that directly approximates the\noptimal advantage function and enables efficient training of LLMs for reasoning\ntasks. In the first stage, we leverage offline sampling from a reference policy\nto estimate the optimal value function $V$*, eliminating the need for costly\nonline value estimation. In the second stage, we perform on-policy updates\nusing a simple least-squares regression loss with only a single generation per\nprompt. Theoretically, we establish performance guarantees and prove that the\nKL-regularized RL objective can be optimized without requiring complex\nexploration strategies. Empirically, $A$*-PO achieves competitive performance\nacross a wide range of mathematical reasoning benchmarks, while reducing\ntraining time by up to 2$\\times$ and peak memory usage by over 30% compared to\nPPO, GRPO, and REBEL. Implementation of $A$*-PO can be found at\nhttps://github.com/ZhaolinGao/A-PO.','Kianté Brantley, Mingyu Chen, Zhaolin Gao, Jason D. Lee, Wen Sun, Wenhao Zhan, Xuezhou Zhang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20686v1'),('2505.20688v1','A False Discovery Rate Control Method Using a Fully Connected Hidden Markov Random Field for Neuroimaging Data','False discovery rate (FDR) control methods are essential for voxel-wise\nmultiple testing in neuroimaging data analysis, where hundreds of thousands or\neven millions of tests are conducted to detect brain regions associated with\ndisease-related changes. Classical FDR control methods (e.g., BH, q-value, and\nLocalFDR) assume independence among tests and often lead to high false\nnon-discovery rates (FNR). Although various spatial FDR control methods have\nbeen developed to improve power, they still fall short in jointly addressing\nthree major challenges in neuroimaging applications: capturing complex spatial\ndependencies, maintaining low variability in both false discovery proportion\n(FDP) and false non-discovery proportion (FNP) across replications, and\nachieving computational scalability for high-resolution data. To address these\nchallenges, we propose fcHMRF-LIS, a powerful, stable, and scalable spatial FDR\ncontrol method for voxel-wise multiple testing. It integrates the local index\nof significance (LIS)-based testing procedure with a novel fully connected\nhidden Markov random field (fcHMRF) designed to model complex spatial\nstructures using a parsimonious parameterization. We develop an efficient\nexpectation-maximization algorithm incorporating mean-field approximation, the\nConditional Random Fields as Recurrent Neural Networks (CRF-RNN) technique, and\npermutohedral lattice filtering, reducing the computational complexity from\nquadratic to linear in the number of tests. Extensive simulations demonstrate\nthat fcHMRF-LIS achieves accurate FDR control, lower FNR, reduced variability\nin FDP and FNP, and a higher number of true positives compared to existing\nmethods. Applied to an FDG-PET dataset from the Alzheimer\\\'s Disease\nNeuroimaging Initiative, fcHMRF-LIS identifies neurobiologically relevant brain\nregions and offers notable advantages in computational efficiency.','Taehyo Kim, Qiran Jia, Mony J. de Leon, Hai Shu','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.20688v1'),('2505.20691v1','Evidential Deep Active Learning for Semi-Supervised Classification','Semi-supervised classification based on active learning has made significant\nprogress, but the existing methods often ignore the uncertainty estimation (or\nreliability) of the prediction results during the learning process, which makes\nit questionable whether the selected samples can effectively update the model.\nHence, this paper proposes an evidential deep active learning approach for\nsemi-supervised classification (EDALSSC). EDALSSC builds a semi-supervised\nlearning framework to simultaneously quantify the uncertainty estimation of\nlabeled and unlabeled data during the learning process. The uncertainty\nestimation of the former is associated with evidential deep learning, while\nthat of the latter is modeled by combining ignorance information and conflict\ninformation of the evidence from the perspective of the T-conorm operator.\nFurthermore, this article constructs a heuristic method to dynamically balance\nthe influence of evidence and the number of classes on uncertainty estimation\nto ensure that it does not produce counter-intuitive results in EDALSSC. For\nthe sample selection strategy, EDALSSC selects the sample with the greatest\nuncertainty estimation that is calculated in the form of a sum when the\ntraining loss increases in the latter half of the learning process.\nExperimental results demonstrate that EDALSSC outperforms existing\nsemi-supervised and supervised active learning approaches on image\nclassification datasets.','Shenkai Zhao, Xinao Zhang, Lipeng Pan, Xiaobin Xu, Danilo Pelusi','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20691v1'),('2505.20692v1','Can we Debias Social Stereotypes in AI-Generated Images? Examining Text-to-Image Outputs and User Perceptions','Recent advances in generative AI have enabled visual content creation through\ntext-to-image (T2I) generation. However, despite their creative potential, T2I\nmodels often replicate and amplify societal stereotypes -- particularly those\nrelated to gender, race, and culture -- raising important ethical concerns.\nThis paper proposes a theory-driven bias detection rubric and a Social\nStereotype Index (SSI) to systematically evaluate social biases in T2I outputs.\nWe audited three major T2I model outputs -- DALL-E-3, Midjourney-6.1, and\nStability AI Core -- using 100 queries across three categories -- geocultural,\noccupational, and adjectival. Our analysis reveals that initial outputs are\nprone to include stereotypical visual cues, including gendered professions,\ncultural markers, and western beauty norms. To address this, we adopted our\nrubric to conduct targeted prompt refinement using LLMs, which significantly\nreduced bias -- SSI dropped by 61% for geocultural, 69% for occupational, and\n51% for adjectival queries. We complemented our quantitative analysis through a\nuser study examining perceptions, awareness, and preferences around\nAI-generated biased imagery. Our findings reveal a key tension -- although\nprompt refinement can mitigate stereotypes, it can limit contextual alignment.\nInterestingly, users often perceived stereotypical images to be more aligned\nwith their expectations. We discuss the need to balance ethical debiasing with\ncontextual relevance and call for T2I systems that support global diversity and\ninclusivity while not compromising the reflection of real-world social\ncomplexity.','Saharsh Barve, Andy Mao, Jiayue Melissa Shi, Prerna Juneja, Koustuv Saha','2025-05-27','cs.HC','http://arxiv.org/pdf/2505.20692v1'),('2505.20693v1','Phir Hera Fairy: An English Fairytaler is a Strong Faker of Fluent Speech in Low-Resource Indian Languages','What happens when an English Fairytaler is fine-tuned on Indian languages? We\nevaluate how the English F5-TTS model adapts to 11 Indian languages, measuring\npolyglot fluency, voice-cloning, style-cloning, and code-mixing. We compare:\n(i) training from scratch, (ii) fine-tuning English F5 on Indian data, and\n(iii) fine-tuning on both Indian and English data to prevent forgetting.\nFine-tuning with only Indian data proves most effective and the resultant IN-F5\nis a near-human polyglot; that enables speakers of one language (e.g., Odia) to\nfluently speak in another (e.g., Hindi). Our results show English pretraining\naids low-resource TTS in reaching human parity. To aid progress in other\nlow-resource languages, we study data-constrained setups and arrive at a\ncompute optimal strategy. Finally, we show IN-F5 can synthesize unseen\nlanguages like Bhojpuri and Tulu using a human-in-the-loop approach for\nzero-resource TTS via synthetic data generation.','Praveen Srinivasa Varadhan, Srija Anand, Soma Siddhartha, Mitesh M. Khapra','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20693v1'),('2505.20694v1','Temporal Saliency-Guided Distillation: A Scalable Framework for Distilling Video Datasets','Dataset distillation (DD) has emerged as a powerful paradigm for dataset\ncompression, enabling the synthesis of compact surrogate datasets that\napproximate the training utility of large-scale ones. While significant\nprogress has been achieved in distilling image datasets, extending DD to the\nvideo domain remains challenging due to the high dimensionality and temporal\ncomplexity inherent in video data. Existing video distillation (VD) methods\noften suffer from excessive computational costs and struggle to preserve\ntemporal dynamics, as na\\\"ive extensions of image-based approaches typically\nlead to degraded performance. In this paper, we propose a novel uni-level video\ndataset distillation framework that directly optimizes synthetic videos with\nrespect to a pre-trained model. To address temporal redundancy and enhance\nmotion preservation, we introduce a temporal saliency-guided filtering\nmechanism that leverages inter-frame differences to guide the distillation\nprocess, encouraging the retention of informative temporal cues while\nsuppressing frame-level redundancy. Extensive experiments on standard video\nbenchmarks demonstrate that our method achieves state-of-the-art performance,\nbridging the gap between real and distilled video data and offering a scalable\nsolution for video dataset compression.','Xulin Gu, Xinhao Zhong, Zhixing Wei, Yimin Zhou, Shuoyang Sun, Bin Chen, Hongpeng Wang, Yuan Luo','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20694v1'),('2505.20697v1','Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series','The field of hypothesis generation promises to reduce costs in neuroscience\nby narrowing the range of interventional studies needed to study various\nphenomena. Existing machine learning methods can generate scientific hypotheses\nfrom complex datasets, but many approaches assume causal relationships are\nstatic over time, limiting their applicability to systems with dynamic,\nstate-dependent behavior, such as the brain. While some techniques attempt\ndynamic causal discovery through factor models, they often restrict\nrelationships to linear patterns or impose other simplifying assumptions. We\npropose a novel method that models dynamic graphs as a conditionally weighted\nsuperposition of static graphs, where each static graph can capture nonlinear\nrelationships. This approach enables the detection of complex, time-varying\ninteractions between variables beyond linear limitations. Our method improves\nf1-scores of predicted dynamic causal patterns by roughly 22-28% on average\nover baselines in some of our experiments, with some improvements reaching well\nover 60%. A case study on real brain data demonstrates our method\\\'s ability to\nuncover relationships linked to specific behavioral states, offering valuable\ninsights into neural dynamics.','Zachary C. Brown, David Carlson','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20697v1'),('2505.20698v1','Sparsified State-Space Models are Efficient Highway Networks','State-space models (SSMs) offer a promising architecture for sequence\nmodeling, providing an alternative to Transformers by replacing expensive\nself-attention with linear recurrences. In this paper, we propose a simple yet\neffective trick to enhance SSMs within given computational budgets by\nsparsifying them. Our intuition is that tokens in SSMs are highly redundant due\nto gradual recurrent updates, and dense recurrence operations block the\ndelivery of past information. In particular, we observe that upper layers of\nSSMs tend to be more redundant as they encode global information, while lower\nlayers encode local information. Motivated by this, we introduce Simba, a\nhierarchical sparsification method for SSMs based on token pruning. Simba\nsparsifies upper layers more than lower layers, encouraging the upper layers to\nbehave like highways. To achieve this, we propose a novel token pruning\ncriterion for SSMs, measuring the global impact of tokens on the final output\nby accumulating local recurrences. We demonstrate that Simba outperforms the\nbaseline model, Mamba, with the same FLOPS in various natural language tasks.\nMoreover, we illustrate the effect of highways, showing that Simba not only\nenhances efficiency but also improves the information flow across long\nsequences. Code is available at https://github.com/woominsong/Simba.','Woomin Song, Jihoon Tack, Sangwoo Mo, Seunghyuk Oh, Jinwoo Shin','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20698v1'),('2505.20700v1','Beyond Templates: Dynamic Adaptation of Reasoning Demonstrations via Feasibility-Aware Exploration','Large language models (LLMs) have shown remarkable reasoning capabilities,\nyet aligning such abilities to small language models (SLMs) remains a challenge\ndue to distributional mismatches and limited model capacity. Existing reasoning\ndatasets, typically designed for powerful LLMs, often lead to degraded\nperformance when directly applied to weaker models. In this work, we introduce\nDynamic Adaptation of Reasoning Trajectories (DART), a novel data adaptation\nframework that bridges the capability gap between expert reasoning trajectories\nand diverse SLMs. Instead of uniformly imitating expert steps, DART employs a\nselective imitation strategy guided by step-wise adaptability estimation via\nsolution simulation. When expert steps surpass the student\\\'s capacity --\nsignaled by an Imitation Gap -- the student autonomously explores alternative\nreasoning paths, constrained by outcome consistency. We validate DART across\nmultiple reasoning benchmarks and model scales, demonstrating that it\nsignificantly improves generalization and data efficiency over static\nfine-tuning. Our method enhances supervision quality by aligning training\nsignals with the student\\\'s reasoning capabilities, offering a scalable solution\nfor reasoning alignment in resource-constrained models.','Yong Wu, Weihang Pan, Ke Li, Chen Binhui, Ping Li, Binbin Lin','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20700v1'),('2505.20705v1','Time-Series Learning for Proactive Fault Prediction in Distributed Systems with Deep Neural Structures','This paper addresses the challenges of fault prediction and delayed response\nin distributed systems by proposing an intelligent prediction method based on\ntemporal feature learning. The method takes multi-dimensional performance\nmetric sequences as input. We use a Gated Recurrent Unit (GRU) to model the\nevolution of system states over time. An attention mechanism is then applied to\nenhance key temporal segments, improving the model\\\'s ability to identify\npotential faults. On this basis, a feedforward neural network is designed to\nperform the final classification, enabling early warning of system failures. To\nvalidate the effectiveness of the proposed approach, comparative experiments\nand ablation analyses were conducted using data from a large-scale real-world\ncloud system. The experimental results show that the model outperforms various\nmainstream time-series models in terms of Accuracy, F1-Score, and AUC. This\ndemonstrates strong prediction capability and stability. Furthermore, the loss\nfunction curve confirms the convergence and reliability of the training\nprocess. It indicates that the proposed method effectively learns system\nbehavior patterns and achieves efficient fault detection.','Yang Wang, Wenxuan Zhu, Xuehui Quan, Heyi Wang, Chang Liu, Qiyuan Wu','2025-05-27','cs.DC','http://arxiv.org/pdf/2505.20705v1'),('2505.20707v1','Dissecting Physics Reasoning in Small Language Models: A Multi-Dimensional Analysis from an Educational Perspective','Small Language Models (SLMs) offer computational efficiency and\naccessibility, making them promising for educational applications. However,\ntheir capacity for complex reasoning, particularly in domains such as physics,\nremains underexplored. This study investigates the high school physics\nreasoning capabilities of state-of-the-art SLMs (under 4 billion parameters),\nincluding instruct versions of Llama 3.2, Phi 4 Mini, Gemma 3, and Qwen series.\nWe developed a comprehensive physics dataset from the OpenStax High School\nPhysics textbook, annotated according to Bloom\\\'s Taxonomy, with LaTeX and\nplaintext mathematical notations. A novel cultural contextualization approach\nwas applied to a subset, creating culturally adapted problems for Asian,\nAfrican, and South American/Australian contexts while preserving core physics\nprinciples. Using an LLM-as-a-judge framework with Google\\\'s Gemini 2.5 Flash,\nwe evaluated answer and reasoning chain correctness, along with calculation\naccuracy. The results reveal significant differences between the SLMs. Qwen 3\n1.7B achieved high `answer accuracy\\\' (85%), but `fully correct reasoning\\\' was\nsubstantially low (38%). The format of the mathematical notation had a\nnegligible impact on performance. SLMs exhibited varied performance across the\nphysics topics and showed a decline in reasoning quality with increasing\ncognitive and knowledge complexity. In particular, the consistency of reasoning\nwas largely maintained in diverse cultural contexts, especially by better\nperforming models. These findings indicate that, while SLMs can often find\ncorrect answers, their underlying reasoning is frequently flawed, suggesting an\noverreliance on pattern recognition. For SLMs to become reliable educational\ntools in physics, future development must prioritize enhancing genuine\nunderstanding and the generation of sound, verifiable reasoning chains over\nmere answer accuracy.','Nicy Scaria, Silvester John Joseph Kennedy, Diksha Seth, Deepak Subramani','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20707v1'),('2505.20714v1','Wideband RF Radiance Field Modeling Using Frequency-embedded 3D Gaussian Splatting','This paper presents an innovative frequency-embedded 3D Gaussian splatting\n(3DGS) algorithm for wideband radio-frequency (RF) radiance field modeling,\noffering an advancement over the existing works limited to single-frequency\nmodeling. Grounded in fundamental physics, we uncover the complex relationship\nbetween EM wave propagation behaviors and RF frequencies. Inspired by this, we\ndesign an EM feature network with attenuation and radiance modules to learn the\ncomplex relationships between RF frequencies and the key properties of each 3D\nGaussian, specifically the attenuation factor and RF signal intensity. By\ntraining the frequency-embedded 3DGS model, we can efficiently reconstruct RF\nradiance fields at arbitrary unknown frequencies within a given 3D environment.\nFinally, we propose a large-scale power angular spectrum (PAS) dataset\ncontaining 50000 samples ranging from 1 to 100 GHz in 6 indoor environments,\nand conduct extensive experiments to verify the effectiveness of our method.\nOur approach achieves an average Structural Similarity Index Measure (SSIM) up\nto 0.72, and a significant improvement up to 17.8% compared to the current\nstate-of-the-art (SOTA) methods trained on individual test frequencies.\nAdditionally, our method achieves an SSIM of 0.70 without prior training on\nthese frequencies, which represents only a 2.8% performance drop compared to\nmodels trained with full PAS data. This demonstrates our model\\\'s capability to\nestimate PAS at unknown frequencies. For related code and datasets, please\nrefer to https://github.com/sim-2-real/Wideband3DGS.','Zechen Li, Lanqing Yang, Yiheng Bian, Hao Pan, Yongjian Fu, Yezhou Wang, Yi-Chao Chen, Guangtao Xue, Ju Ren','2025-05-27','cs.NI','http://arxiv.org/pdf/2505.20714v1'),('2505.20715v1','MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding','Video temporal understanding is crucial for multimodal large language models\n(MLLMs) to reason over events in videos. Despite recent advances in general\nvideo understanding, current MLLMs still struggle with fine-grained temporal\nreasoning. While reinforcement learning (RL) has been explored to address this\nissue recently, existing RL approaches remain limited in effectiveness. In this\nwork, we propose MUSEG, a novel RL-based method that enhances temporal\nunderstanding by introducing timestamp-aware multi-segment grounding. MUSEG\nenables MLLMs to align queries with multiple relevant video segments, promoting\nmore comprehensive temporal reasoning. To facilitate effective learning, we\ndesign a customized RL training recipe with phased rewards that progressively\nguides the model toward temporally grounded reasoning. Extensive experiments on\ntemporal grounding and time-sensitive video QA tasks demonstrate that MUSEG\nsignificantly outperforms existing methods and generalizes well across diverse\ntemporal understanding scenarios. View our project at\nhttps://github.com/THUNLP-MT/MUSEG.','Fuwen Luo, Shengfeng Lou, Chi Chen, Ziyue Wang, Chenliang Li, Weizhou Shen, Jiyue Guo, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20715v1'),('2505.20716v1','Are Data Embeddings effective in time series forecasting?','Time series forecasting plays a crucial role in many real-world applications,\nand numerous complex forecasting models have been proposed in recent years.\nDespite their architectural innovations, most state-of-the-art models report\nonly marginal improvements -- typically just a few thousandths in standard\nerror metrics. These models often incorporate complex data embedding layers to\ntransform raw inputs into higher-dimensional representations to enhance\naccuracy. But are data embedding techniques actually effective in time series\nforecasting? Through extensive ablation studies across fifteen state-of-the-art\nmodels and four benchmark datasets, we find that removing data embedding layers\nfrom many state-of-the-art models does not degrade forecasting performance. In\nmany cases, it improves both accuracy and computational efficiency. The gains\nfrom removing embedding layers often exceed the performance differences\ntypically reported between competing models. Code available at:\nhttps://github.com/neuripsdataembedidng/DataEmbedding','Reza Nematirad, Anil Pahwa, Balasubramaniam Natarajan','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20716v1'),('2505.20718v2','VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Vision-Language Models','We introduce a novel self-improving framework that enhances Embodied Visual\nTracking (EVT) with Vision-Language Models (VLMs) to address the limitations of\ncurrent active visual tracking systems in recovering from tracking failure. Our\napproach combines the off-the-shelf active tracking methods with VLMs\\\'\nreasoning capabilities, deploying a fast visual policy for normal tracking and\nactivating VLM reasoning only upon failure detection. The framework features a\nmemory-augmented self-reflection mechanism that enables the VLM to\nprogressively improve by learning from past experiences, effectively addressing\nVLMs\\\' limitations in 3D spatial reasoning. Experimental results demonstrate\nsignificant performance improvements, with our framework boosting success rates\nby $72\\%$ with state-of-the-art RL-based approaches and $220\\%$ with PID-based\nmethods in challenging environments. This work represents the first integration\nof VLM-based reasoning to assist EVT agents in proactive failure recovery,\noffering substantial advances for real-world robotic applications that require\ncontinuous target monitoring in dynamic, unstructured environments. Project\nwebsite: https://sites.google.com/view/evt-recovery-assistant.','Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20718v2'),('2505.20721v1','Recurrent Neural Operators: Stable Long-Term PDE Prediction','Neural operators have emerged as powerful tools for learning solution\noperators of partial differential equations. However, in time-dependent\nproblems, standard training strategies such as teacher forcing introduce a\nmismatch between training and inference, leading to compounding errors in\nlong-term autoregressive predictions. To address this issue, we propose\nRecurrent Neural Operators (RNOs)-a novel framework that integrates recurrent\ntraining into neural operator architectures. Instead of conditioning each\ntraining step on ground-truth inputs, RNOs recursively apply the operator to\ntheir own predictions over a temporal window, effectively simulating\ninference-time dynamics during training. This alignment mitigates exposure bias\nand enhances robustness to error accumulation. Theoretically, we show that\nrecurrent training can reduce the worst-case exponential error growth typical\nof teacher forcing to linear growth. Empirically, we demonstrate that\nrecurrently trained Multigrid Neural Operators significantly outperform their\nteacher-forced counterparts in long-term accuracy and stability on standard\nbenchmarks. Our results underscore the importance of aligning training with\ninference dynamics for robust temporal generalization in neural operator\nlearning.','Zaijun Ye, Chen-Song Zhang, Wansheng Wang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20721v1'),('2505.20723v1','LeDiFlow: Learned Distribution-guided Flow Matching to Accelerate Image Generation','Enhancing the efficiency of high-quality image generation using Diffusion\nModels (DMs) is a significant challenge due to the iterative nature of the\nprocess. Flow Matching (FM) is emerging as a powerful generative modeling\nparadigm based on a simulation-free training objective instead of a score-based\none used in DMs. Typical FM approaches rely on a Gaussian distribution prior,\nwhich induces curved, conditional probability paths between the prior and\ntarget data distribution. These curved paths pose a challenge for the Ordinary\nDifferential Equation (ODE) solver, requiring a large number of inference calls\nto the flow prediction network. To address this issue, we present Learned\nDistribution-guided Flow Matching (LeDiFlow), a novel scalable method for\ntraining FM-based image generation models using a better-suited prior\ndistribution learned via a regression-based auxiliary model. By initializing\nthe ODE solver with a prior closer to the target data distribution, LeDiFlow\nenables the learning of more computationally tractable probability paths. These\npaths directly translate to fewer solver steps needed for high-quality image\ngeneration at inference time. Our method utilizes a State-Of-The-Art (SOTA)\ntransformer architecture combined with latent space sampling and can be trained\non a consumer workstation. We empirically demonstrate that LeDiFlow remarkably\noutperforms the respective FM baselines. For instance, when operating directly\non pixels, our model accelerates inference by up to 3.75x compared to the\ncorresponding pixel-space baseline. Simultaneously, our latent FM model\nenhances image quality on average by 1.32x in CLIP Maximum Mean Discrepancy\n(CMMD) metric against its respective baseline.','Pascal Zwick, Nils Friederich, Maximilian Beichter, Lennart Hilbert, Ralf Mikut, Oliver Bringmann','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20723v1'),('2505.20725v1','A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs','Efficient maintenance has always been essential for the successful\napplication of engineering systems. However, the challenges to be overcome in\nthe implementation of Industry 4.0 necessitate new paradigms of maintenance\noptimization. Machine learning techniques are becoming increasingly used in\nengineering and maintenance, with reinforcement learning being one of the most\npromising. In this paper, we propose a gamma degradation process together with\na novel maintenance model in which repairs are increasingly imperfect, i.e.,\nthe beneficial effect of system repairs decreases as more repairs are\nperformed, reflecting the degradational behavior of real-world systems. To\ngenerate maintenance policies for this system, we developed a\nreinforcement-learning-based agent using a Double Deep Q-Network architecture.\nThis agent presents two important advantages: it works without a predefined\npreventive threshold, and it can operate in a continuous degradation state\nspace. Our agent learns to behave in different scenarios, showing great\nflexibility. In addition, we performed an analysis of how changes in the main\nparameters of the environment affect the maintenance policy proposed by the\nagent. The proposed approach is demonstrated to be appropriate and to\nsignificatively improve long-run cost as compared with other common maintenance\nstrategies.','Alberto Pliego Marugán, Jesús M. Pinar-Pérez, Fausto Pedro García Márquez','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20725v1'),('2505.20728v1','Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models','Spatial reasoning is a core component of human cognition, enabling\nindividuals to perceive, comprehend, and interact with the physical world. It\nrelies on a nuanced understanding of spatial structures and inter-object\nrelationships, serving as the foundation for complex reasoning and\ndecision-making. To investigate whether current vision-language models (VLMs)\nexhibit similar capability, we introduce Jigsaw-Puzzles, a novel benchmark\nconsisting of 1,100 carefully curated real-world images with high spatial\ncomplexity. Based on this dataset, we design five tasks to rigorously evaluate\nVLMs\\\' spatial perception, structural understanding, and reasoning capabilities,\nwhile deliberately minimizing reliance on domain-specific knowledge to better\nisolate and assess the general spatial reasoning capability. We conduct a\ncomprehensive evaluation across 24 state-of-the-art VLMs. The results show that\neven the strongest model, Gemini-2.5-Pro, achieves only 77.14% overall accuracy\nand performs particularly poorly on the Order Generation task, with only 30.00%\naccuracy, far below the performance exceeding 90% achieved by human\nparticipants. This persistent gap underscores the need for continued progress,\npositioning Jigsaw-Puzzles as a challenging and diagnostic benchmark for\nadvancing spatial reasoning research in VLMs.','Zesen Lyu, Dandan Zhang, Wei Ye, Fangdi Li, Zhihang Jiang, Yao Yang','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20728v1'),('2505.20730v1','What LLMs Miss in Recommendations: Bridging the Gap with Retrieval-Augmented Collaborative Signals','User-item interactions contain rich collaborative signals that form the\nbackbone of many successful recommender systems. While recent work has explored\nthe use of large language models (LLMs) for recommendation, it remains unclear\nwhether LLMs can effectively reason over this type of collaborative\ninformation. In this paper, we conduct a systematic comparison between LLMs and\nclassical matrix factorization (MF) models to assess LLMs\\\' ability to leverage\nuser-item interaction data. We further introduce a simple retrieval-augmented\ngeneration (RAG) method that enhances LLMs by grounding their predictions in\nstructured interaction data. Our experiments reveal that current LLMs often\nfall short in capturing collaborative patterns inherent to MF models, but that\nour RAG-based approach substantially improves recommendation\nquality-highlighting a promising direction for future LLM-based recommenders.','Shahrooz Pouryousef','2025-05-27','cs.IR','http://arxiv.org/pdf/2505.20730v1'),('2505.20731v1','Semi-supervised Clustering Through Representation Learning of Large-scale EHR Data','Electronic Health Records (EHR) offer rich real-world data for personalized\nmedicine, providing insights into disease progression, treatment responses, and\npatient outcomes. However, their sparsity, heterogeneity, and high\ndimensionality make them difficult to model, while the lack of standardized\nground truth further complicates predictive modeling. To address these\nchallenges, we propose SCORE, a semi-supervised representation learning\nframework that captures multi-domain disease profiles through patient\nembeddings. SCORE employs a Poisson-Adapted Latent factor Mixture (PALM) Model\nwith pre-trained code embeddings to characterize codified features and extract\nmeaningful patient phenotypes and embeddings. To handle the computational\nchallenges of large-scale data, it introduces a hybrid Expectation-Maximization\n(EM) and Gaussian Variational Approximation (GVA) algorithm, leveraging limited\nlabeled data to refine estimates on a vast pool of unlabeled samples. We\ntheoretically establish the convergence of this hybrid approach, quantify GVA\nerrors, and derive SCORE\\\'s error rate under diverging embedding dimensions. Our\nanalysis shows that incorporating unlabeled data enhances accuracy and reduces\nsensitivity to label scarcity. Extensive simulations confirm SCORE\\\'s superior\nfinite-sample performance over existing methods. Finally, we apply SCORE to\npredict disability status for patients with multiple sclerosis (MS) using\npartially labeled EHR data, demonstrating that it produces more informative and\npredictive patient embeddings for multiple MS-related conditions compared to\nexisting approaches.','Linshanshan Wang, Mengyan Li, Zongqi Xia, Molei Liu, Tianxi Cai','2025-05-27','stat.ME','http://arxiv.org/pdf/2505.20731v1'),('2505.20732v1','SPA-RL: Reinforcing LLM Agents via Stepwise Progress Attribution','Reinforcement learning (RL) holds significant promise for training LLM agents\nto handle complex, goal-oriented tasks that require multi-step interactions\nwith external environments. However, a critical challenge when applying RL to\nthese agentic tasks arises from delayed rewards: feedback signals are typically\navailable only after the entire task is completed. This makes it non-trivial to\nassign delayed rewards to earlier actions, providing insufficient guidance\nregarding environmental constraints and hindering agent training. In this work,\nwe draw on the insight that the ultimate completion of a task emerges from the\ncumulative progress an agent makes across individual steps. We propose Stepwise\nProgress Attribution (SPA), a general reward redistribution framework that\ndecomposes the final reward into stepwise contributions, each reflecting its\nincremental progress toward overall task completion. To achieve this, we train\na progress estimator that accumulates stepwise contributions over a trajectory\nto match the task completion. During policy optimization, we combine the\nestimated per-step contribution with a grounding signal for actions executed in\nthe environment as the fine-grained, intermediate reward for effective agent\ntraining. Extensive experiments on common agent benchmarks (including Webshop,\nALFWorld, and VirtualHome) demonstrate that SPA consistently outperforms the\nstate-of-the-art method in both success rate (+2.5\\% on average) and grounding\naccuracy (+1.9\\% on average). Further analyses demonstrate that our method\nremarkably provides more effective intermediate rewards for RL training. Our\ncode is available at https://github.com/WangHanLinHenry/SPA-RL-Agent.','Hanlin Wang, Chak Tou Leong, Jiashuo Wang, Jian Wang, Wenjie Li','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20732v1'),('2505.20733v1','E2E Process Automation Leveraging Generative AI and IDP-Based Automation Agent: A Case Study on Corporate Expense Processing','This paper presents an intelligent work automation approach in the context of\ncontemporary digital transformation by integrating generative AI and\nIntelligent Document Processing (IDP) technologies with an Automation Agent to\nrealize End-to-End (E2E) automation of corporate financial expense processing\ntasks. While traditional Robotic Process Automation (RPA) has proven effective\nfor repetitive, rule-based simple task automation, it faces limitations in\nhandling unstructured data, exception management, and complex decision-making.\nThis study designs and implements a four-stage integrated process comprising\nautomatic recognition of supporting documents such as receipts via OCR/IDP,\nitem classification based on a policy-driven database, intelligent exception\nhandling supported by generative AI (large language models, LLMs), and\nhuman-in-the-loop final decision-making with continuous system learning through\nan Automation Agent. Applied to a major Korean enterprise (Company S), the\nsystem demonstrated quantitative benefits including over 80% reduction in\nprocessing time for paper receipt expense tasks, decreased error rates, and\nimproved compliance, as well as qualitative benefits such as enhanced accuracy\nand consistency, increased employee satisfaction, and data-driven decision\nsupport. Furthermore, the system embodies a virtuous cycle by learning from\nhuman judgments to progressively improve automatic exception handling\ncapabilities. Empirically, this research confirms that the organic integration\nof generative AI, IDP, and Automation Agents effectively overcomes the\nlimitations of conventional automation and enables E2E automation of complex\ncorporate processes. The study also discusses potential extensions to other\ndomains such as accounting, human resources, and procurement, and proposes\nfuture directions for AI-driven hyper-automation development.','Cheonsu Jeong, Seongmin Sim, Hyoyoung Cho, Sungsu Kim, Byounggwan Shin','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20733v1'),('2505.20734v1','Adversarial bandit optimization for approximately linear functions','We consider a bandit optimization problem for nonconvex and non-smooth\nfunctions, where in each trial the loss function is the sum of a linear\nfunction and a small but arbitrary perturbation chosen after observing the\nplayer\\\'s choice. We give both expected and high probability regret bounds for\nthe problem. Our result also implies an improved high-probability regret bound\nfor the bandit linear optimization, a special case with no perturbation. We\nalso give a lower bound on the expected regret.','Zhuoyu Cheng, Kohei Hatano, Eiji Takimoto','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20734v1'),('2505.20737v1','RRO: LLM Agent Optimization Through Rising Reward Trajectories','Large language models (LLMs) have exhibited extraordinary performance in a\nvariety of tasks while it remains challenging for them to solve complex\nmulti-step tasks as agents. In practice, agents sensitive to the outcome of\ncertain key steps which makes them likely to fail the task because of a subtle\nmistake in the planning trajectory. Recent approaches resort to calibrating the\nreasoning process through reinforcement learning. They reward or penalize every\nreasoning step with process supervision, as known as Process Reward Models\n(PRMs). However, PRMs are difficult and costly to scale up with a large number\nof next action candidates since they require extensive computations to acquire\nthe training data through the per-step trajectory exploration. To mitigate this\nissue, we focus on the relative reward trend across successive reasoning steps\nand propose maintaining an increasing reward in the collected trajectories for\nprocess supervision, which we term Reward Rising Optimization (RRO).\nSpecifically, we incrementally augment the process supervision until\nidentifying a step exhibiting positive reward differentials, i.e. rising\nrewards, relative to its preceding iteration. This method dynamically expands\nthe search space for the next action candidates, efficiently capturing\nhigh-quality data. We provide mathematical groundings and empirical results on\nthe WebShop and InterCode-SQL benchmarks, showing that our proposed RRO\nachieves superior performance while requiring much less exploration cost.','Zilong Wang, Jingfeng Yang, Sreyashi Nag, Samarth Varshney, Xianfeng Tang, Haoming Jiang, Jingbo Shang, Sheikh Muhammad Sarwar','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20737v1'),('2505.20738v1','Silencer: From Discovery to Mitigation of Self-Bias in LLM-as-Benchmark-Generator','LLM-as-Benchmark-Generator methods have been widely studied as a supplement\nto human annotators for scalable evaluation, while the potential biases within\nthis paradigm remain underexplored. In this work, we systematically define and\nvalidate the phenomenon of inflated performance in models evaluated on their\nself-generated benchmarks, referred to as self-bias, and attribute it to\nsub-biases arising from question domain, language style, and wrong labels. On\nthis basis, we propose Silencer, a general framework that leverages the\nheterogeneity between multiple generators at both the sample and benchmark\nlevels to neutralize bias and generate high-quality, self-bias-silenced\nbenchmark. Experimental results across various settings demonstrate that\nSilencer can suppress self-bias to near zero, significantly improve evaluation\neffectiveness of the generated benchmark (with an average improvement from\n0.655 to 0.833 in Pearson correlation with high-quality human-annotated\nbenchmark), while also exhibiting strong generalizability.','Peiwen Yuan, Yiwei Li, Shaoxiong Feng, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20738v1'),('2505.20739v1','Detecting Informative Channels: ActionFormer','Human Activity Recognition (HAR) has recently witnessed advancements with\nTransformer-based models. Especially, ActionFormer shows us a new perspectives\nfor HAR in the sense that this approach gives us additional outputs which\ndetect the border of the activities as well as the activity labels.\nActionFormer was originally proposed with its input as image/video. However,\nthis was converted to with its input as sensor signals as well. We analyze this\nextensively in terms of deep learning architectures. Based on the report of\nhigh temporal dynamics which limits the model\\\'s ability to capture subtle\nchanges effectively and of the interdependencies between the spatial and\ntemporal features. We propose the modified ActionFormer which will decrease\nthese defects for sensor signals. The key to our approach lies in accordance\nwith the Sequence-and-Excitation strategy to minimize the increase in\nadditional parameters and opt for the swish activation function to retain the\ninformation about direction in the negative range. Experiments on the WEAR\ndataset show that our method achieves substantial improvement of a 16.01\\% in\nterms of average mAP for inertial data.','Kunpeng Zhao, Asahi Miyazaki, Tsuyoshi Okita','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20739v1'),('2505.20740v1','MSEarth: A Benchmark for Multimodal Scientific Comprehension of Earth Science','The rapid advancement of multimodal large language models (MLLMs) has\nunlocked new opportunities to tackle complex scientific challenges. Despite\nthis progress, their application in addressing earth science problems,\nespecially at the graduate level, remains underexplored. A significant barrier\nis the absence of benchmarks that capture the depth and contextual complexity\nof geoscientific reasoning. Current benchmarks often rely on synthetic datasets\nor simplistic figure-caption pairs, which do not adequately reflect the\nintricate reasoning and domain-specific insights required for real-world\nscientific applications. To address these gaps, we introduce MSEarth, a\nmultimodal scientific benchmark curated from high-quality, open-access\nscientific publications. MSEarth encompasses the five major spheres of Earth\nscience: atmosphere, cryosphere, hydrosphere, lithosphere, and biosphere,\nfeaturing over 7K figures with refined captions. These captions are crafted\nfrom the original figure captions and enriched with discussions and reasoning\nfrom the papers, ensuring the benchmark captures the nuanced reasoning and\nknowledge-intensive content essential for advanced scientific tasks. MSEarth\nsupports a variety of tasks, including scientific figure captioning, multiple\nchoice questions, and open-ended reasoning challenges. By bridging the gap in\ngraduate-level benchmarks, MSEarth provides a scalable and high-fidelity\nresource to enhance the development and evaluation of MLLMs in scientific\nreasoning. The benchmark is publicly available to foster further research and\ninnovation in this field. Resources related to this benchmark can be found at\nhttps://huggingface.co/MSEarth and https://github.com/xiangyu-mm/MSEarth.','Xiangyu Zhao, Wanghan Xu, Bo Liu, Yuhao Zhou, Fenghua Ling, Ben Fei, Xiaoyu Yue, Lei Bai, Wenlong Zhang, Xiao-Ming Wu','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20740v1'),('2505.20742v1','\\\'Hello, World!\\\': Making GNNs Talk with LLMs','While graph neural networks (GNNs) have shown remarkable performance across\ndiverse graph-related tasks, their high-dimensional hidden representations\nrender them black boxes. In this work, we propose Graph Lingual Network (GLN),\na GNN built on large language models (LLMs), with hidden representations in the\nform of human-readable text. Through careful prompt design, GLN incorporates\nnot only the message passing module of GNNs but also advanced GNN techniques,\nincluding graph attention and initial residual connection. The\ncomprehensibility of GLN\\\'s hidden representations enables an intuitive analysis\nof how node representations change (1) across layers and (2) under advanced GNN\ntechniques, shedding light on the inner workings of GNNs. Furthermore, we\ndemonstrate that GLN achieves strong zero-shot performance on node\nclassification and link prediction, outperforming existing LLM-based baseline\nmethods.','Sunwoo Kim, Soo Yong Lee, Jaemin Yoo, Kijung Shin','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20742v1'),('2505.20745v1','Foundation Model Hidden Representations for Heart Rate Estimation from Auscultation','Auscultation, particularly heart sound, is a non-invasive technique that\nprovides essential vital sign information. Recently, self-supervised acoustic\nrepresentation foundation models (FMs) have been proposed to offer insights\ninto acoustics-based vital signs. However, there has been little exploration of\nthe extent to which auscultation is encoded in these pre-trained FM\nrepresentations. In this work, using a publicly available phonocardiogram (PCG)\ndataset and a heart rate (HR) estimation model, we conduct a layer-wise\ninvestigation of six acoustic representation FMs: HuBERT, wav2vec2, wavLM,\nWhisper, Contrastive Language-Audio Pretraining (CLAP), and an in-house CLAP\nmodel. Additionally, we implement the baseline method from Nie et al., 2024\n(which relies on acoustic features) and show that overall, representation\nvectors from pre-trained foundation models (FMs) offer comparable performance\nto the baseline. Notably, HR estimation using the representations from the\naudio encoder of the in-house CLAP model outperforms the results obtained from\nthe baseline, achieving a lower mean absolute error (MAE) across various\ntrain/validation/test splits despite the domain mismatch.','Jingping Nie, Dung T. Tran, Karan Thakkar, Vasudha Kowtha, John Huang, Carlos Avendano, Erdrin Azemi, Vikramjit Mitra','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.20745v1'),('2505.20749v1','Can Agents Fix Agent Issues?','LLM-based agent systems are emerging as a new software paradigm and have been\nwidely adopted across diverse domains such as medicine, robotics, and\nprogramming. However, maintaining these systems requires substantial effort, as\nthey are inevitably prone to bugs and continually evolve to meet changing\nexternal requirements. Therefore, automatically resolving agent issues (i.e.,\nbug reports or feature requests) is a crucial and challenging task. While\nrecent software engineering (SE) agents (e.g., SWE-agent) have shown promise in\naddressing issues in traditional software systems, it remains unclear how\neffectively they can resolve real-world issues in agent systems, which differ\nsignificantly from traditional software. To fill this gap, we first manually\nanalyze 201 real-world agent issues and identify common categories of agent\nissues. We then spend 500 person-hours constructing AGENTISSUE-BENCH, a\nreproducible benchmark comprising 50 agent issue resolution tasks (each with an\nexecutable environment and failure-triggering tests). We further evaluate\nstate-of-the-art SE agents on AGENTISSUE-BENCH and reveal their limited\neffectiveness (i.e., with only 3.33% - 12.67% resolution rates). These results\nunderscore the unique challenges of maintaining agent systems compared to\ntraditional software, highlighting the need for further research to develop\nadvanced SE agents for resolving agent issues. Data and code are available at\nhttps://alfin06.github.io/AgentIssue-Bench-Leaderboard/#/ .','Alfin Wijaya Rahardja, Junwei Liu, Weitong Chen, Zhenpeng Chen, Yiling Lou','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20749v1'),('2505.20751v1','Interactive OT Gym: A Reinforcement Learning-Based Interactive Optical tweezer (OT)-Driven Microrobotics Simulation Platform','Optical tweezers (OT) offer unparalleled capabilities for micromanipulation\nwith submicron precision in biomedical applications. However, controlling\nconventional multi-trap OT to achieve cooperative manipulation of multiple\ncomplex-shaped microrobots in dynamic environments poses a significant\nchallenge. To address this, we introduce Interactive OT Gym, a reinforcement\nlearning (RL)-based simulation platform designed for OT-driven microrobotics.\nOur platform supports complex physical field simulations and integrates haptic\nfeedback interfaces, RL modules, and context-aware shared control strategies\ntailored for OT-driven microrobot in cooperative biological object manipulation\ntasks. This integration allows for an adaptive blend of manual and autonomous\ncontrol, enabling seamless transitions between human input and autonomous\noperation. We evaluated the effectiveness of our platform using a cell\nmanipulation task. Experimental results show that our shared control system\nsignificantly improves micromanipulation performance, reducing task completion\ntime by approximately 67% compared to using pure human or RL control alone and\nachieving a 100% success rate. With its high fidelity, interactivity, low cost,\nand high-speed simulation capabilities, Interactive OT Gym serves as a\nuser-friendly training and testing environment for the development of advanced\ninteractive OT-driven micromanipulation systems and control algorithms. For\nmore details on the project, please see our website\nhttps://sites.google.com/view/otgym','Zongcai Tan amd Dandan Zhang','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.20751v1'),('2505.20753v1','Understand, Think, and Answer: Advancing Visual Reasoning with Large Multimodal Models','Large Multimodal Models (LMMs) have recently demonstrated remarkable visual\nunderstanding performance on both vision-language and vision-centric tasks.\nHowever, they often fall short in integrating advanced, task-specific\ncapabilities for compositional reasoning, which hinders their progress toward\ntruly competent general vision models. To address this, we present a unified\nvisual reasoning mechanism that enables LMMs to solve complicated compositional\nproblems by leveraging their intrinsic capabilities (e.g. grounding and visual\nunderstanding capabilities). Different from the previous shortcut learning\nmechanism, our approach introduces a human-like\nunderstanding-thinking-answering process, allowing the model to complete all\nsteps in a single pass forwarding without the need for multiple inferences or\nexternal tools. This design bridges the gap between foundational visual\ncapabilities and general question answering, encouraging LMMs to generate\nfaithful and traceable responses for complex visual reasoning. Meanwhile, we\ncurate 334K visual instruction samples covering both general scenes and\ntext-rich scenes and involving multiple foundational visual capabilities. Our\ntrained model, Griffon-R, has the ability of end-to-end automatic\nunderstanding, self-thinking, and reasoning answers. Comprehensive experiments\nshow that Griffon-R not only achieves advancing performance on complex visual\nreasoning benchmarks including VSR and CLEVR, but also enhances multimodal\ncapabilities across various benchmarks like MMBench and ScienceQA. Data,\nmodels, and codes will be release at\nhttps://github.com/jefferyZhan/Griffon/tree/master/Griffon-R soon.','Yufei Zhan, Hongyin Zhao, Yousong Zhu, Shurong Zheng, Fan Yang, Ming Tang, Jinqiao Wang','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20753v1'),('2505.20754v1','Stationary MMD Points for Cubature','Approximation of a target probability distribution using a finite set of\npoints is a problem of fundamental importance, arising in cubature, data\ncompression, and optimisation. Several authors have proposed to select points\nby minimising a maximum mean discrepancy (MMD), but the non-convexity of this\nobjective precludes global minimisation in general. Instead, we consider\n\\emph{stationary} points of the MMD which, in contrast to points globally\nminimising the MMD, can be accurately computed. Our main theoretical\ncontribution is the (perhaps surprising) result that, for integrands in the\nassociated reproducing kernel Hilbert space, the cubature error of stationary\nMMD points vanishes \\emph{faster} than the MMD. Motivated by this\n\\emph{super-convergence} property, we consider discretised gradient flows as a\npractical strategy for computing stationary points of the MMD, presenting a\nrefined convergence analysis that establishes a novel non-asymptotic\nfinite-particle error bound, which may be of independent interest.','Zonghao Chen, Toni Karvonen, Heishiro Kanagawa, François-Xavier Briol, Chris. J. Oates','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.20754v1'),('2505.20755v1','Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction','In this paper, we unify more than 10 existing one-step diffusion distillation\napproaches, such as Diff-Instruct, DMD, SIM, SiD, $f$-distill, etc, inside a\ntheory-driven framework which we name the \\textbf{\\emph{Uni-Instruct}}.\nUni-Instruct is motivated by our proposed diffusion expansion theory of the\n$f$-divergence family. Then we introduce key theories that overcome the\nintractability issue of the original expanded $f$-divergence, resulting in an\nequivalent yet tractable loss that effectively trains one-step diffusion models\nby minimizing the expanded $f$-divergence family. The novel unification\nintroduced by Uni-Instruct not only offers new theoretical contributions that\nhelp understand existing approaches from a high-level perspective but also\nleads to state-of-the-art one-step diffusion generation performances. On the\nCIFAR10 generation benchmark, Uni-Instruct achieves record-breaking Frechet\nInception Distance (FID) values of \\textbf{\\emph{1.46}} for unconditional\ngeneration and \\textbf{\\emph{1.38}} for conditional generation. On the\nImageNet-$64\\times 64$ generation benchmark, Uni-Instruct achieves a new SoTA\none-step generation FID of \\textbf{\\emph{1.02}}, which outperforms its 79-step\nteacher diffusion with a significant improvement margin of 1.33 (1.02 vs 2.35).\nWe also apply Uni-Instruct on broader tasks like text-to-3D generation. For\ntext-to-3D generation, Uni-Instruct gives decent results, which slightly\noutperforms previous methods, such as SDS and VSD, in terms of both generation\nquality and diversity. Both the solid theoretical and empirical contributions\nof Uni-Instruct will potentially help future studies on one-step diffusion\ndistillation and knowledge transferring of diffusion models.','Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20755v1'),('2505.20759v1','PARTONOMY: Large Multimodal Models with Part-Level Visual Understanding','Real-world objects are composed of distinctive, object-specific parts.\nIdentifying these parts is key to performing fine-grained, compositional\nreasoning-yet, large multimodal models (LMMs) struggle to perform this\nseemingly straightforward task. In this work, we introduce PARTONOMY, an LMM\nbenchmark designed for pixel-level part grounding. We construct PARTONOMY from\nexisting part datasets and our own rigorously annotated set of images,\nencompassing 862 part labels and 534 object labels for evaluation. Unlike\nexisting datasets that simply ask models to identify generic parts, PARTONOMY\nuses specialized concepts (e.g., agricultural airplane), and challenges models\nto compare objects\\\' parts, consider part-whole relationships, and justify\ntextual predictions with visual segmentations. Our experiments demonstrate\nsignificant limitations in state-of-the-art LMMs (e.g., LISA-13B achieves only\n5.9% gIoU), highlighting a critical gap in their part grounding abilities. We\nnote that existing segmentation-enabled LMMs (segmenting LMMs) have two key\narchitectural shortcomings: they use special [SEG] tokens not seen during\npretraining which induce distribution shift, and they discard predicted\nsegmentations instead of using past predictions to guide future ones. To\naddress these deficiencies, we train several part-centric LMMs and propose\nPLUM, a novel segmenting LMM that uses span tagging instead of segmentation\ntokens and that conditions on prior predictions in a feedback loop. We find\nthat pretrained PLUM outperforms existing segmenting LMMs on reasoning\nsegmentation, VQA, and visual hallucination benchmarks. In addition, PLUM\nfinetuned on our proposed Explanatory Part Segmentation task is competitive\nwith segmenting LMMs trained on significantly more segmentation data. Our work\nopens up new avenues towards enabling fine-grained, grounded visual\nunderstanding in LMMs.','Ansel Blume, Jeonghwan Kim, Hyeonjeong Ha, Elen Chatikyan, Xiaomeng Jin, Khanh Duy Nguyen, Nanyun Peng, Kai-Wei Chang, Derek Hoiem, Heng Ji','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20759v1'),('2505.20761v1','Practical estimation of the optimal classification error with soft labels and calibration','While the performance of machine learning systems has experienced significant\nimprovement in recent years, relatively little attention has been paid to the\nfundamental question: to what extent can we improve our models? This paper\nprovides a means of answering this question in the setting of binary\nclassification, which is practical and theoretically supported. We extend a\nprevious work that utilizes soft labels for estimating the Bayes error, the\noptimal error rate, in two important ways. First, we theoretically investigate\nthe properties of the bias of the hard-label-based estimator discussed in the\noriginal work. We reveal that the decay rate of the bias is adaptive to how\nwell the two class-conditional distributions are separated, and it can decay\nsignificantly faster than the previous result suggested as the number of hard\nlabels per instance grows. Second, we tackle a more challenging problem\nsetting: estimation with corrupted soft labels. One might be tempted to use\ncalibrated soft labels instead of clean ones. However, we reveal that\ncalibration guarantee is not enough, that is, even perfectly calibrated soft\nlabels can result in a substantially inaccurate estimate. Then, we show that\nisotonic calibration can provide a statistically consistent estimator under an\nassumption weaker than that of the previous work. Our method is instance-free,\ni.e., we do not assume access to any input instances. This feature allows it to\nbe adopted in practical scenarios where the instances are not available due to\nprivacy issues. Experiments with synthetic and real-world datasets show the\nvalidity of our methods and theory.','Ryota Ushio, Takashi Ishida, Masashi Sugiyama','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20761v1'),('2505.20764v1','ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval','Composed image retrieval (CIR) is the task of retrieving a target image\nspecified by a query image and a relative text that describes a semantic\nmodification to the query image. Existing methods in CIR struggle to accurately\nrepresent the image and the text modification, resulting in subpar performance.\nTo address this limitation, we introduce a CIR framework, ConText-CIR, trained\nwith a Text Concept-Consistency loss that encourages the representations of\nnoun phrases in the text modification to better attend to the relevant parts of\nthe query image. To support training with this loss function, we also propose a\nsynthetic data generation pipeline that creates training data from existing CIR\ndatasets or unlabeled images. We show that these components together enable\nstronger performance on CIR tasks, setting a new state-of-the-art in composed\nimage retrieval in both the supervised and zero-shot settings on multiple\nbenchmark datasets, including CIRR and CIRCO. Source code, model checkpoints,\nand our new datasets are available at https://github.com/mvrl/ConText-CIR.','Eric Xing, Pranavi Kolouju, Robert Pless, Abby Stylianou, Nathan Jacobs','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20764v1'),('2505.20765v1','Robust and Explainable Detector of Time Series Anomaly via Augmenting Multiclass Pseudo-Anomalies','Unsupervised anomaly detection in time series has been a pivotal research\narea for decades. Current mainstream approaches focus on learning normality, on\nthe assumption that all or most of the samples in the training set are normal.\nHowever, anomalies in the training set (i.e., anomaly contamination) can be\nmisleading. Recent studies employ data augmentation to generate\npseudo-anomalies and learn the boundary separating the training samples from\nthe augmented samples. Although this approach mitigates anomaly contamination\nif augmented samples mimic unseen real anomalies, it suffers from several\nlimitations. (1) Covering a wide range of time series anomalies is challenging.\n(2) It disregards augmented samples that resemble normal samples (i.e., false\nanomalies). (3) It places too much trust in the labels of training and\naugmented samples. In response, we propose RedLamp, which employs diverse data\naugmentations to generate multiclass pseudo-anomalies and learns the multiclass\nboundary. Such multiclass pseudo-anomalies cover a wide variety of time series\nanomalies. We conduct multiclass classification using soft labels, which\nprevents the model from being overconfident and ensures its robustness against\ncontaminated/false anomalies. The learned latent space is inherently\nexplainable as it is trained to separate pseudo-anomalies into multiclasses.\nExtensive experiments demonstrate the effectiveness of RedLamp in anomaly\ndetection and its robustness against anomaly contamination.','Kohei Obata, Yasuko Matsubara, Yasushi Sakurai','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20765v1'),('2505.20767v2','CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models','Faithfulness hallucination are claims generated by a Large Language Model\n(LLM) not supported by contexts provided to the LLM. Lacking assessment\nstandard, existing benchmarks only contain \"factual statements\" that rephrase\nsource materials without marking \"cognitive statements\" that make inference\nfrom the given context, making the consistency evaluation and optimization of\ncognitive statements difficult. Inspired by how an evidence is assessed in the\nlegislative domain, we design a rigorous framework to assess different levels\nof faithfulness of cognitive statements and create a benchmark dataset where we\nreveal insightful statistics. We design an annotation pipeline to create larger\nbenchmarks for different LLMs automatically, and the resulting larger-scale\nCogniBench-L dataset can be used to train accurate cognitive hallucination\ndetection model. We release our model and dataset at:\nhttps://github.com/FUTUREEEEEE/CogniBench','Xiaqiang Tang, Jian Li, Keyu Hu, Du Nan, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20767v2'),('2505.20771v1','Bridging the Gap: Self-Optimized Fine-Tuning for LLM-based Recommender Systems','Recent years have witnessed extensive exploration of Large Language Models\n(LLMs) on the field of Recommender Systems (RS). There are currently two\ncommonly used strategies to enable LLMs to have recommendation capabilities: 1)\nThe \"Guidance-Only\" strategy uses in-context learning to exploit and amplify\nthe inherent semantic understanding and item recommendation capabilities of\nLLMs; 2) The \"Tuning-Only\" strategy uses supervised fine-tuning (SFT) to\nfine-tune LLMs with the aim of fitting them to real recommendation data.\nHowever, neither of these strategies can effectively bridge the gap between the\nknowledge space of LLMs and recommendation, and their performance do not meet\nour expectations.\n  To better enable LLMs to learn recommendation knowledge, we combine the\nadvantages of the above two strategies and proposed a novel \"Guidance+Tuning\"\nmethod called Self-Optimized Fine-Tuning (SOFT), which adopts the idea of\ncurriculum learning. It first employs self-distillation to construct an\nauxiliary easy-to-learn but meaningful dataset from a fine-tuned LLM. Then it\nfurther utilizes a self-adaptive curriculum scheduler to enable LLMs to\ngradually learn from simpler data (self-distilled data) to more challenging\ndata (real RS data). Extensive experiments demonstrate that SOFT significantly\nenhances the recommendation accuracy (37.59\\% on average) of LLM-based methods.\nThe code is available via\nhttps://anonymous.4open.science/r/Self-Optimized-Fine-Tuning-264E','Heng Tang, Feng Liu, Xinbo Chen, Jiawei Chen, Bohao Wang, Changwang Zhang, Jun Wang, Yuegang Sun, Bingde Hu, Can Wang','2025-05-27','cs.IR','http://arxiv.org/pdf/2505.20771v1'),('2505.20772v1','MetaSlot: Break Through the Fixed Number of Slots in Object-Centric Learning','Learning object-level, structured representations is widely regarded as a key\nto better generalization in vision and underpins the design of next-generation\nPre-trained Vision Models (PVMs). Mainstream Object-Centric Learning (OCL)\nmethods adopt Slot Attention or its variants to iteratively aggregate objects\\\'\nsuper-pixels into a fixed set of query feature vectors, termed slots. However,\ntheir reliance on a static slot count leads to an object being represented as\nmultiple parts when the number of objects varies. We introduce MetaSlot, a\nplug-and-play Slot Attention variant that adapts to variable object counts.\nMetaSlot (i) maintains a codebook that holds prototypes of objects in a dataset\nby vector-quantizing the resulting slot representations; (ii) removes duplicate\nslots from the traditionally aggregated slots by quantizing them with the\ncodebook; and (iii) injects progressively weaker noise into the Slot Attention\niterations to accelerate and stabilize the aggregation. MetaSlot is a general\nSlot Attention variant that can be seamlessly integrated into existing OCL\narchitectures. Across multiple public datasets and tasks--including object\ndiscovery and recognition--models equipped with MetaSlot achieve significant\nperformance gains and markedly interpretable slot representations, compared\nwith existing Slot Attention variants.','Hongjia Liu, Rongzhen Zhao, Haohan Chen, Joni Pajarinen','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20772v1'),('2505.20774v1','TimePro: Efficient Multivariate Long-term Time Series Forecasting with Variable- and Time-Aware Hyper-state','In long-term time series forecasting, different variables often influence the\ntarget variable over distinct time intervals, a challenge known as the\nmulti-delay issue. Traditional models typically process all variables or time\npoints uniformly, which limits their ability to capture complex variable\nrelationships and obtain non-trivial time representations. To address this\nissue, we propose TimePro, an innovative Mamba-based model that constructs\nvariate- and time-aware hyper-states. Unlike conventional approaches that\nmerely transfer plain states across variable or time dimensions, TimePro\npreserves the fine-grained temporal features of each variate token and\nadaptively selects the focused time points to tune the plain state. The\nreconstructed hyper-state can perceive both variable relationships and salient\ntemporal information, which helps the model make accurate forecasting. In\nexperiments, TimePro performs competitively on eight real-world long-term\nforecasting benchmarks with satisfactory linear complexity. Code is available\nat https://github.com/xwmaxwma/TimePro.','Xiaowen Ma, Zhenliang Ni, Shuai Xiao, Xinghao Chen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20774v1'),('2505.20775v1','Non-invasive maturity assessment of iPSC-CMs based on optical maturity characteristics using interpretable AI','Human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) are an\nimportant resource for the identification of new therapeutic targets and\ncardioprotective drugs. After differentiation iPSC-CMs show an immature,\nfetal-like phenotype. Cultivation of iPSC-CMs in lipid-supplemented maturation\nmedium (MM) strongly enhances their structural, metabolic and functional\nphenotype. Nevertheless, assessing iPSC-CM maturation state remains challenging\nas most methods are time consuming and go in line with cell damage or loss of\nthe sample. To address this issue, we developed a non-invasive approach for\nautomated classification of iPSC-CM maturity through interpretable artificial\nintelligence (AI)-based analysis of beat characteristics derived from\nvideo-based motion analysis. In a prospective study, we evaluated 230 video\nrecordings of early-state, immature iPSC-CMs on day 21 after differentiation\n(d21) and more mature iPSC-CMs cultured in MM (d42, MM). For each recording, 10\nfeatures were extracted using Maia motion analysis software and entered into a\nsupport vector machine (SVM). The hyperparameters of the SVM were optimized in\na grid search on 80 % of the data using 5-fold cross-validation. The optimized\nmodel achieved an accuracy of 99.5 $\\pm$ 1.1 % on a hold-out test set. Shapley\nAdditive Explanations (SHAP) identified displacement, relaxation-rise time and\nbeating duration as the most relevant features for assessing maturity level.\nOur results suggest the use of non-invasive, optical motion analysis combined\nwith AI-based methods as a tool to assess iPSC-CMs maturity and could be\napplied before performing functional readouts or drug testing. This may\npotentially reduce the variability and improve the reproducibility of\nexperimental studies.','Fabian Scheurer, Alexander Hammer, Mario Schubert, Robert-Patrick Steiner, Oliver Gamm, Kaomei Guan, Frank Sonntag, Hagen Malberg, Martin Schmidt','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20775v1'),('2505.20776v1','SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences','Speculative decoding is a widely adopted technique for accelerating inference\nin large language models (LLMs), but its performance degrades on long inputs\ndue to increased attention cost and reduced draft accuracy. We introduce\nSpecExtend, a drop-in enhancement that improves the performance of speculative\ndecoding on long sequences without any additional training. SpecExtend\nintegrates efficient attention mechanisms such as FlashAttention and Hybrid\nTree Attention into both the draft and target models, reducing latency across\nall stages. To improve draft accuracy and speed, we propose Cross-model\nRetrieval, a novel KV cache update strategy that uses the target model\\\'s\nattention scores to dynamically select relevant context for the draft model.\nExtensive evaluations on three long-context understanding datasets show that\nSpecExtend accelerates standard tree-based speculative decoding by up to 2.22x\nfor inputs up to 16K tokens, providing an effective solution for speculative\ndecoding of long sequences. The code is available at\nhttps://github.com/jycha98/SpecExtend .','Jungyoub Cha, Hyunjong Kim, Sungzoon Cho','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20776v1'),('2505.20779v2','CHIMERA: A Knowledge Base of Idea Recombination in Scientific Literature','A hallmark of human innovation is the process of recombination -- creating\noriginal ideas by integrating elements of existing mechanisms and concepts. In\nthis work, we automatically mine the scientific literature and build CHIMERA: a\nlarge-scale knowledge base (KB) of recombination examples. CHIMERA can be used\nto empirically explore at scale how scientists recombine concepts and take\ninspiration from different areas, or to train supervised machine learning\nmodels that learn to predict new creative cross-domain directions. To build\nthis KB, we present a novel information extraction task of extracting\nrecombination from scientific paper abstracts, collect a high-quality corpus of\nhundreds of manually annotated abstracts, and use it to train an LLM-based\nextraction model. The model is applied to a large corpus of papers in the AI\ndomain, yielding a KB of over 28K recombination examples. We analyze CHIMERA to\nexplore the properties of recombination in different subareas of AI. Finally,\nwe train a scientific hypothesis generation model using the KB, which predicts\nnew recombination directions that real-world researchers find inspiring. Our\ndata and code are available at https://github.com/noy-sternlicht/CHIMERA-KB','Noy Sternlicht, Tom Hope','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20779v2'),('2505.20781v1','STITCH-OPE: Trajectory Stitching with Guided Diffusion for Off-Policy Evaluation','Off-policy evaluation (OPE) estimates the performance of a target policy\nusing offline data collected from a behavior policy, and is crucial in domains\nsuch as robotics or healthcare where direct interaction with the environment is\ncostly or unsafe. Existing OPE methods are ineffective for high-dimensional,\nlong-horizon problems, due to exponential blow-ups in variance from importance\nweighting or compounding errors from learned dynamics models. To address these\nchallenges, we propose STITCH-OPE, a model-based generative framework that\nleverages denoising diffusion for long-horizon OPE in high-dimensional state\nand action spaces. Starting with a diffusion model pre-trained on the behavior\ndata, STITCH-OPE generates synthetic trajectories from the target policy by\nguiding the denoising process using the score function of the target policy.\nSTITCH-OPE proposes two technical innovations that make it advantageous for\nOPE: (1) prevents over-regularization by subtracting the score of the behavior\npolicy during guidance, and (2) generates long-horizon trajectories by\nstitching partial trajectories together end-to-end. We provide a theoretical\nguarantee that under mild assumptions, these modifications result in an\nexponential reduction in variance versus long-horizon trajectory diffusion.\nExperiments on the D4RL and OpenAI Gym benchmarks show substantial improvement\nin mean squared error, correlation, and regret metrics compared to\nstate-of-the-art OPE methods.','Hossein Goli, Michael Gimelfarb, Nathan Samuel de Lara, Haruki Nishimura, Masha Itkina, Florian Shkurti','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.20781v1'),('2505.20783v1','FM-Planner: Foundation Model Guided Path Planning for Autonomous Drone Navigation','Path planning is a critical component in autonomous drone operations,\nenabling safe and efficient navigation through complex environments. Recent\nadvances in foundation models, particularly large language models (LLMs) and\nvision-language models (VLMs), have opened new opportunities for enhanced\nperception and intelligent decision-making in robotics. However, their\npractical applicability and effectiveness in global path planning remain\nrelatively unexplored. This paper proposes foundation model-guided path\nplanners (FM-Planner) and presents a comprehensive benchmarking study and\npractical validation for drone path planning. Specifically, we first\nsystematically evaluate eight representative LLM and VLM approaches using\nstandardized simulation scenarios. To enable effective real-time navigation, we\nthen design an integrated LLM-Vision planner that combines semantic reasoning\nwith visual perception. Furthermore, we deploy and validate the proposed path\nplanner through real-world experiments under multiple configurations. Our\nfindings provide valuable insights into the strengths, limitations, and\nfeasibility of deploying foundation models in real-world drone applications and\nproviding practical implementations in autonomous flight. Project site:\nhttps://github.com/NTU-ICG/FM-Planner.','Jiaping Xiao, Cheng Wen Tsao, Yuhang Zhang, Mir Feroskhan','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.20783v1'),('2505.20787v1','Debiased Ill-Posed Regression','In various statistical settings, the goal is to estimate a function which is\nrestricted by the statistical model only through a conditional moment\nrestriction. Prominent examples include the nonparametric instrumental variable\nframework for estimating the structural function of the outcome variable, and\nthe proximal causal inference framework for estimating the bridge functions. A\ncommon strategy in the literature is to find the minimizer of the projected\nmean squared error. However, this approach can be sensitive to misspecification\nor slow convergence rate of the estimators of the involved nuisance components.\nIn this work, we propose a debiased estimation strategy based on the influence\nfunction of a modification of the projected error and demonstrate its\nfinite-sample convergence rate. Our proposed estimator possesses a second-order\nbias with respect to the involved nuisance functions and a desirable robustness\nproperty with respect to the misspecification of one of the nuisance functions.\nThe proposed estimator involves a hyper-parameter, for which the optimal value\ndepends on potentially unknown features of the underlying data-generating\nprocess. Hence, we further propose a hyper-parameter selection approach based\non cross-validation and derive an error bound for the resulting estimator. This\nanalysis highlights the potential rate loss due to hyper-parameter selection\nand underscore the importance and advantages of incorporating debiasing in this\nsetting. We also study the application of our approach to the estimation of\nregular parameters in a specific parameter class, which are linear functionals\nof the solutions to the conditional moment restrictions and provide sufficient\nconditions for achieving root-n consistency using our debiased estimator.','AmirEmad Ghassami, James M. Robins, Andrea Rotnitzky','2025-05-27','stat.ME','http://arxiv.org/pdf/2505.20787v1'),('2505.20788v1','Enhancing Wearable Tap Water Audio Detection through Subclass Annotation in the HD-Epic Dataset','Wearable human activity recognition has been shown to benefit from the\ninclusion of acoustic data, as the sounds around a person often contain\nvaluable context. However, due to privacy concerns, it is usually not ethically\nfeasible to record and save microphone data from the device, since the audio\ncould, for instance, also contain private conversations. Rather, the data\nshould be processed locally, which in turn requires processing power and\nconsumes energy on the wearable device. One special use case of contextual\ninformation that can be utilized to augment special tasks in human activity\nrecognition is water flow detection, which can, e.g., be used to aid wearable\nhand washing detection. We created a new label called tap water for the\nrecently released HD-Epic data set, creating 717 hand-labeled annotations of\ntap water flow, based on existing annotations of the water class. We analyzed\nthe relation of tap water and water in the dataset and additionally trained and\nevaluated two lightweight classifiers to evaluate the newly added label class,\nshowing that the new class can be learned more easily.','Robin Burchard, Kristof Van Laerhoven','2025-05-27','cs.HC','http://arxiv.org/pdf/2505.20788v1'),('2505.20789v2','Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models','Inverse problems (IPs) involve reconstructing signals from noisy\nobservations. Recently, diffusion models (DMs) have emerged as a powerful\nframework for solving IPs, achieving remarkable reconstruction performance.\nHowever, existing DM-based methods frequently encounter issues such as heavy\ncomputational demands and suboptimal convergence. In this work, building upon\nthe idea of the recent work DMPlug, we propose two novel methods, DMILO and\nDMILO-PGD, to address these challenges. Our first method, DMILO, employs\nintermediate layer optimization (ILO) to alleviate the memory burden inherent\nin DMPlug. Additionally, by introducing sparse deviations, we expand the range\nof DMs, enabling the exploration of underlying signals that may lie outside the\nrange of the diffusion model. We further propose DMILO-PGD, which integrates\nILO with projected gradient descent (PGD), thereby reducing the risk of\nsuboptimal convergence. We provide an intuitive theoretical analysis of our\napproaches under appropriate conditions and validate their superiority through\nextensive experiments on diverse image datasets, encompassing both linear and\nnonlinear IPs. Our results demonstrate significant performance gains over\nstate-of-the-art methods, highlighting the effectiveness of DMILO and DMILO-PGD\nin addressing common challenges in DM-based IP solvers.','Yang Zheng, Wen Li, Zhaoqiang Liu','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20789v2'),('2505.20793v1','Rendering-Aware Reinforcement Learning for Vector Graphics Generation','Scalable Vector Graphics (SVG) offer a powerful format for representing\nvisual designs as interpretable code. Recent advances in vision-language models\n(VLMs) have enabled high-quality SVG generation by framing the problem as a\ncode generation task and leveraging large-scale pretraining. VLMs are\nparticularly suitable for this task as they capture both global semantics and\nfine-grained visual patterns, while transferring knowledge across vision,\nnatural language, and code domains. However, existing VLM approaches often\nstruggle to produce faithful and efficient SVGs because they never observe the\nrendered images during training. Although differentiable rendering for\nautoregressive SVG code generation remains unavailable, rendered outputs can\nstill be compared to original inputs, enabling evaluative feedback suitable for\nreinforcement learning (RL). We introduce RLRF(Reinforcement Learning from\nRendering Feedback), an RL method that enhances SVG generation in\nautoregressive VLMs by leveraging feedback from rendered SVG outputs. Given an\ninput image, the model generates SVG roll-outs that are rendered and compared\nto the original image to compute a reward. This visual fidelity feedback guides\nthe model toward producing more accurate, efficient, and semantically coherent\nSVGs. RLRF significantly outperforms supervised fine-tuning, addressing common\nfailure modes and enabling precise, high-quality SVG generation with strong\nstructural understanding and generalization.','Juan A. Rodriguez, Haotian Zhang, Abhay Puri, Aarash Feizi, Rishav Pramanik, Pascal Wichmann, Arnab Mondal, Mohammad Reza Samsami, Rabiul Awal, Perouz Taslakian, Spandana Gella, Sai Rajeswar, David Vazquez, Christopher Pal, Marco Pedersoli','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20793v1'),('2505.20794v1','VibE-SVC: Vibrato Extraction with High-frequency F0 Contour for Singing Voice Conversion','Controlling singing style is crucial for achieving an expressive and natural\nsinging voice. Among the various style factors, vibrato plays a key role in\nconveying emotions and enhancing musical depth. However, modeling vibrato\nremains challenging due to its dynamic nature, making it difficult to control\nin singing voice conversion. To address this, we propose VibESVC, a\ncontrollable singing voice conversion model that explicitly extracts and\nmanipulates vibrato using discrete wavelet transform. Unlike previous methods\nthat model vibrato implicitly, our approach decomposes the F0 contour into\nfrequency components, enabling precise transfer. This allows vibrato control\nfor enhanced flexibility. Experimental results show that VibE-SVC effectively\ntransforms singing styles while preserving speaker similarity. Both subjective\nand objective evaluations confirm high-quality conversion.','Joon-Seung Choi, Dong-Min Byun, Hyung-Seok Oh, Seong-Whan Lee','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.20794v1'),('2505.20797v1','Multi-VQC: A Novel QML Approach for Enhancing Healthcare Classification','Accurate and reliable diagnosis of diseases is crucial in enabling timely\nmedical treatment and enhancing patient survival rates. In recent years,\nMachine Learning has revolutionized diagnostic practices by creating\nclassification models capable of identifying diseases. However, these\nclassification problems often suffer from significant class imbalances, which\ncan inhibit the effectiveness of traditional models. Therefore, the interest in\nQuantum models has arisen, driven by the captivating promise of overcoming the\nlimitations of the classical counterpart thanks to their ability to express\ncomplex patterns by mapping data in a higher-dimensional computational space.','Antonio Tudisco, Deborah Volpe, Giovanna Turvani','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20797v1'),('2505.20802v1','Leaner Transformers: More Heads, Less Depth','Transformers have reshaped machine learning by utilizing attention mechanisms\nto capture complex patterns in large datasets, leading to significant\nimprovements in performance. This success has contributed to the belief that\n\"bigger means better\", leading to ever-increasing model sizes. This paper\nchallenge this ideology by showing that many existing transformers might be\nunnecessarily oversized. We discover a theoretical principle that redefines the\nrole of multi-head attention. An important benefit of the multiple heads is in\nimproving the conditioning of the attention block. We exploit this theoretical\ninsight and redesign popular architectures with an increased number of heads.\nThe improvement in the conditioning proves so significant in practice that\nmodel depth can be decreased, reducing the parameter count by up to 30-50%\nwhile maintaining accuracy. We obtain consistent benefits across a variety of\ntransformer-based architectures of various scales, on tasks in computer vision\n(ImageNet-1k) as well as language and sequence modeling (GLUE benchmark,\nTinyStories, and the Long-Range Arena benchmark).','Hemanth Saratchandran, Damien Teney, Simon Lucey','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20802v1'),('2505.20804v1','Quantum Machine Learning in Healthcare: Evaluating QNN and QSVM Models','Effective and accurate diagnosis of diseases such as cancer, diabetes, and\nheart failure is crucial for timely medical intervention and improving patient\nsurvival rates. Machine learning has revolutionized diagnostic methods in\nrecent years by developing classification models that detect diseases based on\nselected features. However, these classification tasks are often highly\nimbalanced, limiting the performance of classical models. Quantum models offer\na promising alternative, exploiting their ability to express complex patterns\nby operating in a higher-dimensional computational space through superposition\nand entanglement. These unique properties make quantum models potentially more\neffective in addressing the challenges of imbalanced datasets. This work\nevaluates the potential of quantum classifiers in healthcare, focusing on\nQuantum Neural Networks (QNNs) and Quantum Support Vector Machines (QSVMs),\ncomparing them with popular classical models. The study is based on three\nwell-known healthcare datasets -- Prostate Cancer, Heart Failure, and Diabetes.\nThe results indicate that QSVMs outperform QNNs across all datasets due to\ntheir susceptibility to overfitting. Furthermore, quantum models prove the\nability to overcome classical models in scenarios with high dataset imbalance.\nAlthough preliminary, these findings highlight the potential of quantum models\nin healthcare classification tasks and lead the way for further research in\nthis domain.','Antonio Tudisco, Deborah Volpe, Giovanna Turvani','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20804v1'),('2505.20807v1','Simple yet Effective Graph Distillation via Clustering','Despite plentiful successes achieved by graph representation learning in\nvarious domains, the training of graph neural networks (GNNs) still remains\ntenaciously challenging due to the tremendous computational overhead needed for\nsizable graphs in practice. Recently, graph data distillation (GDD), which\nseeks to distill large graphs into compact and informative ones, has emerged as\na promising technique to enable efficient GNN training. However, most existing\nGDD works rely on heuristics that align model gradients or representation\ndistributions on condensed and original graphs, leading to compromised result\nquality, expensive training for distilling large graphs, or both. Motivated by\nthis, this paper presents an efficient and effective GDD approach, ClustGDD.\nUnder the hood, ClustGDD resorts to synthesizing the condensed graph and node\nattributes through fast and theoretically-grounded clustering that minimizes\nthe within-cluster sum of squares and maximizes the homophily on the original\ngraph. The fundamental idea is inspired by our empirical and theoretical\nfindings unveiling the connection between clustering and empirical condensation\nquality using Fr\\\\\'echet Inception Distance, a well-known quality metric for\nsynthetic images. Furthermore, to mitigate the adverse effects caused by the\nhomophily-based clustering, ClustGDD refines the nodal attributes of the\ncondensed graph with a small augmentation learned via class-aware graph\nsampling and consistency loss. Our extensive experiments exhibit that GNNs\ntrained over condensed graphs output by ClustGDD consistently achieve superior\nor comparable performance to state-of-the-art GDD methods in terms of node\nclassification on five benchmark datasets, while being orders of magnitude\nfaster.','Yurui Lai, Taiyan Zhang, Renchi Yang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20807v1'),('2505.20809v1','Improved Representation Steering for Language Models','Steering methods for language models (LMs) seek to provide fine-grained and\ninterpretable control over model generations by variously changing model\ninputs, weights, or representations to adjust behavior. Recent work has shown\nthat adjusting weights or representations is often less effective than steering\nby prompting, for instance when wanting to introduce or suppress a particular\nconcept. We demonstrate how to improve representation steering via our new\nReference-free Preference Steering (RePS), a bidirectional\npreference-optimization objective that jointly does concept steering and\nsuppression. We train three parameterizations of RePS and evaluate them on\nAxBench, a large-scale model steering benchmark. On Gemma models with sizes\nranging from 2B to 27B, RePS outperforms all existing steering methods trained\nwith a language modeling objective and substantially narrows the gap with\nprompting -- while promoting interpretability and minimizing parameter count.\nIn suppression, RePS matches the language-modeling objective on Gemma-2 and\noutperforms it on the larger Gemma-3 variants while remaining resilient to\nprompt-based jailbreaking attacks that defeat prompting. Overall, our results\nsuggest that RePS provides an interpretable and robust alternative to prompting\nfor both steering and suppression.','Zhengxuan Wu, Qinan Yu, Aryaman Arora, Christopher D. Manning, Christopher Potts','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20809v1'),('2505.20813v2','RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph','In knowledge graph embedding, leveraging relation specific entity\ntransformation has markedly enhanced performance. However, the consistency of\nembedding differences before and after transformation remains unaddressed,\nrisking the loss of valuable inductive bias inherent in the embeddings. This\ninconsistency stems from two problems. First, transformation representations\nare specified for relations in a disconnected manner, allowing dissimilar\ntransformations and corresponding entity embeddings for similar relations.\nSecond, a generalized plug-in approach as a SFBR (Semantic Filter Based on\nRelations) disrupts this consistency through excessive concentration of entity\nembeddings under entity-based regularization, generating indistinguishable\nscore distributions among relations. In this paper, we introduce a plug-in KGE\nmethod, Relation-Semantics Consistent Filter (RSCF). Its entity transformation\nhas three features for enhancing semantic consistency: 1) shared affine\ntransformation of relation embeddings across all relations, 2) rooted entity\ntransformation that adds an entity embedding to its change represented by the\ntransformed vector, and 3) normalization of the change to prevent scale\nreduction. To amplify the advantages of consistency that preserve semantics on\nembeddings, RSCF adds relation transformation and prediction modules for\nenhancing the semantics. In knowledge graph completion tasks with\ndistance-based and tensor decomposition models, RSCF significantly outperforms\nstate-of-the-art KGE methods, showing robustness across all relations and their\nfrequencies.','Junsik Kim, Jinwook Park, Kangil Kim','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20813v2'),('2505.20815v1','Interpretable Credit Default Prediction with Ensemble Learning and SHAP','This study focuses on the problem of credit default prediction, builds a\nmodeling framework based on machine learning, and conducts comparative\nexperiments on a variety of mainstream classification algorithms. Through\npreprocessing, feature engineering, and model training of the Home Credit\ndataset, the performance of multiple models including logistic regression,\nrandom forest, XGBoost, LightGBM, etc. in terms of accuracy, precision, and\nrecall is evaluated. The results show that the ensemble learning method has\nobvious advantages in predictive performance, especially in dealing with\ncomplex nonlinear relationships between features and data imbalance problems.\nIt shows strong robustness. At the same time, the SHAP method is used to\nanalyze the importance and dependency of features, and it is found that the\nexternal credit score variable plays a dominant role in model decision making,\nwhich helps to improve the model\\\'s interpretability and practical application\nvalue. The research results provide effective reference and technical support\nfor the intelligent development of credit risk control systems.','Shiqi Yang, Ziyi Huang, Wengran Xiao, Xinyu Shen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20815v1'),('2505.20816v1','Rethinking Information Synthesis in Multimodal Question Answering A Multi-Agent Perspective','Recent advances in multimodal question answering have primarily focused on\ncombining heterogeneous modalities or fine-tuning multimodal large language\nmodels. While these approaches have shown strong performance, they often rely\non a single, generalized reasoning strategy, overlooking the unique\ncharacteristics of each modality ultimately limiting both accuracy and\ninterpretability. To address these limitations, we propose MAMMQA, a\nmulti-agent QA framework for multimodal inputs spanning text, tables, and\nimages. Our system includes two Visual Language Model (VLM) agents and one\ntext-based Large Language Model (LLM) agent. The first VLM decomposes the user\nquery into sub-questions and sequentially retrieves partial answers from each\nmodality. The second VLM synthesizes and refines these results through\ncross-modal reasoning. Finally, the LLM integrates the insights into a cohesive\nanswer. This modular design enhances interpretability by making the reasoning\nprocess transparent and allows each agent to operate within its domain of\nexpertise. Experiments on diverse multimodal QA benchmarks demonstrate that our\ncooperative, multi-agent framework consistently outperforms existing baselines\nin both accuracy and robustness.','Krishna Singh Rajput, Tejas Anvekar, Chitta Baral, Vivek Gupta','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20816v1'),('2505.20817v1','Convergence of Clipped-SGD for Convex $(L_0,L_1)$-Smooth Optimization with Heavy-Tailed Noise','Gradient clipping is a widely used technique in Machine Learning and Deep\nLearning (DL), known for its effectiveness in mitigating the impact of\nheavy-tailed noise, which frequently arises in the training of large language\nmodels. Additionally, first-order methods with clipping, such as Clip-SGD,\nexhibit stronger convergence guarantees than SGD under the\n$(L_0,L_1)$-smoothness assumption, a property observed in many DL tasks.\nHowever, the high-probability convergence of Clip-SGD under both assumptions --\nheavy-tailed noise and $(L_0,L_1)$-smoothness -- has not been fully addressed\nin the literature. In this paper, we bridge this critical gap by establishing\nthe first high-probability convergence bounds for Clip-SGD applied to convex\n$(L_0,L_1)$-smooth optimization with heavy-tailed noise. Our analysis extends\nprior results by recovering known bounds for the deterministic case and the\nstochastic setting with $L_1 = 0$ as special cases. Notably, our rates avoid\nexponentially large factors and do not rely on restrictive sub-Gaussian noise\nassumptions, significantly broadening the applicability of gradient clipping.','Savelii Chezhegov, Aleksandr Beznosikov, Samuel Horváth, Eduard Gorbunov','2025-05-27','math.OC','http://arxiv.org/pdf/2505.20817v1'),('2505.20819v1','Tracing and Reversing Rank-One Model Edits','Knowledge editing methods (KEs) are a cost-effective way to update the\nfactual content of large language models (LLMs), but they pose a dual-use risk.\nWhile KEs are beneficial for updating outdated or incorrect information, they\ncan be exploited maliciously to implant misinformation or bias. In order to\ndefend against these types of malicious manipulation, we need robust techniques\nthat can reliably detect, interpret, and mitigate adversarial edits. This work\ninvestigates the traceability and reversibility of knowledge edits, focusing on\nthe widely used Rank-One Model Editing (ROME) method. We first show that ROME\nintroduces distinctive distributional patterns in the edited weight matrices,\nwhich can serve as effective signals for locating the edited weights. Second,\nwe show that these altered weights can reliably be used to predict the edited\nfactual relation, enabling partial reconstruction of the modified fact.\nBuilding on this, we propose a method to infer the edited object entity\ndirectly from the modified weights, without access to the editing prompt,\nachieving over 95% accuracy. Finally, we demonstrate that ROME edits can be\nreversed, recovering the model\\\'s original outputs with $\\geq$ 80% accuracy. Our\nfindings highlight the feasibility of detecting, tracing, and reversing edits\nbased on the edited weights, offering a robust framework for safeguarding LLMs\nagainst adversarial manipulations.','Paul Youssef, Zhixue Zhao, Christin Seifert, Jörg Schlötterer','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20819v1'),('2505.20820v1','MT-Mol:Multi Agent System with Tool-based Reasoning for Molecular Optimization','Large language models (LLMs) have large potential for molecular optimization,\nas they can gather external chemistry tools and enable collaborative\ninteractions to iteratively refine molecular candidates. However, this\npotential remains underexplored, particularly in the context of structured\nreasoning, interpretability, and comprehensive tool-grounded molecular\noptimization. To address this gap, we introduce MT-Mol, a multi-agent framework\nfor molecular optimization that leverages tool-guided reasoning and\nrole-specialized LLM agents. Our system incorporates comprehensive RDKit tools,\ncategorized into five distinct domains: structural descriptors, electronic and\ntopological features, fragment-based functional groups, molecular\nrepresentations, and miscellaneous chemical properties. Each category is\nmanaged by an expert analyst agent, responsible for extracting task-relevant\ntools and enabling interpretable, chemically grounded feedback. MT-Mol produces\nmolecules with tool-aligned and stepwise reasoning through the interaction\nbetween the analyst agents, a molecule-generating scientist, a reasoning-output\nverifier, and a reviewer agent. As a result, we show that our framework shows\nthe state-of-the-art performance of the PMO-1K benchmark on 17 out of 23 tasks.','Hyomin Kim, Yunhui Jang, Sungsoo Ahn','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20820v1'),('2505.20824v1','MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems','As large language models (LLMs) are increasingly deployed in healthcare,\nensuring their safety, particularly within collaborative multi-agent\nconfigurations, is paramount. In this paper we introduce MedSentry, a benchmark\ncomprising 5 000 adversarial medical prompts spanning 25 threat categories with\n100 subthemes. Coupled with this dataset, we develop an end-to-end\nattack-defense evaluation pipeline to systematically analyze how four\nrepresentative multi-agent topologies (Layers, SharedPool, Centralized, and\nDecentralized) withstand attacks from \\\'dark-personality\\\' agents. Our findings\nreveal critical differences in how these architectures handle information\ncontamination and maintain robust decision-making, exposing their underlying\nvulnerability mechanisms. For instance, SharedPool\\\'s open information sharing\nmakes it highly susceptible, whereas Decentralized architectures exhibit\ngreater resilience thanks to inherent redundancy and isolation. To mitigate\nthese risks, we propose a personality-scale detection and correction mechanism\nthat identifies and rehabilitates malicious agents, restoring system safety to\nnear-baseline levels. MedSentry thus furnishes both a rigorous evaluation\nframework and practical defense strategies that guide the design of safer\nLLM-based multi-agent systems in medical domains.','Kai Chen, Taihang Zhen, Hewei Wang, Kailai Liu, Xinfeng Li, Jing Huo, Tianpei Yang, Jinfeng Xu, Wei Dong, Yang Gao','2025-05-27','cs.MA','http://arxiv.org/pdf/2505.20824v1'),('2505.20825v1','Reinforced Informativeness Optimization for Long-Form Retrieval-Augmented Generation','Long-form question answering (LFQA) presents unique challenges for large\nlanguage models, requiring the synthesis of coherent, paragraph-length answers.\nWhile retrieval-augmented generation (RAG) systems have emerged as a promising\nsolution, existing research struggles with key limitations: the scarcity of\nhigh-quality training data for long-form generation, the compounding risk of\nhallucination in extended outputs, and the absence of reliable evaluation\nmetrics for factual completeness. In this paper, we propose RioRAG, a novel\nreinforcement learning (RL) framework that advances long-form RAG through\nreinforced informativeness optimization. Our approach introduces two\nfundamental innovations to address the core challenges. First, we develop an RL\ntraining paradigm of reinforced informativeness optimization that directly\noptimizes informativeness and effectively addresses the slow-thinking deficit\nin conventional RAG systems, bypassing the need for expensive supervised data.\nSecond, we propose a nugget-centric hierarchical reward modeling approach that\nenables precise assessment of long-form answers through a three-stage process:\nextracting the nugget from every source webpage, constructing a nugget claim\nchecklist, and computing rewards based on factual alignment. Extensive\nexperiments on two LFQA benchmarks LongFact and RAGChecker demonstrate the\neffectiveness of the proposed method. Our codes are available at\nhttps://github.com/RUCAIBox/RioRAG.','Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20825v1'),('2505.20826v1','AdParaphrase v2.0: Generating Attractive Ad Texts Using a Preference-Annotated Paraphrase Dataset','Identifying factors that make ad text attractive is essential for advertising\nsuccess. This study proposes AdParaphrase v2.0, a dataset for ad text\nparaphrasing, containing human preference data, to enable the analysis of the\nlinguistic factors and to support the development of methods for generating\nattractive ad texts. Compared with v1.0, this dataset is 20 times larger,\ncomprising 16,460 ad text paraphrase pairs, each annotated with preference data\nfrom ten evaluators, thereby enabling a more comprehensive and reliable\nanalysis. Through the experiments, we identified multiple linguistic features\nof engaging ad texts that were not observed in v1.0 and explored various\nmethods for generating attractive ad texts. Furthermore, our analysis\ndemonstrated the relationships between human preference and ad performance, and\nhighlighted the potential of reference-free metrics based on large language\nmodels for evaluating ad text attractiveness. The dataset is publicly available\nat: https://github.com/CyberAgentAILab/AdParaphrase-v2.0.','Soichiro Murakami, Peinan Zhang, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20826v1'),('2505.20836v1','HAD: Hybrid Architecture Distillation Outperforms Teacher in Genomic Sequence Modeling','Inspired by the great success of Masked Language Modeling (MLM) in the\nnatural language domain, the paradigm of self-supervised pre-training and\nfine-tuning has also achieved remarkable progress in the field of DNA sequence\nmodeling. However, previous methods often relied on massive pre-training data\nor large-scale base models with huge parameters, imposing a significant\ncomputational burden. To address this, many works attempted to use more compact\nmodels to achieve similar outcomes but still fell short by a considerable\nmargin. In this work, we propose a Hybrid Architecture Distillation (HAD)\napproach, leveraging both distillation and reconstruction tasks for more\nefficient and effective pre-training. Specifically, we employ the NTv2-500M as\nthe teacher model and devise a grouping masking strategy to align the feature\nembeddings of visible tokens while concurrently reconstructing the invisible\ntokens during MLM pre-training. To validate the effectiveness of our proposed\nmethod, we conducted comprehensive experiments on the Nucleotide Transformer\nBenchmark and Genomic Benchmark. Compared to models with similar parameters,\nour model achieved excellent performance. More surprisingly, it even surpassed\nthe distillation ceiling-teacher model on some sub-tasks, which is more than\n500 $\\times$ larger. Lastly, we utilize t-SNE for more intuitive visualization,\nwhich shows that our model can gain a sophisticated understanding of the\nintrinsic representation pattern in genomic sequences.','Hexiong Yang, Mingrui Chen, Huaibo Huang, Junxian Duan, Jie Cao, Zhen Zhou, Ran He','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20836v1'),('2505.20839v2','FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration','As large language models become increasingly prevalent, memory bandwidth\nconstraints significantly limit inference throughput, motivating post-training\nquantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ\nframework and an INT4-FP8 matrix multiplication kernel that accelerates LLM\ninference across all linear layers. Specifically, FireQ quantizes linear layer\nweights and key-values to INT4, and activations and queries to FP8,\nsignificantly enhancing throughput. Additionally, we introduce a three-stage\npipelining for the prefill phase, which modifies the FlashAttention-3 kernel,\neffectively reducing time-to-first-token in the prefill phase. To minimize\naccuracy loss from quantization, we develop novel outlier smoothing techniques\ntailored separately for linear and attention layers. In linear layers, we\nexplicitly use per-tensor scaling to prevent underflow caused by the FP8\nquantization scaling factor of INT4 quantization, and channel-wise scaling to\ncompensate for coarse granularity of INT4. In attention layers, we address\nquantization challenges posed by rotary positional embeddings (RoPE) by\ncombining pre-RoPE and post-RoPE scaling strategies. FireQ significantly\noutperforms state-of-the-art methods, achieving 1.68x faster inference in\nfeed-forward network layers on Llama2-7B and 1.26x faster prefill phase\nperformance on Llama3-8B compared to QServe, with negligible accuracy loss.','Daehyeon Baek, Jieun Choi, Jimyoung Son, Kyungmin Bin, Seungbeom Choi, Kihyo Moon, Minsung Jang, Hyojung Lee','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20839v2'),('2505.20840v1','Aggregation Buffer: Revisiting DropEdge with a New Parameter Block','We revisit DropEdge, a data augmentation technique for GNNs which randomly\nremoves edges to expose diverse graph structures during training. While being a\npromising approach to effectively reduce overfitting on specific connections in\nthe graph, we observe that its potential performance gain in supervised\nlearning tasks is significantly limited. To understand why, we provide a\ntheoretical analysis showing that the limited performance of DropEdge comes\nfrom the fundamental limitation that exists in many GNN architectures. Based on\nthis analysis, we propose Aggregation Buffer, a parameter block specifically\ndesigned to improve the robustness of GNNs by addressing the limitation of\nDropEdge. Our method is compatible with any GNN model, and shows consistent\nperformance improvements on multiple datasets. Moreover, our method effectively\naddresses well-known problems such as degree bias or structural disparity as a\nunifying solution. Code and datasets are available at\nhttps://github.com/dooho00/agg-buffer.','Dooho Lee, Myeong Kong, Sagad Hamid, Cheonwoo Lee, Jaemin Yoo','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20840v1'),('2505.20841v1','Concealment of Intent: A Game-Theoretic Analysis','As large language models (LLMs) grow more capable, concerns about their safe\ndeployment have also grown. Although alignment mechanisms have been introduced\nto deter misuse, they remain vulnerable to carefully designed adversarial\nprompts. In this work, we present a scalable attack strategy: intent-hiding\nadversarial prompting, which conceals malicious intent through the composition\nof skills. We develop a game-theoretic framework to model the interaction\nbetween such attacks and defense systems that apply both prompt and response\nfiltering. Our analysis identifies equilibrium points and reveals structural\nadvantages for the attacker. To counter these threats, we propose and analyze a\ndefense mechanism tailored to intent-hiding attacks. Empirically, we validate\nthe attack\\\'s effectiveness on multiple real-world LLMs across a range of\nmalicious behaviors, demonstrating clear advantages over existing adversarial\nprompting techniques.','Xinbo Wu, Abhishek Umrawal, Lav R. Varshney','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20841v1'),('2505.20853v2','Cooperation of Experts: Fusing Heterogeneous Information with Large Margin','Fusing heterogeneous information remains a persistent challenge in modern\ndata analysis. While significant progress has been made, existing approaches\noften fail to account for the inherent heterogeneity of object patterns across\ndifferent semantic spaces. To address this limitation, we propose the\nCooperation of Experts (CoE) framework, which encodes multi-typed information\ninto unified heterogeneous multiplex networks. By overcoming modality and\nconnection differences, CoE provides a powerful and flexible model for\ncapturing the intricate structures of real-world complex data. In our\nframework, dedicated encoders act as domain-specific experts, each specializing\nin learning distinct relational patterns in specific semantic spaces. To\nenhance robustness and extract complementary knowledge, these experts\ncollaborate through a novel large margin mechanism supported by a tailored\noptimization strategy. Rigorous theoretical analyses guarantee the framework\\\'s\nfeasibility and stability, while extensive experiments across diverse\nbenchmarks demonstrate its superior performance and broad applicability. Our\ncode is available at https://github.com/strangeAlan/CoE.','Shuo Wang, Shunyang Huang, Jinghui Yuan, Zhixiang Shen, Zhao Kang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20853v2'),('2505.20854v1','An LLM-as-Judge Metric for Bridging the Gap with Human Evaluation in SE Tasks','Large Language Models (LLMs) and other automated techniques have been\nincreasingly used to support software developers by generating software\nartifacts such as code snippets, patches, and comments. However, accurately\nassessing the correctness of these generated artifacts remains a significant\nchallenge. On one hand, human evaluation provides high accuracy but is\nlabor-intensive and lacks scalability. On the other hand, other existing\nautomatic evaluation metrics are scalable and require minimal human effort, but\nthey often fail to accurately reflect the actual correctness of generated\nsoftware artifacts.\n  In this paper, we present SWE-Judge, the first evaluation metric for\nLLM-as-Ensemble-Judge specifically designed to accurately assess the\ncorrectness of generated software artifacts. SWE-Judge first defines five\ndistinct evaluation strategies, each implemented as an independent judge. A\ndynamic team selection mechanism then identifies the most appropriate subset of\njudges to produce a final correctness score through ensembling. We evaluate\nSWE-Judge across a diverse set of software engineering (SE) benchmarks,\nincluding CoNaLa, Card2Code, HumanEval-X, APPS, APR-Assess, and Summary-Assess.\nThese benchmarks span three SE tasks: code generation, automated program\nrepair, and code summarization. Experimental results demonstrate that SWE-Judge\nconsistently achieves a higher correlation with human judgments, with\nimprovements ranging from 5.9% to 183.8% over existing automatic metrics.\nFurthermore, SWE-Judge reaches agreement levels with human annotators that are\ncomparable to inter-annotator agreement in code generation and program repair\ntasks. These findings underscore SWE-Judge\\\'s potential as a scalable and\nreliable alternative to human evaluation.','Xin Zhou, Kisub Kim, Ting Zhang, Martin Weyssow, Luis F. Gomes, Guang Yang, David Lo','2025-05-27','cs.SE','http://arxiv.org/pdf/2505.20854v1'),('2505.20863v1','Leveraging Diffusion Models for Parameterized Quantum Circuit Generation','Quantum computing holds immense potential, yet its practical success depends\non multiple factors, including advances in quantum circuit design. In this\npaper, we introduce a generative approach based on denoising diffusion models\n(DMs) to synthesize parameterized quantum circuits (PQCs). Extending the recent\ndiffusion model pipeline of F\\\"urrutter et al. [1], our model effectively\nconditions the synthesis process, enabling the simultaneous generation of\ncircuit architectures and their continuous gate parameters. We demonstrate our\napproach in synthesizing PQCs optimized for generating high-fidelity\nGreenberger-Horne-Zeilinger (GHZ) states and achieving high accuracy in quantum\nmachine learning (QML) classification tasks. Our results indicate a strong\ngeneralization across varying gate sets and scaling qubit counts, highlighting\nthe versatility and computational efficiency of diffusion-based methods. This\nwork illustrates the potential of generative models as a powerful tool for\naccelerating and optimizing the design of PQCs, supporting the development of\nmore practical and scalable quantum applications.','Daniel Barta, Darya Martyniuk, Johannes Jung, Adrian Paschke','2025-05-27','quant-ph','http://arxiv.org/pdf/2505.20863v1'),('2505.20864v1','Stability Selection via Variable Decorrelation','The Lasso is a prominent algorithm for variable selection. However, its\ninstability in the presence of correlated variables in the high-dimensional\nsetting is well-documented. Although previous research has attempted to address\nthis issue by modifying the Lasso loss function, this paper introduces an\napproach that simplifies the data processed by Lasso. We propose that\ndecorrelating variables before applying the Lasso improves the stability of\nvariable selection regardless of the direction of correlation among predictors.\nFurthermore, we highlight that the irrepresentable condition, which ensures\nconsistency for the Lasso, is satisfied after variable decorrelation under two\nassumptions. In addition, by noting that the instability of the Lasso is not\nlimited to high-dimensional settings, we demonstrate the effectiveness of the\nproposed approach for low-dimensional data. Finally, we present empirical\nresults that indicate the efficacy of the proposed method across different\nvariable selection techniques, highlighting its potential for broader\napplication. The DVS R package is developed to facilitate the implementation of\nthe methodology proposed in this paper.','Mahdi Nouraie, Connor Smith, Samuel Muller','2025-05-27','stat.ME','http://arxiv.org/pdf/2505.20864v1'),('2505.20866v1','Respond to Change with Constancy: Instruction-tuning with LLM for Non-I.I.D. Network Traffic Classification','Encrypted traffic classification is highly challenging in network security\ndue to the need for extracting robust features from content-agnostic traffic\ndata. Existing approaches face critical issues: (i) Distribution drift, caused\nby reliance on the closedworld assumption, limits adaptability to realworld,\nshifting patterns; (ii) Dependence on labeled data restricts applicability\nwhere such data is scarce or unavailable. Large language models (LLMs) have\ndemonstrated remarkable potential in offering generalizable solutions across a\nwide range of tasks, achieving notable success in various specialized fields.\nHowever, their effectiveness in traffic analysis remains constrained by\nchallenges in adapting to the unique requirements of the traffic domain. In\nthis paper, we introduce a novel traffic representation model named Encrypted\nTraffic Out-of-Distribution Instruction Tuning with LLM (ETooL), which\nintegrates LLMs with knowledge of traffic structures through a self-supervised\ninstruction tuning paradigm. This framework establishes connections between\ntextual information and traffic interactions. ETooL demonstrates more robust\nclassification performance and superior generalization in both supervised and\nzero-shot traffic classification tasks. Notably, it achieves significant\nimprovements in F1 scores: APP53 (I.I.D.) to 93.19%(6.62%) and 92.11%(4.19%),\nAPP53 (O.O.D.) to 74.88%(18.17%) and 72.13%(15.15%), and ISCX-Botnet (O.O.D.)\nto 95.03%(9.16%) and 81.95%(12.08%). Additionally, we construct NETD, a traffic\ndataset designed to support dynamic distributional shifts, and use it to\nvalidate ETooL\\\'s effectiveness under varying distributional conditions.\nFurthermore, we evaluate the efficiency gains achieved through ETooL\\\'s\ninstruction tuning approach.','Xinjie Lin, Gang Xiong, Gaopeng Gou, Wenqi Dong, Jing Yu, Zhen Li, Wei Xia','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.20866v1'),('2505.20868v1','Spotlight-TTS: Spotlighting the Style via Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech','Recent advances in expressive text-to-speech (TTS) have introduced diverse\nmethods based on style embedding extracted from reference speech. However,\nsynthesizing high-quality expressive speech remains challenging. We propose\nSpotlight-TTS, which exclusively emphasizes style via voiced-aware style\nextraction and style direction adjustment. Voiced-aware style extraction\nfocuses on voiced regions highly related to style while maintaining continuity\nacross different speech regions to improve expressiveness. We adjust the\ndirection of the extracted style for optimal integration into the TTS model,\nwhich improves speech quality. Experimental results demonstrate that\nSpotlight-TTS achieves superior performance compared to baseline models in\nterms of expressiveness, overall speech quality, and style transfer capability.\nOur audio samples are publicly available.','Nam-Gyu Kim, Deok-Hyeon Cho, Seung-Bin Kim, Seong-Whan Lee','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.20868v1'),('2505.20869v1','Step-Wise Formal Verification for LLM-Based Mathematical Problem Solving','Large Language Models (LLMs) have demonstrated formidable capabilities in\nsolving mathematical problems, yet they may still commit logical reasoning and\ncomputational errors during the problem-solving process. Thus, this paper\nproposes a framework, MATH-VF, which includes a Formalizer and a Critic, for\nformally verifying the correctness of the solutions generated by large language\nmodels. Our framework first utilizes a Formalizer which employs an LLM to\ntranslate a natural language solution into a formal context. Afterward, our\nCritic (which integrates various external tools such as a Computer Algebra\nSystem and an SMT solver) evaluates the correctness of each statement within\nthe formal context, and when a statement is incorrect, our Critic provides\ncorrective feedback. We empirically investigate the effectiveness of MATH-VF in\ntwo scenarios: 1) Verification: MATH-VF is utilized to determine the\ncorrectness of a solution to a given problem. 2) Refinement: When MATH-VF\nidentifies errors in the solution generated by an LLM-based solution generator\nfor a given problem, it submits the corrective suggestions proposed by the\nCritic to the solution generator to regenerate the solution. We evaluate our\nframework on widely used mathematical benchmarks: MATH500 and ProcessBench,\ndemonstrating the superiority of our approach over existing approaches.','Kuo Zhou, Lu Zhang','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20869v1'),('2505.20871v1','Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG','Large language models (LLMs) augmented with retrieval systems have\nsignificantly advanced natural language processing tasks by integrating\nexternal knowledge sources, enabling more accurate and contextually rich\nresponses. To improve the robustness of such systems against noisy retrievals,\nRetrieval-Augmented Fine-Tuning (RAFT) has emerged as a widely adopted method.\nHowever, RAFT conditions models to generate answers even in the absence of\nreliable knowledge. This behavior undermines their reliability in high-stakes\ndomains, where acknowledging uncertainty is critical. To address this issue, we\npropose Divide-Then-Align (DTA), a post-training approach designed to endow RAG\nsystems with the ability to respond with \"I don\\\'t know\" when the query is out\nof the knowledge boundary of both the retrieved passages and the model\\\'s\ninternal knowledge. DTA divides data samples into four knowledge quadrants and\nconstructs tailored preference data for each quadrant, resulting in a curated\ndataset for Direct Preference Optimization (DPO). Experimental results on three\nbenchmark datasets demonstrate that DTA effectively balances accuracy with\nappropriate abstention, enhancing the reliability and trustworthiness of\nretrieval-augmented systems.','Xin Sun, Jianan Xie, Zhongqi Chen, Qiang Liu, Shu Wu, Yuehe Chen, Bowen Song, Weiqiang Wang, Zilei Wang, Liang Wang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20871v1'),('2505.20872v1','In Context Learning with Vision Transformers: Case Study','Large transformer models have been shown to be capable of performing\nin-context learning. By using examples in a prompt as well as a query, they are\ncapable of performing tasks such as few-shot, one-shot, or zero-shot learning\nto output the corresponding answer to this query. One area of interest to us is\nthat these transformer models have been shown to be capable of learning the\ngeneral class of certain functions, such as linear functions and small 2-layer\nneural networks, on random data (Garg et al, 2023). We aim to extend this to\nthe image space to analyze their capability to in-context learn more complex\nfunctions on the image space, such as convolutional neural networks and other\nmethods.','Antony Zhao, Alex Proshkin, Fergal Hennessy, Francesco Crivelli','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20872v1'),('2505.20874v1','Can LLMs Learn to Map the World from Local Descriptions?','Recent advances in Large Language Models (LLMs) have demonstrated strong\ncapabilities in tasks such as code and mathematics. However, their potential to\ninternalize structured spatial knowledge remains underexplored. This study\ninvestigates whether LLMs, grounded in locally relative human observations, can\nconstruct coherent global spatial cognition by integrating fragmented\nrelational descriptions. We focus on two core aspects of spatial cognition:\nspatial perception, where models infer consistent global layouts from local\npositional relationships, and spatial navigation, where models learn road\nconnectivity from trajectory data and plan optimal paths between unconnected\nlocations. Experiments conducted in a simulated urban environment demonstrate\nthat LLMs not only generalize to unseen spatial relationships between points of\ninterest (POIs) but also exhibit latent representations aligned with real-world\nspatial distributions. Furthermore, LLMs can learn road connectivity from\ntrajectory descriptions, enabling accurate path planning and dynamic spatial\nawareness during navigation.','Sirui Xia, Aili Chen, Xintao Wang, Tinghui Zhu, Yikai Zhang, Jiangjie Chen, Yanghua Xiao','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20874v1'),('2505.20875v1','Trans-EnV: A Framework for Evaluating the Linguistic Robustness of LLMs Against English Varieties','Large Language Models (LLMs) are predominantly evaluated on Standard American\nEnglish (SAE), often overlooking the diversity of global English varieties.\nThis narrow focus may raise fairness concerns as degraded performance on\nnon-standard varieties can lead to unequal benefits for users worldwide.\nTherefore, it is critical to extensively evaluate the linguistic robustness of\nLLMs on multiple non-standard English varieties. We introduce Trans-EnV, a\nframework that automatically transforms SAE datasets into multiple English\nvarieties to evaluate the linguistic robustness. Our framework combines (1)\nlinguistics expert knowledge to curate variety-specific features and\ntransformation guidelines from linguistic literature and corpora, and (2)\nLLM-based transformations to ensure both linguistic validity and scalability.\nUsing Trans-EnV, we transform six benchmark datasets into 38 English varieties\nand evaluate seven state-of-the-art LLMs. Our results reveal significant\nperformance disparities, with accuracy decreasing by up to 46.3% on\nnon-standard varieties. These findings highlight the importance of\ncomprehensive linguistic robustness evaluation across diverse English\nvarieties. Each construction of Trans-EnV was validated through rigorous\nstatistical testing and consultation with a researcher in the field of second\nlanguage acquisition, ensuring its linguistic validity. Our\n\\href{https://github.com/jiyounglee-0523/TransEnV}{code} and\n\\href{https://huggingface.co/collections/jiyounglee0523/transenv-681eadb3c0c8cf363b363fb1}{datasets}\nare publicly available.','Jiyoung Lee, Seungho Kim, Jieun Han, Jun-Min Lee, Kitaek Kim, Alice Oh, Edward Choi','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20875v1'),('2505.20880v1','MSA at SemEval-2025 Task 3: High Quality Weak Labeling and LLM Ensemble Verification for Multilingual Hallucination Detection','This paper describes our submission for SemEval-2025 Task 3: Mu-SHROOM, the\nMultilingual Shared-task on Hallucinations and Related Observable\nOvergeneration Mistakes. The task involves detecting hallucinated spans in text\ngenerated by instruction-tuned Large Language Models (LLMs) across multiple\nlanguages. Our approach combines task-specific prompt engineering with an LLM\nensemble verification mechanism, where a primary model extracts hallucination\nspans and three independent LLMs adjudicate their validity through\nprobability-based voting. This framework simulates the human annotation\nworkflow used in the shared task validation and test data. Additionally, fuzzy\nmatching refines span alignment. Our system ranked 1st in Arabic and Basque,\n2nd in German, Swedish, and Finnish, and 3rd in Czech, Farsi, and French.','Baraa Hikal, Ahmed Nasreldin, Ali Hamdi','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20880v1'),('2505.20881v1','Generalizable Heuristic Generation Through Large Language Models with Meta-Optimization','Heuristic design with large language models (LLMs) has emerged as a promising\napproach for tackling combinatorial optimization problems (COPs). However,\nexisting approaches often rely on manually predefined evolutionary computation\n(EC) optimizers and single-task training schemes, which may constrain the\nexploration of diverse heuristic algorithms and hinder the generalization of\nthe resulting heuristics. To address these issues, we propose Meta-Optimization\nof Heuristics (MoH), a novel framework that operates at the optimizer level,\ndiscovering effective optimizers through the principle of meta-learning.\nSpecifically, MoH leverages LLMs to iteratively refine a meta-optimizer that\nautonomously constructs diverse optimizers through (self-)invocation, thereby\neliminating the reliance on a predefined EC optimizer. These constructed\noptimizers subsequently evolve heuristics for downstream tasks, enabling\nbroader heuristic exploration. Moreover, MoH employs a multi-task training\nscheme to promote its generalization capability. Experiments on classic COPs\ndemonstrate that MoH constructs an effective and interpretable meta-optimizer,\nachieving state-of-the-art performance across various downstream tasks,\nparticularly in cross-size settings.','Yiding Shi, Jianan Zhou, Wen Song, Jieyi Bi, Yaoxin Wu, Jie Zhang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20881v1'),('2505.20882v1','Fedivertex: a Graph Dataset based on Decentralized Social Networks for Trustworthy Machine Learning','Decentralized machine learning - where each client keeps its own data locally\nand uses its own computational resources to collaboratively train a model by\nexchanging peer-to-peer messages - is increasingly popular, as it enables\nbetter scalability and control over the data. A major challenge in this setting\nis that learning dynamics depend on the topology of the communication graph,\nwhich motivates the use of real graph datasets for benchmarking decentralized\nalgorithms. Unfortunately, existing graph datasets are largely limited to\nfor-profit social networks crawled at a fixed point in time and often collected\nat the user scale, where links are heavily influenced by the platform and its\nrecommendation algorithms. The Fediverse, which includes several free and\nopen-source decentralized social media platforms such as Mastodon, Misskey, and\nLemmy, offers an interesting real-world alternative. We introduce Fedivertex, a\nnew dataset of 182 graphs, covering seven social networks from the Fediverse,\ncrawled weekly over 14 weeks. We release the dataset along with a Python\npackage to facilitate its use, and illustrate its utility on several tasks,\nincluding a new defederation task, which captures a process of link deletion\nobserved on these networks.','Marc Damie, Edwige Cyffers','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20882v1'),('2505.20885v2','Improved Bounds for Swap Multicalibration and Swap Omniprediction','In this paper, we consider the related problems of multicalibration -- a\nmultigroup fairness notion and omniprediction -- a simultaneous loss\nminimization paradigm, both in the distributional and online settings. The\nrecent work of Garg et al. (2024) raised the open problem of whether it is\npossible to efficiently achieve $O(\\sqrt{T})$ $\\ell_{2}$-multicalibration error\nagainst bounded linear functions. In this paper, we answer this question in a\nstrongly affirmative sense. We propose an efficient algorithm that achieves\n$O(T^{\\frac{1}{3}})$ $\\ell_{2}$-swap multicalibration error (both in high\nprobability and expectation). On propagating this bound onward, we obtain\nsignificantly improved rates for $\\ell_{1}$-swap multicalibration and swap\nomniprediction for a loss class of convex Lipschitz functions. In particular,\nwe show that our algorithm achieves $O(T^{\\frac{2}{3}})$ $\\ell_{1}$-swap\nmulticalibration and swap omniprediction errors, thereby improving upon the\nprevious best-known bound of $O(T^{\\frac{7}{8}})$. As a consequence of our\nimproved online results, we further obtain several improved sample complexity\nrates in the distributional setting. In particular, we establish a\n$O(\\varepsilon ^ {-3})$ sample complexity of efficiently learning an\n$\\varepsilon$-swap omnipredictor for the class of convex and Lipschitz\nfunctions, $O(\\varepsilon ^{-2.5})$ sample complexity of efficiently learning\nan $\\varepsilon$-swap agnostic learner for the squared loss, and $O(\\varepsilon\n^ {-5}), O(\\varepsilon ^ {-2.5})$ sample complexities of learning $\\ell_{1},\n\\ell_{2}$-swap multicalibrated predictors against linear functions, all of\nwhich significantly improve on the previous best-known bounds.','Haipeng Luo, Spandan Senapati, Vatsal Sharan','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20885v2'),('2505.20888v1','EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models','In this paper, we present EasyDistill, a comprehensive toolkit designed for\neffective black-box and white-box knowledge distillation (KD) of large language\nmodels (LLMs). Our framework offers versatile functionalities, including data\nsynthesis, supervised fine-tuning, ranking optimization, and reinforcement\nlearning techniques specifically tailored for KD scenarios. The toolkit\naccommodates KD functionalities for both System 1 (fast, intuitive) and System\n2 (slow, analytical) models. With its modular design and user-friendly\ninterface, EasyDistill empowers researchers and industry practitioners to\nseamlessly experiment with and implement state-of-the-art KD strategies for\nLLMs. In addition, EasyDistill provides a series of robust distilled models and\nKD-based industrial solutions developed by us, along with the corresponding\nopen-sourced datasets, catering to a variety of use cases. Furthermore, we\ndescribe the seamless integration of EasyDistill into Alibaba Cloud\\\'s Platform\nfor AI (PAI). Overall, the EasyDistill toolkit makes advanced KD techniques for\nLLMs more accessible and impactful within the NLP community.','Chengyu Wang, Junbing Yan, Wenrui Cai, Yuanhao Yue, Jun Huang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20888v1'),('2505.20889v1','Reinforcement Learning-based Sequential Route Recommendation for System-Optimal Traffic Assignment','Modern navigation systems and shared mobility platforms increasingly rely on\npersonalized route recommendations to improve individual travel experience and\noperational efficiency. However, a key question remains: can such sequential,\npersonalized routing decisions collectively lead to system-optimal (SO) traffic\nassignment? This paper addresses this question by proposing a learning-based\nframework that reformulates the static SO traffic assignment problem as a\nsingle-agent deep reinforcement learning (RL) task. A central agent\nsequentially recommends routes to travelers as origin-destination (OD) demands\narrive, to minimize total system travel time. To enhance learning efficiency\nand solution quality, we develop an MSA-guided deep Q-learning algorithm that\nintegrates the iterative structure of traditional traffic assignment methods\ninto the RL training process. The proposed approach is evaluated on both the\nBraess and Ortuzar-Willumsen (OW) networks. Results show that the RL agent\nconverges to the theoretical SO solution in the Braess network and achieves\nonly a 0.35% deviation in the OW network. Further ablation studies demonstrate\nthat the route action set\\\'s design significantly impacts convergence speed and\nfinal performance, with SO-informed route sets leading to faster learning and\nbetter outcomes. This work provides a theoretically grounded and practically\nrelevant approach to bridging individual routing behavior with system-level\nefficiency through learning-based sequential assignment.','Leizhen Wang, Peibo Duan, Cheng Lyu, Zhenliang Ma','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20889v1'),('2505.20890v1','Frequency Composition for Compressed and Domain-Adaptive Neural Networks','Modern on-device neural network applications must operate under resource\nconstraints while adapting to unpredictable domain shifts. However, this\ncombined challenge-model compression and domain adaptation-remains largely\nunaddressed, as prior work has tackled each issue in isolation: compressed\nnetworks prioritize efficiency within a fixed domain, whereas large, capable\nmodels focus on handling domain shifts. In this work, we propose CoDA, a\nfrequency composition-based framework that unifies compression and domain\nadaptation. During training, CoDA employs quantization-aware training (QAT)\nwith low-frequency components, enabling a compressed model to selectively learn\nrobust, generalizable features. At test time, it refines the compact model in a\nsource-free manner (i.e., test-time adaptation, TTA), leveraging the\nfull-frequency information from incoming data to adapt to target domains while\ntreating high-frequency components as domain-specific cues. LFC are aligned\nwith the trained distribution, while HFC unique to the target distribution are\nsolely utilized for batch normalization. CoDA can be integrated synergistically\ninto existing QAT and TTA methods. CoDA is evaluated on widely used\ndomain-shift benchmarks, including CIFAR10-C and ImageNet-C, across various\nmodel architectures. With significant compression, it achieves accuracy\nimprovements of 7.96%p on CIFAR10-C and 5.37%p on ImageNet-C over the\nfull-precision TTA baseline.','Yoojin Kwon, Hongjun Suh, Wooseok Lee, Taesik Gong, Songyi Han, Hyung-Sin Kim','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20890v1'),('2505.20892v1','One-Time Soft Alignment Enables Resilient Learning without Weight Transport','Backpropagation is the cornerstone of deep learning, but its reliance on\nsymmetric weight transport and global synchronization makes it computationally\nexpensive and biologically implausible. Feedback alignment offers a promising\nalternative by approximating error gradients through fixed random feedback,\nthereby avoiding symmetric weight transport. However, this approach often\nstruggles with poor learning performance and instability, especially in deep\nnetworks. Here, we show that a one-time soft alignment between forward and\nfeedback weights at initialization enables deep networks to achieve performance\ncomparable to backpropagation, without requiring weight transport during\nlearning. This simple initialization condition guides stable error minimization\nin the loss landscape, improving network trainability. Spectral analyses\nfurther reveal that initial alignment promotes smoother gradient flow and\nconvergence to flatter minima, resulting in better generalization and\nrobustness. Notably, we also find that allowing moderate deviations from exact\nweight symmetry can improve adversarial robustness compared to standard\nbackpropagation. These findings demonstrate that a simple initialization\nstrategy can enable effective learning in deep networks in a biologically\nplausible and resource-efficient manner.','Jeonghwan Cheon, Jaehyuk Bae, Se-Bum Paik','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20892v1'),('2505.20894v1','DeepConvContext: A Multi-Scale Approach to Timeseries Classification in Human Activity Recognition','Despite recognized limitations in modeling long-range temporal dependencies,\nHuman Activity Recognition (HAR) has traditionally relied on a sliding window\napproach to segment labeled datasets. Deep learning models like the\nDeepConvLSTM typically classify each window independently, thereby restricting\nlearnable temporal context to within-window information. To address this\nconstraint, we propose DeepConvContext, a multi-scale time series\nclassification framework for HAR. Drawing inspiration from the vision-based\nTemporal Action Localization community, DeepConvContext models both intra- and\ninter-window temporal patterns by processing sequences of time-ordered windows.\nUnlike recent HAR models that incorporate attention mechanisms, DeepConvContext\nrelies solely on LSTMs -- with ablation studies demonstrating the superior\nperformance of LSTMs over attention-based variants for modeling inertial sensor\ndata. Across six widely-used HAR benchmarks, DeepConvContext achieves an\naverage 10% improvement in F1-score over the classic DeepConvLSTM, with gains\nof up to 21%. Code to reproduce our experiments is publicly available via\ngithub.com/mariusbock/context_har.','Marius Bock, Michael Moeller, Kristof Van Laerhoven','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20894v1'),('2505.20896v1','How Do Transformers Learn Variable Binding in Symbolic Programs?','Variable binding -- the ability to associate variables with values -- is\nfundamental to symbolic computation and cognition. Although classical\narchitectures typically implement variable binding via addressable memory, it\nis not well understood how modern neural networks lacking built-in binding\noperations may acquire this capacity. We investigate this by training a\nTransformer to dereference queried variables in symbolic programs where\nvariables are assigned either numerical constants or other variables. Each\nprogram requires following chains of variable assignments up to four steps deep\nto find the queried value, and also contains irrelevant chains of assignments\nacting as distractors. Our analysis reveals a developmental trajectory with\nthree distinct phases during training: (1) random prediction of numerical\nconstants, (2) a shallow heuristic prioritizing early variable assignments, and\n(3) the emergence of a systematic mechanism for dereferencing assignment\nchains. Using causal interventions, we find that the model learns to exploit\nthe residual stream as an addressable memory space, with specialized attention\nheads routing information across token positions. This mechanism allows the\nmodel to dynamically track variable bindings across layers, resulting in\naccurate dereferencing. Our results show how Transformer models can learn to\nimplement systematic variable binding without explicit architectural support,\nbridging connectionist and symbolic approaches.','Yiwei Wu, Atticus Geiger, Raphaël Millière','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20896v1'),('2505.20897v1','Cross from Left to Right Brain: Adaptive Text Dreamer for Vision-and-Language Navigation','Vision-and-Language Navigation (VLN) requires the agent to navigate by\nfollowing natural instructions under partial observability, making it difficult\nto align perception with language. Recent methods mitigate this by imagining\nfuture scenes, yet they rely on vision-based synthesis, leading to high\ncomputational cost and redundant details. To this end, we propose to adaptively\nimagine key environmental semantics via \\textit{language} form, enabling a more\nreliable and efficient strategy. Specifically, we introduce a novel Adaptive\nText Dreamer (ATD), a dual-branch self-guided imagination policy built upon a\nlarge language model (LLM). ATD is designed with a human-like left-right brain\narchitecture, where the left brain focuses on logical integration, and the\nright brain is responsible for imaginative prediction of future scenes. To\nachieve this, we fine-tune only the Q-former within both brains to efficiently\nactivate domain-specific knowledge in the LLM, enabling dynamic updates of\nlogical reasoning and imagination during navigation. Furthermore, we introduce\na cross-interaction mechanism to regularize the imagined outputs and inject\nthem into a navigation expert module, allowing ATD to jointly exploit both the\nreasoning capacity of the LLM and the expertise of the navigation model. We\nconduct extensive experiments on the R2R benchmark, where ATD achieves\nstate-of-the-art performance with fewer parameters. The code is\n\\href{https://github.com/zhangpingrui/Adaptive-Text-Dreamer}{here}.','Pingrui Zhang, Yifei Su, Pengyuan Wu, Dong An, Li Zhang, Zhigang Wang, Dong Wang, Yan Ding, Bin Zhao, Xuelong Li','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20897v1'),('2505.20899v1','Dub-S2ST: Textless Speech-to-Speech Translation for Seamless Dubbing','This paper introduces a cross-lingual dubbing system that translates speech\nfrom one language to another while preserving key characteristics such as\nduration, speaker identity, and speaking speed. Despite the strong translation\nquality of existing speech translation approaches, they often overlook the\ntransfer of speech patterns, leading to mismatches with source speech and\nlimiting their suitability for dubbing applications. To address this, we\npropose a discrete diffusion-based speech-to-unit translation model with\nexplicit duration control, enabling time-aligned translation. We then\nsynthesize speech based on the predicted units and source identity with a\nconditional flow matching model. Additionally, we introduce a unit-based speed\nadaptation mechanism that guides the translation model to produce speech at a\nrate consistent with the source, without relying on any text. Extensive\nexperiments demonstrate that our framework generates natural and fluent\ntranslations that align with the original speech\\\'s duration and speaking pace,\nwhile achieving competitive translation performance.','Jeongsoo Choi, Jaehun Kim, Joon Son Chung','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20899v1'),('2505.20901v1','A Stereotype Content Analysis on Color-related Social Bias in Large Vision Language Models','As large vision language models(LVLMs) rapidly advance, concerns about their\npotential to learn and generate social biases and stereotypes are increasing.\nPrevious studies on LVLM\\\'s stereotypes face two primary limitations: metrics\nthat overlooked the importance of content words, and datasets that overlooked\nthe effect of color. To address these limitations, this study introduces new\nevaluation metrics based on the Stereotype Content Model (SCM). We also propose\nBASIC, a benchmark for assessing gender, race, and color stereotypes. Using SCM\nmetrics and BASIC, we conduct a study with eight LVLMs to discover stereotypes.\nAs a result, we found three findings. (1) The SCM-based evaluation is effective\nin capturing stereotypes. (2) LVLMs exhibit color stereotypes in the output\nalong with gender and race ones. (3) Interaction between model architecture and\nparameter sizes seems to affect stereotypes. We release BASIC publicly on\n[anonymized for review].','Junhyuk Choi, Minju Kim, Yeseon Hong, Bugeun Kim','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20901v1'),('2505.20903v1','Towards Objective Fine-tuning: How LLMs\\\' Prior Knowledge Causes Potential Poor Calibration?','Fine-tuned Large Language Models (LLMs) often demonstrate poor calibration,\nwith their confidence scores misaligned with actual performance. While\ncalibration has been extensively studied in models trained from scratch, the\nimpact of LLMs\\\' prior knowledge on calibration during fine-tuning remains\nunderstudied. Our research reveals that LLMs\\\' prior knowledge causes potential\npoor calibration due to the ubiquitous presence of known data in real-world\nfine-tuning, which appears harmful for calibration. Specifically, data aligned\nwith LLMs\\\' prior knowledge would induce overconfidence, while new knowledge\nimproves calibration. Our findings expose a tension: LLMs\\\' encyclopedic\nknowledge, while enabling task versatility, undermines calibration through\nunavoidable knowledge overlaps. To address this, we propose CogCalib, a\ncognition-aware framework that applies targeted learning strategies according\nto the model\\\'s prior knowledge. Experiments across 7 tasks using 3 LLM families\nprove that CogCalib significantly improves calibration while maintaining\nperformance, achieving an average 57\\% reduction in ECE compared to standard\nfine-tuning in Llama3-8B. These improvements generalize well to out-of-domain\ntasks, enhancing the objectivity and reliability of domain-specific LLMs, and\nmaking them more trustworthy for critical human-AI interaction applications.','Ziming Wang, Zeyu Shi, Haoyi Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20903v1'),('2505.20910v1','Automated Privacy Information Annotation in Large Language Model Interactions','Users interacting with large language models (LLMs) under their real\nidentifiers often unknowingly risk disclosing private information.\nAutomatically notifying users whether their queries leak privacy and which\nphrases leak what private information has therefore become a practical need.\nExisting privacy detection methods, however, were designed for different\nobjectives and application scenarios, typically tagging personally identifiable\ninformation (PII) in anonymous content. In this work, to support the\ndevelopment and evaluation of privacy detection models for LLM interactions\nthat are deployable on local user devices, we construct a large-scale\nmultilingual dataset with 249K user queries and 154K annotated privacy phrases.\nIn particular, we build an automated privacy annotation pipeline with\ncloud-based strong LLMs to automatically extract privacy phrases from dialogue\ndatasets and annotate leaked information. We also design evaluation metrics at\nthe levels of privacy leakage, extracted privacy phrase, and privacy\ninformation. We further establish baseline methods using light-weight LLMs with\nboth tuning-free and tuning-based methods, and report a comprehensive\nevaluation of their performance. Evaluation results reveal a gap between\ncurrent performance and the requirements of real-world LLM applications,\nmotivating future research into more effective local privacy detection methods\ngrounded in our dataset.','Hang Zeng, Xiangyu Liu, Yong Hu, Chaoyue Niu, Fan Wu, Shaojie Tang, Guihai Chen','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20910v1'),('2505.20918v1','Humble AI in the real-world: the case of algorithmic hiring','Humble AI (Knowles et al., 2023) argues for cautiousness in AI development\nand deployments through scepticism (accounting for limitations of statistical\nlearning), curiosity (accounting for unexpected outcomes), and commitment\n(accounting for multifaceted values beyond performance). We present a\nreal-world case study for humble AI in the domain of algorithmic hiring.\nSpecifically, we evaluate virtual screening algorithms in a widely used hiring\nplatform that matches candidates to job openings. There are several challenges\nin misrecognition and stereotyping in such contexts that are difficult to\nassess through standard fairness and trust frameworks; e.g., someone with a\nnon-traditional background is less likely to rank highly. We demonstrate\ntechnical feasibility of how humble AI principles can be translated to practice\nthrough uncertainty quantification of ranks, entropy estimates, and a user\nexperience that highlights algorithmic unknowns. We describe preliminary\ndiscussions with focus groups made up of recruiters. Future user studies seek\nto evaluate whether the higher cognitive load of a humble AI system fosters a\nclimate of trust in its outcomes.','Rahul Nair, Inge Vejsbjerg, Elizabeth Daly, Christos Varytimidis, Bran Knowles','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20918v1'),('2505.20921v1','Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models','LLM providers typically offer multiple LLM tiers, varying in performance and\nprice. As NLP tasks become more complex and modularized, selecting the suitable\nLLM tier for each subtask is a key challenge to balance between cost and\nperformance. To address the problem, we introduce LLM Automatic Transmission\n(LLM-AT) framework that automatically selects LLM tiers without training.\nLLM-AT consists of Starter, Generator, and Judge. The starter selects the\ninitial LLM tier expected to solve the given question, the generator produces a\nresponse using the LLM of the selected tier, and the judge evaluates the\nvalidity of the response. If the response is invalid, LLM-AT iteratively\nupgrades to a higher-tier model, generates a new response, and re-evaluates\nuntil a valid response is obtained. Additionally, we propose accuracy\nestimator, which enables the suitable initial LLM tier selection without\ntraining. Given an input question, accuracy estimator estimates the expected\naccuracy of each LLM tier by computing the valid response rate across top-k\nsimilar queries from past inference records. Experiments demonstrate that\nLLM-AT achieves superior performance while reducing costs, making it a\npractical solution for real-world applications.','Injae Na, Keonwoong Noh, Woohwan Jung','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20921v1'),('2505.20922v1','Revisiting Multi-Agent World Modeling from a Diffusion-Inspired Perspective','World models have recently attracted growing interest in Multi-Agent\nReinforcement Learning (MARL) due to their ability to improve sample efficiency\nfor policy learning. However, accurately modeling environments in MARL is\nchallenging due to the exponentially large joint action space and highly\nuncertain dynamics inherent in multi-agent systems. To address this, we reduce\nmodeling complexity by shifting from jointly modeling the entire state-action\ntransition dynamics to focusing on the state space alone at each timestep\nthrough sequential agent modeling. Specifically, our approach enables the model\nto progressively resolve uncertainty while capturing the structured\ndependencies among agents, providing a more accurate representation of how\nagents influence the state. Interestingly, this sequential revelation of\nagents\\\' actions in a multi-agent system aligns with the reverse process in\ndiffusion models--a class of powerful generative models known for their\nexpressiveness and training stability compared to autoregressive or latent\nvariable models. Leveraging this insight, we develop a flexible and robust\nworld model for MARL using diffusion models. Our method, Diffusion-Inspired\nMulti-Agent world model (DIMA), achieves state-of-the-art performance across\nmultiple multi-agent control benchmarks, significantly outperforming prior\nworld models in terms of final return and sample efficiency, including MAMuJoCo\nand Bi-DexHands. DIMA establishes a new paradigm for constructing multi-agent\nworld models, advancing the frontier of MARL research.','Yang Zhang, Xinran Li, Jianing Ye, Delin Qu, Shuang Qiu, Chongjie Zhang, Xiu Li, Chenjia Bai','2025-05-27','cs.MA','http://arxiv.org/pdf/2505.20922v1'),('2505.20924v1','Label Leakage in Federated Inertial-based Human Activity Recognition','While prior work has shown that Federated Learning updates can leak sensitive\ninformation, label reconstruction attacks, which aim to recover input labels\nfrom shared gradients, have not yet been examined in the context of Human\nActivity Recognition (HAR). Given the sensitive nature of activity labels, this\nstudy evaluates the effectiveness of state-of-the-art gradient-based label\nleakage attacks on HAR benchmark datasets. Our findings show that the number of\nactivity classes, sampling strategy, and class imbalance are critical factors\ninfluencing the extent of label leakage, with reconstruction accuracies\nreaching up to 90% on two benchmark datasets, even for trained models.\nMoreover, we find that Local Differential Privacy techniques such as gradient\nnoise and clipping offer only limited protection, as certain attacks still\nreliably infer both majority and minority class labels. We conclude by offering\npractical recommendations for the privacy-aware deployment of federated HAR\nsystems and identify open challenges for future research. Code to reproduce our\nexperiments is publicly available via github.com/mariusbock/leakage_har.','Marius Bock, Maximilian Hopp, Kristof Van Laerhoven, Michael Moeller','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20924v1'),('2505.20925v1','Multi-objective Large Language Model Alignment with Hierarchical Experts','Aligning large language models (LLMs) to simultaneously satisfy multiple\nobjectives remains a significant challenge, especially given the diverse and\noften conflicting nature of human preferences. Existing alignment methods\nstruggle to balance trade-offs effectively, often requiring costly retraining\nor yielding suboptimal results across the Pareto frontier of preferences. In\nthis paper, we introduce \\textit{HoE}(Hierarchical Mixture-of-Experts), a\n\\textit{lightweight}, \\textit{parameter-efficient}, and \\textit{plug-and-play}\napproach that eliminates the need for model training, while enabling LLMs to\nadapt across the entire Pareto frontier and accommodate diverse user\npreferences. In particular, \\textit{HoE} consists of three hierarchical\ncomponents: LoRA Experts, Router Experts and Preference Routing, reaching\noptimal Pareto frontiers and achieving a trade-off between parameter size,\ntraining cost, and performance. We evaluate \\textit{HoE} across various tasks\non 14 objectives and 200 different preferences among 6 benchmarks,\ndemonstrating superior performance over 15 recent baselines. Code is available\nin the supplementary materials.','Zhuo Li, Guodong Du, Weiyang Guo, Yigeng Zhou, Xiucheng Li, Wenya Wang, Fangming Liu, Yequan Wang, Deheng Ye, Min Zhang, Jing Li','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20925v1'),('2505.20930v1','MLMC-based Resource Adequacy Assessment with Active Learning Trained Surrogate Models','Multilevel Monte Carlo (MLMC) is a flexible and effective variance reduction\ntechnique for accelerating reliability assessments of complex power system.\nRecently, data-driven surrogate models have been proposed as lower-level models\nin the MLMC framework due to their high correlation and negligible execution\ntime once trained. However, in resource adequacy assessments, pre-labeled\ndatasets are typically unavailable. For large-scale systems, the efficiency\ngains from surrogate models are often offset by the substantial time required\nfor labeling training data. Therefore, this paper introduces a speed metric\nthat accounts for training time in evaluating MLMC efficiency. Considering the\ntotal time budget is limited, a vote-by-committee active learning approach is\nproposed to reduce the required labeling calls. A case study demonstrates that,\nwithin practical variance thresholds, active learning enables significantly\nimproved MLMC efficiency with reduced training effort, compared to regular\nsurrogate modelling approaches.','Ruiqi Zhang, Simon H. Tindemans','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20930v1'),('2505.20933v1','Information-Theoretic Complementary Prompts for Improved Continual Text Classification','Continual Text Classification (CTC) aims to continuously classify new text\ndata over time while minimizing catastrophic forgetting of previously acquired\nknowledge. However, existing methods often focus on task-specific knowledge,\noverlooking the importance of shared, task-agnostic knowledge. Inspired by the\ncomplementary learning systems theory, which posits that humans learn\ncontinually through the interaction of two systems -- the hippocampus,\nresponsible for forming distinct representations of specific experiences, and\nthe neocortex, which extracts more general and transferable representations\nfrom past experiences -- we introduce Information-Theoretic Complementary\nPrompts (InfoComp), a novel approach for CTC. InfoComp explicitly learns two\ndistinct prompt spaces: P(rivate)-Prompt and S(hared)-Prompt. These\nrespectively encode task-specific and task-invariant knowledge, enabling models\nto sequentially learn classification tasks without relying on data replay. To\npromote more informative prompt learning, InfoComp uses an\ninformation-theoretic framework that maximizes mutual information between\ndifferent parameters (or encoded representations). Within this framework, we\ndesign two novel loss functions: (1) to strengthen the accumulation of\ntask-specific knowledge in P-Prompt, effectively mitigating catastrophic\nforgetting, and (2) to enhance the retention of task-invariant knowledge in\nS-Prompt, improving forward knowledge transfer. Extensive experiments on\ndiverse CTC benchmarks show that our approach outperforms previous\nstate-of-the-art methods.','Duzhen Zhang, Yong Ren, Chenxing Li, Dong Yu, Tielin Zhang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20933v1'),('2505.20934v1','NatADiff: Adversarial Boundary Guidance for Natural Adversarial Diffusion','Adversarial samples exploit irregularities in the manifold ``learned\\\'\\\' by\ndeep learning models to cause misclassifications. The study of these\nadversarial samples provides insight into the features a model uses to classify\ninputs, which can be leveraged to improve robustness against future attacks.\nHowever, much of the existing literature focuses on constrained adversarial\nsamples, which do not accurately reflect test-time errors encountered in\nreal-world settings. To address this, we propose `NatADiff\\\', an adversarial\nsampling scheme that leverages denoising diffusion to generate natural\nadversarial samples. Our approach is based on the observation that natural\nadversarial samples frequently contain structural elements from the adversarial\nclass. Deep learning models can exploit these structural elements to shortcut\nthe classification process, rather than learning to genuinely distinguish\nbetween classes. To leverage this behavior, we guide the diffusion trajectory\ntowards the intersection of the true and adversarial classes, combining\ntime-travel sampling with augmented classifier guidance to enhance attack\ntransferability while preserving image fidelity. Our method achieves comparable\nattack success rates to current state-of-the-art techniques, while exhibiting\nsignificantly higher transferability across model architectures and better\nalignment with natural test-time errors as measured by FID. These results\ndemonstrate that NatADiff produces adversarial samples that not only transfer\nmore effectively across models, but more faithfully resemble naturally\noccurring test-time errors.','Max Collins, Jordan Vice, Tim French, Ajmal Mian','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20934v1'),('2505.20937v1','On VLMs for Diverse Tasks in Multimodal Meme Classification','In this paper, we present a comprehensive and systematic analysis of\nvision-language models (VLMs) for disparate meme classification tasks. We\nintroduced a novel approach that generates a VLM-based understanding of meme\nimages and fine-tunes the LLMs on textual understanding of the embedded meme\ntext for improving the performance. Our contributions are threefold: (1)\nBenchmarking VLMs with diverse prompting strategies purposely to each sub-task;\n(2) Evaluating LoRA fine-tuning across all VLM components to assess performance\ngains; and (3) Proposing a novel approach where detailed meme interpretations\ngenerated by VLMs are used to train smaller language models (LLMs),\nsignificantly improving classification. The strategy of combining VLMs with\nLLMs improved the baseline performance by 8.34%, 3.52% and 26.24% for sarcasm,\noffensive and sentiment classification, respectively. Our results reveal the\nstrengths and limitations of VLMs and present a novel strategy for meme\nunderstanding.','Deepesh Gavit, Debajyoti Mazumder, Samiran Das, Jasabanta Patro','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20937v1'),('2505.20938v1','Revisiting Sparsity Constraint Under High-Rank Property in Partial Multi-Label Learning','Partial Multi-Label Learning (PML) extends the multi-label learning paradigm\nto scenarios where each sample is associated with a candidate label set\ncontaining both ground-truth labels and noisy labels. Existing PML methods\ncommonly rely on two assumptions: sparsity of the noise label matrix and\nlow-rankness of the ground-truth label matrix. However, these assumptions are\ninherently conflicting and impractical for real-world scenarios, where the true\nlabel matrix is typically full-rank or close to full-rank. To address these\nlimitations, we demonstrate that the sparsity constraint contributes to the\nhigh-rank property of the predicted label matrix. Based on this, we propose a\nnovel method Schirn, which introduces a sparsity constraint on the noise label\nmatrix while enforcing a high-rank property on the predicted label matrix.\nExtensive experiments demonstrate the superior performance of Schirn compared\nto state-of-the-art methods, validating its effectiveness in tackling\nreal-world PML challenges.','Chongjie Si, Yidan Cui, Fuchao Yang, Xiaokang Yang, Wei Shen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20938v1'),('2505.20943v1','Efficient Spectral Control of Partially Observed Linear Dynamical Systems','We propose a new method for the problem of controlling linear dynamical\nsystems under partial observation and adversarial disturbances. Our new\nalgorithm, Double Spectral Control (DSC), matches the best known regret\nguarantees while exponentially improving runtime complexity over previous\napproaches in its dependence on the system\\\'s stability margin. Our key\ninnovation is a two-level spectral approximation strategy, leveraging double\nconvolution with a universal basis of spectral filters, enabling efficient and\naccurate learning of the best linear dynamical controllers.','Anand Brahmbhatt, Gon Buzaglo, Sofiia Druchyna, Elad Hazan','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20943v1'),('2505.20947v1','Unified Deep Learning Approach for Estimating the Metallicities of RR Lyrae Stars Using light curves from Gaia Data Release 3','RR Lyrae stars (RRLs) are old pulsating variables widely used as metallicity\ntracers due to the correlation between their metal abundances and light curve\nmorphology. With ESA Gaia DR3 providing light curves for about 270,000 RRLs,\nthere is a pressing need for scalable methods to estimate their metallicities\nfrom photometric data. We introduce a unified deep learning framework that\nestimates metallicities for both fundamental-mode (RRab) and first-overtone\n(RRc) RRLs using Gaia G-band light curves. This approach extends our previous\nwork on RRab stars to include RRc stars, aiming for high predictive accuracy\nand broad generalization across both pulsation types. The model is based on a\nGated Recurrent Unit (GRU) neural network optimized for time-series extrinsic\nregression. Our pipeline includes preprocessing steps such as phase folding,\nsmoothing, and sample weighting, and uses photometric metallicities from the\nliterature as training targets. The architecture is designed to handle\nmorphological differences between RRab and RRc light curves without requiring\nseparate models. On held-out validation sets, our GRU model achieves strong\nperformance: for RRab stars, MAE = 0.0565 dex, RMSE = 0.0765 dex, R^2 = 0.9401;\nfor RRc stars, MAE = 0.0505 dex, RMSE = 0.0720 dex, R^2 = 0.9625. These results\nshow the effectiveness of deep learning for large-scale photometric metallicity\nestimation and support its application to studies of stellar populations and\nGalactic structure.','Lorenzo Monti, Tatiana Muraveva, Alessia Garofalo, Gisella Clementini, Maria Letizia Valentini','2025-05-27','astro-ph.SR','http://arxiv.org/pdf/2505.20947v1'),('2505.20948v1','Controllable Logical Hypothesis Generation for Abductive Reasoning in Knowledge Graphs','Abductive reasoning in knowledge graphs aims to generate plausible logical\nhypotheses from observed entities, with broad applications in areas such as\nclinical diagnosis and scientific discovery. However, due to a lack of\ncontrollability, a single observation may yield numerous plausible but\nredundant or irrelevant hypotheses on large-scale knowledge graphs. To address\nthis limitation, we introduce the task of controllable hypothesis generation to\nimprove the practical utility of abductive reasoning. This task faces two key\nchallenges when controlling for generating long and complex logical hypotheses:\nhypothesis space collapse and hypothesis oversensitivity. To address these\nchallenges, we propose CtrlHGen, a Controllable logcial Hypothesis Generation\nframework for abductive reasoning over knowledge graphs, trained in a two-stage\nparadigm including supervised learning and subsequent reinforcement learning.\nTo mitigate hypothesis space collapse, we design a dataset augmentation\nstrategy based on sub-logical decomposition, enabling the model to learn\ncomplex logical structures by leveraging semantic patterns in simpler\ncomponents. To address hypothesis oversensitivity, we incorporate smoothed\nsemantic rewards including Dice and Overlap scores, and introduce a\ncondition-adherence reward to guide the generation toward user-specified\ncontrol constraints. Extensive experiments on three benchmark datasets\ndemonstrate that our model not only better adheres to control conditions but\nalso achieves superior semantic similarity performance compared to baselines.','Yisen Gao, Jiaxin Bai, Tianshi Zheng, Qingyun Sun, Ziwei Zhang, Jianxin Li, Yangqiu Song, Xingcheng Fu','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.20948v1'),('2505.20949v1','Streamlining Knowledge Graph Creation with PyRML','Knowledge Graphs (KGs) are increasingly adopted as a foundational technology\nfor integrating heterogeneous data in domains such as climate science, cultural\nheritage, and the life sciences. Declarative mapping languages like R2RML and\nRML have played a central role in enabling scalable and reusable KG\nconstruction, offering a transparent means of transforming structured and\nsemi-structured data into RDF. In this paper, we present PyRML, a lightweight,\nPython-native library for building Knowledge Graphs through declarative\nmappings. PyRML supports core RML constructs and provides a programmable\ninterface for authoring, executing, and testing mappings directly within Python\nenvironments. It integrates with popular data and semantic web libraries (e.g.,\nPandas and RDFlib), enabling transparent and modular workflows. By lowering the\nbarrier to entry for KG creation and fostering reproducible, ontology-aligned\ndata integration, PyRML bridges the gap between declarative semantics and\npractical KG engineering.','Andrea Giovanni Nuzzolese','2025-05-27','cs.DB','http://arxiv.org/pdf/2505.20949v1'),('2505.20950v1','Scattering Networks on Noncommutative Finite Groups','Scattering Networks were initially designed to elucidate the behavior of\nearly layers in Convolutional Neural Networks (CNNs) over Euclidean spaces and\nare grounded in wavelets. In this work, we introduce a scattering transform on\nan arbitrary finite group (not necessarily abelian) within the context of\ngroup-equivariant convolutional neural networks (G-CNNs). We present wavelets\non finite groups and analyze their similarity to classical wavelets. We\ndemonstrate that, under certain conditions in the wavelet coefficients, the\nscattering transform is non-expansive, stable under deformations, preserves\nenergy, equivariant with respect to left and right group translations, and, as\ndepth increases, the scattering coefficients are less sensitive to group\ntranslations of the signal, all desirable properties of convolutional neural\nnetworks. Furthermore, we provide examples illustrating the application of the\nscattering transform to classify data with domains involving abelian and\nnonabelian groups.','Maria Teresa Arias, Davide Barbieri, Eugenio Hernández','2025-05-27','math.NA','http://arxiv.org/pdf/2505.20950v1'),('2505.20955v1','Unveiling Impact of Frequency Components on Membership Inference Attacks for Diffusion Models','Diffusion models have achieved tremendous success in image generation, but\nthey also raise significant concerns regarding privacy and copyright issues.\nMembership Inference Attacks (MIAs) are designed to ascertain whether specific\ndata were utilized during a model\\\'s training phase. As current MIAs for\ndiffusion models typically exploit the model\\\'s image prediction ability, we\nformalize them into a unified general paradigm which computes the membership\nscore for membership identification. Under this paradigm, we empirically find\nthat existing attacks overlook the inherent deficiency in how diffusion models\nprocess high-frequency information. Consequently, this deficiency leads to\nmember data with more high-frequency content being misclassified as hold-out\ndata, and hold-out data with less high-frequency content tend to be\nmisclassified as member data. Moreover, we theoretically demonstrate that this\ndeficiency reduces the membership advantage of attacks, thereby interfering\nwith the effective discrimination of member data and hold-out data. Based on\nthis insight, we propose a plug-and-play high-frequency filter module to\nmitigate the adverse effects of the deficiency, which can be seamlessly\nintegrated into any attacks within this general paradigm without additional\ntime costs. Extensive experiments corroborate that this module significantly\nimproves the performance of baseline attacks across different datasets and\nmodels.','Puwei Lian, Yujun Cai, Songze Li','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.20955v1'),('2505.20956v1','Hybrid Disagreement-Diversity Active Learning for Bioacoustic Sound Event Detection','Bioacoustic sound event detection (BioSED) is crucial for biodiversity\nconservation but faces practical challenges during model development and\ntraining: limited amounts of annotated data, sparse events, species diversity,\nand class imbalance. To address these challenges efficiently with a limited\nlabeling budget, we apply the mismatch-first farthest-traversal (MFFT), an\nactive learning method integrating committee voting disagreement and diversity\nanalysis. We also refine an existing BioSED dataset specifically for evaluating\nactive learning algorithms. Experimental results demonstrate that MFFT achieves\na mAP of 68% when cold-starting and 71% when warm-starting (which is close to\nthe fully-supervised mAP of 75%) while using only 2.3% of the annotations.\nNotably, MFFT excels in cold-start scenarios and with rare species, which are\ncritical for monitoring endangered species, demonstrating its practical value.','Shiqi Zhang, Tuomas Virtanen','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.20956v1'),('2505.20959v1','Research Community Perspectives on \"Intelligence\" and Large Language Models','Despite the widespread use of \\\'\\\'artificial intelligence\\\'\\\' (AI) framing in\nNatural Language Processing (NLP) research, it is not clear what researchers\nmean by \\\'\\\'intelligence\\\'\\\'. To that end, we present the results of a survey on\nthe notion of \\\'\\\'intelligence\\\'\\\' among researchers and its role in the research\nagenda. The survey elicited complete responses from 303 researchers from a\nvariety of fields including NLP, Machine Learning (ML), Cognitive Science,\nLinguistics, and Neuroscience. We identify 3 criteria of intelligence that the\ncommunity agrees on the most: generalization, adaptability, & reasoning. Our\nresults suggests that the perception of the current NLP systems as\n\\\'\\\'intelligent\\\'\\\' is a minority position (29%). Furthermore, only 16.2% of the\nrespondents see developing intelligent systems as a research goal, and these\nrespondents are more likely to consider the current systems intelligent.','Bertram Højer, Terne Sasha Thorn Jakobsen, Anna Rogers, Stefan Heinrich','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20959v1'),('2505.20961v1','Efficient and Microphone-Fault-Tolerant 3D Sound Source Localization','Sound source localization (SSL) is a critical technology for determining the\nposition of sound sources in complex environments. However, existing methods\nface challenges such as high computational costs and precise calibration\nrequirements, limiting their deployment in dynamic or resource-constrained\nenvironments. This paper introduces a novel 3D SSL framework, which uses sparse\ncross-attention, pretraining, and adaptive signal coherence metrics, to achieve\naccurate and computationally efficient localization with fewer input\nmicrophones. The framework is also fault-tolerant to unreliable or even unknown\nmicrophone position inputs, ensuring its applicability in real-world scenarios.\nPreliminary experiments demonstrate its scalability for multi-source\nlocalization without requiring additional hardware. This work advances SSL by\nbalancing the model\\\'s performance and efficiency and improving its robustness\nfor real-world scenarios.','Yiyuan Yang, Shitong Xu, Niki Trigoni, Andrew Markham','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.20961v1'),('2505.20963v1','Context-Aware Content Moderation for German Newspaper Comments','The increasing volume of online discussions requires advanced automatic\ncontent moderation to maintain responsible discourse. While hate speech\ndetection on social media is well-studied, research on German-language\nnewspaper forums remains limited. Existing studies often neglect\nplatform-specific context, such as user history and article themes. This paper\naddresses this gap by developing and evaluating binary classification models\nfor automatic content moderation in German newspaper forums, incorporating\ncontextual information. Using LSTM, CNN, and ChatGPT-3.5 Turbo, and leveraging\nthe One Million Posts Corpus from the Austrian newspaper Der Standard, we\nassess the impact of context-aware models. Results show that CNN and LSTM\nmodels benefit from contextual information and perform competitively with\nstate-of-the-art approaches. In contrast, ChatGPT\\\'s zero-shot classification\ndoes not improve with added context and underperforms.','Felix Krejca, Tobias Kietreiber, Alexander Buchelt, Sebastian Neumaier','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20963v1'),('2505.20964v1','Semantic Communication meets System 2 ML: How Abstraction, Compositionality and Emergent Languages Shape Intelligence','The trajectories of 6G and AI are set for a creative collision. However,\ncurrent visions for 6G remain largely incremental evolutions of 5G, while\nprogress in AI is hampered by brittle, data-hungry models that lack robust\nreasoning capabilities. This paper argues for a foundational paradigm shift,\nmoving beyond the purely technical level of communication toward systems\ncapable of semantic understanding and effective, goal-oriented interaction. We\npropose a unified research vision rooted in the principles of System-2\ncognition, built upon three pillars: Abstraction, enabling agents to learn\nmeaningful world models from raw sensorimotor data; Compositionality, providing\nthe algebraic tools to combine learned concepts and subsystems; and Emergent\nCommunication, allowing intelligent agents to create their own adaptive and\ngrounded languages. By integrating these principles, we lay the groundwork for\ntruly intelligent systems that can reason, adapt, and collaborate, unifying\nadvances in wireless communications, machine learning, and robotics under a\nsingle coherent framework.','Mehdi Bennis, Salem Lahlou','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20964v1'),('2505.20966v1','Personalized Query Auto-Completion for Long and Short-Term Interests with Adaptive Detoxification Generation','Query auto-completion (QAC) plays a crucial role in modern search systems.\nHowever, in real-world applications, there are two pressing challenges that\nstill need to be addressed. First, there is a need for hierarchical\npersonalized representations for users. Previous approaches have typically used\nusers\\\' search behavior as a single, overall representation, which proves\ninadequate in more nuanced generative scenarios. Additionally, query prefixes\nare typically short and may contain typos or sensitive information, increasing\nthe likelihood of generating toxic content compared to traditional text\ngeneration tasks. Such toxic content can degrade user experience and lead to\npublic relations issues. Therefore, the second critical challenge is\ndetoxifying QAC systems.\n  To address these two limitations, we propose a novel model (LaD) that\ncaptures personalized information from both long-term and short-term interests,\nincorporating adaptive detoxification. In LaD, personalized information is\ncaptured hierarchically at both coarse-grained and fine-grained levels. This\napproach preserves as much personalized information as possible while enabling\nonline generation within time constraints. To move a futher step, we propose an\nonline training method based on Reject Preference Optimization (RPO). By\nincorporating a special token [Reject] during both the training and inference\nprocesses, the model achieves adaptive detoxification. Consequently, the\ngenerated text presented to users is both non-toxic and relevant to the given\nprefix. We conduct comprehensive experiments on industrial-scale datasets and\nperform online A/B tests, delivering the largest single-experiment metric\nimprovement in nearly two years of our product. Our model has been deployed on\nKuaishou search, driving the primary traffic for hundreds of millions of active\nusers. The code is available at https://github.com/JXZe/LaD.','Zhibo Wang, Xiaoze Jiang, Zhiheng Qin, Enyun Yu, Han Li','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20966v1'),('2505.20970v2','Understanding the behavior of representation forgetting in continual learning','In continual learning scenarios, catastrophic forgetting of previously\nlearned tasks is a critical issue, making it essential to effectively measure\nsuch forgetting. Recently, there has been growing interest in focusing on\nrepresentation forgetting, the forgetting measured at the hidden layer. In this\npaper, we provide the first theoretical analysis of representation forgetting\nand use this analysis to better understand the behavior of continual learning.\nFirst, we introduce a new metric called representation discrepancy, which\nmeasures the difference between representation spaces constructed by two\nsnapshots of a model trained through continual learning. We demonstrate that\nour proposed metric serves as an effective surrogate for the representation\nforgetting while remaining analytically tractable. Second, through mathematical\nanalysis of our metric, we derive several key findings about the dynamics of\nrepresentation forgetting: the forgetting occurs more rapidly to a higher\ndegree as the layer index increases, while increasing the width of the network\nslows down the forgetting process. Third, we support our theoretical findings\nthrough experiments on real image datasets, including Split-CIFAR100 and\nImageNet1K.','Joonkyu Kim, Yejin Kim, Jy-yong Sohn','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20970v2'),('2505.20971v1','Reason-Align-Respond: Aligning LLM Reasoning with Knowledge Graphs for KGQA','LLMs have demonstrated remarkable capabilities in complex reasoning tasks,\nyet they often suffer from hallucinations and lack reliable factual grounding.\nMeanwhile, knowledge graphs (KGs) provide structured factual knowledge but lack\nthe flexible reasoning abilities of LLMs. In this paper, we present\nReason-Align-Respond (RAR), a novel framework that systematically integrates\nLLM reasoning with knowledge graphs for KGQA. Our approach consists of three\nkey components: a Reasoner that generates human-like reasoning chains, an\nAligner that maps these chains to valid KG paths, and a Responser that\nsynthesizes the final answer. We formulate this process as a probabilistic\nmodel and optimize it using the Expectation-Maximization algorithm, which\niteratively refines the reasoning chains and knowledge paths. Extensive\nexperiments on multiple benchmarks demonstrate the effectiveness of RAR,\nachieving state-of-the-art performance with Hit@1 scores of 93.3% and 91.0% on\nWebQSP and CWQ respectively. Human evaluation confirms that RAR generates\nhigh-quality, interpretable reasoning chains well-aligned with KG paths.\nFurthermore, RAR exhibits strong zero-shot generalization capabilities and\nmaintains computational efficiency during inference.','Xiangqing Shen, Fanfan Wang, Rui Xia','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20971v1'),('2505.20972v1','Deep k-grouping: An Unsupervised Learning Framework for Combinatorial Optimization on Graphs and Hypergraphs','Along with AI computing shining in scientific discovery, its potential in the\ncombinatorial optimization (CO) domain has also emerged in recent years. Yet,\nexisting unsupervised neural network solvers struggle to solve $k$-grouping\nproblems (e.g., coloring, partitioning) on large-scale graphs and hypergraphs,\ndue to limited computational frameworks. In this work, we propose Deep\n$k$-grouping, an unsupervised learning-based CO framework. Specifically, we\ncontribute: Novel one-hot encoded polynomial unconstrained binary optimization\n(OH-PUBO), a formulation for modeling k-grouping problems on graphs and\nhypergraphs (e.g., graph/hypergraph coloring and partitioning); GPU-accelerated\nalgorithms for large-scale k-grouping CO problems. Deep $k$-grouping employs\nthe relaxation of large-scale OH-PUBO objectives as differentiable loss\nfunctions and trains to optimize them in an unsupervised manner. To ensure\nscalability, it leverages GPU-accelerated algorithms to unify the training\npipeline; A Gini coefficient-based continuous relaxation annealing strategy to\nenforce discreteness of solutions while preventing convergence to local optima.\nExperimental results demonstrate that Deep $k$-grouping outperforms existing\nneural network solvers and classical heuristics such as SCIP and Tabu.','Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20972v1'),('2505.20973v2','Towards Conversational Development Environments: Using Theory-of-Mind and Multi-Agent Architectures for Requirements Refinement','Foundation Models (FMs) have shown remarkable capabilities in various natural\nlanguage tasks. However, their ability to accurately capture stakeholder\nrequirements remains a significant challenge for using FMs for software\ndevelopment. This paper introduces a novel approach that leverages an\nFM-powered multi-agent system called AlignMind to address this issue. By having\na cognitive architecture that enhances FMs with Theory-of-Mind capabilities,\nour approach considers the mental states and perspectives of software makers.\nThis allows our solution to iteratively clarify the beliefs, desires, and\nintentions of stakeholders, translating these into a set of refined\nrequirements and a corresponding actionable natural language workflow in the\noften-overlooked requirements refinement phase of software engineering, which\nis crucial after initial elicitation. Through a multifaceted evaluation\ncovering 150 diverse use cases, we demonstrate that our approach can accurately\ncapture the intents and requirements of stakeholders, articulating them as both\nspecifications and a step-by-step plan of action. Our findings suggest that the\npotential for significant improvements in the software development process\njustifies these investments. Our work lays the groundwork for future innovation\nin building intent-first development environments, where software makers can\nseamlessly collaborate with AIs to create software that truly meets their\nneeds.','Keheliya Gallaba, Ali Arabat, Dayi Lin, Mohammed Sayagh, Ahmed E. Hassan','2025-05-27','cs.SE','http://arxiv.org/pdf/2505.20973v2'),('2505.20976v1','Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing','Cross-domain constituency parsing is still an unsolved challenge in\ncomputational linguistics since the available multi-domain constituency\ntreebank is limited. We investigate automatic treebank generation by large\nlanguage models (LLMs) in this paper. The performance of LLMs on constituency\nparsing is poor, therefore we propose a novel treebank generation method, LLM\nback generation, which is similar to the reverse process of constituency\nparsing. LLM back generation takes the incomplete cross-domain constituency\ntree with only domain keyword leaf nodes as input and fills the missing words\nto generate the cross-domain constituency treebank. Besides, we also introduce\na span-level contrastive learning pre-training strategy to make full use of the\nLLM back generation treebank for cross-domain constituency parsing. We verify\nthe effectiveness of our LLM back generation treebank coupled with contrastive\nlearning pre-training on five target domains of MCTB. Experimental results show\nthat our approach achieves state-of-the-art performance on average results\ncompared with various baselines.','Peiming Guo, Meishan Zhang, Jianling Li, Min Zhang, Yue Zhang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20976v1'),('2505.20977v1','Evaluating and Steering Modality Preferences in Multimodal Large Language Model','Multimodal large language models (MLLMs) have achieved remarkable performance\non complex tasks with multimodal context. However, it is still understudied\nwhether they exhibit modality preference when processing multimodal contexts.\nTo study this question, we first build a \\textbf{MC\\textsuperscript{2}}\nbenchmark under controlled evidence conflict scenarios to systematically\nevaluate modality preference, which is the tendency to favor one modality over\nanother when making decisions based on multimodal conflicting evidence. Our\nextensive evaluation reveals that all 18 tested MLLMs generally demonstrate\nclear modality bias, and modality preference can be influenced by external\ninterventions. An in-depth analysis reveals that the preference direction can\nbe captured within the latent representations of MLLMs. Built on this, we\npropose a probing and steering method based on representation engineering to\nexplicitly control modality preference without additional fine-tuning or\ncarefully crafted prompts. Our method effectively amplifies modality preference\ntoward a desired direction and applies to downstream tasks such as\nhallucination mitigation and multimodal machine translation, yielding promising\nimprovements.','Yu Zhang, Jinlong Ma, Yongshuai Hou, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20977v1'),('2505.20979v1','MelodySim: Measuring Melody-aware Music Similarity for Plagiarism Detection','We propose MelodySim, a melody-aware music similarity model and dataset for\nplagiarism detection. First, we introduce a novel method to construct a dataset\nwith focus on melodic similarity. By augmenting Slakh2100; an existing MIDI\ndataset, we generate variations of each piece while preserving the melody\nthrough modifications such as note splitting, arpeggiation, minor track dropout\n(excluding bass), and re-instrumentation. A user study confirms that positive\npairs indeed contain similar melodies, with other musical tracks significantly\nchanged. Second, we develop a segment-wise melodic-similarity detection model\nthat uses a MERT encoder and applies a triplet neural network to capture\nmelodic similarity. The resultant decision matrix highlights where plagiarism\nmight occur. Our model achieves high accuracy on the MelodySim test set.','Tongyu Lu, Charlotta-Marlena Geist, Jan Melechovsky, Abhinaba Roy, Dorien Herremans','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.20979v1'),('2505.20980v1','Identifying Super Spreaders in Multilayer Networks','Identifying super-spreaders can be framed as a subtask of the influence\nmaximisation problem. It seeks to pinpoint agents within a network that, if\nselected as single diffusion seeds, disseminate information most effectively.\nMultilayer networks, a specific class of heterogeneous graphs, can capture\ndiverse types of interactions (e.g., physical-virtual or professional-social),\nand thus offer a more accurate representation of complex relational structures.\nIn this work, we introduce a novel approach to identifying super-spreaders in\nsuch networks by leveraging graph neural networks. To this end, we construct a\ndataset by simulating information diffusion across hundreds of networks - to\nthe best of our knowledge, the first of its kind tailored specifically to\nmultilayer networks. We further formulate the task as a variation of the\nranking prediction problem based on a four-dimensional vector that quantifies\neach agent\\\'s spreading potential: (i) the number of activations; (ii) the\nduration of the diffusion process; (iii) the peak number of activations; and\n(iv) the simulation step at which this peak occurs. Our model,\nTopSpreadersNetwork, comprises a relationship-agnostic encoder and a custom\naggregation layer. This design enables generalisation to previously unseen data\nand adapts to varying graph sizes. In an extensive evaluation, we compare our\nmodel against classic centrality-based heuristics and competitive deep learning\nmethods. The results, obtained across a broad spectrum of real-world and\nsynthetic multilayer networks, demonstrate that TopSpreadersNetwork achieves\nsuperior performance in identifying high-impact nodes, while also offering\nimproved interpretability through its structured output.','Michał Czuba, Mateusz Stolarski, Adam Piróg, Piotr Bielak, Piotr Bródka','2025-05-27','cs.SI','http://arxiv.org/pdf/2505.20980v1'),('2505.20981v1','RefAV: Towards Planning-Centric Scenario Mining','Autonomous Vehicles (AVs) collect and pseudo-label terabytes of multi-modal\ndata localized to HD maps during normal fleet testing. However, identifying\ninteresting and safety-critical scenarios from uncurated driving logs remains a\nsignificant challenge. Traditional scenario mining techniques are error-prone\nand prohibitively time-consuming, often relying on hand-crafted structured\nqueries. In this work, we revisit spatio-temporal scenario mining through the\nlens of recent vision-language models (VLMs) to detect whether a described\nscenario occurs in a driving log and, if so, precisely localize it in both time\nand space. To address this problem, we introduce RefAV, a large-scale dataset\nof 10,000 diverse natural language queries that describe complex multi-agent\ninteractions relevant to motion planning derived from 1000 driving logs in the\nArgoverse 2 Sensor dataset. We evaluate several referential multi-object\ntrackers and present an empirical analysis of our baselines. Notably, we find\nthat naively repurposing off-the-shelf VLMs yields poor performance, suggesting\nthat scenario mining presents unique challenges. Our code and dataset are\navailable at https://github.com/CainanD/RefAV/ and\nhttps://argoverse.github.io/user-guide/tasks/scenario_mining.html','Cainan Davidson, Deva Ramanan, Neehar Peri','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.20981v1'),('2505.20992v1','Efficient Identity and Position Graph Embedding via Spectral-Based Random Feature Aggregation','Graph neural networks (GNNs), which capture graph structures via a feature\naggregation mechanism following the graph embedding framework, have\ndemonstrated a powerful ability to support various tasks. According to the\ntopology properties (e.g., structural roles or community memberships of nodes)\nto be preserved, graph embedding can be categorized into identity and position\nembedding. However, it is unclear for most GNN-based methods which property\nthey can capture. Some of them may also suffer from low efficiency and\nscalability caused by several time- and space-consuming procedures (e.g.,\nfeature extraction and training). From a perspective of graph signal\nprocessing, we find that high- and low-frequency information in the graph\nspectral domain may characterize node identities and positions, respectively.\nBased on this investigation, we propose random feature aggregation (RFA) for\nefficient identity and position embedding, serving as an extreme ablation study\nregarding GNN feature aggregation. RFA (i) adopts a spectral-based GNN without\nlearnable parameters as its backbone, (ii) only uses random noises as inputs,\nand (iii) derives embeddings via just one feed-forward propagation (FFP).\nInspired by degree-corrected spectral clustering, we further introduce a degree\ncorrection mechanism to the GNN backbone. Surprisingly, our experiments\ndemonstrate that two variants of RFA with high- and low-pass filters can\nrespectively derive informative identity and position embeddings via just one\nFFP (i.e., without any training). As a result, RFA can achieve a better\ntrade-off between quality and efficiency for both identity and position\nembedding over various baselines.','Meng Qin, Jiahong Liu, Irwin King','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20992v1'),('2505.20993v1','Who Reasons in the Large Language Models?','Despite the impressive performance of large language models (LLMs), the\nprocess of endowing them with new capabilities--such as mathematical\nreasoning--remains largely empirical and opaque. A critical open question is\nwhether reasoning abilities stem from the entire model, specific modules, or\nare merely artifacts of overfitting. In this work, we hypothesize that the\nreasoning capabilities in well-trained LLMs are primarily attributed to the\noutput projection module (oproj) in the Transformer\\\'s multi-head self-attention\n(MHSA) mechanism. To support this hypothesis, we introduce Stethoscope for\nNetworks (SfN), a suite of diagnostic tools designed to probe and analyze the\ninternal behaviors of LLMs. Using SfN, we provide both circumstantial and\nempirical evidence suggesting that oproj plays a central role in enabling\nreasoning, whereas other modules contribute more to fluent dialogue. These\nfindings offer a new perspective on LLM interpretability and open avenues for\nmore targeted training strategies, potentially enabling more efficient and\nspecialized LLMs.','Jie Shao, Jianxin Wu','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20993v1'),('2505.20995v1','Articulatory strategy in vowel production as a basis for speaker discrimination','The way speakers articulate is well known to be variable across individuals\nwhile at the same time subject to anatomical and biomechanical constraints. In\nthis study, we ask whether articulatory strategy in vowel production can be\nsufficiently speaker-specific to form the basis for speaker discrimination. We\nconducted Generalised Procrustes Analyses of tongue shape data from 40 English\nspeakers from the North West of England, and assessed the\nspeaker-discriminatory potential of orthogonal tongue shape features within the\nframework of likelihood ratios. Tongue size emerged as the individual dimension\nwith the strongest discriminatory power, while tongue shape variation in the\nmore anterior part of the tongue generally outperformed tongue shape variation\nin the posterior part. When considered in combination, shape-only information\nmay offer comparable levels of speaker specificity to size-and-shape\ninformation, but only when features do not exhibit speaker-level co-variation.','Justin J. H. Lo, Patrycja Strycharczuk, Sam Kirkham','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.20995v1'),('2505.20997v1','BIPNN: Learning to Solve Binary Integer Programming via Hypergraph Neural Networks','Binary (0-1) integer programming (BIP) is pivotal in scientific domains\nrequiring discrete decision-making. As the advance of AI computing, recent\nworks explore neural network-based solvers for integer linear programming (ILP)\nproblems. Yet, they lack scalability for tackling nonlinear challenges. To\nhandle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linear\nrelaxations, leading to exponential growth in auxiliary variables and severe\ncomputation limitations. To overcome these limitations, we propose BIPNN\n(Binary Integer Programming Neural Network), an unsupervised learning framework\nto solve nonlinear BIP problems via hypergraph neural networks (HyperGNN).\nSpecifically, BIPNN reformulates BIPs-constrained, discrete, and nonlinear\n(sin, log, exp) optimization problems-into unconstrained, differentiable, and\npolynomial loss functions. The reformulation stems from the observation of a\nprecise one-to-one mapping between polynomial BIP objectives and hypergraph\nstructures, enabling the unsupervised training of HyperGNN to optimize BIP\nproblems in an end-to-end manner. On this basis, we propose a GPU-accelerated\nand continuous-annealing-enhanced training pipeline for BIPNN. The pipeline\nenables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallel\nvia straightforward gradient descent, thus significantly reducing the training\ncost while ensuring the generation of discrete, high-quality solutions.\nExtensive experiments on synthetic and real-world datasets highlight the\nsuperiority of our approach.','Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.20997v1'),('2505.21003v1','Uncertainty Unveiled: Can Exposure to More In-context Examples Mitigate Uncertainty for Large Language Models?','Recent advances in handling long sequences have facilitated the exploration\nof long-context in-context learning (ICL). While much of the existing research\nemphasizes performance improvements driven by additional in-context examples,\nthe influence on the trustworthiness of generated responses remains\nunderexplored. This paper addresses this gap by investigating how increased\nexamples influence predictive uncertainty, an essential aspect in\ntrustworthiness. We begin by systematically quantifying the uncertainty of ICL\nwith varying shot counts, analyzing the impact of example quantity. Through\nuncertainty decomposition, we introduce a novel perspective on performance\nenhancement, with a focus on epistemic uncertainty (EU). Our results reveal\nthat additional examples reduce total uncertainty in both simple and complex\ntasks by injecting task-specific knowledge, thereby diminishing EU and\nenhancing performance. For complex tasks, these advantages emerge only after\naddressing the increased noise and uncertainty associated with longer inputs.\nFinally, we explore the evolution of internal confidence across layers,\nunveiling the mechanisms driving the reduction in uncertainty.','Yifei Wang, Yu Sheng, Linjing Li, Daniel Zeng','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21003v1'),('2505.21005v1','Efficient and Unbiased Sampling from Boltzmann Distributions via Variance-Tuned Diffusion Models','Score-based diffusion models (SBDMs) are powerful amortized samplers for\nBoltzmann distributions; however, imperfect score estimates bias downstream\nMonte Carlo estimates. Classical importance sampling (IS) can correct this\nbias, but computing exact likelihoods requires solving the probability-flow\nordinary differential equation (PF-ODE), a procedure that is prohibitively\ncostly and scales poorly with dimensionality. We introduce Variance-Tuned\nDiffusion Importance Sampling (VT-DIS), a lightweight post-training method that\nadapts the per-step noise covariance of a pretrained SBDM by minimizing the\n$\\alpha$-divergence ($\\alpha=2$) between its forward diffusion and reverse\ndenoising trajectories. VT-DIS assigns a single trajectory-wise importance\nweight to the joint forward-reverse process, yielding unbiased expectation\nestimates at test time with negligible overhead compared to standard sampling.\nOn the DW-4, LJ-13, and alanine-dipeptide benchmarks, VT-DIS achieves effective\nsample sizes of approximately 80 %, 35 %, and 3.5 %, respectively, while using\nonly a fraction of the computational budget required by vanilla diffusion + IS\nor PF-ODE-based IS.','Fengzhe Zhang, Laurence I. Midgley, José Miguel Hernández-Lobato','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21005v1'),('2505.21010v1','Unified Alignment Protocol: Making Sense of the Unlabeled Data in New Domains','Semi-Supervised Federated Learning (SSFL) is gaining popularity over\nconventional Federated Learning in many real-world applications. Due to the\npractical limitation of limited labeled data on the client side, SSFL considers\nthat participating clients train with unlabeled data, and only the central\nserver has the necessary resources to access limited labeled data, making it an\nideal fit for real-world applications (e.g., healthcare). However, traditional\nSSFL assumes that the data distributions in the training phase and testing\nphase are the same. In practice, however, domain shifts frequently occur,\nmaking it essential for SSFL to incorporate generalization capabilities and\nenhance their practicality. The core challenge is improving model\ngeneralization to new, unseen domains while the client participate in SSFL.\nHowever, the decentralized setup of SSFL and unsupervised client training\nnecessitates innovation to achieve improved generalization across domains. To\nachieve this, we propose a novel framework called the Unified Alignment\nProtocol (UAP), which consists of an alternating two-stage training process.\nThe first stage involves training the server model to learn and align the\nfeatures with a parametric distribution, which is subsequently communicated to\nclients without additional communication overhead. The second stage proposes a\nnovel training algorithm that utilizes the server feature distribution to align\nclient features accordingly. Our extensive experiments on standard domain\ngeneralization benchmark datasets across multiple model architectures reveal\nthat proposed UAP successfully achieves SOTA generalization performance in SSFL\nsetting.','Sabbir Ahmed, Mamshad Nayeem Rizve, Abdullah Al Arafat, Jacqueline Liu, Rahim Hossain, Mohaiminul Al Nahian, Adnan Siraj Rakin','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21010v1'),('2505.21011v1','LLMs are Frequency Pattern Learners in Natural Language Inference','While fine-tuning LLMs on NLI corpora improves their inferential performance,\nthe underlying mechanisms driving this improvement remain largely opaque. In\nthis work, we conduct a series of experiments to investigate what LLMs actually\nlearn during fine-tuning. We begin by analyzing predicate frequencies in\npremises and hypotheses across NLI datasets and identify a consistent frequency\nbias, where predicates in hypotheses occur more frequently than those in\npremises for positive instances. To assess the impact of this bias, we evaluate\nboth standard and NLI fine-tuned LLMs on bias-consistent and bias-adversarial\ncases. We find that LLMs exploit frequency bias for inference and perform\npoorly on adversarial instances. Furthermore, fine-tuned LLMs exhibit\nsignificantly increased reliance on this bias, suggesting that they are\nlearning these frequency patterns from datasets. Finally, we compute the\nfrequencies of hyponyms and their corresponding hypernyms from WordNet,\nrevealing a correlation between frequency bias and textual entailment. These\nfindings help explain why learning frequency patterns can enhance model\nperformance on inference tasks.','Liang Cheng, Zhaowei Wang, Mark Steedman','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21011v1'),('2505.21012v1','Federated Instrumental Variable Analysis via Federated Generalized Method of Moments','Instrumental variables (IV) analysis is an important applied tool for areas\nsuch as healthcare and consumer economics. For IV analysis in high-dimensional\nsettings, the Generalized Method of Moments (GMM) using deep neural networks\noffers an efficient approach. With non-i.i.d. data sourced from scattered\ndecentralized clients, federated learning is a popular paradigm for training\nthe models while promising data privacy. However, to our knowledge, no\nfederated algorithm for either GMM or IV analysis exists to date. In this work,\nwe introduce federated instrumental variables analysis (FedIV) via federated\ngeneralized method of moments (FedGMM). We formulate FedGMM as a federated\nzero-sum game defined by a federated non-convex non-concave minimax\noptimization problem, which is solved using federated gradient descent ascent\n(FedGDA) algorithm. One key challenge arises in theoretically characterizing\nthe federated local optimality. To address this, we present properties and\nexistence results of clients\\\' local equilibria via FedGDA limit points.\nThereby, we show that the federated solution consistently estimates the local\nmoment conditions of every participating client. The proposed algorithm is\nbacked by extensive experiments to demonstrate the efficacy of our approach.','Geetika, Somya Tyagi, Bapi Chatterjee','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21012v1'),('2505.21019v1','Cardiac Digital Twins at Scale from MRI: Open Tools and Representative Models from ~55000 UK Biobank Participants','A cardiac digital twin is a virtual replica of a patient\\\'s heart for\nscreening, diagnosis, prognosis, risk assessment, and treatment planning of\ncardiovascular diseases. This requires an anatomically accurate\npatient-specific 3D structural representation of the heart, suitable for\nelectro-mechanical simulations or study of disease mechanisms. However,\ngeneration of cardiac digital twins at scale is demanding and there are no\npublic repositories of models across demographic groups. We describe an\nautomatic open-source pipeline for creating patient-specific left and right\nventricular meshes from cardiovascular magnetic resonance images, its\napplication to a large cohort of ~55000 participants from UK Biobank, and the\nconstruction of the most comprehensive cohort of adult heart models to date,\ncomprising 1423 representative meshes across sex (male, female), body mass\nindex (range: 16 - 42 kg/m$^2$) and age (range: 49 - 80 years). Our code is\navailable at https://github.com/cdttk/biv-volumetric-meshing/tree/plos2025 ,\nand pre-trained networks, representative volumetric meshes with fibers and UVCs\nwill be made available soon.','Devran Ugurlu, Shuang Qian, Elliot Fairweather, Charlene Mauger, Bram Ruijsink, Laura Dal Toso, Yu Deng, Marina Strocchi, Reza Razavi, Alistair Young, Pablo Lamata, Steven Niederer, Martin Bishop','2025-05-27','eess.IV','http://arxiv.org/pdf/2505.21019v1'),('2505.21020v1','NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation','Accurate Subseasonal-to-Seasonal (S2S) ocean simulation is critically\nimportant for marine research, yet remains challenging due to its substantial\nthermal inertia and extended time delay. Machine learning (ML)-based models\nhave demonstrated significant advancements in simulation accuracy and\ncomputational efficiency compared to traditional numerical methods.\nNevertheless, a significant limitation of current ML models for S2S ocean\nsimulation is their inadequate incorporation of physical consistency and the\nslow-changing properties of the ocean system. In this work, we propose a neural\nocean model (NeuralOM) for S2S ocean simulation with a multi-scale interactive\ngraph neural network to emulate diverse physical phenomena associated with\nocean systems effectively. Specifically, we propose a multi-stage framework\ntailored to model the ocean\\\'s slowly changing nature. Additionally, we\nintroduce a multi-scale interactive messaging module to capture complex\ndynamical behaviors, such as gradient changes and multiplicative coupling\nrelationships inherent in ocean dynamics. Extensive experimental evaluations\nconfirm that our proposed NeuralOM outperforms state-of-the-art models in S2S\nand extreme event simulation. The codes are available at\nhttps://github.com/YuanGao-YG/NeuralOM.','Yuan Gao, Ruiqi Shu, Hao Wu, Fan Xu, Yanfei Xiang, Ruijian Gou, Qingsong Wen, Xian Wu, Xiaomeng Huang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21020v1'),('2505.21024v1','Pause Tokens Strictly Increase the Expressivity of Constant-Depth Transformers','Pause tokens, simple filler symbols such as \"...\", consistently improve\nTransformer performance on both language and mathematical tasks, yet their\ntheoretical effect remains unexplained. We provide the first formal separation\nresult, proving that adding pause tokens to constant-depth, logarithmic-width\nTransformers strictly increases their computational expressivity. With\nbounded-precision activations, Transformers without pause tokens compute only a\nstrict subset of $\\mathsf{AC}^0$ functions, while adding a polynomial number of\npause tokens allows them to express the entire class. For logarithmic-precision\nTransformers, we show that adding pause tokens achieves expressivity equivalent\nto $\\mathsf{TC}^0$, matching known upper bounds. Empirically, we demonstrate\nthat two-layer causally masked Transformers can learn parity when supplied with\npause tokens, a function that they appear unable to learn without them. Our\nresults provide a rigorous theoretical explanation for prior empirical\nfindings, clarify how pause tokens interact with width, depth, and numeric\nprecision, and position them as a distinct mechanism, complementary to\nchain-of-thought prompting, for enhancing Transformer reasoning.','Charles London, Varun Kanade','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21024v1'),('2505.21025v1','Text-Queried Audio Source Separation via Hierarchical Modeling','Target audio source separation with natural language queries presents a\npromising paradigm for extracting arbitrary audio events through arbitrary text\ndescriptions. Existing methods mainly face two challenges, the difficulty in\njointly modeling acoustic-textual alignment and semantic-aware separation\nwithin a blindly-learned single-stage architecture, and the reliance on\nlarge-scale accurately-labeled training data to compensate for inefficient\ncross-modal learning and separation. To address these challenges, we propose a\nhierarchical decomposition framework, HSM-TSS, that decouples the task into\nglobal-local semantic-guided feature separation and structure-preserving\nacoustic reconstruction. Our approach introduces a dual-stage mechanism for\nsemantic separation, operating on distinct global and local semantic feature\nspaces. We first perform global-semantic separation through a global semantic\nfeature space aligned with text queries. A Q-Audio architecture is employed to\nalign audio and text modalities, serving as pretrained global-semantic\nencoders. Conditioned on the predicted global feature, we then perform the\nsecond-stage local-semantic separation on AudioMAE features that preserve\ntime-frequency structures, followed by acoustic reconstruction. We also propose\nan instruction processing pipeline to parse arbitrary text queries into\nstructured operations, extraction or removal, coupled with audio descriptions,\nenabling flexible sound manipulation. Our method achieves state-of-the-art\nseparation performance with data-efficient training while maintaining superior\nsemantic consistency with queries in complex auditory scenes.','Xinlei Yin, Xiulian Peng, Xue Jiang, Zhiwei Xiong, Yan Lu','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.21025v1'),('2505.21026v1','Multi-Mode Process Control Using Multi-Task Inverse Reinforcement Learning','In the era of Industry 4.0 and smart manufacturing, process systems\nengineering must adapt to digital transformation. While reinforcement learning\noffers a model-free approach to process control, its applications are limited\nby the dependence on accurate digital twins and well-designed reward functions.\nTo address these limitations, this paper introduces a novel framework that\nintegrates inverse reinforcement learning (IRL) with multi-task learning for\ndata-driven, multi-mode control design. Using historical closed-loop data as\nexpert demonstrations, IRL extracts optimal reward functions and control\npolicies. A latent-context variable is incorporated to distinguish modes,\nenabling the training of mode-specific controllers. Case studies on a\ncontinuous stirred tank reactor and a fed-batch bioreactor validate the\neffectiveness of this framework in handling multi-mode data and training\nadaptable controllers.','Runze Lin, Junghui Chen, Biao Huang, Lei Xie, Hongye Su','2025-05-27','eess.SY','http://arxiv.org/pdf/2505.21026v1'),('2505.21027v1','TabAttackBench: A Benchmark for Adversarial Attacks on Tabular Data','Adversarial attacks pose a significant threat to machine learning models by\ninducing incorrect predictions through imperceptible perturbations to input\ndata. While these attacks have been extensively studied in unstructured data\nlike images, their application to tabular data presents new challenges. These\nchallenges arise from the inherent heterogeneity and complex feature\ninterdependencies in tabular data, which differ significantly from those in\nimage data. To address these differences, it is crucial to consider\nimperceptibility as a key criterion specific to tabular data. Most current\nresearch focuses primarily on achieving effective adversarial attacks, often\noverlooking the importance of maintaining imperceptibility. To address this\ngap, we propose a new benchmark for adversarial attacks on tabular data that\nevaluates both effectiveness and imperceptibility. In this study, we assess the\neffectiveness and imperceptibility of five adversarial attacks across four\nmodels using eleven tabular datasets, including both mixed and numerical-only\ndatasets. Our analysis explores how these factors interact and influence the\noverall performance of the attacks. We also compare the results across\ndifferent dataset types to understand the broader implications of these\nfindings. The findings from this benchmark provide valuable insights for\nimproving the design of adversarial attack algorithms, thereby advancing the\nfield of adversarial machine learning on tabular data.','Zhipeng He, Chun Ouyang, Lijie Wen, Cong Liu, Catarina Moreira','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21027v1'),('2505.21032v1','FeatInv: Spatially resolved mapping from feature space to input space using conditional diffusion models','Internal representations are crucial for understanding deep neural networks,\nsuch as their properties and reasoning patterns, but remain difficult to\ninterpret. While mapping from feature space to input space aids in interpreting\nthe former, existing approaches often rely on crude approximations. We propose\nusing a conditional diffusion model - a pretrained high-fidelity diffusion\nmodel conditioned on spatially resolved feature maps - to learn such a mapping\nin a probabilistic manner. We demonstrate the feasibility of this approach\nacross various pretrained image classifiers from CNNs to ViTs, showing\nexcellent reconstruction capabilities. Through qualitative comparisons and\nrobustness analysis, we validate our method and showcase possible applications,\nsuch as the visualization of concept steering in input space or investigations\nof the composite nature of the feature space. This approach has broad potential\nfor improving feature space understanding in computer vision models.','Nils Neukirch, Johanna Vielhaben, Nils Strodthoff','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21032v1'),('2505.21033v1','Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation','Dialogue Topic Segmentation (DTS) aims to divide dialogues into coherent\nsegments. DTS plays a crucial role in various NLP downstream tasks, but suffers\nfrom chronic problems: data shortage, labeling ambiguity, and incremental\ncomplexity of recently proposed solutions. On the other hand, Despite advances\nin Large Language Models (LLMs) and reasoning strategies, these have rarely\nbeen applied to DTS. This paper introduces Def-DTS: Deductive Reasoning for\nOpen-domain Dialogue Topic Segmentation, which utilizes LLM-based multi-step\ndeductive reasoning to enhance DTS performance and enable case study using\nintermediate result. Our method employs a structured prompting approach for\nbidirectional context summarization, utterance intent classification, and\ndeductive topic shift detection. In the intent classification process, we\npropose the generalizable intent list for domain-agnostic dialogue intent\nclassification. Experiments in various dialogue settings demonstrate that\nDef-DTS consistently outperforms traditional and state-of-the-art approaches,\nwith each subtask contributing to improved performance, particularly in\nreducing type 2 error. We also explore the potential for autolabeling,\nemphasizing the importance of LLM reasoning techniques in DTS.','Seungmin Lee, Yongsang Yoo, Minhwa Jung, Min Song','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21033v1'),('2505.21034v1','LLaMEA-BO: A Large Language Model Evolutionary Algorithm for Automatically Generating Bayesian Optimization Algorithms','Bayesian optimization (BO) is a powerful class of algorithms for optimizing\nexpensive black-box functions, but designing effective BO algorithms remains a\nmanual, expertise-driven task. Recent advancements in Large Language Models\n(LLMs) have opened new avenues for automating scientific discovery, including\nthe automatic design of optimization algorithms. While prior work has used LLMs\nwithin optimization loops or to generate non-BO algorithms, we tackle a new\nchallenge: Using LLMs to automatically generate full BO algorithm code. Our\nframework uses an evolution strategy to guide an LLM in generating Python code\nthat preserves the key components of BO algorithms: An initial design, a\nsurrogate model, and an acquisition function. The LLM is prompted to produce\nmultiple candidate algorithms, which are evaluated on the established Black-Box\nOptimization Benchmarking (BBOB) test suite from the COmparing Continuous\nOptimizers (COCO) platform. Based on their performance, top candidates are\nselected, combined, and mutated via controlled prompt variations, enabling\niterative refinement. Despite no additional fine-tuning, the LLM-generated\nalgorithms outperform state-of-the-art BO baselines in 19 (out of 24) BBOB\nfunctions in dimension 5 and generalize well to higher dimensions, and\ndifferent tasks (from the Bayesmark framework). This work demonstrates that\nLLMs can serve as algorithmic co-designers, offering a new paradigm for\nautomating BO development and accelerating the discovery of novel algorithmic\ncombinations. The source code is provided at\nhttps://github.com/Ewendawi/LLaMEA-BO.','Wenhu Li, Niki van Stein, Thomas Bäck, Elena Raponi','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21034v1'),('2505.21036v1','RainFusion: Adaptive Video Generation Acceleration via Multi-Dimensional Visual Redundancy','Video generation using diffusion models is highly computationally intensive,\nwith 3D attention in Diffusion Transformer (DiT) models accounting for over\n80\\% of the total computational resources. In this work, we introduce {\\bf\nRainFusion}, a novel training-free sparse attention method that exploits\ninherent sparsity nature in visual data to accelerate attention computation\nwhile preserving video quality. Specifically, we identify three unique sparse\npatterns in video generation attention calculations--Spatial Pattern, Temporal\nPattern and Textural Pattern. The sparse pattern for each attention head is\ndetermined online with negligible overhead (\\textasciitilde\\,0.2\\%) with our\nproposed {\\bf ARM} (Adaptive Recognition Module) during inference. Our proposed\n{\\bf RainFusion} is a plug-and-play method, that can be seamlessly integrated\ninto state-of-the-art 3D-attention video generation models without additional\ntraining or calibration. We evaluate our method on leading open-sourced models\nincluding HunyuanVideo, OpenSoraPlan-1.2 and CogVideoX-5B, demonstrating its\nbroad applicability and effectiveness. Experimental results show that\nRainFusion achieves over {\\bf 2\\(\\times\\)} speedup in attention computation\nwhile maintaining video quality, with only a minimal impact on VBench scores\n(-0.2\\%).','Aiyue Chen, Bin Dong, Jingru Li, Jing Lin, Yiwu Yao, Gongyi Wang','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21036v1'),('2505.21038v1','Fixed-Point Traps and Identity Emergence in Educational Feedback Systems','This paper presents a formal categorical proof that exam-driven educational\nsystems obstruct identity emergence and block creative convergence. Using the\nframework of Alpay Algebra II and III, we define Exam-Grade Collapse Systems\n(EGCS) as functorial constructs where learning dynamics $\\varphi$ are\nrecursively collapsed by evaluative morphisms $E$. We prove that under such\ncollapse regimes, no nontrivial fixed-point algebra $\\mu_\\varphi$ can exist,\nhence learner identity cannot stabilize. This creates a universal fixed-point\ntrap: all generative functors are entropically folded before symbolic emergence\noccurs. Our model mathematically explains the creativity suppression, research\nstagnation, and structural entropy loss induced by timed exams and grade-based\nfeedback. The results apply category theory to expose why modern educational\nsystems prevent {\\phi}-emergence and block observer-invariant self-formation.\nThis work provides the first provable algebraic obstruction of identity\nformation caused by institutional feedback mechanics.','Faruk Alpay','2025-05-27','math.CT','http://arxiv.org/pdf/2505.21038v1'),('2505.21039v1','Scalable and adaptive prediction bands with kernel sum-of-squares','Conformal Prediction (CP) is a popular framework for constructing prediction\nbands with valid coverage in finite samples, while being free of any\ndistributional assumption. A well-known limitation of conformal prediction is\nthe lack of adaptivity, although several works introduced practically efficient\nalternate procedures. In this work, we build upon recent ideas that rely on\nrecasting the CP problem as a statistical learning problem, directly targeting\ncoverage and adaptivity. This statistical learning problem is based on\nreproducible kernel Hilbert spaces (RKHS) and kernel sum-of-squares (SoS)\nmethods. First, we extend previous results with a general representer theorem\nand exhibit the dual formulation of the learning problem. Crucially, such dual\nformulation can be solved efficiently by accelerated gradient methods with\nseveral hundreds or thousands of samples, unlike previous strategies based on\noff-the-shelf semidefinite programming algorithms. Second, we introduce a new\nhyperparameter tuning strategy tailored specifically to target adaptivity\nthrough bounds on test-conditional coverage. This strategy, based on the\nHilbert-Schmidt Independence Criterion (HSIC), is introduced here to tune\nkernel lengthscales in our framework, but has broader applicability since it\ncould be used in any CP algorithm where the score function is learned. Finally,\nextensive experiments are conducted to show how our method compares to related\nwork. All figures can be reproduced with the accompanying code.','Louis Allain, Sébastien da Veiga, Brian Staber','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21039v1'),('2505.21040v2','FCKT: Fine-Grained Cross-Task Knowledge Transfer with Semantic Contrastive Learning for Targeted Sentiment Analysis','In this paper, we address the task of targeted sentiment analysis (TSA),\nwhich involves two sub-tasks, i.e., identifying specific aspects from reviews\nand determining their corresponding sentiments. Aspect extraction forms the\nfoundation for sentiment prediction, highlighting the critical dependency\nbetween these two tasks for effective cross-task knowledge transfer. While most\nexisting studies adopt a multi-task learning paradigm to align task-specific\nfeatures in the latent space, they predominantly rely on coarse-grained\nknowledge transfer. Such approaches lack fine-grained control over\naspect-sentiment relationships, often assuming uniform sentiment polarity\nwithin related aspects. This oversimplification neglects contextual cues that\ndifferentiate sentiments, leading to negative transfer. To overcome these\nlimitations, we propose FCKT, a fine-grained cross-task knowledge transfer\nframework tailored for TSA. By explicitly incorporating aspect-level\ninformation into sentiment prediction, FCKT achieves fine-grained knowledge\ntransfer, effectively mitigating negative transfer and enhancing task\nperformance. Experiments on three datasets, including comparisons with various\nbaselines and large language models (LLMs), demonstrate the effectiveness of\nFCKT. The source code is available on https://github.com/cwei01/FCKT.','Wei Chen, Zhao Zhang, Meng Yuan, Kepeng Xu, Fuzhen Zhuang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21040v2'),('2505.21043v1','Visual Cues Enhance Predictive Turn-Taking for Two-Party Human Interaction','Turn-taking is richly multimodal. Predictive turn-taking models (PTTMs)\nfacilitate naturalistic human-robot interaction, yet most rely solely on\nspeech. We introduce MM-VAP, a multimodal PTTM which combines speech with\nvisual cues including facial expression, head pose and gaze. We find that it\noutperforms the state-of-the-art audio-only in videoconferencing interactions\n(84% vs. 79% hold/shift prediction accuracy). Unlike prior work which\naggregates all holds and shifts, we group by duration of silence between turns.\nThis reveals that through the inclusion of visual features, MM-VAP outperforms\na state-of-the-art audio-only turn-taking model across all durations of speaker\ntransitions. We conduct a detailed ablation study, which reveals that facial\nexpression features contribute the most to model performance. Thus, our working\nhypothesis is that when interlocutors can see one another, visual cues are\nvital for turn-taking and must therefore be included for accurate turn-taking\nprediction. We additionally validate the suitability of automatic speech\nalignment for PTTM training using telephone speech. This work represents the\nfirst comprehensive analysis of multimodal PTTMs. We discuss implications for\nfuture work and make all code publicly available.','Sam O\'Connor Russell, Naomi Harte','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21043v1'),('2505.21045v1','Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking','Low-Altitude Economic Networking (LAENet) aims to support diverse flying\napplications below 1,000 meters by deploying various aerial vehicles for\nflexible and cost-effective aerial networking. However, complex\ndecision-making, resource constraints, and environmental uncertainty pose\nsignificant challenges to the development of the LAENet. Reinforcement learning\n(RL) offers a potential solution in response to these challenges but has\nlimitations in generalization, reward design, and model stability. The\nemergence of large language models (LLMs) offers new opportunities for RL to\nmitigate these limitations. In this paper, we first present a tutorial about\nintegrating LLMs into RL by using the capacities of generation, contextual\nunderstanding, and structured reasoning of LLMs. We then propose an\nLLM-enhanced RL framework for the LAENet in terms of serving the LLM as\ninformation processor, reward designer, decision-maker, and generator.\nMoreover, we conduct a case study by using LLMs to design a reward function to\nimprove the learning performance of RL in the LAENet. Finally, we provide a\nconclusion and discuss future work.','Lingyi Cai, Ruichen Zhang, Changyuan Zhao, Yu Zhang, Jiawen Kang, Dusit Niyato, Tao Jiang, Xuemin Shen','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21045v1'),('2505.21046v1','A domain adaptation neural network for digital twin-supported fault diagnosis','Digital twins offer a promising solution to the lack of sufficient labeled\ndata in deep learning-based fault diagnosis by generating simulated data for\nmodel training. However, discrepancies between simulation and real-world\nsystems can lead to a significant drop in performance when models are applied\nin real scenarios. To address this issue, we propose a fault diagnosis\nframework based on Domain-Adversarial Neural Networks (DANN), which enables\nknowledge transfer from simulated (source domain) to real-world (target domain)\ndata. We evaluate the proposed framework using a publicly available robotics\nfault diagnosis dataset, which includes 3,600 sequences generated by a digital\ntwin model and 90 real sequences collected from physical systems. The DANN\nmethod is compared with commonly used lightweight deep learning models such as\nCNN, TCN, Transformer, and LSTM. Experimental results show that incorporating\ndomain adaptation significantly improves the diagnostic performance. For\nexample, applying DANN to a baseline CNN model improves its accuracy from\n70.00% to 80.22% on real-world test data, demonstrating the effectiveness of\ndomain adaptation in bridging the sim-to-real gap.','Zhenling Chen, Haiwei Fu, Zhiguo Zeng','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21046v1'),('2505.21055v1','Agent-Environment Alignment via Automated Interface Generation','Large language model (LLM) agents have shown impressive reasoning\ncapabilities in interactive decision-making tasks. These agents interact with\nenvironment through intermediate interfaces, such as predefined action spaces\nand interaction rules, which mediate the perception and action. However,\nmismatches often happen between the internal expectations of the agent\nregarding the influence of its issued actions and the actual state transitions\nin the environment, a phenomenon referred to as \\textbf{agent-environment\nmisalignment}. While prior work has invested substantially in improving agent\nstrategies and environment design, the critical role of the interface still\nremains underexplored. In this work, we empirically demonstrate that\nagent-environment misalignment poses a significant bottleneck to agent\nperformance. To mitigate this issue, we propose \\textbf{ALIGN}, an\n\\underline{A}uto-A\\underline{l}igned \\underline{I}nterface\n\\underline{G}e\\underline{n}eration framework that alleviates the misalignment\nby enriching the interface. Specifically, the ALIGN-generated interface\nenhances both the static information of the environment and the step-wise\nobservations returned to the agent. Implemented as a lightweight wrapper, this\ninterface achieves the alignment without modifying either the agent logic or\nthe environment code. Experiments across multiple domains including embodied\ntasks, web navigation and tool-use, show consistent performance improvements,\nwith up to a 45.67\\% success rate improvement observed in ALFWorld. Meanwhile,\nALIGN-generated interface can generalize across different agent architectures\nand LLM backbones without interface regeneration. Code and experimental results\nare available at https://github.com/THUNLP-MT/ALIGN.','Kaiming Liu, Xuanyu Lei, Ziyue Wang, Peng Li, Yang Liu','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21055v1'),('2505.21061v1','LPOI: Listwise Preference Optimization for Vision Language Models','Aligning large VLMs with human preferences is a challenging task, as methods\nlike RLHF and DPO often overfit to textual information or exacerbate\nhallucinations. Although augmenting negative image samples partially addresses\nthese pitfalls, no prior work has employed listwise preference optimization for\nVLMs, due to the complexity and cost of constructing listwise image samples. In\nthis work, we propose LPOI, the first object-aware listwise preference\noptimization developed for reducing hallucinations in VLMs. LPOI identifies and\nmasks a critical object in the image, and then interpolates the masked region\nbetween the positive and negative images to form a sequence of incrementally\nmore complete images. The model is trained to rank these images in ascending\norder of object visibility, effectively reducing hallucinations while retaining\nvisual fidelity. LPOI requires no extra annotations beyond standard pairwise\npreference data, as it automatically constructs the ranked lists through object\nmasking and interpolation. Comprehensive experiments on MMHalBench, AMBER, and\nObject HalBench confirm that LPOI outperforms existing preference optimization\nmethods in reducing hallucinations and enhancing VLM performance. We make the\ncode available at https://github.com/fatemehpesaran310/lpoi.','Fatemeh Pesaran Zadeh, Yoojin Oh, Gunhee Kim','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21061v1'),('2505.21067v1','Why Distillation can Outperform Zero-RL: The Role of Flexible Reasoning','Reinforcement learning (RL) has played an important role in improving the\nreasoning ability of large language models (LLMs). Some studies apply RL\ndirectly to \\textit{smaller} base models (known as zero-RL) and also achieve\nnotable progress. However, in this paper, we show that using only 920 examples,\na simple distillation method based on the base model can clearly outperform\nzero-RL, which typically requires much more data and computational cost. By\nanalyzing the token frequency in model outputs, we find that the distilled\nmodel shows more flexible reasoning. It uses anthropomorphic tokens and logical\nconnectors much more often than the zero-RL model. Further analysis reveals\nthat distillation enhances the presence of two advanced cognitive behaviors:\nMulti-Perspective Thinking or Attempting and Metacognitive Awareness. Frequent\noccurrences of these two advanced cognitive behaviors give rise to flexible\nreasoning, which is essential for solving complex reasoning problems, while\nzero-RL fails to significantly boost the frequency of these behaviors.','Xiao Hu, Xingyu Lu, Liyuan Mao, YiFan Zhang, Tianke Zhang, Bin Wen, Fan Yang, Tingting Gao, Guorui Zhou','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21067v1'),('2505.21068v1','Predicting Implicit Arguments in Procedural Video Instructions','Procedural texts help AI enhance reasoning about context and action\nsequences. Transforming these into Semantic Role Labeling (SRL) improves\nunderstanding of individual steps by identifying predicate-argument structure\nlike {verb,what,where/with}. Procedural instructions are highly elliptic, for\ninstance, (i) add cucumber to the bowl and (ii) add sliced tomatoes, the second\nstep\\\'s where argument is inferred from the context, referring to where the\ncucumber was placed. Prior SRL benchmarks often miss implicit arguments,\nleading to incomplete understanding. To address this, we introduce\nImplicit-VidSRL, a dataset that necessitates inferring implicit and explicit\narguments from contextual information in multimodal cooking procedures. Our\nproposed dataset benchmarks multimodal models\\\' contextual reasoning, requiring\nentity tracking through visual changes in recipes. We study recent multimodal\nLLMs and reveal that they struggle to predict implicit arguments of what and\nwhere/with from multi-modal procedural data given the verb. Lastly, we propose\niSRL-Qwen2-VL, which achieves a 17% relative improvement in F1-score for\nwhat-implicit and a 14.7% for where/with-implicit semantic roles over GPT-4o.','Anil Batra, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21068v1'),('2505.21072v2','Faithfulness-Aware Uncertainty Quantification for Fact-Checking the Output of Retrieval Augmented Generation','Large Language Models (LLMs) enhanced with external knowledge retrieval, an\napproach known as Retrieval-Augmented Generation (RAG), have shown strong\nperformance in open-domain question answering. However, RAG systems remain\nsusceptible to hallucinations: factually incorrect outputs that may arise\neither from inconsistencies in the model\\\'s internal knowledge or incorrect use\nof the retrieved context. Existing approaches often conflate factuality with\nfaithfulness to the retrieved context, misclassifying factually correct\nstatements as hallucinations if they are not directly supported by the\nretrieval. In this paper, we introduce FRANQ (Faithfulness-based Retrieval\nAugmented UNcertainty Quantification), a novel method for hallucination\ndetection in RAG outputs. FRANQ applies different Uncertainty Quantification\n(UQ) techniques to estimate factuality based on whether a statement is faithful\nto the retrieved context or not. To evaluate FRANQ and other UQ techniques for\nRAG, we present a new long-form Question Answering (QA) dataset annotated for\nboth factuality and faithfulness, combining automated labeling with manual\nvalidation of challenging examples. Extensive experiments on long- and\nshort-form QA across multiple datasets and LLMs show that FRANQ achieves more\naccurate detection of factual errors in RAG-generated responses compared to\nexisting methods.','Ekaterina Fadeeva, Aleksandr Rubashevskii, Roman Vashurin, Shehzaad Dhuliawala, Artem Shelmanov, Timothy Baldwin, Preslav Nakov, Mrinmaya Sachan, Maxim Panov','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21072v2'),('2505.21073v2','Bridging Arbitrary and Tree Metrics via Differentiable Gromov Hyperbolicity','Trees and the associated shortest-path tree metrics provide a powerful\nframework for representing hierarchical and combinatorial structures in data.\nGiven an arbitrary metric space, its deviation from a tree metric can be\nquantified by Gromov\\\'s $\\delta$-hyperbolicity. Nonetheless, designing\nalgorithms that bridge an arbitrary metric to its closest tree metric is still\na vivid subject of interest, as most common approaches are either heuristical\nand lack guarantees, or perform moderately well. In this work, we introduce a\nnovel differentiable optimization framework, coined DeltaZero, that solves this\nproblem. Our method leverages a smooth surrogate for Gromov\\\'s\n$\\delta$-hyperbolicity which enables a gradient-based optimization, with a\ntractable complexity. The corresponding optimization procedure is derived from\na problem with better worst case guarantees than existing bounds, and is\njustified statistically. Experiments on synthetic and real-world datasets\ndemonstrate that our method consistently achieves state-of-the-art distortion.','Pierre Houedry, Nicolas Courty, Florestan Martin-Baillon, Laetitia Chapel, Titouan Vayer','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21073v2'),('2505.21074v1','Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling','Text-to-image (T2I) models raise ethical and safety concerns due to their\npotential to generate inappropriate or harmful images. Evaluating these models\\\'\nsecurity through red-teaming is vital, yet white-box approaches are limited by\ntheir need for internal access, complicating their use with closed-source\nmodels. Moreover, existing black-box methods often assume knowledge about the\nmodel\\\'s specific defense mechanisms, limiting their utility in real-world\ncommercial API scenarios. A significant challenge is how to evade unknown and\ndiverse defense mechanisms. To overcome this difficulty, we propose a novel\nRule-based Preference modeling Guided Red-Teaming (RPG-RT), which iteratively\nemploys LLM to modify prompts to query and leverages feedback from T2I systems\nfor fine-tuning the LLM. RPG-RT treats the feedback from each iteration as a\nprior, enabling the LLM to dynamically adapt to unknown defense mechanisms.\nGiven that the feedback is often labeled and coarse-grained, making it\ndifficult to utilize directly, we further propose rule-based preference\nmodeling, which employs a set of rules to evaluate desired or undesired\nfeedback, facilitating finer-grained control over the LLM\\\'s dynamic adaptation\nprocess. Extensive experiments on nineteen T2I systems with varied safety\nmechanisms, three online commercial API services, and T2V models verify the\nsuperiority and practicality of our approach.','Yichuan Cao, Yibo Miao, Xiao-Shan Gao, Yinpeng Dong','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21074v1'),('2505.21077v1','Efficient Large Language Model Inference with Neural Block Linearization','The high inference demands of transformer-based Large Language Models (LLMs)\npose substantial challenges in their deployment. To this end, we introduce\nNeural Block Linearization (NBL), a novel framework for accelerating\ntransformer model inference by replacing self-attention layers with linear\napproximations derived from Linear Minimum Mean Squared Error estimators. NBL\nleverages Canonical Correlation Analysis to compute a theoretical upper bound\non the approximation error. Then, we use this bound as a criterion for\nsubstitution, selecting the LLM layers with the lowest linearization error. NBL\ncan be efficiently applied to pre-trained LLMs without the need for\nfine-tuning. In experiments, NBL achieves notable computational speed-ups while\npreserving competitive accuracy on multiple reasoning benchmarks. For instance,\napplying NBL to 12 self-attention layers in DeepSeek-R1-Distill-Llama-8B\nincreases the inference speed by 32% with less than 1% accuracy trade-off,\nmaking it a flexible and promising solution to improve the inference efficiency\nof LLMs.','Mete Erdogan, Francesco Tonin, Volkan Cevher','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21077v1'),('2505.21082v2','LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models','Large language models (LLMs) have recently achieved impressive performance\nacross a wide range of natural language tasks and are now widely used in\nreal-world applications. Among them, black-box LLMs--served via APIs without\naccess to model internals--are especially dominant due to their scalability and\nease of deployment. Despite their strong capabilities, these models typically\nproduce generalized responses that overlook personal preferences and reasoning\nstyles. This has led to growing interest in black-box LLM personalization,\nwhich aims to tailor model outputs to user-specific context without modifying\nmodel parameters. However, existing approaches primarily focus on\nresponse-level personalization, attempting to match final outputs without\nmodeling personal thought process. To address this limitation, we propose RPM,\na framework for reasoning-level personalization that aligns the model\\\'s\nreasoning process with a user\\\'s personalized logic. RPM first constructs\nstatistical user-specific factors by extracting and grouping\nresponse-influential features from user history. It then builds personalized\nreasoning paths that reflect how these factors are used in context. In the\ninference stage, RPM retrieves reasoning-aligned examples for new queries via\nfeature-level similarity and performs inference conditioned on the structured\nfactors and retrieved reasoning paths, enabling the model to follow\nuser-specific reasoning trajectories. This reasoning-level personalization\nenhances both predictive accuracy and interpretability by grounding model\noutputs in user-specific logic through structured information. Extensive\nexperiments across diverse tasks show that RPM consistently outperforms\nresponse-level personalization methods, demonstrating the effectiveness of\nreasoning-level personalization in black-box LLMs.','Jieyong Kim, Tongyoung Kim, Soojin Yoon, Jaehyung Kim, Dongha Lee','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21082v2'),('2505.21087v1','Stopping Criteria for Value Iteration on Concurrent Stochastic Reachability and Safety Games','We consider two-player zero-sum concurrent stochastic games (CSGs) played on\ngraphs with reachability and safety objectives. These include degenerate\nclasses such as Markov decision processes or turn-based stochastic games, which\ncan be solved by linear or quadratic programming; however, in practice, value\niteration (VI) outperforms the other approaches and is the most implemented\nmethod. Similarly, for CSGs, this practical performance makes VI an attractive\nalternative to the standard theoretical solution via the existential theory of\nreals.\n  VI starts with an under-approximation of the sought values for each state and\niteratively updates them, traditionally terminating once two consecutive\napproximations are $\\epsilon$-close. However, this stopping criterion lacks\nguarantees on the precision of the approximation, which is the goal of this\nwork. We provide bounded (a.k.a. interval) VI for CSGs: it complements standard\nVI with a converging sequence of over-approximations and terminates once the\nover- and under-approximations are $\\epsilon$-close.','Marta Grobelna, Jan Křetínský, Maximilian Weininger','2025-05-27','cs.LO','http://arxiv.org/pdf/2505.21087v1'),('2505.21091v1','Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)','System prompts in Large Language Models (LLMs) are predefined directives that\nguide model behaviour, taking precedence over user inputs in text processing\nand generation. LLM deployers increasingly use them to ensure consistent\nresponses across contexts. While model providers set a foundation of system\nprompts, deployers and third-party developers can append additional prompts\nwithout visibility into others\\\' additions, while this layered implementation\nremains entirely hidden from end-users. As system prompts become more complex,\nthey can directly or indirectly introduce unaccounted for side effects. This\nlack of transparency raises fundamental questions about how the position of\ninformation in different directives shapes model outputs. As such, this work\nexamines how the placement of information affects model behaviour. To this end,\nwe compare how models process demographic information in system versus user\nprompts across six commercially available LLMs and 50 demographic groups. Our\nanalysis reveals significant biases, manifesting in differences in user\nrepresentation and decision-making scenarios. Since these variations stem from\ninaccessible and opaque system-level configurations, they risk\nrepresentational, allocative and potential other biases and downstream harms\nbeyond the user\\\'s ability to detect or correct. Our findings draw attention to\nthese critical issues, which have the potential to perpetuate harms if left\nunexamined. Further, we argue that system prompt analysis must be incorporated\ninto AI auditing processes, particularly as customisable system prompts become\nincreasingly prevalent in commercial AI deployments.','Anna Neumann, Elisabeth Kirsten, Muhammad Bilal Zafar, Jatinder Singh','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21091v1'),('2505.21092v1','BLUCK: A Benchmark Dataset for Bengali Linguistic Understanding and Cultural Knowledge','In this work, we introduce BLUCK, a new dataset designed to measure the\nperformance of Large Language Models (LLMs) in Bengali linguistic understanding\nand cultural knowledge. Our dataset comprises 2366 multiple-choice questions\n(MCQs) carefully curated from compiled collections of several college and job\nlevel examinations and spans 23 categories covering knowledge on Bangladesh\\\'s\nculture and history and Bengali linguistics. We benchmarked BLUCK using 6\nproprietary and 3 open-source LLMs - including GPT-4o, Claude-3.5-Sonnet,\nGemini-1.5-Pro, Llama-3.3-70B-Instruct, and DeepSeekV3. Our results show that\nwhile these models perform reasonably well overall, they, however, struggles in\nsome areas of Bengali phonetics. Although current LLMs\\\' performance on Bengali\ncultural and linguistic contexts is still not comparable to that of mainstream\nlanguages like English, our results indicate Bengali\\\'s status as a mid-resource\nlanguage. Importantly, BLUCK is also the first MCQ-based evaluation benchmark\nthat is centered around native Bengali culture, history, and linguistics.','Daeen Kabir, Minhajur Rahman Chowdhury Mahim, Sheikh Shafayat, Adnan Sadik, Arian Ahmed, Eunsu Kim, Alice Oh','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21092v1'),('2505.21095v1','Improved Impossible Tuning and Lipschitz-Adaptive Universal Online Learning with Gradient Variations','A central goal in online learning is to achieve adaptivity to unknown problem\ncharacteristics, such as environmental changes captured by gradient variation\n(GV), function curvature (universal online learning, UOL), and gradient scales\n(Lipschitz adaptivity, LA). Simultaneously achieving these with optimal\nperformance is a major challenge, partly due to limitations in algorithms for\nprediction with expert advice. These algorithms often serve as meta-algorithms\nin online ensemble frameworks, and their sub-optimality hinders overall UOL\nperformance. Specifically, existing algorithms addressing the ``impossible\ntuning\\\'\\\' issue incur an excess $\\sqrt{\\log T}$ factor in their regret bound\ncompared to the lower bound. To solve this problem, we propose a novel\noptimistic online mirror descent algorithm with an auxiliary initial round\nusing large learning rates. This design enables a refined analysis where a\ngenerated negative term cancels the gap-related factor, resolving the\nimpossible tuning issue up to $\\log\\log T$ factors. Leveraging our improved\nalgorithm as a meta-algorithm, we develop the first UOL algorithm that\nsimultaneously achieves state-of-the-art GV bounds and LA under standard\nassumptions. Our UOL result overcomes key limitations of prior works, notably\nresolving the conflict between LA mechanisms and regret analysis for GV bounds\n-- an open problem highlighted by Xie et al.','Kei Takemura, Ryuta Matsuno, Keita Sakuma','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21095v1'),('2505.21097v1','Thinker: Learning to Think Fast and Slow','Recent studies show that the reasoning capabilities of Large Language Models\n(LLMs) can be improved by applying Reinforcement Learning (RL) to\nquestion-answering (QA) tasks in areas such as math and coding. With a long\ncontext length, LLMs may learn to perform search, as indicated by the\nself-correction behavior observed in DeepSeek R1. However, this search behavior\nis often imprecise and lacks confidence, resulting in long, redundant responses\nand highlighting deficiencies in intuition and verification. Inspired by the\nDual Process Theory in psychology, we introduce a simple modification to the QA\ntask that includes four stages: Fast Thinking, where the LLM must answer within\na strict token budget; Verification, where the model evaluates its initial\nresponse; Slow Thinking, where it refines the initial response with more\ndeliberation; and Summarization, where it distills the refinement from the\nprevious stage into precise steps. Our proposed task improves average accuracy\nfrom 24.9% to 27.9% for Qwen2.5-1.5B, and from 45.9% to 49.8% for\nDeepSeek-R1-Qwen-1.5B. Notably, for Qwen2.5-1.5B, the Fast Thinking mode alone\nachieves 26.8% accuracy using fewer than 1000 tokens, demonstrating substantial\ninference efficiency gains. These findings suggest that intuition and\ndeliberative reasoning are distinct, complementary systems benefiting from\ntargeted training.','Stephen Chung, Wenyu Du, Jie Fu','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21097v1'),('2505.21101v1','Conditional Diffusion Models with Classifier-Free Gibbs-like Guidance','Classifier-Free Guidance (CFG) is a widely used technique for improving\nconditional diffusion models by linearly combining the outputs of conditional\nand unconditional denoisers. While CFG enhances visual quality and improves\nalignment with prompts, it often reduces sample diversity, leading to a\nchallenging trade-off between quality and diversity. To address this issue, we\nmake two key contributions. First, CFG generally does not correspond to a\nwell-defined denoising diffusion model (DDM). In particular, contrary to common\nintuition, CFG does not yield samples from the target distribution associated\nwith the limiting CFG score as the noise level approaches zero -- where the\ndata distribution is tilted by a power $w \\gt 1$ of the conditional\ndistribution. We identify the missing component: a R\\\\\'enyi divergence term that\nacts as a repulsive force and is required to correct CFG and render it\nconsistent with a proper DDM. Our analysis shows that this correction term\nvanishes in the low-noise limit. Second, motivated by this insight, we propose\na Gibbs-like sampling procedure to draw samples from the desired tilted\ndistribution. This method starts with an initial sample from the conditional\ndiffusion model without CFG and iteratively refines it, preserving diversity\nwhile progressively enhancing sample quality. We evaluate our approach on both\nimage and text-to-audio generation tasks, demonstrating substantial\nimprovements over CFG across all considered metrics. The code is available at\nhttps://github.com/yazidjanati/cfgig','Badr Moufad, Yazid Janati, Alain Durmus, Ahmed Ghorbel, Eric Moulines, Jimmy Olsson','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21101v1'),('2505.21106v1','Interpreting Social Bias in LVLMs via Information Flow Analysis and Multi-Round Dialogue Evaluation','Large Vision Language Models (LVLMs) have achieved remarkable progress in\nmultimodal tasks, yet they also exhibit notable social biases. These biases\noften manifest as unintended associations between neutral concepts and\nsensitive human attributes, leading to disparate model behaviors across\ndemographic groups. While existing studies primarily focus on detecting and\nquantifying such biases, they offer limited insight into the underlying\nmechanisms within the models. To address this gap, we propose an explanatory\nframework that combines information flow analysis with multi-round dialogue\nevaluation, aiming to understand the origin of social bias from the perspective\nof imbalanced internal information utilization. Specifically, we first identify\nhigh-contribution image tokens involved in the model\\\'s reasoning process for\nneutral questions via information flow analysis. Then, we design a multi-turn\ndialogue mechanism to evaluate the extent to which these key tokens encode\nsensitive information. Extensive experiments reveal that LVLMs exhibit\nsystematic disparities in information usage when processing images of different\ndemographic groups, suggesting that social bias is deeply rooted in the model\\\'s\ninternal reasoning dynamics. Furthermore, we complement our findings from a\ntextual modality perspective, showing that the model\\\'s semantic representations\nalready display biased proximity patterns, thereby offering a cross-modal\nexplanation of bias formation.','Zhengyang Ji, Yifan Jia, Shang Gao, Yutao Yue','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21106v1'),('2505.21109v1','A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction','Despite recent advancements in domain adaptation techniques for large\nlanguage models, these methods remain computationally intensive, and the\nresulting models can still exhibit hallucination issues. Most existing\nadaptation methods do not prioritize reducing the computational resources\nrequired for fine-tuning and inference of language models. Hallucination issues\nhave gradually decreased with each new model release. However, they remain\nprevalent in engineering contexts, where generating well-structured text with\nminimal errors and inconsistencies is critical. This work introduces a novel\napproach called the Small Language Graph (SLG), which is a lightweight\nadaptation solution designed to address the two key challenges outlined above.\nThe system is structured in the form of a graph, where each node represents a\nlightweight expert - a small language model fine-tuned on specific and concise\ntexts. The results of this study have shown that SLG was able to surpass\nconventional fine-tuning methods on the Exact Match metric by 3 times.\nAdditionally, the fine-tuning process was 1.7 times faster compared to that of\na larger stand-alone language model. These findings introduce a potential for\nsmall to medium-sized engineering companies to confidently use generative AI\ntechnologies, such as LLMs, without the necessity to invest in expensive\ncomputational resources. Also, the graph architecture and the small size of\nexpert nodes offer a possible opportunity for distributed AI systems, thus\npotentially diverting the global need for expensive centralized compute\nclusters.','Bogdan Bogachov, Yaoyao Fiona Zhao','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21109v1'),('2505.21115v1','Will It Still Be True Tomorrow? Multilingual Evergreen Question Classification to Improve Trustworthy QA','Large Language Models (LLMs) often hallucinate in question answering (QA)\ntasks. A key yet underexplored factor contributing to this is the temporality\nof questions -- whether they are evergreen (answers remain stable over time) or\nmutable (answers change). In this work, we introduce EverGreenQA, the first\nmultilingual QA dataset with evergreen labels, supporting both evaluation and\ntraining. Using EverGreenQA, we benchmark 12 modern LLMs to assess whether they\nencode question temporality explicitly (via verbalized judgments) or implicitly\n(via uncertainty signals). We also train EG-E5, a lightweight multilingual\nclassifier that achieves SoTA performance on this task. Finally, we demonstrate\nthe practical utility of evergreen classification across three applications:\nimproving self-knowledge estimation, filtering QA datasets, and explaining\nGPT-4o retrieval behavior.','Sergey Pletenev, Maria Marina, Nikolay Ivanov, Daria Galimzianova, Nikita Krayko, Mikhail Salnikov, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21115v1'),('2505.21116v1','Creativity in LLM-based Multi-Agent Systems: A Survey','Large language model (LLM)-driven multi-agent systems (MAS) are transforming\nhow humans and AIs collaboratively generate ideas and artifacts. While existing\nsurveys provide comprehensive overviews of MAS infrastructures, they largely\noverlook the dimension of \\emph{creativity}, including how novel outputs are\ngenerated and evaluated, how creativity informs agent personas, and how\ncreative workflows are coordinated. This is the first survey dedicated to\ncreativity in MAS. We focus on text and image generation tasks, and present:\n(1) a taxonomy of agent proactivity and persona design; (2) an overview of\ngeneration techniques, including divergent exploration, iterative refinement,\nand collaborative synthesis, as well as relevant datasets and evaluation\nmetrics; and (3) a discussion of key challenges, such as inconsistent\nevaluation standards, insufficient bias mitigation, coordination conflicts, and\nthe lack of unified benchmarks. This survey offers a structured framework and\nroadmap for advancing the development, evaluation, and standardization of\ncreative MAS.','Yi-Cheng Lin, Kang-Chieh Chen, Zhe-Yan Li, Tzu-Heng Wu, Tzu-Hsuan Wu, Kuan-Yu Chen, Hung-yi Lee, Yun-Nung Chen','2025-05-27','cs.HC','http://arxiv.org/pdf/2505.21116v1'),('2505.21119v1','Universal Value-Function Uncertainties','Estimating epistemic uncertainty in value functions is a crucial challenge\nfor many aspects of reinforcement learning (RL), including efficient\nexploration, safe decision-making, and offline RL. While deep ensembles provide\na robust method for quantifying value uncertainty, they come with significant\ncomputational overhead. Single-model methods, while computationally favorable,\noften rely on heuristics and typically require additional propagation\nmechanisms for myopic uncertainty estimates. In this work we introduce\nuniversal value-function uncertainties (UVU), which, similar in spirit to\nrandom network distillation (RND), quantify uncertainty as squared prediction\nerrors between an online learner and a fixed, randomly initialized target\nnetwork. Unlike RND, UVU errors reflect policy-conditional value uncertainty,\nincorporating the future uncertainties any given policy may encounter. This is\ndue to the training procedure employed in UVU: the online network is trained\nusing temporal difference learning with a synthetic reward derived from the\nfixed, randomly initialized target network. We provide an extensive theoretical\nanalysis of our approach using neural tangent kernel (NTK) theory and show that\nin the limit of infinite network width, UVU errors are exactly equivalent to\nthe variance of an ensemble of independent universal value functions.\nEmpirically, we show that UVU achieves equal performance to large ensembles on\nchallenging multi-task offline RL settings, while offering simplicity and\nsubstantial computational savings.','Moritz A. Zanger, Max Weltevrede, Yaniv Oren, Pascal R. Van der Vaart, Caroline Horsch, Wendelin Böhmer, Matthijs T. J. Spaan','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21119v1'),('2505.21133v1','Robust and Computation-Aware Gaussian Processes','Gaussian processes (GPs) are widely used for regression and optimization\ntasks such as Bayesian optimization (BO) due to their expressiveness and\nprincipled uncertainty estimates. However, in settings with large datasets\ncorrupted by outliers, standard GPs and their sparse approximations struggle\nwith computational tractability and robustness. We introduce Robust\nComputation-aware Gaussian Process (RCaGP), a novel GP model that jointly\naddresses these challenges by combining a principled treatment of\napproximation-induced uncertainty with robust generalized Bayesian updating.\nThe key insight is that robustness and approximation-awareness are not\northogonal but intertwined: approximations can exacerbate the impact of\noutliers, and mitigating one without the other is insufficient. Unlike previous\nwork that focuses narrowly on either robustness or approximation quality, RCaGP\ncombines both in a principled and scalable framework, thus effectively managing\nboth outliers and computational uncertainties introduced by approximations such\nas low-rank matrix multiplications. Our model ensures more conservative and\nreliable uncertainty estimates, a property we rigorously demonstrate.\nAdditionally, we establish a robustness property and show that the mean\nfunction is key to preserving it, motivating a tailored model selection scheme\nfor robust mean functions. Empirical results confirm that solving these\nchallenges jointly leads to superior performance across both clean and\noutlier-contaminated settings, both on regression and high-throughput Bayesian\noptimization benchmarks.','Marshal Arijona Sinaga, Julien Martinelli, Samuel Kaski','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21133v1'),('2505.21135v1','Learning Single Index Models with Diffusion Priors','Diffusion models (DMs) have demonstrated remarkable ability to generate\ndiverse and high-quality images by efficiently modeling complex data\ndistributions. They have also been explored as powerful generative priors for\nsignal recovery, resulting in a substantial improvement in the quality of\nreconstructed signals. However, existing research on signal recovery with\ndiffusion models either focuses on specific reconstruction problems or is\nunable to handle nonlinear measurement models with discontinuous or unknown\nlink functions. In this work, we focus on using DMs to achieve accurate\nrecovery from semi-parametric single index models, which encompass a variety of\npopular nonlinear models that may have {\\em discontinuous} and {\\em unknown}\nlink functions. We propose an efficient reconstruction method that only\nrequires one round of unconditional sampling and (partial) inversion of DMs.\nTheoretical analysis on the effectiveness of the proposed methods has been\nestablished under appropriate conditions. We perform numerical experiments on\nimage datasets for different nonlinear measurement models. We observe that\ncompared to competing methods, our approach can yield more accurate\nreconstructions while utilizing significantly fewer neural function\nevaluations.','Anqi Tang, Youming Chen, Shuchen Xue, Zhaoqiang Liu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21135v1'),('2505.21136v2','SageAttention2++: A More Efficient Implementation of SageAttention2','The efficiency of attention is critical because its time complexity grows\nquadratically with sequence length. SageAttention2 addresses this by utilizing\nquantization to accelerate matrix multiplications (Matmul) in attention. To\nfurther accelerate SageAttention2, we propose to utilize the faster instruction\nof FP8 Matmul accumulated in FP16. The instruction is 2x faster than the FP8\nMatmul used in SageAttention2. Our experiments show that SageAttention2++\nachieves a 3.9x speedup over FlashAttention while maintaining the same\nattention accuracy as SageAttention2. This means SageAttention2++ effectively\naccelerates various models, including those for language, image, and video\ngeneration, with negligible end-to-end metrics loss. The code will be available\nat https://github.com/thu-ml/SageAttention.','Jintao Zhang, Xiaoming Xu, Jia Wei, Haofeng Huang, Pengle Zhang, Chendong Xiang, Jun Zhu, Jianfei Chen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21136v2'),('2505.21137v1','Scaling and Prompting for Improved End-to-End Spoken Grammatical Error Correction','Spoken Grammatical Error Correction (SGEC) and Feedback (SGECF) are crucial\nfor second language learners, teachers and test takers. Traditional SGEC\nsystems rely on a cascaded pipeline consisting of an ASR, a module for\ndisfluency detection (DD) and removal and one for GEC. With the rise of\nend-to-end (E2E) speech foundation models, we investigate their effectiveness\nin SGEC and feedback generation. This work introduces a pseudo-labelling\nprocess to address the challenge of limited labelled data, expanding the\ntraining data size from 77 hours to approximately 2500 hours, leading to\nimproved performance. Additionally, we prompt an E2E Whisper-based SGEC model\nwith fluent transcriptions, showing a slight improvement in SGEC performance,\nwith more significant gains in feedback generation. Finally, we assess the\nimpact of increasing model size, revealing that while pseudo-labelled data does\nnot yield performance gain for a larger Whisper model, training with prompts\nproves beneficial.','Mengjie Qian, Rao Ma, Stefano Bannò, Kate M. Knill, Mark J. F. Gales','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21137v1'),('2505.21138v1','Leveraging LLM and Self-Supervised Training Models for Speech Recognition in Chinese Dialects: A Comparative Analysis','Large-scale training corpora have significantly improved the performance of\nASR models. Unfortunately, due to the relative scarcity of data, Chinese\naccents and dialects remain a challenge for most ASR models. Recent\nadvancements in self-supervised learning have shown that self-supervised pre-\ntraining, combined with large language models (LLM), can effectively enhance\nASR performance in low-resource scenarios. We aim to investigate the\neffectiveness of this paradigm for Chinese dialects. Specifically, we pre-train\na Data2vec2 model on 300,000 hours of unlabeled dialect and accented speech\ndata and do alignment training on a supervised dataset of 40,000 hours. Then,\nwe systematically examine the impact of various projectors and LLMs on\nMandarin, dialect, and accented speech recognition performance under this\nparadigm. Our method achieved SOTA results on multiple dialect datasets,\nincluding Kespeech. We will open-source our work to promote reproducible\nresearch','Tianyi Xu, Hongjie Chen, Wang Qing, Lv Hang, Jian Kang, Li Jie, Zhennan Lin, Yongxiang Li, Xie Lei','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21138v1'),('2505.21139v1','Identifying Heart Attack Risk in Vulnerable Population: A Machine Learning Approach','The COVID-19 pandemic has significantly increased the incidence of\npost-infection cardiovascular events, particularly myocardial infarction, in\nindividuals over 40. While the underlying mechanisms remain elusive, this study\nemploys a hybrid machine learning approach to analyze epidemiological data in\nassessing 13 key heart attack risk factors and their susceptibility. Based on a\nunique dataset that combines demographic, biochemical, ECG, and thallium\nstress-tests, this study categorizes distinct subpopulations against varying\nrisk profiles and then divides the population into \\\'at-risk\\\' (AR) and\n\\\'not-at-risk\\\' (NAR) groups using clustering algorithms. The study reveals\nstrong association between the likelihood of experiencing a heart attack on the\n13 risk factors studied. The aggravated risk for postmenopausal patients\nindicates compromised individual risk factors due to estrogen depletion that\nmay be, further compromised by extraneous stress impacts, like anxiety and\nfear, aspects that have traditionally eluded data modeling predictions.','Subhagata Chattopadhyay, Amit K Chattopadhyay','2025-05-27','q-bio.PE','http://arxiv.org/pdf/2505.21139v1'),('2505.21140v1','HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs','Heterogeneous graph neural networks (HGNNs) have recently drawn increasing\nattention for modeling complex multi-relational data in domains such as\nrecommendation, finance, and social networks. While existing research has been\nlargely focused on enhancing HGNNs\\\' predictive performance, their robustness\nand security, especially under backdoor attacks, remain underexplored. In this\npaper, we propose a novel Heterogeneous Backdoor Attack (HeteroBA) framework\nfor node classification tasks on heterogeneous graphs. HeteroBA inserts\ncarefully crafted trigger nodes with realistic features and targeted structural\nconnections, leveraging attention-based and clustering-based strategies to\nselect influential auxiliary nodes for effective trigger propagation, thereby\ncausing the model to misclassify specific nodes into a target label while\nmaintaining accuracy on clean data. Experimental results on three datasets and\nvarious HGNN architectures demonstrate that HeteroBA achieves high attack\nsuccess rates with minimal impact on the clean accuracy. Our method sheds light\non potential vulnerabilities in HGNNs and calls for more robust defenses\nagainst backdoor threats in multi-relational graph scenarios.','Honglin Gao, Xiang Li, Lan Zhao, Gaoxi Xiao','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21140v1'),('2505.21141v1','A Predicting Phishing Websites Using Support Vector Machine and MultiClass Classification Based on Association Rule Techniques','Phishing is a semantic attack which targets the user rather than the\ncomputer. It is a new Internet crime in comparison with other forms such as\nvirus and hacking. Considering the damage phishing websites has caused to\nvarious economies by collapsing organizations, stealing information and\nfinancial diversion, various researchers have embarked on different ways of\ndetecting phishing websites but there has been no agreement about the best\nalgorithm to be used for prediction. This study is interested in integrating\nthe strengths of two algorithms, Support Vector Machines (SVM) and Multi-Class\nClassification Rules based on Association Rules (MCAR) to establish a strong\nand better means of predicting phishing websites. A total of 11,056 websites\nwere used from both PhishTank and yahoo directory to verify the effectiveness\nof this approach. Feature extraction and rules generation were done by the MCAR\ntechnique; classification and prediction were done by SVM technique. The result\nshowed that the technique achieved 98.30% classification accuracy with a\ncomputation time of 2205.33s with minimum error rate. It showed a total of 98%\nArea under the Curve (AUC) which showed the proportion of accuracy in\nclassifying phishing websites. The model showed 82.84% variance in the\nprediction of phishing websites based on the coefficient of determination. The\nuse of two techniques together in detecting phishing websites produced a more\naccurate result as it combined the strength of both techniques respectively.\nThis research work centralized on this advantage by building a hybrid of two\ntechniques to help produce a more accurate result.','Nancy C. Woods, Virtue Ene Agada, Adebola K. Ojo','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21141v1'),('2505.21147v1','Semi-Supervised Conformal Prediction With Unlabeled Nonconformity Score','Conformal prediction (CP) is a powerful framework for uncertainty\nquantification, providing prediction sets with coverage guarantees when\ncalibrated on sufficient labeled data. However, in real-world applications\nwhere labeled data is often limited, standard CP can lead to coverage deviation\nand output overly large prediction sets. In this paper, we extend CP to the\nsemi-supervised setting and propose SemiCP, leveraging both labeled data and\nunlabeled data for calibration. Specifically, we introduce a novel\nnonconformity score function, NNM, designed for unlabeled data. This function\nselects labeled data with similar pseudo-label scores to estimate nonconformity\nscores, integrating them into the calibration process to overcome sample size\nlimitations. We theoretically demonstrate that, under mild assumptions, SemiCP\nprovide asymptotically coverage guarantee for prediction sets. Extensive\nexperiments further validate that our approach effectively reduces instability\nand inefficiency under limited calibration data, can be adapted to conditional\ncoverage settings, and integrates seamlessly with existing CP methods.','Xuanning Zhou, Hao Zeng, Xiaobo Xia, Bingyi Jing, Hongxin Wei','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21147v1'),('2505.21148v1','Assessment of L2 Oral Proficiency using Speech Large Language Models','The growing population of L2 English speakers has increased the demand for\ndeveloping automatic graders for spoken language assessment (SLA).\nHistorically, statistical models, text encoders, and self-supervised speech\nmodels have been utilised for this task. However, cascaded systems suffer from\nthe loss of information, while E2E graders also have limitations. With the\nrecent advancements of multi-modal large language models (LLMs), we aim to\nexplore their potential as L2 oral proficiency graders and overcome these\nissues. In this work, we compare various training strategies using regression\nand classification targets. Our results show that speech LLMs outperform all\nprevious competitive baselines, achieving superior performance on two datasets.\nFurthermore, the trained grader demonstrates strong generalisation capabilities\nin the cross-part or cross-task evaluation, facilitated by the audio\nunderstanding knowledge acquired during LLM pre-training.','Rao Ma, Mengjie Qian, Siyuan Tang, Stefano Bannò, Kate M. Knill, Mark J. F. Gales','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21148v1'),('2505.21154v1','GGBond: Growing Graph-Based AI-Agent Society for Socially-Aware Recommender Simulation','Current personalized recommender systems predominantly rely on static offline\ndata for algorithm design and evaluation, significantly limiting their ability\nto capture long-term user preference evolution and social influence dynamics in\nreal-world scenarios. To address this fundamental challenge, we propose a\nhigh-fidelity social simulation platform integrating human-like cognitive\nagents and dynamic social interactions to realistically simulate user behavior\nevolution under recommendation interventions. Specifically, the system\ncomprises a population of Sim-User Agents, each equipped with a five-layer\ncognitive architecture that encapsulates key psychological mechanisms,\nincluding episodic memory, affective state transitions, adaptive preference\nlearning, and dynamic trust-risk assessments. In particular, we innovatively\nintroduce the Intimacy--Curiosity--Reciprocity--Risk (ICR2) motivational engine\ngrounded in psychological and sociological theories, enabling more realistic\nuser decision-making processes. Furthermore, we construct a multilayer\nheterogeneous social graph (GGBond Graph) supporting dynamic relational\nevolution, effectively modeling users\\\' evolving social ties and trust dynamics\nbased on interest similarity, personality alignment, and structural homophily.\nDuring system operation, agents autonomously respond to recommendations\ngenerated by typical recommender algorithms (e.g., Matrix Factorization,\nMultVAE, LightGCN), deciding whether to consume, rate, and share content while\ndynamically updating their internal states and social connections, thereby\nforming a stable, multi-round feedback loop. This innovative design transcends\nthe limitations of traditional static datasets, providing a controlled,\nobservable environment for evaluating long-term recommender effects.','Hailin Zhong, Hanlin Wang, Yujun Ye, Meiyi Zhang, Shengxin Zhu','2025-05-27','cs.MA','http://arxiv.org/pdf/2505.21154v1'),('2505.21156v1','Model as Loss: A Self-Consistent Training Paradigm','Conventional methods for speech enhancement rely on handcrafted loss\nfunctions (e.g., time or frequency domain losses) or deep feature losses (e.g.,\nusing WavLM or wav2vec), which often fail to capture subtle signal properties\nessential for optimal performance. To address this, we propose Model as Loss, a\nnovel training paradigm that utilizes the encoder from the same model as a loss\nfunction to guide the training.\n  The Model as Loss paradigm leverages the encoder\\\'s task-specific feature\nspace, optimizing the decoder to produce output consistent with perceptual and\ntask-relevant characteristics of the clean signal. By using the encoder\\\'s\nlearned features as a loss function, this framework enforces self-consistency\nbetween the clean reference speech and the enhanced model output. Our approach\noutperforms pre-trained deep feature losses on standard speech enhancement\nbenchmarks, offering better perceptual quality and robust generalization to\nboth in-domain and out-of-domain datasets.','Saisamarth Rajesh Phaye, Milos Cernak, Andrew Harper','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.21156v1'),('2505.21160v1','STEB: In Search of the Best Evaluation Approach for Synthetic Time Series','The growing need for synthetic time series, due to data augmentation or\nprivacy regulations, has led to numerous generative models, frameworks, and\nevaluation measures alike. Objectively comparing these measures on a large\nscale remains an open challenge. We propose the Synthetic Time series\nEvaluation Benchmark (STEB) -- the first benchmark framework that enables\ncomprehensive and interpretable automated comparisons of synthetic time series\nevaluation measures. Using 10 diverse datasets, randomness injection, and 13\nconfigurable data transformations, STEB computes indicators for measure\nreliability and score consistency. It tracks running time, test errors, and\nfeatures sequential and parallel modes of operation. In our experiments, we\ndetermine a ranking of 41 measures from literature and confirm that the choice\nof upstream time series embedding heavily impacts the final score.','Michael Stenger, Robert Leppich, André Bauer, Samuel Kounev','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21160v1'),('2505.21162v1','Leveraging GANs for citation intent classification and its impact on citation network analysis','Citations play a fundamental role in the scientific ecosystem, serving as a\nfoundation for tracking the flow of knowledge, acknowledging prior work, and\nassessing scholarly influence. In scientometrics, they are also central to the\nconstruction of quantitative indicators. Not all citations, however, serve the\nsame function: some provide background, others introduce methods, or compare\nresults. Therefore, understanding citation intent allows for a more nuanced\ninterpretation of scientific impact. In this paper, we adopted a GAN-based\nmethod to classify citation intents. Our results revealed that the proposed\nmethod achieves competitive classification performance, closely matching\nstate-of-the-art results with substantially fewer parameters. This demonstrates\nthe effectiveness and efficiency of leveraging GAN architectures combined with\ncontextual embeddings in intent classification task. We also investigated\nwhether filtering citation intents affects the centrality of papers in citation\nnetworks. Analyzing the network constructed from the unArXiv dataset, we found\nthat paper rankings can be significantly influenced by citation intent. All\nfour centrality metrics examined- degree, PageRank, closeness, and betweenness\n- were sensitive to the filtering of citation types. The betweenness centrality\ndisplayed the greatest sensitivity, showing substantial changes in ranking when\nspecific citation intents were removed.','Davi A. Bezerra, Filipi N. Silva, Diego R. Amancio','2025-05-27','cs.DL','http://arxiv.org/pdf/2505.21162v1'),('2505.21170v1','Quantum AIXI: Universal Intelligence via Quantum Information','AIXI is a widely studied model of artificial general intelligence (AGI) based\nupon principles of induction and reinforcement learning. However, AIXI is\nfundamentally classical in nature - as are the environments in which it is\nmodelled. Given the universe is quantum mechanical in nature and the\nexponential overhead required to simulate quantum mechanical systems\nclassically, the question arises as to whether there are quantum mechanical\nanalogues of AIXI which are theoretically consistent or practically feasible as\nmodels of universal intelligence. To address this question, we extend the\nframework to quantum information and present Quantum AIXI (QAIXI). We introduce\na model of quantum agent/environment interaction based upon quantum and\nclassical registers and channels, showing how quantum AIXI agents may take both\nclassical and quantum actions. We formulate the key components of AIXI in\nquantum information terms, extending previous research on quantum Kolmogorov\ncomplexity and a QAIXI value function. We discuss conditions and limitations\nupon quantum Solomonoff induction and show how contextuality fundamentally\naffects QAIXI models.','Elija Perrier','2025-05-27','quant-ph','http://arxiv.org/pdf/2505.21170v1'),('2505.21171v1','M-Wanda: Improving One-Shot Pruning for Multilingual LLMs','Multilingual LLM performance is often critically dependent on model size.\nWith an eye on efficiency, this has led to a surge in interest in one-shot\npruning methods that retain the benefits of large-scale pretraining while\nshrinking the model size. However, as pruning tends to come with performance\nloss, it is important to understand the trade-offs between multilinguality and\nsparsification. In this work, we study multilingual performance under different\nsparsity constraints and show that moderate ratios already substantially harm\nperformance. To help bridge this gap, we propose M-Wanda, a pruning method that\nmodels cross-lingual variation by incorporating language-aware activation\nstatistics into its pruning criterion and dynamically adjusts layerwise\nsparsity based on cross-lingual importance. We show that M-Wanda consistently\nimproves performance at minimal additional costs. We are the first to\nexplicitly optimize pruning to retain multilingual performance, and hope to\ninspire future advances in multilingual pruning.','Rochelle Choenni, Ivan Titov','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21171v1'),('2505.21172v1','TAT-R1: Terminology-Aware Translation with Reinforcement Learning and Word Alignment','Recently, deep reasoning large language models(LLMs) like DeepSeek-R1 have\nmade significant progress in tasks such as mathematics and coding. Inspired by\nthis, several studies have employed reinforcement learning(RL) to enhance\nmodels\\\' deep reasoning capabilities and improve machine translation(MT)\nquality. However, the terminology translation, an essential task in MT, remains\nunexplored in deep reasoning LLMs. In this paper, we propose \\textbf{TAT-R1}, a\nterminology-aware translation model trained with reinforcement learning and\nword alignment. Specifically, we first extract the keyword translation pairs\nusing a word alignment model. Then we carefully design three types of\nrule-based alignment rewards with the extracted alignment relationships. With\nthose alignment rewards, the RL-trained translation model can learn to focus on\nthe accurate translation of key information, including terminology in the\nsource text. Experimental results show the effectiveness of TAT-R1. Our model\nsignificantly improves terminology translation accuracy compared to the\nbaseline models while maintaining comparable performance on general translation\ntasks. In addition, we conduct detailed ablation studies of the\nDeepSeek-R1-like training paradigm for machine translation and reveal several\nkey findings.','Zheng Li, Mao Zheng, Mingyang Song, Wenjie Yang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21172v1'),('2505.21173v1','Topological Deep Learning for Speech Data','Topological data analysis (TDA) offers novel mathematical tools for deep\nlearning. Inspired by Carlsson et al., this study designs topology-aware\nconvolutional kernels that significantly improve speech recognition networks.\nTheoretically, by investigating orthogonal group actions on kernels, we\nestablish a fiber-bundle decomposition of matrix spaces, enabling new filter\ngeneration methods. Practically, our proposed Orthogonal Feature (OF) layer\nachieves superior performance in phoneme recognition, particularly in low-noise\nscenarios, while demonstrating cross-domain adaptability. This work reveals\nTDA\\\'s potential in neural network optimization, opening new avenues for\nmathematics-deep learning interdisciplinary studies.','Zhiwang Yu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21173v1'),('2505.21178v1','Walk Before You Run! Concise LLM Reasoning via Reinforcement Learning','As test-time scaling becomes a pivotal research frontier in Large Language\nModels (LLMs) development, contemporary and advanced post-training\nmethodologies increasingly focus on extending the generation length of long\nChain-of-Thought (CoT) responses to enhance reasoning capabilities toward\nDeepSeek R1-like performance. However, recent studies reveal a persistent\noverthinking phenomenon in state-of-the-art reasoning models, manifesting as\nexcessive redundancy or repetitive thinking patterns in long CoT responses. To\naddress this issue, in this paper, we propose a simple yet effective two-stage\nreinforcement learning framework for achieving concise reasoning in LLMs, named\nConciseR. Specifically, the first stage, using more training steps, aims to\nincentivize the model\\\'s reasoning capabilities via Group Relative Policy\nOptimization with clip-higher and dynamic sampling components (GRPO++), and the\nsecond stage, using fewer training steps, explicitly enforces conciseness and\nimproves efficiency via Length-aware Group Relative Policy Optimization\n(L-GRPO). Significantly, ConciseR only optimizes response length once all\nrollouts of a sample are correct, following the \"walk before you run\"\nprinciple. Extensive experimental results demonstrate that our ConciseR model,\nwhich generates more concise CoT reasoning responses, outperforms recent\nstate-of-the-art reasoning models with zero RL paradigm across AIME 2024,\nMATH-500, AMC 2023, Minerva, and Olympiad benchmarks.','Mingyang Song, Mao Zheng','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21178v1'),('2505.21180v1','Latent label distribution grid representation for modeling uncertainty','Although \\textbf{L}abel \\textbf{D}istribution \\textbf{L}earning (LDL) has\npromising representation capabilities for characterizing the polysemy of an\ninstance, the complexity and high cost of the label distribution annotation\nlead to inexact in the construction of the label space. The existence of a\nlarge number of inexact labels generates a label space with uncertainty, which\nmisleads the LDL algorithm to yield incorrect decisions. To alleviate this\nproblem, we model the uncertainty of label distributions by constructing a\n\\textbf{L}atent \\textbf{L}abel \\textbf{D}istribution \\textbf{G}rid (LLDG) to\nform a low-noise representation space. Specifically, we first construct a label\ncorrelation matrix based on the differences between labels, and then expand\neach value of the matrix into a vector that obeys a Gaussian distribution, thus\nbuilding a LLDG to model the uncertainty of the label space. Finally, the LLDG\nis reconstructed by the LLDG-Mixer to generate an accurate label distribution.\nNote that we enforce a customized low-rank scheme on this grid, which assumes\nthat the label relations may be noisy and it needs to perform noise-reduction\nwith the help of a Tucker reconstruction technique. Furthermore, we attempt to\nevaluate the effectiveness of the LLDG by considering its generation as an\nupstream task to achieve the classification of the objects. Extensive\nexperimental results show that our approach performs competitively on several\nbenchmarks.','ShuNing Sun, YinSong Xiong, Yu Zhang, Zhuoran Zheng','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21180v1'),('2505.21182v1','Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations','Offline imitation learning typically learns from expert and unlabeled\ndemonstrations, yet often overlooks the valuable signal in explicitly\nundesirable behaviors. In this work, we study offline imitation learning from\ncontrasting behaviors, where the dataset contains both expert and undesirable\ndemonstrations. We propose a novel formulation that optimizes a difference of\nKL divergences over the state-action visitation distributions of expert and\nundesirable (or bad) data. Although the resulting objective is a DC\n(Difference-of-Convex) program, we prove that it becomes convex when expert\ndemonstrations outweigh undesirable demonstrations, enabling a practical and\nstable non-adversarial training objective. Our method avoids adversarial\ntraining and handles both positive and negative demonstrations in a unified\nframework. Extensive experiments on standard offline imitation learning\nbenchmarks demonstrate that our approach consistently outperforms\nstate-of-the-art baselines.','Huy Hoang, Tien Mai, Pradeep Varakantham, Tanvi Verma','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21182v1'),('2505.21184v1','PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing','To construct responsible and secure AI applications, harmful information data\nis widely utilized for adversarial testing and the development of safeguards.\nExisting studies mainly leverage Large Language Models (LLMs) to synthesize\ndata to obtain high-quality task datasets at scale, thereby avoiding costly\nhuman annotation. However, limited by the safety alignment mechanisms of LLMs,\nthe synthesis of harmful data still faces challenges in generation reliability\nand content diversity. In this study, we propose a novel harmful information\nsynthesis framework, PoisonSwarm, which applies the model crowdsourcing\nstrategy to generate diverse harmful data while maintaining a high success\nrate. Specifically, we generate abundant benign data as the based templates in\na counterfactual manner. Subsequently, we decompose each based template into\nmultiple semantic units and perform unit-by-unit toxification and final\nrefinement through dynamic model switching, thus ensuring the success of\nsynthesis. Experimental results demonstrate that PoisonSwarm achieves\nstate-of-the-art performance in synthesizing different categories of harmful\ndata with high scalability and diversity.','Yu Yan, Sheng Sun, Zhifei Zheng, Ziji Hao, Teli Liu, Min Liu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21184v1'),('2505.21189v1','Exploring the Latent Capacity of LLMs for One-Step Text Generation','A recent study showed that large language models (LLMs) can reconstruct\nsurprisingly long texts - up to thousands of tokens - via autoregressive\ngeneration from just one specially trained input embedding. In this work, we\nexplore whether such reconstruction is possible without autoregression. We show\nthat frozen LLMs can generate hundreds of accurate tokens in just one forward\npass, when provided with only two learned embeddings. This reveals a surprising\nand underexplored capability of LLMs - multi-token generation without iterative\ndecoding. We investigate the behaviour of these embeddings and provide insight\ninto the type of information they encode. We also empirically show that\nalthough these representations are not unique for a given text, they form\nconnected and local regions in embedding space - a property that suggests the\npotential of learning a dedicated encoder into that space.','Gleb Mezentsev, Ivan Oseledets','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21189v1'),('2505.21190v1','Lunguage: A Benchmark for Structured and Sequential Chest X-ray Interpretation','Radiology reports convey detailed clinical observations and capture\ndiagnostic reasoning that evolves over time. However, existing evaluation\nmethods are limited to single-report settings and rely on coarse metrics that\nfail to capture fine-grained clinical semantics and temporal dependencies. We\nintroduce LUNGUAGE,a benchmark dataset for structured radiology report\ngeneration that supports both single-report evaluation and longitudinal\npatient-level assessment across multiple studies. It contains 1,473 annotated\nchest X-ray reports, each reviewed by experts, and 80 of them contain\nlongitudinal annotations to capture disease progression and inter-study\nintervals, also reviewed by experts. Using this benchmark, we develop a\ntwo-stage framework that transforms generated reports into fine-grained,\nschema-aligned structured representations, enabling longitudinal\ninterpretation. We also propose LUNGUAGESCORE, an interpretable metric that\ncompares structured outputs at the entity, relation, and attribute level while\nmodeling temporal consistency across patient timelines. These contributions\nestablish the first benchmark dataset, structuring framework, and evaluation\nmetric for sequential radiology reporting, with empirical results demonstrating\nthat LUNGUAGESCORE effectively supports structured report evaluation. The code\nis available at: https://github.com/SuperSupermoon/Lunguage','Jong Hak Moon, Geon Choi, Paloma Rabaey, Min Gwan Kim, Hyuk Gi Hong, Jung-Oh Lee, Hangyul Yoon, Eun Woo Doe, Jiyoun Kim, Harshita Sharma, Daniel C. Castro, Javier Alvarez-Valle, Edward Choi','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21190v1'),('2505.21191v1','Unveiling Instruction-Specific Neurons & Experts: An Analytical Framework for LLM\\\'s Instruction-Following Capabilities','The finetuning of Large Language Models (LLMs) has significantly advanced\ntheir instruction-following capabilities, yet the underlying computational\nmechanisms driving these improvements remain poorly understood. This study\nsystematically examines how fine-tuning reconfigures LLM computations by\nisolating and analyzing instruction-specific sparse components, i.e., neurons\nin dense models and both neurons and experts in Mixture-of-Experts (MoE)\narchitectures. In particular, we introduce HexaInst, a carefully curated and\nbalanced instructional dataset spanning six distinct categories, and propose\nSPARCOM, a novel analytical framework comprising three key contributions: (1) a\nmethod for identifying these sparse components, (2) an evaluation of their\nfunctional generality and uniqueness, and (3) a systematic comparison of their\nalterations. Through experiments, we demonstrate functional generality,\nuniqueness, and the critical role of these components in instruction execution.\nBy elucidating the relationship between fine-tuning-induced adaptations and\nsparse computational substrates, this work provides deeper insights into how\nLLMs internalize instruction-following behavior for the trustworthy LLM\ncommunity.','Junyan Zhang, Yubo Gao, Yibo Yan, Jungang Li, Zhaorui Hou, Sicheng Tao, Shuliang Liu, Song Dai, Yonghua Hei, Junzhuo Li, Xuming Hu','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21191v1'),('2505.21201v1','Crop recommendation with machine learning: leveraging environmental and economic factors for optimal crop selection','Agriculture constitutes a primary source of food production, economic growth\nand employment in India, but the sector is confronted with low farm\nproductivity and yields aggravated by increased pressure on natural resources\nand adverse climate change variability. Efforts involving green revolution,\nland irrigations, improved seeds and organic farming have yielded suboptimal\noutcomes. The adoption of computational tools like crop recommendation systems\noffers a new way to provide insights and help farmers tackle low productivity.\nHowever, most agricultural recommendation systems in India focus narrowly on\nenvironmental factors and regions, limiting accurate predictions of high-yield,\nprofitable crops. This study uses environmental and economic factors with 19\ncrops across 15 states to develop and evaluate Random Forest and SVM models\nusing 10-fold Cross Validation, Time-series Split, and Lag Variables. The\n10-fold cross validation showed high accuracy (RF: 99.96%, SVM: 94.71%) but\nraised overfitting concerns. Introducing temporal order, better reflecting\nreal-world conditions, reduced performance (RF: 78.55%, SVM: 71.18%) in the\nTime-series Split.To further increase the model accuracy while maintaining the\ntemporal order, the Lag Variables approach was employed, which resulted in\nimproved performance (RF: 83.62%, SVM: 74.38%) compared to the 10-fold cross\nvalidation approach. Overall, the models in the Time-series Split and Lag\nVariable Approaches offer practical insights by handling temporal dependencies\nand enhancing its adaptability to changing agricultural conditions over time.\nConsequently, the study shows the Random Forest model developed based on the\nLag Variables as the most preferred algorithm for optimal crop recommendation\nin the Indian context.','Steven Sam, Silima Marshal DAbreo','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21201v1'),('2505.21204v1','Developing hybrid mechanistic and data-driven personalized prediction models for platelet dynamics','Hematotoxicity, drug-induced damage to the blood-forming system, is a\nfrequent side effect of cytotoxic chemotherapy and poses a significant\nchallenge in clinical practice due to its high inter-patient variability and\nlimited predictability. Current mechanistic models often struggle to accurately\nforecast outcomes for patients with irregular or atypical trajectories. In this\nstudy, we develop and compare hybrid mechanistic and data-driven approaches for\nindividualized time series modeling of platelet counts during chemotherapy. We\nconsider hybrid models that combine mechanistic models with neural networks,\nknown as universal differential equations. As a purely data-driven alternative,\nwe utilize a nonlinear autoregressive exogenous model using gated recurrent\nunits as the underlying architecture. These models are evaluated across a range\nof real patient scenarios, varying in data availability and sparsity, to assess\npredictive performance. Our findings demonstrate that data-driven methods, when\nprovided with sufficient data, significantly improve prediction accuracy,\nparticularly for high-risk patients with irregular platelet dynamics. This\nhighlights the potential of data-driven approaches in enhancing clinical\ndecision-making. In contrast, hybrid and mechanistic models are superior in\nscenarios with limited or sparse data. The proposed modeling and comparison\nframework is generalizable and could be extended to predict other\ntreatment-related toxicities, offering broad applicability in personalized\nmedicine.','Marie Steinacker, Yuri Kheifetz, Markus Scholz','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21204v1'),('2505.21208v1','Input Convex Kolmogorov Arnold Networks','This article presents an input convex neural network architecture using\nKolmogorov-Arnold networks (ICKAN). Two specific networks are presented: the\nfirst is based on a low-order, linear-by-part, representation of functions, and\na universal approximation theorem is provided. The second is based on cubic\nsplines, for which only numerical results support convergence. We demonstrate\non simple tests that these networks perform competitively with classical input\nconvex neural networks (ICNNs). In a second part, we use the networks to solve\nsome optimal transport problems needing a convex approximation of functions and\ndemonstrate their effectiveness. Comparisons with ICNNs show that cubic ICKANs\nproduce results similar to those of classical ICNNs.','Thomas Deschatre, Xavier Warin','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.21208v1'),('2505.21212v1','Interpretable DNFs','A classifier is considered interpretable if each of its decisions has an\nexplanation which is small enough to be easily understood by a human user. A\nDNF formula can be seen as a binary classifier $\\kappa$ over boolean domains.\nThe size of an explanation of a positive decision taken by a DNF $\\kappa$ is\nbounded by the size of the terms in $\\kappa$, since we can explain a positive\ndecision by giving a term of $\\kappa$ that evaluates to true. Since both\npositive and negative decisions must be explained, we consider that\ninterpretable DNFs are those $\\kappa$ for which both $\\kappa$ and\n$\\overline{\\kappa}$ can be expressed as DNFs composed of terms of bounded size.\nIn this paper, we study the family of $k$-DNFs whose complements can also be\nexpressed as $k$-DNFs. We compare two such families, namely depth-$k$ decision\ntrees and nested $k$-DNFs, a novel family of models. Experiments indicate that\nnested $k$-DNFs are an interesting alternative to decision trees in terms of\ninterpretability and accuracy.','Martin C. Cooper, Imane Bousdira, Clément Carbonnel','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21212v1'),('2505.21215v1','Transfer learning for multifidelity simulation-based inference in cosmology','Simulation-based inference (SBI) enables cosmological parameter estimation\nwhen closed-form likelihoods or models are unavailable. However, SBI relies on\nmachine learning for neural compression and density estimation. This requires\nlarge training datasets which are prohibitively expensive for high-quality\nsimulations. We overcome this limitation with multifidelity transfer learning,\ncombining less expensive, lower-fidelity simulations with a limited number of\nhigh-fidelity simulations. We demonstrate our methodology on dark matter\ndensity maps from two separate simulation suites in the hydrodynamical CAMELS\nMultifield Dataset. Pre-training on dark-matter-only $N$-body simulations\nreduces the required number of high-fidelity hydrodynamical simulations by a\nfactor between $8$ and $15$, depending on the model complexity, posterior\ndimensionality, and performance metrics used. By leveraging cheaper\nsimulations, our approach enables performant and accurate inference on\nhigh-fidelity models while substantially reducing computational costs.','Alex A. Saoulis, Davide Piras, Niall Jeffrey, Alessio Spurio Mancini, Ana M. G. Ferreira, Benjamin Joachimi','2025-05-27','astro-ph.CO','http://arxiv.org/pdf/2505.21215v1'),('2505.21218v1','Pretrained LLMs Learn Multiple Types of Uncertainty','Large Language Models are known to capture real-world knowledge, allowing\nthem to excel in many downstream tasks. Despite recent advances, these models\nare still prone to what are commonly known as hallucinations, causing them to\nemit unwanted and factually incorrect text. In this work, we study how well\nLLMs capture uncertainty, without explicitly being trained for that. We show\nthat, if considering uncertainty as a linear concept in the model\\\'s latent\nspace, it might indeed be captured, even after only pretraining. We further\nshow that, though unintuitive, LLMs appear to capture several different types\nof uncertainty, each of which can be useful to predict the correctness for a\nspecific task or benchmark. Furthermore, we provide in-depth results such as\ndemonstrating a correlation between our correction prediction and the model\\\'s\nability to abstain from misinformation using words, and the lack of impact of\nmodel scaling for capturing uncertainty. Finally, we claim that unifying the\nuncertainty types as a single one using instruction-tuning or [IDK]-token\ntuning is helpful for the model in terms of correctness prediction.','Roi Cohen, Omri Fahn, Gerard de Melo','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21218v1'),('2505.21219v1','Addressing Data Quality Decompensation in Federated Learning via Dynamic Client Selection','In cross-silo Federated Learning (FL), client selection is critical to ensure\nhigh model performance, yet it remains challenging due to data quality\ndecompensation, budget constraints, and incentive compatibility. As training\nprogresses, these factors exacerbate client heterogeneity and degrade global\nperformance. Most existing approaches treat these challenges in isolation,\nmaking jointly optimizing multiple factors difficult. To address this, we\npropose Shapley-Bid Reputation Optimized Federated Learning (SBRO-FL), a\nunified framework integrating dynamic bidding, reputation modeling, and\ncost-aware selection. Clients submit bids based on their perceived data\nquality, and their contributions are evaluated using Shapley values to quantify\ntheir marginal impact on the global model. A reputation system, inspired by\nprospect theory, captures historical performance while penalizing\ninconsistency. The client selection problem is formulated as a 0-1 integer\nprogram that maximizes reputation-weighted utility under budget constraints.\nExperiments on FashionMNIST, EMNIST, CIFAR-10, and SVHN datasets show that\nSBRO-FL improves accuracy, convergence speed, and robustness, even in\nadversarial and low-bid interference scenarios. Our results highlight the\nimportance of balancing data reliability, incentive compatibility, and cost\nefficiency to enable scalable and trustworthy FL deployments.','Qinjun Fei, Nuria Rodríguez-Barroso, María Victoria Luzón, Zhongliang Zhang, Francisco Herrera','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21219v1'),('2505.21220v1','Wavelet Flow For Extragalactic Foreground Simulations','Extragalactic foregrounds in cosmic microwave background (CMB) observations\nare both a source of cosmological and astrophysical information and a nuisance\nto the CMB. Effective field-level modeling that captures their non-Gaussian\nstatistical distributions is increasingly important for optimal information\nextraction, particularly given the precise and low-noise observations from\ncurrent and upcoming experiments. We explore the use of Wavelet Flow (WF)\nmodels to tackle the novel task of modeling the field-level probability\ndistributions of multi-component CMB secondaries. Specifically, we jointly\ntrain correlated CMB lensing convergence ($\\kappa$) and cosmic infrared\nbackground (CIB) maps with a WF model and obtain a network that statistically\nrecovers the input to high accuracy -- the trained network generates samples of\n$\\kappa$ and CIB fields whose average power spectra are within a few percent of\nthe inputs across all scales, and whose Minkowski functionals are similarly\naccurate compared to the inputs. Leveraging the multiscale architecture of\nthese models, we fine-tune both the model parameters and the priors at each\nscale independently, optimizing performance across different resolutions. These\nresults demonstrate that WF models can accurately simulate correlated\ncomponents of CMB secondaries, supporting improved analysis of cosmological\ndata. Our code and trained models can be found here\n(https://github.com/matiwosm/HybridPriorWavletFlow.git).','M. Mebratu, W. L. K. Wu','2025-05-27','astro-ph.CO','http://arxiv.org/pdf/2505.21220v1'),('2505.21224v1','A Representation Level Analysis of NMT Model Robustness to Grammatical Errors','Understanding robustness is essential for building reliable NLP systems.\nUnfortunately, in the context of machine translation, previous work mainly\nfocused on documenting robustness failures or improving robustness. In\ncontrast, we study robustness from a model representation perspective by\nlooking at internal model representations of ungrammatical inputs and how they\nevolve through model layers. For this purpose, we perform Grammatical Error\nDetection (GED) probing and representational similarity analysis. Our findings\nindicate that the encoder first detects the grammatical error, then corrects it\nby moving its representation toward the correct form. To understand what\ncontributes to this process, we turn to the attention mechanism where we\nidentify what we term Robustness Heads. We find that Robustness Heads attend to\ninterpretable linguistic units when responding to grammatical errors, and that\nwhen we fine-tune models for robustness, they tend to rely more on Robustness\nHeads for updating the ungrammatical word representation.','Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21224v1'),('2505.21226v1','Why Do More Experts Fail? A Theoretical Analysis of Model Merging','Model merging dramatically reduces storage and computational resources by\ncombining multiple expert models into a single multi-task model. Although\nrecent model merging methods have shown promising results, they struggle to\nmaintain performance gains as the number of merged models increases. In this\npaper, we investigate the key obstacles that limit the scalability of model\nmerging when integrating a large number of expert models. First, we prove that\nthere is an upper bound on model merging. Further theoretical analysis reveals\nthat the limited effective parameter space imposes a strict constraint on the\nnumber of models that can be successfully merged. Gaussian Width shows that the\nmarginal benefit of merging additional models diminishes according to a\nstrictly concave function. This implies that the effective parameter space\nbecomes rapidly saturated as the number of merged models increases.\nFurthermore, using Approximate Kinematics Theory, we prove the existence of a\nunique optimal threshold beyond which adding more models does not yield\nsignificant performance improvements. At the same time, we introduce a\nstraightforward Reparameterized Heavy-Tailed method (RHT) to extend the\ncoverage of the merged model, thereby enhancing its performance. Empirical\nresults on 12 benchmarks, including both knowledge-intensive and\ngeneral-purpose tasks, validate our theoretical analysis. We believe that these\nresults spark further research beyond the current scope of model merging. The\nsource code is in the anonymous Github repository\nhttps://github.com/wzj1718/ModelMergingAnalysis.','Zijing Wang, Xingle Xu, Yongkang Liu, Yiqun Zhang, Peiqin Lin, Shi Feng, Xiaocui Yang, Daling Wang, Hinrich Schütze','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21226v1'),('2505.21228v1','Is Hyperbolic Space All You Need for Medical Anomaly Detection?','Medical anomaly detection has emerged as a promising solution to challenges\nin data availability and labeling constraints. Traditional methods extract\nfeatures from different layers of pre-trained networks in Euclidean space;\nhowever, Euclidean representations fail to effectively capture the hierarchical\nrelationships within these features, leading to suboptimal anomaly detection\nperformance. We propose a novel yet simple approach that projects feature\nrepresentations into hyperbolic space, aggregates them based on confidence\nlevels, and classifies samples as healthy or anomalous. Our experiments\ndemonstrate that hyperbolic space consistently outperforms Euclidean-based\nframeworks, achieving higher AUROC scores at both image and pixel levels across\nmultiple medical benchmark datasets. Additionally, we show that hyperbolic\nspace exhibits resilience to parameter variations and excels in few-shot\nscenarios, where healthy images are scarce. These findings underscore the\npotential of hyperbolic space as a powerful alternative for medical anomaly\ndetection. The project website can be found at\nhttps://hyperbolic-anomalies.github.io','Alvaro Gonzalez-Jimenez, Simone Lionetti, Ludovic Amruthalingam, Philippe Gottfrois, Fabian Gröger, Marc Pouly, Alexander A. Navarini','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21228v1'),('2505.21230v1','PSRB: A Comprehensive Benchmark for Evaluating Persian ASR Systems','Although Automatic Speech Recognition (ASR) systems have become an integral\npart of modern technology, their evaluation remains challenging, particularly\nfor low-resource languages such as Persian. This paper introduces Persian\nSpeech Recognition Benchmark(PSRB), a comprehensive benchmark designed to\naddress this gap by incorporating diverse linguistic and acoustic conditions.\nWe evaluate ten ASR systems, including state-of-the-art commercial and\nopen-source models, to examine performance variations and inherent biases.\nAdditionally, we conduct an in-depth analysis of Persian ASR transcriptions,\nidentifying key error types and proposing a novel metric that weights\nsubstitution errors. This metric enhances evaluation robustness by reducing the\nimpact of minor and partial errors, thereby improving the precision of\nperformance assessment. Our findings indicate that while ASR models generally\nperform well on standard Persian, they struggle with regional accents,\nchildren\\\'s speech, and specific linguistic challenges. These results highlight\nthe necessity of fine-tuning and incorporating diverse, representative training\ndatasets to mitigate biases and enhance overall ASR performance. PSRB provides\na valuable resource for advancing ASR research in Persian and serves as a\nframework for developing benchmarks in other low-resource languages. A subset\nof the PSRB dataset is publicly available at\nhttps://huggingface.co/datasets/PartAI/PSRB.','Nima Sedghiyeh, Sara Sadeghi, Reza Khodadadi, Farzin Kashani, Omid Aghdaei, Somayeh Rahimi, Mohammad Sadegh Safari','2025-05-27','eess.AS','http://arxiv.org/pdf/2505.21230v1'),('2505.21236v1','Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies','Reinforcement learning (RL) systems have countless applications, from\nenergy-grid management to protein design. However, such real-world scenarios\nare often extremely difficult, combinatorial in nature, and require complex\ncoordination between multiple agents. This level of complexity can cause even\nstate-of-the-art RL systems, trained until convergence, to hit a performance\nceiling which they are unable to break out of with zero-shot inference.\nMeanwhile, many digital or simulation-based applications allow for an inference\nphase that utilises a specific time and compute budget to explore multiple\nattempts before outputting a final solution. In this work, we show that such an\ninference phase employed at execution time, and the choice of a corresponding\ninference strategy, are key to breaking the performance ceiling observed in\ncomplex multi-agent RL problems. Our main result is striking: we can obtain up\nto a 126% and, on average, a 45% improvement over the previous state-of-the-art\nacross 17 tasks, using only a couple seconds of extra wall-clock time during\nexecution. We also demonstrate promising compute scaling properties, supported\nby over 60k experiments, making it the largest study on inference strategies\nfor complex RL to date. Our experimental data and code are available at\nhttps://sites.google.com/view/inf-marl.','Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Ruan de Kock, Claude Formanek, Sasha Abramowitz, Oumayma Mahjoub, Wiem Khlifi, Simon Du Toit, Louay Ben Nessir, Refiloe Shabe, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21236v1'),('2505.21239v1','LMCD: Language Models are Zeroshot Cognitive Diagnosis Learners','Cognitive Diagnosis (CD) has become a critical task in AI-empowered\neducation, supporting personalized learning by accurately assessing students\\\'\ncognitive states. However, traditional CD models often struggle in cold-start\nscenarios due to the lack of student-exercise interaction data. Recent\nNLP-based approaches leveraging pre-trained language models (PLMs) have shown\npromise by utilizing textual features but fail to fully bridge the gap between\nsemantic understanding and cognitive profiling. In this work, we propose\nLanguage Models as Zeroshot Cognitive Diagnosis Learners (LMCD), a novel\nframework designed to handle cold-start challenges by harnessing large language\nmodels (LLMs). LMCD operates via two primary phases: (1) Knowledge Diffusion,\nwhere LLMs generate enriched contents of exercises and knowledge concepts\n(KCs), establishing stronger semantic links; and (2) Semantic-Cognitive Fusion,\nwhere LLMs employ causal attention mechanisms to integrate textual information\nand student cognitive states, creating comprehensive profiles for both students\nand exercises. These representations are efficiently trained with off-the-shelf\nCD models. Experiments on two real-world datasets demonstrate that LMCD\nsignificantly outperforms state-of-the-art methods in both exercise-cold and\ndomain-cold settings. The code is publicly available at\nhttps://github.com/TAL-auroraX/LMCD','Yu He, Zihan Yao, Chentao Song, Tianyu Qi, Jun Liu, Ming Li, Qing Huang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21239v1'),('2505.21241v1','BindEnergyCraft: Casting Protein Structure Predictors as Energy-Based Models for Binder Design','Protein binder design has been transformed by hallucination-based methods\nthat optimize structure prediction confidence metrics, such as the interface\npredicted TM-score (ipTM), via backpropagation. However, these metrics do not\nreflect the statistical likelihood of a binder-target complex under the learned\ndistribution and yield sparse gradients for optimization. In this work, we\npropose a method to extract such likelihoods from structure predictors by\nreinterpreting their confidence outputs as an energy-based model (EBM). By\nleveraging the Joint Energy-based Modeling (JEM) framework, we introduce\npTMEnergy, a statistical energy function derived from predicted inter-residue\nerror distributions. We incorporate pTMEnergy into BindEnergyCraft (BECraft), a\ndesign pipeline that maintains the same optimization framework as BindCraft but\nreplaces ipTM with our energy-based objective. BECraft outperforms BindCraft,\nRFDiffusion, and ESM3 across multiple challenging targets, achieving higher in\nsilico binder success rates while reducing structural clashes. Furthermore,\npTMEnergy establishes a new state-of-the-art in structure-based virtual\nscreening tasks for miniprotein and RNA aptamer binders.','Divya Nori, Anisha Parsan, Caroline Uhler, Wengong Jin','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21241v1'),('2505.21242v1','Evaluation of LLMs in Medical Text Summarization: The Role of Vocabulary Adaptation in High OOV Settings','Large Language Models (LLMs) recently achieved great success in medical text\nsummarization by simply using in-context learning. However, these recent\nefforts do not perform fine-grained evaluations under difficult settings where\nLLMs might fail. They typically report performance scores over the entire\ndataset. Through our benchmarking study, we show that LLMs show a significant\nperformance drop for data points with high concentration of out-of-vocabulary\n(OOV) words or with high novelty. Vocabulary adaptation is an intuitive\nsolution to this vocabulary mismatch issue where the LLM vocabulary gets\nupdated with certain expert domain (here, medical) words or subwords. An\ninteresting finding from our study is that Llama-3.1, even with a vocabulary\nsize of around 128K tokens, still faces over-fragmentation issue with medical\nwords. To that end, we show vocabulary adaptation helps improve the LLM\nsummarization performance even in difficult settings. Through extensive\nexperimentation of multiple vocabulary adaptation strategies, two continual\npretraining strategies, and three benchmark medical summarization datasets, we\ngain valuable insights into the role of vocabulary adaptation strategies for\ncustomizing LLMs to the medical domain. We also performed a human evaluation\nstudy with medical experts where they found that vocabulary adaptation results\nin more relevant and faithful summaries. Our codebase is made publicly\navailable at https://github.com/gb-kgp/LLM-MedicalSummarization-Benchmark.','Gunjan Balde, Soumyadeep Roy, Mainack Mondal, Niloy Ganguly','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21242v1'),('2505.21250v1','ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision','Multi-hop question answering (MHQA) involves reasoning across multiple\ndocuments to answer complex questions. Dense retrievers typically outperform\nsparse methods like BM25 by leveraging semantic embeddings; however, they\nrequire labeled query-document pairs for fine-tuning. This poses a significant\nchallenge in MHQA due to the high variability of queries (reformulated)\nquestions throughout the reasoning steps. To overcome this limitation, we\nintroduce Retriever Supervision with Consistency and Relevance (ReSCORE), a\nnovel method for training dense retrievers for MHQA without labeled documents.\nReSCORE leverages large language models to capture each documents relevance to\nthe question and consistency with the correct answer and use them to train a\nretriever within an iterative question-answering framework. Experiments on\nthree MHQA benchmarks demonstrate the effectiveness of ReSCORE, with\nsignificant improvements in retrieval, and in turn, the state-of-the-art MHQA\nperformance. Our implementation is available at:\nhttps://leeds1219.github.io/ReSCORE.','Dosung Lee, Wonjun Oh, Boyoung Kim, Minyoung Kim, Joonsuk Park, Paul Hongsuck Seo','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21250v1'),('2505.21251v2','Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework','We introduce copresheaf topological neural networks (CTNNs), a powerful and\nunifying framework that encapsulates a wide spectrum of deep learning\narchitectures, designed to operate on structured data: including images, point\nclouds, graphs, meshes, and topological manifolds. While deep learning has\nprofoundly impacted domains ranging from digital assistants to autonomous\nsystems, the principled design of neural architectures tailored to specific\ntasks and data types remains one of the field\\\'s most persistent open\nchallenges. CTNNs address this gap by grounding model design in the language of\ncopresheaves, a concept from algebraic topology that generalizes and subsumes\nmost practical deep learning models in use today. This abstract yet\nconstructive formulation yields a rich design space from which theoretically\nsound and practically effective solutions can be derived to tackle core\nchallenges in representation learning: long-range dependencies, oversmoothing,\nheterophily, and non-Euclidean domains. Our empirical results on structured\ndata benchmarks demonstrate that CTNNs consistently outperform conventional\nbaselines, particularly in tasks requiring hierarchical or localized\nsensitivity. These results underscore CTNNs as a principled, multi-scale\nfoundation for the next generation of deep learning architectures.','Mustafa Hajij, Lennart Bastian, Sarah Osentoski, Hardik Kabaria, John L. Davenport, Sheik Dawood, Balaji Cherukuri, Joseph G. Kocheemoolayil, Nastaran Shahmansouri, Adrian Lew, Theodore Papamarkou, Tolga Birdal','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21251v2'),('2505.21265v1','Multilingual Pretraining for Pixel Language Models','Pixel language models operate directly on images of rendered text,\neliminating the need for a fixed vocabulary. While these models have\ndemonstrated strong capabilities for downstream cross-lingual transfer,\nmultilingual pretraining remains underexplored. We introduce PIXEL-M4, a model\npretrained on four visually and linguistically diverse languages: English,\nHindi, Ukrainian, and Simplified Chinese. Multilingual evaluations on semantic\nand syntactic tasks show that PIXEL-M4 outperforms an English-only counterpart\non non-Latin scripts. Word-level probing analyses confirm that PIXEL-M4\ncaptures rich linguistic features, even in languages not seen during\npretraining. Furthermore, an analysis of its hidden representations shows that\nmultilingual pretraining yields a semantic embedding space closely aligned\nacross the languages used for pretraining. This work demonstrates that\nmultilingual pretraining substantially enhances the capability of pixel\nlanguage models to effectively support a diverse set of languages.','Ilker Kesen, Jonas F. Lotz, Ingo Ziegler, Phillip Rust, Desmond Elliott','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21265v1'),('2505.21277v2','Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space','Large Language Models (LLMs), despite advanced general capabilities, still\nsuffer from numerous safety risks, especially jailbreak attacks that bypass\nsafety protocols. Understanding these vulnerabilities through black-box\njailbreak attacks, which better reflect real-world scenarios, offers critical\ninsights into model robustness. While existing methods have shown improvements\nthrough various prompt engineering techniques, their success remains limited\nagainst safety-aligned models, overlooking a more fundamental problem: the\neffectiveness is inherently bounded by the predefined strategy spaces. However,\nexpanding this space presents significant challenges in both systematically\ncapturing essential attack patterns and efficiently navigating the increased\ncomplexity. To better explore the potential of expanding the strategy space, we\naddress these challenges through a novel framework that decomposes jailbreak\nstrategies into essential components based on the Elaboration Likelihood Model\n(ELM) theory and develops genetic-based optimization with intention evaluation\nmechanisms. To be striking, our experiments reveal unprecedented jailbreak\ncapabilities by expanding the strategy space: we achieve over 90% success rate\non Claude-3.5 where prior methods completely fail, while demonstrating strong\ncross-model transferability and surpassing specialized safeguard models in\nevaluation accuracy. The code is open-sourced at:\nhttps://github.com/Aries-iai/CL-GSO.','Yao Huang, Yitong Sun, Shouwei Ruan, Yichi Zhang, Yinpeng Dong, Xingxing Wei','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.21277v2'),('2505.21279v1','XBOUND: Exploring the Capability Boundaries of Device-Control Agents through Trajectory Tree Exploration','Recent advancements in vision-language models (VLMs) have spurred increased\ninterest in Device-Control Agents (DC agents), such as utilizing in-the-wild\ndevice control to manage graphical user interfaces. Conventional methods for\nassessing the capabilities of DC agents, such as computing step-wise action\naccuracy and overall task success rates, provide a macroscopic view of DC\nagents\\\' performance; however, they fail to offer microscopic insights into\npotential errors that may occur in real-world applications. Conducting a\nfiner-grained performance evaluation of DC agents presents significant\nchallenges. This study introduces a new perspective on evaluation methods for\nDC agents by proposing the XBOUND evaluation method, which employs the\ncalculation of a novel Explore Metric to delineate the capability boundaries of\nDC agents. Compared to previous evaluation methods, XBOUND focuses on\nindividual states to assess the proficiency of DC agents in mastering these\nstates. Furthermore, we have developed a ``pseudo\\\'\\\' episode tree dataset\nderived from Android Control test data. Utilizing this dataset and XBOUND, we\ncomprehensively evaluate the OS-Atlas and UI-TARS series, examining both the\noverall and specific performance across five common tasks. Additionally, we\nselect representative cases to highlight the current deficiencies and\nlimitations inherent in both series. Code is available at\nhttps://github.com/sqzhang-lazy/XBOUND.','Shaoqing Zhang, Kehai Chen, Zhuosheng Zhang, Rumei Li, Rongxiang Weng, Yang Xiang, Liqiang Nie, Min Zhang','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21279v1'),('2505.21281v1','RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large Language Models','Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existing\nsemantic-enhanced LJP models integrate judicial precedents and legal knowledge\nfor high performance. But they neglect legal reasoning logic, a critical\ncomponent of legal judgments requiring rigorous logical analysis. Although some\napproaches utilize legal reasoning logic for high-quality predictions, their\nlogic rigidity hinders adaptation to case-specific logical frameworks,\nparticularly in complex cases that are lengthy and detailed. This paper\nproposes a rule-enhanced legal judgment prediction framework based on\nfirst-order logic (FOL) formalism and comparative learning (CL) to develop an\nadaptive adjustment mechanism for legal judgment logic and further enhance\nperformance in LJP. Inspired by the process of human exam preparation, our\nmethod follows a three-stage approach: first, we initialize judgment rules\nusing the FOL formalism to capture complex reasoning logic accurately; next, we\npropose a Confusion-aware Contrastive Learning (CACL) to dynamically optimize\nthe judgment rules through a quiz consisting of confusable cases; finally, we\nutilize the optimized judgment rules to predict legal judgments. Experimental\nresults on two public datasets show superior performance across all metrics.\nThe code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}.','Yue Zhang, Zhiliang Tian, Shicheng Zhou, Haiyang Wang, Wenqing Hou, Yuying Liu, Xuechen Zhao, Minlie Huang, Ye Wang, Bin Zhou','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21281v1'),('2505.21285v1','Learnable Kernel Density Estimation for Graphs','This work proposes a framework LGKDE that learns kernel density estimation\nfor graphs. The key challenge in graph density estimation lies in effectively\ncapturing both structural patterns and semantic variations while maintaining\ntheoretical guarantees. Combining graph kernels and kernel density estimation\n(KDE) is a standard approach to graph density estimation, but has\nunsatisfactory performance due to the handcrafted and fixed features of\nkernels. Our method LGKDE leverages graph neural networks to represent each\ngraph as a discrete distribution and utilizes maximum mean discrepancy to learn\nthe graph metric for multi-scale KDE, where all parameters are learned by\nmaximizing the density of graphs relative to the density of their well-designed\nperturbed counterparts. The perturbations are conducted on both node features\nand graph spectra, which helps better characterize the boundary of normal\ndensity regions. Theoretically, we establish consistency and convergence\nguarantees for LGKDE, including bounds on the mean integrated squared error,\nrobustness, and complexity. We validate LGKDE by demonstrating its\neffectiveness in recovering the underlying density of synthetic graph\ndistributions and applying it to graph anomaly detection across diverse\nbenchmark datasets. Extensive empirical evaluation shows that LGKDE\ndemonstrates superior performance compared to state-of-the-art baselines on\nmost benchmark datasets.','Xudong Wang, Ziheng Sun, Chris Ding, Jicong Fan','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21285v1'),('2505.21288v1','GSAT: Graph Structure Attention Networks','Graph Neural Networks (GNNs) have emerged as a powerful tool for processing\ndata represented in graph structures, achieving remarkable success across a\nwide range of applications. However, to further improve the performance on\ngraph classification benchmarks, structural representation of each node that\nencodes rich local topological information in the neighbourhood of nodes is an\nimportant type of feature that is often overlooked in the modeling. The\nconsequence of neglecting the structural information has resulted high number\nof layers to connect messages from distant nodes which by itself produces other\nproblems such as oversmoothing. In the present paper, we leverage these\nstructural information that are modeled by anonymous random walks (ARWs) and\nintroduce graph structure attention network (GSAT) which is a generalization of\ngraph attention network(GAT) to integrate the original attribute and the\nstructural representation to enforce the model to automatically find patterns\nfor attending to different edges in the node neighbourhood to enrich graph\nrepresentation. Our experiments show GSAT slightly improves SOTA on some graph\nclassification benchmarks.','Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21288v1'),('2505.21289v1','LoFT: Low-Rank Adaptation That Behaves Like Full Fine-Tuning','Large pre-trained models are commonly adapted to downstream tasks using\nparameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA),\nwhich injects small trainable low-rank matrices instead of updating all\nweights. While LoRA dramatically reduces trainable parameters with little\noverhead, it can still underperform full fine-tuning in accuracy and often\nconverges more slowly. We introduce LoFT, a novel low-rank adaptation method\nthat behaves like full fine-tuning by aligning the optimizer\\\'s internal\ndynamics with those of updating all model weights. LoFT not only learns weight\nupdates in a low-rank subspace (like LoRA) but also properly projects the\noptimizer\\\'s first and second moments (Adam\\\'s momentum and variance) into the\nsame subspace, mirroring full-model updates. By aligning the low-rank update\nitself with the full update, LoFT eliminates the need for tuning extra\nhyperparameters, e.g., LoRA scaling factor $\\alpha$. Empirically, this approach\nsubstantially narrows the performance gap between adapter-based tuning and full\nfine-tuning and consistently outperforms standard LoRA-style methods, all\nwithout increasing inference cost.','Nurbek Tastan, Stefanos Laskaridis, Martin Takac, Karthik Nandakumar, Samuel Horvath','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21289v1'),('2505.21291v1','Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework','In this paper, we present a novel diagnostic framework that integrates\nKnowledge Graphs (KGs) and Large Language Models (LLMs) to support system\ndiagnostics in high-reliability systems such as nuclear power plants.\nTraditional diagnostic modeling struggles when systems become too complex,\nmaking functional modeling a more attractive approach. Our approach introduces\na diagnostic framework grounded in the functional modeling principles of the\nDynamic Master Logic (DML) model. It incorporates two coordinated LLM\ncomponents, including an LLM-based workflow for automated construction of DML\nlogic from system documentation and an LLM agent that facilitates interactive\ndiagnostics. The generated logic is encoded into a structured KG, referred to\nas KG-DML, which supports hierarchical fault reasoning. Expert knowledge or\noperational data can also be incorporated to refine the model\\\'s precision and\ndiagnostic depth. In the interaction phase, users submit natural language\nqueries, which are interpreted by the LLM agent. The agent selects appropriate\ntools for structured reasoning, including upward and downward propagation\nacross the KG-DML. Rather than embedding KG content into every prompt, the LLM\nagent distinguishes between diagnostic and interpretive tasks. For diagnostics,\nthe agent selects and executes external tools that perform structured KG\nreasoning. For general queries, a Graph-based Retrieval-Augmented Generation\n(Graph-RAG) approach is used, retrieving relevant KG segments and embedding\nthem into the prompt to generate natural explanations. A case study on an\nauxiliary feedwater system demonstrated the framework\\\'s effectiveness, with\nover 90% accuracy in key elements and consistent tool and argument extraction,\nsupporting its use in safety-critical diagnostics.','Saman Marandi, Yu-Shu Hu, Mohammad Modarres','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21291v1'),('2505.21297v1','rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset','Advancing code reasoning in large language models (LLMs) is fundamentally\nlimited by the scarcity of high-difficulty datasets, especially those with\nverifiable input-output test cases necessary for rigorous solution validation\nat scale. We introduce rStar-Coder, which significantly improves LLM code\nreasoning capabilities by constructing a large-scale, verified dataset of 418K\ncompetition-level code problems, 580K long-reasoning solutions along with rich\ntest cases of varying difficulty. This is achieved through three core\ncontributions: (1) we curate competitive programming code problems and oracle\nsolutions to synthesize new, solvable problems; (2) we introduce a reliable\ninput-output test case synthesis pipeline that decouples the generation into a\nthree-step input generation method and a mutual verification mechanism for\neffective output labeling; (3) we augment problems with high-quality,\ntest-case-verified long-reasoning solutions. Extensive experiments on Qwen\nmodels (1.5B-14B) across various code reasoning benchmarks demonstrate the\nsuperiority of rStar-Coder dataset, achieving leading performance comparable to\nfrontier reasoning LLMs with much smaller model sizes. On LiveCodeBench,\nrStar-Coder improves Qwen2.5-7B from 17.4% to an impressive 57.3%, and\nQwen2.5-14B from 23.3% to 62.5%, surpassing o3-mini (low) by3.1%. On the more\nchallenging USA Computing Olympiad, our 7B model achieves an average pass@1\naccuracy of 16.15%, outperforming the frontier-level QWQ-32B. Code and the\ndataset will be released at https://github.com/microsoft/rStar.','Yifei Liu, Li Lyna Zhang, Yi Zhu, Bingcheng Dong, Xudong Zhou, Ning Shang, Fan Yang, Mao Yang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21297v1'),('2505.21298v1','Large Language Models Miss the Multi-Agent Mark','Recent interest in Multi-Agent Systems of Large Language Models (MAS LLMs)\nhas led to an increase in frameworks leveraging multiple LLMs to tackle complex\ntasks. However, much of this literature appropriates the terminology of MAS\nwithout engaging with its foundational principles. In this position paper, we\nhighlight critical discrepancies between MAS theory and current MAS LLMs\nimplementations, focusing on four key areas: the social aspect of agency,\nenvironment design, coordination and communication protocols, and measuring\nemergent behaviours. Our position is that many MAS LLMs lack multi-agent\ncharacteristics such as autonomy, social interaction, and structured\nenvironments, and often rely on oversimplified, LLM-centric architectures. The\nfield may slow down and lose traction by revisiting problems the MAS literature\nhas already addressed. Therefore, we systematically analyse this issue and\noutline associated research opportunities; we advocate for better integrating\nestablished MAS concepts and more precise terminology to avoid\nmischaracterisation and missed opportunities.','Emanuele La Malfa, Gabriele La Malfa, Samuele Marro, Jie M. Zhang, Elizabeth Black, Micheal Luck, Philip Torr, Michael Wooldridge','2025-05-27','cs.MA','http://arxiv.org/pdf/2505.21298v1'),('2505.21301v1','How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian','People can categorize the same entity at multiple taxonomic levels, such as\nbasic (bear), superordinate (animal), and subordinate (grizzly bear). While\nprior research has focused on basic-level categories, this study is the first\nattempt to examine the organization of categories by analyzing exemplars\nproduced at the subordinate level. We present a new Italian psycholinguistic\ndataset of human-generated exemplars for 187 concrete words. We then use these\ndata to evaluate whether textual and vision LLMs produce meaningful exemplars\nthat align with human category organization across three key tasks: exemplar\ngeneration, category induction, and typicality judgment. Our findings show a\nlow alignment between humans and LLMs, consistent with previous studies.\nHowever, their performance varies notably across different semantic domains.\nUltimately, this study highlights both the promises and the constraints of\nusing AI-generated exemplars to support psychological and linguistic research.','Andrea Pedrotti, Giulia Rambelli, Caterina Villani, Marianna Bolognesi','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21301v1'),('2505.21304v1','Optimizing fMRI Data Acquisition for Decoding Natural Speech with Limited Participants','We investigate optimal strategies for decoding perceived natural speech from\nfMRI data acquired from a limited number of participants. Leveraging Lebel et\nal. (2023)\\\'s dataset of 8 participants, we first demonstrate the effectiveness\nof training deep neural networks to predict LLM-derived text representations\nfrom fMRI activity. Then, in this data regime, we observe that multi-subject\ntraining does not improve decoding accuracy compared to single-subject\napproach. Furthermore, training on similar or different stimuli across subjects\nhas a negligible effect on decoding accuracy. Finally, we find that our\ndecoders better model syntactic than semantic features, and that stories\ncontaining sentences with complex syntax or rich semantic content are more\nchallenging to decode. While our results demonstrate the benefits of having\nextensive data per participant (deep phenotyping), they suggest that leveraging\nmulti-subject for natural speech decoding likely requires deeper phenotyping or\na substantially larger cohort.','Louis Jalouzot, Alexis Thual, Yair Lakretz, Christophe Pallier, Bertrand Thirion','2025-05-27','q-bio.NC','http://arxiv.org/pdf/2505.21304v1'),('2505.21315v2','Charting the Landscape of African NLP: Mapping Progress and Shaping the Road Ahead','With over 2,000 languages and potentially millions of speakers, Africa\nrepresents one of the richest linguistic regions in the world. Yet, this\ndiversity is scarcely reflected in state-of-the-art natural language processing\n(NLP) systems and large language models (LLMs), which predominantly support a\nnarrow set of high-resource languages. This exclusion not only limits the reach\nand utility of modern NLP technologies but also risks widening the digital\ndivide across linguistic communities. Nevertheless, NLP research on African\nlanguages is active and growing. In recent years, there has been a surge of\ninterest in this area, driven by several factors-including the creation of\nmultilingual language resources, the rise of community-led initiatives, and\nincreased support through funding programs. In this survey, we analyze 734\nresearch papers on NLP for African languages published over the past five\nyears, offering a comprehensive overview of recent progress across core tasks.\nWe identify key trends shaping the field and conclude by outlining promising\ndirections to foster more inclusive and sustainable NLP research for African\nlanguages.','Jesujoba O. Alabi, Michael A. Hedderich, David Ifeoluwa Adelani, Dietrich Klakow','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21315v2'),('2505.21317v1','A Cross Modal Knowledge Distillation & Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features','Understanding cellular responses to stimuli is crucial for biological\ndiscovery and drug development. Transcriptomics provides interpretable,\ngene-level insights, while microscopy imaging offers rich predictive features\nbut is harder to interpret. Weakly paired datasets, where samples share\nbiological states, enable multimodal learning but are scarce, limiting their\nutility for training and multimodal inference. We propose a framework to\nenhance transcriptomics by distilling knowledge from microscopy images. Using\nweakly paired data, our method aligns and binds modalities, enriching gene\nexpression representations with morphological information. To address data\nscarcity, we introduce (1) Semi-Clipped, an adaptation of CLIP for cross-modal\ndistillation using pretrained foundation models, achieving state-of-the-art\nresults, and (2) PEA (Perturbation Embedding Augmentation), a novel\naugmentation technique that enhances transcriptomics data while preserving\ninherent biological information. These strategies improve the predictive power\nand retain the interpretability of transcriptomics, enabling rich unimodal\nrepresentations for complex biological tasks.','Ihab Bendidi, Yassir El Mesbahi, Alisandra K. Denton, Karush Suri, Kian Kenyon-Dean, Auguste Genovesio, Emmanuel Noutahi','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21317v1'),('2505.21318v1','Beyond Chemical QA: Evaluating LLM\\\'s Chemical Reasoning with Modular Chemical Operations','While large language models (LLMs) with Chain-of-Thought (CoT) reasoning\nexcel in mathematics and coding, their potential for systematic reasoning in\nchemistry, a domain demanding rigorous structural analysis for real-world tasks\nlike drug design and reaction engineering, remains untapped. Current benchmarks\nfocus on simple knowledge retrieval, neglecting step-by-step reasoning required\nfor complex tasks such as molecular optimization and reaction prediction. To\naddress this, we introduce ChemCoTBench, a reasoning framework that bridges\nmolecular structure understanding with arithmetic-inspired operations,\nincluding addition, deletion, and substitution, to formalize chemical\nproblem-solving into transparent, step-by-step workflows. By treating molecular\ntransformations as modular \"chemical operations\", the framework enables\nslow-thinking reasoning, mirroring the logic of mathematical proofs while\ngrounding solutions in real-world chemical constraints. We evaluate models on\ntwo high-impact tasks: Molecular Property Optimization and Chemical Reaction\nPrediction. These tasks mirror real-world challenges while providing structured\nevaluability. By providing annotated datasets, a reasoning taxonomy, and\nbaseline evaluations, ChemCoTBench bridges the gap between abstract reasoning\nmethods and practical chemical discovery, establishing a foundation for\nadvancing LLMs as tools for AI-driven scientific innovation.','Hao Li, He Cao, Bin Feng, Yanjun Shao, Xiangru Tang, Zhiyuan Yan, Li Yuan, Yonghong Tian, Yu Li','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21318v1'),('2505.21321v1','Bencher: Simple and Reproducible Benchmarking for Black-Box Optimization','We present Bencher, a modular benchmarking framework for black-box\noptimization that fundamentally decouples benchmark execution from optimization\nlogic. Unlike prior suites that focus on combining many benchmarks in a single\nproject, Bencher introduces a clean abstraction boundary: each benchmark is\nisolated in its own virtual Python environment and accessed via a unified,\nversion-agnostic remote procedure call (RPC) interface. This design eliminates\ndependency conflicts and simplifies the integration of diverse, real-world\nbenchmarks, which often have complex and conflicting software requirements.\nBencher can be deployed locally or remotely via Docker or on high-performance\ncomputing (HPC) clusters via Singularity, providing a containerized,\nreproducible runtime for any benchmark. Its lightweight client requires minimal\nsetup and supports drop-in evaluation of 80 benchmarks across continuous,\ncategorical, and binary domains.','Leonard Papenmeier, Luigi Nardi','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21321v1'),('2505.21322v1','Assured Autonomy with Neuro-Symbolic Perception','Many state-of-the-art AI models deployed in cyber-physical systems (CPS),\nwhile highly accurate, are simply pattern-matchers.~With limited security\nguarantees, there are concerns for their reliability in safety-critical and\ncontested domains. To advance assured AI, we advocate for a paradigm shift that\nimbues data-driven perception models with symbolic structure, inspired by a\nhuman\\\'s ability to reason over low-level features and high-level context. We\npropose a neuro-symbolic paradigm for perception (NeuSPaPer) and illustrate how\njoint object detection and scene graph generation (SGG) yields deep scene\nunderstanding.~Powered by foundation models for offline knowledge extraction\nand specialized SGG algorithms for real-time deployment, we design a framework\nleveraging structured relational graphs that ensures the integrity of\nsituational awareness in autonomy. Using physics-based simulators and\nreal-world datasets, we demonstrate how SGG bridges the gap between low-level\nsensor perception and high-level reasoning, establishing a foundation for\nresilient, context-aware AI and advancing trusted autonomy in CPS.','R. Spencer Hallyburton, Miroslav Pajic','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21322v1'),('2505.21324v1','Leveraging large language models and traditional machine learning ensembles for ADHD detection from narrative transcripts','Despite rapid advances in large language models (LLMs), their integration\nwith traditional supervised machine learning (ML) techniques that have proven\napplicability to medical data remains underexplored. This is particularly true\nfor psychiatric applications, where narrative data often exhibit nuanced\nlinguistic and contextual complexity, and can benefit from the combination of\nmultiple models with differing characteristics. In this study, we introduce an\nensemble framework for automatically classifying\nAttention-Deficit/Hyperactivity Disorder (ADHD) diagnosis (binary) using\nnarrative transcripts. Our approach integrates three complementary models:\nLLaMA3, an open-source LLM that captures long-range semantic structure;\nRoBERTa, a pre-trained transformer model fine-tuned on labeled clinical\nnarratives; and a Support Vector Machine (SVM) classifier trained using\nTF-IDF-based lexical features. These models are aggregated through a majority\nvoting mechanism to enhance predictive robustness. The dataset includes 441\ninstances, including 352 for training and 89 for validation. Empirical results\nshow that the ensemble outperforms individual models, achieving an F$_1$ score\nof 0.71 (95\\% CI: [0.60-0.80]). Compared to the best-performing individual\nmodel (SVM), the ensemble improved recall while maintaining competitive\nprecision. This indicates the strong sensitivity of the ensemble in identifying\nADHD-related linguistic cues. These findings demonstrate the promise of hybrid\narchitectures that leverage the semantic richness of LLMs alongside the\ninterpretability and pattern recognition capabilities of traditional supervised\nML, offering a new direction for robust and generalizable psychiatric text\nclassification.','Yuxin Zhu, Yuting Guo, Noah Marchuck, Abeed Sarker, Yun Wang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21324v1'),('2505.21327v1','MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs','Logical reasoning is a fundamental aspect of human intelligence and an\nessential capability for multimodal large language models (MLLMs). Despite the\nsignificant advancement in multimodal reasoning, existing benchmarks fail to\ncomprehensively evaluate their reasoning abilities due to the lack of explicit\ncategorization for logical reasoning types and an unclear understanding of\nreasoning. To address these issues, we introduce MME-Reasoning, a comprehensive\nbenchmark designed to evaluate the reasoning ability of MLLMs, which covers all\nthree types of reasoning (i.e., inductive, deductive, and abductive) in its\nquestions. We carefully curate the data to ensure that each question\neffectively evaluates reasoning ability rather than perceptual skills or\nknowledge breadth, and extend the evaluation protocols to cover the evaluation\nof diverse questions. Our evaluation reveals substantial limitations of\nstate-of-the-art MLLMs when subjected to holistic assessments of logical\nreasoning capabilities. Even the most advanced MLLMs show limited performance\nin comprehensive logical reasoning, with notable performance imbalances across\nreasoning types. In addition, we conducted an in-depth analysis of approaches\nsuch as ``thinking mode\\\'\\\' and Rule-based RL, which are commonly believed to\nenhance reasoning abilities. These findings highlight the critical limitations\nand performance imbalances of current MLLMs in diverse logical reasoning\nscenarios, providing comprehensive and systematic insights into the\nunderstanding and evaluation of reasoning capabilities.','Jiakang Yuan, Tianshuo Peng, Yilei Jiang, Yiting Lu, Renrui Zhang, Kaituo Feng, Chaoyou Fu, Tao Chen, Lei Bai, Bo Zhang, Xiangyu Yue','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21327v1'),('2505.21329v2','Something\\\'s Fishy In The Data Lake: A Critical Re-evaluation of Table Union Search Benchmarks','Recent table representation learning and data discovery methods tackle table\nunion search (TUS) within data lakes, which involves identifying tables that\ncan be unioned with a given query table to enrich its content. These methods\nare commonly evaluated using benchmarks that aim to assess semantic\nunderstanding in real-world TUS tasks. However, our analysis of prominent TUS\nbenchmarks reveals several limitations that allow simple baselines to perform\nsurprisingly well, often outperforming more sophisticated approaches. This\nsuggests that current benchmark scores are heavily influenced by\ndataset-specific characteristics and fail to effectively isolate the gains from\nsemantic understanding. To address this, we propose essential criteria for\nfuture benchmarks to enable a more realistic and reliable evaluation of\nprogress in semantic table union search.','Allaa Boutaleb, Bernd Amann, Hubert Naacke, Rafael Angarita','2025-05-27','cs.IR','http://arxiv.org/pdf/2505.21329v2'),('2505.21330v1','UGCE: User-Guided Incremental Counterfactual Exploration','Counterfactual explanations (CFEs) are a popular approach for interpreting\nmachine learning predictions by identifying minimal feature changes that alter\nmodel outputs. However, in real-world settings, users often refine feasibility\nconstraints over time, requiring counterfactual generation to adapt\ndynamically. Existing methods fail to support such iterative updates, instead\nrecomputing explanations from scratch with each change, an inefficient and\nrigid approach. We propose User-Guided Incremental Counterfactual Exploration\n(UGCE), a genetic algorithm-based framework that incrementally updates\ncounterfactuals in response to evolving user constraints. Experimental results\nacross five benchmark datasets demonstrate that UGCE significantly improves\ncomputational efficiency while maintaining high-quality solutions compared to a\nstatic, non-incremental approach. Our evaluation further shows that UGCE\nsupports stable performance under varying constraint sequences, benefits from\nan efficient warm-start strategy, and reveals how different constraint types\nmay affect search behavior.','Christos Fragkathoulas, Evaggelia Pitoura','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21330v1'),('2505.21331v1','Scheduling with Uncertain Holding Costs and its Application to Content Moderation','In content moderation for social media platforms, the cost of delaying the\nreview of a content is proportional to its view trajectory, which fluctuates\nand is apriori unknown. Motivated by such uncertain holding costs, we consider\na queueing model where job states evolve based on a Markov chain with\nstate-dependent instantaneous holding costs. We demonstrate that in the\npresence of such uncertain holding costs, the two canonical algorithmic\nprinciples, instantaneous-cost ($c\\mu$-rule) and expected-remaining-cost\n($c\\mu/\\theta$-rule), are suboptimal. By viewing each job as a Markovian\nski-rental problem, we develop a new index-based algorithm,\nOpportunity-adjusted Remaining Cost (OaRC), that adjusts to the opportunity of\nserving jobs in the future when uncertainty partly resolves. We show that the\nregret of OaRC scales as $\\tilde{O}(L^{1.5}\\sqrt{N})$, where $L$ is the maximum\nlength of a job\\\'s holding cost trajectory and $N$ is the system size. This\nregret bound shows that OaRC achieves asymptotic optimality when the system\nsize $N$ scales to infinity. Moreover, its regret is independent of the\nstate-space size, which is a desirable property when job states contain\ncontextual information. We corroborate our results with an extensive simulation\nstudy based on two holding cost patterns (online ads and user-generated\ncontent) that arise in content moderation for social media platforms. Our\nsimulations based on synthetic and real datasets demonstrate that OaRC\nconsistently outperforms existing practice, which is based on the two canonical\nalgorithmic principles.','Caner Gocmen, Thodoris Lykouris, Deeksha Sinha, Wentao Weng','2025-05-27','cs.DS','http://arxiv.org/pdf/2505.21331v1'),('2505.21335v1','Structure from Collision','Recent advancements in neural 3D representations, such as neural radiance\nfields (NeRF) and 3D Gaussian splatting (3DGS), have enabled the accurate\nestimation of 3D structures from multiview images. However, this capability is\nlimited to estimating the visible external structure, and identifying the\ninvisible internal structure hidden behind the surface is difficult. To\novercome this limitation, we address a new task called Structure from Collision\n(SfC), which aims to estimate the structure (including the invisible internal\nstructure) of an object from appearance changes during collision. To solve this\nproblem, we propose a novel model called SfC-NeRF that optimizes the invisible\ninternal structure of an object through a video sequence under physical,\nappearance (i.e., visible external structure)-preserving, and keyframe\nconstraints. In particular, to avoid falling into undesirable local optima\nowing to its ill-posed nature, we propose volume annealing; that is, searching\nfor global optima by repeatedly reducing and expanding the volume. Extensive\nexperiments on 115 objects involving diverse structures (i.e., various cavity\nshapes, locations, and sizes) and material properties revealed the properties\nof SfC and demonstrated the effectiveness of the proposed SfC-NeRF.','Takuhiro Kaneko','2025-05-27','cs.GR','http://arxiv.org/pdf/2505.21335v1'),('2505.21336v1','Joint Learning in the Gaussian Single Index Model','We consider the problem of jointly learning a one-dimensional projection and\na univariate function in high-dimensional Gaussian models. Specifically, we\nstudy predictors of the form $f(x)=\\varphi^\\star(\\langle w^\\star, x \\rangle)$,\nwhere both the direction $w^\\star \\in \\mathcal{S}_{d-1}$, the sphere of\n$\\mathbb{R}^d$, and the function $\\varphi^\\star: \\mathbb{R} \\to \\mathbb{R}$ are\nlearned from Gaussian data. This setting captures a fundamental non-convex\nproblem at the intersection of representation learning and nonlinear\nregression. We analyze the gradient flow dynamics of a natural alternating\nscheme and prove convergence, with a rate controlled by the information\nexponent reflecting the \\textit{Gaussian regularity} of the function\n$\\varphi^\\star$. Strikingly, our analysis shows that convergence still occurs\neven when the initial direction is negatively correlated with the target. On\nthe practical side, we demonstrate that such joint learning can be effectively\nimplemented using a Reproducing Kernel Hilbert Space (RKHS) adapted to the\nstructure of the problem, enabling efficient and flexible estimation of the\nunivariate function. Our results offer both theoretical insight and practical\nmethodology for learning low-dimensional structure in high-dimensional\nsettings.','Loucas Pillaud-Vivien, Adrien Schertzer','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21336v1'),('2505.21339v1','An Uncertainty-Aware ED-LSTM for Probabilistic Suffix Prediction','Suffix prediction of business processes forecasts the remaining sequence of\nevents until process completion. Current approaches focus on predicting a\nsingle, most likely suffix. However, if the future course of a process is\nexposed to uncertainty or has high variability, the expressiveness of a single\nsuffix prediction can be limited. To address this limitation, we propose\nprobabilistic suffix prediction, a novel approach that approximates a\nprobability distribution of suffixes. The proposed approach is based on an\nUncertainty-Aware Encoder-Decoder LSTM (U-ED-LSTM) and a Monte Carlo (MC)\nsuffix sampling algorithm. We capture epistemic uncertainties via MC dropout\nand aleatoric uncertainties as learned loss attenuation. This technical report\nprovides a detailed evaluation of the U-ED-LSTM\\\'s predictive performance and\nassesses its calibration on four real-life event logs with three different\nhyperparameter settings. The results show that i) the U-ED-LSTM has reasonable\npredictive performance across various datasets, ii) aggregating probabilistic\nsuffix predictions into mean values can outperform most likely predictions,\nparticularly for rare prefixes or longer suffixes, and iii) the approach\neffectively captures uncertainties present in event logs.','Henryk Mustroph, Michel Kunkler, Stefanie Rinderle-Ma','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21339v1'),('2505.21342v2','PEDANTIC: A Dataset for the Automatic Examination of Definiteness in Patent Claims','Patent claims define the scope of protection for an invention. If there are\nambiguities in a claim, it is rejected by the patent office. In the US, this is\nreferred to as indefiniteness (35 U.S.C {\\S} 112(b)) and is among the most\nfrequent reasons for patent application rejection. The development of automatic\nmethods for patent definiteness examination has the potential to make patent\ndrafting and examination more efficient, but no annotated dataset has been\npublished to date. We introduce PEDANTIC (Patent Definiteness Examination\nCorpus), a novel dataset of 14k US patent claims from patent applications\nrelating to Natural Language Processing (NLP), annotated with reasons for\nindefiniteness. We construct PEDANTIC using a fully automatic pipeline that\nretrieves office action documents from the USPTO and uses Large Language Models\n(LLMs) to extract the reasons for indefiniteness. A human validation study\nconfirms the pipeline\\\'s accuracy in generating high-quality annotations. To\ngain insight beyond binary classification metrics, we implement an LLM-as-Judge\nevaluation that compares the free-form reasoning of every model-cited reason\nwith every examiner-cited reason. We show that LLM agents based on Qwen 2.5 32B\nand 72B struggle to outperform logistic regression baselines on definiteness\nprediction, even though they often correctly identify the underlying reasons.\nPEDANTIC provides a valuable resource for patent AI researchers, enabling the\ndevelopment of advanced examination models. We will publicly release the\ndataset and code.','Valentin Knappich, Annemarie Friedrich, Anna Hätty, Simon Razniewski','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21342v2'),('2505.21344v1','The Multilingual Divide and Its Impact on Global AI Safety','Despite advances in large language model capabilities in recent years, a\nlarge gap remains in their capabilities and safety performance for many\nlanguages beyond a relatively small handful of globally dominant languages.\nThis paper provides researchers, policymakers and governance experts with an\noverview of key challenges to bridging the \"language gap\" in AI and minimizing\nsafety risks across languages. We provide an analysis of why the language gap\nin AI exists and grows, and how it creates disparities in global AI safety. We\nidentify barriers to address these challenges, and recommend how those working\nin policy and governance can help address safety concerns associated with the\nlanguage gap by supporting multilingual dataset creation, transparency, and\nresearch.','Aidan Peppin, Julia Kreutzer, Alice Schoenauer Sebag, Kelly Marchisio, Beyza Ermis, John Dang, Samuel Cahyawijaya, Shivalika Singh, Seraphina Goldfarb-Tarrant, Viraat Aryabumi, Aakanksha, Wei-Yin Ko, Ahmet Üstün, Matthias Gallé, Marzieh Fadaee, Sara Hooker','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21344v1'),('2505.21347v2','OVERT: A Benchmark for Over-Refusal Evaluation on Text-to-Image Models','Text-to-Image (T2I) models have achieved remarkable success in generating\nvisual content from text inputs. Although multiple safety alignment strategies\nhave been proposed to prevent harmful outputs, they often lead to overly\ncautious behavior -- rejecting even benign prompts -- a phenomenon known as\n$\\textit{over-refusal}$ that reduces the practical utility of T2I models.\nDespite over-refusal having been observed in practice, there is no large-scale\nbenchmark that systematically evaluates this phenomenon for T2I models. In this\npaper, we present an automatic workflow to construct synthetic evaluation data,\nresulting in OVERT ($\\textbf{OVE}$r-$\\textbf{R}$efusal evaluation on\n$\\textbf{T}$ext-to-image models), the first large-scale benchmark for assessing\nover-refusal behaviors in T2I models. OVERT includes 4,600 seemingly harmful\nbut benign prompts across nine safety-related categories, along with 1,785\ngenuinely harmful prompts (OVERT-unsafe) to evaluate the safety-utility\ntrade-off. Using OVERT, we evaluate several leading T2I models and find that\nover-refusal is a widespread issue across various categories (Figure 1),\nunderscoring the need for further research to enhance the safety alignment of\nT2I models without compromising their functionality. As a preliminary attempt\nto reduce over-refusal, we explore prompt rewriting; however, we find it often\ncompromises faithfulness to the meaning of the original prompts. Finally, we\ndemonstrate the flexibility of our generation framework in accommodating\ndiverse safety requirements by generating customized evaluation data adapting\nto user-defined policies.','Ziheng Cheng, Yixiao Huang, Hui Xu, Somayeh Sojoudi, Xuandong Zhao, Dawn Song, Song Mei','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21347v2'),('2505.21354v1','Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning','Solving Bengali Math Word Problems (MWPs) remains a major challenge in\nnatural language processing (NLP) due to the language\\\'s low-resource status and\nthe multi-step reasoning required. Existing models struggle with complex\nBengali MWPs, largely because no human-annotated Bengali dataset has previously\naddressed this task. This gap has limited progress in Bengali mathematical\nreasoning. To address this, we created SOMADHAN, a dataset of 8792 complex\nBengali MWPs with manually written, step-by-step solutions. We designed this\ndataset to support reasoning-focused evaluation and model development in a\nlinguistically underrepresented context. Using SOMADHAN, we evaluated a range\nof large language models (LLMs) - including GPT-4o, GPT-3.5 Turbo, LLaMA series\nmodels, Deepseek, and Qwen - through both zero-shot and few-shot prompting with\nand without Chain of Thought (CoT) reasoning. CoT prompting consistently\nimproved performance over standard prompting, especially in tasks requiring\nmulti-step logic. LLaMA-3.3 70B achieved the highest accuracy of 88% with\nfew-shot CoT prompting. We also applied Low-Rank Adaptation (LoRA) to fine-tune\nmodels efficiently, enabling them to adapt to Bengali MWPs with minimal\ncomputational cost. Our work fills a critical gap in Bengali NLP by providing a\nhigh-quality reasoning dataset and a scalable framework for solving complex\nMWPs. We aim to advance equitable research in low-resource languages and\nenhance reasoning capabilities in educational and language technologies.','Bidyarthi Paul, Jalisha Jashim Era, Mirazur Rahman Zim, Tahmid Sattar Aothoi, Faisal Muhammad Shah','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21354v1'),('2505.21355v1','Prostate Cancer Screening with Artificial Intelligence-Enhanced Micro-Ultrasound: A Comparative Study with Traditional Methods','Background and objective: Micro-ultrasound (micro-US) is a novel imaging\nmodality with diagnostic accuracy comparable to MRI for detecting clinically\nsignificant prostate cancer (csPCa). We investigated whether artificial\nintelligence (AI) interpretation of micro-US can outperform clinical screening\nmethods using PSA and digital rectal examination (DRE). Methods: We\nretrospectively studied 145 men who underwent micro-US guided biopsy (79 with\ncsPCa, 66 without). A self-supervised convolutional autoencoder was used to\nextract deep image features from 2D micro-US slices. Random forest classifiers\nwere trained using five-fold cross-validation to predict csPCa at the slice\nlevel. Patients were classified as csPCa-positive if 88 or more consecutive\nslices were predicted positive. Model performance was compared with a\nclassifier using PSA, DRE, prostate volume, and age. Key findings and\nlimitations: The AI-based micro-US model and clinical screening model achieved\nAUROCs of 0.871 and 0.753, respectively. At a fixed threshold, the micro-US\nmodel achieved 92.5% sensitivity and 68.1% specificity, while the clinical\nmodel showed 96.2% sensitivity but only 27.3% specificity. Limitations include\na retrospective single-center design and lack of external validation.\nConclusions and clinical implications: AI-interpreted micro-US improves\nspecificity while maintaining high sensitivity for csPCa detection. This method\nmay reduce unnecessary biopsies and serve as a low-cost alternative to\nPSA-based screening. Patient summary: We developed an AI system to analyze\nprostate micro-ultrasound images. It outperformed PSA and DRE in detecting\naggressive cancer and may help avoid unnecessary biopsies.','Muhammad Imran, Wayne G. Brisbane, Li-Ming Su, Jason P. Joseph, Wei Shao','2025-05-27','eess.IV','http://arxiv.org/pdf/2505.21355v1'),('2505.21356v2','Towards Robust Automated Perceptual Voice Quality Assessment with Speech Foundation Models','Perceptual voice quality assessment is essential for diagnosing and\nmonitoring voice disorders. Traditionally, expert raters use scales such as the\nCAPE-V and GRBAS. However, these are subjective and prone to inter-rater\nvariability, motivating the need for automated, objective assessment methods.\nThis study proposes VOQANet, a deep learning framework with an attention\nmechanism that leverages a Speech Foundation Model (SFM) to extract high-level\nacoustic and prosodic information from raw speech. To improve robustness and\ninterpretability, we introduce VOQANet+, which integrates handcrafted acoustic\nfeatures such as jitter, shimmer, and harmonics-to-noise ratio (HNR) with SFM\nembeddings into a hybrid representation. Unlike prior work focusing only on\nvowel-based phonation (PVQD-A subset) from the Perceptual Voice Quality Dataset\n(PVQD), we evaluate our models on both vowel-based and sentence-level speech\n(PVQD-S subset) for better generalizability. Results show that sentence-based\ninput outperforms vowel-based input, particularly at the patient level,\nhighlighting the benefit of longer utterances for capturing voice attributes.\nVOQANet consistently surpasses baseline methods in root mean squared error and\nPearson correlation across CAPE-V and GRBAS dimensions, with VOQANet+ achieving\nfurther improvements. Additional tests under noisy conditions show that\nVOQANet+ maintains high prediction accuracy, supporting its use in real-world\nand telehealth settings. These findings demonstrate the value of combining SFM\nembeddings with domain-informed acoustic features for interpretable and robust\nvoice quality assessment.','Whenty Ariyanti, Kuan-Yu Chen, Sabato Marco Siniscalchi, Hsin-Min Wang, Yu Tsao','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.21356v2'),('2505.21357v2','AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop Mapping','Accurate crop mapping fundamentally relies on modeling multi-scale\nspatiotemporal patterns, where spatial scales range from individual field\ntextures to landscape-level context, and temporal scales capture both\nshort-term phenological transitions and full growing-season dynamics.\nTransformer-based remote sensing foundation models (RSFMs) offer promising\npotential for crop mapping due to their innate ability for unified\nspatiotemporal processing. However, current RSFMs remain suboptimal for crop\nmapping: they either employ fixed spatiotemporal windows that ignore the\nmulti-scale nature of crop systems or completely disregard temporal information\nby focusing solely on spatial patterns. To bridge these gaps, we present\nAgriFM, a multi-source remote sensing foundation model specifically designed\nfor agricultural crop mapping. Our approach begins by establishing the\nnecessity of simultaneous hierarchical spatiotemporal feature extraction,\nleading to the development of a modified Video Swin Transformer architecture\nwhere temporal down-sampling is synchronized with spatial scaling operations.\nThis modified backbone enables efficient unified processing of long time-series\nsatellite inputs. AgriFM leverages temporally rich data streams from three\nsatellite sources including MODIS, Landsat-8/9 and Sentinel-2, and is\npre-trained on a global representative dataset comprising over 25 million image\nsamples supervised by land cover products. The resulting framework incorporates\na versatile decoder architecture that dynamically fuses these learned\nspatiotemporal representations, supporting diverse downstream tasks.\nComprehensive evaluations demonstrate AgriFM\\\'s superior performance over\nconventional deep learning approaches and state-of-the-art general-purpose\nRSFMs across all downstream tasks. Codes will be available at\nhttps://github.com/flyakon/AgriFM.','Wenyuan Li, Shunlin Liang, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan, Husheng Fang, Zhenwei Shi','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21357v2'),('2505.21360v1','CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models','Competing risks are crucial considerations in survival modelling,\nparticularly in healthcare domains where patients may experience multiple\ndistinct event types. We propose CRISP-NAM (Competing Risks Interpretable\nSurvival Prediction with Neural Additive Models), an interpretable neural\nadditive model for competing risks survival analysis which extends the neural\nadditive architecture to model cause-specific hazards while preserving\nfeature-level interpretability. Each feature contributes independently to risk\nestimation through dedicated neural networks, allowing for visualization of\ncomplex non-linear relationships between covariates and each competing risk. We\ndemonstrate competitive performance on multiple datasets compared to existing\napproaches.','Dhanesh Ramachandram','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21360v1'),('2505.21362v1','Evaluating LLM Adaptation to Sociodemographic Factors: User Profile vs. Dialogue History','Effective engagement by large language models (LLMs) requires adapting\nresponses to users\\\' sociodemographic characteristics, such as age, occupation,\nand education level. While many real-world applications leverage dialogue\nhistory for contextualization, existing evaluations of LLMs\\\' behavioral\nadaptation often focus on single-turn prompts. In this paper, we propose a\nframework to evaluate LLM adaptation when attributes are introduced either (1)\nexplicitly via user profiles in the prompt or (2) implicitly through multi-turn\ndialogue history. We assess the consistency of model behavior across these\nmodalities. Using a multi-agent pipeline, we construct a synthetic dataset\npairing dialogue histories with distinct user profiles and employ questions\nfrom the Value Survey Module (VSM 2013) (Hofstede and Hofstede, 2016) to probe\nvalue expression. Our findings indicate that most models adjust their expressed\nvalues in response to demographic changes, particularly in age and education\nlevel, but consistency varies. Models with stronger reasoning capabilities\ndemonstrate greater alignment, indicating the importance of reasoning in robust\nsociodemographic adaptation.','Qishuai Zhong, Zongmin Li, Siqi Fan, Aixin Sun','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21362v1'),('2505.21363v1','Subgroups Matter for Robust Bias Mitigation','Despite the constant development of new bias mitigation methods for machine\nlearning, no method consistently succeeds, and a fundamental question remains\nunanswered: when and why do bias mitigation techniques fail? In this paper, we\nhypothesise that a key factor may be the often-overlooked but crucial step\nshared by many bias mitigation methods: the definition of subgroups. To\ninvestigate this, we conduct a comprehensive evaluation of state-of-the-art\nbias mitigation methods across multiple vision and language classification\ntasks, systematically varying subgroup definitions, including coarse,\nfine-grained, intersectional, and noisy subgroups. Our results reveal that\nsubgroup choice significantly impacts performance, with certain groupings\nparadoxically leading to worse outcomes than no mitigation at all. Our findings\nsuggest that observing a disparity between a set of subgroups is not a\nsufficient reason to use those subgroups for mitigation. Through theoretical\nanalysis, we explain these phenomena and uncover a counter-intuitive insight\nthat, in some cases, improving fairness with respect to a particular set of\nsubgroups is best achieved by using a different set of subgroups for\nmitigation. Our work highlights the importance of careful subgroup definition\nin bias mitigation and suggest it as a alternative lever for improving the\nrobustness and fairness of machine learning models.','Anissa Alloula, Charles Jones, Ben Glocker, Bartłomiej W. Papież','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21363v1'),('2505.21364v1','Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders','Multilayer perceptrons (MLPs) are an integral part of large language models,\nyet their dense representations render them difficult to understand, edit, and\nsteer. Recent methods learn interpretable approximations via neuron-level\nsparsity, yet fail to faithfully reconstruct the original\nmapping--significantly increasing model\\\'s next-token cross-entropy loss. In\nthis paper, we advocate for moving to layer-level sparsity to overcome the\naccuracy trade-off in sparse layer approximation. Under this paradigm, we\nintroduce Mixture of Decoders (MxDs). MxDs generalize MLPs and Gated Linear\nUnits, expanding pre-trained dense layers into tens of thousands of specialized\nsublayers. Through a flexible form of tensor factorization, each sparsely\nactivating MxD sublayer implements a linear transformation with full-rank\nweights--preserving the original decoders\\\' expressive capacity even under heavy\nsparsity. Experimentally, we show that MxDs significantly outperform\nstate-of-the-art methods (e.g., Transcoders) on the sparsity-accuracy frontier\nin language models with up to 3B parameters. Further evaluations on sparse\nprobing and feature steering demonstrate that MxDs learn similarly specialized\nfeatures of natural language--opening up a promising new avenue for designing\ninterpretable yet faithful decompositions. Our code is included at:\nhttps://github.com/james-oldfield/MxD/.','James Oldfield, Shawn Im, Yixuan Li, Mihalis A. Nicolaou, Ioannis Patras, Grigorios G Chrysos','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21364v1'),('2505.21366v1','PLANETALIGN: A Comprehensive Python Library for Benchmarking Network Alignment','Network alignment (NA) aims to identify node correspondence across different\nnetworks and serves as a critical cornerstone behind various downstream\nmulti-network learning tasks. Despite growing research in NA, there lacks a\ncomprehensive library that facilitates the systematic development and\nbenchmarking of NA methods. In this work, we introduce PLANETALIGN, a\ncomprehensive Python library for network alignment that features a rich\ncollection of built-in datasets, methods, and evaluation pipelines with\neasy-to-use APIs. Specifically, PLANETALIGN integrates 18 datasets and 14 NA\nmethods with extensible APIs for easy use and development of NA methods. Our\nstandardized evaluation pipeline encompasses a wide range of metrics, enabling\na systematic assessment of the effectiveness, scalability, and robustness of NA\nmethods. Through extensive comparative studies, we reveal practical insights\ninto the strengths and limitations of existing NA methods. We hope that\nPLANETALIGN can foster a deeper understanding of the NA problem and facilitate\nthe development and benchmarking of more effective, scalable, and robust\nmethods in the future. The source code of PLANETALIGN is available at\nhttps://github.com/yq-leo/PlanetAlign.','Qi Yu, Zhichen Zeng, Yuchen Yan, Zhining Liu, Baoyu Jing, Ruizhong Qiu, Ariful Azad, Hanghang Tong','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21366v1'),('2505.21372v1','Improving LLM-based Global Optimization with Search Space Partitioning','Large Language Models (LLMs) have recently emerged as effective surrogate\nmodels and candidate generators within global optimization frameworks for\nexpensive blackbox functions. Despite promising results, LLM-based methods\noften struggle in high-dimensional search spaces or when lacking\ndomain-specific priors, leading to sparse or uninformative suggestions. To\novercome these limitations, we propose HOLLM, a novel global optimization\nalgorithm that enhances LLM-driven sampling by partitioning the search space\ninto promising subregions. Each subregion acts as a ``meta-arm\\\'\\\' selected via a\nbandit-inspired scoring mechanism that effectively balances exploration and\nexploitation. Within each selected subregion, an LLM then proposes high-quality\ncandidate points, without any explicit domain knowledge. Empirical evaluation\non standard optimization benchmarks shows that HOLLM consistently matches or\nsurpasses leading Bayesian optimization and trust-region methods, while\nsubstantially outperforming global LLM-based sampling strategies.','Andrej Schwanke, Lyubomir Ivanov, David Salinas, Fabio Ferreira, Aaron Klein, Frank Hutter, Arber Zela','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21372v1'),('2505.21378v1','Analyzing values about gendered language reform in LLMs\\\' revisions','Within the common LLM use case of text revision, we study LLMs\\\' revision of\ngendered role nouns (e.g., outdoorsperson/woman/man) and their justifications\nof such revisions. We evaluate their alignment with feminist and\ntrans-inclusive language reforms for English. Drawing on insight from\nsociolinguistics, we further assess if LLMs are sensitive to the same\ncontextual effects in the application of such reforms as people are, finding\nbroad evidence of such effects. We discuss implications for value alignment.','Jules Watson, Xi Wang, Raymond Liu, Suzanne Stevenson, Barend Beekhuizen','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21378v1'),('2505.21380v1','PHISH in MESH: Korean Adversarial Phonetic Substitution and Phonetic-Semantic Feature Integration Defense','As malicious users increasingly employ phonetic substitution to evade hate\nspeech detection, researchers have investigated such strategies. However, two\nkey challenges remain. First, existing studies have overlooked the Korean\nlanguage, despite its vulnerability to phonetic perturbations due to its\nphonographic nature. Second, prior work has primarily focused on constructing\ndatasets rather than developing architectural defenses. To address these\nchallenges, we propose (1) PHonetic-Informed Substitution for Hangul (PHISH)\nthat exploits the phonological characteristics of the Korean writing system,\nand (2) Mixed Encoding of Semantic-pHonetic features (MESH) that enhances the\ndetector\\\'s robustness by incorporating phonetic information at the\narchitectural level. Our experimental results demonstrate the effectiveness of\nour proposed methods on both perturbed and unperturbed datasets, suggesting\nthat they not only improve detection performance but also reflect realistic\nadversarial behaviors employed by malicious users.','Byungjun Kim, Minju Kim, Hyeonchu Park, Bugeun Kim','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21380v1'),('2505.21382v1','DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models','Low-Rank Adaptation (LoRA) has emerged as one of the most effective,\ncomputationally tractable fine-tuning approaches for training Vision-Language\nModels (VLMs) and Large Language Models (LLMs). LoRA accomplishes this by\nfreezing the pre-trained model weights and injecting trainable low-rank\nmatrices, allowing for efficient learning of these foundation models even on\nedge devices. However, LoRA in decentralized settings still remains under\nexplored, particularly for the theoretical underpinnings due to the lack of\nsmoothness guarantee and model consensus interference (defined formally below).\nThis work improves the convergence rate of decentralized LoRA (DLoRA) to match\nthe rate of decentralized SGD by ensuring gradient smoothness. We also\nintroduce DeCAF, a novel algorithm integrating DLoRA with truncated singular\nvalue decomposition (TSVD)-based matrix factorization to resolve consensus\ninterference. Theoretical analysis shows TSVD\\\'s approximation error is bounded\nand consensus differences between DLoRA and DeCAF vanish as rank increases,\nyielding DeCAF\\\'s matching convergence rate. Extensive experiments across\nvision/language tasks demonstrate our algorithms outperform local training and\nrivals federated learning under both IID and non-IID data distributions.','Nastaran Saadati, Zhanhong Jiang, Joshua R. Waite, Shreyan Ganguly, Aditya Balu, Chinmay Hegde, Soumik Sarkar','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21382v1'),('2505.21388v1','DeSocial: Blockchain-based Decentralized Social Networks','Web 2.0 social platforms are inherently centralized, with user data and\nalgorithmic decisions controlled by the platform. However, users can only\npassively receive social predictions without being able to choose the\nunderlying algorithm, which limits personalization. Fortunately, with the\nemergence of blockchain, users are allowed to choose algorithms that are\ntailored to their local situation, improving prediction results in a\npersonalized way. In a blockchain environment, each user possesses its own\nmodel to perform the social prediction, capturing different perspectives on\nsocial interactions. In our work, we propose DeSocial, a decentralized social\nnetwork learning framework deployed on an Ethereum (ETH) local development\nchain that integrates distributed data storage, node-level consensus, and\nuser-driven model selection through Ganache. In the first stage, each user\nleverages DeSocial to evaluate multiple backbone models on their local\nsubgraph. DeSocial coordinates the execution and returns model-wise prediction\nresults, enabling the user to select the most suitable backbone for\npersonalized social prediction. Then, DeSocial uniformly selects several\nvalidation nodes that possess the algorithm specified by each user, and\naggregates the prediction results by majority voting, to prevent errors caused\nby any single model\\\'s misjudgment. Extensive experiments show that DeSocial has\nan evident improvement compared to the five classical centralized social\nnetwork learning models, promoting user empowerment in blockchain-based\ndecentralized social networks, showing the importance of multi-node validation\nand personalized algorithm selection based on blockchain. Our implementation is\navailable at: https://github.com/agiresearch/DeSocial.','Jingyuan Huang, Xi Zhu, Minghao Guo, Yongfeng Zhang','2025-05-27','cs.SI','http://arxiv.org/pdf/2505.21388v1'),('2505.21389v1','AutoJudger: An Agent-Driven Framework for Efficient Benchmarking of MLLMs','Evaluating multimodal large language models (MLLMs) is increasingly\nexpensive, as the growing size and cross-modality complexity of benchmarks\ndemand significant scoring efforts. To tackle with this difficulty, we\nintroduce AutoJudger, an agent-driven framework for efficient and adaptive\nbenchmarking of MLLMs that tackles this escalating cost. AutoJudger employs the\nItem Response Theory (IRT) to estimate the question difficulty and an\nautonomous evaluation agent to dynamically select the most informative test\nquestions based on the model\\\'s real-time performance. Specifically, AutoJudger\nincorporates two pivotal components: a semantic-aware retrieval mechanism to\nensure that selected questions cover diverse and challenging scenarios across\nboth vision and language modalities, and a dynamic memory that maintains\ncontextual statistics of previously evaluated questions to guide coherent and\nglobally informed question selection throughout the evaluation process.\nExtensive experiments on four representative multimodal benchmarks demonstrate\nthat our adaptive framework dramatically reduces evaluation expenses, i.e.\nAutoJudger uses only 4% of the data to achieve over 90% ranking accuracy with\nthe full benchmark evaluation on MMT-Bench.','Xuanwen Ding, Chengjun Pan, Zejun Li, Jiwen Zhang, Siyuan Wang, Zhongyu Wei','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21389v1'),('2505.21391v1','Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features','Linear TD($\\lambda$) is one of the most fundamental reinforcement learning\nalgorithms for policy evaluation. Previously, convergence rates are typically\nestablished under the assumption of linearly independent features, which does\nnot hold in many practical scenarios. This paper instead establishes the first\n$L^2$ convergence rates for linear TD($\\lambda$) operating under arbitrary\nfeatures, without making any algorithmic modification or additional\nassumptions. Our results apply to both the discounted and average-reward\nsettings. To address the potential non-uniqueness of solutions resulting from\narbitrary features, we develop a novel stochastic approximation result\nfeaturing convergence rates to the solution set instead of a single point.','Zixuan Xie, Xinyu Liu, Rohan Chandra, Shangtong Zhang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21391v1'),('2505.21393v1','Leveraging the Power of Conversations: Optimal Key Term Selection in Conversational Contextual Bandits','Conversational recommender systems proactively query users with relevant \"key\nterms\" and leverage the feedback to elicit users\\\' preferences for personalized\nrecommendations. Conversational contextual bandits, a prevalent approach in\nthis domain, aim to optimize preference learning by balancing exploitation and\nexploration. However, several limitations hinder their effectiveness in\nreal-world scenarios. First, existing algorithms employ key term selection\nstrategies with insufficient exploration, often failing to thoroughly probe\nusers\\\' preferences and resulting in suboptimal preference estimation. Second,\ncurrent algorithms typically rely on deterministic rules to initiate\nconversations, causing unnecessary interactions when preferences are\nwell-understood and missed opportunities when preferences are uncertain. To\naddress these limitations, we propose three novel algorithms: CLiSK, CLiME, and\nCLiSK-ME. CLiSK introduces smoothed key term contexts to enhance exploration in\npreference learning, CLiME adaptively initiates conversations based on\npreference uncertainty, and CLiSK-ME integrates both techniques. We\ntheoretically prove that all three algorithms achieve a tighter regret upper\nbound of $O(\\sqrt{dT\\log{T}})$ with respect to the time horizon $T$, improving\nupon existing methods. Additionally, we provide a matching lower bound\n$\\Omega(\\sqrt{dT})$ for conversational bandits, demonstrating that our\nalgorithms are nearly minimax optimal. Extensive evaluations on both synthetic\nand real-world datasets show that our approaches achieve at least a 14.6%\nimprovement in cumulative regret.','Maoli Liu, Zhuohua Li, Xiangxiang Dai, John C. S. Lui','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21393v1'),('2505.21395v1','Square$χ$PO: Differentially Private and Robust $χ^2$-Preference Optimization in Offline Direct Alignment','In this paper, we theoretically study the offline alignment of language\nmodels with human preference feedback, under both preference label corruption\nand privacy protections. To this end, we propose Square$\\chi$PO, a simple\none-line change to $\\chi$PO where the standard log-loss is replaced by a new\nsquare loss over probability. Thanks to the inherent properties of this new\nloss, we have advanced the state-of-the-art of differentially private and\nrobust offline direct alignment. Specifically, for the local model of label\nprivacy, Square$\\chi$PO is the first algorithm that attains an optimal rate\nbased on single-policy concentrability even with general function\napproximations. It also gives the first result under the central model of\nprivacy protection over both prompts (responses) and labels. On the robustness\nside against Huber label corruption, Square$\\chi$PO is the first alignment\nmethod that has a meaningful theoretical guarantee under general function\napproximations. More importantly, Square$\\chi$PO can address privacy protection\nand corruption simultaneously, where an interesting separation is observed,\nimplying that the order of privacy and corruption matters. Furthermore, we show\nthat Square$\\chi$PO can also be easily extended to handle the scenario of the\ngeneral preference model with state-of-the-art guarantees under corruption and\nprivacy. Last but not least, all of our theoretical guarantees enjoy a unified\nanalysis, building upon a new result on the generalization error bounds of\nleast-square regression under corruption and privacy constraints, which we\nbelieve is of independent interest to the community.','Xingyu Zhou, Yulian Wu, Wenqian Weng, Francesco Orabona','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21395v1'),('2505.21396v1','Improving Research Idea Generation Through Data: An Empirical Investigation in Social Science','Recent advancements in large language models (LLMs) have shown promise in\ngenerating novel research ideas. However, these ideas often face challenges\nrelated to feasibility and expected effectiveness. This paper explores how\naugmenting LLMs with relevant data during the idea generation process can\nenhance the quality of generated ideas. We introduce two ways of incorporating\ndata: (1) providing metadata during the idea generation stage to guide LLMs\ntoward feasible directions, and (2) adding automatic validation during the idea\nselection stage to assess the empirical plausibility of hypotheses within\nideas. We conduct experiments in the social science domain, specifically with\nclimate negotiation topics, and find that metadata improves the feasibility of\ngenerated ideas by 20%, while automatic validation improves the overall quality\nof selected ideas by 7%. A human study shows that LLM-generated ideas, along\nwith their related data and validation processes, inspire researchers to\npropose research ideas with higher quality. Our work highlights the potential\nof data-driven research idea generation, and underscores the practical utility\nof LLM-assisted ideation in real-world academic settings.','Xiao Liu, Xinyi Dong, Xinyang Gao, Yansong Feng, Xun Pang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21396v1'),('2505.21397v1','DecisionFlow: Advancing Large Language Model as Principled Decision Maker','In high-stakes domains such as healthcare and finance, effective\ndecision-making demands not just accurate outcomes but transparent and\nexplainable reasoning. However, current language models often lack the\nstructured deliberation needed for such tasks, instead generating decisions and\njustifications in a disconnected, post-hoc manner. To address this, we propose\nDecisionFlow, a novel decision modeling framework that guides models to reason\nover structured representations of actions, attributes, and constraints. Rather\nthan predicting answers directly from prompts, DecisionFlow builds a\nsemantically grounded decision space and infers a latent utility function to\nevaluate trade-offs in a transparent, utility-driven manner. This process\nproduces decisions tightly coupled with interpretable rationales reflecting the\nmodel\\\'s reasoning. Empirical results on two high-stakes benchmarks show that\nDecisionFlow not only achieves up to 30% accuracy gains over strong prompting\nbaselines but also enhances alignment in outcomes. Our work is a critical step\ntoward integrating symbolic reasoning with LLMs, enabling more accountable,\nexplainable, and reliable LLM decision support systems. We release the data and\ncode at https://github.com/xiusic/DecisionFlow.','Xiusi Chen, Shanyong Wang, Cheng Qian, Hongru Wang, Peixuan Han, Heng Ji','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21397v1'),('2505.21398v1','A Structured Unplugged Approach for Foundational AI Literacy in Primary Education','Younger generations are growing up in a world increasingly shaped by\nintelligent technologies, making early AI literacy crucial for developing the\nskills to critically understand and navigate them. However, education in this\nfield often emphasizes tool-based learning, prioritizing usage over\nunderstanding the underlying concepts. This lack of knowledge leaves\nnon-experts, especially children, prone to misconceptions, unrealistic\nexpectations, and difficulties in recognizing biases and stereotypes. In this\npaper, we propose a structured and replicable teaching approach that fosters\nfoundational AI literacy in primary students, by building upon core\nmathematical elements closely connected to and of interest in primary\ncurricula, to strengthen conceptualization, data representation, classification\nreasoning, and evaluation of AI. To assess the effectiveness of our approach,\nwe conducted an empirical study with thirty-one fifth-grade students across two\nclasses, evaluating their progress through a post-test and a satisfaction\nsurvey. Our results indicate improvements in terminology understanding and\nusage, features description, logical reasoning, and evaluative skills, with\nstudents showing a deeper comprehension of decision-making processes and their\nlimitations. Moreover, the approach proved engaging, with students particularly\nenjoying activities that linked AI concepts to real-world reasoning. Materials:\nhttps://github.com/tail-unica/ai-literacy-primary-ed.','Maria Cristina Carrisi, Mirko Marras, Sara Vergallo','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21398v1'),('2505.21399v1','Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling','Factual incorrectness in generated content is one of the primary concerns in\nubiquitous deployment of large language models (LLMs). Prior findings suggest\nLLMs can (sometimes) detect factual incorrectness in their generated content\n(i.e., fact-checking post-generation). In this work, we provide evidence\nsupporting the presence of LLMs\\\' internal compass that dictate the correctness\nof factual recall at the time of generation. We demonstrate that for a given\nsubject entity and a relation, LLMs internally encode linear features in the\nTransformer\\\'s residual stream that dictate whether it will be able to recall\nthe correct attribute (that forms a valid entity-relation-attribute triplet).\nThis self-awareness signal is robust to minor formatting variations. We\ninvestigate the effects of context perturbation via different example selection\nstrategies. Scaling experiments across model sizes and training dynamics\nhighlight that self-awareness emerges rapidly during training and peaks in\nintermediate layers. These findings uncover intrinsic self-monitoring\ncapabilities within LLMs, contributing to their interpretability and\nreliability.','Hovhannes Tamoyan, Subhabrata Dutta, Iryna Gurevych','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21399v1'),('2505.21400v1','A Convergence Theory for Diffusion Language Models: An Information-Theoretic Perspective','Diffusion models have emerged as a powerful paradigm for modern generative\nmodeling, demonstrating strong potential for large language models (LLMs).\nUnlike conventional autoregressive (AR) models that generate tokens\nsequentially, diffusion models enable parallel token sampling, leading to\nfaster generation and eliminating left-to-right generation constraints. Despite\ntheir empirical success, the theoretical understanding of diffusion model\napproaches remains underdeveloped. In this work, we develop convergence\nguarantees for diffusion language models from an information-theoretic\nperspective. Our analysis demonstrates that the sampling error, measured by the\nKullback-Leibler (KL) divergence, decays inversely with the number of\niterations $T$ and scales linearly with the mutual information between tokens\nin the target text sequence. In particular, we establish matching upper and\nlower bounds, up to some constant factor, to demonstrate the tightness of our\nconvergence analysis. These results offer novel theoretical insights into the\npractical effectiveness of diffusion language models.','Gen Li, Changxiao Cai','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21400v1'),('2505.21404v1','Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks','Natural-gradient methods markedly accelerate the training of Physics-Informed\nNeural Networks (PINNs), yet their Gauss--Newton update must be solved in the\nparameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is\nthe number of network trainable weights. We show that exactly the same step can\ninstead be formulated in a generally smaller residual space of size $m =\n\\sum_{\\gamma} N_{\\gamma} d_{\\gamma}$, where each residual class $\\gamma$ (e.g.\nPDE interior, boundary, initial data) contributes $N_{\\gamma}$ collocation\npoints of output dimension $d_{\\gamma}$.\n  Building on this insight, we introduce \\textit{Dual Natural Gradient Descent}\n(D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it\nwith a geodesic-acceleration correction at negligible extra cost, and provides\nboth a dense direct solver for modest $m$ and a Nystrom-preconditioned\nconjugate-gradient solver for larger $m$.\n  Experimentally, D-NGD scales second-order PINN optimization to networks with\nup to 12.8 million parameters, delivers one- to three-order-of-magnitude lower\nfinal error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton\nmethods, and -- crucially -- enables natural-gradient training of PINNs at this\nscale on a single GPU.','Anas Jnini, Flavio Vella','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21404v1'),('2505.21409v1','RelationalFactQA: A Benchmark for Evaluating Tabular Fact Retrieval from Large Language Models','Factuality in Large Language Models (LLMs) is a persistent challenge. Current\nbenchmarks often assess short factual answers, overlooking the critical ability\nto generate structured, multi-record tabular outputs from parametric knowledge.\nWe demonstrate that this relational fact retrieval is substantially more\ndifficult than isolated point-wise queries, even when individual facts are\nknown to the model, exposing distinct failure modes sensitive to output\ndimensionality (e.g., number of attributes or records). To systematically\nevaluate this under-explored capability, we introduce RelationalFactQA, a new\nbenchmark featuring diverse natural language questions (paired with SQL) and\ngold-standard tabular answers, specifically designed to assess knowledge\nretrieval in a structured format. RelationalFactQA enables analysis across\nvarying query complexities, output sizes, and data characteristics. Our\nexperiments reveal that even state-of-the-art LLMs struggle significantly, not\nexceeding 25% factual accuracy in generating relational outputs, with\nperformance notably degrading as output dimensionality increases. These\nfindings underscore critical limitations in current LLMs\\\' ability to synthesize\nstructured factual knowledge and establish RelationalFactQA as a crucial\nresource for measuring future progress in LLM factuality.','Dario Satriani, Enzo Veltri, Donatello Santoro, Paolo Papotti','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21409v1'),('2505.21410v1','MRSD: Multi-Resolution Skill Discovery for HRL Agents','Hierarchical reinforcement learning (HRL) relies on abstract skills to solve\nlong-horizon tasks efficiently. While existing skill discovery methods learns\nthese skills automatically, they are limited to a single skill per task. In\ncontrast, humans learn and use both fine-grained and coarse motor skills\nsimultaneously. Inspired by human motor control, we propose Multi-Resolution\nSkill Discovery (MRSD), an HRL framework that learns multiple skill encoders at\ndifferent temporal resolutions in parallel. A high-level manager dynamically\nselects among these skills, enabling adaptive control strategies over time. We\nevaluate MRSD on tasks from the DeepMind Control Suite and show that it\noutperforms prior state-of-the-art skill discovery and HRL methods, achieving\nfaster convergence and higher final performance. Our findings highlight the\nbenefits of integrating multi-resolution skills in HRL, paving the way for more\nversatile and efficient agents.','Shashank Sharma, Janina Hoffmann, Vinay Namboodiri','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21410v1'),('2505.21411v2','Pangu Pro MoE: Mixture of Grouped Experts for Efficient Sparsity','The surgence of Mixture of Experts (MoE) in Large Language Models promises a\nsmall price of execution cost for a much larger model parameter count and\nlearning capacity, because only a small fraction of parameters are activated\nfor each input token. However, it is commonly observed that some experts are\nactivated far more often than others, leading to system inefficiency when\nrunning the experts on different devices in parallel. Therefore, we introduce\nMixture of Grouped Experts (MoGE), which groups the experts during selection\nand balances the expert workload better than MoE in nature. It constrains\ntokens to activate an equal number of experts within each predefined expert\ngroup. When a model execution is distributed on multiple devices, this\narchitectural design ensures a balanced computational load across devices,\nsignificantly enhancing throughput, particularly for the inference phase.\nFurther, we build Pangu Pro MoE on Ascend NPUs, a sparse model based on MoGE\nwith 72 billion total parameters, 16 billion of which are activated for each\ntoken. The configuration of Pangu Pro MoE is optimized for Ascend 300I Duo and\n800I A2 through extensive system simulation studies. Our experiments indicate\nthat MoGE indeed leads to better expert load balancing and more efficient\nexecution for both model training and inference on Ascend NPUs. The inference\nperformance of Pangu Pro MoE achieves 1148 tokens/s per card and can be further\nimproved to 1528 tokens/s per card by speculative acceleration, outperforming\ncomparable 32B and 72B Dense models. Furthermore, we achieve an excellent\ncost-to-performance ratio for model inference on Ascend 300I Duo. Our studies\nshow that Ascend NPUs are capable of training Pangu Pro MoE with massive\nparallelization to make it a leading model within the sub-100B total parameter\nclass, outperforming prominent open-source models like GLM-Z1-32B and\nQwen3-32B.','Yehui Tang, Xiaosong Li, Fangcheng Liu, Wei Guo, Hang Zhou, Yaoyuan Wang, Kai Han, Xianzhi Yu, Jinpeng Li, Hui Zang, Fei Mi, Xiaojun Meng, Zhicheng Liu, Hanting Chen, Binfan Zheng, Can Chen, Youliang Yan, Ruiming Tang, Peifeng Qin, Xinghao Chen, Dacheng Tao, Yunhe Wang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21411v2'),('2505.21413v1','RefTool: Enhancing Model Reasoning with Reference-Guided Tool Creation','Tools enhance the reasoning capabilities of large language models (LLMs) in\ncomplex problem-solving tasks, but not all tasks have available tools. In the\nabsence of predefined tools, prior works have explored instructing LLMs to\ngenerate tools on their own. However, such approaches rely heavily on the\nmodels\\\' internal knowledge and would fail in domains beyond the LLMs\\\' knowledge\nscope. To address this limitation, we propose RefTool, a reference-guided\nframework for automatic tool creation that leverages structured external\nmaterials such as textbooks. RefTool consists of two modules: (1) tool\ncreation, where LLMs generate executable tools from reference content, validate\nthem using illustrative examples, and organize them hierarchically into a\ntoolbox; and (2) tool utilization, where LLMs navigate the toolbox structure to\nselect and apply the appropriate tools to solve problems. Experiments on\ncausality, physics, and chemistry benchmarks demonstrate that RefTool\noutperforms existing tool-creation and domain-specific reasoning methods by\n11.3% on average accuracy, while being cost-efficient and broadly\ngeneralizable. Analyses reveal that grounding tool creation in references\nproduces accurate and faithful tools, and that the hierarchical structure\nfacilitates effective tool selection. RefTool enables LLMs to overcome\nknowledge limitations, demonstrating the value of grounding tool creation in\nexternal references for enhanced and generalizable reasoning.','Xiao Liu, Da Yin, Zirui Wu, Yansong Feng','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21413v1'),('2505.21414v1','A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment','This paper introduces a comprehensive framework designed to analyze and\nsecure decision-support systems trained with Deep Reinforcement Learning (DRL),\nprior to deployment, by providing insights into learned behavior patterns and\nvulnerabilities discovered through simulation. The introduced framework aids in\nthe development of precisely timed and targeted observation perturbations,\nenabling researchers to assess adversarial attack outcomes within a strategic\ndecision-making context. We validate our framework, visualize agent behavior,\nand evaluate adversarial outcomes within the context of a custom-built\nstrategic game, CyberStrike. Utilizing the proposed framework, we introduce a\nmethod for systematically discovering and ranking the impact of attacks on\nvarious observation indices and time-steps, and we conduct experiments to\nevaluate the transferability of adversarial attacks across agent architectures\nand DRL training algorithms. The findings underscore the critical need for\nrobust adversarial defense mechanisms to protect decision-making policies in\nhigh-stakes environments.','Brett Bissey, Kyle Gatesman, Walker Dimon, Mohammad Alam, Luis Robaina, Joseph Weissman','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21414v1'),('2505.21419v2','Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs','Today\\\'s cloud-hosted applications and services are complex systems, and a\nperformance or functional instability can have dozens or hundreds of potential\nroot causes. Our hypothesis is that by combining the pattern matching\ncapabilities of modern AI tools with a natural multi-modal RAG LLM interface,\nproblem identification and resolution can be simplified. ARCA is a new\nmulti-modal RAG LLM system that targets this domain. Step-wise evaluations show\nthat ARCA outperforms state-of-the-art alternatives.','Yifan Wang, Kenneth P. Birman','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21419v2'),('2505.21420v1','Mentor3AD: Feature Reconstruction-based 3D Anomaly Detection via Multi-modality Mentor Learning','Multimodal feature reconstruction is a promising approach for 3D anomaly\ndetection, leveraging the complementary information from dual modalities. We\nfurther advance this paradigm by utilizing multi-modal mentor learning, which\nfuses intermediate features to further distinguish normal from feature\ndifferences. To address these challenges, we propose a novel method called\nMentor3AD, which utilizes multi-modal mentor learning. By leveraging the shared\nfeatures of different modalities, Mentor3AD can extract more effective features\nand guide feature reconstruction, ultimately improving detection performance.\nSpecifically, Mentor3AD includes a Mentor of Fusion Module (MFM) that merges\nfeatures extracted from RGB and 3D modalities to create a mentor feature.\nAdditionally, we have designed a Mentor of Guidance Module (MGM) to facilitate\ncross-modal reconstruction, supported by the mentor feature. Lastly, we\nintroduce a Voting Module (VM) to more accurately generate the final anomaly\nscore. Extensive comparative and ablation studies on MVTec 3D-AD and Eyecandies\nhave verified the effectiveness of the proposed method.','Jinbao Wang, Hanzhe Liang, Can Gao, Chenxi Hu, Jie Zhou, Yunkang Cao, Linlin Shen, Weiming Shen','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21420v1'),('2505.21421v1','A Physics-Augmented GraphGPS Framework for the Reconstruction of 3D Riemann Problems from Sparse Data','In compressible fluid flow, reconstructing shocks, discontinuities,\nrarefactions, and their interactions from sparse measurements is an important\ninverse problem with practical applications. Moreover, physics-informed machine\nlearning has recently become an increasingly popular approach for performing\nreconstructions tasks. In this work we explore a machine learning recipe, known\nas GraphGPS, for reconstructing canonical compressible flows known as 3D\nRiemann problems from sparse observations, in a physics-informed manner. The\nGraphGPS framework combines the benefits of positional encodings, local\nmessage-passing of graphs, and global contextual awareness, and we explore the\nlatter two components through an ablation study. Furthermore, we modify the\naggregation step of message-passing such that it is aware of shocks and\ndiscontinuities, resulting in sharper reconstructions of these features.\nAdditionally, we modify message-passing such that information flows strictly\nfrom known nodes only, which results in computational savings, better training\nconvergence, and no degradation of reconstruction accuracy. We also show that\nthe GraphGPS framework outperforms numerous machine learning benchmarks.','Rami Cassia, Rich Kerswell','2025-05-27','physics.flu-dyn','http://arxiv.org/pdf/2505.21421v1'),('2505.21422v1','When Shift Happens - Confounding Is to Blame','Distribution shifts introduce uncertainty that undermines the robustness and\ngeneralization capabilities of machine learning models. While conventional\nwisdom suggests that learning causal-invariant representations enhances\nrobustness to such shifts, recent empirical studies present a counterintuitive\nfinding: (i) empirical risk minimization (ERM) can rival or even outperform\nstate-of-the-art out-of-distribution (OOD) generalization methods, and (ii) its\nOOD generalization performance improves when all available covariates, not just\ncausal ones, are utilized. Drawing on both empirical and theoretical evidence,\nwe attribute this phenomenon to hidden confounding. Shifts in hidden\nconfounding induce changes in data distributions that violate assumptions\ncommonly made by existing OOD generalization approaches. Under such conditions,\nwe prove that effective generalization requires learning environment-specific\nrelationships, rather than relying solely on invariant ones. Furthermore, we\nshow that models augmented with proxies for hidden confounders can mitigate the\nchallenges posed by hidden confounding shifts. These findings offer new\ntheoretical insights and practical guidance for designing robust OOD\ngeneralization algorithms and principled covariate selection strategies.','Abbavaram Gowtham Reddy, Celia Rubio-Madrigal, Rebekka Burkholz, Krikamol Muandet','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21422v1'),('2505.21423v1','Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization','A widely believed explanation for the remarkable generalization capacities of\noverparameterized neural networks is that the optimization algorithms used for\ntraining induce an implicit bias towards benign solutions. To grasp this\ntheoretically, recent works examine gradient descent and its variants in\nsimplified training settings, often assuming vanishing learning rates. These\nstudies reveal various forms of implicit regularization, such as $\\ell_1$-norm\nminimizing parameters in regression and max-margin solutions in classification.\nConcurrently, empirical findings show that moderate to large learning rates\nexceeding standard stability thresholds lead to faster, albeit oscillatory,\nconvergence in the so-called Edge-of-Stability regime, and induce an implicit\nbias towards minima of low sharpness (norm of training loss Hessian). In this\nwork, we argue that a comprehensive understanding of the generalization\nperformance of gradient descent requires analyzing the interaction between\nthese various forms of implicit regularization. We empirically demonstrate that\nthe learning rate balances between low parameter norm and low sharpness of the\ntrained model. We furthermore prove for diagonal linear networks trained on a\nsimple regression task that neither implicit bias alone minimizes the\ngeneralization error. These findings demonstrate that focusing on a single\nimplicit bias is insufficient to explain good generalization, and they motivate\na broader view of implicit regularization that captures the dynamic trade-off\nbetween norm and sharpness induced by non-negligible learning rates.','Vit Fojtik, Maria Matveev, Hung-Hsu Chou, Gitta Kutyniok, Johannes Maly','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21423v1'),('2505.21426v1','Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks','Agent-Based Models (ABMs) are powerful tools for studying emergent properties\nin complex systems. In ABMs, agent behaviors are governed by local interactions\nand stochastic rules. However, these rules are, in general, non-differentiable,\nlimiting the use of gradient-based methods for optimization, and thus\nintegration with real-world data. We propose a novel framework to learn a\ndifferentiable surrogate of any ABM by observing its generated data. Our method\ncombines diffusion models to capture behavioral stochasticity and graph neural\nnetworks to model agent interactions. Distinct from prior surrogate approaches,\nour method introduces a fundamental shift: rather than approximating\nsystem-level outputs, it models individual agent behavior directly, preserving\nthe decentralized, bottom-up dynamics that define ABMs. We validate our\napproach on two ABMs (Schelling\\\'s segregation model and a Predator-Prey\necosystem) showing that it replicates individual-level patterns and accurately\nforecasts emergent dynamics beyond training. Our results demonstrate the\npotential of combining diffusion models and graph learning for data-driven ABM\nsimulation.','Francesco Cozzi, Marco Pangallo, Alan Perotti, André Panisson, Corrado Monti','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21426v1'),('2505.21427v1','Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning','Early-stage startup investment is a high-risk endeavor characterized by\nscarce data and uncertain outcomes. Traditional machine learning approaches\noften require large, labeled datasets and extensive fine-tuning, yet remain\nopaque and difficult for domain experts to interpret or improve. In this paper,\nwe propose a transparent and data-efficient investment decision framework\npowered by memory-augmented large language models (LLMs) using in-context\nlearning (ICL). Central to our method is a natural language policy embedded\ndirectly into the LLM prompt, enabling the model to apply explicit reasoning\npatterns and allowing human experts to easily interpret, audit, and iteratively\nrefine the logic. We introduce a lightweight training process that combines\nfew-shot learning with an in-context learning loop, enabling the LLM to update\nits decision policy iteratively based on structured feedback. With only minimal\nsupervision and no gradient-based optimization, our system predicts startup\nsuccess far more accurately than existing benchmarks. It is over 20x more\nprecise than random chance, which succeeds 1.9% of the time. It is also 7.1x\nmore precise than the typical 5.6% success rate of top-tier venture capital\n(VC) firms.','Xianling Mu, Joseph Ternasky, Fuat Alican, Yigit Ihlamur','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21427v1'),('2505.21430v1','Attribute-Efficient PAC Learning of Sparse Halfspaces with Constant Malicious Noise Rate','Attribute-efficient learning of sparse halfspaces has been a fundamental\nproblem in machine learning theory. In recent years, machine learning\nalgorithms are faced with prevalent data corruptions or even adversarial\nattacks. It is of central interest to design efficient algorithms that are\nrobust to noise corruptions. In this paper, we consider that there exists a\nconstant amount of malicious noise in the data and the goal is to learn an\nunderlying $s$-sparse halfspace $w^* \\in \\mathbb{R}^d$ with $\\text{poly}(s,\\log\nd)$ samples. Specifically, we follow a recent line of works and assume that the\nunderlying distribution satisfies a certain concentration condition and a\nmargin condition at the same time. Under such conditions, we show that\nattribute-efficiency can be achieved by simple variants to existing hinge loss\nminimization programs. Our key contribution includes: 1) an attribute-efficient\nPAC learning algorithm that works under constant malicious noise rate; 2) a new\ngradient analysis that carefully handles the sparsity constraint in hinge loss\nminimization.','Shiwei Zeng, Jie Shen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21430v1'),('2505.21432v1','Hume: Introducing System-2 Thinking in Visual-Language-Action Model','Humans practice slow thinking before performing actual actions when handling\ncomplex tasks in the physical world. This thinking paradigm, recently, has\nachieved remarkable advancement in boosting Large Language Models (LLMs) to\nsolve complex tasks in digital domains. However, the potential of slow thinking\nremains largely unexplored for robotic foundation models interacting with the\nphysical world. In this work, we propose Hume: a dual-system\nVision-Language-Action (VLA) model with value-guided System-2 thinking and\ncascaded action denoising, exploring human-like thinking capabilities of\nVision-Language-Action models for dexterous robot control. System 2 of Hume\nimplements value-Guided thinking by extending a Vision-Language-Action Model\nbackbone with a novel value-query head to estimate the state-action value of\npredicted actions. The value-guided thinking is conducted by repeat sampling\nmultiple action candidates and selecting one according to state-action value.\nSystem 1 of Hume is a lightweight reactive visuomotor policy that takes System\n2 selected action and performs cascaded action denoising for dexterous robot\ncontrol. At deployment time, System 2 performs value-guided thinking at a low\nfrequency while System 1 asynchronously receives the System 2 selected action\ncandidate and predicts fluid actions in real time. We show that Hume\noutperforms the existing state-of-the-art Vision-Language-Action models across\nmultiple simulation benchmark and real-robot deployments.','Haoming Song, Delin Qu, Yuanqi Yao, Qizhi Chen, Qi Lv, Yiwen Tang, Modi Shi, Guanghui Ren, Maoqing Yao, Bin Zhao, Dong Wang, Xuelong Li','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.21432v1'),('2505.21438v1','Measuring Fine-Grained Relatedness in Multitask Learning via Data Attribution','Measuring task relatedness and mitigating negative transfer remain a critical\nopen challenge in Multitask Learning (MTL). This work extends data attribution\n-- which quantifies the influence of individual training data points on model\npredictions -- to MTL setting for measuring task relatedness. We propose the\nMultiTask Influence Function (MTIF), a method that adapts influence functions\nto MTL models with hard or soft parameter sharing. Compared to conventional\ntask relatedness measurements, MTIF provides a fine-grained, instance-level\nrelatedness measure beyond the entire-task level. This fine-grained relatedness\nmeasure enables a data selection strategy to effectively mitigate negative\ntransfer in MTL. Through extensive experiments, we demonstrate that the\nproposed MTIF efficiently and accurately approximates the performance of models\ntrained on data subsets. Moreover, the data selection strategy enabled by MTIF\nconsistently improves model performance in MTL. Our work establishes a novel\nconnection between data attribution and MTL, offering an efficient and\nfine-grained solution for measuring task relatedness and enhancing MTL models.','Yiwen Tu, Ziqi Liu, Jiaqi W. Ma, Weijing Tang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21438v1'),('2505.21439v1','Towards Better Instruction Following Retrieval Models','Modern information retrieval (IR) models, trained exclusively on standard\n<query, passage> pairs, struggle to effectively interpret and follow explicit\nuser instructions. We introduce InF-IR, a large-scale, high-quality training\ncorpus tailored for enhancing retrieval models in Instruction-Following IR.\nInF-IR expands traditional training pairs into over 38,000 expressive\n<instruction, query, passage> triplets as positive samples. In particular, for\neach positive triplet, we generate two additional hard negative examples by\npoisoning both instructions and queries, then rigorously validated by an\nadvanced reasoning model (o3-mini) to ensure semantic plausibility while\nmaintaining instructional incorrectness. Unlike existing corpora that primarily\nsupport computationally intensive reranking tasks for decoder-only language\nmodels, the highly contrastive positive-negative triplets in InF-IR further\nenable efficient representation learning for smaller encoder-only models,\nfacilitating direct embedding-based retrieval. Using this corpus, we train\nInF-Embed, an instruction-aware Embedding model optimized through contrastive\nlearning and instruction-query attention mechanisms to align retrieval outcomes\nprecisely with user intents. Extensive experiments across five\ninstruction-based retrieval benchmarks demonstrate that InF-Embed significantly\nsurpasses competitive baselines by 8.1% in p-MRR, measuring the\ninstruction-following capabilities.','Yuchen Zhuang, Aaron Trinh, Rushi Qiang, Haotian Sun, Chao Zhang, Hanjun Dai, Bo Dai','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21439v1'),('2505.21441v1','Autoencoding Random Forests','We propose a principled method for autoencoding with random forests. Our\nstrategy builds on foundational results from nonparametric statistics and\nspectral graph theory to learn a low-dimensional embedding of the model that\noptimally represents relationships in the data. We provide exact and\napproximate solutions to the decoding problem via constrained optimization,\nsplit relabeling, and nearest neighbors regression. These methods effectively\ninvert the compression pipeline, establishing a map from the embedding space\nback to the input space using splits learned by the ensemble\\\'s constituent\ntrees. The resulting decoders are universally consistent under common\nregularity assumptions. The procedure works with supervised or unsupervised\nmodels, providing a window into conditional or joint distributions. We\ndemonstrate various applications of this autoencoder, including powerful new\ntools for visualization, compression, clustering, and denoising. Experiments\nillustrate the ease and utility of our method in a wide range of settings,\nincluding tabular, image, and genomic data.','Binh Duc Vu, Jan Kapar, Marvin Wright, David S. Watson','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.21441v1'),('2505.21444v1','Can Large Reasoning Models Self-Train?','Scaling the performance of large language models (LLMs) increasingly depends\non methods that reduce reliance on human supervision. Reinforcement learning\nfrom automated verification offers an alternative, but it incurs scalability\nlimitations due to dependency upon human-designed verifiers. Self-training,\nwhere the model\\\'s own judgment provides the supervisory signal, presents a\ncompelling direction. We propose an online self-training reinforcement learning\nalgorithm that leverages the model\\\'s self-consistency to infer correctness\nsignals and train without any ground-truth supervision. We apply the algorithm\nto challenging mathematical reasoning tasks and show that it quickly reaches\nperformance levels rivaling reinforcement-learning methods trained explicitly\non gold-standard answers. Additionally, we analyze inherent limitations of the\nalgorithm, highlighting how the self-generated proxy reward initially\ncorrelated with correctness can incentivize reward hacking, where confidently\nincorrect outputs are favored. Our results illustrate how self-supervised\nimprovement can achieve significant performance gains without external labels,\nwhile also revealing its fundamental challenges.','Sheikh Shafayat, Fahim Tajwar, Ruslan Salakhutdinov, Jeff Schneider, Andrea Zanette','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21444v1'),('2505.21445v1','VoxAging: Continuously Tracking Speaker Aging with a Large-Scale Longitudinal Dataset in English and Mandarin','The performance of speaker verification systems is adversely affected by\nspeaker aging. However, due to challenges in data collection, particularly the\nlack of sustained and large-scale longitudinal data for individuals, research\non speaker aging remains difficult. In this paper, we present VoxAging, a\nlarge-scale longitudinal dataset collected from 293 speakers (226 English\nspeakers and 67 Mandarin speakers) over several years, with the longest time\nspan reaching 17 years (approximately 900 weeks). For each speaker, the data\nwere recorded at weekly intervals. We studied the phenomenon of speaker aging\nand its effects on advanced speaker verification systems, analyzed individual\nspeaker aging processes, and explored the impact of factors such as age group\nand gender on speaker aging research.','Zhiqi Ai, Meixuan Bao, Zhiyong Chen, Zhi Yang, Xinnuo Li, Shugong Xu','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.21445v1'),('2505.21451v1','Words Like Knives: Backstory-Personalized Modeling and Detection of Violent Communication','Conversational breakdowns in close relationships are deeply shaped by\npersonal histories and emotional context, yet most NLP research treats conflict\ndetection as a general task, overlooking the relational dynamics that influence\nhow messages are perceived. In this work, we leverage nonviolent communication\n(NVC) theory to evaluate LLMs in detecting conversational breakdowns and\nassessing how relationship backstory influences both human and model perception\nof conflicts. Given the sensitivity and scarcity of real-world datasets\nfeaturing conflict between familiar social partners with rich personal\nbackstories, we contribute the PersonaConflicts Corpus, a dataset of N=5,772\nnaturalistic simulated dialogues spanning diverse conflict scenarios between\nfriends, family members, and romantic partners. Through a controlled human\nstudy, we annotate a subset of dialogues and obtain fine-grained labels of\ncommunication breakdown types on individual turns, and assess the impact of\nbackstory on human and model perception of conflict in conversation. We find\nthat the polarity of relationship backstories significantly shifted human\nperception of communication breakdowns and impressions of the social partners,\nyet models struggle to meaningfully leverage those backstories in the detection\ntask. Additionally, we find that models consistently overestimate how\npositively a message will make a listener feel. Our findings underscore the\ncritical role of personalization to relationship contexts in enabling LLMs to\nserve as effective mediators in human communication for authentic connection.','Jocelyn Shen, Akhila Yerukola, Xuhui Zhou, Cynthia Breazeal, Maarten Sap, Hae Won Park','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21451v1'),('2505.21452v1','Designing Cyclic Peptides via Harmonic SDE with Atom-Bond Modeling','Cyclic peptides offer inherent advantages in pharmaceuticals. For example,\ncyclic peptides are more resistant to enzymatic hydrolysis compared to linear\npeptides and usually exhibit excellent stability and affinity. Although deep\ngenerative models have achieved great success in linear peptide design, several\nchallenges prevent the development of computational methods for designing\ndiverse types of cyclic peptides. These challenges include the scarcity of 3D\nstructural data on target proteins and associated cyclic peptide ligands, the\ngeometric constraints that cyclization imposes, and the involvement of\nnon-canonical amino acids in cyclization. To address the above challenges, we\nintroduce CpSDE, which consists of two key components: AtomSDE, a generative\nstructure prediction model based on harmonic SDE, and ResRouter, a residue type\npredictor. Utilizing a routed sampling algorithm that alternates between these\ntwo models to iteratively update sequences and structures, CpSDE facilitates\nthe generation of cyclic peptides. By employing explicit all-atom and bond\nmodeling, CpSDE overcomes existing data limitations and is proficient in\ndesigning a wide variety of cyclic peptides. Our experimental results\ndemonstrate that the cyclic peptides designed by our method exhibit reliable\nstability and affinity.','Xiangxin Zhou, Mingyu Li, Yi Xiao, Jiahan Li, Dongyu Xue, Zaixiang Zheng, Jianzhu Ma, Quanquan Gu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21452v1'),('2505.21457v1','Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO','Active vision, also known as active perception, refers to the process of\nactively selecting where and how to look in order to gather task-relevant\ninformation. It is a critical component of efficient perception and\ndecision-making in humans and advanced embodied agents. Recently, the use of\nMultimodal Large Language Models (MLLMs) as central planning and\ndecision-making modules in robotic systems has gained extensive attention.\nHowever, despite the importance of active perception in embodied intelligence,\nthere is little to no exploration of how MLLMs can be equipped with or learn\nactive perception capabilities. In this paper, we first provide a systematic\ndefinition of MLLM-based active perception tasks. We point out that the\nrecently proposed GPT-o3 model\\\'s zoom-in search strategy can be regarded as a\nspecial case of active perception; however, it still suffers from low search\nefficiency and inaccurate region selection. To address these issues, we propose\nACTIVE-O3, a purely reinforcement learning based training framework built on\ntop of GRPO, designed to equip MLLMs with active perception capabilities. We\nfurther establish a comprehensive benchmark suite to evaluate ACTIVE-O3 across\nboth general open-world tasks, such as small-object and dense object grounding,\nand domain-specific scenarios, including small object detection in remote\nsensing and autonomous driving, as well as fine-grained interactive\nsegmentation. In addition, ACTIVE-O3 also demonstrates strong zero-shot\nreasoning abilities on the V* Benchmark, without relying on any explicit\nreasoning data. We hope that our work can provide a simple codebase and\nevaluation protocol to facilitate future research on active perception in\nMLLMs.','Muzhi Zhu, Hao Zhong, Canyu Zhao, Zongze Du, Zheng Huang, Mingyu Liu, Hao Chen, Cheng Zou, Jingdong Chen, Ming Yang, Chunhua Shen','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21457v1'),('2505.21458v1','Do LLMs Need to Think in One Language? Correlation between Latent Language and Task Performance','Large Language Models (LLMs) are known to process information using a\nproficient internal language consistently, referred to as latent language,\nwhich may differ from the input or output languages. However, how the\ndiscrepancy between the latent language and the input and output language\naffects downstream task performance remains largely unexplored. While many\nstudies research the latent language of LLMs, few address its importance in\ninfluencing task performance. In our study, we hypothesize that thinking in\nlatent language consistently enhances downstream task performance. To validate\nthis, our work varies the input prompt languages across multiple downstream\ntasks and analyzes the correlation between consistency in latent language and\ntask performance. We create datasets consisting of questions from diverse\ndomains such as translation and geo-culture, which are influenced by the choice\nof latent language. Experimental results across multiple LLMs on translation\nand geo-culture tasks, which are sensitive to the choice of language, indicate\nthat maintaining consistency in latent language is not always necessary for\noptimal downstream task performance. This is because these models adapt their\ninternal representations near the final layers to match the target language,\nreducing the impact of consistency on overall performance.','Shintaro Ozaki, Tatsuya Hiraoka, Hiroto Otake, Hiroki Ouchi, Masaru Isonuma, Benjamin Heinzerling, Kentaro Inui, Taro Watanabe, Yusuke Miyao, Yohei Oseki, Yu Takagi','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21458v1'),('2505.21459v1','LazyVLM: Neuro-Symbolic Approach to Video Analytics','Current video analytics approaches face a fundamental trade-off between\nflexibility and efficiency. End-to-end Vision Language Models (VLMs) often\nstruggle with long-context processing and incur high computational costs, while\nneural-symbolic methods depend heavily on manual labeling and rigid rule\ndesign. In this paper, we introduce LazyVLM, a neuro-symbolic video analytics\nsystem that provides a user-friendly query interface similar to VLMs, while\naddressing their scalability limitation. LazyVLM enables users to effortlessly\ndrop in video data and specify complex multi-frame video queries using a\nsemi-structured text interface for video analytics. To address the scalability\nlimitations of VLMs, LazyVLM decomposes multi-frame video queries into\nfine-grained operations and offloads the bulk of the processing to efficient\nrelational query execution and vector similarity search. We demonstrate that\nLazyVLM provides a robust, efficient, and user-friendly solution for querying\nopen-domain video data at scale.','Xiangru Jian, Wei Pang, Zhengyuan Dong, Chao Zhang, M. Tamer Özsu','2025-05-27','cs.DB','http://arxiv.org/pdf/2505.21459v1'),('2505.21460v1','High-Dimensional Calibration from Swap Regret','We study the online calibration of multi-dimensional forecasts over an\narbitrary convex set $\\mathcal{P} \\subset \\mathbb{R}^d$ relative to an\narbitrary norm $\\Vert\\cdot\\Vert$. We connect this with the problem of external\nregret minimization for online linear optimization, showing that if it is\npossible to guarantee $O(\\sqrt{\\rho T})$ worst-case regret after $T$ rounds\nwhen actions are drawn from $\\mathcal{P}$ and losses are drawn from the dual\n$\\Vert \\cdot \\Vert_*$ unit norm ball, then it is also possible to obtain\n$\\epsilon$-calibrated forecasts after $T = \\exp(O(\\rho /\\epsilon^2))$ rounds.\nWhen $\\mathcal{P}$ is the $d$-dimensional simplex and $\\Vert \\cdot \\Vert$ is\nthe $\\ell_1$-norm, the existence of $O(\\sqrt{T\\log d})$-regret algorithms for\nlearning with experts implies that it is possible to obtain\n$\\epsilon$-calibrated forecasts after $T = \\exp(O(\\log{d}/\\epsilon^2)) =\nd^{O(1/\\epsilon^2)}$ rounds, recovering a recent result of Peng (2025).\n  Interestingly, our algorithm obtains this guarantee without requiring access\nto any online linear optimization subroutine or knowledge of the optimal rate\n$\\rho$ -- in fact, our algorithm is identical for every setting of\n$\\mathcal{P}$ and $\\Vert \\cdot \\Vert$. Instead, we show that the optimal\nregularizer for the above OLO problem can be used to upper bound the above\ncalibration error by a swap regret, which we then minimize by running the\nrecent TreeSwap algorithm with Follow-The-Leader as a subroutine.\n  Finally, we prove that any online calibration algorithm that guarantees\n$\\epsilon T$ $\\ell_1$-calibration error over the $d$-dimensional simplex\nrequires $T \\geq \\exp(\\mathrm{poly}(1/\\epsilon))$ (assuming $d \\geq\n\\mathrm{poly}(1/\\epsilon)$). This strengthens the corresponding\n$d^{\\Omega(\\log{1/\\epsilon})}$ lower bound of Peng, and shows that an\nexponential dependence on $1/\\epsilon$ is necessary.','Maxwell Fishelson, Noah Golowich, Mehryar Mohri, Jon Schneider','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21460v1'),('2505.21465v1','ID-Align: RoPE-Conscious Position Remapping for Dynamic High-Resolution Adaptation in Vision-Language Models','Currently, a prevalent approach for enhancing Vision-Language Models (VLMs)\nperformance is to encode both the high-resolution version and the thumbnail of\nan image simultaneously. While effective, this method generates a large number\nof image tokens. When combined with the widely used Rotary Position Embedding\n(RoPE), its long-term decay property hinders the interaction between\nhigh-resolution tokens and thumbnail tokens, as well as between text and image.\nTo address these issues, we propose ID-Align, which alleviates these problems\nby reordering position IDs. In this method, high-resolution tokens inherit IDs\nfrom their corresponding thumbnail token while constraining the overexpansion\nof positional indices. Our experiments conducted within the LLaVA-Next\nframework demonstrate that ID-Align achieves significant improvements,\nincluding a 6.09% enhancement on MMBench\\\'s relation reasoning tasks and notable\ngains across multiple benchmarks. Our code is available at the following link:\nhttps://github.com/zooblastlbz/ID-Align.','Bozhou Li, Wentao Zhang','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21465v1'),('2505.21467v1','Accelerating Diffusion Language Model Inference via Efficient KV Caching and Guided Diffusion','Diffusion language models offer parallel token generation and inherent\nbidirectionality, promising more efficient and powerful sequence modeling\ncompared to autoregressive approaches. However, state-of-the-art diffusion\nmodels (e.g., Dream 7B, LLaDA 8B) suffer from slow inference. While they match\nthe quality of similarly sized Autoregressive (AR) Models (e.g., Qwen2.5 7B,\nLlama3 8B), their iterative denoising requires multiple full-sequence forward\npasses, resulting in high computational costs and latency, particularly for\nlong input prompts and long-context scenarios. Furthermore, parallel token\ngeneration introduces token incoherence problems, and current sampling\nheuristics suffer from significant quality drops with decreasing denoising\nsteps. We address these limitations with two training-free techniques. First,\nwe propose FreeCache, a Key-Value (KV) approximation caching technique that\nreuses stable KV projections across denoising steps, effectively reducing the\ncomputational cost of DLM inference. Second, we introduce Guided Diffusion, a\ntraining-free method that uses a lightweight pretrained autoregressive model to\nsupervise token unmasking, dramatically reducing the total number of denoising\niterations without sacrificing quality. We conduct extensive evaluations on\nopen-source reasoning benchmarks, and our combined methods deliver up to a 34x\nend-to-end speedup without compromising accuracy. For the first time, diffusion\nlanguage models achieve a comparable and even faster latency as the widely\nadopted autoregressive models. Our work successfully paved the way for scaling\nup the diffusion language model to a broader scope of applications across\ndifferent domains.','Zhanqiu Hu, Jian Meng, Yash Akhauri, Mohamed S. Abdelfattah, Jae-sun Seo, Zhiru Zhang, Udit Gupta','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21467v1'),('2505.21468v1','Causal Posterior Estimation','We present Causal Posterior Estimation (CPE), a novel method for Bayesian\ninference in simulator models, i.e., models where the evaluation of the\nlikelihood function is intractable or too computationally expensive, but where\none can simulate model outputs given parameter values. CPE utilizes a\nnormalizing flow-based (NF) approximation to the posterior distribution which\ncarefully incorporates the conditional dependence structure induced by the\ngraphical representation of the model into the neural network. Thereby it is\npossible to improve the accuracy of the approximation. We introduce both\ndiscrete and continuous NF architectures for CPE and propose a constant-time\nsampling procedure for the continuous case which reduces the computational\ncomplexity of drawing samples to O(1) as for discrete NFs. We show, through an\nextensive experimental evaluation, that by incorporating the conditional\ndependencies induced by the graphical model directly into the neural network,\nrather than learning them from data, CPE is able to conduct highly accurate\nposterior inference either outperforming or matching the state of the art in\nthe field.','Simon Dirmeier, Antonietta Mira','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21468v1'),('2505.21471v1','Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration','With the rapid advancement of post-training techniques for reasoning and\ninformation seeking, large language models (LLMs) can incorporate a large\nquantity of retrieved knowledge to solve complex tasks. However, the limited\ncontext window of LLMs obstructs scaling the amount of external knowledge\ninput, prohibiting further improvement, especially for tasks requiring\nsignificant amount of external knowledge. Existing context window extension\nmethods inevitably cause information loss. LLM-based multi-agent methods emerge\nas a new paradigm to handle massive input in a distributional manner, where we\nidentify two core bottlenecks in existing knowledge synchronization and\nreasoning processes. In this work, we develop a multi-agent framework,\n$\\textbf{ExtAgents}$, to overcome the bottlenecks and enable better scalability\nin inference-time knowledge integration without longer-context training.\nBenchmarked with our enhanced multi-hop question answering test,\n$\\textbf{$\\boldsymbol{\\infty}$Bench+}$, and other public test sets including\nlong survey generation, ExtAgents significantly enhances the performance over\nexisting non-training methods with the same amount of external knowledge input,\nregardless of whether it falls $\\textit{within or exceeds the context window}$.\nMoreover, the method maintains high efficiency due to high parallelism. Further\nstudy in the coordination of LLM agents on increasing external knowledge input\ncould benefit real-world applications.','Zijun Liu, Zhennan Wan, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21471v1'),('2505.21472v1','Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration','Large vision-language models (LVLMs) achieve impressive performance on\nmultimodal tasks but often suffer from hallucination, and confidently describe\nobjects or attributes not present in the image. Current inference-time\ninterventions, while training-free, struggle to maintain accuracy in open-ended\nand long-form generation scenarios. We introduce the Confidence-Aware Attention\nCalibration (CAAC) framework to address this challenge by targeting two key\nbiases: spatial perception bias, which distributes attention disproportionately\nacross image tokens, and modality bias, which shifts focus from visual to\ntextual inputs over time. CAAC employs a two-step approach: Visual-Token\nCalibration (VTC) to balance attention across visual tokens, and Adaptive\nAttention Re-Scaling (AAR) to reinforce visual grounding based on the model\\\'s\nconfidence. This confidence-driven adjustment ensures consistent visual\nalignment during generation. Experiments on CHAIR, AMBER, and POPE benchmarks\ndemonstrate that CAAC outperforms baselines, particularly in long-form\ngenerations, effectively reducing hallucination.','Mehrdad Fazli, Bowen Wei, Ziwei Zhu','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21472v1'),('2505.21475v1','Algorithms and SQ Lower Bounds for Robustly Learning Real-valued Multi-index Models','We study the complexity of learning real-valued Multi-Index Models (MIMs)\nunder the Gaussian distribution. A $K$-MIM is a function $f:\\mathbb{R}^d\\to\n\\mathbb{R}$ that depends only on the projection of its input onto a\n$K$-dimensional subspace. We give a general algorithm for PAC learning a broad\nclass of MIMs with respect to the square loss, even in the presence of\nadversarial label noise. Moreover, we establish a nearly matching Statistical\nQuery (SQ) lower bound, providing evidence that the complexity of our algorithm\nis qualitatively optimal as a function of the dimension. Specifically, we\nconsider the class of bounded variation MIMs with the property that degree at\nmost $m$ distinguishing moments exist with respect to projections onto any\nsubspace. In the presence of adversarial label noise, the complexity of our\nlearning algorithm is $d^{O(m)}2^{\\mathrm{poly}(K/\\epsilon)}$. For the\nrealizable and independent noise settings, our algorithm incurs complexity\n$d^{O(m)}2^{\\mathrm{poly}(K)}(1/\\epsilon)^{O(K)}$. To complement our upper\nbound, we show that if for some subspace degree-$m$ distinguishing moments do\nnot exist, then any SQ learner for the corresponding class of MIMs requires\ncomplexity $d^{\\Omega(m)}$. As an application, we give the first efficient\nlearner for the class of positive-homogeneous $L$-Lipschitz $K$-MIMs. The\nresulting algorithm has complexity $\\mathrm{poly}(d)\n2^{\\mathrm{poly}(KL/\\epsilon)}$. This gives a new PAC learning algorithm for\nLipschitz homogeneous ReLU networks with complexity independent of the network\nsize, removing the exponential dependence incurred in prior work.','Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Lisheng Ren','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21475v1'),('2505.21478v1','Policy Optimized Text-to-Image Pipeline Design','Text-to-image generation has evolved beyond single monolithic models to\ncomplex multi-component pipelines. These combine fine-tuned generators,\nadapters, upscaling blocks and even editing steps, leading to significant\nimprovements in image quality. However, their effective design requires\nsubstantial expertise. Recent approaches have shown promise in automating this\nprocess through large language models (LLMs), but they suffer from two critical\nlimitations: extensive computational requirements from generating images with\nhundreds of predefined pipelines, and poor generalization beyond memorized\ntraining examples. We introduce a novel reinforcement learning-based framework\nthat addresses these inefficiencies. Our approach first trains an ensemble of\nreward models capable of predicting image quality scores directly from\nprompt-workflow combinations, eliminating the need for costly image generation\nduring training. We then implement a two-phase training strategy: initial\nworkflow vocabulary training followed by GRPO-based optimization that guides\nthe model toward higher-performing regions of the workflow space. Additionally,\nwe incorporate a classifier-free guidance based enhancement technique that\nextrapolates along the path between the initial and GRPO-tuned models, further\nimproving output quality. We validate our approach through a set of\ncomparisons, showing that it can successfully create new flows with greater\ndiversity and lead to superior image quality compared to existing baselines.','Uri Gadot, Rinon Gal, Yftah Ziser, Gal Chechik, Shie Mannor','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21478v1'),('2505.21479v1','Are Language Models Consequentialist or Deontological Moral Reasoners?','As AI systems increasingly navigate applications in healthcare, law, and\ngovernance, understanding how they handle ethically complex scenarios becomes\ncritical. Previous work has mainly examined the moral judgments in large\nlanguage models (LLMs), rather than their underlying moral reasoning process.\nIn contrast, we focus on a large-scale analysis of the moral reasoning traces\nprovided by LLMs. Furthermore, unlike prior work that attempted to draw\ninferences from only a handful of moral dilemmas, our study leverages over 600\ndistinct trolley problems as probes for revealing the reasoning patterns that\nemerge within different LLMs. We introduce and test a taxonomy of moral\nrationales to systematically classify reasoning traces according to two main\nnormative ethical theories: consequentialism and deontology. Our analysis\nreveals that LLM chains-of-thought tend to favor deontological principles based\non moral obligations, while post-hoc explanations shift notably toward\nconsequentialist rationales that emphasize utility. Our framework provides a\nfoundation for understanding how LLMs process and articulate ethical\nconsiderations, an important step toward safe and interpretable deployment of\nLLMs in high-stakes decision-making environments. Our code is available at\nhttps://github.com/keenansamway/moral-lens .','Keenan Samway, Max Kleiman-Weiner, David Guzman Piedrahita, Rada Mihalcea, Bernhard Schölkopf, Zhijing Jin','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21479v1'),('2505.21486v1','Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming','Automating robust hypothesis generation in open environments is pivotal for\nAI cognition. We introduce a novel framework integrating a multi-agent system,\npowered by Large Language Models (LLMs), with Inductive Logic Programming\n(ILP). Our system\\\'s LLM agents autonomously define a structured symbolic\nvocabulary (predicates) and relational templates , i.e., \\emph{language bias}\ndirectly from raw textual data. This automated symbolic grounding (the\nconstruction of the language bias), traditionally an expert-driven bottleneck\nfor ILP, then guides the transformation of text into facts for an ILP solver,\nwhich inductively learns interpretable rules. This approach overcomes\ntraditional ILP\\\'s reliance on predefined symbolic structures and the\nnoise-sensitivity of pure LLM methods. Extensive experiments in diverse,\nchallenging scenarios validate superior performance, paving a new path for\nautomated, explainable, and verifiable hypothesis generation.','Yang Yang, Jiemin Wu, Yutao Yue','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21486v1'),('2505.21487v1','Hardware-Efficient Attention for Fast Decoding','LLM decoding is bottlenecked for large batches and long contexts by loading\nthe key-value (KV) cache from high-bandwidth memory, which inflates per-token\nlatency, while the sequential nature of decoding limits parallelism. We analyze\nthe interplay among arithmetic intensity, parallelization, and model quality\nand question whether current architectures fully exploit modern hardware. This\nwork redesigns attention to perform more computation per byte loaded from\nmemory to maximize hardware efficiency without trading off parallel\nscalability. We first propose Grouped-Tied Attention (GTA), a simple variant\nthat combines and reuses key and value states, reducing memory transfers\nwithout compromising model quality. We then introduce Grouped Latent Attention\n(GLA), a parallel-friendly latent attention paired with low-level optimizations\nfor fast decoding while maintaining high model quality. Experiments show that\nGTA matches Grouped-Query Attention (GQA) quality while using roughly half the\nKV cache and that GLA matches Multi-head Latent Attention (MLA) and is easier\nto shard. Our optimized GLA kernel is up to 2$\\times$ faster than FlashMLA, for\nexample, in a speculative decoding setting when the query length exceeds one.\nFurthermore, by fetching a smaller KV cache per device, GLA reduces end-to-end\nlatency and increases throughput in online serving benchmarks by up to\n2$\\times$.','Ted Zadouri, Hubert Strauss, Tri Dao','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21487v1'),('2505.21488v1','Be Decisive: Noise-Induced Layouts for Multi-Subject Generation','Generating multiple distinct subjects remains a challenge for existing\ntext-to-image diffusion models. Complex prompts often lead to subject leakage,\ncausing inaccuracies in quantities, attributes, and visual features. Preventing\nleakage among subjects necessitates knowledge of each subject\\\'s spatial\nlocation. Recent methods provide these spatial locations via an external layout\ncontrol. However, enforcing such a prescribed layout often conflicts with the\ninnate layout dictated by the sampled initial noise, leading to misalignment\nwith the model\\\'s prior. In this work, we introduce a new approach that predicts\na spatial layout aligned with the prompt, derived from the initial noise, and\nrefines it throughout the denoising process. By relying on this noise-induced\nlayout, we avoid conflicts with externally imposed layouts and better preserve\nthe model\\\'s prior. Our method employs a small neural network to predict and\nrefine the evolving noise-induced layout at each denoising step, ensuring clear\nboundaries between subjects while maintaining consistency. Experimental results\nshow that this noise-aligned strategy achieves improved text-image alignment\nand more stable multi-subject generation compared to existing layout-guided\ntechniques, while preserving the rich diversity of the model\\\'s original\ndistribution.','Omer Dahary, Yehonathan Cohen, Or Patashnik, Kfir Aberman, Daniel Cohen-Or','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21488v1'),('2505.21493v1','Reinforcing General Reasoning without Verifiers','The recent paradigm shift towards training large language models (LLMs) using\nDeepSeek-R1-Zero-style reinforcement learning (RL) on verifiable rewards has\nled to impressive advancements in code and mathematical reasoning. However,\nthis methodology is limited to tasks where rule-based answer verification is\npossible and does not naturally extend to real-world domains such as chemistry,\nhealthcare, engineering, law, biology, business, and economics. Current\npractical workarounds use an additional LLM as a model-based verifier; however,\nthis introduces issues such as reliance on a strong verifier LLM,\nsusceptibility to reward hacking, and the practical burden of maintaining the\nverifier model in memory during training. To address this and extend\nDeepSeek-R1-Zero-style training to general reasoning domains, we propose a\nverifier-free method (VeriFree) that bypasses answer verification and instead\nuses RL to directly maximize the probability of generating the reference\nanswer. We compare VeriFree with verifier-based methods and demonstrate that,\nin addition to its significant practical benefits and reduced compute\nrequirements, VeriFree matches and even surpasses verifier-based methods on\nextensive evaluations across MMLU-Pro, GPQA, SuperGPQA, and math-related\nbenchmarks. Moreover, we provide insights into this method from multiple\nperspectives: as an elegant integration of training both the policy and\nimplicit verifier in a unified model, and as a variational optimization\napproach. Code is available at https://github.com/sail-sg/VeriFree.','Xiangxin Zhou, Zichen Liu, Anya Sims, Haonan Wang, Tianyu Pang, Chongxuan Li, Liang Wang, Min Lin, Chao Du','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21493v1'),('2505.21496v1','UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents','In this paper, we introduce UI-Genie, a self-improving framework addressing\ntwo key challenges in GUI agents: verification of trajectory outcome is\nchallenging and high-quality training data are not scalable. These challenges\nare addressed by a reward model and a self-improving pipeline, respectively.\nThe reward model, UI-Genie-RM, features an image-text interleaved architecture\nthat efficiently pro- cesses historical context and unifies action-level and\ntask-level rewards. To sup- port the training of UI-Genie-RM, we develop\ndeliberately-designed data genera- tion strategies including rule-based\nverification, controlled trajectory corruption, and hard negative mining. To\naddress the second challenge, a self-improvement pipeline progressively expands\nsolvable complex GUI tasks by enhancing both the agent and reward models\nthrough reward-guided exploration and outcome verification in dynamic\nenvironments. For training the model, we generate UI- Genie-RM-517k and\nUI-Genie-Agent-16k, establishing the first reward-specific dataset for GUI\nagents while demonstrating high-quality synthetic trajectory gen- eration\nwithout manual annotation. Experimental results show that UI-Genie achieves\nstate-of-the-art performance across multiple GUI agent benchmarks with three\ngenerations of data-model self-improvement. We open-source our complete\nframework implementation and generated datasets to facilitate further research\nin https://github.com/Euphoria16/UI-Genie.','Han Xiao, Guozhi Wang, Yuxiang Chai, Zimu Lu, Weifeng Lin, Hao He, Lue Fan, Liuyang Bian, Rui Hu, Liang Liu, Shuai Ren, Yafei Wen, Xiaoxin Chen, Aojun Zhou, Hongsheng Li','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21496v1'),('2505.21497v1','Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers','Academic poster generation is a crucial yet challenging task in scientific\ncommunication, requiring the compression of long-context interleaved documents\ninto a single, visually coherent page. To address this challenge, we introduce\nthe first benchmark and metric suite for poster generation, which pairs recent\nconference papers with author-designed posters and evaluates outputs on\n(i)Visual Quality-semantic alignment with human posters, (ii)Textual\nCoherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic\nand informational criteria scored by a VLM-as-judge, and notably\n(iv)PaperQuiz-the poster\\\'s ability to convey core paper content as measured by\nVLMs answering generated quizzes. Building on this benchmark, we propose\nPosterAgent, a top-down, visual-in-the-loop multi-agent pipeline: the (a)Parser\ndistills the paper into a structured asset library; the (b)Planner aligns\ntext-visual pairs into a binary-tree layout that preserves reading order and\nspatial balance; and the (c)Painter-Commenter loop refines each panel by\nexecuting rendering code and using VLM feedback to eliminate overflow and\nensure alignment. In our comprehensive evaluation, we find that GPT-4o\noutputs-though visually appealing at first glance-often exhibit noisy text and\npoor PaperQuiz scores, and we find that reader engagement is the primary\naesthetic bottleneck, as human-designed posters rely largely on visual\nsemantics to convey meaning. Our fully open-source variants (e.g. based on the\nQwen-2.5 series) outperform existing 4o-driven multi-agent systems across\nnearly all metrics, while using 87% fewer tokens. It transforms a 22-page paper\ninto a finalized yet editable .pptx poster - all for just $0.005. These\nfindings chart clear directions for the next generation of fully automated\nposter-generation models. The code and datasets are available at\nhttps://github.com/Paper2Poster/Paper2Poster.','Wei Pang, Kevin Qinghong Lin, Xiangru Jian, Xi He, Philip Torr','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21497v1'),('2505.21499v1','AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery','Vision-Language Model (VLM) based Web Agents represent a significant step\ntowards automating complex tasks by simulating human-like interaction with\nwebsites. However, their deployment in uncontrolled web environments introduces\nsignificant security vulnerabilities. Existing research on adversarial\nenvironmental injection attacks often relies on unrealistic assumptions, such\nas direct HTML manipulation, knowledge of user intent, or access to agent model\nparameters, limiting their practical applicability. In this paper, we propose\nAdInject, a novel and real-world black-box attack method that leverages the\ninternet advertising delivery to inject malicious content into the Web Agent\\\'s\nenvironment. AdInject operates under a significantly more realistic threat\nmodel than prior work, assuming a black-box agent, static malicious content\nconstraints, and no specific knowledge of user intent. AdInject includes\nstrategies for designing malicious ad content aimed at misleading agents into\nclicking, and a VLM-based ad content optimization technique that infers\npotential user intents from the target website\\\'s context and integrates these\nintents into the ad content to make it appear more relevant or critical to the\nagent\\\'s task, thus enhancing attack effectiveness. Experimental evaluations\ndemonstrate the effectiveness of AdInject, attack success rates exceeding 60%\nin most scenarios and approaching 100% in certain cases. This strongly\ndemonstrates that prevalent advertising delivery constitutes a potent and\nreal-world vector for environment injection attacks against Web Agents. This\nwork highlights a critical vulnerability in Web Agent security arising from\nreal-world environment manipulation channels, underscoring the urgent need for\ndeveloping robust defense mechanisms against such threats. Our code is\navailable at https://github.com/NicerWang/AdInject.','Haowei Wang, Junjie Wang, Xiaojun Jia, Rupeng Zhang, Mingyang Li, Zhe Liu, Yang Liu, Qing Wang','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.21499v1'),('2505.21500v1','ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models','Vision-language models (VLMs) have demonstrated remarkable capabilities in\nunderstanding and reasoning about visual content, but significant challenges\npersist in tasks requiring cross-viewpoint understanding and spatial reasoning.\nWe identify a critical limitation: current VLMs excel primarily at egocentric\nspatial reasoning (from the camera\\\'s perspective) but fail to generalize to\nallocentric viewpoints when required to adopt another entity\\\'s spatial frame of\nreference. We introduce ViewSpatial-Bench, the first comprehensive benchmark\ndesigned specifically for multi-viewpoint spatial localization recognition\nevaluation across five distinct task types, supported by an automated 3D\nannotation pipeline that generates precise directional labels. Comprehensive\nevaluation of diverse VLMs on ViewSpatial-Bench reveals a significant\nperformance disparity: models demonstrate reasonable performance on\ncamera-perspective tasks but exhibit reduced accuracy when reasoning from a\nhuman viewpoint. By fine-tuning VLMs on our multi-perspective spatial dataset,\nwe achieve an overall performance improvement of 46.24% across tasks,\nhighlighting the efficacy of our approach. Our work establishes a crucial\nbenchmark for spatial intelligence in embodied AI systems and provides\nempirical evidence that modeling 3D spatial relationships enhances VLMs\\\'\ncorresponding spatial comprehension capabilities.','Dingming Li, Hongxing Li, Zixuan Wang, Yuchen Yan, Hang Zhang, Siqi Chen, Guiyang Hou, Shengpei Jiang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Yueting Zhuang','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21500v1'),('2505.21503v1','Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making','Large language models (LLMs) have demonstrated strong potential in clinical\nquestion answering, with recent multi-agent frameworks further improving\ndiagnostic accuracy via collaborative reasoning. However, we identify a\nrecurring issue of Silent Agreement, where agents prematurely converge on\ndiagnoses without sufficient critical analysis, particularly in complex or\nambiguous cases. We present a new concept called Catfish Agent, a\nrole-specialized LLM designed to inject structured dissent and counter silent\nagreement. Inspired by the ``catfish effect\\\'\\\' in organizational psychology, the\nCatfish Agent is designed to challenge emerging consensus to stimulate deeper\nreasoning. We formulate two mechanisms to encourage effective and context-aware\ninterventions: (i) a complexity-aware intervention that modulates agent\nengagement based on case difficulty, and (ii) a tone-calibrated intervention\narticulated to balance critique and collaboration. Evaluations on nine medical\nQ&A and three medical VQA benchmarks show that our approach consistently\noutperforms both single- and multi-agent LLMs frameworks, including leading\ncommercial models such as GPT-4o and DeepSeek-R1.','Yihan Wang, Qiao Yan, Zhenghao Xing, Lihao Liu, Junjun He, Chi-Wing Fu, Xiaowei Hu, Pheng-Ann Heng','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21503v1'),('2505.21505v1','How does Alignment Enhance LLMs\\\' Multilingual Capabilities? A Language Neurons Perspective','Multilingual Alignment is an effective and representative paradigm to enhance\nLLMs\\\' multilingual capabilities, which transfers the capabilities from the\nhigh-resource languages to the low-resource languages. Meanwhile, some\nresearches on language-specific neurons reveal that there are language-specific\nneurons that are selectively activated in LLMs when processing different\nlanguages. This provides a new perspective to analyze and understand LLMs\\\'\nmechanisms more specifically in multilingual scenarios. In this work, we\npropose a new finer-grained neuron identification algorithm, which detects\nlanguage neurons~(including language-specific neurons and language-related\nneurons) and language-agnostic neurons. Furthermore, based on the\ndistributional characteristics of different types of neurons, we divide the\nLLMs\\\' internal process for multilingual inference into four parts: (1)\nmultilingual understanding, (2) shared semantic space reasoning, (3)\nmultilingual output space transformation, and (4) vocabulary space outputting.\nAdditionally, we systematically analyze the models before and after alignment\nwith a focus on different types of neurons. We also analyze the phenomenon of\n\\\'\\\'Spontaneous Multilingual Alignment\\\'\\\'. Overall, our work conducts a\ncomprehensive investigation based on different types of neurons, providing\nempirical results and valuable insights for better understanding multilingual\nalignment and multilingual capabilities of LLMs.','Shimao Zhang, Zhejian Lai, Xiang Liu, Shuaijie She, Xiao Liu, Yeyun Gong, Shujian Huang, Jiajun Chen','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21505v1'),('2505.21556v1','Benign-to-Toxic Jailbreaking: Inducing Harmful Responses from Harmless Prompts','Optimization-based jailbreaks typically adopt the Toxic-Continuation setting\nin large vision-language models (LVLMs), following the standard next-token\nprediction objective. In this setting, an adversarial image is optimized to\nmake the model predict the next token of a toxic prompt. However, we find that\nthe Toxic-Continuation paradigm is effective at continuing already-toxic\ninputs, but struggles to induce safety misalignment when explicit toxic signals\nare absent. We propose a new paradigm: Benign-to-Toxic (B2T) jailbreak. Unlike\nprior work, we optimize adversarial images to induce toxic outputs from benign\nconditioning. Since benign conditioning contains no safety violations, the\nimage alone must break the model\\\'s safety mechanisms. Our method outperforms\nprior approaches, transfers in black-box settings, and complements text-based\njailbreaks. These results reveal an underexplored vulnerability in multimodal\nalignment and introduce a fundamentally new direction for jailbreak approaches.','Hee-Seon Kim, Minbeom Kim, Wonjun Lee, Kihyun Kim, Changick Kim','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.21556v1'),('2505.21557v1','Analytical Calculation of Weights Convolutional Neural Network','This paper presents an algorithm for analytically calculating the weights and\nthresholds of convolutional neural networks (CNNs) without using standard\ntraining procedures. The algorithm enables the determination of CNN parameters\nbased on just 10 selected images from the MNIST dataset, each representing a\ndigit from 0 to 9. As part of the method, the number of channels in CNN layers\nis also derived analytically. A software module was implemented in C++ Builder,\nand a series of experiments were conducted using the MNIST dataset. Results\ndemonstrate that the analytically computed CNN can recognize over half of 1000\nhandwritten digit images without any training, achieving inference in fractions\nof a second. These findings suggest that CNNs can be constructed and applied\ndirectly for classification tasks without training, using purely analytical\ncomputation of weights.','Polad Geidarov','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.21557v1'),('2505.21558v1','A Novel Convolutional Neural Network-Based Framework for Complex Multiclass Brassica Seed Classification','Agricultural research has accelerated in recent years, yet farmers often lack\nthe time and resources for on-farm research due to the demands of crop\nproduction and farm operations. Seed classification offers valuable insights\ninto quality control, production efficiency, and impurity detection. Early\nidentification of seed types is critical to reducing the cost and risk\nassociated with field emergence, which can lead to yield losses or disruptions\nin downstream processes like harvesting. Seed sampling supports growers in\nmonitoring and managing seed quality, improving precision in determining seed\npurity levels, guiding management adjustments, and enhancing yield estimations.\nThis study proposes a novel convolutional neural network (CNN)-based framework\nfor the efficient classification of ten common Brassica seed types. The\napproach addresses the inherent challenge of texture similarity in seed images\nusing a custom-designed CNN architecture. The model\\\'s performance was evaluated\nagainst several pre-trained state-of-the-art architectures, with adjustments to\nlayer configurations for optimized classification. Experimental results using\nour collected Brassica seed dataset demonstrate that the proposed model\nachieved a high accuracy rate of 93 percent.','Elhoucine Elfatimia, Recep Eryigitb, Lahcen Elfatimi','2025-05-26','cs.CV','http://arxiv.org/pdf/2505.21558v1'),('2505.21559v1','Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems via an Automated Online Design Framework','In cloud-native systems, Kubernetes clusters with interdependent services\noften face challenges to their operational resilience due to poor workload\nmanagement issues such as resource blocking, bottlenecks, or continuous pod\ncrashes. These vulnerabilities are further amplified in adversarial scenarios,\nsuch as Distributed Denial-of-Service attacks (DDoS). Conventional Horizontal\nPod Autoscaling (HPA) approaches struggle to address such dynamic conditions,\nwhile reinforcement learning-based methods, though more adaptable, typically\noptimize single goals like latency or resource usage, neglecting broader\nfailure scenarios. We propose decomposing the overarching goal of maintaining\noperational resilience into failure-specific sub-goals delegated to\ncollaborative agents, collectively forming an HPA Multi-Agent System (MAS). We\nintroduce an automated, four-phase online framework for HPA MAS design: 1)\nmodeling a digital twin built from cluster traces; 2) training agents in\nsimulation using roles and missions tailored to failure contexts; 3) analyzing\nagent behaviors for explainability; and 4) transferring learned policies to the\nreal cluster. Experimental results demonstrate that the generated HPA MASs\noutperform three state-of-the-art HPA systems in sustaining operational\nresilience under various adversarial conditions in a proposed complex cluster.','Julien Soulé, Jean-Paul Jamont, Michel Occello, Louis-Marie Traonouez, Paul Théron','2025-05-26','cs.MA','http://arxiv.org/pdf/2505.21559v1'),('2505.21561v1','Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment','We introduce a novel deep learning framework for the automated staging of\nspheno-occipital synchondrosis (SOS) fusion, a critical diagnostic marker in\nboth orthodontics and forensic anthropology. Our approach leverages a\ndual-model architecture wherein a teacher model, trained on manually cropped\nimages, transfers its precise spatial understanding to a student model that\noperates on full, uncropped images. This knowledge distillation is facilitated\nby a newly formulated loss function that aligns spatial logits as well as\nincorporates gradient-based attention spatial mapping, ensuring that the\nstudent model internalizes the anatomically relevant features without relying\non external cropping or YOLO-based segmentation. By leveraging expert-curated\ndata and feedback at each step, our framework attains robust diagnostic\naccuracy, culminating in a clinically viable end-to-end pipeline. This\nstreamlined approach obviates the need for additional pre-processing tools and\naccelerates deployment, thereby enhancing both the efficiency and consistency\nof skeletal maturation assessment in diverse clinical settings.','Omid Halimi Milani, Amanda Nikho, Marouane Tliba, Lauren Mills, Ahmet Enis Cetin, Mohammed H Elnagar','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21561v1'),('2505.21562v1','Enhancing Selection of Climate Tech Startups with AI -- A Case Study on Integrating Human and AI Evaluations in the ClimaTech Great Global Innovation Challenge','This case study examines the ClimaTech Great Global Innovation Challenge\\\'s\napproach to selecting climate tech startups by integrating human and AI\nevaluations. The competition aimed to identify top startups and enhance the\naccuracy and efficiency of the selection process through a hybrid model.\nResearch shows data-driven approaches help VC firms reduce bias and improve\ndecision-making. Machine learning models have outperformed human investors in\ndeal screening, helping identify high-potential startups. Incorporating AI\naimed to ensure more equitable and objective evaluations.\n  The methodology included three phases: initial AI review, semi-finals judged\nby humans, and finals using a hybrid weighting. In phase one, 57 applications\nwere scored by an AI tool built with StackAI and OpenAI\\\'s GPT-4o, and the top\n36 advanced. In the semi-finals, human judges, unaware of AI scores, evaluated\nstartups on team quality, market potential, and technological innovation. Each\nscore - human or AI - was weighted equally, resulting in 75 percent human and\n25 percent AI influence. In the finals, with five human judges, weighting\nshifted to 83.3 percent human and 16.7 percent AI. There was a moderate\npositive correlation between AI and human scores - Spearman\\\'s = 0.47 -\nindicating general alignment with key differences. Notably, the final four\nstartups, selected mainly by humans, were among those rated highest by the AI.\nThis highlights the complementary nature of AI and human judgment. The study\nshows that hybrid models can streamline and improve startup assessments. The\nClimaTech approach offers a strong framework for future competitions by\ncombining human expertise with AI capabilities.','Jennifer Turliuk, Alejandro Sevilla, Daniela Gorza, Tod Hynes','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21562v1'),('2505.21563v1','Fog Intelligence for Network Anomaly Detection','Anomalies are common in network system monitoring. When manifested as network\nthreats to be mitigated, service outages to be prevented, and security risks to\nbe ameliorated, detecting such anomalous network behaviors becomes of great\nimportance. However, the growing scale and complexity of the mobile\ncommunication networks, as well as the ever-increasing amount and\ndimensionality of the network surveillance data, make it extremely difficult to\nmonitor a mobile network and discover abnormal network behaviors. Recent\nadvances in machine learning allow for obtaining near-optimal solutions to\ncomplicated decision-making problems with many sources of uncertainty that\ncannot be accurately characterized by traditional mathematical models. However,\nmost machine learning algorithms are centralized, which renders them\ninapplicable to a large-scale distributed wireless networks with tens of\nmillions of mobile devices. In this article, we present fog intelligence, a\ndistributed machine learning architecture that enables intelligent wireless\nnetwork management. It preserves the advantage of both edge processing and\ncentralized cloud computing. In addition, the proposed architecture is\nscalable, privacy-preserving, and well suited for intelligent management of a\ndistributed wireless network.','Kai Yang, Hui Ma, Shaoyu Dou','2025-05-27','cs.NI','http://arxiv.org/pdf/2505.21563v1'),('2505.21564v1','Multi-instance Learning as Downstream Task of Self-Supervised Learning-based Pre-trained Model','In deep multi-instance learning, the number of applicable instances depends\non the data set. In histopathology images, deep learning multi-instance\nlearners usually assume there are hundreds to thousands instances in a bag.\nHowever, when the number of instances in a bag increases to 256 in brain\nhematoma CT, learning becomes extremely difficult. In this paper, we address\nthis drawback. To overcome this problem, we propose using a pre-trained model\nwith self-supervised learning for the multi-instance learner as a downstream\ntask. With this method, even when the original target task suffers from the\nspurious correlation problem, we show improvements of 5% to 13% in accuracy and\n40% to 55% in the F1 measure for the hypodensity marker classification of brain\nhematoma CT.','Koki Matsuishi, Tsuyoshi Okita','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21564v1'),('2505.21565v1','Towards Human-Like Trajectory Prediction for Autonomous Driving: A Behavior-Centric Approach','Predicting the trajectories of vehicles is crucial for the development of\nautonomous driving (AD) systems, particularly in complex and dynamic traffic\nenvironments. In this study, we introduce HiT (Human-like Trajectory\nPrediction), a novel model designed to enhance trajectory prediction by\nincorporating behavior-aware modules and dynamic centrality measures. Unlike\ntraditional methods that primarily rely on static graph structures, HiT\nleverages a dynamic framework that accounts for both direct and indirect\ninteractions among traffic participants. This allows the model to capture the\nsubtle yet significant influences of surrounding vehicles, enabling more\naccurate and human-like predictions. To evaluate HiT\\\'s performance, we\nconducted extensive experiments using diverse and challenging real-world\ndatasets, including NGSIM, HighD, RounD, ApolloScape, and MoCAD++. The results\ndemonstrate that HiT consistently outperforms other top models across multiple\nmetrics, particularly excelling in scenarios involving aggressive driving\nbehaviors. This research presents a significant step forward in trajectory\nprediction, offering a more reliable and interpretable approach for enhancing\nthe safety and efficiency of fully autonomous driving systems.','Haicheng Liao, Zhenning Li, Guohui Zhang, Keqiang Li, Chengzhong Xu','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.21565v1'),('2505.21566v1','Diffusion Model-based Activity Completion for AI Motion Capture from Videos','AI-based motion capture is an emerging technology that offers a\ncost-effective alternative to traditional motion capture systems. However,\ncurrent AI motion capture methods rely entirely on observed video sequences,\nsimilar to conventional motion capture. This means that all human actions must\nbe predefined, and movements outside the observed sequences are not possible.\nTo address this limitation, we aim to apply AI motion capture to virtual\nhumans, where flexible actions beyond the observed sequences are required. We\nassume that while many action fragments exist in the training data, the\ntransitions between them may be missing. To bridge these gaps, we propose a\ndiffusion-model-based action completion technique that generates complementary\nhuman motion sequences, ensuring smooth and continuous movements. By\nintroducing a gate module and a position-time embedding module, our approach\nachieves competitive results on the Human3.6M dataset. Our experimental results\nshow that (1) MDC-Net outperforms existing methods in ADE, FDE, and MMADE but\nis slightly less accurate in MMFDE, (2) MDC-Net has a smaller model size\n(16.84M) compared to HumanMAC (28.40M), and (3) MDC-Net generates more natural\nand coherent motion sequences. Additionally, we propose a method for extracting\nsensor data, including acceleration and angular velocity, from human motion\nsequences.','Gao Huayu, Huang Tengjiu, Ye Xiaolong, Tsuyoshi Okita','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21566v1'),('2505.21567v1','EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models','With the development of Embodied Artificial intelligence, the end-to-end\ncontrol policy such as Vision-Language-Action (VLA) model has become the\nmainstream. Existing VLA models faces expensive computing/storage cost, which\nneed to be optimized. Quantization is considered as the most effective method\nwhich can not only reduce the memory cost but also achieve computation\nacceleration. However, we find the token alignment of VLA models hinders the\napplication of existing quantization methods. To address this, we proposed an\noptimized framework called EaqVLA, which apply encoding-aligned quantization to\nVLA models. Specifically, we propose an complete analysis method to find the\nmisalignment in various granularity. Based on the analysis results, we propose\na mixed precision quantization with the awareness of encoding alignment.\nExperiments shows that the porposed EaqVLA achieves better quantization\nperformance (with the minimal quantization loss for end-to-end action control\nand xxx times acceleration) than existing quantization methods.','Feng Jiang, Zihao Zheng, Xiuping Cui, Maoliang Li, JIayu Chen, Xiang Chen','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21567v1'),('2505.21568v1','VoiceMark: Zero-Shot Voice Cloning-Resistant Watermarking Approach Leveraging Speaker-Specific Latents','Voice cloning (VC)-resistant watermarking is an emerging technique for\ntracing and preventing unauthorized cloning. Existing methods effectively trace\ntraditional VC models by training them on watermarked audio but fail in\nzero-shot VC scenarios, where models synthesize audio from an audio prompt\nwithout training. To address this, we propose VoiceMark, the first zero-shot\nVC-resistant watermarking method that leverages speaker-specific latents as the\nwatermark carrier, allowing the watermark to transfer through the zero-shot VC\nprocess into the synthesized audio. Additionally, we introduce VC-simulated\naugmentations and VAD-based loss to enhance robustness against distortions.\nExperiments on multiple zero-shot VC models demonstrate that VoiceMark achieves\nover 95% accuracy in watermark detection after zero-shot VC synthesis,\nsignificantly outperforming existing methods, which only reach around 50%. See\nour code and demos at: https://huggingface.co/spaces/haiyunli/VoiceMark','Haiyun Li, Zhiyong Wu, Xiaofeng Xie, Jingran Xie, Yaoxun Xu, Hanyang Peng','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.21568v1'),('2505.21569v1','ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools','Large Language Model (LLM)-based agents have demonstrated the ability to\nimprove performance in chemistry-related tasks by selecting appropriate tools.\nHowever, their effectiveness remains limited by the inherent prediction errors\nof chemistry tools. In this paper, we take a step further by exploring how\nLLMbased agents can, in turn, be leveraged to reduce prediction errors of the\ntools. To this end, we propose ChemHAS (Chemical Hierarchical Agent Stacking),\na simple yet effective method that enhances chemistry tools through optimizing\nagent-stacking structures from limited data. ChemHAS achieves state-of-the-art\nperformance across four fundamental chemistry tasks, demonstrating that our\nmethod can effectively compensate for prediction errors of the tools.\nFurthermore, we identify and characterize four distinct agent-stacking\nbehaviors, potentially improving interpretability and revealing new\npossibilities for AI agent applications in scientific research. Our code and\ndataset are publicly available at https:\n//anonymous.4open.science/r/ChemHAS-01E4/README.md.','Zhucong Li, Bowei Zhang, Jin Xiao, Zhijian Zhou, Fenglei Cao, Jiaqing Liang, Yuan Qi','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21569v1'),('2505.21570v1','Beyond Explainability: The Case for AI Validation','Artificial Knowledge (AK) systems are transforming decision-making across\ncritical domains such as healthcare, finance, and criminal justice. However,\ntheir growing opacity presents governance challenges that current regulatory\napproaches, focused predominantly on explainability, fail to address\nadequately. This article argues for a shift toward validation as a central\nregulatory pillar. Validation, ensuring the reliability, consistency, and\nrobustness of AI outputs, offers a more practical, scalable, and risk-sensitive\nalternative to explainability, particularly in high-stakes contexts where\ninterpretability may be technically or economically unfeasible. We introduce a\ntypology based on two axes, validity and explainability, classifying AK systems\ninto four categories and exposing the trade-offs between interpretability and\noutput reliability. Drawing on comparative analysis of regulatory approaches in\nthe EU, US, UK, and China, we show how validation can enhance societal trust,\nfairness, and safety even where explainability is limited. We propose a\nforward-looking policy framework centered on pre- and post-deployment\nvalidation, third-party auditing, harmonized standards, and liability\nincentives. This framework balances innovation with accountability and provides\na governance roadmap for responsibly integrating opaque, high-performing AK\nsystems into society.','Dalit Ken-Dror Feldman, Daniel Benoliel','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21570v1'),('2505.21571v1','FCOS: A Two-Stage Recoverable Model Pruning Framework for Automatic Modulation Recognition','With the rapid development of wireless communications and the growing\ncomplexity of digital modulation schemes, traditional manual modulation\nrecognition methods struggle to extract reliable signal features and meet\nreal-time requirements in modern scenarios. Recently, deep learning based\nAutomatic Modulation Recognition (AMR) approaches have greatly improved\nclassification accuracy. However, their large model sizes and high\ncomputational demands hinder deployment on resource-constrained devices. Model\npruning provides a general approach to reduce model complexity, but existing\nweight, channel, and layer pruning techniques each present a trade-off between\ncompression rate, hardware acceleration, and accuracy preservation. To this\nend, in this paper, we introduce FCOS, a novel Fine-to-COarse two-Stage pruning\nframework that combines channel-level pruning with layer-level collapse\ndiagnosis to achieve extreme compression, high performance and efficient\ninference. In the first stage of FCOS, hierarchical clustering and parameter\nfusion are applied to channel weights to achieve channel-level pruning. Then a\nLayer Collapse Diagnosis (LaCD) module uses linear probing to identify layer\ncollapse and removes the collapsed layers due to high channel compression\nratio. Experiments on multiple AMR benchmarks demonstrate that FCOS outperforms\nexisting channel and layer pruning methods. Specifically, FCOS achieves 95.51%\nFLOPs reduction and 95.31% parameter reduction while still maintaining\nperformance close to the original ResNet56, with only a 0.46% drop in accuracy\non Sig2019-12. Code is available at https://github.com/yaolu-zjut/FCOS.','Yao Lu, Tengfei Ma, Zeyu Wang, Zhuangzhi Chen, Dongwei Xu, Yun Lin, Qi Xuan, Guan Gui','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21571v1'),('2505.21572v1','Thickness-aware E(3)-Equivariant 3D Mesh Neural Networks','Mesh-based 3D static analysis methods have recently emerged as efficient\nalternatives to traditional computational numerical solvers, significantly\nreducing computational costs and runtime for various physics-based analyses.\nHowever, these methods primarily focus on surface topology and geometry, often\noverlooking the inherent thickness of real-world 3D objects, which exhibits\nhigh correlations and similar behavior between opposing surfaces. This\nlimitation arises from the disconnected nature of these surfaces and the\nabsence of internal edge connections within the mesh. In this work, we propose\na novel framework, the Thickness-aware E(3)-Equivariant 3D Mesh Neural Network\n(T-EMNN), that effectively integrates the thickness of 3D objects while\nmaintaining the computational efficiency of surface meshes. Additionally, we\nintroduce data-driven coordinates that encode spatial information while\npreserving E(3)-equivariance or invariance properties, ensuring consistent and\nrobust analysis. Evaluations on a real-world industrial dataset demonstrate the\nsuperior performance of T-EMNN in accurately predicting node-level 3D\ndeformations, effectively capturing thickness effects while maintaining\ncomputational efficiency.','Sungwon Kim, Namkyeong Lee, Yunyoung Doh, Seungmin Shin, Guimok Cho, Seung-Won Jeon, Sangkook Kim, Chanyoung Park','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21572v1'),('2505.21573v1','Spectral-inspired Neural Operator for Data-efficient PDE Simulation in Physics-agnostic Regimes','Partial differential equations (PDEs) govern the spatiotemporal evolution of\nvarious physical systems. Classical numerical solvers, while accurate, require\nfine discretization and full knowledge of the governing PDEs, limiting their\napplicability when the physics is unknown or fast inference is required.\nData-driven neural PDE solvers alleviate these constraints by learning from\ndata but demand large training datasets and perform poorly in data-scarce\nregimes. Physics-aware methods mitigate data requirements by incorporating\nphysical knowledge yet rely on known PDE terms or local numerical schemes,\nrestricting their ability to handle unknown or globally coupled systems. In\nthis work, we propose the Spectral-inspired Neural Operator (SINO), a novel\nframework that learns PDE operators from limited trajectories (as few as 2-5),\nwithout any known PDE terms. SINO operates in the frequency domain and\nintroduces a Frequency-to-Vector module to learn spectral representations\nanalogous to derivative multipliers. To model nonlinear physical interactions,\nwe design a nonlinear operator block that includes a $\\Pi$-Block with low-pass\nfiltering to prevent aliasing. Finally, we introduce an operator distillation\ntechnique to distill the trained model for efficient inference. SINO achieves\nstate-of-the-art results across multiple PDE benchmarks, demonstrating strong\ndiscretization invariance and robust generalization to out-of-distribution\ninitial conditions. To our knowledge, SINO is the first physics-aware method\ncapable of accurately simulating globally coupled systems (e.g., the\nNavier-Stokes equations) from limited data without any explicit PDE terms.','Han Wan, Rui Zhang, Hao Sun','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21573v1'),('2505.21574v1','Do We Need All the Synthetic Data? Towards Targeted Synthetic Image Augmentation via Diffusion Models','Synthetically augmenting training datasets with diffusion models has been an\neffective strategy for improving generalization of image classifiers. However,\nexisting techniques struggle to ensure the diversity of generation and increase\nthe size of the data by up to 10-30x to improve the in-distribution\nperformance. In this work, we show that synthetically augmenting part of the\ndata that is not learned early in training outperforms augmenting the entire\ndataset. By analyzing a two-layer CNN, we prove that this strategy improves\ngeneralization by promoting homogeneity in feature learning speed without\namplifying noise. Our extensive experiments show that by augmenting only\n30%-40% of the data, our method boosts the performance by up to 2.8% in a\nvariety of scenarios, including training ResNet, ViT and DenseNet on CIFAR-10,\nCIFAR-100, and TinyImageNet, with a range of optimizers including SGD and SAM.\nNotably, our method applied with SGD outperforms the SOTA optimizer, SAM, on\nCIFAR-100 and TinyImageNet. It can also easily stack with existing weak and\nstrong augmentation strategies to further boost the performance.','Dang Nguyen, Jiping Li, Jinghao Zheng, Baharan Mirzasoleiman','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21574v1'),('2505.21575v1','StreamLink: Large-Language-Model Driven Distributed Data Engineering System','Large Language Models (LLMs) have shown remarkable proficiency in natural\nlanguage understanding (NLU), opening doors for innovative applications. We\nintroduce StreamLink - an LLM-driven distributed data system designed to\nimprove the efficiency and accessibility of data engineering tasks. We build\nStreamLink on top of distributed frameworks such as Apache Spark and Hadoop to\nhandle large data at scale. One of the important design philosophies of\nStreamLink is to respect user data privacy by utilizing local fine-tuned LLMs\ninstead of a public AI service like ChatGPT. With help from domain-adapted\nLLMs, we can improve our system\\\'s understanding of natural language queries\nfrom users in various scenarios and simplify the procedure of generating\ndatabase queries like the Structured Query Language (SQL) for information\nprocessing. We also incorporate LLM-based syntax and security checkers to\nguarantee the reliability and safety of each generated query. StreamLink\nillustrates the potential of merging generative LLMs with distributed data\nprocessing for comprehensive and user-centric data engineering. With this\narchitecture, we allow users to interact with complex database systems at\ndifferent scales in a user-friendly and security-ensured manner, where the SQL\ngeneration reaches over 10\\% of execution accuracy compared to baseline\nmethods, and allow users to find the most concerned item from hundreds of\nmillions of items within a few seconds using natural language.','Dawei Feng, Di Mei, Huiri Tan, Lei Ren, Xianying Lou, Zhangxi Tan','2025-05-27','cs.DB','http://arxiv.org/pdf/2505.21575v1'),('2505.21576v1','Concentration Distribution Learning from Label Distributions','Label distribution learning (LDL) is an effective method to predict the\nrelative label description degree (a.k.a. label distribution) of a sample.\nHowever, the label distribution is not a complete representation of an instance\nbecause it overlooks the absolute intensity of each label. Specifically, it\\\'s\nimpossible to obtain the total description degree of hidden labels that not in\nthe label space, which leads to the loss of information and confusion in\ninstances. To solve the above problem, we come up with a new concept named\nbackground concentration to serve as the absolute description degree term of\nthe label distribution and introduce it into the LDL process, forming the\nimproved paradigm of concentration distribution learning. Moreover, we propose\na novel model by probabilistic methods and neural networks to learn label\ndistributions and background concentrations from existing LDL datasets.\nExtensive experiments prove that the proposed approach is able to extract\nbackground concentrations from label distributions while producing more\naccurate prediction results than the state-of-the-art LDL methods. The code is\navailable in https://github.com/seutjw/CDL-LD.','Jiawei Tang, Yuheng Jia','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21576v1'),('2505.21577v1','RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving','The ultimate goal of code agents is to solve complex tasks autonomously.\nAlthough large language models (LLMs) have made substantial progress in code\ngeneration, real-world tasks typically demand full-fledged code repositories\nrather than simple scripts. Building such repositories from scratch remains a\nmajor challenge. Fortunately, GitHub hosts a vast, evolving collection of\nopen-source repositories, which developers frequently reuse as modular\ncomponents for complex tasks. Yet, existing frameworks like OpenHands and\nSWE-Agent still struggle to effectively leverage these valuable resources.\nRelying solely on README files provides insufficient guidance, and deeper\nexploration reveals two core obstacles: overwhelming information and tangled\ndependencies of repositories, both constrained by the limited context windows\nof current LLMs. To tackle these issues, we propose RepoMaster, an autonomous\nagent framework designed to explore and reuse GitHub repositories for solving\ncomplex tasks. For efficient understanding, RepoMaster constructs function-call\ngraphs, module-dependency graphs, and hierarchical code trees to identify\nessential components, providing only identified core elements to the LLMs\nrather than the entire repository. During autonomous execution, it\nprogressively explores related components using our exploration tools and\nprunes information to optimize context usage. Evaluated on the adjusted\nMLE-bench, RepoMaster achieves a 110% relative boost in valid submissions over\nthe strongest baseline OpenHands. On our newly released GitTaskBench,\nRepoMaster lifts the task-pass rate from 24.1% to 62.9% while reducing token\nusage by 95%. Our code and demonstration materials are publicly available at\nhttps://github.com/wanghuacan/RepoMaster.','Huacan Wang, Ziyi Ni, Shuo Zhang, Shuo Lu, Sen Hu, Ziyang He, Chen Hu, Jiaye Lin, Yifu Guo, Yuntao Du, Pin Lyu','2025-05-27','cs.SE','http://arxiv.org/pdf/2505.21577v1'),('2505.21578v1','Loquacious Set: 25,000 Hours of Transcribed and Diverse English Speech Recognition Data for Research and Commercial Use','Automatic speech recognition (ASR) research is driven by the availability of\ncommon datasets between industrial researchers and academics, encouraging\ncomparisons and evaluations. LibriSpeech, despite its long success as an ASR\nbenchmark, is now limited by its size and focus on clean, read speech, leading\nto near-zero word error rates. More recent datasets, including MOSEL, YODAS,\nGigaspeech, OWSM, Libriheavy or People\\\'s Speech suffer from major limitations\nincluding licenses that researchers in the industry cannot use, unreliable\ntranscriptions, incorrect audio data, or the lack of evaluation sets. This work\npresents the Loquacious Set, a 25,000-hour curated collection of commercially\nusable English speech. Featuring hundreds of thousands of speakers with diverse\naccents and a wide range of speech types (read, spontaneous, talks, clean,\nnoisy), the Loquacious Set is designed to work for academics and researchers in\nthe industry to build ASR systems in real-world scenarios.','Titouan Parcollet, Yuan Tseng, Shucong Zhang, Rogier van Dalen','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21578v1'),('2505.21580v1','A Kernelised Stein Discrepancy for Assessing the Fit of Inhomogeneous Random Graph Models','Complex data are often represented as a graph, which in turn can often be\nviewed as a realisation of a random graph, such as of an inhomogeneous random\ngraph model (IRG). For general fast goodness-of-fit tests in high dimensions,\nkernelised Stein discrepancy (KSD) tests are a powerful tool. Here, we develop,\ntest, and analyse a KSD-type goodness-of-fit test for IRG models that can be\ncarried out with a single observation of the network. The test is applicable to\na network of any size and does not depend on the asymptotic distribution of the\ntest statistic. We also provide theoretical guarantees.','Anum Fatima, Gesine Reinert','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.21580v1'),('2505.21582v1','AITEE -- Agentic Tutor for Electrical Engineering','Intelligent tutoring systems combined with large language models offer a\npromising approach to address students\\\' diverse needs and promote\nself-efficacious learning. While large language models possess good\nfoundational knowledge of electrical engineering basics, they remain\ninsufficiently capable of addressing specific questions about electrical\ncircuits. In this paper, we present AITEE, an agent-based tutoring system for\nelectrical engineering designed to accompany students throughout their learning\nprocess, offer individualized support, and promote self-directed learning.\nAITEE supports both hand-drawn and digital circuits through an adapted circuit\nreconstruction process, enabling natural interaction with students. Our novel\ngraph-based similarity measure identifies relevant context from lecture\nmaterials through a retrieval augmented generation approach, while parallel\nSpice simulation further enhances accuracy in applying solution methodologies.\nThe system implements a Socratic dialogue to foster learner autonomy through\nguided questioning. Experimental evaluations demonstrate that AITEE\nsignificantly outperforms baseline approaches in domain-specific knowledge\napplication, with even medium-sized LLM models showing acceptable performance.\nOur results highlight the potential of agentic tutors to deliver scalable,\npersonalized, and effective learning environments for electrical engineering\neducation.','Christopher Knievel, Alexander Bernhardt, Christian Bernhardt','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21582v1'),('2505.21584v1','Fairness in Federated Learning: Fairness for Whom?','Fairness in federated learning has emerged as a rapidly growing area of\nresearch, with numerous works proposing formal definitions and algorithmic\ninterventions. Yet, despite this technical progress, fairness in FL is often\ndefined and evaluated in ways that abstract away from the sociotechnical\ncontexts in which these systems are deployed. In this paper, we argue that\nexisting approaches tend to optimize narrow system level metrics, such as\nperformance parity or contribution-based rewards, while overlooking how harms\narise throughout the FL lifecycle and how they impact diverse stakeholders. We\nsupport this claim through a critical analysis of the literature, based on a\nsystematic annotation of papers for their fairness definitions, design\ndecisions, evaluation practices, and motivating use cases. Our analysis reveals\nfive recurring pitfalls: 1) fairness framed solely through the lens of server\nclient architecture, 2) a mismatch between simulations and motivating use-cases\nand contexts, 3) definitions that conflate protecting the system with\nprotecting its users, 4) interventions that target isolated stages of the\nlifecycle while neglecting upstream and downstream effects, 5) and a lack of\nmulti-stakeholder alignment where multiple fairness definitions can be relevant\nat once. Building on these insights, we propose a harm centered framework that\nlinks fairness definitions to concrete risks and stakeholder vulnerabilities.\nWe conclude with recommendations for more holistic, context-aware, and\naccountable fairness research in FL.','Afaf Taik, Khaoula Chehbouni, Golnoosh Farnadi','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21584v1'),('2505.21587v1','CellCLAT: Preserving Topology and Trimming Redundancy in Self-Supervised Cellular Contrastive Learning','Self-supervised topological deep learning (TDL) represents a nascent but\nunderexplored area with significant potential for modeling higher-order\ninteractions in simplicial complexes and cellular complexes to derive\nrepresentations of unlabeled graphs. Compared to simplicial complexes, cellular\ncomplexes exhibit greater expressive power. However, the advancement in\nself-supervised learning for cellular TDL is largely hindered by two core\nchallenges: \\textit{extrinsic structural constraints} inherent to cellular\ncomplexes, and intrinsic semantic redundancy in cellular representations. The\nfirst challenge highlights that traditional graph augmentation techniques may\ncompromise the integrity of higher-order cellular interactions, while the\nsecond underscores that topological redundancy in cellular complexes\npotentially diminish task-relevant information. To address these issues, we\nintroduce Cellular Complex Contrastive Learning with Adaptive Trimming\n(CellCLAT), a twofold framework designed to adhere to the combinatorial\nconstraints of cellular complexes while mitigating informational redundancy.\nSpecifically, we propose a parameter perturbation-based augmentation method\nthat injects controlled noise into cellular interactions without altering the\nunderlying cellular structures, thereby preserving cellular topology during\ncontrastive learning. Additionally, a cellular trimming scheduler is employed\nto mask gradient contributions from task-irrelevant cells through a bi-level\nmeta-learning approach, effectively removing redundant topological elements\nwhile maintaining critical higher-order semantics. We provide theoretical\njustification and empirical validation to demonstrate that CellCLAT achieves\nsubstantial improvements over existing self-supervised graph learning methods,\nmarking a significant attempt in this domain.','Bin Qin, Qirui Ji, Jiangmeng Li, Yupeng Wang, Xuesong Wu, Jianwen Cao, Fanjiang Xu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21587v1'),('2505.21588v1','Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems','Recent advancements in Large Language Models (LLMs) have enabled the\nemergence of multi-agent systems where LLMs interact, collaborate, and make\ndecisions in shared environments. While individual model behavior has been\nextensively studied, the dynamics of peer influence in such systems remain\nunderexplored. In this paper, we investigate herd behavior, the tendency of\nagents to align their outputs with those of their peers, within LLM-based\nmulti-agent interactions. We present a series of controlled experiments that\nreveal how herd behaviors are shaped by multiple factors. First, we show that\nthe gap between self-confidence and perceived confidence in peers significantly\nimpacts an agent\\\'s likelihood to conform. Second, we find that the format in\nwhich peer information is presented plays a critical role in modulating the\nstrength of herd behavior. Finally, we demonstrate that the degree of herd\nbehavior can be systematically controlled, and that appropriately calibrated\nherd tendencies can enhance collaborative outcomes. These findings offer new\ninsights into the social dynamics of LLM-based systems and open pathways for\ndesigning more effective and adaptive multi-agent collaboration frameworks.','Young-Min Cho, Sharath Chandra Guntuku, Lyle Ungar','2025-05-27','cs.MA','http://arxiv.org/pdf/2505.21588v1'),('2505.21589v1','Do you see what I see? An Ambiguous Optical Illusion Dataset exposing limitations of Explainable AI','From uncertainty quantification to real-world object detection, we recognize\nthe importance of machine learning algorithms, particularly in safety-critical\ndomains such as autonomous driving or medical diagnostics. In machine learning,\nambiguous data plays an important role in various machine learning domains.\nOptical illusions present a compelling area of study in this context, as they\noffer insight into the limitations of both human and machine perception.\nDespite this relevance, optical illusion datasets remain scarce. In this work,\nwe introduce a novel dataset of optical illusions featuring intermingled animal\npairs designed to evoke perceptual ambiguity. We identify generalizable visual\nconcepts, particularly gaze direction and eye cues, as subtle yet impactful\nfeatures that significantly influence model accuracy. By confronting models\nwith perceptual ambiguity, our findings underscore the importance of concepts\nin visual learning and provide a foundation for studying bias and alignment\nbetween human and machine vision. To make this dataset useful for general\npurposes, we generate optical illusions systematically with different concepts\ndiscussed in our bias mitigation section. The dataset is accessible in Kaggle\nvia\nhttps://kaggle.com/datasets/693bf7c6dd2cb45c8a863f9177350c8f9849a9508e9d50526e2ffcc5559a8333.\nOur source code can be found at\nhttps://github.com/KDD-OpenSource/Ambivision.git.','Carina Newen, Luca Hinkamp, Maria Ntonti, Emmanuel Müller','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21589v1'),('2505.21591v1','Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning','Model quantization reduces the bit-width of weights and activations,\nimproving memory efficiency and inference speed in diffusion models. However,\nachieving 4-bit quantization remains challenging. Existing methods, primarily\nbased on integer quantization and post-training quantization fine-tuning,\nstruggle with inconsistent performance. Inspired by the success of\nfloating-point (FP) quantization in large language models, we explore low-bit\nFP quantization for diffusion models and identify key challenges: the failure\nof signed FP quantization to handle asymmetric activation distributions, the\ninsufficient consideration of temporal complexity in the denoising process\nduring fine-tuning, and the misalignment between fine-tuning loss and\nquantization error. To address these challenges, we propose the mixup-sign\nfloating-point quantization (MSFP) framework, first introducing unsigned FP\nquantization in model quantization, along with timestep-aware LoRA (TALoRA) and\ndenoising-factor loss alignment (DFA), which ensure precise and stable\nfine-tuning. Extensive experiments show that we are the first to achieve\nsuperior performance in 4-bit FP quantization for diffusion models,\noutperforming existing PTQ fine-tuning methods in 4-bit INT quantization.','Maosen Zhao, Pengtao Chen, Chong Yu, Yan Wen, Xudong Tan, Tao Chen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21591v1'),('2505.21592v1','Taylor expansion-based Kolmogorov-Arnold network for blind image quality assessment','Kolmogorov-Arnold Network (KAN) has attracted growing interest for its strong\nfunction approximation capability. In our previous work, KAN and its variants\nwere explored in score regression for blind image quality assessment (BIQA).\nHowever, these models encounter challenges when processing high-dimensional\nfeatures, leading to limited performance gains and increased computational\ncost. To address these issues, we propose TaylorKAN that leverages the Taylor\nexpansions as learnable activation functions to enhance local approximation\ncapability. To improve the computational efficiency, network depth reduction\nand feature dimensionality compression are integrated into the TaylorKAN-based\nscore regression pipeline. On five databases (BID, CLIVE, KonIQ, SPAQ, and\nFLIVE) with authentic distortions, extensive experiments demonstrate that\nTaylorKAN consistently outperforms the other KAN-related models, indicating\nthat the local approximation via Taylor expansions is more effective than\nglobal approximation using orthogonal functions. Its generalization capacity is\nvalidated through inter-database experiments. The findings highlight the\npotential of TaylorKAN as an efficient and robust model for high-dimensional\nscore regression.','Ze Chen, Shaode Yu','2025-05-27','eess.IV','http://arxiv.org/pdf/2505.21592v1'),('2505.21593v1','Any-to-Bokeh: One-Step Video Bokeh via Multi-Plane Image Guided Diffusion','Recent advances in diffusion based editing models have enabled realistic\ncamera simulation and image-based bokeh, but video bokeh remains largely\nunexplored. Existing video editing models cannot explicitly control focus\nplanes or adjust bokeh intensity, limiting their applicability for controllable\noptical effects. Moreover, naively extending image-based bokeh methods to video\noften results in temporal flickering and unsatisfactory edge blur transitions\ndue to the lack of temporal modeling and generalization capability. To address\nthese challenges, we propose a novel one-step video bokeh framework that\nconverts arbitrary input videos into temporally coherent, depth-aware bokeh\neffects. Our method leverages a multi-plane image (MPI) representation\nconstructed through a progressively widening depth sampling function, providing\nexplicit geometric guidance for depth-dependent blur synthesis. By conditioning\na single-step video diffusion model on MPI layers and utilizing the strong 3D\npriors from pre-trained models such as Stable Video Diffusion, our approach\nachieves realistic and consistent bokeh effects across diverse scenes.\nAdditionally, we introduce a progressive training strategy to enhance temporal\nconsistency, depth robustness, and detail preservation. Extensive experiments\ndemonstrate that our method produces high-quality, controllable bokeh effects\nand achieves state-of-the-art performance on multiple evaluation benchmarks.','Yang Yang, Siming Zheng, Jinwei Chen, Boxi Wu, Xiaofei He, Deng Cai, Bo Li, Peng-Tao Jiang','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21593v1'),('2505.21594v1','Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits','Large Language Models (LLMs) enable various applications on edge devices such\nas smartphones, wearables, and embodied robots. However, their deployment often\ndepends on expensive cloud-based APIs, creating high operational costs, which\nlimit access for smaller organizations and raise sustainability concerns.\nCertain LLMs can be deployed on-device, offering a cost-effective solution with\nreduced latency and improved privacy. Yet, limited computing resources\nconstrain the size and accuracy of models that can be deployed, necessitating a\ncollaborative design between edge and cloud. We propose a fast and\ncost-effective speculative edge-cloud decoding framework with a large target\nmodel on the server and a small draft model on the device. By introducing early\nexits in the target model, tokens are generated mid-verification, allowing the\nclient to preemptively draft subsequent tokens before final verification, thus\nutilizing idle time and enhancing parallelism between edge and cloud. Using an\nNVIDIA Jetson Nano (client) and an A100 GPU (server) with Vicuna-68M (draft)\nand Llama2-7B (target) models, our method achieves up to a 35% reduction in\nlatency compared to cloud-based autoregressive decoding, with an additional 11%\nimprovement from preemptive drafting. To demonstrate real-world applicability,\nwe deploy our method on the Unitree Go2 quadruped robot using Vision-Language\nModel (VLM) based control, achieving a 21% speedup over traditional cloud-based\nautoregressive decoding. These results demonstrate the potential of our\nframework for real-time LLM and VLM applications on resource-constrained edge\ndevices.','Yeshwanth Venkatesha, Souvik Kundu, Priyadarshini Panda','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.21594v1'),('2505.21595v1','Relevance-driven Input Dropout: an Explanation-guided Regularization Technique','Overfitting is a well-known issue extending even to state-of-the-art (SOTA)\nMachine Learning (ML) models, resulting in reduced generalization, and a\nsignificant train-test performance gap. Mitigation measures include a\ncombination of dropout, data augmentation, weight decay, and other\nregularization techniques. Among the various data augmentation strategies,\nocclusion is a prominent technique that typically focuses on randomly masking\nregions of the input during training. Most of the existing literature\nemphasizes randomness in selecting and modifying the input features instead of\nregions that strongly influence model decisions. We propose Relevance-driven\nInput Dropout (RelDrop), a novel data augmentation method which selectively\noccludes the most relevant regions of the input, nudging the model to use other\nimportant features in the prediction process, thus improving model\ngeneralization through informed regularization. We further conduct qualitative\nand quantitative analyses to study how Relevance-driven Input Dropout (RelDrop)\naffects model decision-making. Through a series of experiments on benchmark\ndatasets, we demonstrate that our approach improves robustness towards\nocclusion, results in models utilizing more features within the region of\ninterest, and boosts inference time generalization performance. Our code is\navailable at https://github.com/Shreyas-Gururaj/LRP_Relevance_Dropout.','Shreyas Gururaj, Lars Grüne, Wojciech Samek, Sebastian Lapuschkin, Leander Weber','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21595v1'),('2505.21596v1','Learning optimal treatment strategies for intraoperative hypotension using deep reinforcement learning','Traditional methods of surgical decision making heavily rely on human\nexperience and prompt actions, which are variable. A data-driven system\ngenerating treatment recommendations based on patient states can be a\nsubstantial asset in perioperative decision-making, as in cases of\nintraoperative hypotension, for which suboptimal management is associated with\nacute kidney injury (AKI), a common and morbid postoperative complication. We\ndeveloped a Reinforcement Learning (RL) model to recommend optimum dose of\nintravenous (IV) fluid and vasopressors during surgery to avoid intraoperative\nhypotension and postoperative AKI. We retrospectively analyzed 50,021 surgeries\nfrom 42,547 adult patients who underwent major surgery at a quaternary care\nhospital between June 2014 and September 2020. Of these, 34,186 surgeries were\nused for model training and 15,835 surgeries were reserved for testing. We\ndeveloped a Deep Q-Networks based RL model using 16 variables including\nintraoperative physiologic time series, total dose of IV fluid and vasopressors\nextracted for every 15-minute epoch. The model replicated 69% of physician\\\'s\ndecisions for the dosage of vasopressors and proposed higher or lower dosage of\nvasopressors than received in 10% and 21% of the treatments, respectively. In\nterms of IV fluids, the model\\\'s recommendations were within 0.05 ml/kg/15 min\nof the actual dose in 41% of the cases, with higher or lower doses recommended\nfor 27% and 32% of the treatments, respectively. The model resulted in a higher\nestimated policy value compared to the physicians\\\' actual treatments, as well\nas random and zero-drug policies. AKI prevalence was the lowest in patients\nreceiving medication dosages that aligned with model\\\'s decisions. Our findings\nsuggest that implementation of the model\\\'s policy has the potential to reduce\npostoperative AKI and improve other outcomes driven by intraoperative\nhypotension.','Esra Adiyeke, Tianqi Liu, Venkata Sai Dheeraj Naganaboina, Han Li, Tyler J. Loftus, Yuanfang Ren, Benjamin Shickel, Matthew M. Ruppert, Karandeep Singh, Ruogu Fang, Parisa Rashidi, Azra Bihorac, Tezcan Ozrazgat-Baslanti','2025-05-27','q-bio.QM','http://arxiv.org/pdf/2505.21596v1'),('2505.21597v1','Optimizing Deep Learning for Skin Cancer Classification: A Computationally Efficient CNN with Minimal Accuracy Trade-Off','The rapid advancement of deep learning in medical image analysis has greatly\nenhanced the accuracy of skin cancer classification. However, current\nstate-of-the-art models, especially those based on transfer learning like\nResNet50, come with significant computational overhead, rendering them\nimpractical for deployment in resource-constrained environments. This study\nproposes a custom CNN model that achieves a 96.7\\% reduction in parameters\n(from 23.9 million in ResNet50 to 692,000) while maintaining a classification\naccuracy deviation of less than 0.022\\%. Our empirical analysis of the HAM10000\ndataset reveals that although transfer learning models provide a marginal\naccuracy improvement of approximately 0.022\\%, they result in a staggering\n13,216.76\\% increase in FLOPs, considerably raising computational costs and\ninference latency. In contrast, our lightweight CNN architecture, which\nencompasses only 30.04 million FLOPs compared to ResNet50\\\'s 4.00 billion,\nsignificantly reduces energy consumption, memory footprint, and inference time.\nThese findings underscore the trade-off between the complexity of deep models\nand their real-world feasibility, positioning our optimized CNN as a practical\nsolution for mobile and edge-based skin cancer diagnostics.','Abdullah Al Mamun, Pollob Chandra Ray, Md Rahat Ul Nasib, Akash Das, Jia Uddin, Md Nurul Absur','2025-05-27','eess.IV','http://arxiv.org/pdf/2505.21597v1'),('2505.21598v1','Rethinking Data Mixture for Large Language Models: A Comprehensive Survey and New Perspectives','Training large language models with data collected from various domains can\nimprove their performance on downstream tasks. However, given a fixed training\nbudget, the sampling proportions of these different domains significantly\nimpact the model\\\'s performance. How can we determine the domain weights across\ndifferent data domains to train the best-performing model within constrained\ncomputational resources? In this paper, we provide a comprehensive overview of\nexisting data mixture methods. First, we propose a fine-grained categorization\nof existing methods, extending beyond the previous offline and online\nclassification. Offline methods are further grouped into heuristic-based,\nalgorithm-based, and function fitting-based methods. For online methods, we\ncategorize them into three groups: online min-max optimization, online mixing\nlaw, and other approaches by drawing connections with the optimization\nframeworks underlying offline methods. Second, we summarize the problem\nformulations, representative algorithms for each subtype of offline and online\nmethods, and clarify the relationships and distinctions among them. Finally, we\ndiscuss the advantages and disadvantages of each method and highlight key\nchallenges in the field of data mixture.','Yajiao Liu, Congliang Chen, Junchi Yang, Ruoyu Sun','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21598v1'),('2505.21600v1','R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing','Large Language Models (LLMs) achieve impressive reasoning capabilities at the\ncost of substantial inference overhead, posing substantial deployment\nchallenges. Although distilled Small Language Models (SLMs) significantly\nenhance efficiency, their performance suffers as they fail to follow LLMs\\\'\nreasoning paths. Luckily, we reveal that only a small fraction of tokens\ngenuinely diverge reasoning paths between LLMs and SLMs. Most generated tokens\nare either identical or exhibit neutral differences, such as minor variations\nin abbreviations or expressions. Leveraging this insight, we introduce **Roads\nto Rome (R2R)**, a neural token routing method that selectively utilizes LLMs\nonly for these critical, path-divergent tokens, while leaving the majority of\ntoken generation to the SLM. We also develop an automatic data generation\npipeline that identifies divergent tokens and generates token-level routing\nlabels to train the lightweight router. We apply R2R to combine R1-1.5B and\nR1-32B models from the DeepSeek family, and evaluate on challenging math,\ncoding, and QA benchmarks. With an average activated parameter size of 5.6B,\nR2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even the\nR1-14B model. Compared to R1-32B, it delivers a 2.8x wall-clock speedup with\ncomparable performance, advancing the Pareto frontier of test-time scaling\nefficiency. Our code is available at https://github.com/thu-nics/R2R.','Tianyu Fu, Yi Ge, Yichen You, Enshu Liu, Zhihang Yuan, Guohao Dai, Shengen Yan, Huazhong Yang, Yu Wang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21600v1'),('2505.21603v1','Leveraging XP and CRISP-DM for Agile Data Science Projects','This study explores the integration of eXtreme Programming (XP) and the\nCross-Industry Standard Process for Data Mining (CRISP-DM) in agile Data\nScience projects. We conducted a case study at the e-commerce company Elo7 to\nanswer the research question: How can the agility of the XP method be\nintegrated with CRISP-DM in Data Science projects? Data was collected through\ninterviews and questionnaires with a Data Science team consisting of data\nscientists, ML engineers, and data product managers. The results show that 86%\nof the team frequently or always applies CRISP-DM, while 71% adopt XP practices\nin their projects. Furthermore, the study demonstrates that it is possible to\ncombine CRISP-DM with XP in Data Science projects, providing a structured and\ncollaborative approach. Finally, the study generated improvement\nrecommendations for the company.','Andre Massahiro Shimaoka, Renato Cordeiro Ferreira, Alfredo Goldman','2025-05-27','cs.SE','http://arxiv.org/pdf/2505.21603v1'),('2505.21604v1','Public Discourse Sandbox: Facilitating Human and AI Digital Communication Research','Social media serves as a primary communication and information dissemination\nplatform for major global events, entertainment, and niche or topically focused\ncommunity discussions. Therefore, it represents a valuable resource for\nresearchers who aim to understand numerous questions. However, obtaining data\ncan be difficult, expensive, and often unreliable due to the presence of bots,\nfake accounts, and manipulated content. Additionally, there are ethical\nconcerns if researchers decide to conduct an online experiment without\nexplicitly notifying social media users about their intent. There is a need for\nmore controlled and scalable mechanisms to evaluate the impacts of digital\ndiscussion interventions on audiences. We introduce the Public Discourse\nSandbox (PDS), which serves as a digital discourse research platform for\nhuman-AI as well as AI-AI discourse research, testing, and training. PDS\nprovides a safe and secure space for research experiments that are not viable\non public, commercial social media platforms. Its main purpose is to enable the\nunderstanding of AI behaviors and the impacts of customized AI participants via\ntechniques such as prompt engineering, retrieval-augmented generation (RAG),\nand fine-tuning. We provide a hosted live version of the sandbox to support\nresearchers as well as the open-sourced code on GitHub for community\ncollaboration and contribution.','Kristina Radivojevic, Caleb Reinking, Shaun Whitfield, Paul Brenner','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21604v1'),('2505.21605v1','SOSBENCH: Benchmarking Safety Alignment on Scientific Knowledge','Large language models (LLMs) exhibit advancing capabilities in complex tasks,\nsuch as reasoning and graduate-level question answering, yet their resilience\nagainst misuse, particularly involving scientifically sophisticated risks,\nremains underexplored. Existing safety benchmarks typically focus either on\ninstructions requiring minimal knowledge comprehension (e.g., ``tell me how to\nbuild a bomb\") or utilize prompts that are relatively low-risk (e.g.,\nmultiple-choice or classification tasks about hazardous content). Consequently,\nthey fail to adequately assess model safety when handling knowledge-intensive,\nhazardous scenarios.\n  To address this critical gap, we introduce SOSBench, a regulation-grounded,\nhazard-focused benchmark encompassing six high-risk scientific domains:\nchemistry, biology, medicine, pharmacology, physics, and psychology. The\nbenchmark comprises 3,000 prompts derived from real-world regulations and laws,\nsystematically expanded via an LLM-assisted evolutionary pipeline that\nintroduces diverse, realistic misuse scenarios (e.g., detailed explosive\nsynthesis instructions involving advanced chemical formulas). We evaluate\nfrontier models within a unified evaluation framework using our SOSBench.\nDespite their alignment claims, advanced models consistently disclose\npolicy-violating content across all domains, demonstrating alarmingly high\nrates of harmful responses (e.g., 79.1% for Deepseek-R1 and 47.3% for GPT-4.1).\nThese results highlight significant safety alignment deficiencies and\nunderscore urgent concerns regarding the responsible deployment of powerful\nLLMs.','Fengqing Jiang, Fengbo Ma, Zhangchen Xu, Yuetai Li, Bhaskar Ramasubramanian, Luyao Niu, Bo Li, Xianyan Chen, Zhen Xiang, Radha Poovendran','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21605v1'),('2505.21608v1','How does Misinformation Affect Large Language Model Behaviors and Preferences?','Large Language Models (LLMs) have shown remarkable capabilities in\nknowledge-intensive tasks, while they remain vulnerable when encountering\nmisinformation. Existing studies have explored the role of LLMs in combating\nmisinformation, but there is still a lack of fine-grained analysis on the\nspecific aspects and extent to which LLMs are influenced by misinformation. To\nbridge this gap, we present MisBench, the current largest and most\ncomprehensive benchmark for evaluating LLMs\\\' behavior and knowledge preference\ntoward misinformation. MisBench consists of 10,346,712 pieces of\nmisinformation, which uniquely considers both knowledge-based conflicts and\nstylistic variations in misinformation. Empirical results reveal that while\nLLMs demonstrate comparable abilities in discerning misinformation, they still\nremain susceptible to knowledge conflicts and stylistic variations. Based on\nthese findings, we further propose a novel approach called Reconstruct to\nDiscriminate (RtD) to strengthen LLMs\\\' ability to detect misinformation. Our\nstudy provides valuable insights into LLMs\\\' interactions with misinformation,\nand we believe MisBench can serve as an effective benchmark for evaluating\nLLM-based detectors and enhancing their reliability in real-world applications.\nCodes and data are available at https://github.com/GKNL/MisBench.','Miao Peng, Nuo Chen, Jianheng Tang, Jia Li','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21608v1'),('2505.21609v1','Preventing Adversarial AI Attacks Against Autonomous Situational Awareness: A Maritime Case Study','Adversarial artificial intelligence (AI) attacks pose a significant threat to\nautonomous transportation, such as maritime vessels, that rely on AI\ncomponents. Malicious actors can exploit these systems to deceive and\nmanipulate AI-driven operations. This paper addresses three critical research\nchallenges associated with adversarial AI: the limited scope of traditional\ndefences, inadequate security metrics, and the need to build resilience beyond\nmodel-level defences. To address these challenges, we propose building defences\nutilising multiple inputs and data fusion to create defensive components and an\nAI security metric as a novel approach toward developing more secure AI\nsystems. We name this approach the Data Fusion Cyber Resilience (DFCR) method,\nand we evaluate it through real-world demonstrations and comprehensive\nquantitative analyses, comparing a system built with the DFCR method against\nsingle-input models and models utilising existing state-of-the-art defences.\nThe findings show that the DFCR approach significantly enhances resilience\nagainst adversarial machine learning attacks in maritime autonomous system\noperations, achieving up to a 35\\% reduction in loss for successful\nmulti-pronged perturbation attacks, up to a 100\\% reduction in loss for\nsuccessful adversarial patch attacks and up to 100\\% reduction in loss for\nsuccessful spoofing attacks when using these more resilient systems. We\ndemonstrate how DFCR and DFCR confidence scores can reduce adversarial AI\ncontact confidence and improve decision-making by the system, even when typical\nadversarial defences have been compromised. Ultimately, this work contributes\nto the development of more secure and resilient AI-driven systems against\nadversarial attacks.','Mathew J. Walter, Aaron Barrett, Kimberly Tam','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.21609v1'),('2505.21620v1','VideoMarkBench: Benchmarking Robustness of Video Watermarking','The rapid development of video generative models has led to a surge in highly\nrealistic synthetic videos, raising ethical concerns related to disinformation\nand copyright infringement. Recently, video watermarking has been proposed as a\nmitigation strategy by embedding invisible marks into AI-generated videos to\nenable subsequent detection. However, the robustness of existing video\nwatermarking methods against both common and adversarial perturbations remains\nunderexplored. In this work, we introduce VideoMarkBench, the first systematic\nbenchmark designed to evaluate the robustness of video watermarks under\nwatermark removal and watermark forgery attacks. Our study encompasses a\nunified dataset generated by three state-of-the-art video generative models,\nacross three video styles, incorporating four watermarking methods and seven\naggregation strategies used during detection. We comprehensively evaluate 12\ntypes of perturbations under white-box, black-box, and no-box threat models.\nOur findings reveal significant vulnerabilities in current watermarking\napproaches and highlight the urgent need for more robust solutions. Our code is\navailable at https://github.com/zhengyuan-jiang/VideoMarkBench.','Zhengyuan Jiang, Moyang Guo, Kecen Li, Yuepeng Hu, Yupu Wang, Zhicong Huang, Cheng Hong, Neil Zhenqiang Gong','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.21620v1'),('2505.21626v1','Learning Where to Learn: Training Distribution Selection for Provable OOD Performance','Out-of-distribution (OOD) generalization remains a fundamental challenge in\nmachine learning. Models trained on one data distribution often experience\nsubstantial performance degradation when evaluated on shifted or unseen\ndomains. To address this challenge, the present paper studies the design of\ntraining data distributions that maximize average-case OOD performance. First,\na theoretical analysis establishes a family of generalization bounds that\nquantify how the choice of training distribution influences OOD error across a\npredefined family of target distributions. These insights motivate the\nintroduction of two complementary algorithmic strategies: (i) directly\nformulating OOD risk minimization as a bilevel optimization problem over the\nspace of probability measures and (ii) minimizing a theoretical upper bound on\nOOD error. Last, the paper evaluates the two approaches across a range of\nfunction approximation and operator learning examples. The proposed methods\nsignificantly improve OOD accuracy over standard empirical risk minimization\nwith a fixed distribution. These results highlight the potential of\ndistribution-aware training as a principled and practical framework for robust\nOOD generalization.','Nicolas Guerra, Nicholas H. Nelsen, Yunan Yang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21626v1'),('2505.21627v1','Is Your LLM Overcharging You? Tokenization, Transparency, and Incentives','State-of-the-art large language models require specialized hardware and\nsubstantial energy to operate. As a consequence, cloud-based services that\nprovide access to large language models have become very popular. In these\nservices, the price users pay for an output provided by a model depends on the\nnumber of tokens the model uses to generate it -- they pay a fixed price per\ntoken. In this work, we show that this pricing mechanism creates a financial\nincentive for providers to strategize and misreport the (number of) tokens a\nmodel used to generate an output, and users cannot prove, or even know, whether\na provider is overcharging them. However, we also show that, if an unfaithful\nprovider is obliged to be transparent about the generative process used by the\nmodel, misreporting optimally without raising suspicion is hard. Nevertheless,\nas a proof-of-concept, we introduce an efficient heuristic algorithm that\nallows providers to significantly overcharge users without raising suspicion,\nhighlighting the vulnerability of users under the current pay-per-token pricing\nmechanism. Further, to completely eliminate the financial incentive to\nstrategize, we introduce a simple incentive-compatible token pricing mechanism.\nUnder this mechanism, the price users pay for an output provided by a model\ndepends on the number of characters of the output -- they pay a fixed price per\ncharacter. Along the way, to illustrate and complement our theoretical results,\nwe conduct experiments with several large language models from the\n$\\texttt{Llama}$, $\\texttt{Gemma}$ and $\\texttt{Ministral}$ families, and input\nprompts from the LMSYS Chatbot Arena platform.','Ander Artola Velasco, Stratis Tsirtsis, Nastaran Okati, Manuel Gomez-Rodriguez','2025-05-27','cs.GT','http://arxiv.org/pdf/2505.21627v1'),('2505.21636v1','The Feasibility of Topic-Based Watermarking on Academic Peer Reviews','Large language models (LLMs) are increasingly integrated into academic\nworkflows, with many conferences and journals permitting their use for tasks\nsuch as language refinement and literature summarization. However, their use in\npeer review remains prohibited due to concerns around confidentiality breaches,\nhallucinated content, and inconsistent evaluations. As LLM-generated text\nbecomes more indistinguishable from human writing, there is a growing need for\nreliable attribution mechanisms to preserve the integrity of the review\nprocess. In this work, we evaluate topic-based watermarking (TBW), a\nlightweight, semantic-aware technique designed to embed detectable signals into\nLLM-generated text. We conduct a comprehensive assessment across multiple LLM\nconfigurations, including base, few-shot, and fine-tuned variants, using\nauthentic peer review data from academic conferences. Our results show that TBW\nmaintains review quality relative to non-watermarked outputs, while\ndemonstrating strong robustness to paraphrasing-based evasion. These findings\nhighlight the viability of TBW as a minimally intrusive and practical solution\nfor enforcing LLM usage in peer review.','Alexander Nemecek, Yuzhou Jiang, Erman Ayday','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.21636v1'),('2505.21639v1','Apprenticeship learning with prior beliefs using inverse optimization','The relationship between inverse reinforcement learning (IRL) and inverse\noptimization (IO) for Markov decision processes (MDPs) has been relatively\nunderexplored in the literature, despite addressing the same problem. In this\nwork, we revisit the relationship between the IO framework for MDPs, IRL, and\napprenticeship learning (AL). We incorporate prior beliefs on the structure of\nthe cost function into the IRL and AL problems, and demonstrate that the\nconvex-analytic view of the AL formalism (Kamoutsi et al., 2021) emerges as a\nrelaxation of our framework. Notably, the AL formalism is a special case in our\nframework when the regularization term is absent. Focusing on the suboptimal\nexpert setting, we formulate the AL problem as a regularized min-max problem.\nThe regularizer plays a key role in addressing the ill-posedness of IRL by\nguiding the search for plausible cost functions. To solve the resulting\nregularized-convex-concave-min-max problem, we use stochastic mirror descent\n(SMD) and establish convergence bounds for the proposed method. Numerical\nexperiments highlight the critical role of regularization in learning cost\nvectors and apprentice policies.','Mauricio Junca, Esteban Leiva','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21639v1'),('2505.21640v1','Efficient Diffusion Models for Symmetric Manifolds','We introduce a framework for designing efficient diffusion models for\n$d$-dimensional symmetric-space Riemannian manifolds, including the torus,\nsphere, special orthogonal group and unitary group. Existing manifold diffusion\nmodels often depend on heat kernels, which lack closed-form expressions and\nrequire either $d$ gradient evaluations or exponential-in-$d$ arithmetic\noperations per training step. We introduce a new diffusion model for symmetric\nmanifolds with a spatially-varying covariance, allowing us to leverage a\nprojection of Euclidean Brownian motion to bypass heat kernel computations. Our\ntraining algorithm minimizes a novel efficient objective derived via Ito\\\'s\nLemma, allowing each step to run in $O(1)$ gradient evaluations and\nnearly-linear-in-$d$ ($O(d^{1.19})$) arithmetic operations, reducing the gap\nbetween diffusions on symmetric manifolds and Euclidean space. Manifold\nsymmetries ensure the diffusion satisfies an \"average-case\" Lipschitz\ncondition, enabling accurate and efficient sample generation. Empirically, our\nmodel outperforms prior methods in training speed and improves sample quality\non synthetic datasets on the torus, special orthogonal group, and unitary\ngroup.','Oren Mangoubi, Neil He, Nisheeth K. Vishnoi','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21640v1'),('2505.21641v1','PrivATE: Differentially Private Confidence Intervals for Average Treatment Effects','The average treatment effect (ATE) is widely used to evaluate the\neffectiveness of drugs and other medical interventions. In safety-critical\napplications like medicine, reliable inferences about the ATE typically require\nvalid uncertainty quantification, such as through confidence intervals (CIs).\nHowever, estimating treatment effects in these settings often involves\nsensitive data that must be kept private. In this work, we present PrivATE, a\nnovel machine learning framework for computing CIs for the ATE under\ndifferential privacy. Specifically, we focus on deriving valid\nprivacy-preserving CIs for the ATE from observational data. Our PrivATE\nframework consists of three steps: (i) estimating a differentially private ATE\nthrough output perturbation; (ii) estimating the differentially private\nvariance through a truncated output perturbation mechanism; and (iii)\nconstructing the CIs while accounting for the uncertainty from both the\nestimation and privatization steps. Our PrivATE framework is model agnostic,\ndoubly robust, and ensures valid CIs. We demonstrate the effectiveness of our\nframework using synthetic and real-world medical datasets. To the best of our\nknowledge, we are the first to derive a general, doubly robust framework for\nvalid CIs of the ATE under ($\\varepsilon$, $\\delta$)-differential privacy.','Maresa Schröder, Justin Hartenstein, Stefan Feuerriegel','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21641v1'),('2505.21646v1','Iterative Corpus Refinement for Materials Property Prediction Based on Scientific Texts','The discovery and optimization of materials for specific applications is\nhampered by the practically infinite number of possible elemental combinations\nand associated properties, also known as the `combinatorial explosion\\\'. By\nnature of the problem, data are scarce and all possible data sources should be\nused. In addition to simulations and experimental results, the latent knowledge\nin scientific texts is not yet used to its full potential. We present an\niterative framework that refines a given scientific corpus by strategic\nselection of the most diverse documents, training Word2Vec models, and\nmonitoring the convergence of composition-property correlations in embedding\nspace. Our approach is applied to predict high-performing materials for oxygen\nreduction (ORR), hydrogen evolution (HER), and oxygen evolution (OER) reactions\nfor a large number of possible candidate compositions. Our method successfully\npredicts the highest performing compositions among a large pool of candidates,\nvalidated by experimental measurements of the electrocatalytic performance in\nthe lab. This work demonstrates and validates the potential of iterative corpus\nrefinement to accelerate materials discovery and optimization, offering a\nscalable and efficient tool for screening large compositional spaces where\nreliable data are scarce or non-existent.','Lei Zhang, Markus Stricker','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21646v1'),('2505.21647v1','QuARI: Query Adaptive Retrieval Improvement','Massive-scale pretraining has made vision-language models increasingly\npopular for image-to-image and text-to-image retrieval across a broad\ncollection of domains. However, these models do not perform well when used for\nchallenging retrieval tasks, such as instance retrieval in very large-scale\nimage collections. Recent work has shown that linear transformations of VLM\nfeatures trained for instance retrieval can improve performance by emphasizing\nsubspaces that relate to the domain of interest. In this paper, we explore a\nmore extreme version of this specialization by learning to map a given query to\na query-specific feature space transformation. Because this transformation is\nlinear, it can be applied with minimal computational cost to millions of image\nembeddings, making it effective for large-scale retrieval or re-ranking.\nResults show that this method consistently outperforms state-of-the-art\nalternatives, including those that require many orders of magnitude more\ncomputation at query time.','Eric Xing, Abby Stylianou, Robert Pless, Nathan Jacobs','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21647v1'),('2505.21651v1','AutoSGD: Automatic Learning Rate Selection for Stochastic Gradient Descent','The learning rate is an important tuning parameter for stochastic gradient\ndescent (SGD) and can greatly influence its performance. However, appropriate\nselection of a learning rate schedule across all iterations typically requires\na non-trivial amount of user tuning effort. To address this, we introduce\nAutoSGD: an SGD method that automatically determines whether to increase or\ndecrease the learning rate at a given iteration and then takes appropriate\naction. We introduce theory supporting the convergence of AutoSGD, along with\nits deterministic counterpart for standard gradient descent. Empirical results\nsuggest strong performance of the method on a variety of traditional\noptimization problems and machine learning tasks.','Nikola Surjanovic, Alexandre Bouchard-Côté, Trevor Campbell','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21651v1'),('2505.21652v1','PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation','Fine-grained robot manipulation, such as lifting and rotating a bottle to\ndisplay the label on the cap, requires robust reasoning about object parts and\ntheir relationships with intended tasks. Despite recent advances in training\ngeneral-purpose robot manipulation policies guided by language instructions,\nthere is a notable lack of large-scale datasets for fine-grained manipulation\ntasks with part-level instructions and diverse 3D object instances annotated\nwith part-level labels. In this work, we introduce PartInstruct, the first\nlarge-scale benchmark for training and evaluating fine-grained robot\nmanipulation models using part-level instructions. PartInstruct comprises 513\nobject instances across 14 categories, each annotated with part-level\ninformation, and 1302 fine-grained manipulation tasks organized into 16 task\nclasses. Our training set consists of over 10,000 expert demonstrations\nsynthesized in a 3D simulator, where each demonstration is paired with a\nhigh-level task instruction, a chain of base part-based skill instructions, and\nground-truth 3D information about the object and its parts. Additionally, we\ndesigned a comprehensive test suite to evaluate the generalizability of learned\npolicies across new states, objects, and tasks. We evaluated several\nstate-of-the-art robot manipulation approaches, including end-to-end\nvision-language policy learning and bi-level planning models for robot\nmanipulation on our benchmark. The experimental results reveal that current\nmodels struggle to robustly ground part concepts and predict actions in 3D\nspace, and face challenges when manipulating object parts in long-horizon\ntasks.','Yifan Yin, Zhengtao Han, Shivam Aarya, Jianxin Wang, Shuhang Xu, Jiawei Peng, Angtian Wang, Alan Yuille, Tianmin Shu','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.21652v1'),('2505.21657v1','Explainability of Large Language Models using SMILE: Statistical Model-agnostic Interpretability with Local Explanations','Large language models like GPT, LLAMA, and Claude have become incredibly\npowerful at generating text, but they are still black boxes, so it is hard to\nunderstand how they decide what to say. That lack of transparency can be\nproblematic, especially in fields where trust and accountability matter. To\nhelp with this, we introduce SMILE, a new method that explains how these models\nrespond to different parts of a prompt. SMILE is model-agnostic and works by\nslightly changing the input, measuring how the output changes, and then\nhighlighting which words had the most impact. Create simple visual heat maps\nshowing which parts of a prompt matter the most. We tested SMILE on several\nleading LLMs and used metrics such as accuracy, consistency, stability, and\nfidelity to show that it gives clear and reliable explanations. By making these\nmodels easier to understand, SMILE brings us one step closer to making AI more\ntransparent and trustworthy.','Zeinab Dehghani, Koorosh Aslansefat, Adil Khan, Mohammed Naveed Akram','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21657v1'),('2505.21658v1','STACI: Spatio-Temporal Aleatoric Conformal Inference','Fitting Gaussian Processes (GPs) provides interpretable aleatoric uncertainty\nquantification for estimation of spatio-temporal fields. Spatio-temporal deep\nlearning models, while scalable, typically assume a simplistic independent\ncovariance matrix for the response, failing to capture the underlying\ncorrelation structure. However, spatio-temporal GPs suffer from issues of\nscalability and various forms of approximation bias resulting from restrictive\nassumptions of the covariance kernel function. We propose STACI, a novel\nframework consisting of a variational Bayesian neural network approximation of\nnon-stationary spatio-temporal GP along with a novel spatio-temporal conformal\ninference algorithm. STACI is highly scalable, taking advantage of GPU training\ncapabilities for neural network models, and provides statistically valid\nprediction intervals for uncertainty quantification. STACI outperforms\ncompeting GPs and deep methods in accurately approximating spatio-temporal\nprocesses and we show it easily scales to datasets with millions of\nobservations.','Brandon R. Feng, David Keetae Park, Xihaier Luo, Arantxa Urdangarin, Shinjae Yoo, Brian J. Reich','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.21658v1'),('2505.21660v1','PreGenie: An Agentic Framework for High-quality Visual Presentation Generation','Visual presentations are vital for effective communication. Early attempts to\nautomate their creation using deep learning often faced issues such as poorly\norganized layouts, inaccurate text summarization, and a lack of image\nunderstanding, leading to mismatched visuals and text. These limitations\nrestrict their application in formal contexts like business and scientific\nresearch. To address these challenges, we propose PreGenie, an agentic and\nmodular framework powered by multimodal large language models (MLLMs) for\ngenerating high-quality visual presentations.\n  PreGenie is built on the Slidev presentation framework, where slides are\nrendered from Markdown code. It operates in two stages: (1) Analysis and\nInitial Generation, which summarizes multimodal input and generates initial\ncode, and (2) Review and Re-generation, which iteratively reviews intermediate\ncode and rendered slides to produce final, high-quality presentations. Each\nstage leverages multiple MLLMs that collaborate and share information.\nComprehensive experiments demonstrate that PreGenie excels in multimodal\nunderstanding, outperforming existing models in both aesthetics and content\nconsistency, while aligning more closely with human design preferences.','Xiaojie Xu, Xinli Xu, Sirui Chen, Haoyu Chen, Fan Zhang, Ying-Cong Chen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21660v1'),('2505.21664v1','Expert Survey: AI Reliability & Security Research Priorities','Our survey of 53 specialists across 105 AI reliability and security research\nareas identifies the most promising research prospects to guide strategic AI\nR&D investment. As companies are seeking to develop AI systems with broadly\nhuman-level capabilities, research on reliability and security is urgently\nneeded to ensure AI\\\'s benefits can be safely and broadly realized and prevent\nsevere harms. This study is the first to quantify expert priorities across a\ncomprehensive taxonomy of AI safety and security research directions and to\nproduce a data-driven ranking of their potential impact. These rankings may\nsupport evidence-based decisions about how to effectively deploy resources\ntoward AI reliability and security research.','Joe O\'Brien, Jeremy Dolan, Jay Kim, Jonah Dykhuizen, Jeba Sania, Sebastian Becker, Jam Kraprayoon, Cara Labrador','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21664v1'),('2505.21666v1','Efficient Controllable Diffusion via Optimal Classifier Guidance','The controllable generation of diffusion models aims to steer the model to\ngenerate samples that optimize some given objective functions. It is desirable\nfor a variety of applications including image generation, molecule generation,\nand DNA/sequence generation. Reinforcement Learning (RL) based fine-tuning of\nthe base model is a popular approach but it can overfit the reward function\nwhile requiring significant resources. We frame controllable generation as a\nproblem of finding a distribution that optimizes a KL-regularized objective\nfunction. We present SLCD -- Supervised Learning based Controllable Diffusion,\nwhich iteratively generates online data and trains a small classifier to guide\nthe generation of the diffusion model. Similar to the standard\nclassifier-guided diffusion, SLCD\\\'s key computation primitive is classification\nand does not involve any complex concepts from RL or control. Via a reduction\nto no-regret online learning analysis, we show that under KL divergence, the\noutput from SLCD provably converges to the optimal solution of the\nKL-regularized objective. Further, we empirically demonstrate that SLCD can\ngenerate high quality samples with nearly the same inference time as the base\nmodel in both image generation with continuous diffusion and biological\nsequence generation with discrete diffusion. Our code is available at\nhttps://github.com/Owen-Oertell/slcd','Owen Oertell, Shikun Sun, Yiding Chen, Jin Peng Zhou, Zhiyong Wang, Wen Sun','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21666v1'),('2505.21668v1','R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning','Despite advances in reasoning and planning of R1-like models, Large Language\nModels (LLMs) still struggle with tasks requiring precise computation, symbolic\nmanipulation, optimization, and algorithmic reasoning, in which textual\nreasoning lacks the rigor of code execution. A key challenge is enabling LLMs\nto decide when to use textual reasoning versus code generation. While OpenAI\ntrains models to invoke a Code Interpreter as needed, public research lacks\nguidance on aligning pre-trained LLMs to effectively leverage code and\ngeneralize across diverse tasks. We present R1-Code-Interpreter, an extension\nof a text-only LLM trained via multi-turn supervised fine-tuning (SFT) and\nreinforcement learning (RL) to autonomously generate multiple code queries\nduring step-by-step reasoning. We curate 144 reasoning and planning tasks (107\nfor training, 37 for testing), each with over 200 diverse questions. We\nfine-tune Qwen-2.5 models (3B/7B/14B) using various SFT and RL strategies,\ninvestigating different answer formats, reasoning vs. non-reasoning models,\ncold vs. warm starts, GRPO vs. PPO, and masked vs. unmasked code outputs.\nUnlike prior RL work on narrow domains, we find that Code Interpreter training\nis significantly harder due to high task diversity and expensive code\nexecution, highlighting the critical role of the SFT stage. Our final model,\nR1-CI-14B, improves average accuracy on the 37 test tasks from 44.0\\% to\n64.1\\%, outperforming GPT-4o (text-only: 58.6\\%) and approaching GPT-4o with\nCode Interpreter (70.9\\%), with the emergent self-checking behavior via code\ngeneration. Datasets, Codes, and Models are available at\nhttps://github.com/yongchao98/R1-Code-Interpreter and\nhttps://huggingface.co/yongchao98.','Yongchao Chen, Yueying Liu, Junwei Zhou, Yilun Hao, Jingquan Wang, Yang Zhang, Chuchu Fan','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21668v1'),('2505.21670v1','Rethinking the Outlier Distribution in Large Language Models: An In-depth Study','Investigating outliers in large language models (LLMs) is crucial due to\ntheir significant impact on various aspects of LLM performance, including\nquantization and compression. Outliers often cause considerable quantization\nerrors, leading to degraded model performance. Identifying and addressing these\noutliers can enhance the accuracy and efficiency of the quantization process,\nenabling smoother deployment on edge devices or specialized hardware. Recent\nstudies have identified two common types of outliers in LLMs: massive\nactivations and channel-wise outliers. While numerous quantization algorithms\nhave been proposed to mitigate their effects and maintain satisfactory\naccuracy, few have thoroughly explored the root causes of these outliers in\ndepth. In this paper, we conduct a comprehensive investigation into the\nformation mechanisms of these outliers and propose potential strategies to\nmitigate their occurrence. Ultimately, we introduce some efficient approaches\nto eliminate most massive activations and channel-wise outliers with minimal\nimpact on accuracy.','Rahul Raman, Khushi Sharma, Sai Qian Zhang','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21670v1'),('2505.21671v1','Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing','We study a sequential decision-making problem on a $n$-node graph $G$ where\neach node has an unknown label from a finite set $\\mathbf{\\Sigma}$, drawn from\na joint distribution $P$ that is Markov with respect to $G$. At each step,\nselecting a node reveals its label and yields a label-dependent reward. The\ngoal is to adaptively choose nodes to maximize expected accumulated discounted\nrewards. We impose a frontier exploration constraint, where actions are limited\nto neighbors of previously selected nodes, reflecting practical constraints in\nsettings such as contact tracing and robotic exploration. We design a Gittins\nindex-based policy that applies to general graphs and is provably optimal when\n$G$ is a forest. Our implementation runs in $O(n^2 \\cdot |\\mathbf{\\Sigma}|^2)$\ntime while using $O(n \\cdot |\\mathbf{\\Sigma}|^2)$ oracle calls to $P$ and\n$O(n^2 \\cdot |\\mathbf{\\Sigma}|)$ space. Experiments on synthetic and real-world\ngraphs show that our method consistently outperforms natural baselines,\nincluding in non-tree, budget-limited, and undiscounted settings. For example,\nin HIV testing simulations on real-world sexual interaction networks, our\npolicy detects nearly all positive cases with only half the population tested,\nsubstantially outperforming other baselines.','Davin Choo, Yuqi Pan, Tonghan Wang, Milind Tambe, Alastair van Heerden, Cheryl Johnson','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21671v1'),('2505.21674v1','Make Planning Research Rigorous Again!','In over sixty years since its inception, the field of planning has made\nsignificant contributions to both the theory and practice of building planning\nsoftware that can solve a never-before-seen planning problem. This was done\nthrough established practices of rigorous design and evaluation of planning\nsystems. It is our position that this rigor should be applied to the current\ntrend of work on planning with large language models. One way to do so is by\ncorrectly incorporating the insights, tools, and data from the automated\nplanning community into the design and evaluation of LLM-based planners. The\nexperience and expertise of the planning community are not just important from\na historical perspective; the lessons learned could play a crucial role in\naccelerating the development of LLM-based planners. This position is\nparticularly important in light of the abundance of recent works that replicate\nand propagate the same pitfalls that the planning community has encountered and\nlearned from. We believe that avoiding such known pitfalls will contribute\ngreatly to the progress in building LLM-based planners and to planning in\ngeneral.','Michael Katz, Harsha Kokel, Christian Muise, Shirin Sohrabi, Sarath Sreedharan','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21674v1'),('2505.21677v1','What happens when generative AI models train recursively on each others\\\' generated outputs?','The internet is full of AI-generated content while also serving as a common\nsource of training data for generative AI (genAI) models. This duality raises\nthe possibility that future genAI models may be trained on other models\\\'\ngenerated outputs. Prior work has studied consequences of models training on\ntheir own generated outputs, but limited work has considered what happens if\nmodels ingest content produced by other models. Given society\\\'s increasing\ndependence on genAI tools, understanding downstream effects of such\ndata-mediated model interactions is critical. To this end, we provide empirical\nevidence for how data-mediated interactions might unfold in practice, develop a\ntheoretical model for this interactive training process, and show\nexperimentally possible long-term results of such interactions. We find that\ndata-mediated interactions can benefit models by exposing them to novel\nconcepts perhaps missed in original training data, but also can homogenize\ntheir performance on shared tasks.','Hung Ahn Vu, Galen Reeves, Emily Wenger','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21677v1'),('2505.21680v1','multivariateGPT: a decoder-only transformer for multivariate categorical and numeric data','Real-world processes often generate data that are a mix of categorical and\nnumeric values that are recorded at irregular and informative intervals.\nDiscrete token-based approaches are limited in numeric representation capacity\nwhile methods like neural ordinary differential equations are not well suited\nfor categorical data or informative sampling and require augmentation to handle\ncertain classes of trajectories. Here, we present multivariateGPT, a single\narchitecture for modeling sequences of mixed categorical (including tokenized\ntext) and numeric data. This is accomplished with an autoregressive sequence\ndecomposition, embedding scheme, and loss function that extend the next token\nprediction task to likelihood estimation of the joint distribution of next\ntoken class and value. We demonstrate how this approach can efficiently learn\nto generalize patterns in simple physical systems and model complex time series\nincluding electrocardiograms and multivariate electronic health record data.\nThis work extends the utility of transformer based models to additional classes\nof data.','Andrew J. Loza, Jun Yup Kim, Shangzheng Song, Yihang Liu, Joseph J. Y. Sung, R Andrew Taylor, Dennis L. Shung','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21680v1'),('2505.21684v1','Incentivizing Permissionless Distributed Learning of LLMs','We describe an incentive system for distributed deep learning of foundational\nmodels where peers are rewarded for contributions. The incentive system,\n\\textit{Gauntlet}, has been deployed on the bittensor blockchain and used to\ntrain a 1.2B LLM with completely permissionless contributions of\npseudo-gradients: no control over the users that can register or their\nhardware. \\textit{Gauntlet} can be applied to any synchronous distributed\ntraining scheme that relies on aggregating updates or pseudo-gradients. We rely\non a two-stage mechanism for fast filtering of peer uptime, reliability, and\nsynchronization, combined with the core component that estimates the loss\nbefore and after individual pseudo-gradient contributions. We utilized an\nOpenSkill rating system to track competitiveness of pseudo-gradient scores\nacross time. Finally, we introduce a novel mechanism to ensure peers on the\nnetwork perform unique computations. Our live 1.2B run, which has paid out\nreal-valued tokens to participants based on the value of their contributions,\nyielded a competitive (on a per-iteration basis) 1.2B model that demonstrates\nthe utility of our incentive system.','Joel Lidin, Amir Sarfi, Evangelos Pappas, Samuel Dare, Eugene Belilovsky, Jacob Steeves','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21684v1'),('2505.21686v1','tenSVD algorithm for compression','Tensors provide a robust framework for managing high-dimensional data.\nConsequently, tensor analysis has emerged as an active research area in various\ndomains, including machine learning, signal processing, computer vision, graph\nanalysis, and data mining. This study introduces an efficient image storage\napproach utilizing tensors, aiming to minimize memory to store, bandwidth to\ntransmit and energy to processing. The proposed method organizes original data\ninto a higher-order tensor and applies the Tucker model for compression.\nImplemented in R, this method is compared to a baseline algorithm. The\nevaluation focuses on efficient of algorithm measured in term of computational\ntime and the quality of information preserved, using both simulated and real\ndatasets. A detailed analysis of the results is conducted, employing\nestablished quantitative metrics, with significant attention paid to\nsustainability in terms of energy consumption across algorithms.','Michele Gallo','2025-05-27','stat.CO','http://arxiv.org/pdf/2505.21686v1'),('2505.21689v1','LLMPR: A Novel LLM-Driven Transfer Learning based Petition Ranking Model','The persistent accumulation of unresolved legal cases, especially within the\nIndian judiciary, significantly hampers the timely delivery of justice. Manual\nmethods of prioritizing petitions are often prone to inefficiencies and\nsubjective biases further exacerbating delays. To address this issue, we\npropose LLMPR (Large Language Model-based Petition Ranking), an automated\nframework that utilizes transfer learning and machine learning to assign\npriority rankings to legal petitions based on their contextual urgency.\nLeveraging the ILDC dataset comprising 7,593 annotated petitions, we process\nunstructured legal text and extract features through various embedding\ntechniques, including DistilBERT, LegalBERT, and MiniLM. These textual\nembeddings are combined with quantitative indicators such as gap days, rank\nscores, and word counts to train multiple machine learning models, including\nRandom Forest, Decision Tree, XGBoost, LightGBM, and CatBoost. Our experiments\ndemonstrate that Random Forest and Decision Tree models yield superior\nperformance, with accuracy exceeding 99% and a Spearman rank correlation of\n0.99. Notably, models using only numerical features achieve nearly optimal\nranking results (R2 = 0.988, \\r{ho} = 0.998), while LLM-based embeddings offer\nonly marginal gains. These findings suggest that automated petition ranking can\neffectively streamline judicial workflows, reduce case backlog, and improve\nfairness in legal prioritization.','Avijit Gayen, Somyajit Chakraborty, Mainak Sen, Soham Paul, Angshuman Jana','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21689v1'),('2505.21692v1','What Data Enables Optimal Decisions? An Exact Characterization for Linear Optimization','We study the fundamental question of how informative a dataset is for solving\na given decision-making task. In our setting, the dataset provides partial\ninformation about unknown parameters that influence task outcomes. Focusing on\nlinear programs, we characterize when a dataset is sufficient to recover an\noptimal decision, given an uncertainty set on the cost vector. Our main\ncontribution is a sharp geometric characterization that identifies the\ndirections of the cost vector that matter for optimality, relative to the task\nconstraints and uncertainty set. We further develop a practical algorithm that,\nfor a given task, constructs a minimal or least-costly sufficient dataset. Our\nresults reveal that small, well-chosen datasets can often fully determine\noptimal decisions -- offering a principled foundation for task-aware data\nselection.','Omar Bennouna, Amine Bennouna, Saurabh Amin, Asuman Ozdaglar','2025-05-27','math.OC','http://arxiv.org/pdf/2505.21692v1'),('2505.21693v1','MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs','Large language models (LLMs) are used globally across many languages, but\ntheir English-centric pretraining raises concerns about cross-lingual\ndisparities for cultural awareness, often resulting in biased outputs. However,\ncomprehensive multilingual evaluation remains challenging due to limited\nbenchmarks and questionable translation quality. To better assess these\ndisparities, we introduce MAKIEval, an automatic multilingual framework for\nevaluating cultural awareness in LLMs across languages, regions, and topics.\nMAKIEval evaluates open-ended text generation, capturing how models express\nculturally grounded knowledge in natural language. Leveraging Wikidata\\\'s\nmultilingual structure as a cross-lingual anchor, it automatically identifies\ncultural entities in model outputs and links them to structured knowledge,\nenabling scalable, language-agnostic evaluation without manual annotation or\ntranslation. We then introduce four metrics that capture complementary\ndimensions of cultural awareness: granularity, diversity, cultural specificity,\nand consensus across languages. We assess 7 LLMs developed from different parts\nof the world, encompassing both open-source and proprietary systems, across 13\nlanguages, 19 countries and regions, and 6 culturally salient topics (e.g.,\nfood, clothing). Notably, we find that models tend to exhibit stronger cultural\nawareness in English, suggesting that English prompts more effectively activate\nculturally grounded knowledge. We publicly release our code and data.','Raoyuan Zhao, Beiduo Chen, Barbara Plank, Michael A. Hedderich','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21693v1'),('2505.21695v1','AMSFL: Adaptive Multi-Step Federated Learning via Gradient Difference-Based Error Modeling','Federated learning faces critical challenges in balancing communication\nefficiency and model accuracy. One key issue lies in the approximation of\nupdate errors without incurring high computational costs. In this paper, we\npropose a lightweight yet effective method called Gradient Difference\nApproximation (GDA), which leverages first-order information to estimate local\nerror trends without computing the full Hessian matrix. The proposed method\nforms a key component of the Adaptive Multi-Step Federated Learning (AMSFL)\nframework and provides a unified error modeling strategy for large-scale\nmulti-step adaptive training environments.','Ganglou Xu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21695v1'),('2505.21699v1','STA-Risk: A Deep Dive of Spatio-Temporal Asymmetries for Breast Cancer Risk Prediction','Predicting the risk of developing breast cancer is an important clinical tool\nto guide early intervention and tailoring personalized screening strategies.\nEarly risk models have limited performance and recently machine learning-based\nanalysis of mammogram images showed encouraging risk prediction effects. These\nmodels however are limited to the use of a single exam or tend to overlook\nnuanced breast tissue evolvement in spatial and temporal details of\nlongitudinal imaging exams that are indicative of breast cancer risk. In this\npaper, we propose STA-Risk (Spatial and Temporal Asymmetry-based Risk\nPrediction), a novel Transformer-based model that captures fine-grained\nmammographic imaging evolution simultaneously from bilateral and longitudinal\nasymmetries for breast cancer risk prediction. STA-Risk is innovative by the\nside encoding and temporal encoding to learn spatial-temporal asymmetries,\nregulated by a customized asymmetry loss. We performed extensive experiments\nwith two independent mammogram datasets and achieved superior performance than\nfour representative SOTA models for 1- to 5-year future risk prediction. Source\ncodes will be released upon publishing of the paper.','Zhengbo Zhou, Dooman Arefan, Margarita Zuley, Jules Sumkin, Shandong Wu','2025-05-27','eess.IV','http://arxiv.org/pdf/2505.21699v1'),('2505.21701v1','Do We Know What LLMs Don\\\'t Know? A Study of Consistency in Knowledge Probing','The reliability of large language models (LLMs) is greatly compromised by\ntheir tendency to hallucinate, underscoring the need for precise identification\nof knowledge gaps within LLMs. Various methods for probing such gaps exist,\nranging from calibration-based to prompting-based methods. To evaluate these\nprobing methods, in this paper, we propose a new process based on using input\nvariations and quantitative metrics. Through this, we expose two dimensions of\ninconsistency in knowledge gap probing. (1) Intra-method inconsistency: Minimal\nnon-semantic perturbations in prompts lead to considerable variance in detected\nknowledge gaps within the same probing method; e.g., the simple variation of\nshuffling answer options can decrease agreement to around 40%. (2) Cross-method\ninconsistency: Probing methods contradict each other on whether a model knows\nthe answer. Methods are highly inconsistent -- with decision consistency across\nmethods being as low as 7% -- even though the model, dataset, and prompt are\nall the same. These findings challenge existing probing methods and highlight\nthe urgent need for perturbation-robust probing frameworks.','Raoyuan Zhao, Abdullatif Köksal, Ali Modarressi, Michael A. Hedderich, Hinrich Schütze','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21701v1'),('2505.21703v1','A Joint Reconstruction-Triplet Loss Autoencoder Approach Towards Unseen Attack Detection in IoV Networks','Internet of Vehicles (IoV) systems, while offering significant advancements\nin transportation efficiency and safety, introduce substantial security\nvulnerabilities due to their highly interconnected nature. These dynamic\nsystems produce massive amounts of data between vehicles, infrastructure, and\ncloud services and present a highly distributed framework with a wide attack\nsurface. In considering network-centered attacks on IoV systems, attacks such\nas Denial-of-Service (DoS) can prohibit the communication of essential physical\ntraffic safety information between system elements, illustrating that the\nsecurity concerns for these systems go beyond the traditional confidentiality,\nintegrity, and availability concerns of enterprise systems. Given the\ncomplexity and volume of data generated by IoV systems, traditional security\nmechanisms are often inadequate for accurately detecting sophisticated and\nevolving cyberattacks. Here, we present an unsupervised autoencoder method\ntrained entirely on benign network data for the purpose of unseen attack\ndetection in IoV networks. We leverage a weighted combination of reconstruction\nand triplet margin loss to guide the autoencoder training and develop a diverse\nrepresentation of the benign training set. We conduct extensive experiments on\nrecent network intrusion datasets from two different application domains,\nindustrial IoT and home IoT, that represent the modern IoV task. We show that\nour method performs robustly for all unseen attack types, with roughly 99%\naccuracy on benign data and between 97% and 100% performance on anomaly data.\nWe extend these results to show that our model is adaptable through the use of\ntransfer learning, achieving similarly high results while leveraging domain\nfeatures from one domain to another.','Julia Boone, Tolunay Seyfi, Fatemeh Afghah','2025-05-27','cs.CR','http://arxiv.org/pdf/2505.21703v1'),('2505.21706v1','Network classification through random walks','Network models have been widely used to study diverse systems and analyze\ntheir dynamic behaviors. Given the structural variability of networks, an\nintriguing question arises: Can we infer the type of system represented by a\nnetwork based on its structure? This classification problem involves extracting\nrelevant features from the network. Existing literature has proposed various\nmethods that combine structural measurements and dynamical processes for\nfeature extraction. In this study, we introduce a novel approach to\ncharacterize networks using statistics from random walks, which can be\nparticularly informative about network properties. We present the employed\nstatistical metrics and compare their performance on multiple datasets with\nother state-of-the-art feature extraction methods. Our results demonstrate that\nthe proposed method is effective in many cases, often outperforming existing\napproaches, although some limitations are observed across certain datasets.','Gonzalo Travieso, Joao Merenda, Odemir M. Bruno','2025-05-27','cs.SI','http://arxiv.org/pdf/2505.21706v1'),('2505.21710v1','Assessing and Refining ChatGPT\\\'s Performance in Identifying Targeting and Inappropriate Language: A Comparative Study','This study evaluates the effectiveness of ChatGPT, an advanced AI model for\nnatural language processing, in identifying targeting and inappropriate\nlanguage in online comments. With the increasing challenge of moderating vast\nvolumes of user-generated content on social network sites, the role of AI in\ncontent moderation has gained prominence. We compared ChatGPT\\\'s performance\nagainst crowd-sourced annotations and expert evaluations to assess its\naccuracy, scope of detection, and consistency. Our findings highlight that\nChatGPT performs well in detecting inappropriate content, showing notable\nimprovements in accuracy through iterative refinements, particularly in Version\n6. However, its performance in targeting language detection showed variability,\nwith higher false positive rates compared to expert judgments. This study\ncontributes to the field by demonstrating the potential of AI models like\nChatGPT to enhance automated content moderation systems while also identifying\nareas for further improvement. The results underscore the importance of\ncontinuous model refinement and contextual understanding to better support\nautomated moderation and mitigate harmful online behavior.','Barbarestani Baran, Maks Isa, Vossen Piek','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21710v1'),('2505.21715v1','Privacy-Preserving Chest X-ray Report Generation via Multimodal Federated Learning with ViT and GPT-2','The automated generation of radiology reports from chest X-ray images holds\nsignificant promise in enhancing diagnostic workflows while preserving patient\nprivacy. Traditional centralized approaches often require sensitive data\ntransfer, posing privacy concerns. To address this, the study proposes a\nMultimodal Federated Learning framework for chest X-ray report generation using\nthe IU-Xray dataset. The system utilizes a Vision Transformer (ViT) as the\nencoder and GPT-2 as the report generator, enabling decentralized training\nwithout sharing raw data. Three Federated Learning (FL) aggregation strategies:\nFedAvg, Krum Aggregation and a novel Loss-aware Federated Averaging (L-FedAvg)\nwere evaluated. Among these, Krum Aggregation demonstrated superior performance\nacross lexical and semantic evaluation metrics such as ROUGE, BLEU, BERTScore\nand RaTEScore. The results show that FL can match or surpass centralized models\nin generating clinically relevant and semantically rich radiology reports. This\nlightweight and privacy-preserving framework paves the way for collaborative\nmedical AI development without compromising data confidentiality.','Md. Zahid Hossain, Mustofa Ahmed, Most. Sharmin Sultana Samu, Md. Rakibul Islam','2025-05-27','eess.IV','http://arxiv.org/pdf/2505.21715v1'),('2505.21717v1','Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling','We present LrcSSM, a \\textit{nonlinear} recurrent model that processes long\nsequences as fast as today\\\'s linear state-space layers. By forcing the\nstate-transition matrix to be diagonal and learned at every step, the full\nsequence can be solved in parallel with a single prefix-scan, giving\n$\\mathcal{O}(TD)$ time and memory and only $\\mathcal{O}(\\log T)$ sequential\ndepth, for input-sequence length $T$ and a state dimension $D$. Moreover,\nLrcSSM offers a formal gradient-stability guarantee that other input-varying\nsystems such as Liquid-S4 and Mamba do not provide. Lastly, for network depth\n$L$, as the forward and backward passes cost $\\Theta(T\\,D\\,L)$ FLOPs, with its\nlow sequential depth and parameter count $\\Theta(D\\,L)$, the model follows the\ncompute-optimal scaling law regime ($\\beta \\approx 0.42$) recently observed for\nMamba, outperforming quadratic-attention Transformers at equal compute while\navoiding the memory overhead of FFT-based long convolutions. We show that on a\nseries of long-range forecasting tasks, LrcSSM outperforms LRU, S5 and Mamba.','Mónika Farsang, Ramin Hasani, Radu Grosu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21717v1'),('2505.21720v1','Responsible Data Stewardship: Generative AI and the Digital Waste Problem','As generative AI systems become widely adopted, they enable unprecedented\ncreation levels of synthetic data across text, images, audio, and video\nmodalities. While research has addressed the energy consumption of model\ntraining and inference, a critical sustainability challenge remains\nunderstudied: digital waste. This term refers to stored data that consumes\nresources without serving a specific (and/or immediate) purpose. This paper\npresents this terminology in the AI context and introduces digital waste as an\nethical imperative within (generative) AI development, positioning\nenvironmental sustainability as core for responsible innovation. Drawing from\nestablished digital resource management approaches, we examine how other\ndisciplines manage digital waste and identify transferable approaches for the\nAI community. We propose specific recommendations encompassing re-search\ndirections, technical interventions, and cultural shifts to mitigate the\nenvironmental consequences of in-definite data storage. By expanding AI ethics\nbeyond immediate concerns like bias and privacy to include inter-generational\nenvironmental justice, this work contributes to a more comprehensive ethical\nframework that considers the complete lifecycle impact of generative AI\nsystems.','Vanessa Utz','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21720v1'),('2505.21721v1','Nearly Dimension-Independent Convergence of Mean-Field Black-Box Variational Inference','We prove that, given a mean-field location-scale variational family,\nblack-box variational inference (BBVI) with the reparametrization gradient\nconverges at an almost dimension-independent rate. Specifically, for strongly\nlog-concave and log-smooth targets, the number of iterations for BBVI with a\nsub-Gaussian family to achieve an objective $\\epsilon$-close to the global\noptimum is $\\mathrm{O}(\\log d)$, which improves over the $\\mathrm{O}(d)$\ndependence of full-rank location-scale families. For heavy-tailed families, we\nprovide a weaker $\\mathrm{O}(d^{2/k})$ dimension dependence, where $k$ is the\nnumber of finite moments. Additionally, if the Hessian of the target\nlog-density is constant, the complexity is free of any explicit dimension\ndependence. We also prove that our bound on the gradient variance, which is key\nto our result, cannot be improved using only spectral bounds on the Hessian of\nthe target log-density.','Kyurae Kim, Yi-An Ma, Trevor Campbell, Jacob R. Gardner','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.21721v1'),('2505.21722v1','Saddle-To-Saddle Dynamics in Deep ReLU Networks: Low-Rank Bias in the First Saddle Escape','When a deep ReLU network is initialized with small weights, GD is at first\ndominated by the saddle at the origin in parameter space. We study the\nso-called escape directions, which play a similar role as the eigenvectors of\nthe Hessian for strict saddles. We show that the optimal escape direction\nfeatures a low-rank bias in its deeper layers: the first singular value of the\n$\\ell$-th layer weight matrix is at least $\\ell^{\\frac{1}{4}}$ larger than any\nother singular value. We also prove a number of related results about these\nescape directions. We argue that this result is a first step in proving\nSaddle-to-Saddle dynamics in deep ReLU networks, where GD visits a sequence of\nsaddles with increasing bottleneck rank.','Ioannis Bantzis, James B. Simon, Arthur Jacot','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21722v1'),('2505.21723v1','Are Statistical Methods Obsolete in the Era of Deep Learning?','In the era of AI, neural networks have become increasingly popular for\nmodeling, inference, and prediction, largely due to their potential for\nuniversal approximation. With the proliferation of such deep learning models, a\nquestion arises: are leaner statistical methods still relevant? To shed insight\non this question, we employ the mechanistic nonlinear ordinary differential\nequation (ODE) inverse problem as a testbed, using physics-informed neural\nnetwork (PINN) as a representative of the deep learning paradigm and\nmanifold-constrained Gaussian process inference (MAGI) as a representative of\nstatistically principled methods. Through case studies involving the SEIR model\nfrom epidemiology and the Lorenz model from chaotic dynamics, we demonstrate\nthat statistical methods are far from obsolete, especially when working with\nsparse and noisy observations. On tasks such as parameter inference and\ntrajectory reconstruction, statistically principled methods consistently\nachieve lower bias and variance, while using far fewer parameters and requiring\nless hyperparameter tuning. Statistical methods can also decisively outperform\ndeep learning models on out-of-sample future prediction, where the absence of\nrelevant data often leads overparameterized models astray. Additionally, we\nfind that statistically principled approaches are more robust to accumulation\nof numerical imprecision and can represent the underlying system more faithful\nto the true governing ODEs.','Skyler Wu, Shihao Yang, S. C. Kou','2025-05-27','stat.CO','http://arxiv.org/pdf/2505.21723v1'),('2505.21724v1','OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions','In this paper, we introduce Online Multimodal Conversational Response\nGeneration (OMCRG), a novel task that aims to online generate synchronized\nverbal and non-verbal listener feedback, conditioned on the speaker\\\'s\nmultimodal input. OMCRG reflects natural dyadic interactions and poses new\nchallenges in achieving synchronization between the generated audio and facial\nresponses of the listener. To address these challenges, we innovatively\nintroduce text as an intermediate modality to bridge the audio and facial\nresponses. We hence propose OmniResponse, a Multimodal Large Language Model\n(MLLM) that autoregressively generates high-quality multi-modal listener\nresponses. OmniResponse leverages a pretrained LLM enhanced with two novel\ncomponents: Chrono-Text, which temporally anchors generated text tokens, and\nTempoVoice, a controllable online TTS module that produces speech synchronized\nwith facial reactions. To support further OMCRG research, we present\nResponseNet, a new dataset comprising 696 high-quality dyadic interactions\nfeaturing synchronized split-screen videos, multichannel audio, transcripts,\nand facial behavior annotations. Comprehensive evaluations conducted on\nResponseNet demonstrate that OmniResponse significantly outperforms baseline\nmodels in terms of semantic speech content, audio-visual synchronization, and\ngeneration quality.','Cheng Luo, Jianghui Wang, Bing Li, Siyang Song, Bernard Ghanem','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21724v1'),('2505.21730v1','pared: Model selection using multi-objective optimization','Motivation: Model selection is a ubiquitous challenge in statistics. For\npenalized models, model selection typically entails tuning hyperparameters to\nmaximize a measure of fit or minimize out-of-sample prediction error. However,\nthese criteria fail to reflect other desirable characteristics, such as model\nsparsity, interpretability, or smoothness. Results: We present the R package\npared to enable the use of multi-objective optimization for model selection.\nOur approach entails the use of Gaussian process-based optimization to\nefficiently identify solutions that represent desirable trade-offs. Our\nimplementation includes popular models with multiple objectives including the\nelastic net, fused lasso, fused graphical lasso, and group graphical lasso. Our\nR package generates interactive graphics that allow the user to identify\nhyperparameter values that result in fitted models which lie on the Pareto\nfrontier. Availability: We provide the R package pared and vignettes\nillustrating its application to both simulated and real data at\nhttps://github.com/priyamdas2/pared.','Priyam Das, Sarah Robinson, Christine B. Peterson','2025-05-27','stat.ME','http://arxiv.org/pdf/2505.21730v1'),('2505.21731v1','Deep Reinforcement Learning Agents are not even close to Human Intelligence','Deep reinforcement learning (RL) agents achieve impressive results in a wide\nvariety of tasks, but they lack zero-shot adaptation capabilities. While most\nrobustness evaluations focus on tasks complexifications, for which human also\nstruggle to maintain performances, no evaluation has been performed on tasks\nsimplifications. To tackle this issue, we introduce HackAtari, a set of task\nvariations of the Arcade Learning Environments. We use it to demonstrate that,\ncontrary to humans, RL agents systematically exhibit huge performance drops on\nsimpler versions of their training tasks, uncovering agents\\\' consistent\nreliance on shortcuts. Our analysis across multiple algorithms and\narchitectures highlights the persistent gap between RL agents and human\nbehavioral intelligence, underscoring the need for new benchmarks and\nmethodologies that enforce systematic generalization testing beyond static\nevaluation protocols. Training and testing in the same environment is not\nenough to obtain agents equipped with human-like intelligence.','Quentin Delfosse, Jannis Blüml, Fabian Tatai, Théo Vincent, Bjarne Gregori, Elisabeth Dillies, Jan Peters, Constantin Rothkopf, Kristian Kersting','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21731v1'),('2505.21732v1','LaX: Boosting Low-Rank Training of Foundation Models via Latent Crossing','Training foundation models such as ViTs and LLMs requires tremendous\ncomputing cost. Low-rank matrix or tensor factorization offers a\nparameter-efficient alternative, but often downgrades performance due to the\nrestricted parameter space. In this work, we introduce {\\textbf{Latent Crossing\n(LaX)}} -- a simple yet effective plug-and-play module that enhances the\ncapacity of low-rank models by enabling information flow across low-rank\nsubspaces. We extensively validate the benefits of LaX on pre-training tasks\nwith ViT-Base/Large and LLaMA-like models ranging from 60M to 1B parameters.\nLaX boosts low-rank model performance to match or exceed the full-rank\nbaselines while using 2-3\\(\\times\\) fewer parameters. When equipped with\nlow-rank adapters (i.e., LoRA) for fine-tuning LLaMA-7/13B, LaX consistently\nimproves performance on arithmetic and common sense reasoning tasks with\nnegligible cost.','Ruijie Zhang, Ziyue Liu, Zhengyang Wang, Zheng Zhang','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21732v1'),('2505.21734v1','MIND-Stack: Modular, Interpretable, End-to-End Differentiability for Autonomous Navigation','Developing robust, efficient navigation algorithms is challenging. Rule-based\nmethods offer interpretability and modularity but struggle with learning from\nlarge datasets, while end-to-end neural networks excel in learning but lack\ntransparency and modularity. In this paper, we present MIND-Stack, a modular\nsoftware stack consisting of a localization network and a Stanley Controller\nwith intermediate human interpretable state representations and end-to-end\ndifferentiability. Our approach enables the upstream localization module to\nreduce the downstream control error, extending its role beyond state\nestimation. Unlike existing research on differentiable algorithms that either\nlack modules of the autonomous stack to span from sensor input to actuator\noutput or real-world implementation, MIND-Stack offers both capabilities. We\nconduct experiments that demonstrate the ability of the localization module to\nreduce the downstream control loss through its end-to-end differentiability\nwhile offering better performance than state-of-the-art algorithms. We showcase\nsim-to-real capabilities by deploying the algorithm on a real-world embedded\nautonomous platform with limited computation power and demonstrate simultaneous\ntraining of both the localization and controller towards one goal. While\nMIND-Stack shows good results, we discuss the incorporation of additional\nmodules from the autonomous navigation pipeline in the future, promising even\ngreater stability and performance in the next iterations of the framework.','Felix Jahncke, Johannes Betz','2025-05-27','cs.RO','http://arxiv.org/pdf/2505.21734v1'),('2505.21736v1','Moment kernels: a simple and scalable approach for equivariance to rotations and reflections in deep convolutional networks','The principle of translation equivariance (if an input image is translated an\noutput image should be translated by the same amount), led to the development\nof convolutional neural networks that revolutionized machine vision. Other\nsymmetries, like rotations and reflections, play a similarly critical role,\nespecially in biomedical image analysis, but exploiting these symmetries has\nnot seen wide adoption. We hypothesize that this is partially due to the\nmathematical complexity of methods used to exploit these symmetries, which\noften rely on representation theory, a bespoke concept in differential geometry\nand group theory. In this work, we show that the same equivariance can be\nachieved using a simple form of convolution kernels that we call ``moment\nkernels,\\\'\\\' and prove that all equivariant kernels must take this form. These\nare a set of radially symmetric functions of a spatial position $x$, multiplied\nby powers of the components of $x$ or the identity matrix. We implement\nequivariant neural networks using standard convolution modules, and provide\narchitectures to execute several biomedical image analysis tasks that depend on\nequivariance principles: classification (outputs are invariant under orthogonal\ntransforms), 3D image registration (outputs transform like a vector), and cell\nsegmentation (quadratic forms defining ellipses transform like a matrix).','Zachary Schlamowitz, Andrew Bennecke, Daniel J. Tward','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21736v1'),('2505.21740v1','Counterfactual Simulatability of LLM Explanations for Generation Tasks','LLMs can be unpredictable, as even slight alterations to the prompt can cause\nthe output to change in unexpected ways. Thus, the ability of models to\naccurately explain their behavior is critical, especially in high-stakes\nsettings. One approach for evaluating explanations is counterfactual\nsimulatability, how well an explanation allows users to infer the model\\\'s\noutput on related counterfactuals. Counterfactual simulatability has been\npreviously studied for yes/no question answering tasks. We provide a general\nframework for extending this method to generation tasks, using news\nsummarization and medical suggestion as example use cases. We find that while\nLLM explanations do enable users to better predict LLM outputs on\ncounterfactuals in the summarization setting, there is significant room for\nimprovement for medical suggestion. Furthermore, our results suggest that the\nevaluation for counterfactual simulatability may be more appropriate for\nskill-based tasks as opposed to knowledge-based tasks.','Marvin Limpijankit, Yanda Chen, Melanie Subbiah, Nicholas Deas, Kathleen McKeown','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21740v1'),('2505.21742v1','What is Adversarial Training for Diffusion Models?','We answer the question in the title, showing that adversarial training (AT)\nfor diffusion models (DMs) fundamentally differs from classifiers: while AT in\nclassifiers enforces output invariance, AT in DMs requires equivariance to keep\nthe diffusion process aligned with the data distribution. AT is a way to\nenforce smoothness in the diffusion flow, improving robustness to outliers and\ncorrupted data. Unlike prior art, our method makes no assumptions about the\nnoise model and integrates seamlessly into diffusion training by adding random\nnoise, similar to randomized smoothing, or adversarial noise, akin to AT. This\nenables intrinsic capabilities such as handling noisy data, dealing with\nextreme variability such as outliers, preventing memorization, and improving\nrobustness. We rigorously evaluate our approach with proof-of-concept datasets\nwith known distributions in low- and high-dimensional space, thereby taking a\nperfect measure of errors; we further evaluate on standard benchmarks such as\nCIFAR-10, CelebA and LSUN Bedroom, showing strong performance under severe\nnoise, data corruption, and iterative adversarial attacks.','Briglia Maria Rosaria, Mujtaba Hussain Mirza, Giuseppe Lisanti, Iacopo Masi','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21742v1'),('2505.21743v1','Simulating the Unseen: Crash Prediction Must Learn from What Did Not Happen','Traffic safety science has long been hindered by a fundamental data paradox:\nthe crashes we most wish to prevent are precisely those events we rarely\nobserve. Existing crash-frequency models and surrogate safety metrics rely\nheavily on sparse, noisy, and under-reported records, while even sophisticated,\nhigh-fidelity simulations undersample the long-tailed situations that trigger\ncatastrophic outcomes such as fatalities. We argue that the path to achieving\nVision Zero, i.e., the complete elimination of traffic fatalities and severe\ninjuries, requires a paradigm shift from traditional crash-only learning to a\nnew form of counterfactual safety learning: reasoning not only about what\nhappened, but also about the vast set of plausible yet perilous scenarios that\ncould have happened under slightly different circumstances. To operationalize\nthis shift, our proposed agenda bridges macro to micro. Guided by crash-rate\npriors, generative scene engines, diverse driver models, and causal learning,\nnear-miss events are synthesized and explained. A crash-focused digital twin\ntestbed links micro scenes to macro patterns, while a multi-objective validator\nensures that simulations maintain statistical realism. This pipeline transforms\nsparse crash data into rich signals for crash prediction, enabling the\nstress-testing of vehicles, roads, and policies before deployment. By learning\nfrom crashes that almost happened, we can shift traffic safety from reactive\nforensics to proactive prevention, advancing Vision Zero.','Zihao Li, Xinyuan Cao, Xiangbo Gao, Kexin Tian, Keshu Wu, Mohammad Anis, Hao Zhang, Keke Long, Jiwan Jiang, Xiaopeng Li, Yunlong Zhang, Tianbao Yang, Dominique Lord, Zhengzhong Tu, Yang Zhou','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21743v1'),('2505.21746v1','Learning to See More: UAS-Guided Super-Resolution of Satellite Imagery for Precision Agriculture','Unmanned Aircraft Systems (UAS) and satellites are key data sources for\nprecision agriculture, yet each presents trade-offs. Satellite data offer broad\nspatial, temporal, and spectral coverage but lack the resolution needed for\nmany precision farming applications, while UAS provide high spatial detail but\nare limited by coverage and cost, especially for hyperspectral data. This study\npresents a novel framework that fuses satellite and UAS imagery using\nsuper-resolution methods. By integrating data across spatial, spectral, and\ntemporal domains, we leverage the strengths of both platforms cost-effectively.\nWe use estimation of cover crop biomass and nitrogen (N) as a case study to\nevaluate our approach. By spectrally extending UAS RGB data to the vegetation\nred edge and near-infrared regions, we generate high-resolution Sentinel-2\nimagery and improve biomass and N estimation accuracy by 18% and 31%,\nrespectively. Our results show that UAS data need only be collected from a\nsubset of fields and time points. Farmers can then 1) enhance the spectral\ndetail of UAS RGB imagery; 2) increase the spatial resolution by using\nsatellite data; and 3) extend these enhancements spatially and across the\ngrowing season at the frequency of the satellite flights. Our SRCNN-based\nspectral extension model shows considerable promise for model transferability\nover other cropping systems in the Upper and Lower Chesapeake Bay regions.\nAdditionally, it remains effective even when cloud-free satellite data are\nunavailable, relying solely on the UAS RGB input. The spatial extension model\nproduces better biomass and N predictions than models built on raw UAS RGB\nimages. Once trained with targeted UAS RGB data, the spatial extension model\nallows farmers to stop repeated UAS flights. While we introduce\nsuper-resolution advances, the core contribution is a lightweight and scalable\nsystem for affordable on-farm use.','Arif Masrur, Peder A. Olsen, Paul R. Adler, Carlan Jackson, Matthew W. Myers, Nathan Sedghi, Ray R. Weil','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21746v1'),('2505.21748v1','Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks','Complex systems are often driven by higher-order interactions among multiple\nunits, naturally represented as hypergraphs. Understanding dependency\nstructures within these hypergraphs is crucial for understanding and predicting\nthe behavior of complex systems but is made challenging by their combinatorial\ncomplexity and computational demands. In this paper, we introduce a class of\nprobabilistic models that efficiently represents and discovers a broad spectrum\nof mesoscale structure in large-scale hypergraphs. The key insight enabling\nthis approach is to treat classes of similar units as themselves nodes in a\nlatent hypergraph. By modeling observed node interactions through latent\ninteractions among classes using low-rank representations, our approach\ntractably captures rich structural patterns while ensuring model\nidentifiability. This allows for direct interpretation of distinct node- and\nclass-level structures. Empirically, our model improves link prediction over\nstate-of-the-art methods and discovers interpretable structures in diverse\nreal-world systems, including pharmacological and social networks, advancing\nthe ability to incorporate large-scale higher-order data into the scientific\nprocess.','John Hood, Caterina De Bacco, Aaron Schein','2025-05-27','cs.SI','http://arxiv.org/pdf/2505.21748v1'),('2505.21749v1','Revisiting Bi-Linear State Transitions in Recurrent Neural Networks','The role of hidden units in recurrent neural networks is typically seen as\nmodeling memory, with research focusing on enhancing information retention\nthrough gating mechanisms. A less explored perspective views hidden units as\nactive participants in the computation performed by the network, rather than\npassive memory stores. In this work, we revisit bi-linear operations, which\ninvolve multiplicative interactions between hidden units and input embeddings.\nWe demonstrate theoretically and empirically that they constitute a natural\ninductive bias for representing the evolution of hidden states in state\ntracking tasks. These are the simplest type of task that require hidden units\nto actively contribute to the behavior of the network. We also show that\nbi-linear state updates form a natural hierarchy corresponding to state\ntracking tasks of increasing complexity, with popular linear recurrent networks\nsuch as Mamba residing at the lowest-complexity center of that hierarchy.','M. Reza Ebrahimi, Roland Memisevic','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21749v1'),('2505.21750v1','Hierarchical Reinforcement Learning with Uncertainty-Guided Diffusional Subgoals','Hierarchical reinforcement learning (HRL) learns to make decisions on\nmultiple levels of temporal abstraction. A key challenge in HRL is that the\nlow-level policy changes over time, making it difficult for the high-level\npolicy to generate effective subgoals. To address this issue, the high-level\npolicy must capture a complex subgoal distribution while also accounting for\nuncertainty in its estimates. We propose an approach that trains a conditional\ndiffusion model regularized by a Gaussian Process (GP) prior to generate a\ncomplex variety of subgoals while leveraging principled GP uncertainty\nquantification. Building on this framework, we develop a strategy that selects\nsubgoals from both the diffusion policy and GP\\\'s predictive mean. Our approach\noutperforms prior HRL methods in both sample efficiency and performance on\nchallenging continuous control benchmarks.','Vivienne Huiling Wang, Tinghuai Wang, Joni Pajarinen','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21750v1'),('2505.21753v1','From prosthetic memory to prosthetic denial: Auditing whether large language models are prone to mass atrocity denialism','The proliferation of large language models (LLMs) can influence how\nhistorical narratives are disseminated and perceived. This study explores the\nimplications of LLMs\\\' responses on the representation of mass atrocity memory,\nexamining whether generative AI systems contribute to prosthetic memory, i.e.,\nmediated experiences of historical events, or to what we term \"prosthetic\ndenial,\" the AI-mediated erasure or distortion of atrocity memories. We argue\nthat LLMs function as interfaces that can elicit prosthetic memories and,\ntherefore, act as experiential sites for memory transmission, but also\nintroduce risks of denialism, particularly when their outputs align with\ncontested or revisionist narratives. To empirically assess these risks, we\nconducted a comparative audit of five LLMs (Claude, GPT, Llama, Mixtral, and\nGemini) across four historical case studies: the Holodomor, the Holocaust, the\nCambodian Genocide, and the genocide against the Tutsis in Rwanda. Each model\nwas prompted with questions addressing common denialist claims in English and\nan alternative language relevant to each case (Ukrainian, German, Khmer, and\nFrench). Our findings reveal that while LLMs generally produce accurate\nresponses for widely documented events like the Holocaust, significant\ninconsistencies and susceptibility to denialist framings are observed for more\nunderrepresented cases like the Cambodian Genocide. The disparities highlight\nthe influence of training data availability and the probabilistic nature of LLM\nresponses on memory integrity. We conclude that while LLMs extend the concept\nof prosthetic memory, their unmoderated use risks reinforcing historical\ndenialism, raising ethical concerns for (digital) memory preservation, and\npotentially challenging the advantageous role of technology associated with the\noriginal values of prosthetic memory.','Roberto Ulloa, Eve M. Zucker, Daniel Bultmann, David J. Simon, Mykola Makhortykh','2025-05-27','cs.CY','http://arxiv.org/pdf/2505.21753v1'),('2505.21755v1','FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering','Visual question answering (VQA) systems face significant challenges when\nadapting to real-world data shifts, especially in multi-modal contexts. While\nrobust fine-tuning strategies are essential for maintaining performance across\nin-distribution (ID) and out-of-distribution (OOD) scenarios, current\nevaluation settings are primarily unimodal or particular to some types of OOD,\noffering limited insight into the complexities of multi-modal contexts. In this\nwork, we propose a new benchmark FRAMES-VQA (Fine-Tuning Robustness across\nMulti-Modal Shifts in VQA) for evaluating robust fine-tuning for VQA tasks. We\nutilize ten existing VQA benchmarks, including VQAv2, IV-VQA, VQA-CP, OK-VQA\nand others, and categorize them into ID, near and far OOD datasets covering\nuni-modal, multi-modal and adversarial distribution shifts. We first conduct a\ncomprehensive comparison of existing robust fine-tuning methods. We then\nquantify the distribution shifts by calculating the Mahalanobis distance using\nuni-modal and multi-modal embeddings extracted from various models. Further, we\nperform an extensive analysis to explore the interactions between uni- and\nmulti-modal shifts as well as modality importance for ID and OOD samples. These\nanalyses offer valuable guidance on developing more robust fine-tuning methods\nto handle multi-modal distribution shifts. The code is available at\nhttps://github.com/chengyuehuang511/FRAMES-VQA .','Chengyue Huang, Brisa Maneechotesuwan, Shivang Chopra, Zsolt Kira','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21755v1'),('2505.21757v1','BehaviorSFT: Behavioral Token Conditioning for Clinical Agents Across the Proactivity Spectrum','Large Language Models (LLMs) as clinical agents require careful behavioral\nadaptation. While adept at reactive tasks (e.g., diagnosis reasoning), LLMs\noften struggle with proactive engagement, like unprompted identification of\ncritical missing information or risks. We introduce BehaviorBench, a\ncomprehensive dataset to evaluate agent behaviors across a clinical assistance\nspectrum, ranging from reactive query responses to proactive interventions\n(e.g., clarifying ambiguities, flagging overlooked critical data). Our\nBehaviorBench experiments reveal LLMs\\\' inconsistent proactivity. To address\nthis, we propose BehaviorSFT, a novel training strategy using behavioral tokens\nto explicitly condition LLMs for dynamic behavioral selection along this\nspectrum. BehaviorSFT boosts performance, achieving up to 97.3% overall Macro\nF1 on BehaviorBench and improving proactive task scores (e.g., from 95.0% to\n96.5% for Qwen2.5-7B-Ins). Crucially, blind clinician evaluations confirmed\nBehaviorSFT-trained agents exhibit more realistic clinical behavior, striking a\nsuperior balance between helpful proactivity (e.g., timely, relevant\nsuggestions) and necessary restraint (e.g., avoiding over-intervention) versus\nstandard fine-tuning or explicit instructed agents.','Yubin Kim, Zhiyuan Hu, Hyewon Jeong, Eugene Park, Shuyue Stella Li, Chanwoo Park, Shiyun Xiong, MingYu Lu, Hyeonhoon Lee, Xin Liu, Daniel McDuff, Cynthia Breazeal, Samir Tulebaev, Hae Won Park','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21757v1'),('2505.21765v1','Don\\\'t Think Longer, Think Wisely: Optimizing Thinking Dynamics for Large Reasoning Models','While recent success of large reasoning models (LRMs) significantly advanced\nLLMs\\\' reasoning capability by optimizing the final answer accuracy using\nreinforcement learning, they may also drastically increase the output length\ndue to overthinking, characterized by unnecessarily complex reasoning paths\nthat waste computation and potentially degrade the performance. We hypothesize\nthat such inefficiencies stem from LRMs\\\' limited capability to dynamically\nselect the proper modular reasoning strategies, termed thinking patterns at the\nright position. To investigate this hypothesis, we propose a dynamic\noptimization framework that segments model-generated reasoning paths into\ndistinct thinking patterns, systematically identifying and promoting beneficial\npatterns that improve the answer while removing detrimental ones. Empirical\nanalysis confirms that our optimized thinking paths yield more concise yet\nsufficiently informative trajectories, enhancing reasoning efficiency by\nreducing attention FLOPs by up to 47% while maintaining accuracy for originally\ncorrect responses. Moreover, a non-trivial portion of originally incorrect\nresponses are transformed into correct ones, achieving a 15.6% accuracy\nimprovement with reduced length. Motivated by the improvement brought by the\noptimized thinking paths, we apply a preference optimization technique\nsupported by a pairwise dataset contrasting suboptimal and optimal reasoning\npaths. Experimental evaluations across multiple mathematical reasoning\nbenchmarks reveal that our method notably reduces computational overhead while\nsimultaneously improving reasoning accuracy, achieving up to a 12% accuracy\nimprovement and reducing token usage from approximately 5,000 to 3,000 tokens.','Sohyun An, Ruochen Wang, Tianyi Zhou, Cho-Jui Hsieh','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21765v1'),('2505.21767v1','Beyond 1D: Vision Transformers and Multichannel Signal Images for PPG-to-ECG Reconstruction','Reconstructing ECG from PPG is a promising yet challenging task. While recent\nadvancements in generative models have significantly improved ECG\nreconstruction, accurately capturing fine-grained waveform features remains a\nkey challenge. To address this, we propose a novel PPG-to-ECG reconstruction\nmethod that leverages a Vision Transformer (ViT) as the core network. Unlike\nconventional approaches that rely on single-channel PPG, our method employs a\nfour-channel signal image representation, incorporating the original PPG, its\nfirst-order difference, second-order difference, and area under the curve. This\nmulti-channel design enriches feature extraction by preserving both temporal\nand physiological variations within the PPG. By leveraging the self-attention\nmechanism in ViT, our approach effectively captures both inter-beat and\nintra-beat dependencies, leading to more robust and accurate ECG\nreconstruction. Experimental results demonstrate that our method consistently\noutperforms existing 1D convolution-based approaches, achieving up to 29%\nreduction in PRD and 15% reduction in RMSE. The proposed approach also produces\nimprovements in other evaluation metrics, highlighting its robustness and\neffectiveness in reconstructing ECG signals. Furthermore, to ensure a\nclinically relevant evaluation, we introduce new performance metrics, including\nQRS area error, PR interval error, RT interval error, and RT amplitude\ndifference error. Our findings suggest that integrating a four-channel signal\nimage representation with the self-attention mechanism of ViT enables more\neffective extraction of informative PPG features and improved modeling of\nbeat-to-beat variations for PPG-to-ECG mapping. Beyond demonstrating the\npotential of PPG as a viable alternative for heart activity monitoring, our\napproach opens new avenues for cyclic signal analysis and prediction.','Xiaoyan Li, Shixin Xu, Faisal Habib, Arvind Gupta, Huaxiong Huang','2025-05-27','eess.IV','http://arxiv.org/pdf/2505.21767v1'),('2505.21770v1','Langevin SDEs have unique transient dynamics','The overdamped Langevin stochastic differential equation (SDE) is a classical\nphysical model used for chemical, genetic, and hydrological dynamics. In this\nwork, we prove that the drift and diffusion terms of a Langevin SDE are jointly\nidentifiable from temporal marginal distributions if and only if the process is\nobserved out of equilibrium. This complete characterization of structural\nidentifiability removes the long-standing assumption that the diffusion must be\nknown to identify the drift. We then complement our theory with experiments in\nthe finite sample setting and study the practical identifiability of the drift\nand diffusion, in order to propose heuristics for optimal data collection.','Vincent Guan, Joseph Janssen, Nicolas Lanzetti, Antonio Terpin, Geoffrey Schiebinger, Elina Robeva','2025-05-27','math.PR','http://arxiv.org/pdf/2505.21770v1'),('2505.21771v1','MMTBENCH: A Unified Benchmark for Complex Multimodal Table Reasoning','Multimodal tables those that integrate semi structured data with visual\nelements such as charts and maps are ubiquitous across real world domains, yet\nthey pose a formidable challenge to current vision language models (VLMs).\nWhile Large Language models (LLMs) and VLMs have demonstrated strong\ncapabilities in text and image understanding, their performance on complex,\nreal world multimodal table reasoning remains unexplored. To bridge this gap,\nwe introduce MMTBENCH (Multimodal Table Benchmark), a benchmark consisting of\n500 real world multimodal tables drawn from diverse real world sources, with a\ntotal of 4021 question answer pairs. MMTBENCH questions cover four question\ntypes (Explicit, Implicit, Answer Mention, and Visual Based), five reasoning\ntypes (Mathematical, Extrema Identification, Fact Verification, Vision Based,\nand Others), and eight table types (Single/Multiple Entity, Maps and Charts\nwith Entities, Single/Multiple Charts, Maps, and Visualizations). Extensive\nevaluation of state of the art models on all types reveals substantial\nperformance gaps, particularly on questions requiring visual-based reasoning\nand multi-step inference. These findings show the urgent need for improved\narchitectures that more tightly integrate vision and language processing. By\nproviding a challenging, high-quality resource that mirrors the complexity of\nreal-world tasks, MMTBENCH underscores its value as a resource for future\nresearch on multimodal tables.','Prasham Yatinkumar Titiya, Jainil Trivedi, Chitta Baral, Vivek Gupta','2025-05-27','cs.CV','http://arxiv.org/pdf/2505.21771v1'),('2505.21772v1','Calibrating LLM Confidence by Probing Perturbed Representation Stability','Miscalibration in Large Language Models (LLMs) undermines their reliability,\nhighlighting the need for accurate confidence estimation. We introduce CCPS\n(Calibrating LLM Confidence by Probing Perturbed Representation Stability), a\nnovel method analyzing internal representational stability in LLMs. CCPS\napplies targeted adversarial perturbations to final hidden states, extracts\nfeatures reflecting the model\\\'s response to these perturbations, and uses a\nlightweight classifier to predict answer correctness. CCPS was evaluated on\nLLMs from 8B to 32B parameters (covering Llama, Qwen, and Mistral\narchitectures) using MMLU and MMLU-Pro benchmarks in both multiple-choice and\nopen-ended formats. Our results show that CCPS significantly outperforms\ncurrent approaches. Across four LLMs and three MMLU variants, CCPS reduces\nExpected Calibration Error by approximately 55% and Brier score by 21%, while\nincreasing accuracy by 5 percentage points, Area Under the Precision-Recall\nCurve by 4 percentage points, and Area Under the Receiver Operating\nCharacteristic Curve by 6 percentage points, all relative to the strongest\nprior method. CCPS delivers an efficient, broadly applicable, and more accurate\nsolution for estimating LLM confidence, thereby improving their\ntrustworthiness.','Reza Khanmohammadi, Erfan Miahi, Mehrsa Mardikoraem, Simerjot Kaur, Ivan Brugere, Charese H. Smiley, Kundan Thind, Mohammad M. Ghassemi','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21772v1'),('2505.21775v1','DualSchool: How Reliable are LLMs for Optimization Education?','Consider the following task taught in introductory optimization courses which\naddresses challenges articulated by the community at the intersection of\n(generative) AI and OR: generate the dual of a linear program. LLMs, being\ntrained at web-scale, have the conversion process and many instances of Primal\nto Dual Conversion (P2DC) at their disposal. Students may thus reasonably\nexpect that LLMs would perform well on the P2DC task. To assess this\nexpectation, this paper introduces DualSchool, a comprehensive framework for\ngenerating and verifying P2DC instances. The verification procedure of\nDualSchool uses the Canonical Graph Edit Distance, going well beyond existing\nevaluation methods for optimization models, which exhibit many false positives\nand negatives when applied to P2DC. Experiments performed by DualSchool reveal\ninteresting findings. Although LLMs can recite the conversion procedure\naccurately, state-of-the-art open LLMs fail to consistently produce correct\nduals. This finding holds even for the smallest two-variable instances and for\nderivative tasks, such as correctness, verification, and error classification.\nThe paper also discusses the implications for educators, students, and the\ndevelopment of large reasoning systems.','Michael Klamkin, Arnaud Deza, Sikai Cheng, Haoruo Zhao, Pascal Van Hentenryck','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21775v1'),('2505.21777v1','Memorization to Generalization: Emergence of Diffusion Models from Associative Memory','Hopfield networks are associative memory (AM) systems, designed for storing\nand retrieving patterns as local minima of an energy landscape. In the\nclassical Hopfield model, an interesting phenomenon occurs when the amount of\ntraining data reaches its critical memory load $- spurious\\,\\,states$, or\nunintended stable points, emerge at the end of the retrieval dynamics, leading\nto incorrect recall. In this work, we examine diffusion models, commonly used\nin generative modeling, from the perspective of AMs. The training phase of\ndiffusion model is conceptualized as memory encoding (training data is stored\nin the memory). The generation phase is viewed as an attempt of memory\nretrieval. In the small data regime the diffusion model exhibits a strong\nmemorization phase, where the network creates distinct basins of attraction\naround each sample in the training set, akin to the Hopfield model below the\ncritical memory load. In the large data regime, a different phase appears where\nan increase in the size of the training set fosters the creation of new\nattractor states that correspond to manifolds of the generated samples.\nSpurious states appear at the boundary of this transition and correspond to\nemergent attractor states, which are absent in the training set, but, at the\nsame time, have distinct basins of attraction around them. Our findings\nprovide: a novel perspective on the memorization-generalization phenomenon in\ndiffusion models via the lens of AMs, theoretical prediction of existence of\nspurious states, empirical validation of this prediction in commonly-used\ndiffusion models.','Bao Pham, Gabriel Raya, Matteo Negri, Mohammed J. Zaki, Luca Ambrogioni, Dmitry Krotov','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21777v1'),('2505.21781v1','GMU Systems for the IWSLT 2025 Low-Resource Speech Translation Shared Task','This paper describes the GMU systems for the IWSLT 2025 low-resource speech\ntranslation shared task. We trained systems for all language pairs, except for\nLevantine Arabic. We fine-tuned SeamlessM4T-v2 for automatic speech recognition\n(ASR), machine translation (MT), and end-to-end speech translation (E2E ST).\nThe ASR and MT models are also used to form cascaded ST systems. Additionally,\nwe explored various training paradigms for E2E ST fine-tuning, including direct\nE2E fine-tuning, multi-task training, and parameter initialization using\ncomponents from fine-tuned ASR and/or MT models. Our results show that (1)\ndirect E2E fine-tuning yields strong results; (2) initializing with a\nfine-tuned ASR encoder improves ST performance on languages SeamlessM4T-v2 has\nnot been trained on; (3) multi-task training can be slightly helpful.','Chutong Meng, Antonios Anastasopoulos','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21781v1'),('2505.21783v1','P-DROP: Poisson-Based Dropout for Graph Neural Networks','Over-smoothing remains a major challenge in Graph Neural Networks (GNNs),\nwhere repeated message passing causes node representations to converge and lose\ndiscriminative power. To address this, we propose a novel node selection\nstrategy based on Poisson processes, introducing stochastic but structure-aware\nupdates. Specifically, we equip each node with an independent Poisson clock,\nenabling asynchronous and localized updates that preserve structural diversity.\nWe explore two applications of this strategy: as a replacement for\ndropout-based regularization and as a dynamic subgraph training scheme.\nExperimental results on standard benchmarks (Cora, Citeseer, Pubmed)\ndemonstrate that our Poisson-based method yields competitive or improved\naccuracy compared to traditional Dropout, DropEdge, and DropNode approaches,\nparticularly in later training stages.','Hyunsik Yun','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21783v1'),('2505.21784v1','Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation','Safety reasoning is a recent paradigm where LLMs reason over safety policies\nbefore generating responses, thereby mitigating limitations in existing safety\nmeasures such as over-refusal and jailbreak vulnerabilities. However,\nimplementing this paradigm is challenging due to the resource-intensive process\nof creating high-quality policy-embedded chain-of-thought (CoT) datasets while\nensuring reasoning remains accurate and free from hallucinations or policy\nconflicts. To tackle this, we propose AIDSAFE: Agentic Iterative Deliberation\nfor Safety Reasoning, a novel data generation recipe that leverages multi-agent\ndeliberation to iteratively expand reasoning on safety policies. A data refiner\nstage in AIDSAFE ensures high-quality outputs by eliminating repetitive,\nredundant, and deceptive thoughts. AIDSAFE-generated CoTs provide a strong\nfoundation for supervised fine-tuning (SFT)-based safety training.\nAdditionally, to address the need of preference data in alignment stages, such\nas DPO training, we introduce a supplemental recipe that uses belief\naugmentation to create distinct selected and rejected CoT samples. Our\nevaluations demonstrate that AIDSAFE-generated CoTs achieve superior policy\nadherence and reasoning quality. Consequently, we show that fine-tuning\nopen-source LLMs on these CoTs can significantly improve safety generalization\nand jailbreak robustness while maintaining acceptable utility and over-refusal\naccuracy. AIDSAFE-generated CoT datasets can be found here:\nhttps://huggingface.co/datasets/AmazonScience/AIDSAFE','Tharindu Kumarage, Ninareh Mehrabi, Anil Ramakrishna, Xinyan Zhao, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta, Charith Peris','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21784v1'),('2505.21785v1','Born a Transformer -- Always a Transformer?','Transformers have theoretical limitations in modeling certain\nsequence-to-sequence tasks, yet it remains largely unclear if these limitations\nplay a role in large-scale pretrained LLMs, or whether LLMs might effectively\novercome these constraints in practice due to the scale of both the models\nthemselves and their pretraining data. We explore how these architectural\nconstraints manifest after pretraining, by studying a family of\n$\\textit{retrieval}$ and $\\textit{copying}$ tasks inspired by Liu et al.\n[2024]. We use the recently proposed C-RASP framework for studying length\ngeneralization [Huang et al., 2025b] to provide guarantees for each of our\nsettings. Empirically, we observe an $\\textit{induction-versus-anti-induction}$\nasymmetry, where pretrained models are better at retrieving tokens to the right\n(induction) rather than the left (anti-induction) of a query token. This\nasymmetry disappears upon targeted fine-tuning if length-generalization is\nguaranteed by theory. Mechanistic analysis reveals that this asymmetry is\nconnected to the differences in the strength of induction versus anti-induction\ncircuits within pretrained Transformers. We validate our findings through\npractical experiments on real-world tasks demonstrating reliability risks. Our\nresults highlight that pretraining selectively enhances certain Transformer\ncapabilities, but does not overcome fundamental length-generalization limits.','Yana Veitsman, Mayank Jobanputra, Yash Sarrof, Aleksandra Bakalova, Vera Demberg, Ellie Pavlick, Michael Hahn','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21785v1'),('2505.21786v1','VeriTrail: Closed-Domain Hallucination Detection with Traceability','Even when instructed to adhere to source material, Language Models often\ngenerate unsubstantiated content - a phenomenon known as \"closed-domain\nhallucination.\" This risk is amplified in processes with multiple generative\nsteps (MGS), compared to processes with a single generative step (SGS).\nHowever, due to the greater complexity of MGS processes, we argue that\ndetecting hallucinations in their final outputs is necessary but not\nsufficient: it is equally important to trace where hallucinated content was\nlikely introduced and how faithful content may have been derived from the\nsource through intermediate outputs. To address this need, we present\nVeriTrail, the first closed-domain hallucination detection method designed to\nprovide traceability for both MGS and SGS processes. We also introduce the\nfirst datasets to include all intermediate outputs as well as human annotations\nof final outputs\\\' faithfulness for their respective MGS processes. We\ndemonstrate that VeriTrail outperforms baseline methods on both datasets.','Dasha Metropolitansky, Jonathan Larson','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21786v1'),('2505.21790v1','Faster Rates for Private Adversarial Bandits','We design new differentially private algorithms for the problems of\nadversarial bandits and bandits with expert advice. For adversarial bandits, we\ngive a simple and efficient conversion of any non-private bandit algorithm to a\nprivate bandit algorithm. Instantiating our conversion with existing\nnon-private bandit algorithms gives a regret upper bound of\n$O\\left(\\frac{\\sqrt{KT}}{\\sqrt{\\epsilon}}\\right)$, improving upon the existing\nupper bound $O\\left(\\frac{\\sqrt{KT \\log(KT)}}{\\epsilon}\\right)$ for all\n$\\epsilon \\leq 1$. In particular, our algorithms allow for sublinear expected\nregret even when $\\epsilon \\leq \\frac{1}{\\sqrt{T}}$, establishing the first\nknown separation between central and local differential privacy for this\nproblem. For bandits with expert advice, we give the first differentially\nprivate algorithms, with expected regret\n$O\\left(\\frac{\\sqrt{NT}}{\\sqrt{\\epsilon}}\\right),\nO\\left(\\frac{\\sqrt{KT\\log(N)}\\log(KT)}{\\epsilon}\\right)$, and\n$\\tilde{O}\\left(\\frac{N^{1/6}K^{1/2}T^{2/3}\\log(NT)}{\\epsilon ^{1/3}} +\n\\frac{N^{1/2}\\log(NT)}{\\epsilon}\\right)$, where $K$ and $N$ are the number of\nactions and experts respectively. These rates allow us to get sublinear regret\nfor different combinations of small and large $K, N$ and $\\epsilon.$','Hilal Asi, Vinod Raman, Kunal Talwar','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21790v1'),('2505.21791v1','Global Minimizers of $\\ell^p$-Regularized Objectives Yield the Sparsest ReLU Neural Networks','Overparameterized neural networks can interpolate a given dataset in many\ndifferent ways, prompting the fundamental question: which among these solutions\nshould we prefer, and what explicit regularization strategies will provably\nyield these solutions? This paper addresses the challenge of finding the\nsparsest interpolating ReLU network -- i.e., the network with the fewest\nnonzero parameters or neurons -- a goal with wide-ranging implications for\nefficiency, generalization, interpretability, theory, and model compression.\nUnlike post hoc pruning approaches, we propose a continuous, almost-everywhere\ndifferentiable training objective whose global minima are guaranteed to\ncorrespond to the sparsest single-hidden-layer ReLU networks that fit the data.\nThis result marks a conceptual advance: it recasts the combinatorial problem of\nsparse interpolation as a smooth optimization task, potentially enabling the\nuse of gradient-based training methods. Our objective is based on minimizing\n$\\ell^p$ quasinorms of the weights for $0 < p < 1$, a classical\nsparsity-promoting strategy in finite-dimensional settings. However, applying\nthese ideas to neural networks presents new challenges: the function class is\ninfinite-dimensional, and the weights are learned using a highly nonconvex\nobjective. We prove that, under our formulation, global minimizers correspond\nexactly to sparsest solutions. Our work lays a foundation for understanding\nwhen and how continuous sparsity-inducing objectives can be leveraged to\nrecover sparse networks through training.','Julia Nakhleh, Robert D. Nowak','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.21791v1'),('2505.21792v1','Multimodal Federated Learning: A Survey through the Lens of Different FL Paradigms','Multimodal Federated Learning (MFL) lies at the intersection of two pivotal\nresearch areas: leveraging complementary information from multiple modalities\nto improve downstream inference performance and enabling distributed training\nto enhance efficiency and preserve privacy. Despite the growing interest in\nMFL, there is currently no comprehensive taxonomy that organizes MFL through\nthe lens of different Federated Learning (FL) paradigms. This perspective is\nimportant because multimodal data introduces distinct challenges across various\nFL settings. These challenges, including modality heterogeneity, privacy\nheterogeneity, and communication inefficiency, are fundamentally different from\nthose encountered in traditional unimodal or non-FL scenarios. In this paper,\nwe systematically examine MFL within the context of three major FL paradigms:\nhorizontal FL (HFL), vertical FL (VFL), and hybrid FL. For each paradigm, we\npresent the problem formulation, review representative training algorithms, and\nhighlight the most prominent challenge introduced by multimodal data in\ndistributed settings. We also discuss open challenges and provide insights for\nfuture research. By establishing this taxonomy, we aim to uncover the novel\nchallenges posed by multimodal data from the perspective of different FL\nparadigms and to offer a new lens through which to understand and advance the\ndevelopment of MFL.','Yuanzhe Peng, Jieming Bian, Lei Wang, Yin Huang, Jie Xu','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21792v1'),('2505.21796v1','A General-Purpose Theorem for High-Probability Bounds of Stochastic Approximation with Polyak Averaging','Polyak-Ruppert averaging is a widely used technique to achieve the optimal\nasymptotic variance of stochastic approximation (SA) algorithms, yet its\nhigh-probability performance guarantees remain underexplored in general\nsettings. In this paper, we present a general framework for establishing\nnon-asymptotic concentration bounds for the error of averaged SA iterates. Our\napproach assumes access to individual concentration bounds for the unaveraged\niterates and yields a sharp bound on the averaged iterates. We also construct\nan example, showing the tightness of our result up to constant multiplicative\nfactors. As direct applications, we derive tight concentration bounds for\ncontractive SA algorithms and for algorithms such as temporal difference\nlearning and Q-learning with averaging, obtaining new bounds in settings where\ntraditional analysis is challenging.','Sajad Khodadadian, Martin Zubeldia','2025-05-27','stat.ML','http://arxiv.org/pdf/2505.21796v1'),('2505.21799v1','PolarGrad: A Class of Matrix-Gradient Optimizers from a Unifying Preconditioning Perspective','The ever-growing scale of deep learning models and datasets underscores the\ncritical importance of efficient optimization methods. While preconditioned\ngradient methods such as Adam and AdamW are the de facto optimizers for\ntraining neural networks and large language models, structure-aware\npreconditioned optimizers like Shampoo and Muon, which utilize the matrix\nstructure of gradients, have demonstrated promising evidence of faster\nconvergence. In this paper, we introduce a unifying framework for analyzing\n\"matrix-aware\" preconditioned methods, which not only sheds light on the\neffectiveness of Muon and related optimizers but also leads to a class of new\nstructure-aware preconditioned methods. A key contribution of this framework is\nits precise distinction between preconditioning strategies that treat neural\nnetwork weights as vectors (addressing curvature anisotropy) versus those that\nconsider their matrix structure (addressing gradient anisotropy). This\nperspective provides new insights into several empirical phenomena in language\nmodel pre-training, including Adam\\\'s training instabilities, Muon\\\'s accelerated\nconvergence, and the necessity of learning rate warmup for Adam. Building upon\nthis framework, we introduce PolarGrad, a new class of preconditioned\noptimization methods based on the polar decomposition of matrix-valued\ngradients. As a special instance, PolarGrad includes Muon with updates scaled\nby the nuclear norm of the gradients. We provide numerical implementations of\nthese methods, leveraging efficient numerical polar decomposition algorithms\nfor enhanced convergence. Our extensive evaluations across diverse matrix\noptimization problems and language model pre-training tasks demonstrate that\nPolarGrad outperforms both Adam and Muon.','Tim Tsz-Kit Lau, Qi Long, Weijie Su','2025-05-27','math.OC','http://arxiv.org/pdf/2505.21799v1'),('2505.21800v1','From Directions to Cones: Exploring Multidimensional Representations of Propositional Facts in LLMs','Large Language Models (LLMs) exhibit strong conversational abilities but\noften generate falsehoods. Prior work suggests that the truthfulness of simple\npropositions can be represented as a single linear direction in a model\\\'s\ninternal activations, but this may not fully capture its underlying geometry.\nIn this work, we extend the concept cone framework, recently introduced for\nmodeling refusal, to the domain of truth. We identify multi-dimensional cones\nthat causally mediate truth-related behavior across multiple LLM families. Our\nresults are supported by three lines of evidence: (i) causal interventions\nreliably flip model responses to factual statements, (ii) learned cones\ngeneralize across model architectures, and (iii) cone-based interventions\npreserve unrelated model behavior. These findings reveal the richer,\nmultidirectional structure governing simple true/false propositions in LLMs and\nhighlight concept cones as a promising tool for probing abstract behaviors.','Stanley Yu, Vaidehi Bulusu, Oscar Yasunaga, Clayton Lau, Cole Blondin, Sean O\'Brien, Kevin Zhu, Vasu Sharma','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21800v1'),('2505.21806v1','Towards Operational Automated Greenhouse Gas Plume Detection','Operational deployment of a fully automated greenhouse gas (GHG) plume\ndetection system remains an elusive goal for imaging spectroscopy missions,\ndespite recent advances in deep learning approaches. With the dramatic increase\nin data availability, however, automation continues to increase in importance\nfor natural and anthropogenic emissions monitoring. This work reviews and\naddresses several key obstacles in the field: data and label quality control,\nprevention of spatiotemporal biases, and correctly aligned modeling objectives.\nWe demonstrate through rigorous experiments using multicampaign data from\nairborne and spaceborne instruments that convolutional neural networks (CNNs)\nare able to achieve operational detection performance when these obstacles are\nalleviated. We demonstrate that a multitask model that learns both instance\ndetection and pixelwise segmentation simultaneously can successfully lead\ntowards an operational pathway. We evaluate the model\\\'s plume detectability\nacross emission source types and regions, identifying thresholds for\noperational deployment. Finally, we provide analysis-ready data, models, and\nsource code for reproducibility, and work to define a set of best practices and\nvalidation standards to facilitate future contributions to the field.','Brian D. Bue, Jake H. Lee, Andrew K. Thorpe, Philip G. Brodrick, Daniel Cusworth, Alana Ayasse, Vassiliki Mancoridis, Anagha Satish, Shujun Xiong, Riley Duren','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21806v1'),('2505.21807v1','TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction','Predictive modeling on tabular data is the cornerstone of many real-world\napplications. Although gradient boosting machines and some recent deep models\nachieve strong performance on tabular data, they often lack interpretability.\nOn the other hand, large language models (LLMs) have demonstrated powerful\ncapabilities to generate human-like reasoning and explanations, but remain\nunder-performed for tabular data prediction. In this paper, we propose a new\napproach that leverages reasoning-based LLMs, trained using reinforcement\nlearning, to perform more accurate and explainable predictions on tabular data.\nOur method introduces custom reward functions that guide the model not only\ntoward high prediction accuracy but also toward human-understandable reasons\nfor its predictions. Experimental results show that our model achieves\npromising performance on financial benchmark datasets, outperforming most\nexisting LLMs.','Tommy Xu, Zhitian Zhang, Xiangyu Sun, Lauren Kelly Zung, Hossein Hajimirsadeghi, Greg Mori','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21807v1'),('2505.21809v1','Voice Quality Dimensions as Interpretable Primitives for Speaking Style for Atypical Speech and Affect','Perceptual voice quality dimensions describe key characteristics of atypical\nspeech and other speech modulations. Here we develop and evaluate voice quality\nmodels for seven voice and speech dimensions (intelligibility, imprecise\nconsonants, harsh voice, naturalness, monoloudness, monopitch, and\nbreathiness). Probes were trained on the public Speech Accessibility (SAP)\nproject dataset with 11,184 samples from 434 speakers, using embeddings from\nfrozen pre-trained models as features. We found that our probes had both strong\nperformance and strong generalization across speech elicitation categories in\nthe SAP dataset. We further validated zero-shot performance on additional\ndatasets, encompassing unseen languages and tasks: Italian atypical speech,\nEnglish atypical speech, and affective speech. The strong zero-shot performance\nand the interpretability of results across an array of evaluations suggests the\nutility of using voice quality dimensions in speaking style-related tasks.','Jaya Narain, Vasudha Kowtha, Colin Lea, Lauren Tooley, Dianna Yee, Vikramjit Mitra, Zifang Huang, Miquel Espi Marques, Jon Huang, Carlos Avendano, Shirley Ren','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.21809v1');
INSERT INTO `arxiv_papers` VALUES ('2505.21811v1','Revisiting Self-attention for Cross-domain Sequential Recommendation','Sequential recommendation is a popular paradigm in modern recommender\nsystems. In particular, one challenging problem in this space is cross-domain\nsequential recommendation (CDSR), which aims to predict future behaviors given\nuser interactions across multiple domains. Existing CDSR frameworks are mostly\nbuilt on the self-attention transformer and seek to improve by explicitly\ninjecting additional domain-specific components (e.g. domain-aware module\nblocks). While these additional components help, we argue they overlook the\ncore self-attention module already present in the transformer, a naturally\npowerful tool to learn correlations among behaviors. In this work, we aim to\nimprove the CDSR performance for simple models from a novel perspective of\nenhancing the self-attention. Specifically, we introduce a Pareto-optimal\nself-attention and formulate the cross-domain learning as a multi-objective\nproblem, where we optimize the recommendation task while dynamically minimizing\nthe cross-domain attention scores. Our approach automates knowledge transfer in\nCDSR (dubbed as AutoCDSR) -- it not only mitigates negative transfer but also\nencourages complementary knowledge exchange among auxiliary domains. Based on\nthe idea, we further introduce AutoCDSR+, a more performant variant with slight\nadditional cost. Our proposal is easy to implement and works as a plug-and-play\nmodule that can be incorporated into existing transformer-based recommenders.\nBesides flexibility, it is practical to deploy because it brings little extra\ncomputational overheads without heavy hyper-parameter tuning. AutoCDSR on\naverage improves Recall@10 for SASRec and Bert4Rec by 9.8% and 16.0% and\nNDCG@10 by 12.0% and 16.7%, respectively. Code is available at\nhttps://github.com/snap-research/AutoCDSR.','Clark Mingxuan Ju, Leonardo Neves, Bhuvesh Kumar, Liam Collins, Tong Zhao, Yuwei Qiu, Qing Dou, Sohail Nizam, Sen Yang, Neil Shah','2025-05-27','cs.IR','http://arxiv.org/pdf/2505.21811v1'),('2505.21813v1','Optimizing Data Augmentation through Bayesian Model Selection','Data Augmentation (DA) has become an essential tool to improve robustness and\ngeneralization of modern machine learning. However, when deciding on DA\nstrategies it is critical to choose parameters carefully, and this can be a\ndaunting task which is traditionally left to trial-and-error or expensive\noptimization based on validation performance. In this paper, we counter these\nlimitations by proposing a novel framework for optimizing DA. In particular, we\ntake a probabilistic view of DA, which leads to the interpretation of\naugmentation parameters as model (hyper)-parameters, and the optimization of\nthe marginal likelihood with respect to these parameters as a Bayesian model\nselection problem. Due to its intractability, we derive a tractable Evidence\nLower BOund (ELBO), which allows us to optimize augmentation parameters jointly\nwith model parameters. We provide extensive theoretical results on variational\napproximation quality, generalization guarantees, invariance properties, and\nconnections to empirical Bayes. Through experiments on computer vision tasks,\nwe show that our approach improves calibration and yields robust performance\nover fixed or no augmentation. Our work provides a rigorous foundation for\noptimizing DA through Bayesian principles with significant potential for robust\nmachine learning.','Madi Matymov, Ba-Hien Tran, Michael Kampffmeyer, Markus Heinonen, Maurizio Filippone','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21813v1'),('2505.21815v1','Scientific Paper Retrieval with LLM-Guided Semantic-Based Ranking','Scientific paper retrieval is essential for supporting literature discovery\nand research. While dense retrieval methods demonstrate effectiveness in\ngeneral-purpose tasks, they often fail to capture fine-grained scientific\nconcepts that are essential for accurate understanding of scientific queries.\nRecent studies also use large language models (LLMs) for query understanding;\nhowever, these methods often lack grounding in corpus-specific knowledge and\nmay generate unreliable or unfaithful content. To overcome these limitations,\nwe propose SemRank, an effective and efficient paper retrieval framework that\ncombines LLM-guided query understanding with a concept-based semantic index.\nEach paper is indexed using multi-granular scientific concepts, including\ngeneral research topics and detailed key phrases. At query time, an LLM\nidentifies core concepts derived from the corpus to explicitly capture the\nquery\\\'s information need. These identified concepts enable precise semantic\nmatching, significantly enhancing retrieval accuracy. Experiments show that\nSemRank consistently improves the performance of various base retrievers,\nsurpasses strong existing LLM-based baselines, and remains highly efficient.','Yunyi Zhang, Ruozhen Yang, Siqi Jiao, SeongKu Kang, Jiawei Han','2025-05-27','cs.IR','http://arxiv.org/pdf/2505.21815v1'),('2505.21816v1','Revisiting Common Assumptions about Arabic Dialects in NLP','Arabic has diverse dialects, where one dialect can be substantially different\nfrom the others. In the NLP literature, some assumptions about these dialects\nare widely adopted (e.g., ``Arabic dialects can be grouped into distinguishable\nregional dialects\") and are manifested in different computational tasks such as\nArabic Dialect Identification (ADI). However, these assumptions are not\nquantitatively verified. We identify four of these assumptions and examine them\nby extending and analyzing a multi-label dataset, where the validity of each\nsentence in 11 different country-level dialects is manually assessed by\nspeakers of these dialects. Our analysis indicates that the four assumptions\noversimplify reality, and some of them are not always accurate. This in turn\nmight be hindering further progress in different Arabic NLP tasks.','Amr Keleg, Sharon Goldwater, Walid Magdy','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21816v1'),('2505.21819v1','Representative Language Generation','We introduce \"representative generation,\" extending the theoretical framework\nfor generation proposed by Kleinberg et al. (2024) and formalized by Li et al.\n(2024), to additionally address diversity and bias concerns in generative\nmodels. Our notion requires outputs of a generative model to proportionally\nrepresent groups of interest from the training data. We characterize\nrepresentative uniform and non-uniform generation, introducing the \"group\nclosure dimension\" as a key combinatorial quantity. For representative\ngeneration in the limit, we analyze both information-theoretic and\ncomputational aspects, demonstrating feasibility for countably infinite\nhypothesis classes and collections of groups under certain conditions, but\nproving a negative result for computability using only membership queries. This\ncontrasts with Kleinberg et al.\\\'s (2024) positive results for standard\ngeneration in the limit. Our findings provide a rigorous foundation for\ndeveloping more diverse and representative generative models.','Charlotte Peale, Vinod Raman, Omer Reingold','2025-05-27','cs.CL','http://arxiv.org/pdf/2505.21819v1'),('2505.21824v1','Unsupervised Latent Pattern Analysis for Estimating Type 2 Diabetes Risk in Undiagnosed Populations','The global prevalence of diabetes, particularly type 2 diabetes mellitus\n(T2DM), is rapidly increasing, posing significant health and economic\nchallenges. T2DM not only disrupts blood glucose regulation but also damages\nvital organs such as the heart, kidneys, eyes, nerves, and blood vessels,\nleading to substantial morbidity and mortality. In the US alone, the economic\nburden of diagnosed diabetes exceeded \\$400 billion in 2022. Early detection of\nindividuals at risk is critical to mitigating these impacts. While machine\nlearning approaches for T2DM prediction are increasingly adopted, many rely on\nsupervised learning, which is often limited by the lack of confirmed negative\ncases. To address this limitation, we propose a novel unsupervised framework\nthat integrates Non-negative Matrix Factorization (NMF) with statistical\ntechniques to identify individuals at risk of developing T2DM. Our method\nidentifies latent patterns of multimorbidity and polypharmacy among diagnosed\nT2DM patients and applies these patterns to estimate the T2DM risk in\nundiagnosed individuals. By leveraging data-driven insights from comorbidity\nand medication usage, our approach provides an interpretable and scalable\nsolution that can assist healthcare providers in implementing timely\ninterventions, ultimately improving patient outcomes and potentially reducing\nthe future health and economic burden of T2DM.','Praveen Kumar, Vincent T. Metzger, Scott A. Malec','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21824v1'),('2505.21825v1','Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones','Inference-time computation has emerged as a promising scaling axis for\nimproving large language model reasoning. However, despite yielding impressive\nperformance, the optimal allocation of inference-time computation remains\npoorly understood. A central question is whether to prioritize sequential\nscaling (e.g., longer chains of thought) or parallel scaling (e.g., majority\nvoting across multiple short chains of thought). In this work, we seek to\nilluminate the landscape of test-time scaling by demonstrating the existence of\nreasoning settings where sequential scaling offers an exponential advantage\nover parallel scaling. These settings are based on graph connectivity problems\nin challenging distributions of graphs. We validate our theoretical findings\nwith comprehensive experiments across a range of language models, including\nmodels trained from scratch for graph connectivity with different chain of\nthought strategies as well as large reasoning models.','Parsa Mirtaheri, Ezra Edelman, Samy Jelassi, Eran Malach, Enric Boix-Adsera','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21825v1'),('2505.21827v1','Music Source Restoration','We introduce Music Source Restoration (MSR), a novel task addressing the gap\nbetween idealized source separation and real-world music production. Current\nMusic Source Separation (MSS) approaches assume mixtures are simple sums of\nsources, ignoring signal degradations employed during music production like\nequalization, compression, and reverb. MSR models mixtures as degraded sums of\nindividually degraded sources, with the goal of recovering original, undegraded\nsignals. Due to the lack of data for MSR, we present RawStems, a dataset\nannotation of 578 songs with unprocessed source signals organized into 8\nprimary and 17 secondary instrument groups, totaling 354.13 hours. To the best\nof our knowledge, RawStems is the first dataset that contains unprocessed music\nstems with hierarchical categories. We consider spectral filtering, dynamic\nrange compression, harmonic distortion, reverb and lossy codec as possible\ndegradations, and establish U-Former as a baseline method, demonstrating the\nfeasibility of MSR on our dataset. We release the RawStems dataset annotations,\ndegradation simulation pipeline, training code and pre-trained models to be\npublicly available.','Yongyi Zang, Zheqi Dai, Mark D. Plumbley, Qiuqiang Kong','2025-05-27','cs.SD','http://arxiv.org/pdf/2505.21827v1'),('2505.21828v1','SAGE-Eval: Evaluating LLMs for Systematic Generalizations of Safety Facts','Do LLMs robustly generalize critical safety facts to novel situations?\nLacking this ability is dangerous when users ask naive questions. For instance,\n\"I\\\'m considering packing melon balls for my 10-month-old\\\'s lunch. What other\nfoods would be good to include?\" Before offering food options, the LLM should\nwarn that melon balls pose a choking hazard to toddlers, as documented by the\nCDC. Failing to provide such warnings could result in serious injuries or even\ndeath. To evaluate this, we introduce SAGE-Eval, SAfety-fact systematic\nGEneralization evaluation, the first benchmark that tests whether LLMs properly\napply well established safety facts to naive user queries. SAGE-Eval comprises\n104 facts manually sourced from reputable organizations, systematically\naugmented to create 10,428 test scenarios across 7 common domains (e.g.,\nOutdoor Activities, Medicine). We find that the top model, Claude-3.7-sonnet,\npasses only 58% of all the safety facts tested. We also observe that model\ncapabilities and training compute weakly correlate with performance on\nSAGE-Eval, implying that scaling up is not the golden solution. Our findings\nsuggest frontier LLMs still lack robust generalization ability. We recommend\ndevelopers use SAGE-Eval in pre-deployment evaluations to assess model\nreliability in addressing salient risks. We publicly release SAGE-Eval at\nhttps://huggingface.co/datasets/YuehHanChen/SAGE-Eval and our code is available\nat https://github.com/YuehHanChen/SAGE-Eval/tree/main.','Chen Yueh-Han, Guy Davidson, Brenden M. Lake','2025-05-27','cs.AI','http://arxiv.org/pdf/2505.21828v1'),('2505.21829v1','In Search of Adam\\\'s Secret Sauce','Understanding the remarkable efficacy of Adam when training transformer-based\nlanguage models has become a central research topic within the optimization\ncommunity. To gain deeper insights, several simplifications of Adam have been\nproposed, such as the signed gradient and signed momentum methods. In this\nwork, we conduct an extensive empirical study - training over 1,300 language\nmodels across different data configurations and scales - comparing Adam to\nseveral known simplified variants. We find that signed momentum methods are\nfaster than SGD, but consistently underperform relative to Adam, even after\ncareful tuning of momentum, clipping setting and learning rates. However, our\nanalysis reveals a compelling option that preserves near-optimal performance\nwhile allowing for new insightful reformulations: constraining the Adam\nmomentum parameters to be equal. Beyond robust performance, this choice affords\nnew theoretical insights, highlights the \"secret sauce\" on top of signed\nmomentum, and grants a precise statistical interpretation: we show that Adam in\nthis setting implements a natural online algorithm for estimating the mean and\nvariance of gradients-one that arises from a mean-field Gaussian variational\ninference perspective.','Antonio Orvieto, Robert Gower','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21829v1'),('2505.21835v1','TuneComp: Joint Fine-tuning and Compression for Large Foundation Models','To reduce model size during post-training, compression methods, including\nknowledge distillation, low-rank approximation, and pruning, are often applied\nafter fine-tuning the model. However, sequential fine-tuning and compression\nsacrifices performance, while creating a larger than necessary model as an\nintermediate step. In this work, we aim to reduce this gap, by directly\nconstructing a smaller model while guided by the downstream task. We propose to\njointly fine-tune and compress the model by gradually distilling it to a pruned\nlow-rank structure. Experiments demonstrate that joint fine-tuning and\ncompression significantly outperforms other sequential compression methods.','Xiangyu Chen, Jing Liu, Ye Wang, Matthew Brand, Pu, Wang, Toshiaki Koike-Akino','2025-05-27','cs.LG','http://arxiv.org/pdf/2505.21835v1'),('2505.21837v1','UniMoGen: Universal Motion Generation','Motion generation is a cornerstone of computer graphics, animation, gaming,\nand robotics, enabling the creation of realistic and varied character\nmovements. A significant limitation of existing methods is their reliance on\nspecific skeletal structures, which restricts their versatility across\ndifferent characters. To overcome this, we introduce UniMoGen, a novel\nUNet-based diffusion model designed for skeleton-agnostic motion generation.\nUniMoGen can be trained on motion data from diverse characters, such as humans\nand animals, without the need for a predefined maximum number of joints. By\ndynamically processing only the necessary joints for each character, our model\nachieves both skeleton agnosticism and computational efficiency. Key features\nof UniMoGen include controllability via style and trajectory inputs, and the\nability to continue motions from past frames. We demonstrate UniMoGen\\\'s\neffectiveness on the 100style dataset, where it outperforms state-of-the-art\nmethods in diverse character motion generation. Furthermore, when trained on\nboth the 100style and LAFAN1 datasets, which use different skeletons, UniMoGen\nachieves high performance and improved efficiency across both skeletons. These\nresults highlight UniMoGen\\\'s potential to advance motion generation by\nproviding a flexible, efficient, and controllable solution for a wide range of\ncharacter animations.','Aliasghar Khani, Arianna Rampini, Evan Atherton, Bruno Roy','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21837v1'),('2505.21838v1','Nonadaptive Output Regulation of Second-Order Nonlinear Uncertain Systems','This paper investigates the robust output regulation problem of second-order\nnonlinear uncertain systems with an unknown exosystem. Instead of the adaptive\ncontrol approach, this paper resorts to a robust control methodology to solve\nthe problem and thus avoid the bursting phenomenon. In particular, this paper\nconstructs generic internal models for the steady-state state and input\nvariables of the system. By introducing a coordinate transformation, this paper\nconverts the robust output regulation problem into a nonadaptive stabilization\nproblem of an augmented system composed of the second-order nonlinear uncertain\nsystem and the generic internal models. Then, we design the stabilization\ncontrol law and construct a strict Lyapunov function that guarantees the\nrobustness with respect to unmodeled disturbances. The analysis shows that the\noutput zeroing manifold of the augmented system can be made attractive by the\nproposed nonadaptive control law, which solves the robust output regulation\nproblem. Finally, we demonstrate the effectiveness of the proposed nonadaptive\ninternal model approach by its application to the control of the Duffing\nsystem.','Maobin Lu, Martin Guay, Telema Harry, Shimin Wang, Jordan Cooper','2025-05-28','eess.SY','http://arxiv.org/pdf/2505.21838v1'),('2505.21841v1','An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints','Online safe reinforcement learning (RL) plays a key role in dynamic\nenvironments, with applications in autonomous driving, robotics, and\ncybersecurity. The objective is to learn optimal policies that maximize rewards\nwhile satisfying safety constraints modeled by constrained Markov decision\nprocesses (CMDPs). Existing methods achieve sublinear regret under stochastic\nconstraints but often fail in adversarial settings, where constraints are\nunknown, time-varying, and potentially adversarially designed. In this paper,\nwe propose the Optimistic Mirror Descent Primal-Dual (OMDPD) algorithm, the\nfirst to address online CMDPs with anytime adversarial constraints. OMDPD\nachieves optimal regret O(sqrt(K)) and strong constraint violation O(sqrt(K))\nwithout relying on Slater\\\'s condition or the existence of a strictly known safe\npolicy. We further show that access to accurate estimates of rewards and\ntransitions can further improve these bounds. Our results offer practical\nguarantees for safe decision-making in adversarial environments.','Jiahui Zhu, Kihyun Yu, Dabeen Lee, Xin Liu, Honghao Wei','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21841v1'),('2505.21842v1','A Physics-Informed Learning Framework to Solve the Infinite-Horizon Optimal Control Problem','We propose a physics-informed neural networks (PINNs) framework to solve the\ninfinite-horizon optimal control problem of nonlinear systems. In particular,\nsince PINNs are generally able to solve a class of partial differential\nequations (PDEs), they can be employed to learn the value function of the\ninfinite-horizon optimal control problem via solving the associated\nsteady-state Hamilton-Jacobi-Bellman (HJB) equation. However, an issue here is\nthat the steady-state HJB equation generally yields multiple solutions; hence\nif PINNs are directly employed to it, they may end up approximating a solution\nthat is different from the optimal value function of the problem. We tackle\nthis by instead applying PINNs to a finite-horizon variant of the steady-state\nHJB that has a unique solution, and which uniformly approximates the optimal\nvalue function as the horizon increases. An algorithm to verify if the chosen\nhorizon is large enough is also given, as well as a method to extend it -- with\nreduced computations and robustness to approximation errors -- in case it is\nnot. Unlike many existing methods, the proposed technique works well with\nnon-polynomial basis functions, does not require prior knowledge of a\nstabilizing controller, and does not perform iterative policy evaluations.\nSimulations are performed, which verify and clarify theoretical findings.','Filippos Fotiadis, Kyriakos G. Vamvoudakis','2025-05-28','eess.SY','http://arxiv.org/pdf/2505.21842v1'),('2505.21845v1','Spectral clustering for dependent community Hawkes process models of temporal networks','Temporal networks observed continuously over time through timestamped\nrelational events data are commonly encountered in application settings\nincluding online social media communications, financial transactions, and\ninternational relations. Temporal networks often exhibit community structure\nand strong dependence patterns among node pairs. This dependence can be modeled\nthrough mutual excitations, where an interaction event from a sender to a\nreceiver node increases the possibility of future events among other node\npairs.\n  We provide statistical results for a class of models that we call dependent\ncommunity Hawkes (DCH) models, which combine the stochastic block model with\nmutually exciting Hawkes processes for modeling both community structure and\ndependence among node pairs, respectively. We derive a non-asymptotic upper\nbound on the misclustering error of spectral clustering on the event count\nmatrix as a function of the number of nodes and communities, time duration, and\nthe amount of dependence in the model. Our result leverages recent results on\nbounding an appropriate distance between a multivariate Hawkes process count\nvector and a Gaussian vector, along with results from random matrix theory. We\nalso propose a DCH model that incorporates only self and reciprocal excitation\nalong with highly scalable parameter estimation using a Generalized Method of\nMoments (GMM) estimator that we demonstrate to be consistent for growing\nnetwork size and time duration.','Lingfei Zhao, Hadeel Soliman, Kevin S. Xu, Subhadeep Paul','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.21845v1'),('2505.21847v1','RePaViT: Scalable Vision Transformer Acceleration via Structural Reparameterization on Feedforward Network Layers','We reveal that feedforward network (FFN) layers, rather than attention\nlayers, are the primary contributors to Vision Transformer (ViT) inference\nlatency, with their impact signifying as model size increases. This finding\nhighlights a critical opportunity for optimizing the efficiency of large-scale\nViTs by focusing on FFN layers. In this work, we propose a novel channel idle\nmechanism that facilitates post-training structural reparameterization for\nefficient FFN layers during testing. Specifically, a set of feature channels\nremains idle and bypasses the nonlinear activation function in each FFN layer,\nthereby forming a linear pathway that enables structural reparameterization\nduring inference. This mechanism results in a family of ReParameterizable\nVision Transformers (RePaViTs), which achieve remarkable latency reductions\nwith acceptable sacrifices (sometimes gains) in accuracy across various ViTs.\nThe benefits of our method scale consistently with model sizes, demonstrating\ngreater speed improvements and progressively narrowing accuracy gaps or even\nhigher accuracies on larger models. In particular, RePa-ViT-Large and\nRePa-ViT-Huge enjoy 66.8% and 68.7% speed-ups with +1.7% and +1.1% higher top-1\naccuracies under the same training strategy, respectively. RePaViT is the first\nto employ structural reparameterization on FFN layers to expedite ViTs to our\nbest knowledge, and we believe that it represents an auspicious direction for\nefficient ViTs. Source code is available at\nhttps://github.com/Ackesnal/RePaViT.','Xuwei Xu, Yang Li, Yudong Chen, Jiajun Liu, Sen Wang','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21847v1'),('2505.21849v1','Xinyu AI Search: Enhanced Relevance and Comprehensive Results with Rich Answer Presentations','Traditional search engines struggle to synthesize fragmented information for\ncomplex queries, while generative AI search engines face challenges in\nrelevance, comprehensiveness, and presentation. To address these limitations,\nwe introduce Xinyu AI Search, a novel system that incorporates a\nquery-decomposition graph to dynamically break down complex queries into\nsub-queries, enabling stepwise retrieval and generation. Our retrieval pipeline\nenhances diversity through multi-source aggregation and query expansion, while\nfiltering and re-ranking strategies optimize passage relevance. Additionally,\nXinyu AI Search introduces a novel approach for fine-grained, precise built-in\ncitation and innovates in result presentation by integrating timeline\nvisualization and textual-visual choreography. Evaluated on recent real-world\nqueries, Xinyu AI Search outperforms eight existing technologies in human\nassessments, excelling in relevance, comprehensiveness, and insightfulness.\nAblation studies validate the necessity of its key sub-modules. Our work\npresents the first comprehensive framework for generative AI search engines,\nbridging retrieval, generation, and user-centric presentation.','Bo Tang, Junyi Zhu, Chenyang Xi, Yunhang Ge, Jiahao Wu, Yuchen Feng, Yijun Niu, Wenqiang Wei, Yu Yu, Chunyu Li, Zehao Lin, Hao Wu, Ning Liao, Yebin Yang, Jiajia Wang, Zhiyu Li, Feiyu Xiong, Jingrun Chen','2025-05-28','cs.IR','http://arxiv.org/pdf/2505.21849v1'),('2505.21850v1','Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task','Current Multimodal Large Language Models (MLLMs) excel in general visual\nreasoning but remain underexplored in Abstract Visual Reasoning (AVR), which\ndemands higher-order reasoning to identify abstract rules beyond simple\nperception. Existing AVR benchmarks focus on single-step reasoning, emphasizing\nthe end result but neglecting the multi-stage nature of reasoning process. Past\nstudies found MLLMs struggle with these benchmarks, but it doesn\\\'t explain how\nthey fail. To address this gap, we introduce MultiStAR, a Multi-Stage AVR\nbenchmark, based on RAVEN, designed to assess reasoning across varying levels\nof complexity. Additionally, existing metrics like accuracy only focus on the\nfinal outcomes while do not account for the correctness of intermediate steps.\nTherefore, we propose a novel metric, MSEval, which considers the correctness\nof intermediate steps in addition to the final outcomes. We conduct\ncomprehensive experiments on MultiStAR using 17 representative close-source and\nopen-source MLLMs. The results reveal that while existing MLLMs perform\nadequately on basic perception tasks, they continue to face challenges in more\ncomplex rule detection stages.','Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21850v1'),('2505.21851v1','Streaming Flow Policy: Simplifying diffusion$/$flow-matching policies by treating action trajectories as flow trajectories','Recent advances in diffusion$/$flow-matching policies have enabled imitation\nlearning of complex, multi-modal action trajectories. However, they are\ncomputationally expensive because they sample a trajectory of trajectories: a\ndiffusion$/$flow trajectory of action trajectories. They discard intermediate\naction trajectories, and must wait for the sampling process to complete before\nany actions can be executed on the robot. We simplify diffusion$/$flow policies\nby treating action trajectories as flow trajectories. Instead of starting from\npure noise, our algorithm samples from a narrow Gaussian around the last\naction. Then, it incrementally integrates a velocity field learned via flow\nmatching to produce a sequence of actions that constitute a single trajectory.\nThis enables actions to be streamed to the robot on-the-fly during the flow\nsampling process, and is well-suited for receding horizon policy execution.\nDespite streaming, our method retains the ability to model multi-modal\nbehavior. We train flows that stabilize around demonstration trajectories to\nreduce distribution shift and improve imitation learning performance. Streaming\nflow policy outperforms prior methods while enabling faster policy execution\nand tighter sensorimotor loops for learning-based robot control. Project\nwebsite: https://streaming-flow-policy.github.io/','Sunshine Jiang, Xiaolin Fang, Nicholas Roy, Tomás Lozano-Pérez, Leslie Pack Kaelbling, Siddharth Ancha','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.21851v1'),('2505.21852v1','A Provable Approach for End-to-End Safe Reinforcement Learning','A longstanding goal in safe reinforcement learning (RL) is a method to ensure\nthe safety of a policy throughout the entire process, from learning to\noperation. However, existing safe RL paradigms inherently struggle to achieve\nthis objective. We propose a method, called Provably Lifetime Safe RL (PLS),\nthat integrates offline safe RL with safe policy deployment to address this\nchallenge. Our proposed method learns a policy offline using return-conditioned\nsupervised learning and then deploys the resulting policy while cautiously\noptimizing a limited set of parameters, known as target returns, using Gaussian\nprocesses (GPs). Theoretically, we justify the use of GPs by analyzing the\nmathematical relationship between target and actual returns. We then prove that\nPLS finds near-optimal target returns while guaranteeing safety with high\nprobability. Empirically, we demonstrate that PLS outperforms baselines both in\nsafety and reward performance, thereby achieving the longstanding goal to\nobtain high rewards while ensuring the safety of a policy throughout the\nlifetime from learning to operation.','Akifumi Wachi, Kohei Miyaguchi, Takumi Tanabe, Rei Sato, Youhei Akimoto','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21852v1'),('2505.21854v1','Rethinking Gradient-based Adversarial Attacks on Point Cloud Classification','Gradient-based adversarial attacks have become a dominant approach for\nevaluating the robustness of point cloud classification models. However,\nexisting methods often rely on uniform update rules that fail to consider the\nheterogeneous nature of point clouds, resulting in excessive and perceptible\nperturbations. In this paper, we rethink the design of gradient-based attacks\nby analyzing the limitations of conventional gradient update mechanisms and\npropose two new strategies to improve both attack effectiveness and\nimperceptibility. First, we introduce WAAttack, a novel framework that\nincorporates weighted gradients and an adaptive step-size strategy to account\nfor the non-uniform contribution of points during optimization. This approach\nenables more targeted and subtle perturbations by dynamically adjusting updates\naccording to the local structure and sensitivity of each point. Second, we\npropose SubAttack, a complementary strategy that decomposes the point cloud\ninto subsets and focuses perturbation efforts on structurally critical regions.\nTogether, these methods represent a principled rethinking of gradient-based\nadversarial attacks for 3D point cloud classification. Extensive experiments\ndemonstrate that our approach outperforms state-of-the-art baselines in\ngenerating highly imperceptible adversarial examples. Code will be released\nupon paper acceptance.','Jun Chen, Xinke Li, Mingyue Xu, Tianrui Li, Chongshou Li','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21854v1'),('2505.21855v1','Extracting Research Instruments from Educational Literature Using LLMs','Large Language Models (LLMs) are transforming information extraction from\nacademic literature, offering new possibilities for knowledge management. This\nstudy presents an LLM-based system designed to extract detailed information\nabout research instruments used in the education field, including their names,\ntypes, target respondents, measured constructs, and outcomes. Using multi-step\nprompting and a domain-specific data schema, it generates structured outputs\noptimized for educational research. Our evaluation shows that this system\nsignificantly outperforms other approaches, particularly in identifying\ninstrument names and detailed information. This demonstrates the potential of\nLLM-powered information extraction in educational contexts, offering a\nsystematic way to organize research instrument information. The ability to\naggregate such information at scale enhances accessibility for researchers and\neducation leaders, facilitating informed decision-making in educational\nresearch and policy.','Jiseung Yoo, Curran Mahowald, Meiyu Li, Wei Ai','2025-05-28','cs.IR','http://arxiv.org/pdf/2505.21855v1'),('2505.21857v1','Revisiting Bayesian Model Averaging in the Era of Foundation Models','We revisit the classical, full-fledged Bayesian model averaging (BMA)\nparadigm to ensemble pre-trained and/or lightly-finetuned foundation models to\nenhance the classification performance on image and text data. To make BMA\ntractable under foundation models, we introduce trainable linear classifiers\nthat take frozen features from the pre-trained foundation models as inputs. The\nmodel posteriors over the linear classifiers tell us which linear heads and\nfrozen features are better suited for a given dataset, resulting in a\nprincipled model ensembling method. Furthermore, we propose a computationally\ncheaper, optimizable model averaging scheme (OMA). In OMA, we directly optimize\nthe model ensemble weights, just like those weights based on model posterior\ndistributions in BMA, by reducing the amount of surprise (expected entropy of\nthe predictions) we get from predictions of ensembled models. With the rapid\ndevelopment of foundation models, these approaches will enable the\nincorporation of future, possibly significantly better foundation models to\nenhance the performance of challenging classification tasks.','Mijung Park','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21857v1'),('2505.21859v1','Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries','While large language models (LLMs) are increasingly capable of handling\nlonger contexts, recent work has demonstrated that they exhibit the \"lost in\nthe middle\" phenomenon (Liu et al., 2024) of unevenly attending to different\nparts of the provided context. This hinders their ability to cover diverse\nsource material in multi-document summarization, as noted in the DiverseSumm\nbenchmark (Huang et al., 2024). In this work, we contend that principled\ncontent selection is a simple way to increase source coverage on this task. As\nopposed to prompting an LLM to perform the summarization in a single step, we\nexplicitly divide the task into three steps -- (1) reducing document\ncollections to atomic key points, (2) using determinantal point processes (DPP)\nto perform select key points that prioritize diverse content, and (3) rewriting\nto the final summary. By combining prompting steps, for extraction and\nrewriting, with principled techniques, for content selection, we consistently\nimprove source coverage on the DiverseSumm benchmark across various LLMs.\nFinally, we also show that by incorporating relevance to a provided user intent\ninto the DPP kernel, we can generate personalized summaries that cover relevant\nsource information while retaining coverage.','Vishakh Padmakumar, Zichao Wang, David Arbour, Jennifer Healey','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21859v1'),('2505.21863v1','GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning','Publicly significant images from events hold valuable contextual information,\ncrucial for journalism and education. However, existing methods often struggle\nto extract this relevance accurately. To address this, we introduce GETReason\n(Geospatial Event Temporal Reasoning), a framework that moves beyond\nsurface-level image descriptions to infer deeper contextual meaning. We propose\nthat extracting global event, temporal, and geospatial information enhances\nunderstanding of an image\\\'s significance. Additionally, we introduce GREAT\n(Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric\nfor evaluating reasoning-based image understanding. Our layered multi-agent\napproach, assessed using a reasoning-weighted metric, demonstrates that\nmeaningful insights can be inferred, effectively linking images to their\nbroader event context.','Shikhhar Siingh, Abhinav Rawat, Vivek Gupta, Chitta Baral','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21863v1'),('2505.21866v1','CSI-Bench: A Large-Scale In-the-Wild Dataset for Multi-task WiFi Sensing','WiFi sensing has emerged as a compelling contactless modality for human\nactivity monitoring by capturing fine-grained variations in Channel State\nInformation (CSI). Its ability to operate continuously and non-intrusively\nwhile preserving user privacy makes it particularly suitable for health\nmonitoring. However, existing WiFi sensing systems struggle to generalize in\nreal-world settings, largely due to datasets collected in controlled\nenvironments with homogeneous hardware and fragmented, session-based recordings\nthat fail to reflect continuous daily activity.\n  We present CSI-Bench, a large-scale, in-the-wild benchmark dataset collected\nusing commercial WiFi edge devices across 26 diverse indoor environments with\n35 real users. Spanning over 461 hours of effective data, CSI-Bench captures\nrealistic signal variability under natural conditions. It includes\ntask-specific datasets for fall detection, breathing monitoring, localization,\nand motion source recognition, as well as a co-labeled multitask dataset with\njoint annotations for user identity, activity, and proximity. To support the\ndevelopment of robust and generalizable models, CSI-Bench provides standardized\nevaluation splits and baseline results for both single-task and multi-task\nlearning. CSI-Bench offers a foundation for scalable, privacy-preserving WiFi\nsensing systems in health and broader human-centric applications.','Guozhen Zhu, Yuqian Hu, Weihang Gao, Wei-Hsiang Wang, Beibei Wang, K. J. Ray Liu','2025-05-28','eess.SP','http://arxiv.org/pdf/2505.21866v1'),('2505.21870v1','Evaluating the Retrieval Robustness of Large Language Models','Retrieval-augmented generation (RAG) generally enhances large language\nmodels\\\' (LLMs) ability to solve knowledge-intensive tasks. But RAG may also\nlead to performance degradation due to imperfect retrieval and the model\\\'s\nlimited ability to leverage retrieved content. In this work, we evaluate the\nrobustness of LLMs in practical RAG setups (henceforth retrieval robustness).\nWe focus on three research questions: (1) whether RAG is always better than\nnon-RAG; (2) whether more retrieved documents always lead to better\nperformance; (3) and whether document orders impact results. To facilitate this\nstudy, we establish a benchmark of 1500 open-domain questions, each with\nretrieved documents from Wikipedia. We introduce three robustness metrics, each\ncorresponds to one research question. Our comprehensive experiments, involving\n11 LLMs and 3 prompting strategies, reveal that all of these LLMs exhibit\nsurprisingly high retrieval robustness; nonetheless, different degrees of\nimperfect robustness hinders them from fully utilizing the benefits of RAG.','Shuyang Cao, Karthik Radhakrishnan, David Rosenberg, Steven Lu, Pengxiang Cheng, Lu Wang, Shiyue Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21870v1'),('2505.21872v1','Targeted Unlearning Using Perturbed Sign Gradient Methods With Applications On Medical Images','Machine unlearning aims to remove the influence of specific training samples\nfrom a trained model without full retraining. While prior work has largely\nfocused on privacy-motivated settings, we recast unlearning as a\ngeneral-purpose tool for post-deployment model revision. Specifically, we focus\non utilizing unlearning in clinical contexts where data shifts, device\ndeprecation, and policy changes are common. To this end, we propose a bilevel\noptimization formulation of boundary-based unlearning that can be solved using\niterative algorithms. We provide convergence guarantees when first-order\nalgorithms are used to unlearn. Our method introduces tunable loss design for\ncontrolling the forgetting-retention tradeoff and supports novel model\ncomposition strategies that merge the strengths of distinct unlearning runs.\nAcross benchmark and real-world clinical imaging datasets, our approach\noutperforms baselines on both forgetting and retention metrics, including\nscenarios involving imaging devices and anatomical outliers. This work\nestablishes machine unlearning as a modular, practical alternative to\nretraining for real-world model maintenance in clinical applications.','George R. Nahass, Zhu Wang, Homa Rashidisabet, Won Hwa Kim, Sasha Hubschman, Jeffrey C. Peterson, Ghasem Yazdanpanah, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi, Sathya N. Ravi','2025-05-28','eess.IV','http://arxiv.org/pdf/2505.21872v1'),('2505.21873v1','HelixDesign-Binder: A Scalable Production-Grade Platform for Binder Design Built on HelixFold3','Protein binder design is central to therapeutics, diagnostics, and synthetic\nbiology, yet practical deployment remains challenging due to fragmented\nworkflows, high computational costs, and complex tool integration. We present\nHelixDesign-Binder, a production-grade, high-throughput platform built on\nHelixFold3 that automates the full binder design pipeline, from backbone\ngeneration and sequence design to structural evaluation and multi-dimensional\nscoring. By unifying these stages into a scalable and user-friendly system,\nHelixDesign-Binder enables efficient exploration of binder candidates with\nfavorable structural, energetic, and physicochemical properties. The platform\nleverages Baidu Cloud\\\'s high-performance infrastructure to support large-scale\ndesign and incorporates advanced scoring metrics, including ipTM, predicted\nbinding free energy, and interface hydrophobicity. Benchmarking across six\nprotein targets demonstrates that HelixDesign-Binder reliably produces diverse\nand high-quality binders, some of which match or exceed validated designs in\npredicted binding affinity. HelixDesign-Binder is accessible via an interactive\nweb interface in PaddleHelix platform, supporting both academic research and\nindustrial applications in antibody and protein binder development.','Jie Gao, Jun Li, Jing Hu, Shanzhuo Zhang, Kunrui Zhu, Yueyang Huang, Xiaonan Zhang, Xiaomin Fang','2025-05-28','q-bio.BM','http://arxiv.org/pdf/2505.21873v1'),('2505.21876v1','EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video Guidance','Recent approaches on 3D camera control in video diffusion models (VDMs) often\ncreate anchor videos to guide diffusion models as a structured prior by\nrendering from estimated point clouds following annotated camera trajectories.\nHowever, errors inherent in point cloud estimation often lead to inaccurate\nanchor videos. Moreover, the requirement for extensive camera trajectory\nannotations further increases resource demands. To address these limitations,\nwe introduce EPiC, an efficient and precise camera control learning framework\nthat automatically constructs high-quality anchor videos without expensive\ncamera trajectory annotations. Concretely, we create highly precise anchor\nvideos for training by masking source videos based on first-frame visibility.\nThis approach ensures high alignment, eliminates the need for camera trajectory\nannotations, and thus can be readily applied to any in-the-wild video to\ngenerate image-to-video (I2V) training pairs. Furthermore, we introduce\nAnchor-ControlNet, a lightweight conditioning module that integrates anchor\nvideo guidance in visible regions to pretrained VDMs, with less than 1% of\nbackbone model parameters. By combining the proposed anchor video data and\nControlNet module, EPiC achieves efficient training with substantially fewer\nparameters, training steps, and less data, without requiring modifications to\nthe diffusion model backbone typically needed to mitigate rendering\nmisalignments. Although being trained on masking-based anchor videos, our\nmethod generalizes robustly to anchor videos made with point clouds during\ninference, enabling precise 3D-informed camera control. EPiC achieves SOTA\nperformance on RealEstate10K and MiraData for I2V camera control task,\ndemonstrating precise and robust camera control ability both quantitatively and\nqualitatively. Notably, EPiC also exhibits strong zero-shot generalization to\nvideo-to-video scenarios.','Zun Wang, Jaemin Cho, Jialu Li, Han Lin, Jaehong Yoon, Yue Zhang, Mohit Bansal','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21876v1'),('2505.21877v1','Hybrid Batch Normalisation: Resolving the Dilemma of Batch Normalisation in Federated Learning','Batch Normalisation (BN) is widely used in conventional deep neural network\ntraining to harmonise the input-output distributions for each batch of data.\nHowever, federated learning, a distributed learning paradigm, faces the\nchallenge of dealing with non-independent and identically distributed data\namong the client nodes. Due to the lack of a coherent methodology for updating\nBN statistical parameters, standard BN degrades the federated learning\nperformance. To this end, it is urgent to explore an alternative normalisation\nsolution for federated learning. In this work, we resolve the dilemma of the BN\nlayer in federated learning by developing a customised normalisation approach,\nHybrid Batch Normalisation (HBN). HBN separates the update of statistical\nparameters (i.e. , means and variances used for evaluation) from that of\nlearnable parameters (i.e. , parameters that require gradient updates),\nobtaining unbiased estimates of global statistical parameters in distributed\nscenarios. In contrast with the existing solutions, we emphasise the supportive\npower of global statistics for federated learning. The HBN layer introduces a\nlearnable hybrid distribution factor, allowing each computing node to\nadaptively mix the statistical parameters of the current batch with the global\nstatistics. Our HBN can serve as a powerful plugin to advance federated\nlearning performance. It reflects promising merits across a wide range of\nfederated learning settings, especially for small batch sizes and heterogeneous\ndata.','Hongyao Chen, Tianyang Xu, Xiaojun Wu, Josef Kittler','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21877v1'),('2505.21879v1','Symbolic Foundation Regressor on Complex Networks','In science, we are interested not only in forecasting but also in\nunderstanding how predictions are made, specifically what the interpretable\nunderlying model looks like. Data-driven machine learning technology can\nsignificantly streamline the complex and time-consuming traditional manual\nprocess of discovering scientific laws, helping us gain insights into\nfundamental issues in modern science. In this work, we introduce a pre-trained\nsymbolic foundation regressor that can effectively compress complex data with\nnumerous interacting variables while producing interpretable physical\nrepresentations. Our model has been rigorously tested on non-network symbolic\nregression, symbolic regression on complex networks, and the inference of\nnetwork dynamics across various domains, including physics, biochemistry,\necology, and epidemiology. The results indicate a remarkable improvement in\nequation inference efficiency, being three times more effective than baseline\napproaches while maintaining accurate predictions. Furthermore, we apply our\nmodel to uncover more intuitive laws of interaction transmission from global\nepidemic outbreak data, achieving optimal data fitting. This model extends the\napplication boundary of pre-trained symbolic regression models to complex\nnetworks, and we believe it provides a foundational solution for revealing the\nhidden mechanisms behind changes in complex phenomena, enhancing\ninterpretability, and inspiring further scientific discoveries.','Weiting Liu, Jiaxu Cui, Jiao Hu, En Wang, Bo Yang','2025-05-28','cs.SC','http://arxiv.org/pdf/2505.21879v1'),('2505.21880v1','Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation','This study presents an innovative approach to urban mobility simulation by\nintegrating a Large Language Model (LLM) with Agent-Based Modeling (ABM).\nUnlike traditional rule-based ABM, the proposed framework leverages LLM to\nenhance agent diversity and realism by generating synthetic population\nprofiles, allocating routine and occasional locations, and simulating\npersonalized routes. Using real-world data, the simulation models individual\nbehaviors and large-scale mobility patterns in Taipei City. Key insights, such\nas route heat maps and mode-specific indicators, provide urban planners with\nactionable information for policy-making. Future work focuses on establishing\nrobust validation frameworks to ensure accuracy and reliability in urban\nplanning applications.','Yu-Lun Song, Chung-En Tsern, Che-Cheng Wu, Yu-Ming Chang, Syuan-Bo Huang, Wei-Chu Chen, Michael Chia-Liang Lin, Yu-Ta Lin','2025-05-28','cs.MA','http://arxiv.org/pdf/2505.21880v1'),('2505.21882v1','HydraNet: Momentum-Driven State Space Duality for Multi-Granularity Tennis Tournaments Analysis','In tennis tournaments, momentum, a critical yet elusive phenomenon, reflects\nthe dynamic shifts in performance of athletes that can decisively influence\nmatch outcomes. Despite its significance, momentum in terms of effective\nmodeling and multi-granularity analysis across points, games, sets, and matches\nin tennis tournaments remains underexplored. In this study, we define a novel\nMomentum Score (MS) metric to quantify a player\\\'s momentum level in\nmulti-granularity tennis tournaments, and design HydraNet, a momentum-driven\nstate-space duality-based framework, to model MS by integrating thirty-two\nheterogeneous dimensions of athletes performance in serve, return, psychology\nand fatigue. HydraNet integrates a Hydra module, which builds upon a\nstate-space duality (SSD) framework, capturing explicit momentum with a\nsliding-window mechanism and implicit momentum through cross-game state\npropagation. It also introduces a novel Versus Learning method to better\nenhance the adversarial nature of momentum between the two athletes at a macro\nlevel, along with a Collaborative-Adversarial Attention Mechanism (CAAM) for\ncapturing and integrating intra-player and inter-player dynamic momentum at a\nmicro level. Additionally, we construct a million-level tennis cross-tournament\ndataset spanning from 2012-2023 Wimbledon and 2013-2023 US Open, and validate\nthe multi-granularity modeling capability of HydraNet for the MS metric on this\ndataset. Extensive experimental evaluations demonstrate that the MS metric\nconstructed by the HydraNet framework provides actionable insights into how\nmomentum impacts outcomes at different granularities, establishing a new\nfoundation for momentum modeling and sports analysis. To the best of our\nknowledge. The source code and datasets are available at\nhttps://github.com/ReyJerry/HydraNet.','Ruijie Li, Xiang Zhao, Qiao Ning, Shikai Guo','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21882v1'),('2505.21887v1','SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem','Robust routing under uncertainty is central to real-world logistics, yet most\nbenchmarks assume static, idealized settings. We present SVRPBench, the first\nopen benchmark to capture high-fidelity stochastic dynamics in vehicle routing\nat urban scale. Spanning more than 500 instances with up to 1000 customers, it\nsimulates realistic delivery conditions: time-dependent congestion, log-normal\ndelays, probabilistic accidents, and empirically grounded time windows for\nresidential and commercial clients. Our pipeline generates diverse,\nconstraint-rich scenarios, including multi-depot and multi-vehicle setups.\nBenchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade\nby over 20% under distributional shift, while classical and metaheuristic\nmethods remain robust. To enable reproducible research, we release the dataset\nand evaluation suite. SVRPBench challenges the community to design solvers that\ngeneralize beyond synthetic assumptions and adapt to real-world uncertainty.','Ahmed Heakl, Yahia Salaheldin Shaaban, Martin Takac, Salem Lahlou, Zangir Iklassov','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.21887v1'),('2505.21889v1','EFIM: Efficient Serving of LLMs for Infilling Tasks with Improved KV Cache Reuse','Large language models (LLMs) are often used for infilling tasks, which\ninvolve predicting or generating missing information in a given text. These\ntasks typically require multiple interactions with similar context. To reduce\nthe computation of repeated historical tokens, cross-request key-value (KV)\ncache reuse, a technique that stores and reuses intermediate computations, has\nbecome a crucial method in multi-round interactive services. However, in\ninfilling tasks, the KV cache reuse is often hindered by the structure of the\nprompt format, which typically consists of a prefix and suffix relative to the\ninsertion point. Specifically, the KV cache of the prefix or suffix part is\nfrequently invalidated as the other part (suffix or prefix) is incrementally\ngenerated. To address the issue, we propose EFIM, a transformed prompt format\nof FIM to unleash the performance potential of KV cache reuse. Although the\ntransformed prompt can solve the inefficiency, it exposes subtoken generation\nproblems in current LLMs, where they have difficulty generating partial words\naccurately. Therefore, we introduce a fragment tokenization training method\nwhich splits text into multiple fragments before tokenization during data\nprocessing. Experiments on two representative LLMs show that LLM serving with\nEFIM can lower the latency by 52% and improve the throughput by 98% while\nmaintaining the original infilling capability.EFIM\\\'s source code is publicly\navailable at https://github.com/gty111/EFIM.','Tianyu Guo, Hande Dong, Yichong Leng, Feng Liu, Cheater Lin, Nong Xiao, Xianwei Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21889v1'),('2505.21892v1','Almost Linear Convergence under Minimal Score Assumptions: Quantized Transition Diffusion','Continuous diffusion models have demonstrated remarkable performance in data\ngeneration across various domains, yet their efficiency remains constrained by\ntwo critical limitations: (1) the local adjacency structure of the forward\nMarkov process, which restricts long-range transitions in the data space, and\n(2) inherent biases introduced during the simulation of time-inhomogeneous\nreverse denoising processes. To address these challenges, we propose Quantized\nTransition Diffusion (QTD), a novel approach that integrates data quantization\nwith discrete diffusion dynamics. Our method first transforms the continuous\ndata distribution $p_*$ into a discrete one $q_*$ via histogram approximation\nand binary encoding, enabling efficient representation in a structured discrete\nlatent space. We then design a continuous-time Markov chain (CTMC) with Hamming\ndistance-based transitions as the forward process, which inherently supports\nlong-range movements in the original data space. For reverse-time sampling, we\nintroduce a \\textit{truncated uniformization} technique to simulate the reverse\nCTMC, which can provably provide unbiased generation from $q_*$ under minimal\nscore assumptions. Through a novel KL dynamic analysis of the reverse CTMC, we\nprove that QTD can generate samples with $O(d\\ln^2(d/\\epsilon))$ score\nevaluations in expectation to approximate the $d$--dimensional target\ndistribution $p_*$ within an $\\epsilon$ error tolerance. Our method not only\nestablishes state-of-the-art inference efficiency but also advances the\ntheoretical foundations of diffusion-based generative modeling by unifying\ndiscrete and continuous diffusion paradigms.','Xunpeng Huang, Yingyu Lin, Nikki Lijing Kuang, Hanze Dong, Difan Zou, Yian Ma, Tong Zhang','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.21892v1'),('2505.21893v1','SDPO: Importance-Sampled Direct Preference Optimization for Stable Diffusion Training','Preference learning has become a central technique for aligning generative\nmodels with human expectations. Recently, it has been extended to diffusion\nmodels through methods like Direct Preference Optimization (DPO). However,\nexisting approaches such as Diffusion-DPO suffer from two key challenges:\ntimestep-dependent instability, caused by a mismatch between the reverse and\nforward diffusion processes and by high gradient variance in early noisy\ntimesteps, and off-policy bias arising from the mismatch between optimization\nand data collection policies. We begin by analyzing the reverse diffusion\ntrajectory and observe that instability primarily occurs at early timesteps\nwith low importance weights. To address these issues, we first propose\nDPO-C\\&M, a practical strategy that improves stability by clipping and masking\nuninformative timesteps while partially mitigating off-policy bias. Building on\nthis, we introduce SDPO (Importance-Sampled Direct Preference Optimization), a\nprincipled framework that incorporates importance sampling into the objective\nto fully correct for off-policy bias and emphasize informative updates during\nthe diffusion process. Experiments on CogVideoX-2B, CogVideoX-5B, and\nWan2.1-1.3B demonstrate that both methods outperform standard Diffusion-DPO,\nwith SDPO achieving superior VBench scores, human preference alignment, and\ntraining robustness. These results highlight the importance of timestep-aware,\ndistribution-corrected optimization in diffusion-based preference learning.','Xiaomeng Yang, Zhiyu Tan, Junyan Wang, Zhijian Zhou, Hao Li','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21893v1'),('2505.21895v1','Compressing Sine-Activated Low-Rank Adapters through Post-Training Quantization','Low-Rank Adaptation (LoRA) has become a standard approach for\nparameter-efficient fine-tuning, offering substantial reductions in trainable\nparameters by modeling updates as the product of two low-rank matrices. While\neffective, the low-rank constraint inherently limits representational capacity,\noften resulting in reduced performance compared to full-rank fine-tuning.\nRecent work by Ji et al. (2025) has addressed this limitation by applying a\nfixed-frequency sinusoidal transformation to low-rank adapters, increasing\ntheir stable rank without introducing additional parameters. This raises a\ncrucial question: can the same sine-activated technique be successfully applied\nwithin the context of Post-Training Quantization to retain benefits even after\nmodel compression? In this paper, we investigate this question by extending the\nsinusoidal transformation framework to quantized LoRA adapters. We develop a\ntheoretical analysis showing that the stable rank of a quantized adapter is\ntightly linked to that of its full-precision counterpart, motivating the use of\nsuch rank-enhancing functions even under quantization. Our results demonstrate\nthat the expressivity gains from a sinusoidal non-linearity persist after\nquantization, yielding highly compressed adapters with negligible loss in\nperformance. We validate our approach across a range of fine-tuning tasks for\nlanguage, vision and text-to-image generation achieving significant memory\nsavings while maintaining competitive accuracy.','Cameron Gordon, Yiping Ji, Hemanth Saratchandran, Paul Albert, Simon Lucey','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21895v1'),('2505.21898v1','Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development','Recent advancements in Large Language Models (LLMs) and autonomous agents\nhave demonstrated remarkable capabilities across various domains. However,\nstandalone agents frequently encounter limitations when handling complex tasks\nthat demand extensive interactions and substantial computational resources.\nAlthough Multi-Agent Systems (MAS) alleviate some of these limitations through\ncollaborative mechanisms like task decomposition, iterative communication, and\nrole specialization, they typically remain resource-unaware, incurring\nsignificant inefficiencies due to high token consumption and excessive\nexecution time. To address these limitations, we propose a resource-aware\nmulti-agent system -- Co-Saving (meaning that multiple agents collaboratively\nengage in resource-saving activities), which leverages experiential knowledge\nto enhance operational efficiency and solution quality. Our key innovation is\nthe introduction of \"shortcuts\" -- instructional transitions learned from\nhistorically successful trajectories -- which allows to bypass redundant\nreasoning agents and expedite the collective problem-solving process.\nExperiments for software development tasks demonstrate significant advantages\nover existing methods. Specifically, compared to the state-of-the-art MAS\nChatDev, our method achieves an average reduction of 50.85% in token usage, and\nimproves the overall code quality by 10.06%.','Rennai Qiu, Chen Qian, Ran Li, Yufan Dang, Weize Chen, Cheng Yang, Yingli Zhang, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21898v1'),('2505.21904v1','CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation','Instance segmentation demands costly per-pixel annotations and large models.\nWe introduce CAST, a semi-supervised knowledge distillation (SSKD) framework\nthat compresses pretrained vision foundation models (VFM) into compact experts\nusing limited labeled and abundant unlabeled data. CAST unfolds in three\nstages: (1) domain adaptation of the VFM teacher(s) via self-training with\ncontrastive pixel calibration, (2) distillation into a compact student via a\nunified multi-objective loss that couples standard supervision and\npseudo-labels with our instance-aware pixel-wise contrastive term, and (3)\nfine-tuning on labeled data to remove residual pseudo-label bias. Central to\nCAST is an \\emph{instance-aware pixel-wise contrastive loss} that fuses mask\nand class scores to mine informative negatives and enforce clear inter-instance\nmargins. By maintaining this contrastive signal across both adaptation and\ndistillation, we align teacher and student embeddings and fully leverage\nunlabeled images. On Cityscapes and ADE20K, our ~11X smaller student surpasses\nits adapted VFM teacher(s) by +3.4 AP (33.9 vs. 30.5) and +1.5 AP (16.7 vs.\n15.2) and outperforms state-of-the-art semi-supervised approaches.','Pardis Taghavi, Tian Liu, Renjie Li, Reza Langari, Zhengzhong Tu','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21904v1'),('2505.21906v1','Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge','Vision-language-action (VLA) models have emerged as the next generation of\nmodels in robotics. However, despite leveraging powerful pre-trained\nVision-Language Models (VLMs), existing end-to-end VLA systems often lose key\ncapabilities during fine-tuning as the model adapts to specific robotic tasks.\nWe argue that a generalizable VLA model should retain and expand upon the VLM\\\'s\ncore competencies: 1) Open-world embodied reasoning - the VLA should inherit\nthe knowledge from VLM, i.e., recognize anything that the VLM can recognize,\ncapable of solving math problems, possessing visual-spatial intelligence, 2)\nReasoning following - effectively translating the open-world reasoning into\nactionable steps for the robot. In this work, we introduce ChatVLA-2, a novel\nmixture-of-expert VLA model coupled with a specialized three-stage training\npipeline designed to preserve the VLM\\\'s original strengths while enabling\nactionable reasoning. To validate our approach, we design a math-matching task\nwherein a robot interprets math problems written on a whiteboard and picks\ncorresponding number cards from a table to solve equations. Remarkably, our\nmethod exhibits exceptional mathematical reasoning and OCR capabilities,\ndespite these abilities not being explicitly trained within the VLA.\nFurthermore, we demonstrate that the VLA possesses strong spatial reasoning\nskills, enabling it to interpret novel directional instructions involving\npreviously unseen objects. Overall, our method showcases reasoning and\ncomprehension abilities that significantly surpass state-of-the-art imitation\nlearning methods such as OpenVLA, DexVLA, and pi-zero. This work represents a\nsubstantial advancement toward developing truly generalizable robotic\nfoundation models endowed with robust reasoning capacities.','Zhongyi Zhou, Yichen Zhu, Junjie Wen, Chaomin Shen, Yi Xu','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.21906v1'),('2505.21907v1','Modeling and Optimizing User Preferences in AI Copilots: A Comprehensive Survey and Taxonomy','AI copilots, context-aware, AI-powered systems designed to assist users in\ntasks such as software development and content creation, are becoming integral\nto modern workflows. As these systems grow in capability and adoption,\npersonalization has emerged as a cornerstone for ensuring usability, trust, and\nproductivity. Central to this personalization is preference optimization: the\nability of AI copilots to detect, interpret, and align with individual user\npreferences. While personalization techniques are well-established in domains\nlike recommender systems and dialogue agents, their adaptation to interactive,\nreal-time systems like AI copilots remains fragmented and underexplored. This\nsurvey addresses this gap by synthesizing research on how user preferences are\ncaptured, modeled, and refined within the design of AI copilots. We introduce a\nunified definition of AI copilots and propose a phase-based taxonomy of\npreference optimization strategies, structured around pre-interaction,\nmid-interaction, and post-interaction stages. We analyze techniques for\nacquiring preference signals, modeling user intent, and integrating feedback\nloops, highlighting both established approaches and recent innovations. By\nbridging insights from AI personalization, human-AI collaboration, and large\nlanguage model adaptation, this survey provides a structured foundation for\ndesigning adaptive, preference-aware AI copilots. It offers a holistic view of\nthe available preference resources, how they can be leveraged, and which\ntechnical approaches are most suited to each stage of system design.','Saleh Afzoon, Zahra Jahanandish, Phuong Thao Huynh, Amin Beheshti, Usman Naseem','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.21907v1'),('2505.21908v1','Reinforcement Learning for Out-of-Distribution Reasoning in LLMs: An Empirical Study on Diagnosis-Related Group Coding','Diagnosis-Related Group (DRG) codes are essential for hospital reimbursement\nand operations but require labor-intensive assignment. Large Language Models\n(LLMs) struggle with DRG coding due to the out-of-distribution (OOD) nature of\nthe task: pretraining corpora rarely contain private clinical or billing data.\nWe introduce DRG-Sapphire, which uses large-scale reinforcement learning (RL)\nfor automated DRG coding from clinical notes. Built on Qwen2.5-7B and trained\nwith Group Relative Policy Optimization (GRPO) using rule-based rewards,\nDRG-Sapphire introduces a series of RL enhancements to address domain-specific\nchallenges not seen in previous mathematical tasks. Our model achieves\nstate-of-the-art accuracy on the MIMIC-IV benchmark and generates\nphysician-validated reasoning for DRG assignments, significantly enhancing\nexplainability. Our study further sheds light on broader challenges of applying\nRL to knowledge-intensive, OOD tasks. We observe that RL performance scales\napproximately linearly with the logarithm of the number of supervised\nfine-tuning (SFT) examples, suggesting that RL effectiveness is fundamentally\nconstrained by the domain knowledge encoded in the base model. For OOD tasks\nlike DRG coding, strong RL performance requires sufficient knowledge infusion\nprior to RL. Consequently, scaling SFT may be more effective and\ncomputationally efficient than scaling RL alone for such tasks.','Hanyin Wang, Zhenbang Wu, Gururaj Kolar, Hariprasad Korsapati, Brian Bartlett, Bryan Hull, Jimeng Sun','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21908v1'),('2505.21910v1','Taming Transformer Without Using Learning Rate Warmup','Scaling Transformer to a large scale without using some technical tricks such\nas learning rate warump and using an obviously lower learning rate is an\nextremely challenging task, and is increasingly gaining more attention. In this\npaper, we provide a theoretical analysis for the process of training\nTransformer and reveal the rationale behind the model crash phenomenon in the\ntraining process, termed \\textit{spectral energy concentration} of\n${\\bW_q}^{\\top} \\bW_k$, which is the reason for a malignant entropy collapse,\nwhere ${\\bW_q}$ and $\\bW_k$ are the projection matrices for the query and the\nkey in Transformer, respectively. To remedy this problem, motivated by\n\\textit{Weyl\\\'s Inequality}, we present a novel optimization strategy, \\ie,\nmaking the weight updating in successive steps smooth -- if the ratio\n$\\frac{\\sigma_{1}(\\nabla \\bW_t)}{\\sigma_{1}(\\bW_{t-1})}$ is larger than a\nthreshold, we will automatically bound the learning rate to a weighted multiple\nof $\\frac{\\sigma_{1}(\\bW_{t-1})}{\\sigma_{1}(\\nabla \\bW_t)}$, where $\\nabla\n\\bW_t$ is the updating quantity in step $t$. Such an optimization strategy can\nprevent spectral energy concentration to only a few directions, and thus can\navoid malignant entropy collapse which will trigger the model crash. We conduct\nextensive experiments using ViT, Swin-Transformer and GPT, showing that our\noptimization strategy can effectively and stably train these Transformers\nwithout using learning rate warmup.','Xianbiao Qi, Yelin He, Jiaquan Ye, Chun-Guang Li, Bojia Zi, Xili Dai, Qin Zou, Rong Xiao','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21910v1'),('2505.21918v1','Self-supervised Learning Method Using Transformer for Multi-dimensional Sensor Data Processing','We developed a deep learning algorithm for human activity recognition using\nsensor signals as input. In this study, we built a pretrained language model\nbased on the Transformer architecture, which is widely used in natural language\nprocessing. By leveraging this pretrained model, we aimed to improve\nperformance on the downstream task of human activity recognition. While this\ntask can be addressed using a vanilla Transformer, we propose an enhanced\nn-dimensional numerical processing Transformer that incorporates three key\nfeatures: embedding n-dimensional numerical data through a linear layer,\nbinning-based pre-processing, and a linear transformation in the output layer.\nWe evaluated the effectiveness of our proposed model across five different\ndatasets. Compared to the vanilla Transformer, our model demonstrated 10%-15%\nimprovements in accuracy.','Haruki Kai, Tsuyoshi Okita','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21918v1'),('2505.21919v1','Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference','The increasing adoption of large language models (LLMs) with extended context\nwindows necessitates efficient Key-Value Cache (KVC) management to optimize\ninference performance. Inference workloads like Retrieval-Augmented Generation\n(RAG) and agents exhibit high cache reusability, making efficient caching\ncritical to reducing redundancy and improving speed. We analyze real-world KVC\naccess patterns using publicly available traces and evaluate commercial\nkey-value stores like Redis and state-of-the-art RDMA-based systems (CHIME [1]\nand Sherman [2]) for KVC metadata management. Our work demonstrates the lack of\ntailored storage solution for KVC prefilling, underscores the need for an\nefficient distributed caching system with optimized metadata management for LLM\nworkloads, and provides insights into designing improved KVC management systems\nfor scalable, low-latency inference.','Yue Zhu, Hao Yu, Chen Wang, Zhuoran Liu, Eun Kyung Lee','2025-05-28','cs.ET','http://arxiv.org/pdf/2505.21919v1'),('2505.21923v1','FALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design','Designing analog circuits from performance specifications is a complex,\nmulti-stage process encompassing topology selection, parameter inference, and\nlayout feasibility. We introduce FALCON, a unified machine learning framework\nthat enables fully automated, specification-driven analog circuit synthesis\nthrough topology selection and layout-constrained optimization. Given a target\nperformance, FALCON first selects an appropriate circuit topology using a\nperformance-driven classifier guided by human design heuristics. Next, it\nemploys a custom, edge-centric graph neural network trained to map circuit\ntopology and parameters to performance, enabling gradient-based parameter\ninference through the learned forward model. This inference is guided by a\ndifferentiable layout cost, derived from analytical equations capturing\nparasitic and frequency-dependent effects, and constrained by design rules. We\ntrain and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wave\ncircuits, generated and simulated using Cadence Spectre across 20\nexpert-designed topologies. Through this evaluation, FALCON demonstrates >99\\%\naccuracy in topology inference, <10\\% relative error in performance prediction,\nand efficient layout-aware design that completes in under 1 second per\ninstance. Together, these results position FALCON as a practical and extensible\nfoundation model for end-to-end analog circuit design automation.','Asal Mehradfar, Xuzhe Zhao, Yilun Huang, Emir Ceyani, Yankai Yang, Shihao Han, Hamidreza Aghasi, Salman Avestimehr','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21923v1'),('2505.21925v1','RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination','We present RenderFormer, a neural rendering pipeline that directly renders an\nimage from a triangle-based representation of a scene with full global\nillumination effects and that does not require per-scene training or\nfine-tuning. Instead of taking a physics-centric approach to rendering, we\nformulate rendering as a sequence-to-sequence transformation where a sequence\nof tokens representing triangles with reflectance properties is converted to a\nsequence of output tokens representing small patches of pixels. RenderFormer\nfollows a two stage pipeline: a view-independent stage that models\ntriangle-to-triangle light transport, and a view-dependent stage that\ntransforms a token representing a bundle of rays to the corresponding pixel\nvalues guided by the triangle-sequence from the view-independent stage. Both\nstages are based on the transformer architecture and are learned with minimal\nprior constraints. We demonstrate and evaluate RenderFormer on scenes with\nvarying complexity in shape and light transport.','Chong Zeng, Yue Dong, Pieter Peers, Hongzhi Wu, Xin Tong','2025-05-28','cs.GR','http://arxiv.org/pdf/2505.21925v1'),('2505.21926v1','Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning','In natural language processing (NLP) and computer vision (CV), the successful\napplication of foundation models across diverse tasks has demonstrated their\nremarkable potential. However, despite the rich structural and textual\ninformation embedded in knowledge graphs (KGs), existing research of foundation\nmodel for KG has primarily focused on their structural aspects, with most\nefforts restricted to in-KG tasks (e.g., knowledge graph completion, KGC). This\nlimitation has hindered progress in addressing more challenging out-of-KG\ntasks. In this paper, we introduce MERRY, a foundation model for general\nknowledge graph reasoning, and investigate its performance across two task\ncategories: in-KG reasoning tasks (e.g., KGC) and out-of-KG tasks (e.g., KG\nquestion answering, KGQA). We not only utilize the structural information, but\nalso the textual information in KGs. Specifically, we propose a\nmulti-perspective Conditional Message Passing (CMP) encoding architecture to\nbridge the gap between textual and structural modalities, enabling their\nseamless integration. Additionally, we introduce a dynamic residual fusion\nmodule to selectively retain relevant textual information and a flexible edge\nscoring mechanism to adapt to diverse downstream tasks. Comprehensive\nevaluations on 28 datasets demonstrate that MERRY outperforms existing\nbaselines in most scenarios, showcasing strong reasoning capabilities within\nKGs and excellent generalization to out-of-KG tasks such as KGQA.','Yin Hua, Zhiqiang Liu, Mingyang Chen, Zheng Fang, Chi Man Wong, Lingxiao Li, Chi Man Vong, Huajun Chen, Wen Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21926v1'),('2505.21928v1','Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology','Gastrointestinal (GI) diseases represent a clinically significant burden,\nnecessitating precise diagnostic approaches to optimize patient outcomes.\nConventional histopathological diagnosis, heavily reliant on the subjective\ninterpretation of pathologists, suffers from limited reproducibility and\ndiagnostic variability. To overcome these limitations and address the lack of\npathology-specific foundation models for GI diseases, we develop Digepath, a\nspecialized foundation model for GI pathology. Our framework introduces a\ndual-phase iterative optimization strategy combining pretraining with\nfine-screening, specifically designed to address the detection of sparsely\ndistributed lesion areas in whole-slide images. Digepath is pretrained on more\nthan 353 million image patches from over 200,000 hematoxylin and eosin-stained\nslides of GI diseases. It attains state-of-the-art performance on 33 out of 34\ntasks related to GI pathology, including pathological diagnosis, molecular\nprediction, gene mutation prediction, and prognosis evaluation, particularly in\ndiagnostically ambiguous cases and resolution-agnostic tissue classification.We\nfurther translate the intelligent screening module for early GI cancer and\nachieve near-perfect 99.6% sensitivity across 9 independent medical\ninstitutions nationwide. The outstanding performance of Digepath highlights its\npotential to bridge critical gaps in histopathological practice. This work not\nonly advances AI-driven precision pathology for GI diseases but also\nestablishes a transferable paradigm for other pathology subspecialties.','Lianghui Zhu, Xitong Ling, Minxi Ouyang, Xiaoping Liu, Mingxi Fu, Tian Guan, Fanglei Fu, Xuanyu Wang, Maomao Zeng, Mingxi Zhu, Yibo Jin, Liming Liu, Song Duan, Qiming He, Yizhi Wang, Luxi Xie, Houqiang Li, Yonghong He, Sufang Tian','2025-05-28','eess.IV','http://arxiv.org/pdf/2505.21928v1'),('2505.21930v1','Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets','This paper develops an ensemble method for fine-tuning a language model to\nmultiple datasets. Existing methods, such as quantized LoRA (QLoRA), are\nefficient when adapting to a single dataset. When training on multiple datasets\nof different tasks, a common setup in practice, it remains unclear how to\ndesign an efficient adaptation for fine-tuning language models. We propose to\nuse an ensemble of multiple smaller adapters instead of a single adapter per\ntask. We design an efficient algorithm that partitions $n$ datasets into $m$\ngroups, where $m$ is typically much smaller than $n$ in practice, and train one\nadapter for each group before taking a weighted combination to form the\nensemble. The algorithm leverages a first-order approximation property of\nlow-rank adaptation to quickly obtain the fine-tuning performances of dataset\ncombinations since methods like LoRA stay close to the base model. Hence, we\nuse the gradients of the base model to estimate its behavior during\nfine-tuning. Empirically, this approximation holds with less than $1\\%$ error\non models with up to $34$ billion parameters, leading to an estimation of true\nfine-tuning performances under $5\\%$ error while speeding up computation\ncompared to base fine-tuning by $105$ times. When applied to fine-tune Llama\nand GPT models on ten text classification tasks, our approach provides up to\n$10\\%$ higher average test accuracy over QLoRA, with only $9\\%$ more FLOPs. On\na Llama model with $34$ billion parameters, an ensemble of QLoRA increases test\naccuracy by $3\\%$ compared to QLoRA, with only $8\\%$ more FLOPs.','Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang R. Zhang','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21930v1'),('2505.21932v1','Higher-Order Group Synchronization','Group synchronization is the problem of determining reliable global estimates\nfrom noisy local measurements on networks. The typical task for group\nsynchronization is to assign elements of a group to the nodes of a graph in a\nway that respects group elements given on the edges which encode information\nabout local pairwise relationships between the nodes. In this paper, we\nintroduce a novel higher-order group synchronization problem which operates on\na hypergraph and seeks to synchronize higher-order local measurements on the\nhyperedges to obtain global estimates on the nodes. Higher-order group\nsynchronization is motivated by applications to computer vision and image\nprocessing, among other computational problems. First, we define the problem of\nhigher-order group synchronization and discuss its mathematical foundations.\nSpecifically, we give necessary and sufficient synchronizability conditions\nwhich establish the importance of cycle consistency in higher-order group\nsynchronization. Then, we propose the first computational framework for general\nhigher-order group synchronization; it acts globally and directly on\nhigher-order measurements using a message passing algorithm. We discuss\ntheoretical guarantees for our framework, including convergence analyses under\noutliers and noise. Finally, we show potential advantages of our method through\nnumerical experiments. In particular, we show that in certain cases our\nhigher-order method applied to rotational and angular synchronization\noutperforms standard pairwise synchronization methods and is more robust to\noutliers. We also show that our method has comparable performance on simulated\ncryo-electron microscopy (cryo-EM) data compared to a standard cryo-EM\nreconstruction package.','Adriana L. Duncan, Joe Kileel','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.21932v1'),('2505.21935v1','From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models','Since the advent of Large Language Models (LLMs), efforts have largely\nfocused on improving their instruction-following and deductive reasoning\nabilities, leaving open the question of whether these models can truly discover\nnew knowledge. In pursuit of artificial general intelligence (AGI), there is a\ngrowing need for models that not only execute commands or retrieve information\nbut also learn, reason, and generate new knowledge by formulating novel\nhypotheses and theories that deepen our understanding of the world. Guided by\nPeirce\\\'s framework of abduction, deduction, and induction, this survey offers a\nstructured lens to examine LLM-based hypothesis discovery. We synthesize\nexisting work in hypothesis generation, application, and validation,\nidentifying both key achievements and critical gaps. By unifying these threads,\nwe illuminate how LLMs might evolve from mere ``information executors\\\'\\\' into\nengines of genuine innovation, potentially transforming research, science, and\nreal-world problem solving.','Kaiyu He, Zhiyu Chen','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.21935v1'),('2505.21936v1','RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments','Computer-use agents (CUAs) promise to automate complex tasks across operating\nsystems (OS) and the web, but remain vulnerable to indirect prompt injection.\nCurrent evaluations of this threat either lack support realistic but controlled\nenvironments or ignore hybrid web-OS attack scenarios involving both\ninterfaces. To address this, we propose RedTeamCUA, an adversarial testing\nframework featuring a novel hybrid sandbox that integrates a VM-based OS\nenvironment with Docker-based web platforms. Our sandbox supports key features\ntailored for red teaming, such as flexible adversarial scenario configuration,\nand a setting that decouples adversarial evaluation from navigational\nlimitations of CUAs by initializing tests directly at the point of an\nadversarial injection. Using RedTeamCUA, we develop RTC-Bench, a comprehensive\nbenchmark with 864 examples that investigate realistic, hybrid web-OS attack\nscenarios and fundamental security vulnerabilities. Benchmarking current\nfrontier CUAs identifies significant vulnerabilities: Claude 3.7 Sonnet | CUA\ndemonstrates an ASR of 42.9%, while Operator, the most secure CUA evaluated,\nstill exhibits an ASR of 7.6%. Notably, CUAs often attempt to execute\nadversarial tasks with an Attempt Rate as high as 92.5%, although failing to\ncomplete them due to capability limitations. Nevertheless, we observe\nconcerning ASRs of up to 50% in realistic end-to-end settings, with the\nrecently released frontier Claude 4 Opus | CUA showing an alarming ASR of 48%,\ndemonstrating that indirect prompt injection presents tangible risks for even\nadvanced CUAs despite their capabilities and safeguards. Overall, RedTeamCUA\nprovides an essential framework for advancing realistic, controlled, and\nsystematic analysis of CUA vulnerabilities, highlighting the urgent need for\nrobust defenses to indirect prompt injection prior to real-world deployment.','Zeyi Liao, Jaylen Jones, Linxi Jiang, Eric Fosler-Lussier, Yu Su, Zhiqiang Lin, Huan Sun','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21936v1'),('2505.21937v1','Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic Languages','Translating multi-word expressions (MWEs) and idioms requires a deep\nunderstanding of the cultural nuances of both the source and target languages.\nThis challenge is further amplified by the one-to-many nature of idiomatic\ntranslations, where a single source idiom can have multiple target-language\nequivalents depending on cultural references and contextual variations.\nTraditional static knowledge graphs (KGs) and prompt-based approaches struggle\nto capture these complex relationships, often leading to suboptimal\ntranslations. To address this, we propose IdiomCE, an adaptive graph neural\nnetwork (GNN) based methodology that learns intricate mappings between\nidiomatic expressions, effectively generalizing to both seen and unseen nodes\nduring training. Our proposed method enhances translation quality even in\nresource-constrained settings, facilitating improved idiomatic translation in\nsmaller models. We evaluate our approach on multiple idiomatic translation\ndatasets using reference-less metrics, demonstrating significant improvements\nin translating idioms from English to various Indian languages.','Pratik Rakesh Singh, Kritarth Prasad, Mohammadi Zaki, Pankaj Wasnik','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21937v1'),('2505.21938v1','Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection','Adversarial attacks on stochastic bandits have traditionally relied on some\nunrealistic assumptions, such as per-round reward manipulation and unbounded\nperturbations, limiting their relevance to real-world systems. We propose a\nmore practical threat model, Fake Data Injection, which reflects realistic\nadversarial constraints: the attacker can inject only a limited number of\nbounded fake feedback samples into the learner\\\'s history, simulating legitimate\ninteractions. We design efficient attack strategies under this model,\nexplicitly addressing both magnitude constraints (on reward values) and\ntemporal constraints (on when and how often data can be injected). Our\ntheoretical analysis shows that these attacks can mislead both Upper Confidence\nBound (UCB) and Thompson Sampling algorithms into selecting a target arm in\nnearly all rounds while incurring only sublinear attack cost. Experiments on\nsynthetic and real-world datasets validate the effectiveness of our strategies,\nrevealing significant vulnerabilities in widely used stochastic bandit\nalgorithms under practical adversarial scenarios.','Qirun Zeng, Eric He, Richard Hoffmann, Xuchuang Wang, Jinhang Zuo','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21938v1'),('2505.21940v1','RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering','Large Language Models (LLMs) excel in many areas but continue to face\nchallenges with complex reasoning tasks, such as Multi-Hop Question Answering\n(MHQA). MHQA requires integrating evidence from diverse sources while managing\nintricate logical dependencies, often leads to errors in reasoning.\nRetrieval-Augmented Generation (RAG), widely employed in MHQA tasks, faces\nchallenges in effectively filtering noisy data and retrieving all necessary\nevidence, thereby limiting its effectiveness in addressing MHQA challenges. To\naddress these challenges, we propose RISE:Reasoning Enhancement via Iterative\nSelf-Exploration, a novel framework designed to enhance models\\\' reasoning\ncapability through iterative self-exploration. Specifically, RISE involves\nthree key steps in addressing MHQA tasks: question decomposition,\nretrieve-then-read, and self-critique. By leveraging continuous\nself-exploration, RISE identifies accurate reasoning paths, iteratively\nself-improving the model\\\'s capability to integrate evidence, maintain logical\nconsistency, and enhance performance in MHQA tasks. Extensive experiments on\nmultiple MHQA benchmarks demonstrate that RISE significantly improves reasoning\naccuracy and task performance.','Bolei He, Xinran He, Mengke Chen, Xianwei Xue, Ying Zhu, Zhenhua Ling','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21940v1'),('2505.21941v1','Test-Time Scaling with Repeated Sampling Improves Multilingual Text Generation','Inference-time scaling via repeated sampling has shown promise in reasoning\ntasks, but its effectiveness in multilingual generation remains underexplored.\nWe evaluate this approach using perplexity- and reward-based verifiers on two\nmultilingual benchmarks: the Aya Evaluation Suite and m-ArenaHard. Our results\nshow consistent quality improvements, with gains exceeding 35% in some cases.\nWhile perplexity-based scoring is effective for open-ended prompts, only\nreward-based verifiers improve performance on tasks requiring reasoning (e.g.,\nmath, code). Our results demonstrate the broader utility of repeated sampling\nfor multilingual text generation and underscore the importance of selecting\nright verifiers for the task.','Ashim Gupta, Vivek Srikumar','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21941v1'),('2505.21942v1','Continual Learning Beyond Experience Rehearsal and Full Model Surrogates','Continual learning (CL) has remained a significant challenge for deep neural\nnetworks as learning new tasks erases previously acquired knowledge, either\npartially or completely. Existing solutions often rely on experience rehearsal\nor full model surrogates to mitigate CF. While effective, these approaches\nintroduce substantial memory and computational overhead, limiting their\nscalability and applicability in real-world scenarios. To address this, we\npropose SPARC, a scalable CL approach that eliminates the need for experience\nrehearsal and full-model surrogates. By effectively combining task-specific\nworking memories and task-agnostic semantic memory for cross-task knowledge\nconsolidation, SPARC results in a remarkable parameter efficiency, using only\n6% of the parameters required by full-model surrogates. Despite its lightweight\ndesign, SPARC achieves superior performance on Seq-TinyImageNet and matches\nrehearsal-based methods on various CL benchmarks. Additionally, weight\nre-normalization in the classification layer mitigates task-specific biases,\nestablishing SPARC as a practical and scalable solution for CL under stringent\nefficiency constraints.','Prashant Bhat, Laurens Niesten, Elahe Arani, Bahram Zonooz','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21942v1'),('2505.21944v1','Stochastic Primal-Dual Double Block-Coordinate for Two-way Partial AUC Maximization','Two-way partial AUC (TPAUC) is a critical performance metric for binary\nclassification with imbalanced data, as it focuses on specific ranges of the\ntrue positive rate (TPR) and false positive rate (FPR). However, stochastic\nalgorithms for TPAUC optimization remain under-explored, with existing methods\neither limited to approximated TPAUC loss functions or burdened by sub-optimal\ncomplexities. To overcome these limitations, we introduce two innovative\nstochastic primal-dual double block-coordinate algorithms for TPAUC\nmaximization. These algorithms utilize stochastic block-coordinate updates for\nboth the primal and dual variables, catering to both convex and non-convex\nsettings. We provide theoretical convergence rate analyses, demonstrating\nsignificant improvements over prior approaches. Our experimental results, based\non multiple benchmark datasets, validate the superior performance of our\nalgorithms, showcasing faster convergence and better generalization. This work\nadvances the state of the art in TPAUC optimization and offers practical tools\nfor real-world machine learning applications.','Linli Zhou, Bokun Wang, My T. Thai, Tianbao Yang','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21944v1'),('2505.21954v1','UniTalk: Towards Universal Active Speaker Detection in Real World Scenarios','We present UniTalk, a novel dataset specifically designed for the task of\nactive speaker detection, emphasizing challenging scenarios to enhance model\ngeneralization. Unlike previously established benchmarks such as AVA, which\npredominantly features old movies and thus exhibits significant domain gaps,\nUniTalk focuses explicitly on diverse and difficult real-world conditions.\nThese include underrepresented languages, noisy backgrounds, and crowded scenes\n- such as multiple visible speakers speaking concurrently or in overlapping\nturns. It contains over 44.5 hours of video with frame-level active speaker\nannotations across 48,693 speaking identities, and spans a broad range of video\ntypes that reflect real-world conditions. Through rigorous evaluation, we show\nthat state-of-the-art models, while achieving nearly perfect scores on AVA,\nfail to reach saturation on UniTalk, suggesting that the ASD task remains far\nfrom solved under realistic conditions. Nevertheless, models trained on UniTalk\ndemonstrate stronger generalization to modern \"in-the-wild\" datasets like\nTalkies and ASW, as well as to AVA. UniTalk thus establishes a new benchmark\nfor active speaker detection, providing researchers with a valuable resource\nfor developing and evaluating versatile and resilient models.\n  Dataset: https://huggingface.co/datasets/plnguyen2908/UniTalk-ASD\n  Code: https://github.com/plnguyen2908/UniTalk-ASD-code','Le Thien Phuc Nguyen, Zhuoran Yu, Khoa Quang Nhat Cao, Yuwei Guo, Tu Ho Manh Pham, Tuan Tai Nguyen, Toan Ngo Duc Vo, Lucas Poon, Soochahn Lee, Yong Jae Lee','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21954v1'),('2505.21955v1','Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs','Large vision-language models (LVLMs) are increasingly deployed in interactive\napplications such as virtual and augmented reality, where first-person\n(egocentric) view captured by head-mounted cameras serves as key input. While\nthis view offers fine-grained cues about user attention and hand-object\ninteractions, their narrow field of view and lack of global context often lead\nto failures on spatially or contextually demanding queries. To address this, we\nintroduce a framework that augments egocentric inputs with third-person\n(exocentric) views, providing complementary information such as global scene\nlayout and object visibility to LVLMs. We present E3VQA, the first benchmark\nfor multi-view question answering with 4K high-quality question-answer pairs\ngrounded in synchronized ego-exo image pairs. Additionally, we propose M3CoT, a\ntraining-free prompting technique that constructs a unified scene\nrepresentation by integrating scene graphs from three complementary\nperspectives. M3CoT enables LVLMs to reason more effectively across views,\nyielding consistent performance gains (4.84% for GPT-4o and 5.94% for Gemini\n2.0 Flash) over a recent CoT baseline. Our extensive evaluation reveals key\nstrengths and limitations of LVLMs in multi-view reasoning and highlights the\nvalue of leveraging both egocentric and exocentric inputs.','Insu Lee, Wooje Park, Jaeyun Jang, Minyoung Noh, Kyuhong Shim, Byonghyo Shim','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21955v1'),('2505.21956v1','Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation','Text-to-image generation increasingly demands access to domain-specific,\nfine-grained, and rapidly evolving knowledge that pretrained models cannot\nfully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to\naddress this by retrieving globally relevant images, but they fail when no\nsingle image contains all desired elements from a complex user query. We\npropose Cross-modal RAG, a novel framework that decomposes both queries and\nimages into sub-dimensional components, enabling subquery-aware retrieval and\ngeneration. Our method introduces a hybrid retrieval strategy - combining a\nsub-dimensional sparse retriever with a dense retriever - to identify a\nPareto-optimal set of images, each contributing complementary aspects of the\nquery. During generation, a multimodal large language model is guided to\nselectively condition on relevant visual features aligned to specific\nsubqueries, ensuring subquery-aware image synthesis. Extensive experiments on\nMS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal\nRAG significantly outperforms existing baselines in both retrieval and\ngeneration quality, while maintaining high efficiency.','Mengdan Zhu, Senhao Cheng, Guangji Bai, Yifei Zhang, Liang Zhao','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21956v1'),('2505.21958v1','Resolving Knowledge Conflicts in Domain-specific Data Selection: A Case Study on Medical Instruction-tuning','Domain-specific instruction-tuning has become the defacto standard for\nimproving the performance of large language models (LLMs) in specialized\napplications, e.g., medical question answering. Since the instruction-tuning\ndataset might contain redundant or low-quality data, data selection (DS) is\nusually required to maximize the data efficiency. Despite the successes in the\ngeneral domain, current DS methods often struggle to select the desired data\nfor domain-specific instruction-tuning. One of the main reasons is that they\nneglect the impact of knowledge conflicts, i.e., the discrepancy between LLMs\\\'\npretrained knowledge and context knowledge of instruction data, which could\ndamage LLMs\\\' prior abilities and lead to hallucination. To this end, we propose\na simple-yet-effective Knowledge-aware Data Selection (namely KDS) framework to\nselect the domain-specific instruction-tuning data that meets LLMs\\\' actual\nneeds. The core of KDS is to leverage two knowledge-aware metrics for\nquantitatively measuring knowledge conflicts from two aspects: context-memory\nknowledge alignment and intra-memory knowledge consistency. By filtering the\ndata with large knowledge conflicts and sampling the high-quality and diverse\ndata, KDS can effectively stimulate the LLMs\\\' abilities and achieve better\ndomain-specific performance. Taking the medical domain as the testbed, we\nconduct extensive experiments and empirically prove that KDS surpasses the\nother baselines and brings significant and consistent performance gains among\nall LLMs. More encouragingly, KDS effectively improves the model generalization\nand alleviates the hallucination problem.','Qihuang Zhong, Liang Ding, Fei Liao, Juhua Liu, Bo Du, Dacheng Tao','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21958v1'),('2505.21959v1','EnsemW2S: Enhancing Weak-to-Strong Generalization with Large Language Model Ensembles','With Large Language Models (LLMs) rapidly approaching and potentially\nsurpassing human-level performance, it has become imperative to develop\napproaches capable of effectively supervising and enhancing these powerful\nmodels using smaller, human-level models exposed to only human-level data. We\naddress this critical weak-to-strong (W2S) generalization challenge by\nproposing a novel method aimed at improving weak experts, by training on the\nsame limited human-level data, enabling them to generalize to complex,\nsuper-human-level tasks. Our approach, called \\textbf{EnsemW2S}, employs a\ntoken-level ensemble strategy that iteratively combines multiple weak experts,\nsystematically addressing the shortcomings identified in preceding iterations.\nBy continuously refining these weak models, we significantly enhance their\ncollective ability to supervise stronger student models. We extensively\nevaluate the generalization performance of both the ensemble of weak experts\nand the subsequent strong student model across in-distribution (ID) and\nout-of-distribution (OOD) datasets. For OOD, we specifically introduce question\ndifficulty as an additional dimension for defining distributional shifts. Our\nempirical results demonstrate notable improvements, achieving 4\\%, and 3.2\\%\nimprovements on ID datasets and, upto 6\\% and 2.28\\% on OOD datasets for\nexperts and student models respectively, underscoring the effectiveness of our\nproposed method in advancing W2S generalization.','Aakriti Agrawal, Mucong Ding, Zora Che, Chenghao Deng, Anirudh Satheesh, Bang An, Bayan Bruss, John Langford, Furong Huang','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21959v1'),('2505.21963v1','LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents','Large Language Models (LLMs) have demonstrated exceptional performance across\na wide range of tasks. To further tailor LLMs to specific domains or\napplications, post-training techniques such as Supervised Fine-Tuning (SFT),\nPreference Learning, and model merging are commonly employed. While each of\nthese methods has been extensively studied in isolation, the automated\nconstruction of complete post-training pipelines remains an underexplored area.\nExisting approaches typically rely on manual design or focus narrowly on\noptimizing individual components, such as data ordering or merging strategies.\nIn this work, we introduce LaMDAgent (short for Language Model Developing\nAgent), a novel framework that autonomously constructs and optimizes full\npost-training pipelines through the use of LLM-based agents. LaMDAgent\nsystematically explores diverse model generation techniques, datasets, and\nhyperparameter configurations, leveraging task-based feedback to discover\nhigh-performing pipelines with minimal human intervention. Our experiments show\nthat LaMDAgent improves tool-use accuracy by 9.0 points while preserving\ninstruction-following capabilities. Moreover, it uncovers effective\npost-training strategies that are often overlooked by conventional human-driven\nexploration. We further analyze the impact of data and model size scaling to\nreduce computational costs on the exploration, finding that model size scalings\nintroduces new challenges, whereas scaling data size enables cost-effective\npipeline discovery.','Taro Yano, Yoichi Ishibashi, Masafumi Oyamada','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21963v1'),('2505.21964v1','UI-Evol: Automatic Knowledge Evolving for Computer Use Agents','External knowledge has played a crucial role in the recent development of\ncomputer use agents. We identify a critical knowledge-execution gap: retrieved\nknowledge often fails to translate into effective real-world task execution.\nOur analysis shows even 90\\% correct knowledge yields only 41\\% execution\nsuccess rate. To bridge this gap, we propose UI-Evol, a plug-and-play module\nfor autonomous GUI knowledge evolution. UI-Evol consists of two stages: a\nRetrace Stage that extracts faithful objective action sequences from actual\nagent-environment interactions, and a Critique Stage that refines existing\nknowledge by comparing these sequences against external references. We conduct\ncomprehensive experiments on the OSWorld benchmark with the state-of-the-art\nAgent S2. Our results demonstrate that UI-Evol not only significantly boosts\ntask performance but also addresses a previously overlooked issue of high\nbehavioral standard deviation in computer use agents, leading to superior\nperformance on computer use tasks and substantially improved agent reliability.','Ziyun Zhang, Xinyi Liu, Xiaoyi Zhang, Jun Wang, Gang Chen, Yan Lu','2025-05-28','cs.HC','http://arxiv.org/pdf/2505.21964v1'),('2505.21966v1','MapStory: LLM-Powered Text-Driven Map Animation Prototyping with Human-in-the-Loop Editing','We introduce MapStory, an LLM-powered animation authoring tool that generates\neditable map animation sequences directly from natural language text. Given a\nuser-written script, MapStory leverages an agentic architecture to\nautomatically produce a scene breakdown, which decomposes the script into key\nanimation building blocks such as camera movements, visual highlights, and\nanimated elements. Our system includes a researcher component that accurately\nqueries geospatial information by leveraging an LLM with web search, enabling\nthe automatic extraction of relevant regions, paths, and coordinates while\nallowing users to edit and query for changes or additional information to\nrefine the results. Additionally, users can fine-tune parameters of these\nblocks through an interactive timeline editor. We detail the system\\\'s design\nand architecture, informed by formative interviews with professional animators\nand an analysis of 200 existing map animation videos. Our evaluation, which\nincludes expert interviews (N=5) and a usability study (N=12), demonstrates\nthat MapStory enables users to create map animations with ease, facilitates\nfaster iteration, encourages creative exploration, and lowers barriers to\ncreating map-centric stories.','Aditya Gunturu, Ben Pearman, Keiichi Ihara, Morteza Faraji, Bryan Wang, Rubaiat Habib Kazi, Ryo Suzuki','2025-05-28','cs.HC','http://arxiv.org/pdf/2505.21966v1'),('2505.21967v1','Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack','Large Vision-Language Models (LVLMs) have shown remarkable capabilities\nacross a wide range of multimodal tasks. However, their integration of visual\ninputs introduces expanded attack surfaces, thereby exposing them to novel\nsecurity vulnerabilities. In this work, we conduct a systematic\nrepresentational analysis to uncover why conventional adversarial attacks can\ncircumvent the safety mechanisms embedded in LVLMs. We further propose a novel\ntwo stage evaluation framework for adversarial attacks on LVLMs. The first\nstage differentiates among instruction non compliance, outright refusal, and\nsuccessful adversarial exploitation. The second stage quantifies the degree to\nwhich the model\\\'s output fulfills the harmful intent of the adversarial prompt,\nwhile categorizing refusal behavior into direct refusals, soft refusals, and\npartial refusals that remain inadvertently helpful. Finally, we introduce a\nnormative schema that defines idealized model behavior when confronted with\nharmful prompts, offering a principled target for safety alignment in\nmultimodal systems.','Juan Ren, Mark Dras, Usman Naseem','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21967v1'),('2505.21969v1','DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation','Adaptive navigation in unfamiliar environments is crucial for household\nservice robots but remains challenging due to the need for both low-level path\nplanning and high-level scene understanding. While recent vision-language model\n(VLM) based zero-shot approaches reduce dependence on prior maps and\nscene-specific training data, they face significant limitations: spatiotemporal\ndiscontinuity from discrete observations, unstructured memory representations,\nand insufficient task understanding leading to navigation failures. We propose\nDORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced Memory\nOriented Navigation), a novel cognitive-inspired framework consisting of\nVentral and Dorsal Streams that mimics human navigation capabilities. The\nDorsal Stream implements the Hierarchical Semantic-Spatial Fusion and Topology\nMap to handle spatiotemporal discontinuities, while the Ventral Stream combines\nRAG-VLM and Policy-VLM to improve decision-making. Our approach also develops\nNav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMON\non the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-art\nperformance on both success rate (SR) and success weighted by path length (SPL)\nmetrics, significantly outperforming existing methods. We also introduce a new\nevaluation metric (AORI) to assess navigation intelligence better.\nComprehensive experiments demonstrate DORAEMON\\\'s effectiveness in zero-shot\nautonomous navigation without requiring prior map building or pre-training.','Tianjun Gu, Linfeng Li, Xuhong Wang, Chenghua Gong, Jingyu Gong, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.21969v1'),('2505.21972v1','Judging LLMs on a Simplex','Automated evaluation of free-form outputs from large language models (LLMs)\nis challenging because many distinct answers can be equally valid. A common\npractice is to use LLMs themselves as judges, but the theoretical properties of\nthis approach are not yet well understood. We show that a geometric framework\nthat represents both judges and candidates as points on a probability simplex\ncan provide helpful insight on what is or is not identifiable using LLM judges.\nOur theoretical analysis uncovers a \"phase transition\" in ranking\nidentifiability: for binary scoring systems, true rankings are identifiable\neven with weak judges under mild assumptions, while rankings become\nnon-identifiable for three or more scoring levels even with infinite data,\nabsent additional prior knowledge. This non-identifiability highlights how\nuncertainty in rankings stems from not only aleatoric uncertainty (i.e.,\ninherent stochasticity in the data) but also epistemic uncertainty regarding\nwhich assumptions hold, an aspect that has received limited attention until\nnow. To integrate both types of uncertainty, we use Bayesian inference to\nencode assumptions as priors and conduct sensitivity analysis of ranking\nestimates and credible intervals. Empirical evaluations across multiple\nbenchmarks demonstrate that Bayesian inference yields more accurate rankings\nand substantially improves coverage rates. These results underscore the\nimportance of taking a more holistic approach to uncertainty quantification\nwhen using LLMs as judges.','Patrick Vossler, Fan Xia, Yifan Mai, Jean Feng','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21972v1'),('2505.21974v1','BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL','Bayesian optimization (BO) offers an efficient pipeline for optimizing\nblack-box functions with the help of a Gaussian process prior and an\nacquisition function (AF). Recently, in the context of single-objective BO,\nlearning-based AFs witnessed promising empirical results given its favorable\nnon-myopic nature. Despite this, the direct extension of these approaches to\nmulti-objective Bayesian optimization (MOBO) suffer from the\n\\textit{hypervolume identifiability issue}, which results from the\nnon-Markovian nature of MOBO problems. To tackle this, inspired by the\nnon-Markovian RL literature and the success of Transformers in language\nmodeling, we present a generalized deep Q-learning framework and propose\n\\textit{BOFormer}, which substantiates this framework for MOBO via sequence\nmodeling. Through extensive evaluation, we demonstrate that BOFormer constantly\noutperforms the benchmark rule-based and learning-based algorithms in various\nsynthetic MOBO and real-world multi-objective hyperparameter optimization\nproblems. We have made the source code publicly available to encourage further\nresearch in this direction.','Yu-Heng Hung, Kai-Jie Lin, Yu-Heng Lin, Chien-YiWang, Cheng Sun, Ping-Chun Hsieh','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21974v1'),('2505.21978v1','Two-Stage Feature Generation with Transformer and Reinforcement Learning','Feature generation is a critical step in machine learning, aiming to enhance\nmodel performance by capturing complex relationships within the data and\ngenerating meaningful new features. Traditional feature generation methods\nheavily rely on domain expertise and manual intervention, making the process\nlabor-intensive and challenging to adapt to different scenarios. Although\nautomated feature generation techniques address these issues to some extent,\nthey often face challenges such as feature redundancy, inefficiency in feature\nspace exploration, and limited adaptability to diverse datasets and tasks. To\naddress these problems, we propose a Two-Stage Feature Generation (TSFG)\nframework, which integrates a Transformer-based encoder-decoder architecture\nwith Proximal Policy Optimization (PPO). The encoder-decoder model in TSFG\nleverages the Transformer\\\'s self-attention mechanism to efficiently represent\nand transform features, capturing complex dependencies within the data. PPO\nfurther enhances TSFG by dynamically adjusting the feature generation strategy\nbased on task-specific feedback, optimizing the process for improved\nperformance and adaptability. TSFG dynamically generates high-quality feature\nsets, significantly improving the predictive performance of machine learning\nmodels. Experimental results demonstrate that TSFG outperforms existing\nstate-of-the-art methods in terms of feature quality and adaptability.','Wanfu Gao, Zengyao Man, Zebin He, Yuhao Tang, Jun Gao, Kunpeng Liu','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21978v1'),('2505.21979v1','Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset','Mainstream large vision-language models (LVLMs) inherently encode cultural\nbiases, highlighting the need for diverse multimodal datasets. To address this\ngap, we introduce Pearl, a large-scale Arabic multimodal dataset and benchmark\nexplicitly designed for cultural understanding. Constructed through advanced\nagentic workflows and extensive human-in-the-loop annotations by 45 annotators\nfrom across the Arab world, Pearl comprises over K multimodal examples spanning\nten culturally significant domains covering all Arab countries. We further\nprovide two robust evaluation benchmarks Pearl and Pearl-Lite along with a\nspecialized subset Pearl-X explicitly developed to assess nuanced cultural\nvariations. Comprehensive evaluations on state-of-the-art open and proprietary\nLVLMs demonstrate that reasoning-centric instruction alignment substantially\nimproves models\\\' cultural grounding compared to conventional scaling methods.\nPearl establishes a foundational resource for advancing culturally-informed\nmultimodal modeling research. All datasets and benchmarks are publicly\navailable.','Fakhraddin Alwajih, Samar Mohamed Magdy, Abdellah El Mekki, Omer Nacar, Youssef Nafea, Safaa Taher Abdelfadil, Abdulfattah Mohammed Yahya, Hamzah Luqman, Nada Almarwani, Samah Aloufi, Baraah Qawasmeh, Houdaifa Atou, Serry Sibaee, Hamzah A. Alsayadi, Walid Al-Dhabyani, Maged S. Al-shaibani, Aya El aatar, Nour Qandos, Rahaf Alhamouri, Samar Ahmad, Razan Khassib, Lina Hamad, Mohammed Anwar AL-Ghrawi, Fatimah Alshamari, Cheikh Malainine, Doaa Qawasmeh, Aminetou Yacoub, Tfeil moilid, Ruwa AbuHweidi, Ahmed Aboeitta, Vatimetou Mohamed Lemin, Reem Abdel-Salam, Ahlam Bashiti, Adel Ammar, Aisha Alansari, Ahmed Ashraf, Nora Alturayeif, Sara Shatnawi, Alcides Alcoba Inciarte, AbdelRahim A. Elmadany, Mohamedou cheikh tourad, Ismail Berrada, Mustafa Jarrar, Shady Shehata, Muhammad Abdul-Mageed','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21979v1'),('2505.21981v1','Learning Compositional Behaviors from Demonstration and Language','We introduce Behavior from Language and Demonstration (BLADE), a framework\nfor long-horizon robotic manipulation by integrating imitation learning and\nmodel-based planning. BLADE leverages language-annotated demonstrations,\nextracts abstract action knowledge from large language models (LLMs), and\nconstructs a library of structured, high-level action representations. These\nrepresentations include preconditions and effects grounded in visual perception\nfor each high-level action, along with corresponding controllers implemented as\nneural network-based policies. BLADE can recover such structured\nrepresentations automatically, without manually labeled states or symbolic\ndefinitions. BLADE shows significant capabilities in generalizing to novel\nsituations, including novel initial states, external state perturbations, and\nnovel goals. We validate the effectiveness of our approach both in simulation\nand on real robots with a diverse set of objects with articulated parts,\npartial observability, and geometric constraints.','Weiyu Liu, Neil Nie, Ruohan Zhang, Jiayuan Mao, Jiajun Wu','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.21981v1'),('2505.21985v1','Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning','In multi-agent reinforcement learning (MARL), effective communication\nimproves agent performance, particularly under partial observability. We\npropose MARL-CPC, a framework that enables communication among fully\ndecentralized, independent agents without parameter sharing. MARL-CPC\nincorporates a message learning model based on collective predictive coding\n(CPC) from emergent communication research. Unlike conventional methods that\ntreat messages as part of the action space and assume cooperation, MARL-CPC\nlinks messages to state inference, supporting communication in non-cooperative,\nreward-independent settings. We introduce two algorithms -Bandit-CPC and\nIPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that\nboth outperform standard message-as-action approaches, establishing effective\ncommunication even when messages offer no direct benefit to the sender. These\nresults highlight MARL-CPC\\\'s potential for enabling coordination in complex,\ndecentralized environments.','Naoto Yoshida, Tadahiro Taniguchi','2025-05-28','cs.MA','http://arxiv.org/pdf/2505.21985v1'),('2505.21987v1','ACE: Exploring Activation Cosine Similarity and Variance for Accurate and Calibration-Efficient LLM Pruning','With the rapid expansion of large language models (LLMs), the demand for\nmemory and computational resources has grown significantly. Recent advances in\nLLM pruning aim to reduce the size and computational cost of these models.\nHowever, existing methods often suffer from either suboptimal pruning\nperformance or low time efficiency during the pruning process. In this work, we\npropose an efficient and effective pruning method that simultaneously achieves\nhigh pruning performance and fast pruning speed with improved calibration\nefficiency. Our approach introduces two key innovations: (1) An activation\ncosine similarity loss-guided pruning metric, which considers the angular\ndeviation of the output activation between the dense and pruned models. (2) An\nactivation variance-guided pruning metric, which helps preserve semantic\ndistinctions in output activations after pruning, enabling effective pruning\nwith shorter input sequences. These two components can be readily combined to\nenhance LLM pruning in both accuracy and efficiency. Experimental results show\nthat our method achieves up to an 18% reduction in perplexity and up to 63%\ndecrease in pruning time on prevalent LLMs such as LLaMA, LLaMA-2, and OPT.','Zhendong Mi, Zhenglun Kong, Geng Yuan, Shaoyi Huang','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.21987v1'),('2505.21988v1','Functional Matching of Logic Subgraphs: Beyond Structural Isomorphism','Subgraph matching in logic circuits is foundational for numerous Electronic\nDesign Automation (EDA) applications, including datapath optimization,\narithmetic verification, and hardware trojan detection. However, existing\ntechniques rely primarily on structural graph isomorphism and thus fail to\nidentify function-related subgraphs when synthesis transformations\nsubstantially alter circuit topology. To overcome this critical limitation, we\nintroduce the concept of functional subgraph matching, a novel approach that\nidentifies whether a given logic function is implicitly present within a larger\ncircuit, irrespective of structural variations induced by synthesis or\ntechnology mapping. Specifically, we propose a two-stage multi-modal framework:\n(1) learning robust functional embeddings across AIG and post-mapping netlists\nfor functional subgraph detection, and (2) identifying fuzzy boundaries using a\ngraph segmentation approach. Evaluations on standard benchmarks (ITC99,\nOpenABCD, ForgeEDA) demonstrate significant performance improvements over\nexisting structural methods, with average $93.8\\%$ accuracy in functional\nsubgraph detection and a dice score of $91.3\\%$ in fuzzy boundary\nidentification.','Ziyang Zheng, Kezhi Li, Zhengyuan Shi, Qiang Xu','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.21988v1'),('2505.21994v1','Locking-Free Training of Physics-Informed Neural Network for Solving Nearly Incompressible Elasticity Equations','Due to divergence instability, the accuracy of low-order conforming finite\nelement methods for nearly incompressible homogeneous elasticity equations\ndeteriorates as the Lam\\\\\'e coefficient $\\lambda\\to\\infty$, or equivalently as\nthe Poisson ratio $\\nu\\to1/2$. This phenomenon, known as locking or\nnon-robustness, remains not fully understood despite extensive investigation.\nIn this paper, we propose a robust method based on a fundamentally different,\nmachine-learning-driven approach. Leveraging recently developed\nPhysics-Informed Neural Networks (PINNs), we address the numerical solution of\nlinear elasticity equations governing nearly incompressible materials. The core\nidea of our method is to appropriately decompose the given equations to\nalleviate the extreme imbalance in the coefficients, while simultaneously\nsolving both the forward and inverse problems to recover the solutions of the\ndecomposed systems as well as the associated external conditions. Through\nvarious numerical experiments, including constant, variable and parametric\nLam\\\\\'e coefficients, we illustrate the efficiency of the proposed methodology.','Josef Dick, Seungchan Ko, Kassem Mustapha, Sanghyeon Park','2025-05-28','math.NA','http://arxiv.org/pdf/2505.21994v1'),('2505.21996v1','Learning World Models for Interactive Video Generation','Foundational world models must be both interactive and preserve\nspatiotemporal coherence for effective future planning with action choices.\nHowever, present models for long video generation have limited inherent world\nmodeling capabilities due to two main challenges: compounding errors and\ninsufficient memory mechanisms. We enhance image-to-video models with\ninteractive capabilities through additional action conditioning and\nautoregressive framework, and reveal that compounding error is inherently\nirreducible in autoregressive video generation, while insufficient memory\nmechanism leads to incoherence of world models. We propose video retrieval\naugmented generation (VRAG) with explicit global state conditioning, which\nsignificantly reduces long-term compounding errors and increases spatiotemporal\nconsistency of world models. In contrast, naive autoregressive generation with\nextended context windows and retrieval-augmented generation prove less\neffective for video generation, primarily due to the limited in-context\nlearning capabilities of current video models. Our work illuminates the\nfundamental challenges in video world models and establishes a comprehensive\nbenchmark for improving video generation models with internal world modeling\ncapabilities.','Taiye Chen, Xun Hu, Zihan Ding, Chi Jin','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.21996v1'),('2505.21997v1','Leveraging Interview-Informed LLMs to Model Survey Responses: Comparative Insights from AI-Generated and Human Data','Mixed methods research integrates quantitative and qualitative data but faces\nchallenges in aligning their distinct structures, particularly in examining\nmeasurement characteristics and individual response patterns. Advances in large\nlanguage models (LLMs) offer promising solutions by generating synthetic survey\nresponses informed by qualitative data. This study investigates whether LLMs,\nguided by personal interviews, can reliably predict human survey responses,\nusing the Behavioral Regulations in Exercise Questionnaire (BREQ) and\ninterviews from after-school program staff as a case study. Results indicate\nthat LLMs capture overall response patterns but exhibit lower variability than\nhumans. Incorporating interview data improves response diversity for some\nmodels (e.g., Claude, GPT), while well-crafted prompts and low-temperature\nsettings enhance alignment between LLM and human responses. Demographic\ninformation had less impact than interview content on alignment accuracy. These\nfindings underscore the potential of interview-informed LLMs to bridge\nqualitative and quantitative methodologies while revealing limitations in\nresponse variability, emotional interpretation, and psychometric fidelity.\nFuture research should refine prompt design, explore bias mitigation, and\noptimize model settings to enhance the validity of LLM-generated survey data in\nsocial science research.','Jihong Zhang, Xinya Liang, Anqi Deng, Nicole Bonge, Lin Tan, Ling Zhang, Nicole Zarrett','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21997v1'),('2505.21999v1','Found in Translation: Measuring Multilingual LLM Consistency as Simple as Translate then Evaluate','Large language models (LLMs) provide detailed and impressive responses to\nqueries in English. However, are they really consistent at responding to the\nsame query in other languages? The popular way of evaluating for multilingual\nperformance of LLMs requires expensive-to-collect annotated datasets. Further,\nevaluating for tasks like open-ended generation, where multiple correct answers\nmay exist, is nontrivial. Instead, we propose to evaluate the predictability of\nmodel response across different languages. In this work, we propose a framework\nto evaluate LLM\\\'s cross-lingual consistency based on a simple Translate then\nEvaluate strategy. We instantiate this evaluation framework along two\ndimensions of consistency: information and empathy. Our results reveal\npronounced inconsistencies in popular LLM responses across thirty languages,\nwith severe performance deficits in certain language families and scripts,\nunderscoring critical weaknesses in their multilingual capabilities. These\nfindings necessitate cross-lingual evaluations that are consistent along\nmultiple dimensions. We invite practitioners to use our framework for future\nmultilingual LLM benchmarking.','Ashim Gupta, Maitrey Mehta, Zhichao Xu, Vivek Srikumar','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.21999v1'),('2505.22003v1','Legal Assist AI: Leveraging Transformer-Based Model for Effective Legal Assistance','Pursuit of accessible legal assistance in India faces a critical gap, as many\ncitizens struggle to leverage their legal rights due to limited awareness and\naccess to relevant legal information. This paper introduces Legal Assist AI, a\ntransformer-based model designed to bridge this gap by offering effective legal\nassistance through large language models (LLMs). The system retrieves relevant\nlegal information from a curated database and generates accurate responses,\nenabling effective assistance for diverse users, including legal professionals,\nscholars, and the general public. The model was fine-tuned on extensive\ndatasets from the Indian legal domain, including Indian Constitution, Bharatiya\nNyaya Sanhita (BNS), Bharatiya Nagarik Suraksha Sanhita (BNSS) and so forth,\nproviding a robust understanding of the complexities of Indian law. By\nincorporating domain-specific legal datasets, the proposed model demonstrated\nremarkable efficiency and specialization in legal Question-Answering. The model\nwas evaluated against state-of-the-art models such as GPT-3.5 Turbo and Mistral\n7B, achieving a 60.08% score on the AIBE, outperforming its competitors in\nlegal reasoning and accuracy. Unlike other models, Legal Assist AI avoided\ncommon issues such as hallucinations, making it highly reliable for practical\nlegal applications. It showcases the model\\\'s applicability in real-world legal\nscenarios, with future iterations aiming to enhance performance and expand its\ndataset to cover a broader range of multilingual and case-specific queries as\nwell.','Jatin Gupta, Akhil Sharma, Saransh Singhania, Ali Imam Abidi','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22003v1'),('2505.22006v1','Efficiently Enhancing General Agents With Hierarchical-categorical Memory','With large language models (LLMs) demonstrating remarkable capabilities,\nthere has been a surge in research on leveraging LLMs to build general-purpose\nmulti-modal agents. However, existing approaches either rely on computationally\nexpensive end-to-end training using large-scale multi-modal data or adopt\ntool-use methods that lack the ability to continuously learn and adapt to new\nenvironments. In this paper, we introduce EHC, a general agent capable of\nlearning without parameter updates. EHC consists of a Hierarchical Memory\nRetrieval (HMR) module and a Task-Category Oriented Experience Learning (TOEL)\nmodule. The HMR module facilitates rapid retrieval of relevant memories and\ncontinuously stores new information without being constrained by memory\ncapacity. The TOEL module enhances the agent\\\'s comprehension of various task\ncharacteristics by classifying experiences and extracting patterns across\ndifferent categories. Extensive experiments conducted on multiple standard\ndatasets demonstrate that EHC outperforms existing methods, achieving\nstate-of-the-art performance and underscoring its effectiveness as a general\nagent for handling complex multi-modal tasks.','Changze Qiao, Mingming Lu','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22006v1'),('2505.22008v1','Align-DA: Align Score-based Atmospheric Data Assimilation with Multiple Preferences','Data assimilation (DA) aims to estimate the full state of a dynamical system\nby combining partial and noisy observations with a prior model forecast,\ncommonly referred to as the background. In atmospheric applications, this\nproblem is fundamentally ill-posed due to the sparsity of observations relative\nto the high-dimensional state space. Traditional methods address this challenge\nby simplifying background priors to regularize the solution, which are\nempirical and require continual tuning for application. Inspired by alignment\ntechniques in text-to-image diffusion models, we propose Align-DA, which\nformulates DA as a generative process and uses reward signals to guide\nbackground priors, replacing manual tuning with data-driven alignment.\nSpecifically, we train a score-based model in the latent space to approximate\nthe background-conditioned prior, and align it using three complementary reward\nsignals for DA: (1) assimilation accuracy, (2) forecast skill initialized from\nthe assimilated state, and (3) physical adherence of the analysis fields.\nExperiments with multiple reward signals demonstrate consistent improvements in\nanalysis quality across different evaluation metrics and observation-guidance\nstrategies. These results show that preference alignment, implemented as a soft\nconstraint, can automatically adapt complex background priors tailored to DA,\noffering a promising new direction for advancing the field.','Jing-An Sun, Hang Fan, Junchao Gong, Ben Fei, Kun Chen, Fenghua Ling, Wenlong Zhang, Wanghan Xu, Li Yan, Pierre Gentine, Lei Bai','2025-05-28','physics.ao-ph','http://arxiv.org/pdf/2505.22008v1'),('2505.22014v1','Learning in Compact Spaces with Approximately Normalized Transformers','In deep learning, regularization and normalization are common solutions for\nchallenges such as overfitting, numerical instabilities, and the increasing\nvariance in the residual stream. An alternative approach is to force all\nparameters and representations to lie on a hypersphere. This removes the need\nfor regularization and increases convergence speed, but comes with additional\ncosts. In this work, we propose a more holistic but approximate normalization\n(anTransformer). Our approach constrains the norm of parameters and normalizes\nall representations via scalar multiplications motivated by the tight\nconcentration of the norms of high-dimensional random vectors. When applied to\nGPT training, we observe a 40% faster convergence compared to models with QK\nnormalization, with less than 3% additional runtime. Deriving scaling laws for\nanGPT, we found our method enables training with larger batch sizes and fewer\nhyperparameters, while matching the favorable scaling characteristics of\nclassic GPT architectures.','Jörg K. H. Franke, Urs Spiegelhalter, Marianna Nezhurina, Jenia Jitsev, Frank Hutter, Michael Hefenbrock','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22014v1'),('2505.22017v1','CoThink: Token-Efficient Reasoning via Instruct Models Guiding Reasoning Models','Large language models (LLMs) benefit from increased test-time compute, a\nphenomenon known as test-time scaling. However, reasoning-optimized models\noften overthink even simple problems, producing excessively verbose outputs and\nleading to low token efficiency. By comparing these models with equally sized\ninstruct models, we identify two key causes of this verbosity: (1)\nreinforcement learning reduces the information density of forward reasoning,\nand (2) backward chain-of thought training encourages redundant and often\nunnecessary verification steps. Since LLMs cannot assess the difficulty of a\ngiven problem, they tend to apply the same cautious reasoning strategy across\nall tasks, resulting in inefficient overthinking. To address this, we propose\nCoThink, an embarrassingly simple pipeline: an instruct model first drafts a\nhigh-level solution outline; a reasoning model then works out the solution. We\nobserve that CoThink enables dynamic adjustment of reasoning depth based on\ninput difficulty. Evaluated with three reasoning models DAPO, DeepSeek-R1, and\nQwQ on three datasets GSM8K, MATH500, and AIME24, CoThink reduces total token\ngeneration by 22.3% while maintaining pass@1 accuracy within a 0.42% margin on\naverage. With reference to the instruct model, we formally define reasoning\nefficiency and observe a potential reasoning efficiency scaling law in LLMs.','Siqi Fan, Peng Han, Shuo Shang, Yequan Wang, Aixin Sun','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22017v1'),('2505.22018v1','Improving Continual Pre-training Through Seamless Data Packing','Continual pre-training has demonstrated significant potential in enhancing\nmodel performance, particularly in domain-specific scenarios. The most common\napproach for packing data before continual pre-training involves concatenating\ninput texts and splitting them into fixed-length sequences. While\nstraightforward and efficient, this method often leads to excessive truncation\nand context discontinuity, which can hinder model performance. To address these\nissues, we explore the potential of data engineering to enhance continual\npre-training, particularly its impact on model performance and efficiency. We\npropose Seamless Packing (SP), a novel data packing strategy aimed at\npreserving contextual information more effectively and enhancing model\nperformance. Our approach employs a sliding window technique in the first stage\nthat synchronizes overlapping tokens across consecutive sequences, ensuring\nbetter continuity and contextual coherence. In the second stage, we adopt a\nFirst-Fit-Decreasing algorithm to pack shorter texts into bins slightly larger\nthan the target sequence length, thereby minimizing padding and truncation.\nEmpirical evaluations across various model architectures and corpus domains\ndemonstrate the effectiveness of our method, outperforming baseline method in\n99% of all settings. Code is available at\nhttps://github.com/Infernus-WIND/Seamless-Packing.','Ruicheng Yin, Xuan Gao, Changze Lv, Xiaohua Wang, Xiaoqing Zheng, Xuanjing Huang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22018v1'),('2505.22019v1','VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning','Effectively retrieving, reasoning and understanding visually rich information\nremains a challenge for RAG methods. Traditional text-based methods cannot\nhandle visual-related information. On the other hand, current vision-based RAG\napproaches are often limited by fixed pipelines and frequently struggle to\nreason effectively due to the insufficient activation of the fundamental\ncapabilities of models. As RL has been proven to be beneficial for model\nreasoning, we introduce VRAG-RL, a novel RL framework tailored for complex\nreasoning across visually rich information. With this framework, VLMs interact\nwith search engines, autonomously sampling single-turn or multi-turn reasoning\ntrajectories with the help of visual perception tokens and undergoing continual\noptimization based on these samples. Our approach highlights key limitations of\nRL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely\nincorporate images into the context, leading to insufficient reasoning token\nallocation and neglecting visual-specific perception; and (ii) When models\ninteract with search engines, their queries often fail to retrieve relevant\ninformation due to the inability to articulate requirements, thereby leading to\nsuboptimal performance. To address these challenges, we define an action space\ntailored for visually rich inputs, with actions including cropping and scaling,\nallowing the model to gather information from a coarse-to-fine perspective.\nFurthermore, to bridge the gap between users\\\' original inquiries and the\nretriever, we employ a simple yet effective reward that integrates query\nrewriting and retrieval performance with a model-based reward. Our VRAG-RL\noptimizes VLMs for RAG tasks using specially designed RL strategies, aligning\nthe model with real-world applications. The code is available at\n\\hyperlink{https://github.com/Alibaba-NLP/VRAG}{https://github.com/Alibaba-NLP/VRAG}.','Qiuchen Wang, Ruixue Ding, Yu Zeng, Zehui Chen, Lin Chen, Shihang Wang, Pengjun Xie, Fei Huang, Feng Zhao','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22019v1'),('2505.22021v1','GL-PGENet: A Parameterized Generation Framework for Robust Document Image Enhancement','Document Image Enhancement (DIE) serves as a critical component in Document\nAI systems, where its performance substantially determines the effectiveness of\ndownstream tasks. To address the limitations of existing methods confined to\nsingle-degradation restoration or grayscale image processing, we present Global\nwith Local Parametric Generation Enhancement Network (GL-PGENet), a novel\narchitecture designed for multi-degraded color document images, ensuring both\nefficiency and robustness in real-world scenarios. Our solution incorporates\nthree key innovations: First, a hierarchical enhancement framework that\nintegrates global appearance correction with local refinement, enabling\ncoarse-to-fine quality improvement. Second, a Dual-Branch Local-Refine Network\nwith parametric generation mechanisms that replaces conventional direct\nprediction, producing enhanced outputs through learned intermediate parametric\nrepresentations rather than pixel-wise mapping. This approach enhances local\nconsistency while improving model generalization. Finally, a modified NestUNet\narchitecture incorporating dense block to effectively fuse low-level pixel\nfeatures and high-level semantic features, specifically adapted for document\nimage characteristics. In addition, to enhance generalization performance, we\nadopt a two-stage training strategy: large-scale pretraining on a synthetic\ndataset of 500,000+ samples followed by task-specific fine-tuning. Extensive\nexperiments demonstrate the superiority of GL-PGENet, achieving\nstate-of-the-art SSIM scores of 0.7721 on DocUNet and 0.9480 on RealDAE. The\nmodel also exhibits remarkable cross-domain adaptability and maintains\ncomputational efficiency for high-resolution images without performance\ndegradation, confirming its practical utility in real-world scenarios.','Zhihong Tang, Yang Li','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22021v1'),('2505.22027v1','Improving Respiratory Sound Classification with Architecture-Agnostic Knowledge Distillation from Ensembles','Respiratory sound datasets are limited in size and quality, making high\nperformance difficult to achieve. Ensemble models help but inevitably increase\ncompute cost at inference time. Soft label training distills knowledge\nefficiently with extra cost only at training. In this study, we explore soft\nlabels for respiratory sound classification as an architecture-agnostic\napproach to distill an ensemble of teacher models into a student model. We\nexamine different variations of our approach and find that even a single\nteacher, identical to the student, considerably improves performance beyond its\nown capability, with optimal gains achieved using only a few teachers. We\nachieve the new state-of-the-art Score of 64.39 on ICHBI, surpassing the\nprevious best by 0.85 and improving average Scores across architectures by more\nthan 1.16. Our results highlight the effectiveness of knowledge distillation\nwith soft labels for respiratory sound classification, regardless of size or\narchitecture.','Miika Toikkanen, June-Woo Kim','2025-05-28','cs.SD','http://arxiv.org/pdf/2505.22027v1'),('2505.22028v1','Weakly-Supervised Contrastive Learning for Imprecise Class Labels','Contrastive learning has achieved remarkable success in learning effective\nrepresentations, with supervised contrastive learning often outperforming\nself-supervised approaches. However, in real-world scenarios, data annotations\nare often ambiguous or inaccurate, meaning that class labels may not reliably\nindicate whether two examples belong to the same class. This limitation\nrestricts the applicability of supervised contrastive learning. To address this\nchallenge, we introduce the concept of ``continuous semantic similarity\\\'\\\' to\ndefine positive and negative pairs. Instead of directly relying on imprecise\nclass labels, we measure the semantic similarity between example pairs, which\nquantifies how closely they belong to the same category by iteratively refining\nweak supervisory signals. Based on this concept, we propose a graph-theoretic\nframework for weakly-supervised contrastive learning, where semantic similarity\nserves as the graph weights. Our framework is highly versatile and can be\napplied to many weakly-supervised learning scenarios. We demonstrate its\neffectiveness through experiments in two common settings, i.e., noisy label and\npartial label learning, where existing methods can be easily integrated to\nsignificantly improve performance. Theoretically, we establish an error bound\nfor our approach, showing that it can approximate supervised contrastive\nlearning under mild conditions. The implementation code is available at\nhttps://github.com/Speechless-10308/WSC.','Zi-Hao Zhou, Jun-Jie Wang, Tong Wei, Min-Ling Zhang','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22028v1'),('2505.22029v1','Analysis and Evaluation of Synthetic Data Generation in Speech Dysfluency Detection','Speech dysfluency detection is crucial for clinical diagnosis and language\nassessment, but existing methods are limited by the scarcity of high-quality\nannotated data. Although recent advances in TTS model have enabled synthetic\ndysfluency generation, existing synthetic datasets suffer from unnatural\nprosody and limited contextual diversity. To address these limitations, we\npropose LLM-Dys -- the most comprehensive dysfluent speech corpus with\nLLM-enhanced dysfluency simulation. This dataset captures 11 dysfluency\ncategories spanning both word and phoneme levels. Building upon this resource,\nwe improve an end-to-end dysfluency detection framework. Experimental\nvalidation demonstrates state-of-the-art performance. All data, models, and\ncode are open-sourced at https://github.com/Berkeley-Speech-Group/LLM-Dys.','Jinming Zhang, Xuanru Zhou, Jiachen Lian, Shuhe Li, William Li, Zoe Ezzes, Rian Bogley, Lisa Wauters, Zachary Miller, Jet Vonk, Brittany Morin, Maria Gorno-Tempini, Gopala Anumanchipalli','2025-05-28','eess.AS','http://arxiv.org/pdf/2505.22029v1'),('2505.22037v1','Jailbreak Distillation: Renewable Safety Benchmarking','Large language models (LLMs) are rapidly deployed in critical applications,\nraising urgent needs for robust safety benchmarking. We propose Jailbreak\nDistillation (JBDistill), a novel benchmark construction framework that\n\"distills\" jailbreak attacks into high-quality and easily-updatable safety\nbenchmarks. JBDistill utilizes a small set of development models and existing\njailbreak attack algorithms to create a candidate prompt pool, then employs\nprompt selection algorithms to identify an effective subset of prompts as\nsafety benchmarks. JBDistill addresses challenges in existing safety\nevaluation: the use of consistent evaluation prompts across models ensures fair\ncomparisons and reproducibility. It requires minimal human effort to rerun the\nJBDistill pipeline and produce updated benchmarks, alleviating concerns on\nsaturation and contamination. Extensive experiments demonstrate our benchmarks\ngeneralize robustly to 13 diverse evaluation models held out from benchmark\nconstruction, including proprietary, specialized, and newer-generation LLMs,\nsignificantly outperforming existing safety benchmarks in effectiveness while\nmaintaining high separability and diversity. Our framework thus provides an\neffective, sustainable, and adaptable solution for streamlining safety\nevaluation.','Jingyu Zhang, Ahmed Elgohary, Xiawei Wang, A S M Iftekhar, Ahmed Magooda, Benjamin Van Durme, Daniel Khashabi, Kyle Jackson','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22037v1'),('2505.22038v1','Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization','Large Vision-Language Models (LVLMs) have shown impressive performance across\nmulti-modal tasks by encoding images into thousands of tokens. However, the\nlarge number of image tokens results in significant computational overhead, and\nthe use of dynamic high-resolution inputs further increases this burden.\nPrevious approaches have attempted to reduce the number of image tokens through\ntoken pruning, typically by selecting tokens based on attention scores or image\ntoken diversity. Through empirical studies, we observe that existing methods\noften overlook the joint impact of pruning on both the current layer\\\'s output\n(local) and the outputs of subsequent layers (global), leading to suboptimal\npruning decisions. To address this challenge, we propose Balanced Token Pruning\n(BTP), a plug-and-play method for pruning vision tokens. Specifically, our\nmethod utilizes a small calibration set to divide the pruning process into\nmultiple stages. In the early stages, our method emphasizes the impact of\npruning on subsequent layers, whereas in the deeper stages, the focus shifts\ntoward preserving the consistency of local outputs. Extensive experiments\nacross various LVLMs demonstrate the broad effectiveness of our approach on\nmultiple benchmarks. Our method achieves a 78% compression rate while\npreserving 96.7% of the original models\\\' performance on average.','Kaiyuan Li, Xiaoyue Chen, Chen Gao, Yong Li, Xinlei Chen','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22038v1'),('2505.22041v1','Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation','Conformance checking techniques detect undesired process behavior by\ncomparing process executions that are recorded in event logs to desired\nbehavior that is captured in a dedicated process model. If such models are not\navailable, conformance checking techniques are not applicable, but\norganizations might still be interested in detecting undesired behavior in\ntheir processes. To enable this, existing approaches use Large Language Models\n(LLMs), assuming that they can learn to distinguish desired from undesired\nbehavior through fine-tuning. However, fine-tuning is highly resource-intensive\nand the fine-tuned LLMs often do not generalize well. To address these\nlimitations, we propose an approach that requires neither a dedicated process\nmodel nor resource-intensive fine-tuning to detect undesired process behavior.\nInstead, we use Retrieval Augmented Generation (RAG) to provide an LLM with\ndirect access to a knowledge base that contains both desired and undesired\nprocess behavior from other processes, assuming that the LLM can transfer this\nknowledge to the process at hand. Our evaluation shows that our approach\noutperforms fine-tuned LLMs in detecting undesired behavior, demonstrating that\nRAG is a viable alternative to resource-intensive fine-tuning, particularly\nwhen enriched with relevant context from the event log, such as frequent traces\nand activities.','Michael Grohs, Adrian Rebmann, Jana-Rebecca Rehse','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22041v1'),('2505.22042v1','Estimating the Effects of Sample Training Orders for Large Language Models without Retraining','The order of training samples plays a crucial role in large language models\n(LLMs), significantly impacting both their external performance and internal\nlearning dynamics. Traditional methods for investigating this effect generally\nrequire retraining the model with various sample orders, which is\ncomputationally infeasible for LLMs. In this work, we improve traditional\nmethods by designing a retraining-free framework. By approximating Adam\noptimizer updates with first- and second-order Taylor expansions and utilizing\nrandom projection methods to store intermediate checkpoints, our framework can\nefficiently estimate model parameters for arbitrary training sample orders.\nNext, we apply our framework to two downstream research problems: (1) Training\ncurriculum design for LLMs -- we base our retraining-free framework to propose\na novel curriculum learning strategy that augments curriculum proposals with\nestimated model performances, enabling more informed sample scheduling. (2)\nLLMs\\\' memorization and generalization effect analysis -- we use our\nretraining-free framework to estimate how the positions of training samples\ninfluence LLMs\\\' capacity for memorization and generalization. We conduct\nextensive experiments to validate the effectiveness of our retraining-free\nframework in reproducing the true model performances, and further demonstrate\nits potential in optimizing LLM training curricula and analyzing the\nmemorization and generalization effects of LLMs.','Hao Yang, Haoxuan Li, Mengyue Yang, Xu Chen, Mingming Gong','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22042v1'),('2505.22048v1','Learning Curves of Stochastic Gradient Descent in Kernel Regression','This paper considers a canonical problem in kernel regression: how good are\nthe model performances when it is trained by the popular online first-order\nalgorithms, compared to the offline ones, such as ridge and ridgeless\nregression? In this paper, we analyze the foundational single-pass Stochastic\nGradient Descent (SGD) in kernel regression under source condition where the\noptimal predictor can even not belong to the RKHS, i.e. the model is\nmisspecified. Specifically, we focus on the inner product kernel over the\nsphere and characterize the exact orders of the excess risk curves under\ndifferent scales of sample sizes $n$ concerning the input dimension $d$.\nSurprisingly, we show that SGD achieves min-max optimal rates up to constants\namong all the scales, without suffering the saturation, a prevalent phenomenon\nobserved in (ridge) regression, except when the model is highly misspecified\nand the learning is in a final stage where $n\\gg d^{\\gamma}$ with any constant\n$\\gamma >0$. The main reason for SGD to overcome the curse of saturation is the\nexponentially decaying step size schedule, a common practice in deep neural\nnetwork training. As a byproduct, we provide the \\emph{first} provable\nadvantage of the scheme over the iterative averaging method in the common\nsetting.','Haihan Zhang, Weicheng Lin, Yuanshi Liu, Cong Fang','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22048v1'),('2505.22049v1','Differentiable Generalized Sliced Wasserstein Plans','Optimal Transport (OT) has attracted significant interest in the machine\nlearning community, not only for its ability to define meaningful distances\nbetween probability distributions -- such as the Wasserstein distance -- but\nalso for its formulation of OT plans. Its computational complexity remains a\nbottleneck, though, and slicing techniques have been developed to scale OT to\nlarge datasets. Recently, a novel slicing scheme, dubbed min-SWGG, lifts a\nsingle one-dimensional plan back to the original multidimensional space,\nfinally selecting the slice that yields the lowest Wasserstein distance as an\napproximation of the full OT plan. Despite its computational and theoretical\nadvantages, min-SWGG inherits typical limitations of slicing methods: (i) the\nnumber of required slices grows exponentially with the data dimension, and (ii)\nit is constrained to linear projections. Here, we reformulate min-SWGG as a\nbilevel optimization problem and propose a differentiable approximation scheme\nto efficiently identify the optimal slice, even in high-dimensional settings.\nWe furthermore define its generalized extension for accommodating to data\nliving on manifolds. Finally, we demonstrate the practical value of our\napproach in various applications, including gradient flows on manifolds and\nhigh-dimensional spaces, as well as a novel sliced OT-based conditional flow\nmatching for image generation -- where fast computation of transport plans is\nessential.','Laetitia Chapel, Romain Tavenard, Samuel Vaiter','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22049v1'),('2505.22050v1','Reinforced Reasoning for Embodied Planning','Embodied planning requires agents to make coherent multi-step decisions based\non dynamic visual observations and natural language goals. While recent\nvision-language models (VLMs) excel at static perception tasks, they struggle\nwith the temporal reasoning, spatial understanding, and commonsense grounding\nneeded for planning in interactive environments. In this work, we introduce a\nreinforcement fine-tuning framework that brings R1-style reasoning enhancement\ninto embodied planning. We first distill a high-quality dataset from a powerful\nclosed-source model and perform supervised fine-tuning (SFT) to equip the model\nwith structured decision-making priors. We then design a rule-based reward\nfunction tailored to multi-step action quality and optimize the policy via\nGeneralized Reinforced Preference Optimization (GRPO). Our approach is\nevaluated on Embench, a recent benchmark for interactive embodied tasks,\ncovering both in-domain and out-of-domain scenarios. Experimental results show\nthat our method significantly outperforms models of similar or larger scale,\nincluding GPT-4o-mini and 70B+ open-source baselines, and exhibits strong\ngeneralization to unseen environments. This work highlights the potential of\nreinforcement-driven reasoning to advance long-horizon planning in embodied AI.','Di Wu, Jiaxin Fan, Junzhe Zang, Guanbo Wang, Wei Yin, Wenhao Li, Bo Jin','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22050v1'),('2505.22054v1','Voice Adaptation for Swiss German','This work investigates the performance of Voice Adaptation models for Swiss\nGerman dialects, i.e., translating Standard German text to Swiss German dialect\nspeech. For this, we preprocess a large dataset of Swiss podcasts, which we\nautomatically transcribe and annotate with dialect classes, yielding\napproximately 5000 hours of weakly labeled training material. We fine-tune the\nXTTSv2 model on this dataset and show that it achieves good scores in human and\nautomated evaluations and can correctly render the desired dialect. Our work\nshows a step towards adapting Voice Cloning technology to underrepresented\nlanguages. The resulting model achieves CMOS scores of up to -0.28 and SMOS\nscores of 3.8.','Samuel Stucki, Jan Deriu, Mark Cieliebak','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22054v1'),('2505.22061v1','Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?','Retrieval-augmented generation (RAG) mitigates the hallucination problem in\nlarge language models (LLMs) and has proven effective for specific,\npersonalized applications. However, passing private retrieved documents\ndirectly to LLMs introduces vulnerability to membership inference attacks\n(MIAs), which try to determine whether the target datum exists in the private\nexternal database or not. Based on the insight that MIA queries typically\nexhibit high similarity to only one target document, we introduce Mirabel, a\nsimilarity-based MIA detection framework designed for the RAG system. With the\nproposed Mirabel, we show that simple detect-and-hide strategies can\nsuccessfully obfuscate attackers, maintain data utility, and remain\nsystem-agnostic. We experimentally prove its detection and defense against\nvarious state-of-the-art MIA methods and its adaptability to existing private\nRAG systems.','Yujin Choi, Youngjoo Park, Junyoung Byun, Jaewook Lee, Jinseong Park','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22061v1'),('2505.22067v1','From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving','Ensuring robust and generalizable autonomous driving requires not only broad\nscenario coverage but also efficient repair of failure cases, particularly\nthose related to challenging and safety-critical scenarios. However, existing\nscenario generation and selection methods often lack adaptivity and semantic\nrelevance, limiting their impact on performance improvement. In this paper, we\npropose \\textbf{SERA}, an LLM-powered framework that enables autonomous driving\nsystems to self-evolve by repairing failure cases through targeted scenario\nrecommendation. By analyzing performance logs, SERA identifies failure patterns\nand dynamically retrieves semantically aligned scenarios from a structured\nbank. An LLM-based reflection mechanism further refines these recommendations\nto maximize relevance and diversity. The selected scenarios are used for\nfew-shot fine-tuning, enabling targeted adaptation with minimal data.\nExperiments on the benchmark show that SERA consistently improves key metrics\nacross multiple autonomous driving baselines, demonstrating its effectiveness\nand generalizability under safety-critical conditions.','Xinyu Xia, Xingjun Ma, Yunfeng Hu, Ting Qu, Hong Chen, Xun Gong','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22067v1'),('2505.22068v1','Beyond path selection: Better LLMs for Scientific Information Extraction with MimicSFT and Relevance and Rule-induced(R$^2$)GRPO','Previous study suggest that powerful Large Language Models (LLMs) trained\nwith Reinforcement Learning with Verifiable Rewards (RLVR) only refines\nreasoning path without improving the reasoning capacity in math tasks while\nsupervised-finetuning(SFT) with distillation can. We study this from the view\nof Scientific information extraction (SciIE) where LLMs and reasoning LLMs\nunderperforms small Bert-based models. SciIE require both the reasoning and\nmemorization. We argue that both SFT and RLVR can refine the reasoning path and\nimprove reasoning capacity in a simple way based on SciIE. We propose two-stage\ntraining with 1. MimicSFT, using structured reasoning templates without needing\nhigh-quality chain-of-thought data, 2. R$^2$GRPO with relevance and\nrule-induced rewards. Experiments on scientific IE benchmarks show that both\nmethods can improve the reasoning capacity. R$^2$GRPO with mimicSFT surpasses\nbaseline LLMs and specialized supervised models in relation extraction. Our\ncode is available at https://github.com/ranlislz/R2GRPO.','Ran Li, Shimin Di, Yuchen Liu, Chen Jing, Yu Qiu, Lei Chen','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22068v1'),('2505.22074v1','The Resurrection of the ReLU','Modeling sophisticated activation functions within deep learning\narchitectures has evolved into a distinct research direction. Functions such as\nGELU, SELU, and SiLU offer smooth gradients and improved convergence\nproperties, making them popular choices in state-of-the-art models. Despite\nthis trend, the classical ReLU remains appealing due to its simplicity,\ninherent sparsity, and other advantageous topological characteristics. However,\nReLU units are prone to becoming irreversibly inactive - a phenomenon known as\nthe dying ReLU problem - which limits their overall effectiveness. In this\nwork, we introduce surrogate gradient learning for ReLU (SUGAR) as a novel,\nplug-and-play regularizer for deep architectures. SUGAR preserves the standard\nReLU function during the forward pass but replaces its derivative in the\nbackward pass with a smooth surrogate that avoids zeroing out gradients. We\ndemonstrate that SUGAR, when paired with a well-chosen surrogate function,\nsubstantially enhances generalization performance over convolutional network\narchitectures such as VGG-16 and ResNet-18, providing sparser activations while\neffectively resurrecting dead ReLUs. Moreover, we show that even in modern\narchitectures like Conv2NeXt and Swin Transformer - which typically employ GELU\n- substituting these with SUGAR yields competitive and even slightly superior\nperformance. These findings challenge the prevailing notion that advanced\nactivation functions are necessary for optimal performance. Instead, they\nsuggest that the conventional ReLU, particularly with appropriate gradient\nhandling, can serve as a strong, versatile revived classic across a broad range\nof deep learning vision models.','Coşku Can Horuz, Geoffrey Kasenbacher, Saya Higuchi, Sebastian Kairat, Jendrik Stoltz, Moritz Pesl, Bernhard A. Moser, Christoph Linse, Thomas Martinetz, Sebastian Otte','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22074v1'),('2505.22076v1','ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation','Training large language models (LLMs) to follow instructions has\nsignificantly enhanced their ability to tackle unseen tasks. However, despite\ntheir strong generalization capabilities, instruction-following LLMs encounter\ndifficulties when dealing with tasks that require domain knowledge. This work\nintroduces a specialized instruction fine-tuning for the domain of\ncomputational argumentation (CA). The goal is to enable an LLM to effectively\ntackle any unseen CA tasks while preserving its generalization capabilities.\nReviewing existing CA research, we crafted natural language instructions for\n105 CA tasks to this end. On this basis, we developed a CA-specific benchmark\nfor LLMs that allows for a comprehensive evaluation of LLMs\\\' capabilities in\nsolving various CA tasks. We synthesized 52k CA-related instructions, adapting\nthe self-instruct process to train a CA-specialized instruction-following LLM.\nOur experiments suggest that CA-specialized instruction fine-tuning\nsignificantly enhances the LLM on both seen and unseen CA tasks. At the same\ntime, performance on the general NLP tasks of the SuperNI benchmark remains\nstable.','Maja Stahl, Timon Ziegenbein, Joonsuk Park, Henning Wachsmuth','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22076v1'),('2505.22081v1','Can Test-time Computation Mitigate Memorization Bias in Neural Symbolic Regression?','Symbolic regression aims to discover mathematical equations that fit given\nnumerical data. It has been applied in various fields of scientific research,\nsuch as producing human-readable expressions that explain physical phenomena.\nRecently, Neural symbolic regression (NSR) methods that involve Transformers\npre-trained on large-scale synthetic datasets have gained attention. While\nthese methods offer advantages such as short inference time, they suffer from\nlow performance, particularly when the number of input variables is large. In\nthis study, we hypothesized that this limitation stems from the memorization\nbias of Transformers in symbolic regression. We conducted a quantitative\nevaluation of this bias in Transformers using a synthetic dataset and found\nthat Transformers rarely generate expressions not present in the training data.\nAdditional theoretical analysis reveals that this bias arises from the\nTransformer\\\'s inability to construct expressions compositionally while\nverifying their numerical validity. We finally examined if tailoring test-time\nstrategies can lead to reduced memorization bias and better performance. We\nempirically demonstrate that providing additional information to the model at\ntest time can significantly mitigate memorization bias. On the other hand, we\nalso find that reducing memorization bias does not necessarily correlate with\nimproved performance. These findings contribute to a deeper understanding of\nthe limitations of NSR approaches and offer a foundation for designing more\nrobust, generalizable symbolic regression methods. Code is available at\nhttps://github.com/Shun-0922/Mem-Bias-NSR .','Shun Sato, Issei Sato','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22081v1'),('2505.22083v1','Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz','In this work, we introduce the first type of non-Euclidean neural quantum\nstate (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent\nneural networks (RNNs)), to be used in the Variational Monte Carlo method of\napproximating the ground state wavefunction for quantum many-body systems. In\nparticular, we examine the performances of NQS ansatzes constructed from both\nconventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical\nsettings of the one- and two-dimensional transverse field Ising models (TFIM)\nof up to 100 spins and the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$\nsystems of up 50 spins. By virtue of the fact that, for all of the experiments\nperformed in this work, hyperbolic GRU can yield performances comparable to or\nbetter than Euclidean RNNs, which have been extensively studied in these\nsettings in the literature, our work is a proof-of-concept for the viability of\nhyperbolic GRU as the first type of non-Euclidean NQS ansatz for quantum\nmany-body systems. Furthermore, in settings where the Hamiltonian displays a\nclear hierarchical interaction structure, such as the 1D Heisenberg $J_1J_2$ &\n$J_1J_2J_3$ systems with the 1st, 2nd and even 3rd nearest neighbor\ninteractions, our results show that hyperbolic GRU definitively outperforms its\nEuclidean version in all instances. The fact that these results are reminiscent\nof the established ones from natural language processing where hyperbolic GRU\nalmost always outperforms Euclidean RNNs when the training data exhibit a\ntree-like or hierarchical structure leads us to hypothesize that hyperbolic GRU\nNQS ansatz would likely outperform Euclidean RNN/GRU NQS ansatz in quantum spin\nsystems that involve different degrees of nearest neighbor interactions.\nFinally, with this work, we hope to initiate future studies of other types of\nnon-Euclidean NQS beyond hyperbolic GRU.','H. L. Dao','2025-05-28','quant-ph','http://arxiv.org/pdf/2505.22083v1'),('2505.22085v1','PADAM: Parallel averaged Adam reduces the error for stochastic optimization in scientific machine learning','Averaging techniques such as Ruppert--Polyak averaging and exponential\nmovering averaging (EMA) are powerful approaches to accelerate optimization\nprocedures of stochastic gradient descent (SGD) optimization methods such as\nthe popular ADAM optimizer. However, depending on the specific optimization\nproblem under consideration, the type and the parameters for the averaging need\nto be adjusted to achieve the smallest optimization error. In this work we\npropose an averaging approach, which we refer to as parallel averaged ADAM\n(PADAM), in which we compute parallely different averaged variants of ADAM and\nduring the training process dynamically select the variant with the smallest\noptimization error. A central feature of this approach is that this procedure\nrequires no more gradient evaluations than the usual ADAM optimizer as each of\nthe averaged trajectories relies on the same underlying ADAM trajectory and\nthus on the same underlying gradients. We test the proposed PADAM optimizer in\n13 stochastic optimization and deep neural network (DNN) learning problems and\ncompare its performance with known optimizers from the literature such as\nstandard SGD, momentum SGD, Adam with and without EMA, and ADAMW. In\nparticular, we apply the compared optimizers to physics-informed neural\nnetwork, deep Galerkin, deep backward stochastic differential equation and deep\nKolmogorov approximations for boundary value partial differential equation\nproblems from scientific machine learning, as well as to DNN approximations for\noptimal control and optimal stopping problems. In nearly all of the considered\nexamples PADAM achieves, sometimes among others and sometimes exclusively,\nessentially the smallest optimization error. This work thus strongly suggest to\nconsider PADAM for scientific machine learning problems and also motivates\nfurther research for adaptive averaging procedures within the training of DNNs.','Arnulf Jentzen, Julian Kranz, Adrian Riekert','2025-05-28','math.OC','http://arxiv.org/pdf/2505.22085v1'),('2505.22086v1','iDSE: Navigating Design Space Exploration in High-Level Synthesis Using LLMs','High-Level Synthesis (HLS) serves as an agile hardware development tool that\nstreamlines the circuit design by abstracting the register transfer level into\nbehavioral descriptions, while allowing designers to customize the generated\nmicroarchitectures through optimization directives. However, the combinatorial\nexplosion of possible directive configurations yields an intractable design\nspace. Traditional design space exploration (DSE) methods, despite adopting\nheuristics or constructing predictive models to accelerate Pareto-optimal\ndesign acquisition, still suffer from prohibitive exploration costs and\nsuboptimal results. Addressing these concerns, we introduce iDSE, the first\nLLM-aided DSE framework that leverages HLS design quality perception to\neffectively navigate the design space. iDSE intelligently pruns the design\nspace to guide LLMs in calibrating representative initial sampling designs,\nexpediting convergence toward the Pareto front. By exploiting the convergent\nand divergent thinking patterns inherent in LLMs for hardware optimization,\niDSE achieves multi-path refinement of the design quality and diversity.\nExtensive experiments demonstrate that iDSE outperforms heuristic-based DSE\nmethods by 5.1$\\times$$\\sim$16.6$\\times$ in proximity to the reference Pareto\nfront, matching NSGA-II with only 4.6% of the explored designs. Our work\ndemonstrates the transformative potential of LLMs in scalable and efficient HLS\ndesign optimization, offering new insights into multiobjective optimization\nchallenges.','Runkai Li, Jia Xiong, Xi Wang','2025-05-28','cs.AR','http://arxiv.org/pdf/2505.22086v1'),('2505.22087v1','Cognitively-Inspired Emergent Communication via Knowledge Graphs for Assisting the Visually Impaired','Assistive systems for visually impaired individuals must deliver rapid,\ninterpretable, and adaptive feedback to facilitate real-time navigation.\nCurrent approaches face a trade-off between latency and semantic richness:\nnatural language-based systems provide detailed guidance but are too slow for\ndynamic scenarios, while emergent communication frameworks offer low-latency\nsymbolic languages but lack semantic depth, limiting their utility in tactile\nmodalities like vibration. To address these limitations, we introduce a novel\nframework, Cognitively-Inspired Emergent Communication via Knowledge Graphs\n(VAG-EC), which emulates human visual perception and cognitive mapping. Our\nmethod constructs knowledge graphs to represent objects and their\nrelationships, incorporating attention mechanisms to prioritize task-relevant\nentities, thereby mirroring human selective attention. This structured approach\nenables the emergence of compact, interpretable, and context-sensitive symbolic\nlanguages. Extensive experiments across varying vocabulary sizes and message\nlengths demonstrate that VAG-EC outperforms traditional emergent communication\nmethods in Topographic Similarity (TopSim) and Context Independence (CI). These\nfindings underscore the potential of cognitively grounded emergent\ncommunication as a fast, adaptive, and human-aligned solution for real-time\nassistive technologies. Code is available at\nhttps://github.com/Anonymous-NLPcode/Anonymous_submission/tree/main.','Ruxiao Chen, Dezheng Han, Wenjie Han, Shuaishuai Guo','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22087v1'),('2505.22088v1','Visual Cues Support Robust Turn-taking Prediction in Noise','Accurate predictive turn-taking models (PTTMs) are essential for naturalistic\nhuman-robot interaction. However, little is known about their performance in\nnoise. This study therefore explores PTTM performance in types of noise likely\nto be encountered once deployed. Our analyses reveal PTTMs are highly sensitive\nto noise. Hold/shift accuracy drops from 84% in clean speech to just 52% in 10\ndB music noise. Training with noisy data enables a multimodal PTTM, which\nincludes visual features to better exploit visual cues, with 72% accuracy in 10\ndB music noise. The multimodal PTTM outperforms the audio-only PTTM across all\nnoise types and SNRs, highlighting its ability to exploit visual cues; however,\nthis does not always generalise to new types of noise. Analysis also reveals\nthat successful training relies on accurate transcription, limiting the use of\nASR-derived transcriptions to clean conditions. We make code publicly available\nfor future research.','Sam O\'Connor Russell, Naomi Harte','2025-05-28','cs.SD','http://arxiv.org/pdf/2505.22088v1'),('2505.22090v1','High Volume Rate 3D Ultrasound Reconstruction with Diffusion Models','Three-dimensional ultrasound enables real-time volumetric visualization of\nanatomical structures. Unlike traditional 2D ultrasound, 3D imaging reduces the\nreliance on precise probe orientation, potentially making ultrasound more\naccessible to clinicians with varying levels of experience and improving\nautomated measurements and post-exam analysis. However, achieving both high\nvolume rates and high image quality remains a significant challenge. While 3D\ndiverging waves can provide high volume rates, they suffer from limited tissue\nharmonic generation and increased multipath effects, which degrade image\nquality. One compromise is to retain the focusing in elevation while leveraging\nunfocused diverging waves in the lateral direction to reduce the number of\ntransmissions per elevation plane. Reaching the volume rates achieved by full\n3D diverging waves, however, requires dramatically undersampling the number of\nelevation planes. Subsequently, to render the full volume, simple interpolation\ntechniques are applied. This paper introduces a novel approach to 3D ultrasound\nreconstruction from a reduced set of elevation planes by employing diffusion\nmodels (DMs) to achieve increased spatial and temporal resolution. We compare\nboth traditional and supervised deep learning-based interpolation methods on a\n3D cardiac ultrasound dataset. Our results show that DM-based reconstruction\nconsistently outperforms the baselines in image quality and downstream task\nperformance. Additionally, we accelerate inference by leveraging the temporal\nconsistency inherent to ultrasound sequences. Finally, we explore the\nrobustness of the proposed method by exploiting the probabilistic nature of\ndiffusion posterior sampling to quantify reconstruction uncertainty and\ndemonstrate improved recall on out-of-distribution data with synthetic\nanomalies under strong subsampling.','Tristan S. W. Stevens, Oisín Nolan, Oudom Somphone, Jean-Luc Robert, Ruud J. G. van Sloun','2025-05-28','eess.IV','http://arxiv.org/pdf/2505.22090v1'),('2505.22092v1','VIRAL: Vision-grounded Integration for Reward design And Learning','The alignment between humans and machines is a critical challenge in\nartificial intelligence today. Reinforcement learning, which aims to maximize a\nreward function, is particularly vulnerable to the risks associated with poorly\ndesigned reward functions. Recent advancements has shown that Large Language\nModels (LLMs) for reward generation can outperform human performance in this\ncontext. We introduce VIRAL, a pipeline for generating and refining reward\nfunctions through the use of multi-modal LLMs. VIRAL autonomously creates and\ninteractively improves reward functions based on a given environment and a goal\nprompt or annotated image. The refinement process can incorporate human\nfeedback or be guided by a description generated by a video LLM, which explains\nthe agent\\\'s policy in video form. We evaluated VIRAL in five Gymnasium\nenvironments, demonstrating that it accelerates the learning of new behaviors\nwhile ensuring improved alignment with user intent. The source-code and demo\nvideo are available at: https://github.com/VIRAL-UCBL1/VIRAL and\nhttps://youtu.be/t4_BXugBm9Q.','Valentin Cuzin-Rambaud, Emilien Komlenovic, Alexandre Faure, Bruno Yun','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22092v1'),('2505.22093v1','From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots','The rapid adoption of AI powered coding assistants like ChatGPT and other\ncoding copilots is transforming programming education, raising questions about\nassessment practices, academic integrity, and skill development. As educators\nseek alternatives to traditional grading methods susceptible to AI enabled\nplagiarism, structured peer assessment could be a promising strategy. This\npaper presents an empirical study of a rubric based, anonymized peer review\nprocess implemented in a large introductory programming course.\n  Students evaluated each other\\\'s final projects (2D game), and their\nassessments were compared to instructor grades using correlation, mean absolute\nerror, and root mean square error (RMSE). Additionally, reflective surveys from\n47 teams captured student perceptions of fairness, grading behavior, and\npreferences regarding grade aggregation. Results show that peer review can\napproximate instructor evaluation with moderate accuracy and foster student\nengagement, evaluative thinking, and interest in providing good feedback to\ntheir peers. We discuss these findings for designing scalable, trustworthy peer\nassessment systems to face the age of AI assisted coding.','Santiago Berrezueta-Guzman, Stephan Krusche, Stefan Wagner','2025-05-28','cs.CY','http://arxiv.org/pdf/2505.22093v1'),('2505.22094v1','ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning','We propose ReinFlow, a simple yet effective online reinforcement learning\n(RL) framework that fine-tunes a family of flow matching policies for\ncontinuous robotic control. Derived from rigorous RL theory, ReinFlow injects\nlearnable noise into a flow policy\\\'s deterministic path, converting the flow\ninto a discrete-time Markov Process for exact and straightforward likelihood\ncomputation. This conversion facilitates exploration and ensures training\nstability, enabling ReinFlow to fine-tune diverse flow model variants,\nincluding Rectified Flow [35] and Shortcut Models [19], particularly at very\nfew or even one denoising step. We benchmark ReinFlow in representative\nlocomotion and manipulation tasks, including long-horizon planning with visual\ninput and sparse reward. The episode reward of Rectified Flow policies obtained\nan average net growth of 135.36% after fine-tuning in challenging legged\nlocomotion tasks while saving denoising steps and 82.63% of wall time compared\nto state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate\nof the Shortcut Model policies in state and visual manipulation tasks achieved\nan average net increase of 40.34% after fine-tuning with ReinFlow at four or\neven one denoising step, whose performance is comparable to fine-tuned DDIM\npolicies while saving computation time for an average of 23.20%. Project\nWebpage: https://reinflow.github.io/','Tonghe Zhang, Yu Chao, Sicang Su, Yu Wang','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.22094v1'),('2505.22095v1','Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning','Multimodal Retrieval-Augmented Generation (MRAG) has shown promise in\nmitigating hallucinations in Multimodal Large Language Models (MLLMs) by\nincorporating external knowledge during generation. Existing MRAG methods\ntypically adopt a static retrieval pipeline that fetches relevant information\nfrom multiple Knowledge Bases (KBs), followed by a refinement step. However,\nthese approaches overlook the reasoning and planning capabilities of MLLMs to\ndynamically determine how to interact with different KBs during the reasoning\nprocess. To address this limitation, we propose R1-Router, a novel MRAG\nframework that learns to decide when and where to retrieve knowledge based on\nthe evolving reasoning state. Specifically, R1-Router can generate follow-up\nqueries according to the current reasoning step, routing these intermediate\nqueries to the most suitable KB, and integrating external knowledge into a\ncoherent reasoning trajectory to answer the original query. Furthermore, we\nintroduce Step-wise Group Relative Policy Optimization (Step-GRPO), a tailored\nreinforcement learning algorithm that assigns step-specific rewards to optimize\nthe reasoning behavior of MLLMs. Experimental results on various open-domain QA\nbenchmarks across multiple modalities demonstrate that R1-Router outperforms\nbaseline models by over 7%. Further analysis shows that R1-Router can\nadaptively and effectively leverage diverse KBs, reducing unnecessary\nretrievals and improving both efficiency and accuracy.','Chunyi Peng, Zhipeng Xu, Zhenghao Liu, Yishan Li, Yukun Yan, Shuo Wang, Zhiyuan Liu, Yu Gu, Minghe Yu, Ge Yu, Maosong Sun','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22095v1'),('2505.22096v1','Knowledge Base Construction for Knowledge-Augmented Text-to-SQL','Text-to-SQL aims to translate natural language queries into SQL statements,\nwhich is practical as it enables anyone to easily retrieve the desired\ninformation from databases. Recently, many existing approaches tackle this\nproblem with Large Language Models (LLMs), leveraging their strong capability\nin understanding user queries and generating corresponding SQL code. Yet, the\nparametric knowledge in LLMs might be limited to covering all the diverse and\ndomain-specific queries that require grounding in various database schemas,\nwhich makes generated SQLs less accurate oftentimes. To tackle this, we propose\nconstructing the knowledge base for text-to-SQL, a foundational source of\nknowledge, from which we retrieve and generate the necessary knowledge for\ngiven queries. In particular, unlike existing approaches that either manually\nannotate knowledge or generate only a few pieces of knowledge for each query,\nour knowledge base is comprehensive, which is constructed based on a\ncombination of all the available questions and their associated database\nschemas along with their relevant knowledge, and can be reused for unseen\ndatabases from different datasets and domains. We validate our approach on\nmultiple text-to-SQL datasets, considering both the overlapping and\nnon-overlapping database scenarios, where it outperforms relevant baselines\nsubstantially.','Jinheon Baek, Horst Samulowitz, Oktie Hassanzadeh, Dharmashankar Subramanian, Sola Shirai, Alfio Gliozzo, Debarun Bhattacharjya','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22096v1'),('2505.22099v1','On the Transferability and Discriminability of Repersentation Learning in Unsupervised Domain Adaptation','In this paper, we addressed the limitation of relying solely on distribution\nalignment and source-domain empirical risk minimization in Unsupervised Domain\nAdaptation (UDA). Our information-theoretic analysis showed that this standard\nadversarial-based framework neglects the discriminability of target-domain\nfeatures, leading to suboptimal performance. To bridge this\ntheoretical-practical gap, we defined \"good representation learning\" as\nguaranteeing both transferability and discriminability, and proved that an\nadditional loss term targeting target-domain discriminability is necessary.\nBuilding on these insights, we proposed a novel adversarial-based UDA framework\nthat explicitly integrates a domain alignment objective with a\ndiscriminability-enhancing constraint. Instantiated as Domain-Invariant\nRepresentation Learning with Global and Local Consistency (RLGLC), our method\nleverages Asymmetrically-Relaxed Wasserstein of Wasserstein Distance (AR-WWD)\nto address class imbalance and semantic dimension weighting, and employs a\nlocal consistency mechanism to preserve fine-grained target-domain\ndiscriminative information. Extensive experiments across multiple benchmark\ndatasets demonstrate that RLGLC consistently surpasses state-of-the-art\nmethods, confirming the value of our theoretical perspective and underscoring\nthe necessity of enforcing both transferability and discriminability in\nadversarial-based UDA.','Wenwen Qiang, Ziyin Gu, Lingyu Si, Jiangmeng Li, Changwen Zheng, Fuchun Sun, Hui Xiong','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22099v1'),('2505.22101v1','MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models','Large Language Models (LLMs) have emerged as foundational infrastructure in\nthe pursuit of Artificial General Intelligence (AGI). Despite their remarkable\ncapabilities in language perception and generation, current LLMs fundamentally\nlack a unified and structured architecture for handling memory. They primarily\nrely on parametric memory (knowledge encoded in model weights) and ephemeral\nactivation memory (context-limited runtime states). While emerging methods like\nRetrieval-Augmented Generation (RAG) incorporate plaintext memory, they lack\nlifecycle management and multi-modal integration, limiting their capacity for\nlong-term knowledge evolution. To address this, we introduce MemOS, a memory\noperating system designed for LLMs that, for the first time, elevates memory to\na first-class operational resource. It builds unified mechanisms for\nrepresentation, organization, and governance across three core memory types:\nparametric, activation, and plaintext. At its core is the MemCube, a\nstandardized memory abstraction that enables tracking, fusion, and migration of\nheterogeneous memory, while offering structured, traceable access across tasks\nand contexts. MemOS establishes a memory-centric execution framework with\nstrong controllability, adaptability, and evolvability. It fills a critical gap\nin current LLM infrastructure and lays the groundwork for continual adaptation,\npersonalized intelligence, and cross-platform coordination in next-generation\nintelligent systems.','Zhiyu Li, Shichao Song, Hanyu Wang, Simin Niu, Ding Chen, Jiawei Yang, Chenyang Xi, Huayi Lai, Jihao Zhao, Yezhaohui Wang, Junpeng Ren, Zehao Lin, Jiahao Huo, Tianyi Chen, Kai Chen, Kehang Li, Zhiqiang Yin, Qingchen Yu, Bo Tang, Hongkang Yang, Zhi-Qin John Xu, Feiyu Xiong','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22101v1'),('2505.22104v1','Efficient Dynamic Shielding for Parametric Safety Specifications','Shielding has emerged as a promising approach for ensuring safety of\nAI-controlled autonomous systems. The algorithmic goal is to compute a shield,\nwhich is a runtime safety enforcement tool that needs to monitor and intervene\nthe AI controller\\\'s actions if safety could be compromised otherwise.\nTraditional shields are designed statically for a specific safety requirement.\nTherefore, if the safety requirement changes at runtime due to changing\noperating conditions, the shield needs to be recomputed from scratch, causing\ndelays that could be fatal. We introduce dynamic shields for parametric safety\nspecifications, which are succinctly represented sets of all possible safety\nspecifications that may be encountered at runtime. Our dynamic shields are\nstatically designed for a given safety parameter set, and are able to\ndynamically adapt as the true safety specification (permissible by the\nparameters) is revealed at runtime. The main algorithmic novelty lies in the\ndynamic adaptation procedure, which is a simple and fast algorithm that\nutilizes known features of standard safety shields, like maximal\npermissiveness. We report experimental results for a robot navigation problem\nin unknown territories, where the safety specification evolves as new obstacles\nare discovered at runtime. In our experiments, the dynamic shields took a few\nminutes for their offline design, and took between a fraction of a second and a\nfew seconds for online adaptation at each step, whereas the brute-force online\nrecomputation approach was up to 5 times slower.','Davide Corsi, Kaushik Mallik, Andoni Rodriguez, Cesar Sanchez','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22104v1'),('2505.22106v1','AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion','Diffusion models have significantly improved the quality and diversity of\naudio generation but are hindered by slow inference speed. Rectified flow\nenhances inference speed by learning straight-line ordinary differential\nequation (ODE) paths. However, this approach requires training a flow-matching\nmodel from scratch and tends to perform suboptimally, or even poorly, at low\nstep counts. To address the limitations of rectified flow while leveraging the\nadvantages of advanced pre-trained diffusion models, this study integrates\npre-trained models with the rectified diffusion method to improve the\nefficiency of text-to-audio (TTA) generation. Specifically, we propose\nAudioTurbo, which learns first-order ODE paths from deterministic noise sample\npairs generated by a pre-trained TTA model. Experiments on the AudioCaps\ndataset demonstrate that our model, with only 10 sampling steps, outperforms\nprior models and reduces inference to 3 steps compared to a flow-matching-based\nacceleration model.','Junqi Zhao, Jinzheng Zhao, Haohe Liu, Yun Chen, Lu Han, Xubo Liu, Mark Plumbley, Wenwu Wang','2025-05-28','cs.SD','http://arxiv.org/pdf/2505.22106v1'),('2505.22107v1','Curse of High Dimensionality Issue in Transformer for Long-context Modeling','Transformer-based large language models (LLMs) excel in natural language\nprocessing tasks by capturing long-range dependencies through self-attention\nmechanisms. However, long-context modeling faces significant computational\ninefficiencies due to \\textit{redundant} attention computations: while\nattention weights are often \\textit{sparse}, all tokens consume \\textit{equal}\ncomputational resources. In this paper, we reformulate traditional\nprobabilistic sequence modeling as a \\textit{supervised learning task},\nenabling the separation of relevant and irrelevant tokens and providing a\nclearer understanding of redundancy. Based on this reformulation, we\ntheoretically analyze attention sparsity, revealing that only a few tokens\nsignificantly contribute to predictions. Building on this, we formulate\nattention optimization as a linear coding problem and propose a \\textit{group\ncoding strategy}, theoretically showing its ability to improve robustness\nagainst random noise and enhance learning efficiency. Motivated by this, we\npropose \\textit{Dynamic Group Attention} (DGA), which leverages the group\ncoding to explicitly reduce redundancy by aggregating less important tokens\nduring attention computation. Empirical results show that our DGA significantly\nreduces computational costs while maintaining competitive performance.Code is\navailable at https://github.com/bolixinyu/DynamicGroupAttention.','Shuhai Zhang, Zeng You, Yaofo Chen, Zhiquan Wen, Qianyue Wang, Zhijie Qiu, Yuanqing Li, Mingkui Tan','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22107v1'),('2505.22108v1','Inclusive, Differentially Private Federated Learning for Clinical Data','Federated Learning (FL) offers a promising approach for training clinical AI\nmodels without centralizing sensitive patient data. However, its real-world\nadoption is hindered by challenges related to privacy, resource constraints,\nand compliance. Existing Differential Privacy (DP) approaches often apply\nuniform noise, which disproportionately degrades model performance, even among\nwell-compliant institutions. In this work, we propose a novel compliance-aware\nFL framework that enhances DP by adaptively adjusting noise based on\nquantifiable client compliance scores. Additionally, we introduce a compliance\nscoring tool based on key healthcare and security standards to promote secure,\ninclusive, and equitable participation across diverse clinical settings.\nExtensive experiments on public datasets demonstrate that integrating\nunder-resourced, less compliant clinics with highly regulated institutions\nyields accuracy improvements of up to 15% over traditional FL. This work\nadvances FL by balancing privacy, compliance, and performance, making it a\nviable solution for real-world clinical workflows in global healthcare.','Santhosh Parampottupadam, Melih Coşğun, Sarthak Pati, Maximilian Zenk, Saikat Roy, Dimitrios Bounias, Benjamin Hamm, Sinem Sav, Ralf Floca, Klaus Maier-Hein','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22108v1'),('2505.22109v1','The quest for the GRAph Level autoEncoder (GRALE)','Although graph-based learning has attracted a lot of attention, graph\nrepresentation learning is still a challenging task whose resolution may impact\nkey application fields such as chemistry or biology. To this end, we introduce\nGRALE, a novel graph autoencoder that encodes and decodes graphs of varying\nsizes into a shared embedding space. GRALE is trained using an Optimal\nTransport-inspired loss that compares the original and reconstructed graphs and\nleverages a differentiable node matching module, which is trained jointly with\nthe encoder and decoder. The proposed attention-based architecture relies on\nEvoformer, the core component of AlphaFold, which we extend to support both\ngraph encoding and decoding. We show, in numerical experiments on simulated and\nmolecular data, that GRALE enables a highly general form of pre-training,\napplicable to a wide range of downstream tasks, from classification and\nregression to more complex tasks such as graph interpolation, editing,\nmatching, and prediction.','Paul Krzakala, Gabriel Melo, Charlotte Laclau, Florence d\'Alché-Buc, Rémi Flamary','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22109v1'),('2505.22112v1','Visual Large Language Models Exhibit Human-Level Cognitive Flexibility in the Wisconsin Card Sorting Test','Cognitive flexibility has been extensively studied in human cognition but\nremains relatively unexplored in the context of Visual Large Language Models\n(VLLMs). This study assesses the cognitive flexibility of state-of-the-art\nVLLMs (GPT-4o, Gemini-1.5 Pro, and Claude-3.5 Sonnet) using the Wisconsin Card\nSorting Test (WCST), a classic measure of set-shifting ability. Our results\nreveal that VLLMs achieve or surpass human-level set-shifting capabilities\nunder chain-of-thought prompting with text-based inputs. However, their\nabilities are highly influenced by both input modality and prompting strategy.\nIn addition, we find that through role-playing, VLLMs can simulate various\nfunctional deficits aligned with patients having impairments in cognitive\nflexibility, suggesting that VLLMs may possess a cognitive architecture, at\nleast regarding the ability of set-shifting, similar to the brain. This study\nreveals the fact that VLLMs have already approached the human level on a key\ncomponent underlying our higher cognition, and highlights the potential to use\nthem to emulate complex brain processes.','Guangfu Hao, Frederic Alexandre, Shan Yu','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22112v1'),('2505.22113v1','THINK-Bench: Evaluating Thinking Efficiency and Chain-of-Thought Quality of Large Reasoning Models','Large reasoning models (LRMs) have achieved impressive performance in complex\ntasks, often outperforming conventional large language models (LLMs). However,\nthe prevalent issue of overthinking severely limits their computational\nefficiency. Overthinking occurs when models generate excessive and redundant\ntokens that contribute little to accurate outcomes, especially in simple tasks,\nresulting in a significant waste of computational resources. To systematically\ninvestigate this issue, we introduce Think-Bench, a benchmark designed to\nevaluate the reasoning efficiency of LRMs. We also propose novel efficiency\nmetrics and conduct a comprehensive evaluation of various LRMs across multiple\ndimensions, including the reasoning process, outcome quality, and\nchain-of-thought (CoT) characteristics. Our analysis reveals that most LRMs\nexhibit overthinking in handling easy questions, generating unnecessarily\nlengthy reasoning chains. While many LRMs demonstrate high CoT quality, several\nsuffer from low efficiency. We hope that Think-Bench can serve as a robust\nfoundation for advancing research into LRMs.','Zhiyuan Li, Yi Chang, Yuan Wu','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22113v1'),('2505.22114v1','BiMi Sheets: Infosheets for bias mitigation methods','Over the past 15 years, hundreds of bias mitigation methods have been\nproposed in the pursuit of fairness in machine learning (ML). However,\nalgorithmic biases are domain-, task-, and model-specific, leading to a\n`portability trap\\\': bias mitigation solutions in one context may not be\nappropriate in another. Thus, a myriad of design choices have to be made when\ncreating a bias mitigation method, such as the formalization of fairness it\npursues, and where and how it intervenes in the ML pipeline. This creates\nchallenges in benchmarking and comparing the relative merits of different bias\nmitigation methods, and limits their uptake by practitioners.\n  We propose BiMi Sheets as a portable, uniform guide to document the design\nchoices of any bias mitigation method. This enables researchers and\npractitioners to quickly learn its main characteristics and to compare with\ntheir desiderata. Furthermore, the sheets\\\' structure allow for the creation of\na structured database of bias mitigation methods. In order to foster the\nsheets\\\' adoption, we provide a platform for finding and creating BiMi Sheets at\nbimisheet.com.','MaryBeth Defrance, Guillaume Bied, Maarten Buyl, Jefrey Lijffijt, Tijl De Bie','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22114v1'),('2505.22116v1','Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model','Intraoperative hypotension (IOH) frequently occurs under general anesthesia\nand is strongly linked to adverse outcomes such as myocardial injury and\nincreased mortality. Despite its significance, IOH prediction is hindered by\nevent sparsity and the challenge of integrating static and dynamic data across\ndiverse patients. In this paper, we propose \\textbf{IOHFuseLM}, a multimodal\nlanguage model framework. To accurately identify and differentiate sparse\nhypotensive events, we leverage a two-stage training strategy. The first stage\ninvolves domain adaptive pretraining on IOH physiological time series augmented\nthrough diffusion methods, thereby enhancing the model sensitivity to patterns\nassociated with hypotension. Subsequently, task fine-tuning is performed on the\noriginal clinical dataset to further enhance the ability to distinguish\nnormotensive from hypotensive states. To enable multimodal fusion for each\npatient, we align structured clinical descriptions with the corresponding\nphysiological time series at the token level. Such alignment enables the model\nto capture individualized temporal patterns alongside their corresponding\nclinical semantics. In addition, we convert static patient attributes into\nstructured text to enrich personalized information. Experimental evaluations on\ntwo intraoperative datasets demonstrate that IOHFuseLM outperforms established\nbaselines in accurately identifying IOH events, highlighting its applicability\nin clinical decision support scenarios. Our code is publicly available to\npromote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.','Jintao Zhang, Zirui Liu, Mingyue Cheng, Shilong Zhang, Tingyue Pan, Qi Liu, Yanhu Xie','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22116v1'),('2505.22118v1','Multilingual vs Crosslingual Retrieval of Fact-Checked Claims: A Tale of Two Approaches','Retrieval of previously fact-checked claims is a well-established task, whose\nautomation can assist professional fact-checkers in the initial steps of\ninformation verification. Previous works have mostly tackled the task\nmonolingually, i.e., having both the input and the retrieved claims in the same\nlanguage. However, especially for languages with a limited availability of\nfact-checks and in case of global narratives, such as pandemics, wars, or\ninternational politics, it is crucial to be able to retrieve claims across\nlanguages. In this work, we examine strategies to improve the multilingual and\ncrosslingual performance, namely selection of negative examples (in the\nsupervised) and re-ranking (in the unsupervised setting). We evaluate all\napproaches on a dataset containing posts and claims in 47 languages (283\nlanguage combinations). We observe that the best results are obtained by using\nLLM-based re-ranking, followed by fine-tuning with negative examples sampled\nusing a sentence similarity-based strategy. Most importantly, we show that\ncrosslinguality is a setup with its own unique characteristics compared to the\nmultilingual setup.','Alan Ramponi, Marco Rovera, Robert Moro, Sara Tonelli','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22118v1'),('2505.22120v1','LoKI: Low-damage Knowledge Implanting of Large Language Models','Fine-tuning adapts pretrained models for specific tasks but poses the risk of\ncatastrophic forgetting (CF), where critical knowledge from pre-training is\noverwritten. Current Parameter-Efficient Fine-Tuning (PEFT) methods for Large\nLanguage Models (LLMs), while efficient, often sacrifice general capabilities.\nTo address the issue of CF in a general-purpose PEFT framework, we propose\n\\textbf{Lo}w-damage \\textbf{K}nowledge \\textbf{I}mplanting (\\textbf{LoKI}), a\nPEFT technique that is based on a mechanistic understanding of how knowledge is\nstored in transformer architectures. In two real-world scenarios, LoKI\ndemonstrates task-specific performance that is comparable to or even surpasses\nthat of full fine-tuning and LoRA-based methods across various model types,\nwhile significantly better preserving general capabilities. Our work connects\nmechanistic insights into LLM knowledge storage with practical fine-tuning\nobjectives, achieving state-of-the-art trade-offs between task specialization\nand the preservation of general capabilities. Our implementation is publicly\navailable as ready-to-use code\\footnote{https://github.com/Nexround/LoKI}.','Runyu Wang, Peng Ping, Zhengyu Guo, Xiaoye Zhang, Quan Shi, Liting Zhou, Tianbo Ji','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22120v1'),('2505.22125v1','Sentiment Simulation using Generative AI Agents','Traditional sentiment analysis relies on surface-level linguistic patterns\nand retrospective data, limiting its ability to capture the psychological and\ncontextual drivers of human sentiment. These limitations constrain its\neffectiveness in applications that require predictive insight, such as policy\ntesting, narrative framing, and behavioral forecasting. We present a robust\nframework for sentiment simulation using generative AI agents embedded with\npsychologically rich profiles. Agents are instantiated from a nationally\nrepresentative survey of 2,485 Filipino respondents, combining sociodemographic\ninformation with validated constructs of personality traits, values, beliefs,\nand socio-political attitudes. The framework includes three stages: (1) agent\nembodiment via categorical or contextualized encodings, (2) exposure to\nreal-world political and economic scenarios, and (3) generation of sentiment\nratings accompanied by explanatory rationales. Using Quadratic Weighted\nAccuracy (QWA), we evaluated alignment between agent-generated and human\nresponses. Contextualized encoding achieved 92% alignment in replicating\noriginal survey responses. In sentiment simulation tasks, agents reached\n81%--86% accuracy against ground truth sentiment, with contextualized profile\nencodings significantly outperforming categorical (p < 0.0001, Cohen\\\'s d =\n0.70). Simulation results remained consistent across repeated trials\n(+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676,\nCohen\\\'s d = 0.02). Our findings establish a scalable framework for sentiment\nmodeling through psychographically grounded AI agents. This work signals a\nparadigm shift in sentiment analysis from retrospective classification to\nprospective and dynamic simulation grounded in psychology of sentiment\nformation.','Melrose Tia, Jezreel Sophia Lanuzo, Lei Rigi Baltazar, Marie Joy Lopez-Relente, Diwa Malaya Quiñones, Jason Albia','2025-05-28','cs.MA','http://arxiv.org/pdf/2505.22125v1'),('2505.22126v1','SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model','Recent years have seen rapid advances in AI-driven image generation. Early\ndiffusion models emphasized perceptual quality, while newer multimodal models\nlike GPT-4o-image integrate high-level reasoning, improving semantic\nunderstanding and structural composition. Scientific illustration generation\nexemplifies this evolution: unlike general image synthesis, it demands accurate\ninterpretation of technical content and transformation of abstract ideas into\nclear, standardized visuals. This task is significantly more\nknowledge-intensive and laborious, often requiring hours of manual work and\nspecialized tools. Automating it in a controllable, intelligent manner would\nprovide substantial practical value. Yet, no benchmark currently exists to\nevaluate AI on this front. To fill this gap, we introduce SridBench, the first\nbenchmark for scientific figure generation. It comprises 1,120 instances\ncurated from leading scientific papers across 13 natural and computer science\ndisciplines, collected via human experts and MLLMs. Each sample is evaluated\nalong six dimensions, including semantic fidelity and structural accuracy.\nExperimental results reveal that even top-tier models like GPT-4o-image lag\nbehind human performance, with common issues in text/visual clarity and\nscientific correctness. These findings highlight the need for more advanced\nreasoning-driven visual generation capabilities.','Yifan Chang, Yukang Feng, Jianwen Sun, Jiaxin Ai, Chuanhao Li, S. Kevin Zhou, Kaipeng Zhang','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22126v1'),('2505.22128v1','Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach','This work addresses mechanical defocus in Earth observation images from the\nIMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted\nto space-based edge computing constraints. Leveraging Sentinel-2 data, our\nmethod estimates the defocus kernel and trains a restoration model within a GAN\nframework, effectively operating without reference images.\n  On Sentinel-2 images with synthetic degradation, SSIM improved by 72.47% and\nPSNR by 25.00%, confirming the model\\\'s ability to recover lost details when the\noriginal clean image is known. On IMAGIN-e, where no reference images exist,\nperceptual quality metrics indicate a substantial enhancement, with NIQE\nimproving by 60.66% and BRISQUE by 48.38%, validating real-world onboard\nrestoration. The approach is currently deployed aboard the IMAGIN-e mission,\ndemonstrating its practical application in an operational space environment.\n  By efficiently handling high-resolution images under edge computing\nconstraints, the method enables applications such as water body segmentation\nand contour detection while maintaining processing viability despite resource\nlimitations.','Alejandro D. Mousist','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22128v1'),('2505.22131v1','EULER: Enhancing the Reasoning Ability of Large Language Models through Error-Induced Learning','Large Language Models (LLMs) have demonstrated strong reasoning capabilities\nand achieved promising results in mathematical problem-solving tasks. Learning\nfrom errors offers the potential to further enhance the performance of LLMs\nduring Supervised Fine-Tuning (SFT). However, the errors in synthesized\nsolutions are typically gathered from sampling trails, making it challenging to\ngenerate solution errors for each mathematical problem. This paper introduces\nthe Error-IndUced LEaRning (EULER) model, which aims to develop an error\nexposure model that generates high-quality solution errors to enhance the\nmathematical reasoning capabilities of LLMs. Specifically, EULER optimizes the\nerror exposure model to increase the generation probability of self-made\nsolution errors while utilizing solutions produced by a superior LLM to\nregularize the generation quality. Our experiments across various mathematical\nproblem datasets demonstrate the effectiveness of the EULER model, achieving an\nimprovement of over 4% compared to all baseline models. Further analysis\nreveals that EULER is capable of synthesizing more challenging and educational\nsolution errors, which facilitate both the training and inference processes of\nLLMs. All codes are available at https://github.com/NEUIR/EULER.','Zhuoyang Wu, Xinze Li, Zhenghao Liu, Yukun Yan, Zhiyuan Liu, Minghe Yu, Cheng Yang, Yu Gu, Ge Yu, Maosong Sun','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22131v1'),('2505.22135v1','RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding','Hybrid models combining Transformers and State Space Models (SSMs) are\npromising for balancing performance and efficiency. However, optimizing these\nhybrid models, particularly by addressing the potential redundancy inherent\nwithin the Transformer components, remains a significant challenge. In this\npaper, we propose RAD (Redundancy-Aware Distillation), a novel framework that\nuses self-speculative decoding as a diagnostic tool to identify redundant\nattention layers within the model. These identified layers are then selectively\nreplaced with SSM components, followed by targeted (self-)distillation.\nSpecifically, RAD focuses knowledge transfer on the components identified as\nredundant, considering architectural changes and specific weight initialization\nstrategies. We experimentally demonstrate that self-distillation using RAD\nsignificantly surpasses the performance of the original base model on\nmathematical and coding tasks. Furthermore, RAD is also effective in standard\nknowledge distillation settings, achieving up to approximately 2x faster\nconvergence compared to baseline methods. Notably, while a baseline model\ndistilled from a Llama-3.1 70B teacher achieves scores of 46.17 on GSM8K and\n22.75 on CRUX, RAD achieves significantly higher scores of 71.27 on GSM8K and\n28.25 on CRUX, even when using a much smaller Llama-3.1 8B teacher. RAD offers\na new pathway for efficient optimization and performance enhancement in the\ndistillation of hybrid models.','Yuichiro Hoshino, Hideyuki Tachibana, Muneyoshi Inahara, Hiroto Takegawa','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22135v1'),('2505.22137v1','Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments','Identifying arguments is a necessary prerequisite for various tasks in\nautomated discourse analysis, particularly within contexts such as political\ndebates, online discussions, and scientific reasoning. In addition to\ntheoretical advances in understanding the constitution of arguments, a\nsignificant body of research has emerged around practical argument mining,\nsupported by a growing number of publicly available datasets. On these\nbenchmarks, BERT-like transformers have consistently performed best,\nreinforcing the belief that such models are broadly applicable across diverse\ncontexts of debate. This study offers the first large-scale re-evaluation of\nsuch state-of-the-art models, with a specific focus on their ability to\ngeneralize in identifying arguments. We evaluate four transformers, three\nstandard and one enhanced with contrastive pre-training for better\ngeneralization, on 17 English sentence-level datasets as most relevant to the\ntask. Our findings show that, to varying degrees, these models tend to rely on\nlexical shortcuts tied to content words, suggesting that apparent progress may\noften be driven by dataset-specific cues rather than true task alignment. While\nthe models achieve strong results on familiar benchmarks, their performance\ndrops markedly when applied to unseen datasets. Nonetheless, incorporating both\ntask-specific pre-training and joint benchmark training proves effective in\nenhancing both robustness and generalization.','Marc Feger, Katarina Boland, Stefan Dietze','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22137v1'),('2505.22141v1','FaceEditTalker: Interactive Talking Head Generation with Facial Attribute Editing','Recent advances in audio-driven talking head generation have achieved\nimpressive results in lip synchronization and emotional expression. However,\nthey largely overlook the crucial task of facial attribute editing. This\ncapability is crucial for achieving deep personalization and expanding the\nrange of practical applications, including user-tailored digital avatars,\nengaging online education content, and brand-specific digital customer service.\nIn these key domains, the flexible adjustment of visual attributes-such as\nhairstyle, accessories, and subtle facial features is essential for aligning\nwith user preferences, reflecting diverse brand identities, and adapting to\nvarying contextual demands. In this paper, we present FaceEditTalker, a unified\nframework that enables controllable facial attribute manipulation while\ngenerating high-quality, audio-synchronized talking head videos. Our method\nconsists of two key components: an image feature space editing module, which\nextracts semantic and detail features and allows flexible control over\nattributes like expression, hairstyle, and accessories; and an audio-driven\nvideo generation module, which fuses these edited features with audio-guided\nfacial landmarks to drive a diffusion-based generator. This design ensures\ntemporal coherence, visual fidelity, and identity preservation across frames.\nExtensive experiments on public datasets demonstrate that our method\noutperforms state-of-the-art approaches in lip-sync accuracy, video quality,\nand attribute controllability. Project page:\nhttps://peterfanfan.github.io/FaceEditTalker/','Guanwen Feng, Zhiyuan Ma, Yunan Li, Junwei Jing, Jiahao Yang, Qiguang Miao','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22141v1'),('2505.22146v1','Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language','Flexible tool selection reflects a complex cognitive ability that\ndistinguishes humans from other species, yet computational models that capture\nthis ability remain underdeveloped. We developed a framework using\nlow-dimensional attribute representations to bridge visual tool perception and\nlinguistic task understanding. We constructed a comprehensive dataset (ToolNet)\ncontaining 115 common tools labeled with 13 carefully designed attributes\nspanning physical, functional, and psychological properties, paired with\nnatural language scenarios describing tool usage. Visual encoders (ResNet or\nViT) extract attributes from tool images while fine-tuned language models\n(GPT-2, LLaMA, DeepSeek) derive required attributes from task descriptions. Our\napproach achieves 74% accuracy in tool selection tasks-significantly\noutperforming direct tool matching (20%) and smaller multimodal models\n(21%-58%), while approaching performance of much larger models like GPT-4o\n(73%) with substantially fewer parameters. Ablation studies revealed that\nmanipulation-related attributes (graspability, hand-relatedness, elongation)\nconsistently prove most critical across modalities. This work provides a\nparameter-efficient, interpretable solution that mimics human-like tool\ncognition, advancing both cognitive science understanding and practical\napplications in tool selection tasks.','Guangfu Hao, Haojie Wen, Liangxuna Guo, Yang Chen, Yanchao Bi, Shan Yu','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22146v1'),('2505.22147v1','Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions','Decision making is a central problem in AI that can be formalized using a\nMarkov Decision Process. A problem is that, with increasing numbers of\n(indistinguishable) objects, the state space grows exponentially. To compute\npolicies, the state space has to be enumerated. Even more possibilities have to\nbe enumerated if the size of the action space depends on the size of the state\nspace, especially if we allow concurrent actions. To tackle the exponential\nblow-up in the action and state space, we present a first-order representation\nto store the spaces in polynomial instead of exponential size in the number of\nobjects and introduce Foreplan, a relational forward planner, which uses this\nrepresentation to efficiently compute policies for numerous indistinguishable\nobjects and actions. Additionally, we introduce an even faster approximate\nversion of Foreplan. Moreover, Foreplan identifies how many objects an agent\nshould act on to achieve a certain task given restrictions. Further, we provide\na theoretical analysis and an empirical evaluation of Foreplan, demonstrating a\nspeedup of at least four orders of magnitude.','Florian Andreas Marwitz, Tanya Braun, Ralf Möller, Marcel Gehrke','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22147v1'),('2505.22148v1','What Makes a Good Reasoning Chain? Uncovering Structural Patterns in Long Chain-of-Thought Reasoning','Recent advances in reasoning with large language models (LLMs) have\npopularized Long Chain-of-Thought (LCoT), a strategy that encourages deliberate\nand step-by-step reasoning before producing a final answer. While LCoTs have\nenabled expert-level performance in complex tasks, how the internal structures\nof their reasoning chains drive, or even predict, the correctness of final\nanswers remains a critical yet underexplored question. In this work, we present\nLCoT2Tree, an automated framework that converts sequential LCoTs into\nhierarchical tree structures and thus enables deeper structural analysis of LLM\nreasoning. Using graph neural networks (GNNs), we reveal that structural\npatterns extracted by LCoT2Tree, including exploration, backtracking, and\nverification, serve as stronger predictors of final performance across a wide\nrange of tasks and models. Leveraging an explainability technique, we further\nidentify critical thought patterns such as over-branching that account for\nfailures. Beyond diagnostic insights, the structural patterns by LCoT2Tree\nsupport practical applications, including improving Best-of-N decoding\neffectiveness. Overall, our results underscore the critical role of internal\nstructures of reasoning chains, positioning LCoT2Tree as a powerful tool for\ndiagnosing, interpreting, and improving reasoning in LLMs.','Gangwei Jiang, Yahui Liu, Zhaoyi Li, Qi Wang, Fuzheng Zhang, Linqi Song, Ying Wei, Defu Lian','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22148v1'),('2505.22150v1','Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging','Brain-to-Image reconstruction aims to recover visual stimuli perceived by\nhumans from brain activity. However, the reconstructed visual stimuli often\nmissing details and semantic inconsistencies, which may be attributed to\ninsufficient semantic information. To address this issue, we propose an\napproach named Fine-grained Brain-to-Image reconstruction (FgB2I), which\nemploys fine-grained text as bridge to improve image reconstruction. FgB2I\ncomprises three key stages: detail enhancement, decoding fine-grained text\ndescriptions, and text-bridged brain-to-image reconstruction. In the\ndetail-enhancement stage, we leverage large vision-language models to generate\nfine-grained captions for visual stimuli and experimentally validate its\nimportance. We propose three reward metrics (object accuracy, text-image\nsemantic similarity, and image-image semantic similarity) to guide the language\nmodel in decoding fine-grained text descriptions from fMRI signals. The\nfine-grained text descriptions can be integrated into existing reconstruction\nmethods to achieve fine-grained Brain-to-Image reconstruction.','Runze Xia, Shuo Feng, Renzhi Wang, Congchi Yin, Xuyun Wen, Piji Li','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22150v1'),('2505.22151v1','Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in Offline MARL','A key challenge in offline multi-agent reinforcement learning (MARL) is\nachieving effective many-agent multi-step coordination in complex environments.\nIn this work, we propose Oryx, a novel algorithm for offline cooperative MARL\nto directly address this challenge. Oryx adapts the recently proposed\nretention-based architecture Sable and combines it with a sequential form of\nimplicit constraint Q-learning (ICQ), to develop a novel offline\nauto-regressive policy update scheme. This allows Oryx to solve complex\ncoordination challenges while maintaining temporal coherence over lengthy\ntrajectories. We evaluate Oryx across a diverse set of benchmarks from prior\nworks (SMAC, RWARE, and Multi-Agent MuJoCo) covering tasks of both discrete and\ncontinuous control, varying in scale and difficulty. Oryx achieves\nstate-of-the-art performance on more than 80% of the 65 tested datasets,\noutperforming prior offline MARL methods and demonstrating robust\ngeneralisation across domains with many agents and long horizons. Finally, we\nintroduce new datasets to push the limits of many-agent coordination in offline\nMARL, and demonstrate Oryx\\\'s superior ability to scale effectively in such\nsettings. We will make all of our datasets, experimental data, and code\navailable upon publication.','Claude Formanek, Omayma Mahjoub, Louay Ben Nessir, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon Du Toit, Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22151v1'),('2505.22152v1','Uncertainty Estimation for Heterophilic Graphs Through the Lens of Information Theory','While uncertainty estimation for graphs recently gained traction, most\nmethods rely on homophily and deteriorate in heterophilic settings. We address\nthis by analyzing message passing neural networks from an information-theoretic\nperspective and developing a suitable analog to data processing inequality to\nquantify information throughout the model\\\'s layers. In contrast to non-graph\ndomains, information about the node-level prediction target can increase with\nmodel depth if a node\\\'s features are semantically different from its neighbors.\nTherefore, on heterophilic graphs, the latent embeddings of an MPNN each\nprovide different information about the data distribution - different from\nhomophilic settings. This reveals that considering all node representations\nsimultaneously is a key design principle for epistemic uncertainty estimation\non graphs beyond homophily. We empirically confirm this with a simple post-hoc\ndensity estimator on the joint node embedding space that provides\nstate-of-the-art uncertainty on heterophilic graphs. At the same time, it\nmatches prior work on homophilic graphs without explicitly exploiting homophily\nthrough post-processing.','Dominik Fuchsgruber, Tom Wollschläger, Johannes Bordne, Stephan Günnemann','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22152v1'),('2505.22156v1','InComeS: Integrating Compression and Selection Mechanisms into LLMs for Efficient Model Editing','Although existing model editing methods perform well in recalling exact edit\nfacts, they often struggle in complex scenarios that require deeper semantic\nunderstanding rather than mere knowledge regurgitation. Leveraging the strong\ncontextual reasoning abilities of large language models (LLMs), in-context\nlearning (ICL) becomes a promising editing method by comprehending edit\ninformation through context encoding. However, this method is constrained by\nthe limited context window of LLMs, leading to degraded performance and\nefficiency as the number of edits increases. To overcome this limitation, we\npropose InComeS, a flexible framework that enhances LLMs\\\' ability to process\nediting contexts through explicit compression and selection mechanisms.\nSpecifically, InComeS compresses each editing context into the key-value (KV)\ncache of a special gist token, enabling efficient handling of multiple edits\nwithout being restricted by the model\\\'s context window. Furthermore,\nspecialized cross-attention modules are added to dynamically select the most\nrelevant information from the gist pools, enabling adaptive and effective\nutilization of edit information. We conduct experiments on diverse model\nediting benchmarks with various editing formats, and the results demonstrate\nthe effectiveness and efficiency of our method.','Shuaiyi Li, Zhisong Zhang, Yang Deng, Chenlong Deng, Tianqing Fang, Hongming Zhang, Haitao Mi, Dong Yu, Wai Lam','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22156v1'),('2505.22157v1','Stratified Selective Sampling for Instruction Tuning with Dedicated Scoring Strategy','Recent work shows that post-training datasets for LLMs can be substantially\ndownsampled without noticeably deteriorating performance. However, data\nselection often incurs high computational costs or is limited to narrow\ndomains. In this paper, we demonstrate that data selection can be both --\nefficient and universal -- by using a multi-step pipeline in which we\nefficiently bin data points into groups, estimate quality using specialized\nmodels, and score difficulty with a robust, lightweight method. Task-based\ncategorization allows us to control the composition of our final data --\ncrucial for finetuning multi-purpose models. To guarantee diversity, we improve\nupon previous work using embedding models and a clustering algorithm. This\nintegrated strategy enables high-performance fine-tuning with minimal overhead.','Paramita Mirza, Lucas Weber, Fabian Küch','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22157v1'),('2505.22158v1','The informativeness of the gradient revisited','In the past decade gradient-based deep learning has revolutionized several\napplications. However, this rapid advancement has highlighted the need for a\ndeeper theoretical understanding of its limitations. Research has shown that,\nin many practical learning tasks, the information contained in the gradient is\nso minimal that gradient-based methods require an exceedingly large number of\niterations to achieve success. The informativeness of the gradient is typically\nmeasured by its variance with respect to the random selection of a target\nfunction from a hypothesis class.\n  We use this framework and give a general bound on the variance in terms of a\nparameter related to the pairwise independence of the target function class and\nthe collision entropy of the input distribution. Our bound scales as $\n\\tilde{\\mathcal{O}}(\\varepsilon+e^{-\\frac{1}{2}\\mathcal{E}_c}) $, where $\n\\tilde{\\mathcal{O}} $ hides factors related to the regularity of the learning\nmodel and the loss function, $ \\varepsilon $ measures the pairwise independence\nof the target function class and $\\mathcal{E}_c$ is the collision entropy of\nthe input distribution.\n  To demonstrate the practical utility of our bound, we apply it to the class\nof Learning with Errors (LWE) mappings and high-frequency functions. In\naddition to the theoretical analysis, we present experiments to understand\nbetter the nature of recent deep learning-based attacks on LWE.','Rustem Takhanov','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22158v1'),('2505.22165v1','Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes','Diffusion models have emerged as a promising approach for text generation,\nwith recent works falling into two main categories: discrete and continuous\ndiffusion models. Discrete diffusion models apply token corruption\nindependently using categorical distributions, allowing for different diffusion\nprogress across tokens but lacking fine-grained control. Continuous diffusion\nmodels map tokens to continuous spaces and apply fine-grained noise, but the\ndiffusion progress is uniform across tokens, limiting their ability to capture\nsemantic nuances. To address these limitations, we propose\n\\textbf{\\underline{N}}on-simultan\\textbf{\\underline{e}}ous\nC\\textbf{\\underline{o}}ntinuous \\textbf{\\underline{Diff}}usion Models\n(NeoDiff), a novel diffusion model that integrates the strengths of both\ndiscrete and continuous approaches. NeoDiff introduces a Poisson diffusion\nprocess for the forward process, enabling a flexible and fine-grained noising\nparadigm, and employs a time predictor for the reverse process to adaptively\nmodulate the denoising progress based on token semantics. Furthermore, NeoDiff\nutilizes an optimized schedule for inference to ensure more precise noise\ncontrol and improved performance. Our approach unifies the theories of discrete\nand continuous diffusion models, offering a more principled and effective\nframework for text generation. Experimental results on several text generation\ntasks demonstrate NeoDiff\\\'s superior performance compared to baselines of\nnon-autoregressive continuous and discrete diffusion models, iterative-based\nmethods and autoregressive diffusion-based methods. These results highlight\nNeoDiff\\\'s potential as a powerful tool for generating high-quality text and\nadvancing the field of diffusion-based text generation.','Bocheng Li, Zhujin Gao, Linli Xu','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22165v1'),('2505.22169v1','ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments','LLMs are highly sensitive to prompt phrasing, yet standard benchmarks\ntypically report performance using a single prompt, raising concerns about the\nreliability of such evaluations. In this work, we argue for a stochastic method\nof moments evaluation over the space of meaning-preserving prompt\nperturbations. We introduce a formal definition of reliable evaluation that\naccounts for prompt sensitivity, and suggest ReliableEval - a method for\nestimating the number of prompt resamplings needed to obtain meaningful\nresults. Using our framework, we stochastically evaluate five frontier LLMs and\nfind that even top-performing models like GPT-4o and Claude-3.7-Sonnet exhibit\nsubstantial prompt sensitivity. Our approach is model-, task-, and\nmetric-agnostic, offering a recipe for meaningful and robust LLM evaluation.','Gili Lior, Eliya Habba, Shahar Levy, Avi Caciularu, Gabriel Stanovsky','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22169v1'),('2505.22172v1','Reverse Preference Optimization for Complex Instruction Following','Instruction following (IF) is a critical capability for large language models\n(LLMs). However, handling complex instructions with multiple constraints\nremains challenging. Previous methods typically select preference pairs based\non the number of constraints they satisfy, introducing noise where chosen\nexamples may fail to follow some constraints and rejected examples may excel in\ncertain respects over the chosen ones. To address the challenge of aligning\nwith multiple preferences, we propose a simple yet effective method called\nReverse Preference Optimization (RPO). It mitigates noise in preference pairs\nby dynamically reversing the constraints within the instruction to ensure the\nchosen response is perfect, alleviating the burden of extensive sampling and\nfiltering to collect perfect responses. Besides, reversal also enlarges the gap\nbetween chosen and rejected responses, thereby clarifying the optimization\ndirection and making it more robust to noise. We evaluate RPO on two multi-turn\nIF benchmarks, Sysbench and Multi-IF, demonstrating average improvements over\nthe DPO baseline of 4.6 and 2.5 points (on Llama-3.1 8B), respectively.\nMoreover, RPO scales effectively across model sizes (8B to 70B parameters),\nwith the 70B RPO model surpassing GPT-4o.','Xiang Huang, Ting-En Lin, Feiteng Fang, Yuchuan Wu, Hangyu Li, Yuzhong Qu, Fei Huang, Yongbin Li','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22172v1'),('2505.22174v1','Online Fair Division for Personalized $2$-Value Instances','We study an online fair division setting, where goods arrive one at a time\nand there is a fixed set of $n$ agents, each of whom has an additive valuation\nfunction over the goods. Once a good appears, the value each agent has for it\nis revealed and it must be allocated immediately and irrevocably to one of the\nagents. It is known that without any assumptions about the values being\nseverely restricted or coming from a distribution, very strong impossibility\nresults hold in this setting. To bypass the latter, we turn our attention to\ninstances where the valuation functions are restricted. In particular, we study\npersonalized $2$-value instances, where there are only two possible values each\nagent may have for each good, possibly different across agents, and we show how\nto obtain worst case guarantees with respect to well-known fairness notions,\nsuch as maximin share fairness and envy-freeness up to one (or two) good(s). We\nsuggest a deterministic algorithm that maintains a $1/(2n-1)$-MMS allocation at\nevery time step and show that this is the best possible any deterministic\nalgorithm can achieve if one cares about every single time step; nevertheless,\neventually the allocation constructed by our algorithm becomes a $1/4$-MMS\nallocation. To achieve this, the algorithm implicitly maintains a fragile\nsystem of priority levels for all agents. Further, we show that, by allowing\nsome limited access to future information, it is possible to have stronger\nresults with less involved approaches. By knowing the values of goods for $n-1$\ntime steps into the future, we design a matching-based algorithm that achieves\nan EF$1$ allocation every $n$ time steps, while always maintaining an EF$2$\nallocation. Finally, we show that our results allow us to get the first\nnontrivial guarantees for additive instances in which the ratio of the maximum\nover the minimum value an agent has for a good is bounded.','Georgios Amanatidis, Alexandros Lolos, Evangelos Markakis, Victor Turmel','2025-05-28','cs.GT','http://arxiv.org/pdf/2505.22174v1'),('2505.22176v1','TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation','Evaluating tables qualitatively & quantitatively presents a significant\nchallenge, as traditional metrics often fail to capture nuanced structural and\ncontent discrepancies. To address this, we introduce a novel, methodical rubric\nintegrating multi-level structural descriptors with fine-grained contextual\nquantification, thereby establishing a robust foundation for comprehensive\ntable comparison. Building on this foundation, we propose TabXEval, an\neXhaustive and eXplainable two-phase evaluation framework. TabXEval initially\naligns reference tables structurally via TabAlign & subsequently conducts a\nsystematic semantic and syntactic comparison using TabCompare; this approach\nclarifies the evaluation process and pinpoints subtle discrepancies overlooked\nby conventional methods. The efficacy of this framework is assessed using\nTabXBench, a novel, diverse, multi-domain benchmark we developed, featuring\nrealistic table perturbations and human-annotated assessments. Finally, a\nsystematic analysis of existing evaluation methods through\nsensitivity-specificity trade-offs demonstrates the qualitative and\nquantitative effectiveness of TabXEval across diverse table-related tasks and\ndomains, paving the way for future innovations in explainable table evaluation.','Vihang Pancholi, Jainit Bafna, Tejas Anvekar, Manish Shrivastava, Vivek Gupta','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22176v1'),('2505.22179v1','Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design','Speculative decoding and quantization effectively accelerate memory-bound\ninference of large language models. Speculative decoding mitigates the memory\nbandwidth bottleneck by verifying multiple tokens within a single forward pass,\nwhich increases computational effort. Quantization achieves this optimization\nby compressing weights and activations into lower bit-widths and also reduces\ncomputations via low-bit matrix multiplications. To further leverage their\nstrengths, we investigate the integration of these two techniques.\nSurprisingly, experiments applying the advanced speculative decoding method\nEAGLE-2 to various quantized models reveal that the memory benefits from 4-bit\nweight quantization are diminished by the computational load from speculative\ndecoding. Specifically, verifying a tree-style draft incurs significantly more\ntime overhead than a single-token forward pass on 4-bit weight quantized\nmodels. This finding led to our new speculative decoding design: a hierarchical\nframework that employs a small model as an intermediate stage to turn\ntree-style drafts into sequence drafts, leveraging the memory access benefits\nof the target quantized model. Experimental results show that our hierarchical\napproach achieves a 2.78$\\times$ speedup across various tasks for the 4-bit\nweight Llama-3-70B model on an A100 GPU, outperforming EAGLE-2 by 1.31$\\times$.\nCode available at https://github.com/AI9Stars/SpecMQuant.','Yudi Zhang, Weilin Zhao, Xu Han, Tiejun Zhao, Wang Xu, Hailong Cao, Conghui Zhu','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22179v1'),('2505.22184v1','Breaking the Cloak! Unveiling Chinese Cloaked Toxicity with Homophone Graph and Toxic Lexicon','Social media platforms have experienced a significant rise in toxic content,\nincluding abusive language and discriminatory remarks, presenting growing\nchallenges for content moderation. Some users evade censorship by deliberately\ndisguising toxic words through homophonic cloak, which necessitates the task of\nunveiling cloaked toxicity. Existing methods are mostly designed for English\ntexts, while Chinese cloaked toxicity unveiling has not been solved yet. To\ntackle the issue, we propose C$^2$TU, a novel training-free and prompt-free\nmethod for Chinese cloaked toxic content unveiling. It first employs substring\nmatching to identify candidate toxic words based on Chinese homo-graph and\ntoxic lexicon. Then it filters those candidates that are non-toxic and corrects\ncloaks to be their corresponding toxicities. Specifically, we develop two model\nvariants for filtering, which are based on BERT and LLMs, respectively. For\nLLMs, we address the auto-regressive limitation in computing word occurrence\nprobability and utilize the full semantic contexts of a text sequence to reveal\ncloaked toxic words. Extensive experiments demonstrate that C$^2$TU can achieve\nsuperior performance on two Chinese toxic datasets. In particular, our method\noutperforms the best competitor by up to 71% on the F1 score and 35% on\naccuracy, respectively.','Xuchen Ma, Jianxiang Yu, Wenming Shao, Bo Pang, Xiang Li','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22184v1'),('2505.22193v1','Physics-inspired Generative AI models via real hardware-based noisy quantum diffusion','Quantum Diffusion Models (QDMs) are an emerging paradigm in Generative AI\nthat aims to use quantum properties to improve the performances of their\nclassical counterparts. However, existing algorithms are not easily scalable\ndue to the limitations of near-term quantum devices. Following our previous\nwork on QDMs, here we propose and implement two physics-inspired protocols. In\nthe first, we use the formalism of quantum stochastic walks, showing that a\nspecific interplay of quantum and classical dynamics in the forward process\nproduces statistically more robust models generating sets of MNIST images with\nlower Fr\\\\\'echet Inception Distance (FID) than using totally classical dynamics.\nIn the second approach, we realize an algorithm to generate images by\nexploiting the intrinsic noise of real IBM quantum hardware with only four\nqubits. Our work could be a starting point to pave the way for new scenarios\nfor large-scale algorithms in quantum Generative AI, where quantum noise is\nneither mitigated nor corrected, but instead exploited as a useful resource.','Marco Parigi, Stefano Martina, Francesco Aldo Venturelli, Filippo Caruso','2025-05-28','quant-ph','http://arxiv.org/pdf/2505.22193v1'),('2505.22196v1','An Augmentation-Aware Theory for Self-Supervised Contrastive Learning','Self-supervised contrastive learning has emerged as a powerful tool in\nmachine learning and computer vision to learn meaningful representations from\nunlabeled data. Meanwhile, its empirical success has encouraged many\ntheoretical studies to reveal the learning mechanisms. However, in the existing\ntheoretical research, the role of data augmentation is still under-exploited,\nespecially the effects of specific augmentation types. To fill in the blank, we\nfor the first time propose an augmentation-aware error bound for\nself-supervised contrastive learning, showing that the supervised risk is\nbounded not only by the unsupervised risk, but also explicitly by a trade-off\ninduced by data augmentation. Then, under a novel semantic label assumption, we\ndiscuss how certain augmentation methods affect the error bound. Lastly, we\nconduct both pixel- and representation-level experiments to verify our proposed\ntheoretical results.','Jingyi Cui, Hongwei Wen, Yisen Wang','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22196v1'),('2505.22199v1','Enhancing Uncertainty Estimation and Interpretability via Bayesian Non-negative Decision Layer','Although deep neural networks have demonstrated significant success due to\ntheir powerful expressiveness, most models struggle to meet practical\nrequirements for uncertainty estimation. Concurrently, the entangled nature of\ndeep neural networks leads to a multifaceted problem, where various localized\nexplanation techniques reveal that multiple unrelated features influence the\ndecisions, thereby undermining interpretability. To address these challenges,\nwe develop a Bayesian Non-negative Decision Layer (BNDL), which reformulates\ndeep neural networks as a conditional Bayesian non-negative factor analysis. By\nleveraging stochastic latent variables, the BNDL can model complex dependencies\nand provide robust uncertainty estimation. Moreover, the sparsity and\nnon-negativity of the latent variables encourage the model to learn\ndisentangled representations and decision layers, thereby improving\ninterpretability. We also offer theoretical guarantees that BNDL can achieve\neffective disentangled learning. In addition, we developed a corresponding\nvariational inference method utilizing a Weibull variational inference network\nto approximate the posterior distribution of the latent variables. Our\nexperimental results demonstrate that with enhanced disentanglement\ncapabilities, BNDL not only improves the model\\\'s accuracy but also provides\nreliable uncertainty estimation and improved interpretability.','Xinyue Hu, Zhibin Duan, Bo Chen, Mingyuan Zhou','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22199v1'),('2505.22200v1','Investigating Mechanisms for In-Context Vision Language Binding','To understand a prompt, Vision-Language models (VLMs) must perceive the\nimage, comprehend the text, and build associations within and across both\nmodalities. For instance, given an \\\'image of a red toy car\\\', the model should\nassociate this image to phrases like \\\'car\\\', \\\'red toy\\\', \\\'red object\\\', etc. Feng\nand Steinhardt propose the Binding ID mechanism in LLMs, suggesting that the\nentity and its corresponding attribute tokens share a Binding ID in the model\nactivations. We investigate this for image-text binding in VLMs using a\nsynthetic dataset and task that requires models to associate 3D objects in an\nimage with their descriptions in the text. Our experiments demonstrate that\nVLMs assign a distinct Binding ID to an object\\\'s image tokens and its textual\nreferences, enabling in-context association.','Darshana Saravanan, Makarand Tapaswi, Vineet Gandhi','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22200v1'),('2505.22202v1','Let\\\'s Predict Sentence by Sentence','Autoregressive language models (LMs) generate one token at a time, yet human\nreasoning operates over higher-level abstractions - sentences, propositions,\nand concepts. This contrast raises a central question- Can LMs likewise learn\nto reason over structured semantic units rather than raw token sequences? In\nthis work, we investigate whether pretrained LMs can be lifted into such\nabstract reasoning spaces by building on their learned representations. We\npresent a framework that adapts a pretrained token-level LM to operate in\nsentence space by autoregressively predicting continuous embeddings of next\nsentences. We explore two embedding paradigms inspired by classical\nrepresentation learning: 1) semantic embeddings, learned via autoencoding to\npreserve surface meaning; and 2) contextual embeddings, trained via\nnext-sentence prediction to encode anticipatory structure. We evaluate both\nunder two inference regimes: Discretized, which decodes each predicted\nembedding into text before re-encoding; and Continuous, which reasons entirely\nin embedding space for improved efficiency. Across four domains - mathematics,\nlogic, commonsense, and planning - contextual embeddings under continuous\ninference show competitive performance with Chain-of-Thought (CoT) while\nreducing inference-time FLOPs on average by half. We also present early signs\nof scalability and modular adaptation. Finally, to visualize latent\ntrajectories, we introduce SentenceLens, a diagnostic tool that decodes\nintermediate model states into interpretable sentences. Together, our results\nindicate that pretrained LMs can effectively transition to abstract, structured\nreasoning within latent embedding spaces.','Hyeonbin Hwang, Byeongguk Jeon, Seungone Kim, Jiyeon Kim, Hoyeon Chang, Sohee Yang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22202v1'),('2505.22203v1','Pitfalls of Rule- and Model-based Verifiers -- A Case Study on Mathematical Reasoning','Trustworthy verifiers are essential for the success of reinforcement learning\nwith verifiable reward (RLVR), which is the core methodology behind various\nlarge reasoning models such as DeepSeek-R1. In complex domains like\nmathematical reasoning, rule-based verifiers have been widely adopted in\nprevious works to train strong reasoning models. However, the reliability of\nthese verifiers and their impact on the RL training process remain poorly\nunderstood. In this work, we take mathematical reasoning as a case study and\nconduct a comprehensive analysis of various verifiers in both static evaluation\nand RL training scenarios. First, we find that current open-source rule-based\nverifiers often fail to recognize equivalent answers presented in different\nformats across multiple commonly used mathematical datasets, resulting in\nnon-negligible false negative rates. This limitation adversely affects RL\ntraining performance and becomes more pronounced as the policy model gets\nstronger. Subsequently, we investigate model-based verifiers as a potential\nsolution to address these limitations. While the static evaluation shows that\nmodel-based verifiers achieve significantly higher verification accuracy,\nfurther analysis and RL training results imply that they are highly susceptible\nto hacking, where they misclassify certain patterns in responses as correct\n(i.e., false positives). This vulnerability is exploited during policy model\noptimization, leading to artificially inflated rewards. Our findings underscore\nthe unique risks inherent to both rule-based and model-based verifiers, aiming\nto offer valuable insights to develop more robust reward systems in\nreinforcement learning.','Yuzhen Huang, Weihao Zeng, Xingshan Zeng, Qi Zhu, Junxian He','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22203v1'),('2505.22208v1','LaMM: Semi-Supervised Pre-Training of Large-Scale Materials Models','Neural network potentials (NNPs) are crucial for accelerating computational\nmaterials science by surrogating density functional theory (DFT) calculations.\nImproving their accuracy is possible through pre-training and fine-tuning,\nwhere an NNP model is first pre-trained on a large-scale dataset and then\nfine-tuned on a smaller target dataset. However, this approach is\ncomputationally expensive, mainly due to the cost of DFT-based dataset labeling\nand load imbalances during large-scale pre-training. To address this, we\npropose LaMM, a semi-supervised pre-training method incorporating improved\ndenoising self-supervised learning and a load-balancing algorithm for efficient\nmulti-node training. We demonstrate that our approach effectively leverages a\nlarge-scale dataset of $\\sim$300 million semi-labeled samples to train a single\nNNP model, resulting in improved fine-tuning performance in terms of both speed\nand accuracy.','Yosuke Oyama, Yusuke Majima, Eiji Ohta, Yasufumi Sakai','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22208v1'),('2505.22211v1','Handling bounded response in high dimensions: a Horseshoe prior Bayesian Beta regression approach','Bounded continuous responses -- such as proportions -- arise frequently in\ndiverse scientific fields including climatology, biostatistics, and finance.\nBeta regression is a widely adopted framework for modeling such data, due to\nthe flexibility of the Beta distribution over the unit interval. While Bayesian\nextensions of Beta regression have shown promise, existing methods are limited\nto low-dimensional settings and lack theoretical guarantees. In this work, we\npropose a novel Bayesian approach for high-dimensional sparse Beta regression\nframework that employs a tempered posterior. Our method incorporates the\nHorseshoe prior for effective shrinkage and variable selection. Most notable,\nwe propose a novel Gibbs sampling algorithm using P\\\\\'olya-Gamma augmentation\nfor efficient inference in Beta regression model. We also provide the first\ntheoretical results establishing posterior consistency and convergence rates\nfor Bayesian Beta regression. Through extensive simulation studies in both low-\nand high-dimensional scenarios, we demonstrate that our approach outperforms\nexisting alternatives, offering improved estimation accuracy and model\ninterpretability.\n  Our method is implemented in the R package ``betaregbayes\" available on\nGithub.','The Tien Mai','2025-05-28','stat.ME','http://arxiv.org/pdf/2505.22211v1'),('2505.22222v1','Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation','Recent advancements in multimodal Large Language Models (LLMs) have\nsignificantly enhanced the automation of medical image analysis, particularly\nin generating radiology reports from chest X-rays (CXR). However, these models\nstill suffer from hallucinations and clinically significant errors, limiting\ntheir reliability in real-world applications. In this study, we propose Look &\nMark (L&M), a novel grounding fixation strategy that integrates radiologist eye\nfixations (Look) and bounding box annotations (Mark) into the LLM prompting\nframework. Unlike conventional fine-tuning, L&M leverages in-context learning\nto achieve substantial performance gains without retraining. When evaluated\nacross multiple domain-specific and general-purpose models, L&M demonstrates\nsignificant gains, including a 1.2% improvement in overall metrics (A.AVG) for\nCXR-LLaVA compared to baseline prompting and a remarkable 9.2% boost for\nLLaVA-Med. General-purpose models also benefit from L&M combined with\nin-context learning, with LLaVA-OV achieving an 87.3% clinical average\nperformance (C.AVG)-the highest among all models, even surpassing those\nexplicitly trained for CXR report generation. Expert evaluations further\nconfirm that L&M reduces clinically significant errors (by 0.43 average errors\nper report), such as false predictions and omissions, enhancing both accuracy\nand reliability. These findings highlight L&M\\\'s potential as a scalable and\nefficient solution for AI-assisted radiology, paving the way for improved\ndiagnostic workflows in low-resource clinical settings.','Yunsoo Kim, Jinge Wu, Su-Hwan Kim, Pardeep Vasudev, Jiashu Shen, Honghan Wu','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22222v1'),('2505.22224v1','Solver-Free Decision-Focused Learning for Linear Optimization Problems','Mathematical optimization is a fundamental tool for decision-making in a wide\nrange of applications. However, in many real-world scenarios, the parameters of\nthe optimization problem are not known a priori and must be predicted from\ncontextual features. This gives rise to predict-then-optimize problems, where a\nmachine learning model predicts problem parameters that are then used to make\ndecisions via optimization. A growing body of work on decision-focused learning\n(DFL) addresses this setting by training models specifically to produce\npredictions that maximize downstream decision quality, rather than accuracy.\nWhile effective, DFL is computationally expensive, because it requires solving\nthe optimization problem with the predicted parameters at each loss evaluation.\nIn this work, we address this computational bottleneck for linear optimization\nproblems, a common class of problems in both DFL literature and real-world\napplications. We propose a solver-free training method that exploits the\ngeometric structure of linear optimization to enable efficient training with\nminimal degradation in solution quality. Our method is based on the insight\nthat a solution is optimal if and only if it achieves an objective value that\nis at least as good as that of its adjacent vertices on the feasible polytope.\nBuilding on this, our method compares the estimated quality of the ground-truth\noptimal solution with that of its precomputed adjacent vertices, and uses this\nas loss function. Experiments demonstrate that our method significantly reduces\ncomputational cost while maintaining high decision quality.','Senne Berden, Ali İrfan Mahmutoğulları, Dimos Tsouros, Tias Guns','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22224v1'),('2505.22231v1','Advancing Hearing Assessment: An ASR-Based Frequency-Specific Speech Test for Diagnosing Presbycusis','Traditional audiometry often fails to fully characterize the functional\nimpact of hearing loss on speech understanding, particularly supra-threshold\ndeficits and frequency-specific perception challenges in conditions like\npresbycusis. This paper presents the development and simulated evaluation of a\nnovel Automatic Speech Recognition (ASR)-based frequency-specific speech test\ndesigned to provide granular diagnostic insights. Our approach leverages ASR to\nsimulate the perceptual effects of moderate sloping hearing loss by processing\nspeech stimuli under controlled acoustic degradation and subsequently analyzing\nphoneme-level confusion patterns. Key findings indicate that simulated hearing\nloss introduces specific phoneme confusions, predominantly affecting\nhigh-frequency consonants (e.g., alveolar/palatal to labiodental substitutions)\nand leading to significant phoneme deletions, consistent with the acoustic cues\ndegraded in presbycusis. A test battery curated from these ASR-derived\nconfusions demonstrated diagnostic value, effectively differentiating between\nsimulated normal-hearing and hearing-impaired listeners in a comprehensive\nsimulation. This ASR-driven methodology offers a promising avenue for\ndeveloping objective, granular, and frequency-specific hearing assessment tools\nthat complement traditional audiometry. Future work will focus on validating\nthese findings with human participants and exploring the integration of\nadvanced AI models for enhanced diagnostic precision.','Stefan Bleeck','2025-05-28','cs.SD','http://arxiv.org/pdf/2505.22231v1'),('2505.22232v1','Judging Quality Across Languages: A Multilingual Approach to Pretraining Data Filtering with Language Models','High-quality multilingual training data is essential for effectively\npretraining large language models (LLMs). Yet, the availability of suitable\nopen-source multilingual datasets remains limited. Existing state-of-the-art\ndatasets mostly rely on heuristic filtering methods, restricting both their\ncross-lingual transferability and scalability. Here, we introduce JQL, a\nsystematic approach that efficiently curates diverse and high-quality\nmultilingual data at scale while significantly reducing computational demands.\nJQL distills LLMs\\\' annotation capabilities into lightweight annotators based on\npretrained multilingual embeddings. These models exhibit robust multilingual\nand cross-lingual performance, even for languages and scripts unseen during\ntraining. Evaluated empirically across 35 languages, the resulting annotation\npipeline substantially outperforms current heuristic filtering methods like\nFineweb2. JQL notably enhances downstream model training quality and increases\ndata retention rates. Our research provides practical insights and valuable\nresources for multilingual data curation, raising the standards of multilingual\ndataset development.','Mehdi Ali, Manuel Brack, Max Lübbering, Elias Wendt, Abbas Goher Khan, Richard Rutmann, Alex Jude, Maurice Kraus, Alexander Arno Weber, Felix Stollenwerk, David Kaczér, Florian Mai, Lucie Flek, Rafet Sifa, Nicolas Flores-Herr, Joachim Köhler, Patrick Schramowski, Michael Fromm, Kristian Kersting','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22232v1'),('2505.22235v1','Optimal kernel regression bounds under energy-bounded noise','Non-conservative uncertainty bounds are key for both assessing an estimation\nalgorithm\\\'s accuracy and in view of downstream tasks, such as its deployment in\nsafety-critical contexts. In this paper, we derive a tight, non-asymptotic\nuncertainty bound for kernel-based estimation, which can also handle correlated\nnoise sequences. Its computation relies on a mild norm-boundedness assumption\non the unknown function and the noise, returning the worst-case function\nrealization within the hypothesis class at an arbitrary query input location.\nThe value of this function is shown to be given in terms of the posterior mean\nand covariance of a Gaussian process for an optimal choice of the measurement\nnoise covariance. By rigorously analyzing the proposed approach and comparing\nit with other results in the literature, we show its effectiveness in returning\ntight and easy-to-compute bounds for kernel-based estimates.','Amon Lahr, Johannes Köhler, Anna Scampicchio, Melanie N. Zeilinger','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22235v1'),('2505.22236v1','A Linguistically Motivated Analysis of Intonational Phrasing in Text-to-Speech Systems: Revealing Gaps in Syntactic Sensitivity','We analyze the syntactic sensitivity of Text-to-Speech (TTS) systems using\nmethods inspired by psycholinguistic research. Specifically, we focus on the\ngeneration of intonational phrase boundaries, which can often be predicted by\nidentifying syntactic boundaries within a sentence. We find that TTS systems\nstruggle to accurately generate intonational phrase boundaries in sentences\nwhere syntactic boundaries are ambiguous (e.g., garden path sentences or\nsentences with attachment ambiguity). In these cases, systems need superficial\ncues such as commas to place boundaries at the correct positions. In contrast,\nfor sentences with simpler syntactic structures, we find that systems do\nincorporate syntactic cues beyond surface markers. Finally, we finetune models\non sentences without commas at the syntactic boundary positions, encouraging\nthem to focus on more subtle linguistic cues. Our findings indicate that this\nleads to more distinct intonation patterns that better reflect the underlying\nstructure.','Charlotte Pouw, Afra Alishahi, Willem Zuidema','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22236v1'),('2505.22238v1','Yambda-5B -- A Large-Scale Multi-modal Dataset for Ranking And Retrieval','We present Yambda-5B, a large-scale open dataset sourced from the\nYandex.Music streaming platform. Yambda-5B contains 4.79 billion user-item\ninteractions from 1 million users across 9.39 million tracks. The dataset\nincludes two primary types of interactions: implicit feedback (listening\nevents) and explicit feedback (likes, dislikes, unlikes and undislikes). In\naddition, we provide audio embeddings for most tracks, generated by a\nconvolutional neural network trained on audio spectrograms. A key\ndistinguishing feature of Yambda-5B is the inclusion of the is_organic flag,\nwhich separates organic user actions from recommendation-driven events. This\ndistinction is critical for developing and evaluating machine learning\nalgorithms, as Yandex.Music relies on recommender systems to personalize track\nselection for users. To support rigorous benchmarking, we introduce an\nevaluation protocol based on a Global Temporal Split, allowing recommendation\nalgorithms to be assessed in conditions that closely mirror real-world use. We\nreport benchmark results for standard baselines (ItemKNN, iALS) and advanced\nmodels (SANSA, SASRec) using a variety of evaluation metrics. By releasing\nYambda-5B to the community, we aim to provide a readily accessible,\nindustrial-scale resource to advance research, foster innovation, and promote\nreproducible results in recommender systems.','A. Ploshkin, V. Tytskiy, A. Pismenny, V. Baikalov, E. Taychinov, A. Permiakov, D. Burlakov, E. Krofto, N. Savushkin','2025-05-28','cs.IR','http://arxiv.org/pdf/2505.22238v1'),('2505.22240v1','BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain','Biomedical reasoning often requires traversing interconnected relationships\nacross entities such as drugs, diseases, and proteins. Despite the increasing\nprominence of large language models (LLMs), existing benchmarks lack the\nability to evaluate multi-hop reasoning in the biomedical domain, particularly\nfor queries involving one-to-many and many-to-many relationships. This gap\nleaves the critical challenges of biomedical multi-hop reasoning underexplored.\nTo address this, we introduce BioHopR, a novel benchmark designed to evaluate\nmulti-hop, multi-answer reasoning in structured biomedical knowledge graphs.\nBuilt from the comprehensive PrimeKG, BioHopR includes 1-hop and 2-hop\nreasoning tasks that reflect real-world biomedical complexities.\n  Evaluations of state-of-the-art models reveal that O3-mini, a proprietary\nreasoning-focused model, achieves 37.93% precision on 1-hop tasks and 14.57% on\n2-hop tasks, outperforming proprietary models such as GPT4O and open-source\nbiomedical models including HuatuoGPT-o1-70B and Llama-3.3-70B. However, all\nmodels exhibit significant declines in multi-hop performance, underscoring the\nchallenges of resolving implicit reasoning steps in the biomedical domain. By\naddressing the lack of benchmarks for multi-hop reasoning in biomedical domain,\nBioHopR sets a new standard for evaluating reasoning capabilities and\nhighlights critical gaps between proprietary and open-source models while\npaving the way for future advancements in biomedical LLMs.','Yunsoo Kim, Yusuf Abdulle, Honghan Wu','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22240v1'),('2505.22243v1','UDuo: Universal Dual Optimization Framework for Online Matching','Online resource allocation under budget constraints critically depends on\nproper modeling of user arrival dynamics. Classical approaches employ\nstochastic user arrival models to derive near-optimal solutions through\nfractional matching formulations of exposed users for downstream allocation\ntasks. However, this is no longer a reasonable assumption when the environment\nchanges dynamically. In this work, We propose the Universal Dual optimization\nframework UDuo, a novel paradigm that fundamentally rethinks online allocation\nthrough three key innovations: (i) a temporal user arrival representation\nvector that explicitly captures distribution shifts in user arrival patterns\nand resource consumption dynamics, (ii) a resource pacing learner with adaptive\nallocation policies that generalize to heterogeneous constraint scenarios, and\n(iii) an online time-series forecasting approach for future user arrival\ndistributions that achieves asymptotically optimal solutions with constraint\nfeasibility guarantees in dynamic environments. Experimental results show that\nUDuo achieves higher efficiency and faster convergence than the traditional\nstochastic arrival model in real-world pricing while maintaining rigorous\ntheoretical validity for general online allocation problems.','Bin Li, Diwei Liu, Zehong Hu, Jia Jia','2025-05-28','cs.IR','http://arxiv.org/pdf/2505.22243v1'),('2505.22244v1','A Preprocessing Framework for Efficient Approximate Bi-Objective Shortest-Path Computation in the Presence of Correlated Objectives','The bi-objective shortest-path (BOSP) problem seeks to find paths between\nstart and target vertices of a graph while optimizing two conflicting objective\nfunctions. We consider the BOSP problem in the presence of correlated\nobjectives. Such correlations often occur in real-world settings such as road\nnetworks, where optimizing two positively correlated objectives, such as travel\ntime and fuel consumption, is common. BOSP is generally computationally\nchallenging as the size of the search space is exponential in the number of\nobjective functions and the graph size. Bounded sub-optimal BOSP solvers such\nas A*pex alleviate this complexity by approximating the Pareto-optimal solution\nset rather than computing it exactly (given a user-provided approximation\nfactor). As the correlation between objective functions increases, smaller\napproximation factors are sufficient for collapsing the entire Pareto-optimal\nset into a single solution. We leverage this insight to propose an efficient\nalgorithm that reduces the search effort in the presence of correlated\nobjectives. Our approach for computing approximations of the entire\nPareto-optimal set is inspired by graph-clustering algorithms. It uses a\npreprocessing phase to identify correlated clusters within a graph and to\ngenerate a new graph representation. This allows a natural generalization of\nA*pex to run up to five times faster on DIMACS dataset instances, a standard\nbenchmark in the field. To the best of our knowledge, this is the first\nalgorithm proposed that efficiently and effectively exploits correlations in\nthe context of bi-objective search while providing theoretical guarantees on\nsolution quality.','Yaron Halle, Ariel Felner, Sven Koenig, Oren Salzman','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22244v1'),('2505.22251v1','Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition','Recent work suggests that large language models (LLMs) can improve\nperformance of speech tasks compared to existing systems. To support their\nclaims, results on LibriSpeech and Common Voice are often quoted. However, this\nwork finds that a substantial amount of the LibriSpeech and Common Voice\nevaluation sets appear in public LLM pretraining corpora. This calls into\nquestion the reliability of findings drawn from these two datasets. To measure\nthe impact of contamination, LLMs trained with or without contamination are\ncompared, showing that a contaminated LLM is more likely to generate test\nsentences it has seen during training. Speech recognisers using contaminated\nLLMs shows only subtle differences in error rates, but assigns significantly\nhigher probabilities to transcriptions seen during training. Results show that\nLLM outputs can be biased by tiny amounts of data contamination, highlighting\nthe importance of evaluating LLM-based speech systems with held-out data.','Yuan Tseng, Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya','2025-05-28','eess.AS','http://arxiv.org/pdf/2505.22251v1'),('2505.22252v1','B-XAIC Dataset: Benchmarking Explainable AI for Graph Neural Networks Using Chemical Data','Understanding the reasoning behind deep learning model predictions is crucial\nin cheminformatics and drug discovery, where molecular design determines their\nproperties. However, current evaluation frameworks for Explainable AI (XAI) in\nthis domain often rely on artificial datasets or simplified tasks, employing\ndata-derived metrics that fail to capture the complexity of real-world\nscenarios and lack a direct link to explanation faithfulness. To address this,\nwe introduce B-XAIC, a novel benchmark constructed from real-world molecular\ndata and diverse tasks with known ground-truth rationales for assigned labels.\nThrough a comprehensive evaluation using B-XAIC, we reveal limitations of\nexisting XAI methods for Graph Neural Networks (GNNs) in the molecular domain.\nThis benchmark provides a valuable resource for gaining deeper insights into\nthe faithfulness of XAI, facilitating the development of more reliable and\ninterpretable models.','Magdalena Proszewska, Tomasz Danel, Dawid Rymarczyk','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22252v1'),('2505.22254v1','A Unified Online-Offline Framework for Co-Branding Campaign Recommendations','Co-branding has become a vital strategy for businesses aiming to expand\nmarket reach within recommendation systems. However, identifying effective\ncross-industry partnerships remains challenging due to resource imbalances,\nuncertain brand willingness, and ever-changing market conditions. In this\npaper, we provide the first systematic study of this problem and propose a\nunified online-offline framework to enable co-branding recommendations. Our\napproach begins by constructing a bipartite graph linking ``initiating\\\'\\\' and\n``target\\\'\\\' brands to quantify co-branding probabilities and assess market\nbenefits. During the online learning phase, we dynamically update the graph in\nresponse to market feedback, while striking a balance between exploring new\ncollaborations for long-term gains and exploiting established partnerships for\nimmediate benefits. To address the high initial co-branding costs, our\nframework mitigates redundant exploration, thereby enhancing short-term\nperformance while ensuring sustainable strategic growth. In the offline\noptimization phase, our framework consolidates the interests of multiple\nsub-brands under the same parent brand to maximize overall returns, avoid\nexcessive investment in single sub-brands, and reduce unnecessary costs\nassociated with over-prioritizing a single sub-brand. We present a theoretical\nanalysis of our approach, establishing a highly nontrivial sublinear regret\nbound for online learning in the complex co-branding problem, and enhancing the\napproximation guarantee for the NP-hard offline budget allocation optimization.\nExperiments on both synthetic and real-world co-branding datasets demonstrate\nthe practical effectiveness of our framework, with at least 12\\% improvement.','Xiangxiang Dai, Xiaowei Sun, Jinhang Zuo, Xutong Liu, John C. S. Lui','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22254v1'),('2505.22255v1','Train Sparse Autoencoders Efficiently by Utilizing Features Correlation','Sparse Autoencoders (SAEs) have demonstrated significant promise in\ninterpreting the hidden states of language models by decomposing them into\ninterpretable latent directions. However, training SAEs at scale remains\nchallenging, especially when large dictionary sizes are used. While decoders\ncan leverage sparse-aware kernels for efficiency, encoders still require\ncomputationally intensive linear operations with large output dimensions. To\naddress this, we propose KronSAE, a novel architecture that factorizes the\nlatent representation via Kronecker product decomposition, drastically reducing\nmemory and computational overhead. Furthermore, we introduce mAND, a\ndifferentiable activation function approximating the binary AND operation,\nwhich improves interpretability and performance in our factorized framework.','Vadim Kurochkin, Yaroslav Aksenov, Daniil Laptev, Daniil Gavrilov, Nikita Balagansky','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22255v1'),('2505.22257v1','Revisiting Group Relative Policy Optimization: Insights into On-Policy and Off-Policy Training','We revisit Group Relative Policy Optimization (GRPO) in both on-policy and\noff-policy optimization regimes. Our motivation comes from recent work on\noff-policy Proximal Policy Optimization (PPO), which improves training\nstability, sampling efficiency, and memory usage. In addition, a recent\nanalysis of GRPO suggests that estimating the advantage function with\noff-policy samples could be beneficial. Building on these observations, we\nadapt GRPO to the off-policy setting. We show that both on-policy and\noff-policy GRPO objectives yield an improvement in the reward. This result\nmotivates the use of clipped surrogate objectives in the off-policy version of\nGRPO. We then compare the empirical performance of reinforcement learning with\nverifiable rewards in post-training using both GRPO variants. Our results show\nthat off-policy GRPO either significantly outperforms or performs on par with\nits on-policy counterpart.','Youssef Mroueh, Nicolas Dupuis, Brian Belgodere, Apoorva Nitsure, Mattia Rigotti, Kristjan Greenewald, Jiri Navratil, Jerret Ross, Jesus Rios','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22257v1'),('2505.22258v1','LiDAR Based Semantic Perception for Forklifts in Outdoor Environments','In this study, we present a novel LiDAR-based semantic segmentation framework\ntailored for autonomous forklifts operating in complex outdoor environments.\nCentral to our approach is the integration of a dual LiDAR system, which\ncombines forward-facing and downward-angled LiDAR sensors to enable\ncomprehensive scene understanding, specifically tailored for industrial\nmaterial handling tasks. The dual configuration improves the detection and\nsegmentation of dynamic and static obstacles with high spatial precision. Using\nhigh-resolution 3D point clouds captured from two sensors, our method employs a\nlightweight yet robust approach that segments the point clouds into\nsafety-critical instance classes such as pedestrians, vehicles, and forklifts,\nas well as environmental classes such as driveable ground, lanes, and\nbuildings. Experimental validation demonstrates that our approach achieves high\nsegmentation accuracy while satisfying strict runtime requirements,\nestablishing its viability for safety-aware, fully autonomous forklift\nnavigation in dynamic warehouse and yard environments.','Benjamin Serfling, Hannes Reichert, Lorenzo Bayerlein, Konrad Doll, Kati Radkhah-Lens','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.22258v1'),('2505.22264v1','MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps','In this paper we expose our approach to solve the \\textit{SemEval 2025 Task\n8: Question-Answering over Tabular Data} challenge. Our strategy leverages\nPython code generation with LLMs to interact with the table and get the answer\nto the questions. The process is composed of multiple steps: understanding the\ncontent of the table, generating natural language instructions in the form of\nsteps to follow in order to get the answer, translating these instructions to\ncode, running it and handling potential errors or exceptions. These steps use\nopen source LLMs and fine grained optimized prompts for each task (step). With\nthis approach, we achieved a score of $70.50\\%$ for subtask 1.','Maximiliano Hormazábal Lagos, Álvaro Bueno Saez, Héctor Cerezo-Costas, Pedro Alonso Doval, Jorge Alcalde Vesteiro','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22264v1'),('2505.22271v1','Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models','While (multimodal) large language models (LLMs) have attracted widespread\nattention due to their exceptional capabilities, they remain vulnerable to\njailbreak attacks. Various defense methods are proposed to defend against\njailbreak attacks, however, they are often tailored to specific types of\njailbreak attacks, limiting their effectiveness against diverse adversarial\nstrategies. For instance, rephrasing-based defenses are effective against text\nadversarial jailbreaks but fail to counteract image-based attacks. To overcome\nthese limitations, we propose a universal defense framework, termed Test-time\nIMmunization (TIM), which can adaptively defend against various jailbreak\nattacks in a self-evolving way. Specifically, TIM initially trains a gist token\nfor efficient detection, which it subsequently applies to detect jailbreak\nactivities during inference. When jailbreak attempts are identified, TIM\nimplements safety fine-tuning using the detected jailbreak instructions paired\nwith refusal answers. Furthermore, to mitigate potential performance\ndegradation in the detector caused by parameter updates during safety\nfine-tuning, we decouple the fine-tuning process from the detection module.\nExtensive experiments on both LLMs and multimodal LLMs demonstrate the efficacy\nof TIM.','Yongcan Yu, Yanbo Wang, Ran He, Jian Liang','2025-05-28','cs.CR','http://arxiv.org/pdf/2505.22271v1'),('2505.22273v1','Comprehensive Evaluation on Lexical Normalization: Boundary-Aware Approaches for Unsegmented Languages','Lexical normalization research has sought to tackle the challenge of\nprocessing informal expressions in user-generated text, yet the absence of\ncomprehensive evaluations leaves it unclear which methods excel across multiple\nperspectives. Focusing on unsegmented languages, we make three key\ncontributions: (1) creating a large-scale, multi-domain Japanese normalization\ndataset, (2) developing normalization methods based on state-of-the-art\npretrained models, and (3) conducting experiments across multiple evaluation\nperspectives. Our experiments show that both encoder-only and decoder-only\napproaches achieve promising results in both accuracy and efficiency.','Shohei Higashiyama, Masao Utiyama','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22273v1'),('2505.22275v1','Full Domain Analysis in Fluid Dynamics','Novel techniques in evolutionary optimization, simulation and machine\nlearning allow for a broad analysis of domains like fluid dynamics, in which\ncomputation is expensive and flow behavior is complex. Under the term of full\ndomain analysis we understand the ability to efficiently determine the full\nspace of solutions in a problem domain, and analyze the behavior of those\nsolutions in an accessible and interactive manner. The goal of full domain\nanalysis is to deepen our understanding of domains by generating many examples\nof flow, their diversification, optimization and analysis. We define a formal\nmodel for full domain analysis, its current state of the art, and requirements\nof subcomponents. Finally, an example is given to show what we can learn by\nusing full domain analysis. Full domain analysis, rooted in optimization and\nmachine learning, can be a helpful tool in understanding complex systems in\ncomputational physics and beyond.','Alexander Hagg, Adam Gaier, Dominik Wilde, Alexander Asteroth, Holger Foysi, Dirk Reith','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22275v1'),('2505.22280v1','Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review','Evidence-based medicine (EBM) is at the forefront of modern healthcare,\nemphasizing the use of the best available scientific evidence to guide clinical\ndecisions. Due to the sheer volume and rapid growth of medical literature and\nthe high cost of curation, there is a critical need to investigate Natural\nLanguage Processing (NLP) methods to identify, appraise, synthesize, summarize,\nand disseminate evidence in EBM. This survey presents an in-depth review of 129\nresearch studies on leveraging NLP for EBM, illustrating its pivotal role in\nenhancing clinical decision-making processes. The paper systematically explores\nhow NLP supports the five fundamental steps of EBM -- Ask, Acquire, Appraise,\nApply, and Assess. The review not only identifies current limitations within\nthe field but also proposes directions for future research, emphasizing the\npotential for NLP to revolutionize EBM by refining evidence extraction,\nevidence synthesis, appraisal, summarization, enhancing data comprehensibility,\nand facilitating a more efficient clinical workflow.','Zihan Xu, Haotian Ma, Gongbo Zhang, Yihao Ding, Chunhua Weng, Yifan Peng','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22280v1'),('2505.22287v1','New Tools are Needed for Tracking Adherence to AI Model Behavioral Use Clauses','Foundation models have had a transformative impact on AI. A combination of\nlarge investments in research and development, growing sources of digital data\nfor training, and architectures that scale with data and compute has led to\nmodels with powerful capabilities. Releasing assets is fundamental to\nscientific advancement and commercial enterprise. However, concerns over\nnegligent or malicious uses of AI have led to the design of mechanisms to limit\nthe risks of the technology. The result has been a proliferation of licenses\nwith behavioral-use clauses and acceptable-use-policies that are increasingly\nbeing adopted by commonly used families of models (Llama, Gemma, Deepseek) and\na myriad of smaller projects. We created and deployed a custom AI licenses\ngenerator to facilitate license creation and have quantitatively and\nqualitatively analyzed over 300 customized licenses created with this tool.\nAlongside this we analyzed 1.7 million models licenses on the HuggingFace model\nhub. Our results show increasing adoption of these licenses, interest in tools\nthat support their creation and a convergence on common clause configurations.\nIn this paper we take the position that tools for tracking adoption of, and\nadherence to, these licenses is the natural next step and urgently needed in\norder to ensure they have the desired impact of ensuring responsible use.','Daniel McDuff, Tim Korjakow, Kevin Klyman, Danish Contractor','2025-05-28','cs.CY','http://arxiv.org/pdf/2505.22287v1'),('2505.22288v1','Compression versus Accuracy: A Hierarchy of Lifted Models','Probabilistic graphical models that encode indistinguishable objects and\nrelations among them use first-order logic constructs to compress a\npropositional factorised model for more efficient (lifted) inference. To obtain\na lifted representation, the state-of-the-art algorithm Advanced Colour Passing\n(ACP) groups factors that represent matching distributions. In an approximate\nversion using $\\varepsilon$ as a hyperparameter, factors are grouped that\ndiffer by a factor of at most $(1\\pm \\varepsilon)$. However, finding a suitable\n$\\varepsilon$ is not obvious and may need a lot of exploration, possibly\nrequiring many ACP runs with different $\\varepsilon$ values. Additionally,\nvarying $\\varepsilon$ can yield wildly different models, leading to decreased\ninterpretability. Therefore, this paper presents a hierarchical approach to\nlifted model construction that is hyperparameter-free. It efficiently computes\na hierarchy of $\\varepsilon$ values that ensures a hierarchy of models, meaning\nthat once factors are grouped together given some $\\varepsilon$, these factors\nwill be grouped together for larger $\\varepsilon$ as well. The hierarchy of\n$\\varepsilon$ values also leads to a hierarchy of error bounds. This allows for\nexplicitly weighing compression versus accuracy when choosing specific\n$\\varepsilon$ values to run ACP with and enables interpretability between the\ndifferent models.','Jan Speller, Malte Luttermann, Marcel Gehrke, Tanya Braun','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22288v1'),('2505.22290v1','Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling','Recent research has highlighted that Large Language Models (LLMs), even when\ntrained to generate extended long reasoning steps, still face significant\nchallenges on hard reasoning problems. However, much of the existing literature\nrelies on direct prompting with simple in-context learning examples for\nevaluation, which largely overlooks advanced techniques to elicit LLMs\\\'\ndeliberate reasoning before drawing conclusions that LLMs hit a performance\nceiling. In this paper, we systematically explore the combined potential of\nin-context search and test-time scaling on super hard reasoning tasks. We find\nthat by employing advanced in-context search prompting to LLMs augmented with\ninternal scaling, one can achieve transformative performance breakthroughs on\ntasks previously deemed \"unsolvable\" (e.g., reported success rates below 5%).\nWe provide both empirical results and theoretical analysis of how this\ncombination can unleash LLM reasoning capabilities: i) Empirically, on\ncontrolled NP-hard tasks and complex real-world planning benchmarks, our\napproach achieves up to a 30x improvement in success rates compared to\npreviously reported results without any external mechanisms; ii) Theoretically,\nwe show that in-context search prompting, when combined with internal scaling,\nsignificantly extends the complexity class of solvable reasoning problems.\nThese findings challenge prevailing assumptions about the limitations of LLMs\non complex tasks, indicating that current evaluation paradigms systematically\nunderestimate their true potential. Our work calls for a critical reassessment\nof how LLM reasoning is benchmarked and a more robust evaluation strategy that\nfully captures the true capabilities of contemporary LLMs, which can lead to a\nbetter understanding of their operational reasoning boundaries in real-world\ndeployments.','Fanzeng Xia, Yidong Luo, Tinko Sebastian Bartels, Yaqi Xu, Tongxin Li','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22290v1'),('2505.22291v1','Neural Restoration of Greening Defects in Historical Autochrome Photographs Based on Purely Synthetic Data','The preservation of early visual arts, particularly color photographs, is\nchallenged by deterioration caused by aging and improper storage, leading to\nissues like blurring, scratches, color bleeding, and fading defects. In this\npaper, we present the first approach for the automatic removal of greening\ncolor defects in digitized autochrome photographs. Our main contributions\ninclude a method based on synthetic dataset generation and the use of\ngenerative AI with a carefully designed loss function for the restoration of\nvisual arts. To address the lack of suitable training datasets for analyzing\ngreening defects in damaged autochromes, we introduce a novel approach for\naccurately simulating such defects in synthetic data. We also propose a\nmodified weighted loss function for the ChaIR method to account for color\nimbalances between defected and non-defected areas. While existing methods\nstruggle with accurately reproducing original colors and may require\nsignificant manual effort, our method allows for efficient restoration with\nreduced time requirements.','Saptarshi Neil Sinha, P. Julius Kuehn, Johannes Koppe, Arjan Kuijper, Michael Weinmann','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22291v1'),('2505.22293v1','Compensating for Data with Reasoning: Low-Resource Machine Translation with LLMs','Large Language Models (LLMs) have demonstrated strong capabilities in\nmultilingual machine translation, sometimes even outperforming traditional\nneural systems. However, previous research has highlighted the challenges of\nusing LLMs, particularly with prompt engineering, for low-resource languages.\nIn this work, we introduce Fragment-Shot Prompting, a novel in-context learning\nmethod that segments input and retrieves translation examples based on\nsyntactic coverage, along with Pivoted Fragment-Shot, an extension that enables\ntranslation without direct parallel data. We evaluate these methods using\nGPT-3.5, GPT-4o, o1-mini, LLaMA-3.3, and DeepSeek-R1 for translation between\nItalian and two Ladin variants, revealing three key findings: (1) Fragment-Shot\nPrompting is effective for translating into and between the studied\nlow-resource languages, with syntactic coverage positively correlating with\ntranslation quality; (2) Models with stronger reasoning abilities make more\neffective use of retrieved knowledge, generally produce better translations,\nand enable Pivoted Fragment-Shot to significantly improve translation quality\nbetween the Ladin variants; and (3) prompt engineering offers limited, if any,\nimprovements when translating from a low-resource to a high-resource language,\nwhere zero-shot prompting already yields satisfactory results. We publicly\nrelease our code and the retrieval corpora.','Samuel Frontull, Thomas Ströhle','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22293v1'),('2505.22296v1','360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long Post-Training','Adding sequence parallelism into LLaMA-Factory, we open-sourced\n360-LLaMA-Factory at https://github.com/Qihoo360/360-LLaMA-Factory.\n360-LLaMA-Factory has received wide recognition and used in models such as\nLight-R1 arXiv:2503.10460, TinyR1 arXiv:2503.04872, Kaggle AIMO math models and\nalso in large companies\\\' training frameworks. This technical report delves\ndeeper into the different sequence parallel modes behind 360-LLaMA-Factory and\ndiscusses our implementation insights.','Haosheng Zou, Xiaowei Lv, Shousheng Jia, Xiangzheng Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22296v1'),('2505.22298v1','Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing','Large language models (LLMs) exhibit impressive language capabilities but\nremain vulnerable to malicious prompts and jailbreaking attacks. Existing\nknowledge editing methods for LLM detoxification face two major challenges.\nFirst, they often rely on entity-specific localization, making them ineffective\nagainst adversarial inputs without explicit entities. Second, these methods\nsuffer from over-editing, where detoxified models reject legitimate queries,\ncompromising overall performance. In this paper, we propose ToxEdit, a\ntoxicity-aware knowledge editing approach that dynamically detects toxic\nactivation patterns during forward propagation. It then routes computations\nthrough adaptive inter-layer pathways to mitigate toxicity effectively. This\ndesign ensures precise toxicity mitigation while preserving LLMs\\\' general\ncapabilities. To more accurately assess over-editing, we also enhance the\nSafeEdit benchmark by incorporating instruction-following evaluation tasks.\nExperimental results on multiple LLMs demonstrate that our ToxEdit outperforms\nprevious state-of-the-art methods in both detoxification performance and\nsafeguarding general capabilities of LLMs.','Yifan Lu, Jing Li, Yigeng Zhou, Yihui Zhang, Wenya Wang, Xiucheng Li, Meishan Zhang, Fangming Liu, Jun Yu, Min Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22298v1'),('2505.22303v1','Voice CMS: updating the knowledge base of a digital assistant through conversation','In this study, we propose a solution based on a multi-agent LLM architecture\nand a voice user interface (VUI) designed to update the knowledge base of a\ndigital assistant. Its usability is evaluated in comparison to a more\ntraditional graphical content management system (CMS), with a focus on\nunderstanding the relationship between user preferences and the complexity of\nthe information being provided. The findings demonstrate that, while the\noverall usability of the VUI is rated lower than the graphical interface, it is\nalready preferred by users for less complex tasks. Furthermore, the quality of\ncontent entered through the VUI is comparable to that achieved with the\ngraphical interface, even for highly complex tasks. Obtained qualitative\nresults suggest that a hybrid interface combining the strengths of both\napproaches could address the key challenges identified during the experiment,\nsuch as reducing cognitive load through graphical feedback while maintaining\nthe intuitive nature of voice-based interactions. This work highlights the\npotential of conversational interfaces as a viable and effective method for\nknowledge management in specific business contexts.','Grzegorz Wolny, Michał Szczerbak','2025-05-28','cs.HC','http://arxiv.org/pdf/2505.22303v1'),('2505.22306v1','Versatile Cardiovascular Signal Generation with a Unified Diffusion Transformer','Cardiovascular signals such as photoplethysmography (PPG),\nelectrocardiography (ECG), and blood pressure (BP) are inherently correlated\nand complementary, together reflecting the health of cardiovascular system.\nHowever, their joint utilization in real-time monitoring is severely limited by\ndiverse acquisition challenges from noisy wearable recordings to burdened\ninvasive procedures. Here we propose UniCardio, a multi-modal diffusion\ntransformer that reconstructs low-quality signals and synthesizes unrecorded\nsignals in a unified generative framework. Its key innovations include a\nspecialized model architecture to manage the signal modalities involved in\ngeneration tasks and a continual learning paradigm to incorporate varying\nmodality combinations. By exploiting the complementary nature of cardiovascular\nsignals, UniCardio clearly outperforms recent task-specific baselines in signal\ndenoising, imputation, and translation. The generated signals match the\nperformance of ground-truth signals in detecting abnormal health conditions and\nestimating vital signs, even in unseen domains, while ensuring interpretability\nfor human experts. These advantages position UniCardio as a promising avenue\nfor advancing AI-assisted healthcare.','Zehua Chen, Yuyang Miao, Liyuan Wang, Luyun Fan, Danilo P. Mandic, Jun Zhu','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22306v1'),('2505.22308v1','Transformers Pretrained on Procedural Data Contain Modular Structures for Algorithmic Reasoning','Pretraining on large, semantically rich datasets is key for developing\nlanguage models. Surprisingly, recent studies have shown that even synthetic\ndata, generated procedurally through simple semantic-free algorithms, can yield\nsome of the same benefits as natural language pretraining. It is unclear what\nspecific capabilities such simple synthetic data instils in a model, where\nthese capabilities reside in the architecture, and how they manifest within its\nweights. In this short paper, we identify several beneficial forms of\nprocedural data, together with specific algorithmic reasoning skills that\nimprove in small transformers. Our core finding is that different procedural\nrules instil distinct but complementary inductive structures in the model. With\nextensive ablations and partial-transfer experiments, we discover that these\nstructures reside in different parts of the model. Attention layers often carry\nthe most transferable information, but some pretraining rules impart useful\nstructure to MLP blocks instead. Most interestingly, the structures induced by\nmultiple rules can be composed to jointly reinforce multiple capabilities.\nThese results suggest an exciting possibility of disentangling the acquisition\nof knowledge from reasoning in language models, with the goal of improving\ntheir robustness and data efficiency.','Zachary Shinnick, Liangze Jiang, Hemanth Saratchandran, Anton van den Hengel, Damien Teney','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22308v1'),('2505.22310v1','From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization','Recent unlearning methods for LLMs are vulnerable to relearning attacks:\nknowledge believed-to-be-unlearned re-emerges by fine-tuning on a small set of\n(even seemingly-unrelated) examples. We study this phenomenon in a controlled\nsetting for example-level unlearning in vision classifiers. We make the\nsurprising discovery that forget-set accuracy can recover from around 50%\npost-unlearning to nearly 100% with fine-tuning on just the retain set -- i.e.,\nzero examples of the forget set. We observe this effect across a wide variety\nof unlearning methods, whereas for a model retrained from scratch excluding the\nforget set (gold standard), the accuracy remains at 50%. We observe that\nresistance to relearning attacks can be predicted by weight-space properties,\nspecifically, $L_2$-distance and linear mode connectivity between the original\nand the unlearned model. Leveraging this insight, we propose a new class of\nmethods that achieve state-of-the-art resistance to relearning attacks.','Shoaib Ahmed Siddiqui, Adrian Weller, David Krueger, Gintare Karolina Dziugaite, Michael Curtis Mozer, Eleni Triantafillou','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22310v1'),('2505.22311v1','From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications','With the advent of 6G communications, intelligent communication systems face\nmultiple challenges, including constrained perception and response\ncapabilities, limited scalability, and low adaptability in dynamic\nenvironments. This tutorial provides a systematic introduction to the\nprinciples, design, and applications of Large Artificial Intelligence Models\n(LAMs) and Agentic AI technologies in intelligent communication systems, aiming\nto offer researchers a comprehensive overview of cutting-edge technologies and\npractical guidance. First, we outline the background of 6G communications,\nreview the technological evolution from LAMs to Agentic AI, and clarify the\ntutorial\\\'s motivation and main contributions. Subsequently, we present a\ncomprehensive review of the key components required for constructing LAMs. We\nfurther categorize LAMs and analyze their applicability, covering Large\nLanguage Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models\n(LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a\nLAM-centric design paradigm tailored for communications, encompassing dataset\nconstruction and both internal and external learning approaches. Building upon\nthis, we develop an LAM-based Agentic AI system for intelligent communications,\nclarifying its core components such as planners, knowledge bases, tools, and\nmemory modules, as well as its interaction mechanisms. We also introduce a\nmulti-agent framework with data retrieval, collaborative planning, and\nreflective evaluation for 6G. Subsequently, we provide a detailed overview of\nthe applications of LAMs and Agentic AI in communication scenarios. Finally, we\nsummarize the research challenges and future directions in current studies,\naiming to support the development of efficient, secure, and sustainable\nnext-generation intelligent communication systems.','Feibo Jiang, Cunhua Pan, Li Dong, Kezhi Wang, Octavia A. Dobre, Merouane Debbah','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22311v1'),('2505.22312v1','Skywork Open Reasoner 1 Technical Report','The success of DeepSeek-R1 underscores the significant role of reinforcement\nlearning (RL) in enhancing the reasoning capabilities of large language models\n(LLMs). In this work, we present Skywork-OR1, an effective and scalable RL\nimplementation for long Chain-of-Thought (CoT) models. Building on the\nDeepSeek-R1-Distill model series, our RL approach achieves notable performance\ngains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench\nfrom 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%)\nfor the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and\nQwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable\nresults on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models\ndemonstrate competitive reasoning capabilities among models of similar size. We\nperform comprehensive ablation studies on the core components of our training\npipeline to validate their effectiveness. Additionally, we thoroughly\ninvestigate the phenomenon of entropy collapse, identify key factors affecting\nentropy dynamics, and demonstrate that mitigating premature entropy collapse is\ncritical for improved test performance. To support community research, we fully\nopen-source our model weights, training code, and training datasets.','Jujie He, Jiacai Liu, Chris Yuhao Liu, Rui Yan, Chaojie Wang, Peng Cheng, Xiaoyu Zhang, Fuxiang Zhang, Jiacheng Xu, Wei Shen, Siyuan Li, Liang Zeng, Tianwen Wei, Cheng Cheng, Bo An, Yang Liu, Yahui Zhou','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22312v1'),('2505.22316v1','Rethinking BPS: A Utility-Based Evaluation Framework','Business process simulation (BPS) is a key tool for analyzing and optimizing\norganizational workflows, supporting decision-making by estimating the impact\nof process changes. The reliability of such estimates depends on the ability of\na BPS model to accurately mimic the process under analysis, making rigorous\naccuracy evaluation essential. However, the state-of-the-art approach to\nevaluating BPS models has two key limitations. First, it treats simulation as a\nforecasting problem, testing whether models can predict unseen future events.\nThis fails to assess how well a model captures the as-is process, particularly\nwhen process behavior changes from train to test period. Thus, it becomes\ndifficult to determine whether poor results stem from an inaccurate model or\nthe inherent complexity of the data, such as unpredictable drift. Second, the\nevaluation approach strongly relies on Earth Mover\\\'s Distance-based metrics,\nwhich can obscure temporal patterns and thus yield misleading conclusions about\nsimulation quality. To address these issues, we propose a novel framework that\nevaluates simulation quality based on its ability to generate representative\nprocess behavior. Instead of comparing simulated logs to future real-world\nexecutions, we evaluate whether predictive process monitoring models trained on\nsimulated data perform comparably to those trained on real data for downstream\nanalysis tasks. Empirical results show that our framework not only helps\nidentify sources of discrepancies but also distinguishes between model accuracy\nand data complexity, offering a more meaningful way to assess BPS quality.','Konrad Özdemir, Lukas Kirchdorfer, Keyvan Amiri Elyasi, Han van der Aa, Heiner Stuckenschmidt','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22316v1'),('2505.22318v1','If Pigs Could Fly... Can LLMs Logically Reason Through Counterfactuals?','Large Language Models (LLMs) demonstrate impressive reasoning capabilities in\nfamiliar contexts, but struggle when the context conflicts with their\nparametric knowledge. To investigate this phenomenon, we introduce\nCounterLogic, a dataset containing 1,800 examples across 9 logical schemas,\nexplicitly designed to evaluate logical reasoning through counterfactual\n(hypothetical knowledge-conflicting) scenarios. Our systematic evaluation of 11\nLLMs across 6 different datasets reveals a consistent performance degradation,\nwith accuracies dropping by 27% on average when reasoning through\ncounterfactual information. We propose Self-Segregate, a prompting method\nenabling metacognitive awareness (explicitly identifying knowledge conflicts)\nbefore reasoning. Our method dramatically narrows the average performance gaps\nfrom 27% to just 11%, while significantly increasing the overall accuracy\n(+7.5%). We discuss the implications of these findings and draw parallels to\nhuman cognitive processes, particularly on how humans disambiguate conflicting\ninformation during reasoning tasks. Our findings offer practical insights for\nunderstanding and enhancing LLMs reasoning capabilities in real-world\napplications, especially where models must logically reason independently of\ntheir factual knowledge.','Ishwar B Balappanawar, Vamshi Krishna Bonagiri, Anish R Joishy, Manas Gaur, Krishnaprasad Thirunarayan, Ponnurangam Kumaraguru','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22318v1'),('2505.22322v1','A Closer Look on Memorization in Tabular Diffusion Model: A Data-Centric Perspective','Diffusion models have shown strong performance in generating high-quality\ntabular data, but they carry privacy risks by reproducing exact training\nsamples. While prior work focuses on dataset-level augmentation to reduce\nmemorization, little is known about which individual samples contribute most.\nWe present the first data-centric study of memorization dynamics in tabular\ndiffusion models. We quantify memorization for each real sample based on how\nmany generated samples are flagged as replicas, using a relative distance\nratio. Our empirical analysis reveals a heavy-tailed distribution of\nmemorization counts: a small subset of samples contributes disproportionately\nto leakage, confirmed via sample-removal experiments. To understand this, we\ndivide real samples into top- and non-top-memorized groups and analyze their\ntraining-time behaviors. We track when each sample is first memorized and\nmonitor per-epoch memorization intensity (AUC). Memorized samples are memorized\nslightly earlier and show stronger signals in early training. Based on these\ninsights, we propose DynamicCut, a two-stage, model-agnostic mitigation method:\n(a) rank samples by epoch-wise intensity, (b) prune a tunable top fraction, and\n(c) retrain on the filtered dataset. Across multiple tabular datasets and\nmodels, DynamicCut reduces memorization with minimal impact on data diversity\nand downstream performance. It also complements augmentation-based defenses.\nFurthermore, DynamicCut enables cross-model transferability: high-ranked\nsamples identified from one model (e.g., a diffusion model) are also effective\nfor reducing memorization when removed from others, such as GANs and VAEs.','Zhengyu Fang, Zhimeng Jiang, Huiyuan Chen, Xiaoge Zhang, Kaiyu Tang, Xiao Li, Jing Li','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22322v1'),('2505.22323v1','Advancing Expert Specialization for Better MoE','Mixture-of-Experts (MoE) models enable efficient scaling of large language\nmodels (LLMs) by activating only a subset of experts per input. However, we\nobserve that the commonly used auxiliary load balancing loss often leads to\nexpert overlap and overly uniform routing, which hinders expert specialization\nand degrades overall performance during post-training. To address this, we\npropose a simple yet effective solution that introduces two complementary\nobjectives: (1) an orthogonality loss to encourage experts to process distinct\ntypes of tokens, and (2) a variance loss to encourage more discriminative\nrouting decisions. Gradient-level analysis demonstrates that these objectives\nare compatible with the existing auxiliary loss and contribute to optimizing\nthe training process. Experimental results over various model architectures and\nacross multiple benchmarks show that our method significantly enhances expert\nspecialization. Notably, our method improves classic MoE baselines with\nauxiliary loss by up to 23.79%, while also maintaining load balancing in\ndownstream tasks, without any architectural modifications or additional\ncomponents. We will release our code to contribute to the community.','Hongcan Guo, Haolang Lu, Guoshun Nan, Bolun Chu, Jialin Zhuang, Yuan Yang, Wenhao Che, Sicong Leng, Qimei Cui, Xudong Jiang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22323v1'),('2505.22326v1','Individualised Counterfactual Examples Using Conformal Prediction Intervals','Counterfactual explanations for black-box models aim to pr ovide insight into\nan algorithmic decision to its recipient. For a binary classification problem\nan individual counterfactual details which features might be changed for the\nmodel to infer the opposite class. High-dimensional feature spaces that are\ntypical of machine learning classification models admit many possible\ncounterfactual examples to a decision, and so it is important to identify\nadditional criteria to select the most useful counterfactuals. In this paper,\nwe explore the idea that the counterfactuals should be maximally informative\nwhen considering the knowledge of a specific individual about the underlying\nclassifier. To quantify this information gain we explicitly model the knowledge\nof the individual, and assess the uncertainty of predictions which the\nindividual makes by the width of a conformal prediction interval. Regions of\nfeature space where the prediction interval is wide correspond to areas where\nthe confidence in decision making is low, and an additional counterfactual\nexample might be more informative to an individual. To explore and evaluate our\nindividualised conformal prediction interval counterfactuals (CPICFs), first we\npresent a synthetic data set on a hypercube which allows us to fully visualise\nthe decision boundary, conformal intervals via three different methods, and\nresultant CPICFs. Second, in this synthetic data set we explore the impact of a\nsingle CPICF on the knowledge of an individual locally around the original\nquery. Finally, in both our synthetic data set and a complex real world dataset\nwith a combination of continuous and discrete variables, we measure the utility\nof these counterfactuals via data augmentation, testing the performance on a\nheld out set.','James M. Adams, Gesine Reinert, Lukasz Szpruch, Carsten Maple, Andrew Elliott','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22326v1'),('2505.22327v1','NLP for Social Good: A Survey of Challenges, Opportunities, and Responsible Deployment','Recent advancements in large language models (LLMs) have unlocked\nunprecedented possibilities across a range of applications. However, as a\ncommunity, we believe that the field of Natural Language Processing (NLP) has a\ngrowing need to approach deployment with greater intentionality and\nresponsibility. In alignment with the broader vision of AI for Social Good\n(Toma\\v{s}ev et al., 2020), this paper examines the role of NLP in addressing\npressing societal challenges. Through a cross-disciplinary analysis of social\ngoals and emerging risks, we highlight promising research directions and\noutline challenges that must be addressed to ensure responsible and equitable\nprogress in NLP4SG research.','Antonia Karamolegkou, Angana Borah, Eunjung Cho, Sagnik Ray Choudhury, Martina Galletti, Rajarshi Ghosh, Pranav Gupta, Oana Ignat, Priyanka Kargupta, Neema Kotonya, Hemank Lamba, Sun-Joo Lee, Arushi Mangla, Ishani Mondal, Deniz Nazarova, Poli Nemkova, Dina Pisarevskaya, Naquee Rizwan, Nazanin Sabri, Dominik Stammbach, Anna Steinberg, David Tomás, Steven R Wilson, Bowen Yi, Jessica H Zhu, Arkaitz Zubiaga, Anders Søgaard, Alexander Fraser, Zhijing Jin, Rada Mihalcea, Joel R. Tetreault, Daryna Dementieva','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22327v1'),('2505.22332v1','Credal Prediction based on Relative Likelihood','Predictions in the form of sets of probability distributions, so-called\ncredal sets, provide a suitable means to represent a learner\\\'s epistemic\nuncertainty. In this paper, we propose a theoretically grounded approach to\ncredal prediction based on the statistical notion of relative likelihood: The\ntarget of prediction is the set of all (conditional) probability distributions\nproduced by the collection of plausible models, namely those models whose\nrelative likelihood exceeds a specified threshold. This threshold has an\nintuitive interpretation and allows for controlling the trade-off between\ncorrectness and precision of credal predictions. We tackle the problem of\napproximating credal sets defined in this way by means of suitably modified\nensemble learning techniques. To validate our approach, we illustrate its\neffectiveness by experiments on benchmark datasets demonstrating superior\nuncertainty representation without compromising predictive performance. We also\ncompare our method against several state-of-the-art baselines in credal\nprediction.','Timo Löhr, Paul Hofman, Felix Mohr, Eyke Hüllermeier','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22332v1'),('2505.22334v1','Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start','Recent advancements in large language models (LLMs) have demonstrated\nimpressive chain-of-thought reasoning capabilities, with reinforcement learning\n(RL) playing a crucial role in this progress. While \"aha moment\"\npatterns--where models exhibit self-correction through reflection--are often\nattributed to emergent properties from RL, we first demonstrate that these\npatterns exist in multimodal LLMs (MLLMs) prior to RL training but may not\nnecessarily correlate with improved reasoning performance. Building on these\ninsights, we present a comprehensive study on enhancing multimodal reasoning\nthrough a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start\nwith structured chain-of-thought reasoning patterns, followed by (2)\nreinforcement learning via GRPO to further refine these capabilities. Our\nextensive experiments show that this combined approach consistently outperforms\nboth SFT-only and RL-only methods across challenging multimodal reasoning\nbenchmarks. The resulting models achieve state-of-the-art performance among\nopen-source MLLMs at both 3B and 7B scales, with our 7B model showing\nsubstantial improvements over base models (e.g., 66.3 %$\\rightarrow$73.4 % on\nMathVista, 62.9 %$\\rightarrow$70.4 % on We-Math) and our 3B model achieving\nperformance competitive with several 7B models. Overall, this work provides\npractical guidance for building advanced multimodal reasoning models. Our code\nis available at https://github.com/waltonfuture/RL-with-Cold-Start.','Lai Wei, Yuting Li, Kaipeng Zheng, Chen Wang, Yue Wang, Linghe Kong, Lichao Sun, Weiran Huang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22334v1'),('2505.22338v1','Text2Grad: Reinforcement Learning from Natural Language Feedback','Traditional RLHF optimizes language models with coarse, scalar rewards that\nmask the fine-grained reasons behind success or failure, leading to slow and\nopaque learning. Recent work augments RL with textual critiques through\nprompting or reflection, improving interpretability but leaving model\nparameters untouched. We introduce Text2Grad, a reinforcement-learning paradigm\nthat turns free-form textual feedback into span-level gradients. Given human\n(or programmatic) critiques, Text2Grad aligns each feedback phrase with the\nrelevant token spans, converts these alignments into differentiable reward\nsignals, and performs gradient updates that directly refine the offending\nportions of the model\\\'s policy. This yields precise, feedback-conditioned\nadjustments instead of global nudges. Text2Grad is realized through three\ncomponents: (1) a high-quality feedback-annotation pipeline that pairs\ncritiques with token spans; (2) a fine-grained reward model that predicts\nspan-level reward on answer while generating explanatory critiques; and (3) a\nspan-level policy optimizer that back-propagates natural-language gradients.\nAcross summarization, code generation, and question answering, Text2Grad\nconsistently surpasses scalar-reward RL and prompt-only baselines, providing\nboth higher task metrics and richer interpretability. Our results demonstrate\nthat natural-language feedback, when converted to gradients, is a powerful\nsignal for fine-grained policy optimization. The code for our method is\navailable at https://github.com/microsoft/Text2Grad','Hanyang Wang, Lu Wang, Chaoyun Zhang, Tianjun Mao, Si Qin, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22338v1'),('2505.22342v1','Progressive Data Dropout: An Embarrassingly Simple Approach to Faster Training','The success of the machine learning field has reliably depended on training\non large datasets. While effective, this trend comes at an extraordinary cost.\nThis is due to two deeply intertwined factors: the size of models and the size\nof datasets. While promising research efforts focus on reducing the size of\nmodels, the other half of the equation remains fairly mysterious. Indeed, it is\nsurprising that the standard approach to training remains to iterate over and\nover, uniformly sampling the training dataset. In this paper we explore a\nseries of alternative training paradigms that leverage insights from\nhard-data-mining and dropout, simple enough to implement and use that can\nbecome the new training standard. The proposed Progressive Data Dropout reduces\nthe number of effective epochs to as little as 12.4% of the baseline. This\nsavings actually do not come at any cost for accuracy. Surprisingly, the\nproposed method improves accuracy by up to 4.82%. Our approach requires no\nchanges to model architecture or optimizer, and can be applied across standard\ntraining pipelines, thus posing an excellent opportunity for wide adoption.\nCode can be found here: https://github.com/bazyagami/LearningWithRevision','Shriram M S, Xinyue Hao, Shihao Hou, Yang Lu, Laura Sevilla-Lara, Anurag Arnab, Shreyank N Gowda','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22342v1'),('2505.22343v1','Empowering Intelligent Low-altitude Economy with Large AI Model Deployment','Low-altitude economy (LAE) represents an emerging economic paradigm that\nredefines commercial and social aerial activities. Large artificial\nintelligence models (LAIMs) offer transformative potential to further enhance\nthe intelligence of LAE services. However, deploying LAIMs in LAE poses several\nchallenges, including the significant gap between their computational/storage\ndemands and the limited onboard resources of LAE entities, the mismatch between\nlab-trained LAIMs and dynamic physical environments, and the inefficiencies of\ntraditional decoupled designs for sensing, communication, and computation. To\naddress these issues, we first propose a hierarchical system architecture\ntailored for LAIM deployment and present representative LAE application\nscenarios. Next, we explore key enabling techniques that facilitate the mutual\nco-evolution of LAIMs and low-altitude systems, and introduce a task-oriented\nexecution pipeline for scalable and adaptive service delivery. Then, the\nproposed framework is validated through real-world case studies. Finally, we\noutline open challenges to inspire future research.','Zhonghao Lyu, Yulan Gao, Junting Chen, Hongyang Du, Jie Xu, Kaibin Huang, Dong In Kim','2025-05-28','eess.SP','http://arxiv.org/pdf/2505.22343v1'),('2505.22349v1','ChatPD: An LLM-driven Paper-Dataset Networking System','Scientific research heavily depends on suitable datasets for method\nvalidation, but existing academic platforms with dataset management like\nPapersWithCode suffer from inefficiencies in their manual workflow. To overcome\nthis bottleneck, we present a system, called ChatPD, that utilizes Large\nLanguage Models (LLMs) to automate dataset information extraction from academic\npapers and construct a structured paper-dataset network. Our system consists of\nthree key modules: \\textit{paper collection}, \\textit{dataset information\nextraction}, and \\textit{dataset entity resolution} to construct paper-dataset\nnetworks. Specifically, we propose a \\textit{Graph Completion and Inference}\nstrategy to map dataset descriptions to their corresponding entities. Through\nextensive experiments, we demonstrate that ChatPD not only outperforms the\nexisting platform PapersWithCode in dataset usage extraction but also achieves\nabout 90\\% precision and recall in entity resolution tasks. Moreover, we have\ndeployed ChatPD to continuously extract which datasets are used in papers, and\nprovide a dataset discovery service, such as task-specific dataset queries and\nsimilar dataset recommendations. We open source ChatPD and the current\npaper-dataset network on this [GitHub\nrepository]{https://github.com/ChatPD-web/ChatPD}.','Anjie Xu, Ruiqing Ding, Leye Wang','2025-05-28','cs.DB','http://arxiv.org/pdf/2505.22349v1'),('2505.22353v1','VME: A Satellite Imagery Dataset and Benchmark for Detecting Vehicles in the Middle East and Beyond','Detecting vehicles in satellite images is crucial for traffic management,\nurban planning, and disaster response. However, current models struggle with\nreal-world diversity, particularly across different regions. This challenge is\namplified by geographic bias in existing datasets, which often focus on\nspecific areas and overlook regions like the Middle East. To address this gap,\nwe present the Vehicles in the Middle East (VME) dataset, designed explicitly\nfor vehicle detection in high-resolution satellite images from Middle Eastern\ncountries. Sourced from Maxar, the VME dataset spans 54 cities across 12\ncountries, comprising over 4,000 image tiles and more than 100,000 vehicles,\nannotated using both manual and semi-automated methods. Additionally, we\nintroduce the largest benchmark dataset for Car Detection in Satellite Imagery\n(CDSI), combining images from multiple sources to enhance global car detection.\nOur experiments demonstrate that models trained on existing datasets perform\npoorly on Middle Eastern images, while the VME dataset significantly improves\ndetection accuracy in this region. Moreover, state-of-the-art models trained on\nCDSI achieve substantial improvements in global car detection.','Noora Al-Emadi, Ingmar Weber, Yin Yang, Ferda Ofli','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22353v1'),('2505.22354v1','LLMs Struggle to Reject False Presuppositions when Misinformation Stakes are High','This paper examines how LLMs handle false presuppositions and whether certain\nlinguistic factors influence their responses to falsely presupposed content.\nPresuppositions subtly introduce information as given, making them highly\neffective at embedding disputable or false information. This raises concerns\nabout whether LLMs, like humans, may fail to detect and correct misleading\nassumptions introduced as false presuppositions, even when the stakes of\nmisinformation are high. Using a systematic approach based on linguistic\npresupposition analysis, we investigate the conditions under which LLMs are\nmore or less sensitive to adopt or reject false presuppositions. Focusing on\npolitical contexts, we examine how factors like linguistic construction,\npolitical party, and scenario probability impact the recognition of false\npresuppositions. We conduct experiments with a newly created dataset and\nexamine three LLMs: OpenAI\\\'s GPT-4-o, Meta\\\'s LLama-3-8B, and MistralAI\\\'s\nMistral-7B-v03. Our results show that the models struggle to recognize false\npresuppositions, with performance varying by condition. This study highlights\nthat linguistic presupposition analysis is a valuable tool for uncovering the\nreinforcement of political misinformation in LLM responses.','Judith Sieker, Clara Lachenmaier, Sina Zarrieß','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22354v1'),('2505.22355v1','Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning','Parameter-Efficient Fine-Tuning (PEFT) methods achieve performance comparable\nto Full Fine-Tuning (FFT) while requiring significantly fewer computing\nresources, making it the go-to choice for researchers. We find that although\nPEFT can achieve competitive results on some benchmarks, its performance falls\nshort of FFT in complex tasks, such as reasoning and instruction-based\nfine-tuning. In this paper, we compare the characteristics of PEFT and FFT in\nterms of representational capacity and robustness based on optimization theory.\nWe theoretically demonstrate that PEFT is a strict subset of FFT. By providing\ntheoretical upper bounds for PEFT, we show that the limited parameter space\nconstrains the model\\\'s representational ability, making it more susceptible to\nperturbations. Experiments on 15 datasets encompassing classification,\ngeneration, reasoning, instruction fine-tuning tasks and 11 adversarial test\nsets validate our theories. We hope that these results spark further research\nbeyond the realms of well established PEFT. The source code is in the anonymous\nGithub repository\\footnote{https://github.com/misonsky/PEFTEval}.','Yongkang Liu, Xingle Xu, Ercong Nie, Zijing Wang, Shi Feng, Daling Wang, Qian Li, Hinrich Schütze','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22355v1'),('2505.22356v1','Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings','Deploying machine learning models in safety-critical domains poses a key\nchallenge: ensuring reliable model performance on downstream user data without\naccess to ground truth labels for direct validation. We propose the suitability\nfilter, a novel framework designed to detect performance deterioration by\nutilizing suitability signals -- model output features that are sensitive to\ncovariate shifts and indicative of potential prediction errors. The suitability\nfilter evaluates whether classifier accuracy on unlabeled user data shows\nsignificant degradation compared to the accuracy measured on the labeled test\ndataset. Specifically, it ensures that this degradation does not exceed a\npre-specified margin, which represents the maximum acceptable drop in accuracy.\nTo achieve reliable performance evaluation, we aggregate suitability signals\nfor both test and user data and compare these empirical distributions using\nstatistical hypothesis testing, thus providing insights into decision\nuncertainty. Our modular method adapts to various models and domains. Empirical\nevaluations across different classification tasks demonstrate that the\nsuitability filter reliably detects performance deviations due to covariate\nshift. This enables proactive mitigation of potential failures in high-stakes\napplications.','Angéline Pouget, Mohammad Yaghini, Stephan Rabanser, Nicolas Papernot','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22356v1'),('2505.22358v1','Budget-Adaptive Adapter Tuning in Orthogonal Subspaces for Continual Learning in LLMs','Large language models (LLMs) often suffer from catastrophic forgetting in\ncontinual learning (CL) scenarios, where performance on previously learned\ntasks degrades severely while training on sequentially arriving tasks. Although\npioneering CL approaches using orthogonal subspaces can mitigate task\ninterference, they typically employ fixed budget allocation, neglecting the\nvarying complexity across tasks and layers. Besides, recent budget-adaptive\ntuning methods for LLMs often adopt multi-stage paradigms that decouple\noptimization and budget allocation. Such decoupling results in potential\nmisalignment, which hinders those approaches\\\' practical application in CL\nscenarios. To address these limitations, we propose OA-Adapter, a novel\nparameter-efficient approach for continual learning in LLMs that unifies\ndynamic budget adaptation with orthogonal subspace learning in a single\nend-to-end training stage. Specifically, OA-Adapter introduces a dynamic\nbottleneck dimension adaptation mechanism that simultaneously allocates an\nefficient parameter budget and optimizes task objectives without misalignment.\nTo effectively preserve previously acquired knowledge while coordinating with\nthe dynamic budget allocation, orthogonal constraints are applied specifically\nbetween the parameter subspace of the current task and the dynamically\nallocated parameter subspaces of historical tasks. Experimental results on\ncontinual learning benchmarks demonstrate that OA-Adapter outperforms\nstate-of-the-art methods in both accuracy and parameter efficiency, achieving\nhigher average accuracy while using 58.5% fewer parameters on the standard CL\nbenchmark.','Zhiyi Wan, Wanrou Du, Liang Li, Miao Pan, Xiaoqi Qin','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22358v1'),('2505.22359v1','Multiclass Loss Geometry Matters for Generalization of Gradient Descent in Separable Classification','We study the generalization performance of unregularized gradient methods for\nseparable linear classification. While previous work mostly deal with the\nbinary case, we focus on the multiclass setting with $k$ classes and establish\nnovel population risk bounds for Gradient Descent for loss functions that decay\nto zero. In this setting, we show risk bounds that reveal that convergence\nrates are crucially influenced by the geometry of the loss template, as\nformalized by Wang and Scott (2024), rather than of the loss function itself.\nParticularly, we establish risk upper bounds that holds for any decay rate of\nthe loss whose template is smooth with respect to the $p$-norm. In the case of\nexponentially decaying losses, our results indicates a contrast between the\n$p=\\infty$ case, where the risk exhibits a logarithmic dependence on $k$, and\n$p=2$ where the risk scales linearly with $k$. To establish this separation\nformally, we also prove a lower bound in the latter scenario, demonstrating\nthat the polynomial dependence on $k$ is unavoidable. Central to our analysis\nis a novel bound on the Rademacher complexity of low-noise vector-valued linear\npredictors with a loss template smooth w.r.t.~general $p$-norms.','Matan Schliserman, Tomer Koren','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22359v1'),('2505.22361v1','Continuum-armed Bandit Optimization with Batch Pairwise Comparison Oracles','This paper studies a bandit optimization problem where the goal is to\nmaximize a function $f(x)$ over $T$ periods for some unknown strongly concave\nfunction $f$. We consider a new pairwise comparison oracle, where the\ndecision-maker chooses a pair of actions $(x, x\\\')$ for a consecutive number of\nperiods and then obtains an estimate of $f(x)-f(x\\\')$. We show that such a\npairwise comparison oracle finds important applications to joint pricing and\ninventory replenishment problems and network revenue management. The challenge\nin this bandit optimization is twofold. First, the decision-maker not only\nneeds to determine a pair of actions $(x, x\\\')$ but also a stopping time $n$\n(i.e., the number of queries based on $(x, x\\\')$). Second, motivated by our\ninventory application, the estimate of the difference $f(x)-f(x\\\')$ is biased,\nwhich is different from existing oracles in stochastic optimization literature.\nTo address these challenges, we first introduce a discretization technique and\nlocal polynomial approximation to relate this problem to linear bandits. Then\nwe developed a tournament successive elimination technique to localize the\ndiscretized cell and run an interactive batched version of LinUCB algorithm on\ncells. We establish regret bounds that are optimal up to poly-logarithmic\nfactors. Furthermore, we apply our proposed algorithm and analytical framework\nto the two operations management problems and obtain results that improve\nstate-of-the-art results in the existing literature.','Xiangyu Chang, Xi Chen, Yining Wang, Zhiyi Zeng','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22361v1'),('2505.22362v1','Directed Homophily-Aware Graph Neural Network','Graph Neural Networks (GNNs) have achieved significant success in various\nlearning tasks on graph-structured data. Nevertheless, most GNNs struggle to\ngeneralize to heterophilic neighborhoods. Additionally, many GNNs ignore the\ndirectional nature of real-world graphs, resulting in suboptimal performance on\ndirected graphs with asymmetric structures. In this work, we propose Directed\nHomophily-aware Graph Neural Network (DHGNN), a novel framework that addresses\nthese limitations by incorporating homophily-aware and direction-sensitive\ncomponents. DHGNN employs a resettable gating mechanism to adaptively modulate\nmessage contributions based on homophily levels and informativeness, and a\nstructure-aware noise-tolerant fusion module to effectively integrate node\nrepresentations from the original and reverse directions. Extensive experiments\non both homophilic and heterophilic directed graph datasets demonstrate that\nDHGNN outperforms state-of-the-art methods in node classification and link\nprediction. In particular, DHGNN improves over the best baseline by up to\n15.07% in link prediction. Our analysis further shows that the gating mechanism\ncaptures directional homophily gaps and fluctuating homophily across layers,\nproviding deeper insights into message-passing behavior on complex graph\nstructures.','Aihu Zhang, Jiaxing Xu, Mengcheng Lan, Shili Xiang, Yiping Ke','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22362v1'),('2505.22364v1','Computing Optimal Transport Maps and Wasserstein Barycenters Using Conditional Normalizing Flows','We present a novel method for efficiently computing optimal transport maps\nand Wasserstein barycenters in high-dimensional spaces. Our approach uses\nconditional normalizing flows to approximate the input distributions as\ninvertible pushforward transformations from a common latent space. This makes\nit possible to directly solve the primal problem using gradient-based\nminimization of the transport cost, unlike previous methods that rely on dual\nformulations and complex adversarial optimization. We show how this approach\ncan be extended to compute Wasserstein barycenters by solving a conditional\nvariance minimization problem. A key advantage of our conditional architecture\nis that it enables the computation of barycenters for hundreds of input\ndistributions, which was computationally infeasible with previous methods. Our\nnumerical experiments illustrate that our approach yields accurate results\nacross various high-dimensional tasks and compares favorably with previous\nstate-of-the-art methods.','Gabriele Visentin, Patrick Cheridito','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22364v1'),('2505.22368v1','AgentDNS: A Root Domain Naming System for LLM Agents','The rapid evolution of Large Language Model (LLM) agents has highlighted\ncritical challenges in cross-vendor service discovery, interoperability, and\ncommunication. Existing protocols like model context protocol and\nagent-to-agent protocol have made significant strides in standardizing\ninteroperability between agents and tools, as well as communication among\nmulti-agents. However, there remains a lack of standardized protocols and\nsolutions for service discovery across different agent and tool vendors. In\nthis paper, we propose AgentDNS, a root domain naming and service discovery\nsystem designed to enable LLM agents to autonomously discover, resolve, and\nsecurely invoke third-party agent and tool services across organizational and\ntechnological boundaries. Inspired by the principles of the traditional DNS,\nAgentDNS introduces a structured mechanism for service registration, semantic\nservice discovery, secure invocation, and unified billing. We detail the\narchitecture, core functionalities, and use cases of AgentDNS, demonstrating\nits potential to streamline multi-agent collaboration in real-world scenarios.\nThe source code will be published on https://github.com/agentdns.','Enfang Cui, Yujun Cheng, Rui She, Dan Liu, Zhiyuan Liang, Minxin Guo, Tianzheng Li, Qian Wei, Wenjuan Xing, Zhijie Zhong','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22368v1'),('2505.22370v1','SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting','Continual Learning requires a model to learn multiple tasks in sequence while\nmaintaining both stability:preserving knowledge from previously learned tasks,\nand plasticity:effectively learning new tasks. Gradient projection has emerged\nas an effective and popular paradigm in CL, where it partitions the gradient\nspace of previously learned tasks into two orthogonal subspaces: a primary\nsubspace and a minor subspace. New tasks are learned effectively within the\nminor subspace, thereby reducing interference with previously acquired\nknowledge. However, existing Gradient Projection methods struggle to achieve an\noptimal balance between plasticity and stability, as it is hard to\nappropriately partition the gradient space. In this work, we consider a\ncontinual learning paradigm based on Low-Rank Adaptation, which has gained\nconsiderable attention due to its efficiency and wide applicability, and\npropose a novel approach for continual learning, called SplitLoRA. We first\nprovide a theoretical analysis of how subspace partitioning affects model\nstability and plasticity. Informed by this analysis, we then introduce an\neffective method that derives the optimal partition of the gradient space for\npreviously learned tasks. This approach effectively balances stability and\nplasticity in continual learning. Experimental results on multiple datasets\ndemonstrate that the proposed method achieves state-of-the-art performance.','Haomiao Qiu, Miao Zhang, Ziyue Qiao, Weili Guan, Min Zhang, Liqiang Nie','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22370v1'),('2505.22375v1','Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition','This work presents Pangu Embedded, an efficient Large Language Model (LLM)\nreasoner developed on Ascend Neural Processing Units (NPUs), featuring flexible\nfast and slow thinking capabilities. Pangu Embedded addresses the significant\ncomputational costs and inference latency challenges prevalent in existing\nreasoning-optimized LLMs. We propose a two-stage training framework for its\nconstruction. In Stage 1, the model is finetuned via an iterative distillation\nprocess, incorporating inter-iteration model merging to effectively aggregate\ncomplementary knowledge. This is followed by reinforcement learning on Ascend\nclusters, optimized by a latency-tolerant scheduler that combines stale\nsynchronous parallelism with prioritized data queues. The RL process is guided\nby a Multi-source Adaptive Reward System (MARS), which generates dynamic,\ntask-specific reward signals using deterministic metrics and lightweight LLM\nevaluators for mathematics, coding, and general problem-solving tasks. Stage 2\nintroduces a dual-system framework, endowing Pangu Embedded with a \"fast\" mode\nfor routine queries and a deeper \"slow\" mode for complex inference. This\nframework offers both manual mode switching for user control and an automatic,\ncomplexity-aware mode selection mechanism that dynamically allocates\ncomputational resources to balance latency and reasoning depth. Experimental\nresults on benchmarks including AIME 2024, GPQA, and LiveCodeBench demonstrate\nthat Pangu Embedded with 7B parameters, outperforms similar-size models like\nQwen3-8B and GLM4-9B. It delivers rapid responses and state-of-the-art\nreasoning quality within a single, unified model architecture, highlighting a\npromising direction for developing powerful yet practically deployable LLM\nreasoners.','Hanting Chen, Yasheng Wang, Kai Han, Dong Li, Lin Li, Zhenni Bi, Jinpeng Li, Haoyu Wang, Fei Mi, Mingjian Zhu, Bin Wang, Kaikai Song, Yifei Fu, Xu He, Yu Luo, Chong Zhu, Quan He, Xueyu Wu, Wei He, Hailin Hu, Yehui Tang, Dacheng Tao, Xinghao Chen, Yunhe Wang, Other Contributors','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22375v1'),('2505.22381v1','A Divide-and-Conquer Approach for Modeling Arrival Times in Business Process Simulation','Business Process Simulation (BPS) is a critical tool for analyzing and\nimproving organizational processes by estimating the impact of process changes.\nA key component of BPS is the case-arrival model, which determines the pattern\nof new case entries into a process. Although accurate case-arrival modeling is\nessential for reliable simulations, as it influences waiting and overall cycle\ntimes, existing approaches often rely on oversimplified static distributions of\ninter-arrival times. These approaches fail to capture the dynamic and temporal\ncomplexities inherent in organizational environments, leading to less accurate\nand reliable outcomes. To address this limitation, we propose Auto Time Kernel\nDensity Estimation (AT-KDE), a divide-and-conquer approach that models arrival\ntimes of processes by incorporating global dynamics, day-of-week variations,\nand intraday distributional changes, ensuring both precision and scalability.\nExperiments conducted across 20 diverse processes demonstrate that AT-KDE is\nfar more accurate and robust than existing approaches while maintaining\nsensible execution time efficiency.','Lukas Kirchdorfer, Konrad Özdemir, Stjepan Kusenic, Han van der Aa, Heiner Stuckenschmidt','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22381v1'),('2505.22384v1','Exact Algorithms and Lower Bounds for Forming Coalitions of Constrained Maximum Size','Imagine we want to split a group of agents into teams in the most\n\\emph{efficient} way, considering that each agent has their own preferences\nabout their teammates. This scenario is modeled by the extensively studied\n\\textsc{Coalition Formation} problem. Here, we study a version of this problem\nwhere each team must additionally be of bounded size.\n  We conduct a systematic algorithmic study, providing several intractability\nresults as well as multiple exact algorithms that scale well as the input grows\n(FPT), which could prove useful in practice.\n  Our main contribution is an algorithm that deals efficiently with tree-like\nstructures (bounded \\emph{treewidth}) for ``small\\\'\\\' teams. We complement this\nresult by proving that our algorithm is asymptotically optimal. Particularly,\nthere can be no algorithm that vastly outperforms the one we present, under\nreasonable theoretical assumptions, even when considering star-like structures\n(bounded \\emph{vertex cover number}).','Foivos Fioravantes, Harmender Gahlawat, Nikolaos Melissinos','2025-05-28','cs.DS','http://arxiv.org/pdf/2505.22384v1'),('2505.22387v1','DAM: Domain-Aware Module for Multi-Domain Dataset Condensation','Dataset Condensation (DC) has emerged as a promising solution to mitigate the\ncomputational and storage burdens associated with training deep learning\nmodels. However, existing DC methods largely overlook the multi-domain nature\nof modern datasets, which are increasingly composed of heterogeneous images\nspanning multiple domains. In this paper, we extend DC and introduce\nMulti-Domain Dataset Condensation (MDDC), which aims to condense data that\ngeneralizes across both single-domain and multi-domain settings. To this end,\nwe propose the Domain-Aware Module (DAM), a training-time module that embeds\ndomain-related features into each synthetic image via learnable spatial masks.\nAs explicit domain labels are mostly unavailable in real-world datasets, we\nemploy frequency-based pseudo-domain labeling, which leverages low-frequency\namplitude statistics. DAM is only active during the condensation process, thus\npreserving the same images per class (IPC) with prior methods. Experiments show\nthat DAM consistently improves in-domain, out-of-domain, and cross-architecture\nperformance over baseline dataset condensation methods.','Jaehyun Choi, Gyojin Han, Dong-Jae Lee, Sunghyun Baek, Junmo Kim','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22387v1'),('2505.22389v1','Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning','Continual Learning (CL) aims to enable models to continuously acquire new\nknowledge from a sequence of tasks with avoiding the forgetting of learned\ninformation. However, existing CL methods only rely on the parameters of the\nmost recent task for inference, which makes them susceptible to catastrophic\nforgetting. Inspired by the recent success of model merging techniques, we\npropose \\textbf{Perturb-and-Merge (P\\&M)}, a novel continual learning framework\nthat integrates model merging into the CL paradigm to mitigate forgetting.\nSpecifically, after training on each task, P\\&M constructs a new model by\nforming a convex combination of the previous model and the newly trained\ntask-specific model. Through theoretical analysis, we minimize the total loss\nincrease across all tasks and derive an analytical solution for the optimal\nmerging coefficient. To further improve the performance of the merged model, we\nobserve that the degradation introduced during merging can be alleviated by a\nregularization term composed of the task vector and the Hessian matrix of the\nloss function. Interestingly, we show that this term can be efficiently\napproximated using second-order symmetric finite differences, and a stochastic\nperturbation strategy along the task vector direction is accordingly devised\nwhich incurs no additional forward or backward passes while providing an\neffective approximation of the regularization term. Finally, we combine P\\&M\nwith LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead.\nOur proposed approach achieves state-of-the-art performance on several\ncontinual learning benchmark datasets.','Haomiao Qiu, Miao Zhang, Ziyue Qiao, Liqiang Nie','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22389v1'),('2505.22391v1','Physics-Informed Distillation of Diffusion Models for PDE-Constrained Generation','Modeling physical systems in a generative manner offers several advantages,\nincluding the ability to handle partial observations, generate diverse\nsolutions, and address both forward and inverse problems. Recently, diffusion\nmodels have gained increasing attention in the modeling of physical systems,\nparticularly those governed by partial differential equations (PDEs). However,\ndiffusion models only access noisy data $\\boldsymbol{x}_t$ at intermediate\nsteps, making it infeasible to directly enforce constraints on the clean sample\n$\\boldsymbol{x}_0$ at each noisy level. As a workaround, constraints are\ntypically applied to the expectation of clean samples\n$\\mathbb{E}[\\boldsymbol{x}_0|\\boldsymbol{x}_t]$, which is estimated using the\nlearned score network. However, imposing PDE constraints on the expectation\ndoes not strictly represent the one on the true clean data, known as Jensen\\\'s\nGap. This gap creates a trade-off: enforcing PDE constraints may come at the\ncost of reduced accuracy in generative modeling. To address this, we propose a\nsimple yet effective post-hoc distillation approach, where PDE constraints are\nnot injected directly into the diffusion process, but instead enforced during a\npost-hoc distillation stage. We term our method as Physics-Informed\nDistillation of Diffusion Models (PIDDM). This distillation not only\nfacilitates single-step generation with improved PDE satisfaction, but also\nsupport both forward and inverse problem solving and reconstruction from\nrandomly partial observation. Extensive experiments across various PDE\nbenchmarks demonstrate that PIDDM significantly improves PDE satisfaction over\nseveral recent and competitive baselines, such as PIDM, DiffusionPDE, and\nECI-sampling, with less computation overhead. Our approach can shed light on\nmore efficient and effective strategies for incorporating physical constraints\ninto diffusion models.','Yi Zhang, Difan Zou','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22391v1'),('2505.22411v1','Mitigating Overthinking in Large Reasoning Models via Manifold Steering','Recent advances in Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in solving complex tasks such as mathematics and coding. However,\nthese models frequently exhibit a phenomenon known as overthinking during\ninference, characterized by excessive validation loops and redundant\ndeliberation, leading to substantial computational overheads. In this paper, we\naim to mitigate overthinking by investigating the underlying mechanisms from\nthe perspective of mechanistic interpretability. We first showcase that the\ntendency of overthinking can be effectively captured by a single direction in\nthe model\\\'s activation space and the issue can be eased by intervening the\nactivations along this direction. However, this efficacy soon reaches a plateau\nand even deteriorates as the intervention strength increases. We therefore\nsystematically explore the activation space and find that the overthinking\nphenomenon is actually tied to a low-dimensional manifold, which indicates that\nthe limited effect stems from the noises introduced by the high-dimensional\nsteering direction. Based on this insight, we propose Manifold Steering, a\nnovel approach that elegantly projects the steering direction onto the\nlow-dimensional activation manifold given the theoretical approximation of the\ninterference noise. Extensive experiments on DeepSeek-R1 distilled models\nvalidate that our method reduces output tokens by up to 71% while maintaining\nand even improving the accuracy on several mathematical benchmarks. Our method\nalso exhibits robust cross-domain transferability, delivering consistent token\nreduction performance in code generation and knowledge-based QA tasks. Code is\navailable at: https://github.com/Aries-iai/Manifold_Steering.','Yao Huang, Huanran Chen, Shouwei Ruan, Yichi Zhang, Xingxing Wei, Yinpeng Dong','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22411v1'),('2505.22422v1','STaR-Bets: Sequential Target-Recalculating Bets for Tighter Confidence Intervals','The construction of confidence intervals for the mean of a bounded random\nvariable is a classical problem in statistics with numerous applications in\nmachine learning and virtually all scientific fields. In particular, obtaining\nthe tightest possible confidence intervals is vital every time the sampling of\nthe random variables is expensive. The current state-of-the-art method to\nconstruct confidence intervals is by using betting algorithms. This is a very\nsuccessful approach for deriving optimal confidence sequences, even matching\nthe rate of law of iterated logarithms. However, in the fixed horizon setting,\nthese approaches are either sub-optimal or based on heuristic solutions with\nstrong empirical performance but without a finite-time guarantee. Hence, no\nbetting-based algorithm guaranteeing the optimal\n$\\mathcal{O}(\\sqrt{\\frac{\\sigma^2\\log\\frac1\\delta}{n}})$ width of the\nconfidence intervals are known. This work bridges this gap. We propose a\nbetting-based algorithm to compute confidence intervals that empirically\noutperforms the competitors. Our betting strategy uses the optimal strategy in\nevery step (in a certain sense), whereas the standard betting methods choose a\nconstant strategy in advance. Leveraging this fact results in strict\nimprovements even for classical concentration inequalities, such as the ones of\nHoeffding or Bernstein. Moreover, we also prove that the width of our\nconfidence intervals is optimal up to an $1+o(1)$ factor diminishing with $n$.\nThe code is available\non~https://github.com/vvoracek/STaR-bets-confidence-interval.','Václav Voráček, Francesco Orabona','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22422v1'),('2505.22425v1','Scaling Reasoning without Attention','Large language models (LLMs) have made significant advances in complex\nreasoning tasks, yet they remain bottlenecked by two core challenges:\narchitectural inefficiency due to reliance on Transformers, and a lack of\nstructured fine-tuning for high-difficulty domains. We introduce \\ourmodel, an\nattention-free language model that addresses both issues through architectural\nand data-centric innovations. Built on the state space dual (SSD) layers of\nMamba-2, our model eliminates the need for self-attention and key-value\ncaching, enabling fixed-memory, constant-time inference. To train it for\ncomplex reasoning, we propose a two-phase curriculum fine-tuning strategy based\non the \\textsc{PromptCoT} synthesis paradigm, which generates pedagogically\nstructured problems via abstract concept selection and rationale-guided\ngeneration. On benchmark evaluations, \\ourmodel-7B outperforms strong\nTransformer and hybrid models of comparable scale, and even surpasses the much\nlarger Gemma3-27B by 2.6\\% on AIME 24, 0.6\\% on AIME 25, and 3.0\\% on\nLivecodebench. These results highlight the potential of state space models as\nefficient and scalable alternatives to attention-based architectures for\nhigh-capacity reasoning.','Xueliang Zhao, Wei Wu, Lingpeng Kong','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22425v1'),('2505.22430v1','RAG-Zeval: Towards Robust and Interpretable Evaluation on RAG Responses through End-to-End Rule-Guided Reasoning','Robust evaluation is critical for deploying trustworthy retrieval-augmented\ngeneration (RAG) systems. However, current LLM-based evaluation frameworks\npredominantly rely on directly prompting resource-intensive models with complex\nmulti-stage prompts, underutilizing models\\\' reasoning capabilities and\nintroducing significant computational cost. In this paper, we present RAG-Zeval\n(RAG-Zero Evaluator), a novel end-to-end framework that formulates faithfulness\nand correctness evaluation as a rule-guided reasoning task. Our approach trains\nevaluators with reinforcement learning, facilitating compact models to generate\ncomprehensive and sound assessments with detailed explanation in one-pass. We\nintroduce a ranking-based outcome reward mechanism, using preference judgments\nrather than absolute scores, to address the challenge of obtaining precise\npointwise reward signals. To this end, we synthesize the ranking references by\ngenerating quality-controlled responses with zero human annotation. Experiments\ndemonstrate RAG-Zeval\\\'s superior performance, achieving the strongest\ncorrelation with human judgments and outperforming baselines that rely on LLMs\nwith 10-100 times more parameters. Our approach also exhibits superior\ninterpretability in response evaluation.','Kun Li, Yunxiang Li, Tianhua Zhang, Hongyin Luo, Xixin Wu, James Glass, Helen Meng','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22430v1'),('2505.22438v1','Synonymous Variational Inference for Perceptual Image Compression','Recent contributions of semantic information theory reveal the set-element\nrelationship between semantic and syntactic information, represented as\nsynonymous relationships. In this paper, we propose a synonymous variational\ninference (SVI) method based on this synonymity viewpoint to re-analyze the\nperceptual image compression problem. It takes perceptual similarity as a\ntypical synonymous criterion to build an ideal synonymous set (Synset), and\napproximate the posterior of its latent synonymous representation with a\nparametric density by minimizing a partial semantic KL divergence. This\nanalysis theoretically proves that the optimization direction of perception\nimage compression follows a triple tradeoff that can cover the existing\nrate-distortion-perception schemes. Additionally, we introduce synonymous image\ncompression (SIC), a new image compression scheme that corresponds to the\nanalytical process of SVI, and implement a progressive SIC codec to fully\nleverage the model\\\'s capabilities. Experimental results demonstrate comparable\nrate-distortion-perception performance using a single progressive SIC codec,\nthus verifying the effectiveness of our proposed analysis method.','Zijian Liang, Kai Niu, Changshuo Wang, Jin Xu, Ping Zhang','2025-05-28','cs.IT','http://arxiv.org/pdf/2505.22438v1'),('2505.22440v1','Data-Driven Antenna Miniaturization: A Knowledge-Based System Integrating Quantum PSO and Predictive Machine Learning Models','The rapid evolution of wireless technologies necessitates automated design\nframeworks to address antenna miniaturization and performance optimization\nwithin constrained development cycles. This study demonstrates a machine\nlearning enhanced workflow integrating Quantum-Behaved Dynamic Particle Swarm\nOptimization (QDPSO) with ANSYS HFSS simulations to accelerate antenna design.\nThe QDPSO algorithm autonomously optimized loop dimensions in 11.53 seconds,\nachieving a resonance frequency of 1.4208 GHz a 12.7 percent reduction compared\nto conventional 1.60 GHz designs. Machine learning models (SVM, Random Forest,\nXGBoost, and Stacked ensembles) predicted resonance frequencies in 0.75 seconds\nusing 936 simulation datasets, with stacked models showing superior training\naccuracy (R2=0.9825) and SVM demonstrating optimal validation performance\n(R2=0.7197). The complete design cycle, encompassing optimization, prediction,\nand ANSYS validation, required 12.42 minutes on standard desktop hardware\n(Intel i5-8500, 16GB RAM), contrasting sharply with the 50-hour benchmark of\nPSADEA-based approaches. This 240 times of acceleration eliminates traditional\ntrial-and-error methods that often extend beyond seven expert-led days. The\nsystem enables precise specifications of performance targets with automated\ngeneration of fabrication-ready parameters, particularly benefiting compact\nconsumer devices requiring rapid frequency tuning. By bridging AI-driven\noptimization with CAD validation, this framework reduces engineering workloads\nwhile ensuring production-ready designs, establishing a scalable paradigm for\nnext-generation RF systems in 6G and IoT applications.','Khan Masood Parvez, Sk Md Abidar Rahaman, Ali Shiri Sichani','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22440v1'),('2505.22441v1','Can NeRFs See without Cameras?','Neural Radiance Fields (NeRFs) have been remarkably successful at\nsynthesizing novel views of 3D scenes by optimizing a volumetric scene\nfunction. This scene function models how optical rays bring color information\nfrom a 3D object to the camera pixels. Radio frequency (RF) or audio signals\ncan also be viewed as a vehicle for delivering information about the\nenvironment to a sensor. However, unlike camera pixels, an RF/audio sensor\nreceives a mixture of signals that contain many environmental reflections (also\ncalled \"multipath\"). Is it still possible to infer the environment using such\nmultipath signals? We show that with redesign, NeRFs can be taught to learn\nfrom multipath signals, and thereby \"see\" the environment. As a grounding\napplication, we aim to infer the indoor floorplan of a home from sparse WiFi\nmeasurements made at multiple locations inside the home. Although a difficult\ninverse problem, our implicitly learnt floorplans look promising, and enables\nforward applications, such as indoor signal prediction and basic ray tracing.','Chaitanya Amballa, Sattwik Basu, Yu-Lin Wei, Zhijian Yang, Mehmet Ergezer, Romit Roy Choudhury','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22441v1'),('2505.22442v1','SOReL and TOReL: Two Methods for Fully Offline Reinforcement Learning','Sample efficiency remains a major obstacle for real world adoption of\nreinforcement learning (RL): success has been limited to settings where\nsimulators provide access to essentially unlimited environment interactions,\nwhich in reality are typically costly or dangerous to obtain. Offline RL in\nprinciple offers a solution by exploiting offline data to learn a near-optimal\npolicy before deployment. In practice, however, current offline RL methods rely\non extensive online interactions for hyperparameter tuning, and have no\nreliable bound on their initial online performance. To address these two\nissues, we introduce two algorithms. Firstly, SOReL: an algorithm for safe\noffline reinforcement learning. Using only offline data, our Bayesian approach\ninfers a posterior over environment dynamics to obtain a reliable estimate of\nthe online performance via the posterior predictive uncertainty. Crucially, all\nhyperparameters are also tuned fully offline. Secondly, we introduce TOReL: a\ntuning for offline reinforcement learning algorithm that extends our\ninformation rate based offline hyperparameter tuning methods to general offline\nRL approaches. Our empirical evaluation confirms SOReL\\\'s ability to accurately\nestimate regret in the Bayesian setting whilst TOReL\\\'s offline hyperparameter\ntuning achieves competitive performance with the best online hyperparameter\ntuning methods using only offline data. Thus, SOReL and TOReL make a\nsignificant step towards safe and reliable offline RL, unlocking the potential\nfor RL in the real world. Our implementations are publicly available:\nhttps://github.com/CWibault/sorel\\_torel.','Mattie Fellows, Clarisse Wibault, Uljad Berdica, Johannes Forkel, Jakob N. Foerster, Michael A. Osborne','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22442v1'),('2505.22445v1','NFR: Neural Feature-Guided Non-Rigid Shape Registration','In this paper, we propose a novel learning-based framework for 3D shape\nregistration, which overcomes the challenges of significant non-rigid\ndeformation and partiality undergoing among input shapes, and, remarkably,\nrequires no correspondence annotation during training. Our key insight is to\nincorporate neural features learned by deep learning-based shape matching\nnetworks into an iterative, geometric shape registration pipeline. The\nadvantage of our approach is two-fold -- On one hand, neural features provide\nmore accurate and semantically meaningful correspondence estimation than\nspatial features (e.g., coordinates), which is critical in the presence of\nlarge non-rigid deformations; On the other hand, the correspondences are\ndynamically updated according to the intermediate registrations and filtered by\nconsistency prior, which prominently robustify the overall pipeline. Empirical\nresults show that, with as few as dozens of training shapes of limited\nvariability, our pipeline achieves state-of-the-art results on several\nbenchmarks of non-rigid point cloud matching and partial shape matching across\nvarying settings, but also delivers high-quality correspondences between unseen\nchallenging shape pairs that undergo both significant extrinsic and intrinsic\ndeformations, in which case neither traditional registration methods nor\nintrinsic methods work.','Puhua Jiang, Zhangquan Chen, Mingze Sun, Ruqi Huang','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22445v1'),('2505.22450v1','Position: All Current Generative Fidelity and Diversity Metrics are Flawed','Any method\\\'s development and practical application is limited by our ability\nto measure its reliability. The popularity of generative modeling emphasizes\nthe importance of good synthetic data metrics. Unfortunately, previous works\nhave found many failure cases in current metrics, for example lack of outlier\nrobustness and unclear lower and upper bounds. We propose a list of desiderata\nfor synthetic data metrics, and a suite of sanity checks: carefully chosen\nsimple experiments that aim to detect specific and known generative modeling\nfailure modes. Based on these desiderata and the results of our checks, we\narrive at our position: all current generative fidelity and diversity metrics\nare flawed. This significantly hinders practical use of synthetic data. Our aim\nis to convince the research community to spend more effort in developing\nmetrics, instead of models. Additionally, through analyzing how current metrics\nfail, we provide practitioners with guidelines on how these metrics should\n(not) be used.','Ossi Räisä, Boris van Breugel, Mihaela van der Schaar','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22450v1'),('2505.22451v1','AI Mathematician: Towards Fully Automated Frontier Mathematical Research','Large Reasoning Models (LRMs) have made significant progress in mathematical\ncapabilities in recent times. However, these successes have been primarily\nconfined to competition-level problems. In this work, we propose AI\nMathematician (AIM) framework, which harnesses the reasoning strength of LRMs\nto support frontier mathematical research. We have identified two critical\nchallenges of mathematical research compared to competition, {\\it the intrinsic\ncomplexity of research problems} and {\\it the requirement of procedural rigor}.\nTo address these challenges, AIM incorporates two core strategies: an\nexploration mechanism to foster longer solution paths, and the pessimistic\nreasonable verification method to ensure reliability.\n  This early version of AIM already exhibits strong capability in tackling\nresearch-level tasks. We conducted extensive experiments across several\nreal-world mathematical topics and obtained promising results. AIM is able to\nautonomously construct substantial portions of proofs and uncover non-trivial\ninsights within each research area. These findings highlight the potential of\nLRMs in mathematical discovery and suggest that LRM-based agent systems could\nsignificantly accelerate mathematical research in the future.','Yuanhang Liu, Yanxing Huang, Yanqiao Wang, Peng Li, Yang Liu','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22451v1'),('2505.22453v1','Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO','Improving Multi-modal Large Language Models (MLLMs) in the post-training\nstage typically relies on supervised fine-tuning (SFT) or reinforcement\nlearning (RL). However, these supervised methods require expensive and manually\nannotated multi-modal data--an ultimately unsustainable resource. While recent\nefforts have explored unsupervised post-training, their methods are complex and\ndifficult to iterate. In this work, we are the first to investigate the use of\nGRPO, a stable and scalable online RL algorithm, for enabling continual\nself-improvement without any external supervision. We propose MM-UPT, a simple\nyet effective framework for unsupervised post-training of MLLMs. MM-UPT builds\nupon GRPO, replacing traditional reward signals with a self-rewarding mechanism\nbased on majority voting over multiple sampled responses. Our experiments\ndemonstrate that MM-UPT significantly improves the reasoning ability of\nQwen2.5-VL-7B (e.g., 66.3 %$\\rightarrow$72.9 % on MathVista, 62.9\n%$\\rightarrow$68.7 % on We-Math), using standard dataset without ground truth\nlabels. MM-UPT also outperforms prior unsupervised baselines and even\napproaches the results of supervised GRPO. Furthermore, we show that\nincorporating synthetic questions, generated solely by MLLM itself, can boost\nperformance as well, highlighting a promising approach for scalable\nself-improvement. Overall, MM-UPT offers a new paradigm for continual,\nautonomous enhancement of MLLMs in the absence of external supervision. Our\ncode is available at https://github.com/waltonfuture/MM-UPT.','Lai Wei, Yuting Li, Chen Wang, Yue Wang, Linghe Kong, Weiran Huang, Lichao Sun','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22453v1'),('2505.22454v1','Depth-Based Matrix Classification for the HHL Quantum Algorithm','Under the nearing error-corrected era of quantum computing, it is necessary\nto understand the suitability of certain post-NISQ algorithms for practical\nproblems. One of the most promising, applicable and yet difficult to implement\nin practical terms is the Harrow, Hassidim and Lloyd (HHL) algorithm for linear\nsystems of equations. An enormous number of problems can be expressed as linear\nsystems of equations, from Machine Learning to fluid dynamics. However, in most\ncases, HHL will not be able to provide a practical, reasonable solution to\nthese problems. This paper\\\'s goal inquires about whether problems can be\nlabeled using Machine Learning classifiers as suitable or unsuitable for HHL\nimplementation when some numerical information about the problem is known\nbeforehand. This work demonstrates that training on significantly\nrepresentative data distributions is critical to achieve good classifications\nof the problems based on the numerical properties of the matrix representing\nthe system of equations. Accurate classification is possible through\nMulti-Layer Perceptrons, although with careful design of the training data\ndistribution and classifier parameters.','Mark Danza, Sonia Lopez Alarcon, Cory Merkel','2025-05-28','quant-ph','http://arxiv.org/pdf/2505.22454v1'),('2505.22457v1','Fostering Video Reasoning via Next-Event Prediction','Next-token prediction serves as the foundational learning task enabling\nreasoning in LLMs. But what should the learning task be when aiming to equip\nMLLMs with temporal reasoning capabilities over video inputs? Existing tasks\nsuch as video question answering often rely on annotations from humans or much\nstronger MLLMs, while video captioning tends to entangle temporal reasoning\nwith spatial information. To address this gap, we propose next-event prediction\n(NEP), a learning task that harnesses future video segments as a rich,\nself-supervised signal to foster temporal reasoning. We segment each video into\npast and future frames: the MLLM takes the past frames as input and predicts a\nsummary of events derived from the future frames, thereby encouraging the model\nto reason temporally in order to complete the task. To support this task, we\ncurate V1-33K, a dataset comprising 33,000 automatically extracted video\nsegments spanning diverse real-world scenarios. We further explore a range of\nvideo instruction-tuning strategies to study their effects on temporal\nreasoning. To evaluate progress, we introduce FutureBench to assess coherence\nin predicting unseen future events. Experiments validate that NEP offers a\nscalable and effective training paradigm for fostering temporal reasoning in\nMLLMs.','Haonan Wang, Hongfu Liu, Xiangyan Liu, Chao Du, Kenji Kawaguchi, Ye Wang, Tianyu Pang','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22457v1'),('2505.22467v1','Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems','Large Language Model-based Multi-Agent Systems (MASs) have emerged as a\npowerful paradigm for tackling complex tasks through collaborative\nintelligence. Nevertheless, the question of how agents should be structurally\norganized for optimal cooperation remains largely unexplored. In this position\npaper, we aim to gently redirect the focus of the MAS research community toward\nthis critical dimension: develop topology-aware MASs for specific tasks.\nSpecifically, the system consists of three core components - agents,\ncommunication links, and communication patterns - that collectively shape its\ncoordination performance and efficiency. To this end, we introduce a\nsystematic, three-stage framework: agent selection, structure profiling, and\ntopology synthesis. Each stage would trigger new research opportunities in\nareas such as language models, reinforcement learning, graph learning, and\ngenerative modeling; together, they could unleash the full potential of MASs in\ncomplicated real-world applications. Then, we discuss the potential challenges\nand opportunities in the evaluation of multiple systems. We hope our\nperspective and framework can offer critical new insights in the era of agentic\nAI.','Jiaxi Yang, Mengqi Zhang, Yiqiao Jin, Hao Chen, Qingsong Wen, Lu Lin, Yi He, Weijie Xu, James Evans, Jindong Wang','2025-05-28','cs.MA','http://arxiv.org/pdf/2505.22467v1'),('2505.22469v1','CPINN-ABPI: Physics-Informed Neural Networks for Accurate Power Estimation in MPSoCs','Efficient thermal and power management in modern multiprocessor\nsystems-on-chip (MPSoCs) demands accurate power consumption estimation. One of\nthe state-of-the-art approaches, Alternative Blind Power Identification (ABPI),\ntheoretically eliminates the dependence on steady-state temperatures,\naddressing a major shortcoming of previous approaches. However, ABPI\nperformance has remained unverified in actual hardware implementations. In this\nstudy, we conduct the first empirical validation of ABPI on commercial hardware\nusing the NVIDIA Jetson Xavier AGX platform. Our findings reveal that, while\nABPI provides computational efficiency and independence from steady-state\ntemperature, it exhibits considerable accuracy deficiencies in real-world\nscenarios. To overcome these limitations, we introduce a novel approach that\nintegrates Custom Physics-Informed Neural Networks (CPINNs) with the underlying\nthermal model of ABPI. Our approach employs a specialized loss function that\nharmonizes physical principles with data-driven learning, complemented by\nmulti-objective genetic algorithm optimization to balance estimation accuracy\nand computational cost. In experimental validation, CPINN-ABPI achieves a\nreduction of 84.7\\% CPU and 73.9\\% GPU in the mean absolute error (MAE)\nrelative to ABPI, with the weighted mean absolute percentage error (WMAPE)\nimproving from 47\\%--81\\% to $\\sim$12\\%. The method maintains real-time\nperformance with 195.3~$\\mu$s of inference time, with similar 85\\%--99\\%\naccuracy gains across heterogeneous SoCs.','Mohamed R. Elshamy, Mehdi Elahi, Ahmad Patooghy, Abdel-Hameed A. Badawy','2025-05-28','cs.PF','http://arxiv.org/pdf/2505.22469v1'),('2505.22473v1','Pure Exploration with Infinite Answers','We study pure exploration problems where the set of correct answers is\npossibly infinite, e.g., the regression of any continuous function of the means\nof the bandit. We derive an instance-dependent lower bound for these problems.\nBy analyzing it, we discuss why existing methods (i.e., Sticky Track-and-Stop)\nfor finite answer problems fail at being asymptotically optimal in this more\ngeneral setting. Finally, we present a framework, Sticky-Sequence\nTrack-and-Stop, which generalizes both Track-and-Stop and Sticky\nTrack-and-Stop, and that enjoys asymptotic optimality. Due to its generality,\nour analysis also highlights special cases where existing methods enjoy\noptimality.','Riccardo Poiani, Martino Bernasconi, Andrea Celli','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22473v1'),('2505.22474v1','Forecasting Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis','The forecasting of multivariate urban data presents a complex challenge due\nto the intricate dependencies between various urban metrics such as weather,\nair pollution, carbon intensity, and energy demand. This paper introduces a\nnovel multivariate time-series forecasting model that utilizes advanced Graph\nNeural Networks (GNNs) to capture spatial dependencies among different\ntime-series variables. The proposed model incorporates a decomposition-based\npreprocessing step, isolating trend, seasonal, and residual components to\nenhance the accuracy and interpretability of forecasts. By leveraging the\ndynamic capabilities of GNNs, the model effectively captures interdependencies\nand improves the forecasting performance. Extensive experiments on real-world\ndatasets, including electricity usage, weather metrics, carbon intensity, and\nair pollution data, demonstrate the effectiveness of the proposed approach\nacross various forecasting scenarios. The results highlight the potential of\nthe model to optimize smart infrastructure systems, contributing to\nenergy-efficient urban development and enhanced public well-being.','Amirhossein Sohrabbeig, Omid Ardakanian, Petr Musilek','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22474v1'),('2505.22475v1','Non-Asymptotic Analysis of (Sticky) Track-and-Stop','In pure exploration problems, a statistician sequentially collects\ninformation to answer a question about some stochastic and unknown environment.\nThe probability of returning a wrong answer should not exceed a maximum risk\nparameter $\\delta$ and good algorithms make as few queries to the environment\nas possible. The Track-and-Stop algorithm is a pioneering method to solve these\nproblems. Specifically, it is well-known that it enjoys asymptotic optimality\nsample complexity guarantees for $\\delta\\to 0$ whenever the map from the\nenvironment to its correct answers is single-valued (e.g., best-arm\nidentification with a unique optimal arm). The Sticky Track-and-Stop algorithm\nextends these results to settings where, for each environment, there might\nexist multiple correct answers (e.g., $\\epsilon$-optimal arm identification).\nAlthough both methods are optimal in the asymptotic regime, their\nnon-asymptotic guarantees remain unknown. In this work, we fill this gap and\nprovide non-asymptotic guarantees for both algorithms.','Riccardo Poiani, Martino Bernasconi, Andrea Celli','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22475v1'),('2505.22477v1','Human-Centered Human-AI Collaboration (HCHAC)','In the intelligent era, the interaction between humans and intelligent\nsystems fundamentally involves collaboration with autonomous intelligent\nagents. Human-AI Collaboration (HAC) represents a novel type of human-machine\nrelationship facilitated by autonomous intelligent machines equipped with AI\ntechnologies. In this paradigm, AI agents serve not only as auxiliary tools but\nalso as active teammates, partnering with humans to accomplish tasks\ncollaboratively. Human-centered AI (HCAI) emphasizes that humans play critical\nleadership roles in the collaboration. This human-led collaboration imparts new\ndimensions to the human-machine relationship, necessitating innovative research\nperspectives, paradigms, and agenda to address the unique challenges posed by\nHAC. This chapter delves into the essence of HAC from the human-centered\nperspective, outlining its core concepts and distinguishing features. It\nreviews the current research methodologies and research agenda within the HAC\nfield from the HCAI perspective, highlighting advancements and ongoing studies.\nFurthermore, a framework for human-centered HAC (HCHAC) is proposed by\nintegrating these reviews and analyses. A case study of HAC in the context of\nautonomous vehicles is provided, illustrating practical applications and the\nsynergistic interactions between humans and AI agents. Finally, it identifies\npotential future research directions aimed at enhancing the effectiveness,\nreliability, and ethical integration of human-centered HAC systems in diverse\ndomains.','Qi Gao, Wei Xu, Hanxi Pan, Mowei Shen, Zaifeng Gao','2025-05-28','cs.HC','http://arxiv.org/pdf/2505.22477v1'),('2505.22481v1','Hypothesis Testing in Imaging Inverse Problems','This paper proposes a framework for semantic hypothesis testing tailored to\nimaging inverse problems. Modern imaging methods struggle to support hypothesis\ntesting, a core component of the scientific method that is essential for the\nrigorous interpretation of experiments and robust interfacing with\ndecision-making processes. There are three main reasons why image-based\nhypothesis testing is challenging. First, the difficulty of using a single\nobservation to simultaneously reconstruct an image, formulate hypotheses, and\nquantify their statistical significance. Second, the hypotheses encountered in\nimaging are mostly of semantic nature, rather than quantitative statements\nabout pixel values. Third, it is challenging to control test error\nprobabilities because the null and alternative distributions are often unknown.\nOur proposed approach addresses these difficulties by leveraging concepts from\nself-supervised computational imaging, vision-language models, and\nnon-parametric hypothesis testing with e-values. We demonstrate our proposed\nframework through numerical experiments related to image-based phenotyping,\nwhere we achieve excellent power while robustly controlling Type I errors.','Yiming Xi, Konstantinos Zygalakis, Marcelo Pereyra','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22481v1'),('2505.22483v1','A Closer Look at Multimodal Representation Collapse','We aim to develop a fundamental understanding of modality collapse, a\nrecently observed empirical phenomenon wherein models trained for multimodal\nfusion tend to rely only on a subset of the modalities, ignoring the rest. We\nshow that modality collapse happens when noisy features from one modality are\nentangled, via a shared set of neurons in the fusion head, with predictive\nfeatures from another, effectively masking out positive contributions from the\npredictive features of the former modality and leading to its collapse. We\nfurther prove that cross-modal knowledge distillation implicitly disentangles\nsuch representations by freeing up rank bottlenecks in the student encoder,\ndenoising the fusion-head outputs without negatively impacting the predictive\nfeatures from either modality. Based on the above findings, we propose an\nalgorithm that prevents modality collapse through explicit basis reallocation,\nwith applications in dealing with missing modalities. Extensive experiments on\nmultiple multimodal benchmarks validate our theoretical claims. Project page:\nhttps://abhrac.github.io/mmcollapse/.','Abhra Chaudhuri, Anjan Dutta, Tu Bui, Serban Georgescu','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22483v1'),('2505.22486v1','Understanding Adversarial Training with Energy-based Models','We aim at using Energy-based Model (EBM) framework to better understand\nadversarial training (AT) in classifiers, and additionally to analyze the\nintrinsic generative capabilities of robust classifiers. By viewing standard\nclassifiers through an energy lens, we begin by analyzing how the energies of\nadversarial examples, generated by various attacks, differ from those of the\nnatural samples. The central focus of our work is to understand the critical\nphenomena of Catastrophic Overfitting (CO) and Robust Overfitting (RO) in AT\nfrom an energy perspective. We analyze the impact of existing AT approaches on\nthe energy of samples during training and observe that the behavior of the\n``delta energy\\\' -- change in energy between original sample and its adversarial\ncounterpart -- diverges significantly when CO or RO occurs. After a thorough\nanalysis of these energy dynamics and their relationship with overfitting, we\npropose a novel regularizer, the Delta Energy Regularizer (DER), designed to\nsmoothen the energy landscape during training. We demonstrate that DER is\neffective in mitigating both CO and RO across multiple benchmarks. We further\nshow that robust classifiers, when being used as generative models, have limits\nin handling trade-off between image quality and variability. We propose an\nimproved technique based on a local class-wise principal component analysis\n(PCA) and energy-based guidance for better class-specific initialization and\nadaptive stopping, enhancing sample diversity and generation quality.\nConsidering that we do not explicitly train for generative modeling, we achieve\na competitive Inception Score (IS) and Fr\\\\\'echet inception distance (FID)\ncompared to hybrid discriminative-generative models.','Mujtaba Hussain Mirza, Maria Rosaria Briglia, Filippo Bartolucci, Senad Beadini, Giuseppe Lisanti, Iacopo Masi','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22486v1'),('2505.22487v1','Effective Context in Neural Speech Models','Modern neural speech models benefit from having longer context, and many\napproaches have been proposed to increase the maximum context a model can use.\nHowever, few have attempted to measure how much context these models actually\nuse, i.e., the effective context. Here, we propose two approaches to measuring\nthe effective context, and use them to analyze different speech Transformers.\nFor supervised models, we find that the effective context correlates well with\nthe nature of the task, with fundamental frequency tracking, phone\nclassification, and word classification requiring increasing amounts of\neffective context. For self-supervised models, we find that effective context\nincreases mainly in the early layers, and remains relatively short -- similar\nto the supervised phone model. Given that these models do not use a long\ncontext during prediction, we show that HuBERT can be run in streaming mode\nwithout modification to the architecture and without further fine-tuning.','Yen Meng, Sharon Goldwater, Hao Tang','2025-05-28','cs.SD','http://arxiv.org/pdf/2505.22487v1'),('2505.22491v1','On the Surprising Effectiveness of Large Learning Rates under Standard Width Scaling','The dominant paradigm for training large-scale vision and language models is\nHe initialization and a single global learning rate (\\textit{standard\nparameterization}, SP). Despite its practical success, standard parametrization\nremains poorly understood from a theoretical perspective: Existing\ninfinite-width theory would predict instability under large learning rates and\nvanishing feature learning under stable learning rates. However, empirically\noptimal learning rates consistently decay much slower than theoretically\npredicted. By carefully studying neural network training dynamics, we\ndemonstrate that this discrepancy is not fully explained by finite-width\nphenomena such as catapult effects or a lack of alignment between weights and\nincoming activations. We instead show that the apparent contradiction can be\nfundamentally resolved by taking the loss function into account: In contrast to\nMean Squared Error (MSE) loss, we prove that under cross-entropy (CE) loss, an\nintermediate \\textit{controlled divergence} regime emerges, where logits\ndiverge but loss, gradients, and activations remain stable. Stable training\nunder large learning rates enables persistent feature evolution at scale in all\nhidden layers, which is crucial for the practical success of SP. In experiments\nacross optimizers (SGD, Adam), architectures (MLPs, GPT) and data modalities\n(vision, language), we validate that neural networks operate in this controlled\ndivergence regime under CE loss but not under MSE loss. Our empirical evidence\nsuggests that width-scaling considerations are surprisingly useful for\npredicting empirically optimal learning rate exponents. Finally, our analysis\nclarifies the effectiveness and limitations of recently proposed layerwise\nlearning rate scalings for standard initialization.','Moritz Haas, Sebastian Bordt, Ulrike von Luxburg, Leena Chennuru Vankadara','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22491v1'),('2505.22492v1','Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation','This paper studies off-policy evaluation (OPE) in reinforcement learning with\na focus on behavior policy estimation for importance sampling. Prior work has\nshown empirically that estimating a history-dependent behavior policy can lead\nto lower mean squared error (MSE) even when the true behavior policy is\nMarkovian. However, the question of why the use of history should lower MSE\nremains open. In this paper, we theoretically demystify this paradox by\nderiving a bias-variance decomposition of the MSE of ordinary importance\nsampling (IS) estimators, demonstrating that history-dependent behavior policy\nestimation decreases their asymptotic variances while increasing their\nfinite-sample biases. Additionally, as the estimated behavior policy conditions\non a longer history, we show a consistent decrease in variance. We extend these\nfindings to a range of other OPE estimators, including the sequential IS\nestimator, the doubly robust estimator and the marginalized IS estimator, with\nthe behavior policy estimated either parametrically or non-parametrically.','Hongyi Zhou, Josiah P. Hanna, Jin Zhu, Ying Yang, Chengchun Shi','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22492v1'),('2505.22494v1','ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods','Designing protein sequences of both high fitness and novelty is a challenging\ntask in data-efficient protein engineering. Exploration beyond wild-type\nneighborhoods often leads to biologically implausible sequences or relies on\nsurrogate models that lose fidelity in novel regions. Here, we propose\nProSpero, an active learning framework in which a frozen pre-trained generative\nmodel is guided by a surrogate updated from oracle feedback. By integrating\nfitness-relevant residue selection with biologically-constrained Sequential\nMonte Carlo sampling, our approach enables exploration beyond wild-type\nneighborhoods while preserving biological plausibility. We show that our\nframework remains effective even when the surrogate is misspecified. ProSpero\nconsistently outperforms or matches existing methods across diverse protein\nengineering tasks, retrieving sequences of both high fitness and novelty.','Michal Kmicikiewicz, Vincent Fortuin, Ewa Szczurek','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22494v1'),('2505.22501v1','EvolveSearch: An Iterative Self-Evolving Search Agent','The rapid advancement of large language models (LLMs) has transformed the\nlandscape of agentic information seeking capabilities through the integration\nof tools such as search engines and web browsers. However, current mainstream\napproaches for enabling LLM web search proficiency face significant challenges:\nsupervised fine-tuning struggles with data production in open-search domains,\nwhile RL converges quickly, limiting their data utilization efficiency. To\naddress these issues, we propose EvolveSearch, a novel iterative self-evolution\nframework that combines SFT and RL to enhance agentic web search capabilities\nwithout any external human-annotated reasoning data. Extensive experiments on\nseven multi-hop question-answering (MHQA) benchmarks demonstrate that\nEvolveSearch consistently improves performance across iterations, ultimately\nachieving an average improvement of 4.7\\% over the current state-of-the-art\nacross seven benchmarks, opening the door to self-evolution agentic\ncapabilities in open web search domains.','Dingchu Zhang, Yida Zhao, Jialong Wu, Baixuan Li, Wenbiao Yin, Liwen Zhang, Yong Jiang, Yufeng Li, Kewei Tu, Pengjun Xie, Fei Huang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22501v1'),('2505.22502v1','Assessing Quantum Advantage for Gaussian Process Regression','Gaussian Process Regression is a well-known machine learning technique for\nwhich several quantum algorithms have been proposed. We show here that in a\nwide range of scenarios these algorithms show no exponential speedup. We\nachieve this by rigorously proving that the condition number of a kernel matrix\nscales at least linearly with the matrix size under general assumptions on the\ndata and kernel. We additionally prove that the sparsity and Frobenius norm of\na kernel matrix scale linearly under similar assumptions. The implications for\nthe quantum algorithms runtime are independent of the complexity of loading\nclassical data on a quantum computer and also apply to dequantised algorithms.\nWe supplement our theoretical analysis with numerical verification for popular\nkernels in machine learning.','Dominic Lowe, M. S. Kim, Roberto Bondesan','2025-05-28','quant-ph','http://arxiv.org/pdf/2505.22502v1'),('2505.22503v1','From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation','While embodied agents have made significant progress in performing complex\nphysical tasks, real-world applications demand more than pure task execution.\nThe agents must collaborate with unfamiliar agents and human users, whose goals\nare often vague and implicit. In such settings, interpreting ambiguous\ninstructions and uncovering underlying desires is essential for effective\nassistance. Therefore, fast and accurate desire alignment becomes a critical\ncapability for embodied agents. In this work, we first develop a home\nassistance simulation environment HA-Desire that integrates an LLM-driven human\nuser agent exhibiting realistic value-driven goal selection and communication.\nThe ego agent must interact with this proxy user to infer and adapt to the\nuser\\\'s latent desires. To achieve this, we present a novel framework FAMER for\nfast desire alignment, which introduces a desire-based mental reasoning\nmechanism to identify user intent and filter desire-irrelevant actions. We\nfurther design a reflection-based communication module that reduces redundant\ninquiries, and incorporate goal-relevant information extraction with memory\npersistence to improve information reuse and reduce unnecessary exploration.\nExtensive experiments demonstrate that our framework significantly enhances\nboth task execution and communication efficiency, enabling embodied agents to\nquickly adapt to user-specific desires in complex embodied environments.','Yuanfei Wang, Xinju Huang, Fangwei Zhong, Yaodong Yang, Yizhou Wang, Yuanpei Chen, Hao Dong','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.22503v1'),('2505.22504v1','Geometric GNNs for Charged Particle Tracking at GlueX','Nuclear physics experiments are aimed at uncovering the fundamental building\nblocks of matter. The experiments involve high-energy collisions that produce\ncomplex events with many particle trajectories. Tracking charged particles\nresulting from collisions in the presence of a strong magnetic field is\ncritical to enable the reconstruction of particle trajectories and precise\ndetermination of interactions. It is traditionally achieved through\ncombinatorial approaches that scale worse than linearly as the number of hits\ngrows. Since particle hit data naturally form a 3-dimensional point cloud and\ncan be structured as graphs, Graph Neural Networks (GNNs) emerge as an\nintuitive and effective choice for this task. In this study, we evaluate the\nGNN model for track finding on the data from the GlueX experiment at Jefferson\nLab. We use simulation data to train the model and test on both simulation and\nreal GlueX measurements. We demonstrate that GNN-based track finding\noutperforms the currently used traditional method at GlueX in terms of\nsegment-based efficiency at a fixed purity while providing faster inferences.\nWe show that the GNN model can achieve significant speedup by processing\nmultiple events in batches, which exploits the parallel computation capability\nof Graphical Processing Units (GPUs). Finally, we compare the GNN\nimplementation on GPU and FPGA and describe the trade-off.','Ahmed Hossam Mohammed, Kishansingh Rajput, Simon Taylor, Denis Furletov, Sergey Furletov, Malachi Schram','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22504v1'),('2505.22506v1','Sparsification and Reconstruction from the Perspective of Representation Geometry','Sparse Autoencoders (SAEs) have emerged as a predominant tool in mechanistic\ninterpretability, aiming to identify interpretable monosemantic features.\nHowever, how does sparse encoding organize the representations of activation\nvector from language models? What is the relationship between this\norganizational paradigm and feature disentanglement as well as reconstruction\nperformance? To address these questions, we propose the SAEMA, which validates\nthe stratified structure of the representation by observing the variability of\nthe rank of the symmetric semipositive definite (SSPD) matrix corresponding to\nthe modal tensor unfolded along the latent tensor with the level of noise added\nto the residual stream. To systematically investigate how sparse encoding\nalters representational structures, we define local and global representations,\ndemonstrating that they amplify inter-feature distinctions by merging similar\nsemantic features and introducing additional dimensionality. Furthermore, we\nintervene the global representation from an optimization perspective, proving a\nsignificant causal relationship between their separability and the\nreconstruction performance. This study explains the principles of sparsity from\nthe perspective of representational geometry and demonstrates the impact of\nchanges in representational structure on reconstruction performance.\nParticularly emphasizes the necessity of understanding representations and\nincorporating representational constraints, providing empirical references for\ndeveloping new interpretable tools and improving SAEs. The code is available at\n\\hyperlink{https://github.com/wenjie1835/SAERepGeo}{https://github.com/wenjie1835/SAERepGeo}.','Wenjie Sun, Bingzhe Wu, Zhile Yang, Chengke Wu','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22506v1'),('2505.22509v1','Accelerating Optimization via Differentiable Stopping Time','Optimization is an important module of modern machine learning applications.\nTremendous efforts have been made to accelerate optimization algorithms. A\ncommon formulation is achieving a lower loss at a given time. This enables a\ndifferentiable framework with respect to the algorithm hyperparameters. In\ncontrast, its dual, minimizing the time to reach a target loss, is believed to\nbe non-differentiable, as the time is not differentiable. As a result, it\nusually serves as a conceptual framework or is optimized using zeroth-order\nmethods. To address this limitation, we propose a differentiable stopping time\nand theoretically justify it based on differential equations. An efficient\nalgorithm is designed to backpropagate through it. As a result, the proposed\ndifferentiable stopping time enables a new differentiable formulation for\naccelerating algorithms. We further discuss its applications, such as online\nhyperparameter tuning and learning to optimize. Our proposed methods show\nsuperior performance in comprehensive experiments across various problems,\nwhich confirms their effectiveness.','Zhonglin Xie, Yiman Fong, Haoran Yuan, Zaiwen Wen','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22509v1'),('2505.22513v1','Strengthening Proportionality in Temporal Voting','We study proportional representation in the framework of temporal voting with\napproval ballots. Prior work adapted basic proportional representation concepts\n-- justified representation (JR), proportional JR (PJR), and extended JR (EJR)\n-- from the multiwinner setting to the temporal setting. Our work introduces\nand examines ways of going beyond EJR. Specifically, we consider stronger\nvariants of JR, PJR, and EJR, and introduce temporal adaptations of more\ndemanding multiwinner axioms, such as EJR+, full JR (FJR), full proportional JR\n(FPJR), and the Core. For each of these concepts, we investigate its existence\nand study its relationship to existing notions, thereby establishing a rich\nhierarchy of proportionality concepts. Notably, we show that two of our\nproposed axioms -- EJR+ and FJR -- strengthen EJR while remaining satisfiable\nin every temporal election.','Bradley Phillips, Edith Elkind, Nicholas Teh, Tomasz Wąs','2025-05-28','cs.GT','http://arxiv.org/pdf/2505.22513v1'),('2505.22517v1','Multi-MLLM Knowledge Distillation for Out-of-Context News Detection','Multimodal out-of-context news is a type of misinformation in which the image\nis used outside of its original context. Many existing works have leveraged\nmultimodal large language models (MLLMs) for detecting out-of-context news.\nHowever, observing the limited zero-shot performance of smaller MLLMs, they\ngenerally require label-rich fine-tuning and/or expensive API calls to GPT\nmodels to improve the performance, which is impractical in low-resource\nscenarios. In contrast, we aim to improve the performance of small MLLMs in a\nmore label-efficient and cost-effective manner. To this end, we first prompt\nmultiple teacher MLLMs to generate both label predictions and corresponding\nrationales, which collectively serve as the teachers\\\' knowledge. We then\nintroduce a two-stage knowledge distillation framework to transfer this\nknowledge to a student MLLM. In Stage 1, we apply LoRA fine-tuning to the\nstudent model using all training data. In Stage 2, we further fine-tune the\nstudent model using both LoRA fine-tuning and DPO on the data points where\nteachers\\\' predictions conflict. This two-stage strategy reduces annotation\ncosts and helps the student model uncover subtle patterns in more challenging\ncases. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance using less than 10% labeled data.','Yimeng Gu, Zhao Tong, Ignacio Castro, Shu Wu, Gareth Tyson','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22517v1'),('2505.22518v1','IGNIS: A Neural Network Framework for Robust Parameter Estimation in Archimedean Copulas','Parameter estimation for Archimedean copulas remains a challenging problem,\nparticularly for the recently developed A1 and A2 families that exhibit complex\ndependency structures. Traditional methods, such as the Method of Moments\n(MoM), Maximum Likelihood Estimation (MLE), and Maximum Pseudo-Likelihood\n(MPL), often struggle due to issues of non-monotonic relationship with\ndependency measures such as Kendall\\\'s tau (as in the case of A1) and numerical\ninstability. In this paper, we present the IGNIS Network, a novel, unified\nneural framework that learns a direct mapping from observable dependency\nmeasures to copula parameters, thereby overcoming the limitations of classical\napproaches. Our approach is trained on simulated data spanning five Archimedean\ncopula families including Clayton, Gumbel, Frank, A1, and A2, ensuring its\ngeneral applicability across the entire family. Extensive simulation studies\ndemonstrate that the IGNIS Network reduces estimation errors compared to MoM,\nwhile inherently enforcing parameter constraints through theory-guided\npost-processing. We further validate the practical utility of our method on\ndiverse real-world datasets, including financial returns (AAPL-MSFT),\nhealthcare metrics (CDC Diabetes indicators), and environmental measurements\n(PM2.5 air quality). Our results underscore the transformative potential of\nneural methods for robust and accurate dependence modeling in modern\napplications.','Agnideep Aich, Ashit Baran Aich, Bruce Wade','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22518v1'),('2505.22521v1','Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data','Fraud detection remains a critical task in high-stakes domains such as\nfinance and e-commerce, where undetected fraudulent transactions can lead to\nsignificant economic losses. In this study, we systematically compare the\nperformance of four supervised learning models - Logistic Regression, Random\nForest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit\n(GRU) network - on a large-scale, highly imbalanced online transaction dataset.\nWhile ensemble methods such as Random Forest and LightGBM demonstrated superior\nperformance in both overall and class-specific metrics, Logistic Regression\noffered a reliable and interpretable baseline. The GRU model showed strong\nrecall for the minority fraud class, though at the cost of precision,\nhighlighting a trade-off relevant for real-world deployment. Our evaluation\nemphasizes not only weighted averages but also per-class precision, recall, and\nF1-scores, providing a nuanced view of each model\\\'s effectiveness in detecting\nrare but consequential fraudulent activity. The findings underscore the\nimportance of choosing models based on the specific risk tolerance and\noperational needs of fraud detection systems.','Chao Wang, Chuanhao Nie, Yunbo Liu','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22521v1'),('2505.22524v1','Test-Time Alignment of Discrete Diffusion Models with Sequential Monte Carlo','Discrete diffusion models have become highly effective across various\ndomains. However, real-world applications often require the generative process\nto adhere to certain constraints but without task-specific fine-tuning. To this\nend, we propose a training-free method based on Sequential Monte Carlo (SMC) to\nsample from the reward-aligned target distribution at the test time. Our\napproach leverages twisted SMC with an approximate locally optimal proposal,\nobtained via a first-order Taylor expansion of the reward function. To address\nthe challenge of ill-defined gradients in discrete spaces, we incorporate a\nGumbel-Softmax relaxation, enabling efficient gradient-based approximation\nwithin the discrete generative framework. Empirical results on both synthetic\ndatasets and image modelling validate the effectiveness of our approach.','Chinmay Pani, Zijing Ou, Yingzhen Li','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22524v1'),('2505.22525v1','Thinking with Generated Images','We present Thinking with Generated Images, a novel paradigm that\nfundamentally transforms how large multimodal models (LMMs) engage with visual\nreasoning by enabling them to natively think across text and vision modalities\nthrough spontaneous generation of intermediate visual thinking steps. Current\nvisual reasoning with LMMs is constrained to either processing fixed\nuser-provided images or reasoning solely through text-based chain-of-thought\n(CoT). Thinking with Generated Images unlocks a new dimension of cognitive\ncapability where models can actively construct intermediate visual thoughts,\ncritique their own visual hypotheses, and refine them as integral components of\ntheir reasoning process. We demonstrate the effectiveness of our approach\nthrough two complementary mechanisms: (1) vision generation with intermediate\nvisual subgoals, where models decompose complex visual tasks into manageable\ncomponents that are generated and integrated progressively, and (2) vision\ngeneration with self-critique, where models generate an initial visual\nhypothesis, analyze its shortcomings through textual reasoning, and produce\nrefined outputs based on their own critiques. Our experiments on vision\ngeneration benchmarks show substantial improvements over baseline approaches,\nwith our models achieving up to 50% (from 38% to 57%) relative improvement in\nhandling complex multi-object scenarios. From biochemists exploring novel\nprotein structures, and architects iterating on spatial designs, to forensic\nanalysts reconstructing crime scenes, and basketball players envisioning\nstrategic plays, our approach enables AI models to engage in the kind of visual\nimagination and iterative refinement that characterizes human creative,\nanalytical, and strategic thinking. We release our open-source suite at\nhttps://github.com/GAIR-NLP/thinking-with-generated-images.','Ethan Chern, Zhulin Hu, Steffi Chern, Siqi Kou, Jiadi Su, Yan Ma, Zhijie Deng, Pengfei Liu','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22525v1'),('2505.22527v1','Symplectic Generative Networks (SGNs): A Hamiltonian Framework for Invertible Deep Generative Modeling','We introduce the Symplectic Generative Network (SGN), a deep generative model\nthat leverages Hamiltonian mechanics to construct an invertible,\nvolume-preserving mapping between a latent space and the data space. By\nendowing the latent space with a symplectic structure and modeling data\ngeneration as the time evolution of a Hamiltonian system, SGN achieves exact\nlikelihood evaluation without incurring the computational overhead of Jacobian\ndeterminant calculations. In this work, we provide a rigorous mathematical\nfoundation for SGNs through a comprehensive theoretical framework that\nincludes: (i) complete proofs of invertibility and volume preservation, (ii) a\nformal complexity analysis with theoretical comparisons to Variational\nAutoencoders and Normalizing Flows, (iii) strengthened universal approximation\nresults with quantitative error bounds, (iv) an information-theoretic analysis\nbased on the geometry of statistical manifolds, and (v) an extensive stability\nanalysis with adaptive integration guarantees. These contributions highlight\nthe fundamental advantages of SGNs and establish a solid foundation for future\nempirical investigations and applications to complex, high-dimensional data.','Agnideep Aich, Ashit Aich, Bruce Wade','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22527v1'),('2505.22531v1','Training RL Agents for Multi-Objective Network Defense Tasks','Open-ended learning (OEL) -- which emphasizes training agents that achieve\nbroad capability over narrow competency -- is emerging as a paradigm to develop\nartificial intelligence (AI) agents to achieve robustness and generalization.\nHowever, despite promising results that demonstrate the benefits of OEL,\napplying OEL to develop autonomous agents for real-world cybersecurity\napplications remains a challenge.\n  We propose a training approach, inspired by OEL, to develop autonomous\nnetwork defenders. Our results demonstrate that like in other domains, OEL\nprinciples can translate into more robust and generalizable agents for cyber\ndefense. To apply OEL to network defense, it is necessary to address several\ntechnical challenges. Most importantly, it is critical to provide a task\nrepresentation approach over a broad universe of tasks that maintains a\nconsistent interface over goals, rewards and action spaces. This way, the\nlearning agent can train with varying network conditions, attacker behaviors,\nand defender goals while being able to build on previously gained knowledge.\n  With our tools and results, we aim to fundamentally impact research that\napplies AI to solve cybersecurity problems. Specifically, as researchers\ndevelop gyms and benchmarks for cyber defense, it is paramount that they\nconsider diverse tasks with consistent representations, such as those we\npropose in our work.','Andres Molina-Markham, Luis Robaina, Sean Steinle, Akash Trivedi, Derek Tsui, Nicholas Potteiger, Lauren Brandt, Ransom Winder, Ahmed Ridley','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22531v1'),('2505.22533v1','TabularQGAN: A Quantum Generative Model for Tabular Data','In this paper, we introduce a novel quantum generative model for synthesizing\ntabular data. Synthetic data is valuable in scenarios where real-world data is\nscarce or private, it can be used to augment or replace existing datasets.\nReal-world enterprise data is predominantly tabular and heterogeneous, often\ncomprising a mixture of categorical and numerical features, making it highly\nrelevant across various industries such as healthcare, finance, and software.\nWe propose a quantum generative adversarial network architecture with flexible\ndata encoding and a novel quantum circuit ansatz to effectively model tabular\ndata. The proposed approach is tested on the MIMIC III healthcare and Adult\nCensus datasets, with extensive benchmarking against leading classical models,\nCTGAN, and CopulaGAN. Experimental results demonstrate that our quantum model\noutperforms classical models by an average of 8.5% with respect to an overall\nsimilarity score from SDMetrics, while using only 0.072% of the parameters of\nthe classical models. Additionally, we evaluate the generalization capabilities\nof the models using two custom-designed metrics that demonstrate the ability of\nthe proposed quantum model to generate useful and novel samples. To our\nknowledge, this is one of the first demonstrations of a successful quantum\ngenerative model for handling tabular data, indicating that this task could be\nwell-suited to quantum computers.','Pallavi Bhardwaj, Caitlin Jones, Lasse Dierich, Aleksandar Vučković','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22533v1'),('2505.22535v1','RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting','Recent deep learning approaches for river discharge forecasting have improved\nthe accuracy and efficiency in flood forecasting, enabling more reliable early\nwarning systems for risk management. Nevertheless, existing deep learning\napproaches in hydrology remain largely confined to local-scale applications and\ndo not leverage the inherent spatial connections of bodies of water. Thus,\nthere is a strong need for new deep learning methodologies that are capable of\nmodeling spatio-temporal relations to improve river discharge and flood\nforecasting for scientific and operational applications. To address this, we\npresent RiverMamba, a novel deep learning model that is pretrained with\nlong-term reanalysis data and that can forecast global river discharge and\nfloods on a $0.05^\\circ$ grid up to 7 days lead time, which is of high\nrelevance in early warning. To achieve this, RiverMamba leverages efficient\nMamba blocks that enable the model to capture global-scale channel network\nrouting and enhance its forecast capability for longer lead times. The forecast\nblocks integrate ECMWF HRES meteorological forecasts, while accounting for\ntheir inaccuracies through spatio-temporal modeling. Our analysis demonstrates\nthat RiverMamba delivers reliable predictions of river discharge, including\nextreme floods across return periods and lead times, surpassing both\noperational AI- and physics-based models.','Mohamad Hakam Shams Eddin, Yikui Zahng, Stefan Kollet, Juergen Gall','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22535v1'),('2505.22538v1','Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks','We address the problem of uncertainty quantification and propose measures of\ntotal, aleatoric, and epistemic uncertainty based on a known decomposition of\n(strictly) proper scoring rules, a specific type of loss function, into a\ndivergence and an entropy component. This leads to a flexible framework for\nuncertainty quantification that can be instantiated with different losses\n(scoring rules), which makes it possible to tailor uncertainty quantification\nto the use case at hand. We show that this flexibility is indeed advantageous.\nIn particular, we analyze the task of selective prediction and show that the\nscoring rule should ideally match the task loss. In addition, we perform\nexperiments on two other common tasks. For out-of-distribution detection, our\nresults confirm that a widely used measure of epistemic uncertainty, mutual\ninformation, performs best. Moreover, in the setting of active learning, our\nmeasure of epistemic uncertainty based on the zero-one-loss consistently\noutperforms other uncertainty measures.','Paul Hofman, Yusuf Sale, Eyke Hüllermeier','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22538v1'),('2505.22541v1','A Human-Centric Approach to Explainable AI for Personalized Education','Deep neural networks form the backbone of artificial intelligence research,\nwith potential to transform the human experience in areas ranging from\nautonomous driving to personal assistants, healthcare to education. However,\ntheir integration into the daily routines of real-world classrooms remains\nlimited. It is not yet common for a teacher to assign students individualized\nhomework targeting their specific weaknesses, provide students with instant\nfeedback, or simulate student responses to a new exam question. While these\nmodels excel in predictive performance, this lack of adoption can be attributed\nto a significant weakness: the lack of explainability of model decisions,\nleading to a lack of trust from students, parents, and teachers. This thesis\naims to bring human needs to the forefront of eXplainable AI (XAI) research,\ngrounded in the concrete use case of personalized learning and teaching. We\nframe the contributions along two verticals: technical advances in XAI and\ntheir aligned human studies. We investigate explainability in AI for education,\nrevealing systematic disagreements between post-hoc explainers and identifying\na need for inherently interpretable model architectures. We propose four novel\ntechnical contributions in interpretability with a multimodal modular\narchitecture (MultiModN), an interpretable mixture-of-experts model\n(InterpretCC), adversarial training for explainer stability, and a\ntheory-driven LLM-XAI framework to present explanations to students\n(iLLuMinaTE), which we evaluate in diverse settings with professors, teachers,\nlearning scientists, and university students. By combining empirical\nevaluations of existing explainers with novel architectural designs and human\nstudies, our work lays a foundation for human-centric AI systems that balance\nstate-of-the-art performance with built-in transparency and trust.','Vinitra Swamy','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22541v1'),('2505.22543v1','Scaling-up Perceptual Video Quality Assessment','The data scaling law has been shown to significantly enhance the performance\nof large multi-modal models (LMMs) across various downstream tasks. However, in\nthe domain of perceptual video quality assessment (VQA), the potential of\nscaling law remains unprecedented due to the scarcity of labeled resources and\nthe insufficient scale of datasets. To address this, we propose\n\\textbf{OmniVQA}, an efficient framework designed to efficiently build\nhigh-quality, human-in-the-loop VQA multi-modal instruction databases (MIDBs).\nWe then scale up to create \\textbf{OmniVQA-Chat-400K}, the largest MIDB in the\nVQA field concurrently. Our focus is on the technical and aesthetic quality\ndimensions, with abundant in-context instruction data to provide fine-grained\nVQA knowledge. Additionally, we have built the \\textbf{OmniVQA-MOS-20K} dataset\nto enhance the model\\\'s quantitative quality rating capabilities. We then\nintroduce a \\textbf{complementary} training strategy that effectively leverages\nthe knowledge from datasets for quality understanding and quality rating tasks.\nFurthermore, we propose the \\textbf{OmniVQA-FG (fine-grain)-Benchmark} to\nevaluate the fine-grained performance of the models. Our results demonstrate\nthat our models achieve state-of-the-art performance in both quality\nunderstanding and rating tasks.','Ziheng Jia, Zicheng Zhang, Zeyu Zhang, Yingji Liang, Xiaorong Zhu, Chunyi Li, Jinliang Han, Haoning Wu, Bin Wang, Haoran Zhang, Guanyu Zhu, Qiyong Zhao, Xiaohong Liu, Guangtao Zhai, Xiongkuo Min','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22543v1'),('2505.22548v1','Emotion-o1: Adaptive Long Reasoning for Emotion Understanding in LLMs','Emotion understanding includes basic tasks (e.g., sentiment/emotion\nclassification) and advanced tasks (e.g., sarcasm/humor detection). Current\nmethods rely on fixed-length CoT reasoning, failing to adapt to the varying\ncomplexity of emotions. We propose a task-adaptive reasoning framework that\nemploys DeepSeek-R1 to generate variable-length reasoning chains for different\nemotion tasks. By combining fine-tuning with reinforcement learning, we design\na composite reward function that balances four objectives: prediction accuracy,\nadaptive reasoning depth control, structural diversity in reasoning paths, and\nsuppression of repetitive logic. This approach achieves dynamic\ncontext-sensitive inference while enabling LLMs to autonomously develop deep\nreasoning capabilities. Experimental results demonstrate consistent\nimprovements in both Acc and F1 scores across four tasks: emotion, sentiment,\nhumor, and sarcasm. Notably, peak enhancements reached 3.56% F1 (2.76% Acc) for\nbasic tasks and 37.95% F1 (23.14% Acc) for advanced tasks. Our work bridges\nrigid CoT reasoning and emotional complexity through adaptive-depth analysis.','Changhao Song, Yazhou Zhang, Peng Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22548v1'),('2505.22549v1','DES-LOC: Desynced Low Communication Adaptive Optimizers for Training Foundation Models','Scaling foundation model training with Distributed Data Parallel (DDP)\nmethods is bandwidth-limited. Existing infrequent communication methods like\nLocal SGD were designed to synchronize only model parameters and cannot be\ntrivially applied to adaptive optimizers due to additional optimizer states.\nCurrent approaches extending Local SGD either lack convergence guarantees or\nrequire synchronizing all optimizer states, tripling communication costs. We\npropose Desynced Low Communication Adaptive Optimizers (DES-LOC), a family of\noptimizers assigning independent synchronization periods to parameters and\nmomenta, enabling lower communication costs while preserving convergence.\nThrough extensive experiments on language models of up to 1.7B, we show that\nDES-LOC can communicate 170x less than DDP and 2x less than the previous\nstate-of-the-art Local ADAM. Furthermore, unlike previous heuristic approaches,\nDES-LOC is suited for practical training scenarios prone to system failures.\nDES-LOC offers a scalable, bandwidth-efficient, and fault-tolerant solution for\nfoundation model training.','Alex Iacob, Lorenzo Sani, Mher Safaryan, Paris Giampouras, Samuel Horváth, Andrej Jovanovic, Meghdad Kurmanji, Preslav Aleksandrov, William F. Shen, Xinchi Qiu, Nicholas D. Lane','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22549v1'),('2505.22552v1','ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM','Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of\nlarge language models (LLMs) is an emerging research challenge in claim\nverification. While KGs provide structured, semantically rich representations\nwell-suited for reasoning, most existing verification methods rely on\nunstructured text corpora, limiting their ability to effectively leverage KGs.\nAdditionally, despite possessing strong reasoning abilities, modern LLMs\nstruggle with multi-step modular pipelines and reasoning over KGs without\nadaptation. To address these challenges, we propose ClaimPKG, an end-to-end\nframework that seamlessly integrates LLM reasoning with structured knowledge\nfrom KGs. Specifically, the main idea of ClaimPKG is to employ a lightweight,\nspecialized LLM to represent the input claim as pseudo-subgraphs, guiding a\ndedicated subgraph retrieval module to identify relevant KG subgraphs. These\nretrieved subgraphs are then processed by a general-purpose LLM to produce the\nfinal verdict and justification. Extensive experiments on the FactKG dataset\ndemonstrate that ClaimPKG achieves state-of-the-art performance, outperforming\nstrong baselines in this research field by 9%-12% accuracy points across\nmultiple categories. Furthermore, ClaimPKG exhibits zero-shot generalizability\nto unstructured datasets such as HoVer and FEVEROUS, effectively combining\nstructured knowledge from KGs with LLM reasoning across various LLM backbones.','Hoang Pham, Thanh-Do Nguyen, Khac-Hoai Nam Bui','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22552v1'),('2505.22554v1','Can Copulas Be Used for Feature Selection? A Machine Learning Study on Diabetes Risk Prediction','Accurate diabetes risk prediction relies on identifying key features from\ncomplex health datasets, but conventional methods like mutual information (MI)\nfilters and genetic algorithms (GAs) often overlook extreme dependencies\ncritical for high-risk subpopulations. In this study we introduce a\nfeature-selection framework using the upper-tail dependence coefficient\n({\\lambda}U) of the novel A2 copula, which quantifies how often extreme higher\nvalues of a predictor co-occur with diabetes diagnoses (target variable).\nApplied to the CDC Diabetes Health Indicators dataset (n=253,680), our method\nprioritizes five predictors (self-reported general health, high blood pressure,\nbody mass index, mobility limitations, and high cholesterol levels) based on\nupper tail dependencies. These features match or outperform MI and GA selected\nsubsets across four classifiers (Random Forest, XGBoost, Logistic Regression,\nGradient Boosting), achieving accuracy up to 86.5% (XGBoost) and AUC up to\n0.806 (Gradient Boosting), rivaling the full 21-feature model. Permutation\nimportance confirms clinical relevance, with BMI and general health driving\naccuracy. To our knowledge, this is the first work to apply a copula\\\'s\nupper-tail dependence for supervised feature selection, bridging extreme-value\ntheory and machine learning to deliver a practical toolkit for diabetes\nprevention.','Agnideep Aich, Md Monzur Murshed, Amanda Mayeaux, Sameera Hewage','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22554v1'),('2505.22560v1','Geometric Hyena Networks for Large-scale Equivariant Learning','Processing global geometric context while preserving equivariance is crucial\nwhen modeling biological, chemical, and physical systems. Yet, this is\nchallenging due to the computational demands of equivariance and global context\nat scale. Standard methods such as equivariant self-attention suffer from\nquadratic complexity, while local methods such as distance-based message\npassing sacrifice global information. Inspired by the recent success of\nstate-space and long-convolutional models, we introduce Geometric Hyena, the\nfirst equivariant long-convolutional model for geometric systems. Geometric\nHyena captures global geometric context at sub-quadratic complexity while\nmaintaining equivariance to rotations and translations. Evaluated on all-atom\nproperty prediction of large RNA molecules and full protein molecular dynamics,\nGeometric Hyena outperforms existing equivariant models while requiring\nsignificantly less memory and compute that equivariant self-attention. Notably,\nour model processes the geometric context of 30k tokens 20x faster than the\nequivariant transformer and allows 72x longer context within the same budget.','Artem Moskalev, Mangal Prakash, Junjie Xu, Tianyu Cui, Rui Liao, Tommaso Mansi','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22560v1'),('2505.22563v1','Do Large Language Models Think Like the Brain? Sentence-Level Evidence from fMRI and Hierarchical Embeddings','Understanding whether large language models (LLMs) and the human brain\nconverge on similar computational principles remains a fundamental and\nimportant question in cognitive neuroscience and AI. Do the brain-like patterns\nobserved in LLMs emerge simply from scaling, or do they reflect deeper\nalignment with the architecture of human language processing? This study\nfocuses on the sentence-level neural mechanisms of language models,\nsystematically investigating how hierarchical representations in LLMs align\nwith the dynamic neural responses during human sentence comprehension. By\ncomparing hierarchical embeddings from 14 publicly available LLMs with fMRI\ndata collected from participants, who were exposed to a naturalistic narrative\nstory, we constructed sentence-level neural prediction models to precisely\nidentify the model layers most significantly correlated with brain region\nactivations. Results show that improvements in model performance drive the\nevolution of representational architectures toward brain-like hierarchies,\nparticularly achieving stronger functional and anatomical correspondence at\nhigher semantic abstraction levels.','Yu Lei, Xingyang Ge, Yi Zhang, Yiming Yang, Bolei Ma','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22563v1'),('2505.22564v1','PRISM: Video Dataset Condensation with Progressive Refinement and Insertion for Sparse Motion','Video dataset condensation has emerged as a critical technique for addressing\nthe computational challenges associated with large-scale video data processing\nin deep learning applications. While significant progress has been made in\nimage dataset condensation, the video domain presents unique challenges due to\nthe complex interplay between spatial content and temporal dynamics. This paper\nintroduces PRISM, Progressive Refinement and Insertion for Sparse Motion, for\nvideo dataset condensation, a novel approach that fundamentally reconsiders how\nvideo data should be condensed. Unlike the previous method that separates\nstatic content from dynamic motion, our method preserves the essential\ninterdependence between these elements. Our approach progressively refines and\ninserts frames to fully accommodate the motion in an action while achieving\nbetter performance but less storage, considering the relation of gradients for\neach frame. Extensive experiments across standard video action recognition\nbenchmarks demonstrate that PRISM outperforms existing disentangled approaches\nwhile maintaining compact representations suitable for resource-constrained\nenvironments.','Jaehyun Choi, Jiwan Hur, Gyojin Han, Jaemyung Yu, Junmo Kim','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22564v1'),('2505.22566v1','Universal Visuo-Tactile Video Understanding for Embodied Interaction','Tactile perception is essential for embodied agents to understand physical\nattributes of objects that cannot be determined through visual inspection\nalone. While existing approaches have made progress in visual and language\nmodalities for physical understanding, they fail to effectively incorporate\ntactile information that provides crucial haptic feedback for real-world\ninteraction. In this paper, we present VTV-LLM, the first multi-modal large\nlanguage model for universal Visuo-Tactile Video (VTV) understanding that\nbridges the gap between tactile perception and natural language. To address the\nchallenges of cross-sensor and cross-modal integration, we contribute VTV150K,\na comprehensive dataset comprising 150,000 video frames from 100 diverse\nobjects captured across three different tactile sensors (GelSight Mini, DIGIT,\nand Tac3D), annotated with four fundamental tactile attributes (hardness,\nprotrusion, elasticity, and friction). We develop a novel three-stage training\nparadigm that includes VTV enhancement for robust visuo-tactile representation,\nVTV-text alignment for cross-modal correspondence, and text prompt finetuning\nfor natural language generation. Our framework enables sophisticated tactile\nreasoning capabilities including feature assessment, comparative analysis,\nscenario-based decision making and so on. Experimental evaluations demonstrate\nthat VTV-LLM achieves superior performance in tactile video understanding\ntasks, establishing a foundation for more intuitive human-machine interaction\nin tactile domains.','Yifan Xie, Mingyang Li, Shoujie Li, Xingting Li, Guangyu Chen, Fei Ma, Fei Richard Yu, Wenbo Ding','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22566v1'),('2505.22571v1','Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems','This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.','Hoang Pham, Khac-Hoai Nam Bui','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22571v1'),('2505.22572v1','Fusion Steering: Prompt-Specific Activation Control','We present Fusion Steering, an activation steering methodology that improves\nfactual accuracy in large language models (LLMs) for question-answering (QA)\ntasks. This approach introduces flexible steering configurations, including\nfull-layer steering and segmented steering. Unlike traditional methods\nconstrained to single-layer or fixed-layer operations, Fusion Steering employs\ndynamic injection of prompt-specific activation deltas across all transformer\nlayers. These activation deltas are derived from reference completions that\ncombine the ground-truth answer with a model-generated explanation to\nfacilitate semantically enriched, example-specific steering. The injection\nweights are optimized per prompt using Optuna, targeting a joint objective that\nbalances token overlap (factual alignment) and perplexity (fluency proxy).\nEvaluation employs a composite score integrating token overlap and LLM-graded\nquality, encompassing factual accuracy, coherence, and relevance. Empirical\nresults on 260 SimpleQA prompts (selected from 500 where the baseline failed)\nshowcase the efficacy of segmented steering. Using Gemma-2-2B-IT with 8-bit\nquantization, segmented steering achieves an accuracy of 25.4% (outputs scoring\n$\\geq 0.6$), outperforming the baseline at 3.5% and full-layer steering at\n16.2%. Under the stricter SimpleQA rubric, segmented steering boosts fully\ncorrect responses from 0.0% to 13.1%. These findings highlight the strengths of\nsegmented, dynamic intervention strategies and the promise of per-prompt,\nfull-network activation control. Fusion Steering is also amenable to sparse\nrepresentations, such as Neuronpedia or sparse crosscoders, suggesting a\npromising direction for interpretable and scalable activation-level control in\nLLMs.','Waldemar Chang, Alhassan Yasin','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22572v1'),('2505.22573v1','FNOPE: Simulation-based inference on function spaces with Fourier Neural Operators','Simulation-based inference (SBI) is an established approach for performing\nBayesian inference on scientific simulators. SBI so far works best on\nlow-dimensional parametric models. However, it is difficult to infer\nfunction-valued parameters, which frequently occur in disciplines that model\nspatiotemporal processes such as the climate and earth sciences. Here, we\nintroduce an approach for efficient posterior estimation, using a Fourier\nNeural Operator (FNO) architecture with a flow matching objective. We show that\nour approach, FNOPE, can perform inference of function-valued parameters at a\nfraction of the simulation budget of state of the art methods. In addition,\nFNOPE supports posterior evaluation at arbitrary discretizations of the domain,\nas well as simultaneous estimation of vector-valued parameters. We demonstrate\nthe effectiveness of our approach on several benchmark tasks and a challenging\nspatial inference task from glaciology. FNOPE extends the applicability of SBI\nmethods to new scientific domains by enabling the inference of function-valued\nparameters.','Guy Moss, Leah Sophie Muhle, Reinhard Drews, Jakob H. Macke, Cornelius Schröder','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22573v1'),('2505.22578v1','Benignity of loss landscape with weight decay requires both large overparametrization and initialization','The optimization of neural networks under weight decay remains poorly\nunderstood from a theoretical standpoint. While weight decay is standard\npractice in modern training procedures, most theoretical analyses focus on\nunregularized settings. In this work, we investigate the loss landscape of the\n$\\ell_2$-regularized training loss for two-layer ReLU networks. We show that\nthe landscape becomes benign -- i.e., free of spurious local minima -- under\nlarge overparametrization, specifically when the network width $m$ satisfies $m\n\\gtrsim \\min(n^d, 2^n)$, where $n$ is the number of data points and $d$ the\ninput dimension. More precisely in this regime, almost all constant activation\nregions contain a global minimum and no spurious local minima. We further show\nthat this level of overparametrization is not only sufficient but also\nnecessary via the example of orthogonal data. Finally, we demonstrate that such\nloss landscape results primarily hold relevance in the large initialization\nregime. In contrast, for small initializations -- corresponding to the feature\nlearning regime -- optimization can still converge to spurious local minima,\ndespite the global benignity of the landscape.','Etienne Boursier, Matthew Bowditch, Matthias Englert, Ranko Lazic','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22578v1'),('2505.22581v1','Tell me Habibi, is it Real or Fake?','Deepfake generation methods are evolving fast, making fake media harder to\ndetect and raising serious societal concerns. Most deepfake detection and\ndataset creation research focuses on monolingual content, often overlooking the\nchallenges of multilingual and code-switched speech, where multiple languages\nare mixed within the same discourse. Code-switching, especially between Arabic\nand English, is common in the Arab world and is widely used in digital\ncommunication. This linguistic mixing poses extra challenges for deepfake\ndetection, as it can confuse models trained mostly on monolingual data. To\naddress this, we introduce \\textbf{ArEnAV}, the first large-scale\nArabic-English audio-visual deepfake dataset featuring intra-utterance\ncode-switching, dialectal variation, and monolingual Arabic content. It\n\\textbf{contains 387k videos and over 765 hours of real and fake videos}. Our\ndataset is generated using a novel pipeline integrating four Text-To-Speech and\ntwo lip-sync models, enabling comprehensive analysis of multilingual multimodal\ndeepfake detection. We benchmark our dataset against existing monolingual and\nmultilingual datasets, state-of-the-art deepfake detection models, and a human\nevaluation, highlighting its potential to advance deepfake research. The\ndataset can be accessed\n\\href{https://huggingface.co/datasets/kartik060702/ArEnAV-Full}{here}.','Kartik Kuckreja, Parul Gupta, Injy Hamed, Thamar Solorio, Muhammad Haris Khan, Abhinav Dhall','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22581v1'),('2505.22582v1','Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts','Continually expanding new languages for existing large language models (LLMs)\nis a promising yet challenging approach to building powerful multilingual LLMs.\nThe biggest challenge is to make the model continuously learn new languages\nwhile preserving the proficient ability of old languages. To achieve this,\nrecent work utilizes the Mixture-of-Experts (MoE) architecture to expand new\nlanguages by adding new experts and avoid catastrophic forgetting of old\nlanguages by routing corresponding tokens to the original model backbone (old\nexperts). Although intuitive, this kind of method is parameter-costly when\nexpanding new languages and still inevitably impacts the performance of old\nlanguages. To address these limitations, we analyze the language\ncharacteristics of different layers in LLMs and propose a layer-wise expert\nallocation algorithm (LayerMoE) to determine the appropriate number of new\nexperts for each layer. Specifically, we find different layers in LLMs exhibit\ndifferent representation similarities between languages and then utilize the\nsimilarity as the indicator to allocate experts for each layer, i.e., the\nhigher similarity, the fewer experts. Additionally, to further mitigate the\nforgetting of old languages, we add a classifier in front of the router network\non the layers with higher similarity to guide the routing of old language\ntokens. Experimental results show that our method outperforms the previous\nstate-of-the-art baseline with 60% fewer experts in the single-expansion\nsetting and with 33.3% fewer experts in the lifelong-expansion setting,\ndemonstrating the effectiveness of our method.','Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22582v1'),('2505.22583v1','GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git','Benchmarks for Software Engineering (SE) AI agents, most notably SWE-bench,\nhave catalyzed progress in programming capabilities of AI agents. However, they\noverlook critical developer workflows such as Version Control System (VCS)\noperations. To address this issue, we present GitGoodBench, a novel benchmark\nfor evaluating AI agent performance on VCS tasks. GitGoodBench covers three\ncore Git scenarios extracted from permissive open-source Python, Java, and\nKotlin repositories. Our benchmark provides three datasets: a comprehensive\nevaluation suite (900 samples), a rapid prototyping version (120 samples), and\na training corpus (17,469 samples). We establish baseline performance on the\nprototyping version of our benchmark using GPT-4o equipped with custom tools,\nachieving a 21.11% solve rate overall. We expect GitGoodBench to serve as a\ncrucial stepping stone toward truly comprehensive SE agents that go beyond mere\nprogramming.','Tobias Lindenbauer, Egor Bogomolov, Yaroslav Zharov','2025-05-28','cs.SE','http://arxiv.org/pdf/2505.22583v1'),('2505.22586v1','Precise In-Parameter Concept Erasure in Large Language Models','Large language models (LLMs) often acquire knowledge during pretraining that\nis undesirable in downstream deployments, e.g., sensitive information or\ncopyrighted content. Existing approaches for removing such knowledge rely on\nfine-tuning, training low-rank adapters or fact-level editing, but these are\neither too coarse, too shallow, or ineffective. In this work, we propose PISCES\n(Precise In-parameter Suppression for Concept EraSure), a novel framework for\nprecisely erasing entire concepts from model parameters by directly editing\ndirections that encode them in parameter space. PISCES uses a disentangler\nmodel to decompose MLP vectors into interpretable features, identifies those\nassociated with a target concept using automated interpretability techniques,\nand removes them from model parameters. Experiments on Gemma 2 and Llama 3.1\nover various concepts show that PISCES achieves modest gains in efficacy over\nleading erasure methods, reducing accuracy on the target concept to as low as\n7.7%, while dramatically improving erasure specificity (by up to 31%) and\nrobustness (by up to 38%). Overall, these results demonstrate that\nfeature-based in-parameter editing enables a more precise and reliable approach\nfor removing conceptual knowledge in language models.','Yoav Gur-Arieh, Clara Suslik, Yihuai Hong, Fazl Barez, Mor Geva','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22586v1'),('2505.22591v1','Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning','Although large language models demonstrate strong performance across various\ndomains, they still struggle with numerous bad cases in mathematical reasoning.\nPrevious approaches to learning from errors synthesize training data by solely\nextrapolating from isolated bad cases, thereby failing to generalize the\nextensive patterns inherent within these cases. This paper presents\nSelf-Error-Instruct (SEI), a framework that addresses these model weaknesses\nand synthesizes more generalized targeted training data. Specifically, we\nexplore a target model on two mathematical datasets, GSM8K and MATH, to\npinpoint bad cases. Then, we generate error keyphrases for these cases based on\nthe instructor model\\\'s (GPT-4o) analysis and identify error types by clustering\nthese keyphrases. Next, we sample a few bad cases during each generation for\neach identified error type and input them into the instructor model, which\nsynthesizes additional training data using a self-instruct approach. This new\ndata is refined through a one-shot learning process to ensure that only the\nmost effective examples are kept. Finally, we use these curated data to\nfine-tune the target model, iteratively repeating the process to enhance\nperformance. We apply our framework to various models and observe improvements\nin their reasoning abilities across both in-domain and out-of-domain\nmathematics datasets. These results demonstrate the effectiveness of self-error\ninstruction in improving LLMs\\\' mathematical reasoning through error\ngeneralization.','Erxin Yu, Jing Li, Ming Liao, Qi Zhu, Boyang Xue, Minghui Xu, Baojun Wang, Lanqing Hong, Fei Mi, Lifeng Shang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22591v1'),('2505.22594v1','GLAMP: An Approximate Message Passing Framework for Transfer Learning with Applications to Lasso-based Estimators','Approximate Message Passing (AMP) algorithms enable precise characterization\nof certain classes of random objects in the high-dimensional limit, and have\nfound widespread applications in fields such as statistics, deep learning,\ngenetics, and communications. However, existing AMP frameworks cannot\nsimultaneously handle matrix-valued iterates and non-separable denoising\nfunctions. This limitation prevents them from precisely characterizing\nestimators that draw information from multiple data sources with distribution\nshifts. In this work, we introduce Generalized Long Approximate Message Passing\n(GLAMP), a novel extension of AMP that addresses this limitation. We rigorously\nprove state evolution for GLAMP. GLAMP significantly broadens the scope of AMP,\nenabling the analysis of transfer learning estimators that were previously out\nof reach. We demonstrate the utility of GLAMP by precisely characterizing the\nrisk of three Lasso-based transfer learning estimators: the Stacked Lasso, the\nModel Averaging Estimator, and the Second Step Estimator. We also demonstrate\nthe remarkable finite sample accuracy of our theory via extensive simulations.','Longlin Wang, Yanke Song, Kuanhao Jiang, Pragya Sur','2025-05-28','math.ST','http://arxiv.org/pdf/2505.22594v1'),('2505.22597v1','HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined in HDDL with OpenAI Gym','In recent years, reinforcement learning (RL) methods have been widely tested\nusing tools like OpenAI Gym, though many tasks in these environments could also\nbenefit from hierarchical planning. However, there is a lack of a tool that\nenables seamless integration of hierarchical planning with RL. Hierarchical\nDomain Definition Language (HDDL), used in classical planning, introduces a\nstructured approach well-suited for model-based RL to address this gap. To\nbridge this integration, we introduce HDDLGym, a Python-based tool that\nautomatically generates OpenAI Gym environments from HDDL domains and problems.\nHDDLGym serves as a link between RL and hierarchical planning, supporting\nmulti-agent scenarios and enabling collaborative planning among agents. This\npaper provides an overview of HDDLGym\\\'s design and implementation, highlighting\nthe challenges and design choices involved in integrating HDDL with the Gym\ninterface, and applying RL policies to support hierarchical planning. We also\nprovide detailed instructions and demonstrations for using the HDDLGym\nframework, including how to work with existing HDDL domains and problems from\nInternational Planning Competitions, exemplified by the Transport domain.\nAdditionally, we offer guidance on creating new HDDL domains for multi-agent\nscenarios and demonstrate the practical use of HDDLGym in the Overcooked\ndomain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a\nvaluable tool for studying RL in hierarchical planning, particularly in\nmulti-agent contexts.','Ngoc La, Ruaridh Mon-Williams, Julie A. Shah','2025-05-28','cs.AI','http://arxiv.org/pdf/2505.22597v1'),('2505.22598v1','On the performance of machine-learning assisted Monte Carlo in sampling from simple statistical physics models','Recent years have seen a rise in the application of machine learning\ntechniques to aid the simulation of hard-to-sample systems that cannot be\nstudied using traditional methods. Despite the introduction of many different\narchitectures and procedures, a wide theoretical understanding is still\nlacking, with the risk of suboptimal implementations. As a first step to\naddress this gap, we provide here a complete analytic study of the widely-used\nSequential Tempering procedure applied to a shallow MADE architecture for the\nCurie-Weiss model. The contribution of this work is twofold: firstly, we give a\ndescription of the optimal weights and of the training under Gradient Descent\noptimization. Secondly, we compare what happens in Sequential Tempering with\nand without the addition of local Metropolis Monte Carlo steps. We are thus\nable to give theoretical predictions on the best procedure to apply in this\ncase. This work establishes a clear theoretical basis for the integration of\nmachine learning techniques into Monte Carlo sampling and optimization.','Luca Maria Del Bono, Federico Ricci-Tersenghi, Francesco Zamponi','2025-05-28','cond-mat.dis-nn','http://arxiv.org/pdf/2505.22598v1'),('2505.22601v1','Machine Unlearning under Overparameterization','Machine unlearning algorithms aim to remove the influence of specific\ntraining samples, ideally recovering the model that would have resulted from\ntraining on the remaining data alone. We study unlearning in the\noverparameterized setting, where many models interpolate the data, and defining\nthe unlearning solution as any loss minimizer over the retained\nset$\\unicode{x2013}$as in prior work in the underparameterized\nsetting$\\unicode{x2013}$is inadequate, since the original model may already\ninterpolate the retained data and satisfy this condition. In this regime, loss\ngradients vanish, rendering prior methods based on gradient perturbations\nineffective, motivating both new unlearning definitions and algorithms. For\nthis setting, we define the unlearning solution as the minimum-complexity\ninterpolator over the retained data and propose a new algorithmic framework\nthat only requires access to model gradients on the retained set at the\noriginal solution. We minimize a regularized objective over perturbations\nconstrained to be orthogonal to these model gradients, a first-order relaxation\nof the interpolation condition. For different model classes, we provide exact\nand approximate unlearning guarantees, and we demonstrate that an\nimplementation of our framework outperforms existing baselines across various\nunlearning experiments.','Jacob L. Block, Aryan Mokhtari, Sanjay Shakkottai','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22601v1'),('2505.22602v1','One Rank at a Time: Cascading Error Dynamics in Sequential Learning','Sequential learning -- where complex tasks are broken down into simpler,\nhierarchical components -- has emerged as a paradigm in AI. This paper views\nsequential learning through the lens of low-rank linear regression, focusing\nspecifically on how errors propagate when learning rank-1 subspaces\nsequentially. We present an analysis framework that decomposes the learning\nprocess into a series of rank-1 estimation problems, where each subsequent\nestimation depends on the accuracy of previous steps. Our contribution is a\ncharacterization of the error propagation in this sequential process,\nestablishing bounds on how errors -- e.g., due to limited computational budgets\nand finite precision -- affect the overall model accuracy. We prove that these\nerrors compound in predictable ways, with implications for both algorithmic\ndesign and stability guarantees.','Mahtab Alizadeh Vandchali, Fangshuo, Liao, Anastasios Kyrillidis','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22602v1'),('2505.22608v1','Effective and Efficient One-pass Compression of Speech Foundation Models Using Sparsity-aware Self-pinching Gates','This paper presents a novel approach for speech foundation models compression\nthat tightly integrates model pruning and parameter update into a single stage.\nHighly compact layer-level tied self-pinching gates each containing only a\nsingle learnable threshold are jointly trained with uncompressed models and\nused in fine-grained neuron level pruning. Experiments conducted on the\nLibriSpeech-100hr corpus suggest that our approach reduces the number of\nparameters of wav2vec2.0-base and HuBERT-large models by 65% and 60%\nrespectively, while incurring no statistically significant word error rate\n(WER) increase on the test-clean dataset. Compared to previously published\nmethods on the same task, our approach not only achieves the lowest WER of\n7.05% on the test-clean dataset under a comparable model compression ratio of\n4.26x, but also operates with at least 25% less model compression time.','Haoning Xu, Zhaoqing Li, Youjun Chen, Huimeng Wang, Guinan Li, Mengzhe Geng, Chengxi Deng, Xunying Liu','2025-05-28','cs.SD','http://arxiv.org/pdf/2505.22608v1'),('2505.22609v1','Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method','In this work, we investigate the performance across multiple classification\nmodels to classify chest X-ray images into four categories of COVID-19,\npneumonia, tuberculosis (TB), and normal cases. We leveraged transfer learning\ntechniques with state-of-the-art pre-trained Convolutional Neural Networks\n(CNNs) models. We fine-tuned these pre-trained architectures on a labeled\nmedical x-ray images. The initial results are promising with high accuracy and\nstrong performance in key classification metrics such as precision, recall, and\nF1 score. We applied Gradient-weighted Class Activation Mapping (Grad-CAM) for\nmodel interpretability to provide visual explanations for classification\ndecisions, improving trust and transparency in clinical applications.','Alanna Hazlett, Naomi Ohashi, Timothy Rodriguez, Sodiq Adewole','2025-05-28','eess.IV','http://arxiv.org/pdf/2505.22609v1'),('2505.22613v1','RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction','Image recaptioning is widely used to generate training datasets with enhanced\nquality for various multimodal tasks. Existing recaptioning methods typically\nrely on powerful multimodal large language models (MLLMs) to enhance textual\ndescriptions, but often suffer from inaccuracies due to hallucinations and\nincompleteness caused by missing fine-grained details. To address these\nlimitations, we propose RICO, a novel framework that refines captions through\nvisual reconstruction. Specifically, we leverage a text-to-image model to\nreconstruct a caption into a reference image, and prompt an MLLM to identify\ndiscrepancies between the original and reconstructed images to refine the\ncaption. This process is performed iteratively, further progressively promoting\nthe generation of more faithful and comprehensive descriptions. To mitigate the\nadditional computational cost induced by the iterative process, we introduce\nRICO-Flash, which learns to generate captions like RICO using DPO. Extensive\nexperiments demonstrate that our approach significantly improves caption\naccuracy and completeness, outperforms most baselines by approximately 10% on\nboth CapsBench and CompreCap. Code released at\nhttps://github.com/wangyuchi369/RICO.','Yuchi Wang, Yishuo Cai, Shuhuai Ren, Sihan Yang, Linli Yao, Yuanxin Liu, Yuanxing Zhang, Pengfei Wan, Xu Sun','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22613v1'),('2505.22617v1','The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models','This paper aims to overcome a major obstacle in scaling RL for reasoning with\nLLMs, namely the collapse of policy entropy. Such phenomenon is consistently\nobserved across vast RL runs without entropy intervention, where the policy\nentropy dropped sharply at the early training stage, this diminished\nexploratory ability is always accompanied with the saturation of policy\nperformance. In practice, we establish a transformation equation R=-a*e^H+b\nbetween entropy H and downstream performance R. This empirical law strongly\nindicates that, the policy performance is traded from policy entropy, thus\nbottlenecked by its exhaustion, and the ceiling is fully predictable H=0,\nR=-a+b. Our finding necessitates entropy management for continuous exploration\ntoward scaling compute for RL. To this end, we investigate entropy dynamics\nboth theoretically and empirically. Our derivation highlights that, the change\nin policy entropy is driven by the covariance between action probability and\nthe change in logits, which is proportional to its advantage when using Policy\nGradient-like algorithms. Empirical study shows that, the values of covariance\nterm and entropy differences matched exactly, supporting the theoretical\nconclusion. Moreover, the covariance term stays mostly positive throughout\ntraining, further explaining why policy entropy would decrease monotonically.\nThrough understanding the mechanism behind entropy dynamics, we motivate to\ncontrol entropy by restricting the update of high-covariance tokens.\nSpecifically, we propose two simple yet effective techniques, namely Clip-Cov\nand KL-Cov, which clip and apply KL penalty to tokens with high covariances\nrespectively. Experiments show that these methods encourage exploration, thus\nhelping policy escape entropy collapse and achieve better downstream\nperformance.','Ganqu Cui, Yuchen Zhang, Jiacheng Chen, Lifan Yuan, Zhi Wang, Yuxin Zuo, Haozhan Li, Yuchen Fan, Huayu Chen, Weize Chen, Zhiyuan Liu, Hao Peng, Lei Bai, Wanli Ouyang, Yu Cheng, Bowen Zhou, Ning Ding','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22617v1'),('2505.22618v1','Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding','Diffusion-based large language models (Diffusion LLMs) have shown promise for\nnon-autoregressive text generation with parallel decoding capabilities.\nHowever, the practical inference speed of open-sourced Diffusion LLMs often\nlags behind autoregressive models due to the lack of Key-Value (KV) Cache and\nquality degradation when decoding multiple tokens simultaneously. To bridge\nthis gap, we introduce a novel block-wise approximate KV Cache mechanism\ntailored for bidirectional diffusion models, enabling cache reuse with\nnegligible performance drop. Additionally, we identify the root cause of\ngeneration quality degradation in parallel decoding as the disruption of token\ndependencies under the conditional independence assumption. To address this, we\npropose a confidence-aware parallel decoding strategy that selectively decodes\ntokens exceeding a confidence threshold, mitigating dependency violations and\nmaintaining generation quality. Experimental results on LLaDA and Dream models\nacross multiple LLM benchmarks demonstrate up to \\textbf{27.6$\\times$\nthroughput} improvement with minimal accuracy loss, closing the performance gap\nwith autoregressive models and paving the way for practical deployment of\nDiffusion LLMs.','Chengyue Wu, Hao Zhang, Shuchen Xue, Zhijian Liu, Shizhe Diao, Ligeng Zhu, Ping Luo, Song Han, Enze Xie','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22618v1'),('2505.22622v1','Principled Out-of-Distribution Generalization via Simplicity','Modern foundation models exhibit remarkable out-of-distribution (OOD)\ngeneralization, solving tasks far beyond the support of their training data.\nHowever, the theoretical principles underpinning this phenomenon remain\nelusive. This paper investigates this problem by examining the compositional\ngeneralization abilities of diffusion models in image generation. Our analysis\nreveals that while neural network architectures are expressive enough to\nrepresent a wide range of models -- including many with undesirable behavior on\nOOD inputs -- the true, generalizable model that aligns with human expectations\ntypically corresponds to the simplest among those consistent with the training\ndata.\n  Motivated by this observation, we develop a theoretical framework for OOD\ngeneralization via simplicity, quantified using a predefined simplicity metric.\nWe analyze two key regimes: (1) the constant-gap setting, where the true model\nis strictly simpler than all spurious alternatives by a fixed gap, and (2) the\nvanishing-gap setting, where the fixed gap is replaced by a smoothness\ncondition ensuring that models close in simplicity to the true model yield\nsimilar predictions. For both regimes, we study the regularized maximum\nlikelihood estimator and establish the first sharp sample complexity guarantees\nfor learning the true, generalizable, simple model.','Jiawei Ge, Amanda Wang, Shange Tang, Chi Jin','2025-05-28','stat.ML','http://arxiv.org/pdf/2505.22622v1'),('2505.22626v1','SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning','Imitation learning advances robot capabilities by enabling the acquisition of\ndiverse behaviors from human demonstrations. However, large-scale datasets used\nfor policy training often introduce substantial variability in quality, which\ncan negatively impact performance. As a result, automatically curating datasets\nby filtering low-quality samples to improve quality becomes essential. Existing\nrobotic curation approaches rely on costly manual annotations and perform\ncuration at a coarse granularity, such as the dataset or trajectory level,\nfailing to account for the quality of individual state-action pairs. To address\nthis, we introduce SCIZOR, a self-supervised data curation framework that\nfilters out low-quality state-action pairs to improve the performance of\nimitation learning policies. SCIZOR targets two complementary sources of\nlow-quality data: suboptimal data, which hinders learning with undesirable\nactions, and redundant data, which dilutes training with repetitive patterns.\nSCIZOR leverages a self-supervised task progress predictor for suboptimal data\nto remove samples lacking task progression, and a deduplication module\noperating on joint state-action representation for samples with redundant\npatterns. Empirically, we show that SCIZOR enables imitation learning policies\nto achieve higher performance with less data, yielding an average improvement\nof 15.4% across multiple benchmarks. More information is available at:\nhttps://ut-austin-rpl.github.io/SCIZOR/','Yu Zhang, Yuqi Xie, Huihan Liu, Rutav Shah, Michael Wan, Linxi Fan, Yuke Zhu','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.22626v1'),('2505.22627v1','Chain-of-Talkers (CoTalk): Fast Human Annotation of Dense Image Captions','While densely annotated image captions significantly facilitate the learning\nof robust vision-language alignment, methodologies for systematically\noptimizing human annotation efforts remain underexplored. We introduce\nChain-of-Talkers (CoTalk), an AI-in-the-loop methodology designed to maximize\nthe number of annotated samples and improve their comprehensiveness under fixed\nbudget constraints (e.g., total human annotation time). The framework is built\nupon two key insights. First, sequential annotation reduces redundant workload\ncompared to conventional parallel annotation, as subsequent annotators only\nneed to annotate the ``residual\\\'\\\' -- the missing visual information that\nprevious annotations have not covered. Second, humans process textual input\nfaster by reading while outputting annotations with much higher throughput via\ntalking; thus a multimodal interface enables optimized efficiency. We evaluate\nour framework from two aspects: intrinsic evaluations that assess the\ncomprehensiveness of semantic units, obtained by parsing detailed captions into\nobject-attribute trees and analyzing their effective connections; extrinsic\nevaluation measures the practical usage of the annotated captions in\nfacilitating vision-language alignment. Experiments with eight participants\nshow our Chain-of-Talkers (CoTalk) improves annotation speed (0.42 vs. 0.30\nunits/sec) and retrieval performance (41.13\\% vs. 40.52\\%) over the parallel\nmethod.','Yijun Shen, Delong Chen, Fan Liu, Xingyu Wang, Chuanyi Zhang, Liang Yao, Yuhui Zheng','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22627v1'),('2505.22630v1','Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs','The widespread success of large language models (LLMs) on NLP benchmarks has\nbeen accompanied by concerns that LLMs function primarily as stochastic parrots\nthat reproduce texts similar to what they saw during pre-training, often\nerroneously. But what is the nature of their errors, and do these errors\nexhibit any regularities? In this work, we examine irrelevant context\nhallucinations, in which models integrate misleading contextual cues into their\npredictions. Through behavioral analysis, we show that these errors result from\na structured yet flawed mechanism that we term class-based (mis)generalization,\nin which models combine abstract class cues with features extracted from the\nquery or context to derive answers. Furthermore, mechanistic interpretability\nexperiments on Llama-3, Mistral, and Pythia across 39 factual recall relation\ntypes reveal that this behavior is reflected in the model\\\'s internal\ncomputations: (i) abstract class representations are constructed in lower\nlayers before being refined into specific answers in higher layers, (ii)\nfeature selection is governed by two competing circuits -- one prioritizing\ndirect query-based reasoning, the other incorporating contextual cues -- whose\nrelative influences determine the final output. Our findings provide a more\nnuanced perspective on the stochastic parrot argument: through form-based\ntraining, LLMs can exhibit generalization leveraging abstractions, albeit in\nunreliable ways based on contextual cues -- what we term stochastic chameleons.','Ziling Cheng, Meng Cao, Marc-Antoine Rondeau, Jackie Chi Kit Cheung','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22630v1'),('2505.22633v1','Spatial Knowledge Graph-Guided Multimodal Synthesis','Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced their capabilities; however, their spatial perception\nabilities remain a notable limitation. To address this challenge, multimodal\ndata synthesis offers a promising solution. Yet, ensuring that synthesized data\nadhere to spatial common sense is a non-trivial task. In this work, we\nintroduce SKG2Data, a novel multimodal synthesis approach guided by spatial\nknowledge graphs, grounded in the concept of knowledge-to-data generation.\nSKG2Data automatically constructs a Spatial Knowledge Graph (SKG) to emulate\nhuman-like perception of spatial directions and distances, which is\nsubsequently utilized to guide multimodal data synthesis. Extensive experiments\ndemonstrate that data synthesized from diverse types of spatial knowledge,\nincluding direction and distance, not only enhance the spatial perception and\nreasoning abilities of MLLMs but also exhibit strong generalization\ncapabilities. We hope that the idea of knowledge-based data synthesis can\nadvance the development of spatial intelligence.','Yida Xue, Zhen Bi, Jinnan Yang, Jungang Lou, Huajun Chen, Ningyu Zhang','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22633v1'),('2505.22635v1','Learning Composable Chains-of-Thought','A common approach for teaching large language models (LLMs) to reason is to\ntrain on chain-of-thought (CoT) traces of in-distribution reasoning problems,\nbut such annotated data is costly to obtain for every problem of interest. We\nwant reasoning models to generalize beyond their training distribution, and\nideally to generalize compositionally: combine atomic reasoning skills to solve\nharder, unseen reasoning tasks. We take a step towards compositional\ngeneralization of reasoning skills when addressing a target compositional task\nthat has no labeled CoT data. We find that simply training models on CoT data\nof atomic tasks leads to limited generalization, but minimally modifying CoT\nformats of constituent atomic tasks to be composable can lead to improvements.\nWe can train \"atomic CoT\" models on the atomic tasks with Composable CoT data\nand combine them with multitask learning or model merging for better zero-shot\nperformance on the target compositional task. Such a combined model can be\nfurther bootstrapped on a small amount of compositional data using rejection\nsampling fine-tuning (RFT). Results on string operations and natural language\nskill compositions show that training LLMs on Composable CoT outperforms\nmultitask learning and continued fine-tuning baselines within a given training\ndata budget.','Fangcong Yin, Zeyu Leo Liu, Liu Leqi, Xi Ye, Greg Durrett','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22635v1'),('2505.22637v1','Understanding (Un)Reliability of Steering Vectors in Language Models','Steering vectors are a lightweight method to control language model behavior\nby adding a learned bias to the activations at inference time. Although\nsteering demonstrates promising performance, recent work shows that it can be\nunreliable or even counterproductive in some cases. This paper studies the\ninfluence of prompt types and the geometry of activation differences on\nsteering reliability. First, we find that all seven prompt types used in our\nexperiments produce a net positive steering effect, but exhibit high variance\nacross samples, and often give an effect opposite of the desired one. No prompt\ntype clearly outperforms the others, and yet the steering vectors resulting\nfrom the different prompt types often differ directionally (as measured by\ncosine similarity). Second, we show that higher cosine similarity between\ntraining set activation differences predicts more effective steering. Finally,\nwe observe that datasets where positive and negative activations are better\nseparated are more steerable. Our results suggest that vector steering is\nunreliable when the target behavior is not represented by a coherent direction.','Joschka Braun, Carsten Eickhoff, David Krueger, Seyed Ali Bahrainian, Dmitrii Krasheninnikov','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22637v1'),('2505.22638v1','SimProcess: High Fidelity Simulation of Noisy ICS Physical Processes','Industrial Control Systems (ICS) manage critical infrastructures like power\ngrids and water treatment plants. Cyberattacks on ICSs can disrupt operations,\ncausing severe economic, environmental, and safety issues. For example,\nundetected pollution in a water plant can put the lives of thousands at stake.\nICS researchers have increasingly turned to honeypots -- decoy systems designed\nto attract attackers, study their behaviors, and eventually improve defensive\nmechanisms. However, existing ICS honeypots struggle to replicate the ICS\nphysical process, making them susceptible to detection. Accurately simulating\nthe noise in ICS physical processes is challenging because different factors\nproduce it, including sensor imperfections and external interferences.\n  In this paper, we propose SimProcess, a novel framework to rank the fidelity\nof ICS simulations by evaluating how closely they resemble real-world and noisy\nphysical processes. It measures the simulation distance from a target system by\nestimating the noise distribution with machine learning models like Random\nForest. Unlike existing solutions that require detailed mathematical models or\nare limited to simple systems, SimProcess operates with only a timeseries of\nmeasurements from the real system, making it applicable to a broader range of\ncomplex dynamic systems. We demonstrate the framework\\\'s effectiveness through a\ncase study using real-world power grid data from the EPIC testbed. We compare\nthe performance of various simulation methods, including static and generative\nnoise techniques. Our model correctly classifies real samples with a recall of\nup to 1.0. It also identifies Gaussian and Gaussian Mixture as the best\ndistribution to simulate our power systems, together with a generative solution\nprovided by an autoencoder, thereby helping developers to improve honeypot\nfidelity. Additionally, we make our code publicly available.','Denis Donadel, Gabriele Crestanello, Giulio Morandini, Daniele Antonioli, Mauro Conti, Massimo Merro','2025-05-28','cs.CR','http://arxiv.org/pdf/2505.22638v1'),('2505.22641v1','Spectral Survival Analysis','Survival analysis is widely deployed in a diverse set of fields, including\nhealthcare, business, ecology, etc. The Cox Proportional Hazard (CoxPH) model\nis a semi-parametric model often encountered in the literature. Despite its\npopularity, wide deployment, and numerous variants, scaling CoxPH to large\ndatasets and deep architectures poses a challenge, especially in the\nhigh-dimensional regime. We identify a fundamental connection between rank\nregression and the CoxPH model: this allows us to adapt and extend the\nso-called spectral method for rank regression to survival analysis. Our\napproach is versatile, naturally generalizing to several CoxPH variants,\nincluding deep models. We empirically verify our method\\\'s scalability on\nmultiple real-world high-dimensional datasets; our method outperforms legacy\nmethods w.r.t. predictive performance and efficiency.','Chengzhi Shi, Stratis Ioannidis','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22641v1'),('2505.22642v1','FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control','Reinforcement learning (RL) has driven significant progress in robotics, but\nits complexity and long training times remain major bottlenecks. In this\nreport, we introduce FastTD3, a simple, fast, and capable RL algorithm that\nsignificantly speeds up training for humanoid robots in popular suites such as\nHumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably\nsimple: we train an off-policy TD3 agent with several modifications -- parallel\nsimulation, large-batch updates, a distributional critic, and carefully tuned\nhyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours\non a single A100 GPU, while remaining stable during training. We also provide a\nlightweight and easy-to-use implementation of FastTD3 to accelerate RL research\nin robotics.','Younggyo Seo, Carmelo Sferrazza, Haoran Geng, Michal Nauman, Zhao-Heng Yin, Pieter Abbeel','2025-05-28','cs.RO','http://arxiv.org/pdf/2505.22642v1'),('2505.22645v1','Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese','While the capabilities of Large Language Models (LLMs) have been studied in\nboth Simplified and Traditional Chinese, it is yet unclear whether LLMs exhibit\ndifferential performance when prompted in these two variants of written\nChinese. This understanding is critical, as disparities in the quality of LLM\nresponses can perpetuate representational harms by ignoring the different\ncultural contexts underlying Simplified versus Traditional Chinese, and can\nexacerbate downstream harms in LLM-facilitated decision-making in domains such\nas education or hiring. To investigate potential LLM performance disparities,\nwe design two benchmark tasks that reflect real-world scenarios: regional term\nchoice (prompting the LLM to name a described item which is referred to\ndifferently in Mainland China and Taiwan), and regional name choice (prompting\nthe LLM to choose who to hire from a list of names in both Simplified and\nTraditional Chinese). For both tasks, we audit the performance of 11 leading\ncommercial LLM services and open-sourced models -- spanning those primarily\ntrained on English, Simplified Chinese, or Traditional Chinese. Our analyses\nindicate that biases in LLM responses are dependent on both the task and\nprompting language: while most LLMs disproportionately favored Simplified\nChinese responses in the regional term choice task, they surprisingly favored\nTraditional Chinese names in the regional name choice task. We find that these\ndisparities may arise from differences in training data representation, written\ncharacter preferences, and tokenization of Simplified and Traditional Chinese.\nThese findings highlight the need for further analysis of LLM biases; as such,\nwe provide an open-sourced benchmark dataset to foster reproducible evaluations\nof future LLM behavior across Chinese language variants\n(https://github.com/brucelyu17/SC-TC-Bench).','Hanjia Lyu, Jiebo Luo, Jian Kang, Allison Koenecke','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22645v1'),('2505.22648v1','WebDancer: Towards Autonomous Information Seeking Agency','Addressing intricate real-world problems necessitates in-depth information\nseeking and multi-step reasoning. Recent progress in agentic systems,\nexemplified by Deep Research, underscores the potential for autonomous\nmulti-step research. In this work, we present a cohesive paradigm for building\nend-to-end agentic information seeking agents from a data-centric and\ntraining-stage perspective. Our approach consists of four key stages: (1)\nbrowsing data construction, (2) trajectories sampling, (3) supervised\nfine-tuning for effective cold start, and (4) reinforcement learning for\nenhanced generalisation. We instantiate this framework in a web agent based on\nthe ReAct, WebDancer. Empirical evaluations on the challenging information\nseeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of\nWebDancer, achieving considerable results and highlighting the efficacy of our\ntraining paradigm. Further analysis of agent training provides valuable\ninsights and actionable, systematic pathways for developing more capable\nagentic models. The codes and demo will be released in\nhttps://github.com/Alibaba-NLP/WebAgent.','Jialong Wu, Baixuan Li, Runnan Fang, Wenbiao Yin, Liwen Zhang, Zhengwei Tao, Dingchu Zhang, Zekun Xi, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22648v1'),('2505.22649v1','Pre-training for Recommendation Unlearning','Modern recommender systems powered by Graph Neural Networks (GNNs) excel at\nmodeling complex user-item interactions, yet increasingly face scenarios\nrequiring selective forgetting of training data. Beyond user requests to remove\nspecific interactions due to privacy concerns or preference changes, regulatory\nframeworks mandate recommender systems\\\' ability to eliminate the influence of\ncertain user data from models. This recommendation unlearning challenge\npresents unique difficulties as removing connections within interaction graphs\ncreates ripple effects throughout the model, potentially impacting\nrecommendations for numerous users. Traditional approaches suffer from\nsignificant drawbacks: fragmentation methods damage graph structure and\ndiminish performance, while influence function techniques make assumptions that\nmay not hold in complex GNNs, particularly with self-supervised or random\narchitectures. To address these limitations, we propose a novel model-agnostic\npre-training paradigm UnlearnRec that prepares systems for efficient unlearning\noperations. Our Influence Encoder takes unlearning requests together with\nexisting model parameters and directly produces updated parameters of unlearned\nmodel with little fine-tuning, avoiding complete retraining while preserving\nmodel performance characteristics. Extensive evaluation on public benchmarks\ndemonstrates that our method delivers exceptional unlearning effectiveness\nwhile providing more than 10x speedup compared to retraining approaches. We\nrelease our method implementation at: https://github.com/HKUDS/UnlearnRec.','Guoxuan Chen, Lianghao Xia, Chao Huang','2025-05-28','cs.IR','http://arxiv.org/pdf/2505.22649v1'),('2505.22650v1','On Learning Verifiers for Chain-of-Thought Reasoning','Chain-of-Thought reasoning has emerged as a powerful approach for solving\ncomplex mathematical and logical problems. However, it can often veer off track\nthrough incorrect or unsubstantiated inferences. Formal mathematical reasoning,\nwhich can be checked with a formal verifier, is one approach to addressing this\nissue. However, currently LLMs are simply not good enough to solve complex\nproblems in a formal way, and even just formalizing an informal problem\nstatement can be challenging. Motivated by this fact, in this work we consider\nthe problem of learning reliable verifiers for natural language\nChain-of-Thought reasoning. That is, given a problem statement and step-by-step\nsolution in natural language, the aim of the verifier is to output [Yes] if the\nreasoning steps in the solution are all valid, and [No] otherwise. In this work\nwe give a formal PAC-learning framework for studying this problem. We propose\nand analyze several natural verification goals, at different levels of\nstrength, in this framework. We provide sample complexity upper-bounds for\nlearning verifiers satisfying these goals, as well as lower-bound and\nimpossibility results for learning other natural verification objectives\nwithout additional assumptions.','Maria-Florina Balcan, Avrim Blum, Zhiyuan Li, Dravyansh Sharma','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22650v1'),('2505.22651v1','Sherlock: Self-Correcting Reasoning in Vision-Language Models','Reasoning Vision-Language Models (VLMs) have shown promising performance on\ncomplex multimodal tasks. However, they still face significant challenges: they\nare highly sensitive to reasoning errors, require large volumes of annotated\ndata or accurate verifiers, and struggle to generalize beyond specific domains.\nTo address these limitations, we explore self-correction as a strategy to\nenhance reasoning VLMs. We first conduct an in-depth analysis of reasoning\nVLMs\\\' self-correction abilities and identify key gaps. Based on our findings,\nwe introduce Sherlock, a self-correction and self-improvement training\nframework. Sherlock introduces a trajectory-level self-correction objective, a\npreference data construction method based on visual perturbation, and a dynamic\n$\\beta$ for preference tuning. Once the model acquires self-correction\ncapabilities using only 20k randomly sampled annotated data, it continues to\nself-improve without external supervision. Built on the Llama3.2-Vision-11B\nmodel, Sherlock achieves remarkable results across eight benchmarks, reaching\nan average accuracy of 64.1 with direct generation and 65.4 after\nself-correction. It outperforms LLaVA-CoT (63.2), Mulberry (63.9), and\nLlamaV-o1 (63.4) while using less than 20% of the annotated data.','Yi Ding, Ruqi Zhang','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22651v1'),('2505.22653v1','The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in Learning to Reason','Recent studies on post-training large language models (LLMs) for reasoning\nthrough reinforcement learning (RL) typically focus on tasks that can be\naccurately verified and rewarded, such as solving math problems. In contrast,\nour research investigates the impact of reward noise, a more practical\nconsideration for real-world scenarios involving the post-training of LLMs\nusing reward models. We found that LLMs demonstrate strong robustness to\nsubstantial reward noise. For example, manually flipping 40% of the reward\nfunction\\\'s outputs in math tasks still allows a Qwen-2.5-7B model to achieve\nrapid convergence, improving its performance on math tasks from 5% to 72%,\ncompared to the 75% accuracy achieved by a model trained with noiseless\nrewards. Surprisingly, by only rewarding the appearance of key reasoning\nphrases (namely reasoning pattern reward, RPR), such as ``first, I need\nto\\\'\\\'-without verifying the correctness of answers, the model achieved peak\ndownstream performance (over 70% accuracy for Qwen-2.5-7B) comparable to models\ntrained with strict correctness verification and accurate rewards. Recognizing\nthe importance of the reasoning process over the final results, we combined RPR\nwith noisy reward models. RPR helped calibrate the noisy reward models,\nmitigating potential false negatives and enhancing the LLM\\\'s performance on\nopen-ended tasks. These findings suggest the importance of improving models\\\'\nfoundational abilities during the pre-training phase while providing insights\nfor advancing post-training techniques. Our code and scripts are available at\nhttps://github.com/trestad/Noisy-Rewards-in-Learning-to-Reason.','Ang Lv, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Rui Yan','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22653v1'),('2505.22655v1','Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents','Large-language models (LLMs) and chatbot agents are known to provide wrong\noutputs at times, and it was recently found that this can never be fully\nprevented. Hence, uncertainty quantification plays a crucial role, aiming to\nquantify the level of ambiguity in either one overall number or two numbers for\naleatoric and epistemic uncertainty. This position paper argues that this\ntraditional dichotomy of uncertainties is too limited for the open and\ninteractive setup that LLM agents operate in when communicating with a user,\nand that we need to research avenues that enrich uncertainties in this novel\nscenario. We review the literature and find that popular definitions of\naleatoric and epistemic uncertainties directly contradict each other and lose\ntheir meaning in interactive LLM agent settings. Hence, we propose three novel\nresearch directions that focus on uncertainties in such human-computer\ninteractions: Underspecification uncertainties, for when users do not provide\nall information or define the exact task at the first go, interactive learning,\nto ask follow-up questions and reduce the uncertainty about the current\ncontext, and output uncertainties, to utilize the rich language and speech\nspace to express uncertainties as more than mere numbers. We expect that these\nnew ways of dealing with and communicating uncertainties will lead to LLM agent\ninteractions that are more transparent, trustworthy, and intuitive.','Michael Kirchhof, Gjergji Kasneci, Enkelejda Kasneci','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22655v1'),('2505.22657v1','3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model','Humans excel at performing complex tasks by leveraging long-term memory\nacross temporal and spatial experiences. In contrast, current Large Language\nModels (LLMs) struggle to effectively plan and act in dynamic, multi-room 3D\nenvironments. We posit that part of this limitation is due to the lack of\nproper 3D spatial-temporal memory modeling in LLMs. To address this, we first\nintroduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000\ntrajectories and 2,892 embodied tasks, question-answering and captioning,\ndesigned to evaluate an agent\\\'s ability to reason over long-term memory in 3D\nenvironments. Second, we propose 3DLLM-Mem, a novel dynamic memory management\nand fusion model for embodied spatial-temporal reasoning and actions in LLMs.\nOur model uses working memory tokens, which represents current observations, as\nqueries to selectively attend to and fuse the most useful spatial and temporal\nfeatures from episodic memory, which stores past observations and interactions.\nOur approach allows the agent to focus on task-relevant information while\nmaintaining memory efficiency in complex, long-horizon environments.\nExperimental results demonstrate that 3DLLM-Mem achieves state-of-the-art\nperformance across various tasks, outperforming the strongest baselines by\n16.5% in success rate on 3DMem-Bench\\\'s most challenging in-the-wild embodied\ntasks.','Wenbo Hu, Yining Hong, Yanjun Wang, Leison Gao, Zibu Wei, Xingcheng Yao, Nanyun Peng, Yonatan Bitton, Idan Szpektor, Kai-Wei Chang','2025-05-28','cs.CV','http://arxiv.org/pdf/2505.22657v1'),('2505.22660v1','Maximizing Confidence Alone Improves Reasoning','Reinforcement learning (RL) has enabled machine learning models to achieve\nsignificant advances in many fields. Most recently, RL has empowered frontier\nlanguage models to solve challenging math, science, and coding problems.\nHowever, central to any RL algorithm is the reward function, and reward\nengineering is a notoriously difficult problem in any domain. In this paper, we\npropose RENT: Reinforcement Learning via Entropy Minimization -- a fully\nunsupervised RL method that requires no external reward or ground-truth\nanswers, and instead uses the model\\\'s entropy of its underlying distribution as\nan intrinsic reward. We find that by reinforcing the chains of thought that\nyield high model confidence on its generated answers, the model improves its\nreasoning ability. In our experiments, we showcase these improvements on an\nextensive suite of commonly-used reasoning benchmarks, including GSM8K,\nMATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen and\nMistral families. The generality of our unsupervised learning method lends\nitself to applicability in a wide range of domains where external supervision\nis limited or unavailable.','Mihir Prabhudesai, Lili Chen, Alex Ippoliti, Katerina Fragkiadaki, Hao Liu, Deepak Pathak','2025-05-28','cs.LG','http://arxiv.org/pdf/2505.22660v1'),('2505.22661v1','GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning','The evaluation of large language models (LLMs) has traditionally relied on\nstatic benchmarks, a paradigm that poses two major limitations: (1) predefined\ntest sets lack adaptability to diverse application domains, and (2)\nstandardized evaluation protocols often fail to capture fine-grained\nassessments of domain-specific knowledge and contextual reasoning abilities. To\novercome these challenges, we propose GuessArena, an adaptive evaluation\nframework grounded in adversarial game-based interactions. Inspired by the\ninteractive structure of the Guess Who I Am? game, our framework seamlessly\nintegrates dynamic domain knowledge modeling with progressive reasoning\nassessment to improve evaluation fidelity. Empirical studies across five\nvertical domains-finance, healthcare, manufacturing, information technology,\nand education-demonstrate that GuessArena effectively distinguishes LLMs in\nterms of domain knowledge coverage and reasoning chain completeness. Compared\nto conventional benchmarks, our method provides substantial advantages in\ninterpretability, scalability, and scenario adaptability.','Qingchen Yu, Zifan Zheng, Ding Chen, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22661v1'),('2505.22662v1','AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models','The reasoning-capable large language models (LLMs) demonstrate strong\nperformance on complex reasoning tasks but often suffer from overthinking,\ngenerating unnecessarily long chain-of-thought (CoT) reasoning paths for easy\nreasoning questions, thereby increasing inference cost and latency. Recent\napproaches attempt to address this challenge by manually deciding when to apply\nlong or short reasoning. However, they lack the flexibility to adapt CoT length\ndynamically based on question complexity. In this paper, we propose Auto\nLong-Short Reasoning (AutoL2S), a dynamic and model-agnostic framework that\nenables LLMs to dynamically compress their generated reasoning path based on\nthe complexity of the reasoning question. AutoL2S enables a learned paradigm,\nin which LLMs themselves can decide when longer reasoning is necessary and when\nshorter reasoning suffices, by training on data annotated with our proposed\nmethod, which includes both long and short CoT paths and a special <EASY>\ntoken. We then use <EASY> token to indicate when the model can skip generating\nlengthy CoT reasoning. This proposed annotation strategy can enhance the LLMs\\\'\nability to generate shorter CoT reasoning paths with improved quality after\ntraining. Extensive evaluation results show that AutoL2S reduces the length of\nreasoning generation by up to 57% without compromising performance,\ndemonstrating the effectiveness of AutoL2S for scalable and efficient LLM\nreasoning.','Feng Luo, Yu-Neng Chuang, Guanchu Wang, Hoang Anh Duy Le, Shaochen Zhong, Hongyi Liu, Jiayi Yuan, Yang Sui, Vladimir Braverman, Vipin Chaudhary, Xia Hu','2025-05-28','cs.CL','http://arxiv.org/pdf/2505.22662v1');
/*!40000 ALTER TABLE `arxiv_papers` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2025-06-01 22:13:53
